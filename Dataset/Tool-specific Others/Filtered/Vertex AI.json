[
    {
        "Question_title":"DocAI - Form Processor table issue",
        "Question_creation_date":"2022-11-23T22:00:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/DocAI-Form-Processor-table-issue\/td-p\/492493\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":44,
        "Question_body":"Hello,\nI used Document AI form processor to convert pdf file table data into table object.\nSome table data are not converted properly.In the sample file, the 3rd table is not detected columns properly.\nCould you please throw some light on this ?Source PDF fileAfter conversion using form processor. The third one is having issue on column detection.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-28T12:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Document AI is powered by Machine Learning models and results are not always what is expected due to number of reasons (input quality, volume, etc.), but this service is continuously\u00a0improved.\n\nYou may file a PIT case and a Google Engineer that is directly working on the product can assist you."
            },
            {
                "Answer_creation_date":"2022-11-28T20:03:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks much. I will file a case and I hope I can get a solution over there."
            }
        ]
    },
    {
        "Question_title":"Feelings in Machine",
        "Question_creation_date":"2022-11-28T15:10:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Feelings-in-Machine\/td-p\/494006\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":13,
        "Question_body":"Can we think about it? If yes , then share your thoughts ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-28T15:10:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can we think about it? If yes , then share your thoughts"
            }
        ]
    },
    {
        "Question_title":"Dialogflow CX logs sink to BigQuery. sink error - field: value is not a record",
        "Question_creation_date":"2022-11-16T07:48:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-CX-logs-sink-to-BigQuery-sink-error-field-value-is\/td-p\/490079\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":260,
        "Question_body":"I am using google cloud logging to sink Dialogflow CX requests data to big query. BigQuery tables are auto generated when you create the sink via Google Logging.We keep getting a sink error - field: value is not a record.This is because pageInfo\/formInfo\/parameterInfo\/value is of type String in BigQuery BUT there are values that are records, not strings. One example is @sys.date-timeHow do we fix this?We have not tried anything at this point since the BigQuery dataset is auto created via a Logging Filter. We cannot modify the logs and if we could modify the table schema, what would we change it to since most of the time \"Value\" is a String but other times it is a Record",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-18T10:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Currently working with your question."
            },
            {
                "Answer_creation_date":"2022-11-18T16:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"With the information you shared, I\u2019m afraid it\u2019s not possible to provide a good solution.\n\nPlease include sufficient code and any guides you followed or your process so that we can analyze the issue."
            },
            {
                "Answer_creation_date":"2022-11-19T04:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This is an article that explains how to set up the logging to BigQuery:\u00a0https:\/\/medium.com\/google-cloud\/dialogflow-cx-response-logging-e1b77d7a9fc6\n\nThere is no code, just create a simple agent in Dialogflow CX and set up at least one parameter with entity type\u00a0@sys.date-time, turn on logging, create BigQuery sink, then test the agent a few times and you should get the error notice that the sink has been disabled.\n\nThe financial services example agent would probably show the same bug if you triggered the \"Investigate charges\" intent"
            },
            {
                "Answer_creation_date":"2022-11-28T13:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"With the information you provided from your project, I would highly recommend you to review this Troubleshooting routing and sinks documentation.\n\nAdditionally, you can actually create a PIT (Public Issue Tracker - Dialogflow CX), or please engage GCP Support if you're paying or if you're interested in starting to pay for a Support Package. Please be aware that from these 2 options, the second one is the fastest."
            }
        ]
    },
    {
        "Question_title":"The kernel for MyTest.ipynb appears to have died. It will restart automatically.",
        "Question_creation_date":"2022-11-24T11:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/The-kernel-for-MyTest-ipynb-appears-to-have-died-It-will-restart\/td-p\/492715\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":33,
        "Question_body":"Hello,I'm trying to run a test jupyter notebook of a LSTM model running tensorflow. I have tried setting the GPU memory limit like suggested here. But still the I get the error mentioned above. I can not find anything realted to GC vertex AI and everyone suggest setting the gpu memory in case of such errors. For reference I have tried to run this as well on my Vertex AI jupyter lab and it crashes as well. The only thing I added was this:gpus = tf.config.list_physical_devices('GPU')\nif gpus:\ntf.config.set_logical_device_configuration(\ngpus[0],\n[tf.config.LogicalDeviceConfiguration(memory_limit=12288)]\n)logical_gpus = tf.config.list_logical_devices('GPU')\nprint(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")On my personal computer it runs just fine, but it would take 13 hours to train which is not a option for me at the moment.Any help would be appriciated. Barnabas.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-28T12:08:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, can you share the error you encountered?"
            }
        ]
    },
    {
        "Question_title":"Cloud Vision API in Vertex AI?",
        "Question_creation_date":"2022-11-28T02:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-Vision-API-in-Vertex-AI\/td-p\/493648\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":22,
        "Question_body":"  Hi,I am a newbie in Google Cloud and i have an elementary conceptual question about the dependency between Cloud Vision API and Vertex AI or the recently launched Vertex Vision AI.I have an app that makes predictions on images using Google Vision AI API ImageAnnotatorClient() Is this API going to be part of  Vertex AI  or Vertex Vision AI?Or in other words, should I modify the below code to make it part of Vertex AI\/Vertex Vision AI?          ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-28T02:59:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI am a newbie in Google Cloud and i have an elementary conceptual question about the dependency between\u00a0Cloud Vision API and Vertex AI or the recently launched Vertex Vision AI.\n\nI have an app that makes predictions on images using Google Vision AI API\u00a0ImageAnnotatorClient()\u00a0\n\nIs this API going to be part of\u00a0 Vertex AI\u00a0 or Vertex Vision AI?\n\nOr in other words, should I modify the below code to make it part of Vertex AI\/Vertex Vision AI?\n\n\u00a0\n\nfrom google.cloud import vision\n\ndef detect_labels_uri(uri):\n    client = vision.ImageAnnotatorClient()\n    image = vision.Image()\n    image.source.image_uri = uri\n\n    response = client.label_detection(image=image)\n    labels = response.label_annotations\n    return(labels)"
            }
        ]
    },
    {
        "Question_title":"EntityAnalysis, Version 2 model in natural language API",
        "Question_creation_date":"2022-11-17T12:28:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/EntityAnalysis-Version-2-model-in-natural-language-API\/td-p\/490557\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_upvote_count":0,
        "Question_view_count":162,
        "Question_body":"Hello,could anyone share the python code on how to get natural language API to use version 2 for Entity  Sentiment Analysis?\nThe Demo can be run for that, but it seems like in the docs this part is missing:\nhttps:\/\/cloud.google.com\/natural-language\/docs\/reference\/rest\/v1\/documents\/analyzeEntitySentiment\n\nHowever, for the classification, it is possible, as it is described here: \nhttps:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Version-2-model-in-natural-language-API\/m-p\/484641\n\nThanks ",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"When using the classifyText method of the API, the classification models are available. However, for Entity Sentiment Analysis there is no mention of available options or models that can be declared. Can you add more details of your use case to review?"
            },
            {
                "Answer_creation_date":"2022-11-22T20:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I was using a demo from:\nhttps:\/\/cloud.google.com\/natural-language\n\nAnd here the API provides an example for the V2 of the model, including Entity Analysis for the German\nHowever, when I go to the docs (https:\/\/cloud.google.com\/natural-language\/docs\/reference\/rest\/v1\/documents\/analyzeEntitySentiment)\nI can`t see the option to use V2 model for Entity Analysis, one V1\nHowever, for the Classification Model there is an option:\u00a0https:\/\/cloud.google.com\/natural-language\/docs\/reference\/rest\/v1\/ClassificationModelOptions\n\nSo, my question is: can I use V2 model for the Entity Analysis?\u00a0\nThanks"
            },
            {
                "Answer_creation_date":"2022-11-23T13:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The Natural Language API documentation includes all available code samples. Could you direct me to the one you refer to? Most likely there is some clarification to make, as there is no mention of a V2 model that can be used."
            },
            {
                "Answer_creation_date":"2022-11-24T05:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am interested in the:\nhttps:\/\/cloud.google.com\/natural-language\/docs\/samples\/language-entities-text\n\nHowever, I want to use V2 model for Entity Analysis, as it supports German\nIs it possible to use V2 here ?\u00a0\n\nThanks"
            },
            {
                "Answer_creation_date":"2022-11-25T15:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"German language support is not available for Entity Sentiment Analysis, as the only listed languages\u00a0for it are English, Japanese, and Spanish. There might have been some confusion with the V2 model for Content Classification, since it includes broader language options. However, this model is only for Content Classification, not for Entity Sentiment Analysis, which offers no such option.\n\nKeep in mind that standalone Sentiment analysis and Entity analysis do offer support for German, in case you need either of those API features instead. As a note, you can raise a Feature Request in Google\u2019s Issue Tracker. It would be brought to the attention of the appropriate teams to implement support in the future; however, there\u2019s no assurance of an ETA."
            }
        ]
    },
    {
        "Question_title":"Google cloud speech to text : Dealing with high amount of input data in realtime",
        "Question_creation_date":"2022-09-28T07:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-cloud-speech-to-text-Dealing-with-high-amount-of-input\/td-p\/471924\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":63,
        "Question_body":"Scenario: We are receiving huge amount of voice data streams which could be upto couple of minutes long. There will huge set of data streams as an input every second. This a real time application where I get live data from multiple users and return response from api. I am using google' AsyncStreamingRecognize to create stream. This stream open, read and write functions are blocking as I cannot proceed with other operation until success is returned by get() functions. Due to this my threads responsible for dealing with stream data are getting blocked. Is there a better way to where I can write high amount of input data without my thread being blocked for previous write function ? The code\/setup works fine for a single call in real time. But I doubt how to design it well that could handle huge realtime incoming traffic",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-27T06:05:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi vaibhav_jio, sorry for possible inconvenience. I've noticed you might be explorer of speech recognition engine. I\u2019m owner of a small company A-Transcript, which providing Finnish and Russian native transcription crowd services within comparably small budget (might process other languages as well). (website: a-transcript.com, email: info@a-transcript.com). I do have also some work experience behind on LaMDA and speech recognition engines. Wonder if you could provide any contacts, who are qualified to discuss about collaboration and taking business proposal. Thank you in advance and wish you a great day."
            },
            {
                "Answer_creation_date":"2022-11-23T10:36:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Do you have the capability to deliver speech-to-text subtitles on a VR glass product?"
            },
            {
                "Answer_creation_date":"2022-11-24T00:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"hi hello249, thank you for request. Unfortunately at the moment I'm not familiar with such technology. My services is about providing qualified transcribers, onboard and manage them. (Type of transcription text could be subtitles as well as AI datasets (text with tags including). In order if you are agree with this, then would be glad to have calloboration. my company's email: <PII removed by staff>"
            }
        ]
    },
    {
        "Question_title":"Google Translation issue",
        "Question_creation_date":"2022-10-28T08:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translation-issue\/td-p\/483154\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_upvote_count":0,
        "Question_view_count":205,
        "Question_body":"Hello Team,I am trying to document translation using Google cloud translate V3.I found some issue in below-1. Text Overlapping from German to English2.Some text position was not correct3.table column name show in bottom of pages.4.Some pages were not being Translate. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-31T16:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you please share more information about your project and the process that you are following ?"
            },
            {
                "Answer_creation_date":"2022-11-03T00:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nWe are using google translate cloud Service V3 with \"BatchDocumentService\".\n\nFirst Image is in German Language and Second Image is translate into english but you can see Text overlapping in below-"
            },
            {
                "Answer_creation_date":"2022-11-08T00:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Team,\n\nAny update from your side ,it is really urgent."
            },
            {
                "Answer_creation_date":"2022-11-15T22:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Team,\n\nAny update?"
            },
            {
                "Answer_creation_date":"2022-11-23T12:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Following this process using projects.translateText Method on Cloud Translation API, the translation worked fine.\n\nIn order to better understand how we might assist, please provide more details about how you are utilizing the Cloud Translation API if this behavior seems unique to your use-case and implementation. You may, for instance, let us know what version of the Translation API is being used. Aside from that, consider the translation process you're using. Tell us how you are gathering the data; is it through a web user interface?"
            }
        ]
    },
    {
        "Question_title":"What's the training corpus of models behind GCP Natural Language APIs?",
        "Question_creation_date":"2022-11-17T14:36:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-s-the-training-corpus-of-models-behind-GCP-Natural-Language\/td-p\/490614\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Cloud Natural Language API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":45,
        "Question_body":"Hi, where can I find some information about which datasets are used for training models that power the natural language APIs for sentiment analysis, entity extraction, etc.? Thanks!",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-23T08:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Natural Language API is trained using different types of datasets.\n\nPublic datasets Examples: Five crowd-flower\u00a0sentiment benchmarks\nEAP customer datasets Examples: Feefo sentiment dataset\nAcademic datasets Examples: Stanford rotten tomatoes sentences, UCI Sentiment Labeled Sentences Data Set. See.\nGoogle datasets Examples: Shopping, Play."
            }
        ]
    },
    {
        "Question_title":"A 10+2 Students thrust for Programming can really enable his abilities to capture the AI?",
        "Question_creation_date":"2022-11-23T08:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/A-10-2-Students-thrust-for-Programming-can-really-enable-his\/td-p\/492261\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":18,
        "Question_body":"Students passed out from 10+2 are desperate enough to pursue AI through certifications, bachelor degree and in many other ways.... I am wondering is it really possible for them to capture AI and navigate in an easy manner these days. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-23T08:05:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Students passed out from 10+2 are desperate enough to pursue AI through certifications, bachelor degree and in many other ways....\n\n\u00a0\n\nI am wondering is it really possible for them to capture AI and navigate in an easy manner these days."
            }
        ]
    },
    {
        "Question_title":"Vertex AI video action recognition - can it return action timeframes instead of a timestamps?",
        "Question_creation_date":"2022-11-20T13:47:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-video-action-recognition-can-it-return-action\/td-p\/491200\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Video Intelligence API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":131,
        "Question_body":"My problem is that my usecase requires the AI engine I use to provide predictions with the entire duration of the action. It seems to me that vertex AI picks a random frame in the span of the action and return it as the same start\/end values. Here's an excerpt from an actual response Can I make it work the way I need it to? Maybe I'm annotating in a wrong manner?Here's a mockup of what I need. Notice how timeSegmentStart and timeSegmentEnd represent a duration now:",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T11:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nHaving the equal values for timeSegmentStart and timeSegmentEnd is an expected behavior as seen in this sample prediction response.\n\nWhat I could suggest is to create a feature request in GCPs\u00a0public issue tracker regarding your request.\u00a0Please keep in mind that when you create the feature request, it still needs to be analyzed and considered by the product team and a definite ETA is not guaranteed."
            },
            {
                "Answer_creation_date":"2022-11-23T00:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"@ricconoel\u00a0thanks for your reply. I agree that according to the sample this behavior is expected, however i wanted to know if it can be altered or configured. Looks weird to me that action recognition AI would stop at giving an arbitrary timestamp and not the whole duration of the action. Is there a way to find out if this feature is *already* implemented?"
            },
            {
                "Answer_creation_date":"2022-11-23T07:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Unfortunately it cannot be altered or configured as of now. Hence my suggestion to create a feature request."
            }
        ]
    },
    {
        "Question_title":"Google vertex AI support is terrible",
        "Question_creation_date":"2022-11-22T20:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-vertex-AI-support-is-terrible\/td-p\/492001\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":51,
        "Question_body":"I usually don't post things like this but I have been trying to work with Google support for Vertex AI for a while. It has been a month on a P2 ticket and no help or support so far. I guess I don't pay the big bucks to get Google's attention. So just wanted to post a warning that is helpful hopefully. Use Vertex AI at your own risk. If something fails you are on your own.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T20:59:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I pay for support by the way. Not expecting free support."
            }
        ]
    },
    {
        "Question_title":"How can I explicitly authenticate to the ai-platform using the java PredictionServiceClient",
        "Question_creation_date":"2022-11-21T14:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-explicitly-authenticate-to-the-ai-platform-using-the\/td-p\/491537\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":66,
        "Question_body":"I have a model hosted on a Google Cloud endpoint and I would like to access it via the Java client.  I've created a service account and a key for that service account with the , when I run my client code with the GOOGLE_APPLICATION_CREDENTIALS env var pointed to the key, I am able to call the service.  When I try to authenticate explicitly using FixedCredentialProvider, it fails with an \"unauthenticated\" message.  The code is as follows`````` ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T09:27:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nUpon checking your code, FixedCredentialsProvider.create()\u00a0accepts\u00a0com.google.auth.Credentials\u00a0as a parameter. Can you try a Credentials object to\u00a0FixedCredentialsProvider.create()? See code below:\n\nGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(\"\/Users\/ME\/Downloads\/XYZ.json\")).createScoped(Lists.newArrayList(\"https:\/\/www.googleapis.com\/auth\/cloud-platform\"));\n\n\u00a0If code above did not work, can you provide the stack trace of the error? Also what roles did you assign on your service account?\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-22T09:27:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nUpon checking your code, FixedCredentialsProvider.create()\u00a0accepts\u00a0com.google.auth.Credentials\u00a0as a parameter. Can you try a Credentials object to\u00a0FixedCredentialsProvider.create()? See code below:\n\nGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(\"\/Users\/ME\/Downloads\/XYZ.json\")).createScoped(Lists.newArrayList(\"https:\/\/www.googleapis.com\/auth\/cloud-platform\"));\n\n\u00a0If code above did not work, can you provide the stack trace of the error? Also what roles did you assign on your service account?"
            },
            {
                "Answer_creation_date":"2022-11-22T13:31:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"This worked. Thank you!"
            }
        ]
    },
    {
        "Question_title":"How would you model a list of an unknown number of items in DialogFlow CX?",
        "Question_creation_date":"2022-11-21T19:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-would-you-model-a-list-of-an-unknown-number-of-items-in\/td-p\/491605\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":35,
        "Question_body":"Hi,Taking from the example at Dialogflow CX: Build a retail virtual agent , if you were to build a shopping cart where users could add unlimited items to purchase. How would you model a solution for this?That is, instead of having:Can we have something equivalent to:How?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T10:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nYou might want to see this example where the user created a shopping cart based using Dialogflow CX."
            }
        ]
    },
    {
        "Question_title":"Glossary not found.; Failed to initialize a glossary.",
        "Question_creation_date":"2022-11-17T20:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Glossary-not-found-Failed-to-initialize-a-glossary\/td-p\/490677\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":42,
        "Question_body":"I have created glossary to translate text using Cloud Translation API. it shows me status as running-\n\"name\": \"projects\/xxx\/locations\/us-central1\/operations\/xxx\",\n\"metadata\": {\n\"@type\": \"type.googleapis.com\/google.cloud.translation.v3.CreateGlossaryMetadata\",\n\"name\": \"projects\/xxx\/locations\/us-central1\/glossaries\/xxx\",\n\"state\": \"RUNNING\",\n\"submitTime\": \"2022-11-18T03:59:51.876209069Z\"\n}\n}but when I am trying to use this Glossary for translation api, it shows me error as-\n\"Glossary not found.; Failed to initialize a glossary\".\nEven when I tried listing my Glossary, it doesn't show.Not sure what is the issue. Console activity dashboard shows activity as created Glossary.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T09:59:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Make sure that all permissions are appropriately established.\n\n\u00a0\n\nIn order to make sure you see it, I would suggest listing your glossaries. If you don't, at least you are aware of the problem.\n\nFurthermore, I don't believe that this is a permissions issue. Explicit permission errors ought to be returned if there is a permission problem.\n\nI advise beginning with the create glossary sample and then attempting to access the same resource using the example code you're using in order to troubleshoot."
            }
        ]
    },
    {
        "Question_title":"How to organize intents\/pages for a non-service\/support application",
        "Question_creation_date":"2022-11-21T04:03:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-organize-intents-pages-for-a-non-service-support\/td-p\/491306\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":44,
        "Question_body":"I am a new Dialogflow user and I need to create an agent for an application that is not service or support oriented.  The application is educational and has a large collection of questions and answers (1,000s) with no concrete conclusion (for example,  to renew a driver's license).  For the POC I did in Watson I was able to use folders to organize sub-topics.  What is the best way to group intents and responses by topic and sub-topic (for example, President Lincoln's early life President Lincoln's career)?  I expect it would be difficult to manage a list of 1,000s of pages in the left pane.  Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T09:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0@NoankMary, are you using Dialogflow CX or ES?"
            }
        ]
    },
    {
        "Question_title":"Google Cloud AutoML Vision annotation stopped working",
        "Question_creation_date":"2022-11-18T13:16:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-AutoML-Vision-annotation-stopped-working\/td-p\/490920\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":55,
        "Question_body":"Has anyone encountered the issue where the AutoML Vision annotations for datasets stopped working. This includes not being able to change labels anymore, not being able delete created labels or not save create labels. The annotations were working as expected last week, but for some reason they stopped working this week.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T22:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you share the screenshot?"
            },
            {
                "Answer_creation_date":"2022-11-22T07:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Here is a screenshot of one of the images in my dataset. I can add annotations of the default label type, but cannot change the type of label afterwards. As you can see the default is all cropland labels but since I cannot change the label type, all of them are stuck as \"cropland\"(even though there are 3 labels available for this dataset).\n\n\u00a0The labels behaves as if they are a regular text instead of a dropdown list.\n\nAlso the delete button for each of the labels do not work, as it appears but nothing happens when you click it. Moreover, the cancel button at the bottom of the screen is clickable but does not do anything either."
            },
            {
                "Answer_creation_date":"2022-11-22T08:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for sharing\u00a0@akanel, since this seems to be an issue specific to your project, you may raise a 1:1 GCP support. This kind of support has access to your internal resources and may check your issue in a more comprehensive way."
            }
        ]
    },
    {
        "Question_title":"Airflow Dag for Vertex AI",
        "Question_creation_date":"2022-11-20T02:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Airflow-Dag-for-Vertex-AI\/td-p\/491123\/jump-to\/first-unread-message",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":38,
        "Question_body":"Please advice on how to create airflow dag for vertex ai.**********************************************************\nfrom datetime import datetime\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom google.cloud import aiplatform\nfrom airflow.operators import CreateDatasetOperatorYESTERDAY = datetime.datetime.now() - datetime.timedelta(days=1)default_dag_args = {\n\n'start_date': YESTERDAY,\n}with models.DAG(\n'composer_sample_simple_greeting',\nschedule_interval=datetime.timedelta(weeks=2),\ndefault_args=default_dag_args) as dag:\n\ndef create_entity_type_sample(\nproject: str,\nlocation: str,\nentity_type_id: str,\nvertexai: str,\nservice_account_id: str\ntask_id: str,\nproject_id: str,aiplatform.init(project=project, location=location)my_entity_type = aiplatform.EntityType.create(\nentity_type_id=entity_type_id, vertexai=vertexai\n)my_entity_type.wait()return my_entity_typecreate_image_dataset_job = CreateDatasetOperator(\ntask_id=\"image_dataset\",\ndataset=IMAGE_DATASET,\nregion=REGION,\nproject_id=PROJECT_ID,\n)\ncreate_tabular_dataset_job = CreateDatasetOperator(\ntask_id=\"tabular_dataset\",\ndataset=TABULAR_DATASET,\nregion=REGION,\nproject_id=PROJECT_ID,\n)\ncreate_text_dataset_job = CreateDatasetOperator(\ntask_id=\"text_dataset\",\ndataset=TEXT_DATASET,\nregion=REGION,\nproject_id=PROJECT_ID,\n)\ncreate_video_dataset_job = CreateDatasetOperator(\ntask_id=\"video_dataset\",\ndataset=VIDEO_DATASET,\nregion=REGION,\nproject_id=PROJECT_ID,\n)\ncreate_time_series_dataset_job = CreateDatasetOperator(\ntask_id=\"time_series_dataset\",\ndataset=TIME_SERIES_DATASET,\nregion=REGION,\nproject_id=PROJECT_ID,\n)create_image_dataset_job >> create_tabular_dataset_job >> create_text_dataset_job >> create_video_dataset_job >> create_time_series_dataset_job\n************************************************************************************************************************",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T23:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can check in this link for available Google Cloud VertexAI Operators. There are available operators for creating Datasets (in which you already used in your code), training jobs, batch prediction jobs, endpoint service and more.\u00a0\n\nYou may also check this documentation on how to run an apache airflow DAG in Cloud Composer."
            }
        ]
    },
    {
        "Question_title":"Vertex AI deploy custom model error - Model server terminated: model server container terminated:",
        "Question_creation_date":"2022-11-18T05:47:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-deploy-custom-model-error-Model-server-terminated\/td-p\/490796\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":50,
        "Question_body":"Hi, I'm stuck at following error message when I try to deploy custom model to vertex-ai endpoint.Command:  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T21:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You may check here some things you can check further when deploying your model. If this does not work, it would be helpful to file a 1:1 support case since they can check your internal resources."
            }
        ]
    },
    {
        "Question_title":"Authenticating to Vertex AI deployed endpoints",
        "Question_creation_date":"2022-11-10T13:57:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Authenticating-to-Vertex-AI-deployed-endpoints\/td-p\/488229\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":97,
        "Question_body":"Hello, I am a new user of Vertex AI.  I have trained and deployed a tabular data categorization model to an Vertex AI hosted endpoint.  I have successfully called it from a program running on my laptop where the \"gcloud\" cli is installed.  If I want to run this not from my desktop but have it called from another service, how do I authenticate ?  I have created a service account but I am not sure 1) what roles would need to be attached to that account and 2) how I would provide the service account credentials given that I don't have much control over how the service that will call my model is started (i.e. I can't control its environment vars).  Any help would be appreciated! ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-11T22:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, for starters, you may read the basic concepts of IAM and\u00a0service accounts\u00a0\n\nYou may check this\u00a0pre-defined roles\u00a0for Vertex AI that you can attach on your service account depending on the level of permission you want to give.\u00a0\n\nFor the second question, you need to be a Service Account Admin as per this official\u00a0GCP Documentation\u00a0for you to manage a service account."
            },
            {
                "Answer_creation_date":"2022-11-21T07:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for the response.\u00a0 Now I know I need ServiceAccountAdmin.\u00a0 The thing I'm still not clear on is whether there is some way to provide the service account credentials without referencing a file on the file system.\u00a0 For example, if I'm accessing the service from a client to whose file system I have no access, what are my options ?"
            },
            {
                "Answer_creation_date":"2022-11-21T09:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If this is a file from a service you have no control of, the permission should be given on the side of that service."
            },
            {
                "Answer_creation_date":"2022-11-21T13:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This is custom code that is deployed to an app server like environment. I can deploy code and config to the app server but I don't control the environment variables that the app servers starts up with and I don't control the file system.\u00a0 I'd like to deploy code to the app server that accesses Google hosted model endpoints.\u00a0 Is there some way to do to authenticate to Google Cloud other than setting an environment variable that points to credentials on the file system ?"
            }
        ]
    },
    {
        "Question_title":"Google Vertex AI Automl Model ID is invalid. It should start with 3 letters Error",
        "Question_creation_date":"2022-11-20T02:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Vertex-AI-Automl-Model-ID-is-invalid-It-should-start-with\/td-p\/491126\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":30,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nYou get the error because you are using the old AutoML API to run predictions. See model_id created when the old AutoML API is used.\n\nSince you have trained your model using Vertex AutoML Classification (you got the 18 digit number), you should use aiplatform to run your predictions. See sample prediction code."
            }
        ]
    },
    {
        "Question_title":"Changing the service account for an endpoint",
        "Question_creation_date":"2022-11-21T01:37:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Changing-the-service-account-for-an-endpoint\/td-p\/491278\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":28,
        "Question_body":"Hi, I have deployed a Vertex AI model that was created using a custom image. However, when I tried deploying to an endpoint, it fails when it tries to run this line:In the logs, there was an error message that readsIt appears that the endpoint has been assigned a service account that is not associated with my account. From this documentation (https:\/\/cloud.google.com\/ai-platform\/prediction\/docs\/custom-service-account), it appears that a service account managed by AI Platform Prediction is being used when a custom container is being used. However, my account does not have the permissions to create another custom service account, as it is being managed by my client. I came across this solution (https:\/\/stackoverflow.com\/questions\/68456262\/gcp-vertex-ai-model-access-gcs-failed) where the user had the exact same problem and solved it by changing the service account used at the endpoint. As such, I would like to ask how it will be possible for me to change the service account used by the endpoint without having to create a new service account?Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T01:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I have deployed a Vertex AI model that was created using a custom image. However, when I tried deploying to an endpoint, it fails when it tries to run this line:\n\nbucket = client.get_bucket(\"my-project-id\")\n\nIn the logs, there was an error message that reads\n\ngoogle.api_core.exceptions.Forbidden: 403 GET https:\/\/storage.googleapis.com\/storage\/v1\/b\/{my project ID}?projection=noAcl&prettyPrint=false: custom-online-prediction@{some random numbers}-tp.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission 'storage.buckets.get' denied on resource (or it may not exist).\n\nIt appears that the endpoint has been assigned a service account that is not associated with my account. From this documentation (https:\/\/cloud.google.com\/ai-platform\/prediction\/docs\/custom-service-account), it appears that a\u00a0service account managed by AI Platform Prediction is being used when a custom container is being used. However, my account does not have the permissions\u00a0to create another custom service account, as it is being managed by my client.\u00a0\n\nI came across this solution (https:\/\/stackoverflow.com\/questions\/68456262\/gcp-vertex-ai-model-access-gcs-failed) where the user had the exact same problem and solved it by changing the service account used at the endpoint. As such, I would like to ask how it will be possible for me to change the service account used by the endpoint without having to create a new service account?\n\nThank you."
            }
        ]
    },
    {
        "Question_title":"DocAI - Response in a single json file",
        "Question_creation_date":"2022-11-17T23:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/DocAI-Response-in-a-single-json-file\/td-p\/490702\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":59,
        "Question_body":"Hello Experts,\nI'm doing BatchProcessDocument. I have 18 pages of a PDF file and tried to process this using DocumentProcessorServiceClient API. After the process, Im getting response in json file. This is perfect.\nBut the json output file is created only for the 5 pages of the source PDF file. Each 5 pages of the content are converted into a separate json file.My question here is, is it possible to have a single output json file for a PDF source file? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-18T15:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nJust to confirm, when you said \"Each 5 pages of the content are converted into a separate json file.\" does it mean that 1 json per page? or 1 json per 5 pages? Also can you provide the code and sample file that you are using? Please make sure there are no PIIs (Personal Identifiable Information) in your file when providing it here."
            },
            {
                "Answer_creation_date":"2022-11-20T21:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for you response. Actually I have two points.\n\nA pdf file should be processed and the response for this file in a single json file\nI have a file with a table of around 1000 rows. This table data can not be displayed in a single page. I just want a json object for this whole table. But currently the code is working for objects in a single page.\n\nBelow is my sample source code. I could not attach my sample file to this discussion.\n\n\u00a0\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileReader;\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.TimeoutException;\n\nimport com.google.api.gax.core.FixedCredentialsProvider;\n\n\/\/ [START documentai_batch_process_document]\n\nimport com.google.api.gax.longrunning.OperationFuture;\nimport com.google.api.gax.paging.Page;\nimport com.google.auth.oauth2.GoogleCredentials;\nimport com.google.cloud.documentai.v1.BatchDocumentsInputConfig;\nimport com.google.cloud.documentai.v1.BatchProcessMetadata;\nimport com.google.cloud.documentai.v1.BatchProcessRequest;\nimport com.google.cloud.documentai.v1.BatchProcessResponse;\nimport com.google.cloud.documentai.v1.Document;\nimport com.google.cloud.documentai.v1.DocumentOutputConfig;\nimport com.google.cloud.documentai.v1.DocumentOutputConfig.GcsOutputConfig;\nimport com.google.cloud.documentai.v1.DocumentProcessorServiceClient;\nimport com.google.cloud.documentai.v1.DocumentProcessorServiceSettings;\nimport com.google.cloud.documentai.v1.GcsDocument;\nimport com.google.cloud.documentai.v1.GcsDocuments;\nimport com.google.cloud.storage.Blob;\nimport com.google.cloud.storage.BlobId;\nimport com.google.cloud.storage.Bucket;\nimport com.google.cloud.storage.Storage;\nimport com.google.cloud.storage.StorageOptions;\nimport com.google.common.collect.Lists;\nimport com.google.protobuf.util.JsonFormat;\n\npublic class CustomProcessDocument {\n\t\n\tpublic static void main(String a[]) {\n\t\t\n\t\ttry {\n\t\t\tCustomProcess();\n\t\t} catch (IOException | InterruptedException | ExecutionException | TimeoutException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tpublic static void CustomProcess() \n\t\t\tthrows IOException, InterruptedException, ExecutionException, TimeoutException {\n\t\t\n        String projectId = \"my-project-id\";\n        String location = \"us\"; \/\/ Format is \"us\" or \"eu\".\n        String processerId = \"my-processor-id\";\n        String outputGcsBucketName = \"my-storage-bucket-name\";\n        String outputGcsPrefix = \"my-output-path\";\n        String inputGcsUri = \"gs:\/\/my-storage-bucket-name\/sample-pdf-file.pdf\";\n        String tokenPath = \"credentials-json-file-path\";\n        CustomProcessDoc(projectId, location, processerId, inputGcsUri, outputGcsBucketName, outputGcsPrefix, tokenPath);\n\t}\n\n    public static void CustomProcessDoc(String projectId, String location, String processorId, String gcsInputUri, \n    \t\tString gcsOutputBucketName, String gcsOutputUriPrefix, String tokenPath) {\n    \t\n        \/\/ Initialize client that will be used to send requests. This client only needs to be created\n        \/\/ once, and can be reused for multiple requests. After completing all of your requests, call\n        \/\/ the \"close\" method on the client to safely clean up any remaining background resources.\n        try {\n        \t\n        \tGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(tokenPath)).createScoped(Lists.newArrayList(\"https:\/\/www.googleapis.com\/auth\/cloud-platform\"));\n        \tDocumentProcessorServiceSettings setting = DocumentProcessorServiceSettings.newBuilder().setCredentialsProvider(FixedCredentialsProvider.create(credentials)).build();\n        \tDocumentProcessorServiceClient client = DocumentProcessorServiceClient.create(setting);\n        \t\n            \/\/ The full resource name of the processor, e.g.:\n            \/\/ projects\/project-id\/locations\/location\/processor\/processor-id\n            \/\/ You must create new processors in the Cloud Console first\n            String name = String.format(\"projects\/%s\/locations\/%s\/processors\/%s\", projectId, location, processorId);\n\n            GcsDocument gcsDocument = GcsDocument.newBuilder().setGcsUri(gcsInputUri).setMimeType(\"application\/pdf\").build();\n\n            GcsDocuments gcsDocuments = GcsDocuments.newBuilder().addDocuments(gcsDocument).build();\n\n            BatchDocumentsInputConfig inputConfig = BatchDocumentsInputConfig.newBuilder().setGcsDocuments(gcsDocuments).build();\n\n            String fullGcsPath = String.format(\"gs:\/\/%s\/%s\/\", gcsOutputBucketName, gcsOutputUriPrefix);\n            GcsOutputConfig gcsOutputConfig = GcsOutputConfig.newBuilder().setGcsUri(fullGcsPath).build();\n\n            DocumentOutputConfig documentOutputConfig = DocumentOutputConfig.newBuilder().setGcsOutputConfig(gcsOutputConfig).build();\n\n            \/\/ Configure the batch process request.\n            BatchProcessRequest request = BatchProcessRequest.newBuilder().setName(name).setInputDocuments(inputConfig).setDocumentOutputConfig(documentOutputConfig).build();\n\n            OperationFuture<BatchProcessResponse, BatchProcessMetadata> future = client.batchProcessDocumentsAsync(request);\n\n            \/\/ Batch process document using a long-running operation.\n            \/\/ You can wait for now, or get results later.\n            \/\/ Note: first request to the service takes longer than subsequent\n            \/\/ requests.\n            System.out.println(\"Waiting for operation to complete...\");\n            future.get(240, TimeUnit.SECONDS);\n\n            System.out.println(\"Document processing complete.\");\n\n\/\/            Storage storage = StorageOptions.newBuilder().setProjectId(projectId).build().getService();\n            Storage storage = StorageOptions.newBuilder().setCredentials(credentials).setProjectId(projectId).build().getService();\n            Bucket bucket = storage.get(gcsOutputBucketName);\n\n            \/\/ List all of the files in the Storage bucket.\n            Page<Blob> blobs = bucket.list(Storage.BlobListOption.prefix(gcsOutputUriPrefix + \"\/\"));\n            System.out.println(\"blobs : \"+blobs);\n            int idx = 0;\n            for (Blob blob : blobs.iterateAll()) {\n                if (!blob.isDirectory()) {\n                    System.out.printf(\"Fetched file #%d\\n\", ++idx);\n                    \/\/ Read the results\n\n                    \/\/ Download and store json data in a temp file.\n                    File tempFile = File.createTempFile(\"file\", \".json\");\n                    Blob fileInfo = storage.get(BlobId.of(gcsOutputBucketName, blob.getName()));\n                    fileInfo.downloadTo(tempFile.toPath());\n\n                    \/\/ Parse json file into Document.\n                    FileReader reader = new FileReader(tempFile);\n                    Document.Builder builder = Document.newBuilder();\n                    JsonFormat.parser().merge(reader, builder);\n\n                    Document document = builder.build();\n\n                    \/\/ Get all of the document text as one big string.\n                    String text = document.getText();\n\n                    \/\/ Read the text recognition output from the processor\n                    System.out.println(\"The document contains the following paragraphs:\");\n                    Document.Page page1 = document.getPages(0);\n                    List<Document.Page.Paragraph> paragraphList = page1.getParagraphsList();\n                    for (Document.Page.Paragraph paragraph : paragraphList) {\n                        String paragraphText = getText(paragraph.getLayout().getTextAnchor(), text);\n                        System.out.printf(\"Paragraph text:%s\\n\", paragraphText);\n                    }\n\n                    \/\/ Form parsing provides additional output about\n                    \/\/ form-formatted PDFs. You must create a form\n                    \/\/ processor in the Cloud Console to see full field details.\n                    System.out.println(\"The following form key\/value pairs were detected:\");\n\n                    for (Document.Page.FormField field : page1.getFormFieldsList()) {\n                        String fieldName = getText(field.getFieldName().getTextAnchor(), text);\n                        String fieldValue = getText(field.getFieldValue().getTextAnchor(), text);\n\n                        System.out.println(\"Extracted form fields pair:\");\n                        System.out.printf(\"\\t(%s, %s))\", fieldName, fieldValue);\n                    }\n\n                    \/\/ Clean up temp file.\n                    tempFile.deleteOnExit();\n                }\n            }\n        } catch (IOException | InterruptedException | TimeoutException | ExecutionException e) {\n        \te.printStackTrace();\n        }\n    }\n\n    \/\/ Extract shards from the text field\n    private static String getText(Document.TextAnchor textAnchor, String text) {\n    \t\n        if (textAnchor.getTextSegmentsList().size() > 0) {\n        \t\n            int startIdx = (int) textAnchor.getTextSegments(0).getStartIndex();\n            int endIdx = (int) textAnchor.getTextSegments(0).getEndIndex();\n            return text.substring(startIdx, endIdx);\n        }\n        return \"[NO TEXT]\";\n    }\n}"
            }
        ]
    },
    {
        "Question_title":"Vertex AI - Slow Batch Predictions",
        "Question_creation_date":"2022-01-20T06:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Slow-Batch-Predictions\/td-p\/184803\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":2,
        "Question_view_count":626,
        "Question_body":"Hi, I've been running a Vertex AI Tabular batch prediction job for about 500k rows (50MB BQ table) for nearly 5 hours now, and I can't see any reference to how it's performing anywhere. Is there an estimate for how long this should take? Or where I should look for progress?",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-21T14:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Liam,\u00a0\n\nYou might be able to check results in BigQuery or Cloud Storage [1] to estimate the progress on it. If this does not meet your demand, you might consider filing a feature request per instructions at [2].\u00a0\u00a0\n\n[1]\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/batch-predictions#retrieve_batch_prediction_resu...\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers"
            },
            {
                "Answer_creation_date":"2022-11-20T11:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\u00a0\n\nIt's not possible to check progress by checking the GCS output location. The output files only get uploaded after the job ends."
            }
        ]
    },
    {
        "Question_title":"Importing to Vertex dataset does not import labels.",
        "Question_creation_date":"2022-11-02T04:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Importing-to-Vertex-dataset-does-not-import-labels\/td-p\/484912\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_upvote_count":0,
        "Question_view_count":220,
        "Question_body":"In Vertex AI I am updating an image dataset, thus:the images are uploaded to the dataset but their labels are ignored and they are classed as Unlabeled. What am I doing wrong? TIA!\n\nPS they are in a csv, like:which worked fine for the dataset creation. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-03T17:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You could check this sample code to Import data for image classification single label:\n\n\u00a0\n\nfrom google.cloud import aiplatform\n\n\ndef import_data_image_classification_single_label_sample(\n    project: str,\n    dataset_id: str,\n    gcs_source_uri: str,\n    location: str = \"us-central1\",\n    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n    timeout: int = 1800,\n):\n    # The AI Platform services require regional API endpoints.\n    client_options = {\"api_endpoint\": api_endpoint}\n    # Initialize client that will be used to create and send requests.\n    # This client only needs to be created once, and can be reused for multiple requests.\n    client = aiplatform.gapic.DatasetServiceClient(client_options=client_options)\n    import_configs = [\n        {\n            \"gcs_source\": {\"uris\": [gcs_source_uri]},\n            \"import_schema_uri\": \"gs:\/\/google-cloud-aiplatform\/schema\/dataset\/ioformat\/image_classification_single_label_io_format_1.0.0.yaml\",\n        }\n    ]\n    name = client.dataset_path(project=project, location=location, dataset=dataset_id)\n    response = client.import_data(name=name, import_configs=import_configs)\n    print(\"Long running operation:\", response.operation.name)\n    import_data_response = response.result(timeout=timeout)\n    print(\"import_data_response:\", import_data_response)"
            },
            {
                "Answer_creation_date":"2022-11-04T07:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks, but exactly the same result."
            },
            {
                "Answer_creation_date":"2022-11-14T13:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"From this Tensorflow blog post:\n\nIn addition to image files, we've provided a CSV file (all_data.csv) containing the image URIs and labels. We randomly split this data into two files, train_set.csv and eval_set.csv, with 90% data for training and 10% for eval, respectively.\n\ngs:\/\/cloud-ml-data\/img\/flower_photos\/dandelion\/17388674711_6dca8a2e8b_n.jpg,dandelion\ngs:\/\/cloud-ml-data\/img\/flower_photos\/sunflowers\/9555824387_32b151e9b0_m.jpg,sunflowers\ngs:\/\/cloud-ml-data\/img\/flower_photos\/daisy\/14523675369_97c31d0b5b.jpg,daisy\ngs:\/\/cloud-ml-data\/img\/flower_photos\/roses\/512578026_f6e6f2ad26.jpg,roses\ngs:\/\/cloud-ml-data\/img\/flower_photos\/tulips\/497305666_b5d4348826_n.jpg,tulips\n\n\nWe also need a text file containing all the labels (dict.txt), which is used to sequentially map labels to internally used IDs. In this case, daisy would become ID 0 and tulips would become 4. If the label isn't in the file, it will be ignored from preprocessing and training.\n\ndaisy \ndandelion \nroses \nsunflowers \ntulips \n\n\nTherefore, you need to create the dict.txt file which will have the all the labels used as shown above.\n\nSee also:\n\nHow to classify images with TensorFlow using Google Cloud Machine Learning and Cloud Dataflow"
            },
            {
                "Answer_creation_date":"2022-11-15T03:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks but that is six years old and not a Vertex AI dataset."
            },
            {
                "Answer_creation_date":"2022-11-18T10:55:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you please raise a private thread in the issue tracker (referencing this question, as stated in the template) with the project ID, job ID and a sample data of your input CSV file (Don't want the entire file or any PII)?"
            }
        ]
    },
    {
        "Question_title":"Uploading images to Object detection with bounding boxes",
        "Question_creation_date":"2022-11-16T21:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Uploading-images-to-Object-detection-with-bounding-boxes\/td-p\/490325\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":78,
        "Question_body":"I am trying to upload images with bounding boxes and want to know is there an online tool that can calculate bounding box co-ordinates from an image specifically for Automl?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-18T10:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can have a look into this two articles:\n\nComputer Vision: Object Detection and No-Code AI with AutoML\nVisual Inspection AI: a purpose-built solution for faster, more accurate quality control"
            }
        ]
    },
    {
        "Question_title":"Dialogflox cx conflict: \"intents matching\" and \"parameters form\" at the same page.",
        "Question_creation_date":"2022-11-15T05:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflox-cx-conflict-quot-intents-matching-quot-and-quot\/td-p\/489582\/jump-to\/first-unread-message",
        "Question_topic":[
            "Contact Center AI",
            "Dialogflow CX",
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":67,
        "Question_body":"Hello everyone,I found an unexpected behavior with the following page-level configuration.CONFLICT: After the question \"What do you want? \", if the user input is not clear there will not be any intent matching, but if the user include in the sentence the word \"Value1\" which is synonym of \"Entity1\", then the parameter \"intent_param\" (entity type \"@intent\") will be collected with value \"Entity1\". When this happens I was expecting \"sys.no-match-1\" to be activated, but this did not occurred and the page state status is \"PROCESSING_FORM\" (FormFilled: false).Does anyone knows why this happens and if is there a way to avoid this behavior? In this situation I would like to continue the workflow with the  parameter collected and no intents matched.Thank you,\nMiguel.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-15T15:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you provide an example of\u00a0Value1? It would also help if you provide the whole response for investigation purposes."
            },
            {
                "Answer_creation_date":"2022-11-16T06:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello, this would be an example for the previous explanation:\n\nEntity type:\nEntity1: Tarjetas\nSynonyms: \"Tarjetas\", \"Cart\u00f3n\", \"Pl\u00e1stico\"\n\nPage (not start page):\n- Agent Fulfillment: \"What do you want?\"\n- Required\/Not required Parameter: \"intent_param\" (I said required in the previous explanation, in both cases I can't achieve what I was expecting)\n- Some intent Routes\n- Event handler (\"sys.no-match-1\")\n\nUser input: \"Pl\u00e1stico\"\n\nThe behavior which I was expecting is that Agent tried to match any of the intents and:\n1. If match, activates the corresponding intent route\n2. If no-match, activates the\u00a0\"sys.no-match-1\" event handler\n\nAnd I also expected that simultaneously, if the input matches with the Entity\/Synonym, the parameter was also collected and mapped with the corresponding entity.\n\nSummarizing, is it possible to collect a parameter (map entity type) and try to match intents, with one unique user input at the same time?\n\nResponse for Required parameter (Parameter is collected but event handler is not activated):\n\n{\n  \"advancedSettings\": {\n    \"audioExportGcsDestination\": {},\n    \"loggingSettings\": {\n      \"enableInteractionLogging\": true\n    },\n    \"speechSettings\": {\n      \"endpointerSensitivity\": 90,\n      \"noSpeechTimeout\": \"5s\"\n    }\n  },\n  \"currentPage\": {\n    \"displayName\": \"Prueba params\",\n    \"name\": \"projects\/dev-bbva-dialogflow-poc\/locations\/us-central1\/agents\/57dc60ad-5e59-4913-9c5a-dcef53842159\/flows\/9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\/pages\/5409aed3-7c85-47a8-aa87-2a84947d8b5d\"\n  },\n  \"diagnosticInfo\": {\n    \"Alternative Matched Intents\": [\n      {\n        \"Score\": 1,\n        \"Active\": true,\n        \"Parameters\": {\n          \"intent_param\": {\n            \"resolved\": \"REDACTED\",\n            \"original\": \"REDACTED\",\n            \"type\": \"@resolve_intent\"\n          }\n        },\n        \"Type\": \"NLU_SLOT\"\n      }\n    ],\n    \"Transition Targets Chain\": [],\n    \"Session Id\": \"19db1e-467-50c-8d4-69fdb3e1a\",\n    \"Triggered Transition Names\": [],\n    \"Execution Sequence\": [\n      {\n        \"Step 1\": {\n          \"InitialState\": {\n            \"SessionParameters\": {\n              \"intent_param\": \"REDACTED\"\n            },\n            \"MatchedIntent\": {\n              \"Active\": true,\n              \"Parameters\": {\n                \"intent_param\": {\n                  \"resolved\": \"REDACTED\",\n                  \"type\": \"@resolve_intent\",\n                  \"original\": \"REDACTED\"\n                }\n              },\n              \"Type\": \"NLU_SLOT\",\n              \"Score\": 1\n            },\n            \"FlowState\": {\n              \"Name\": \"Prueba params\",\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\",\n              \"Version\": 0,\n              \"PageState\": {\n                \"Name\": \"Prueba params\",\n                \"ActiveParameter\": \"intent_param\",\n                \"PageId\": \"5409aed3-7c85-47a8-aa87-2a84947d8b5d\",\n                \"FormFilled\": false,\n                \"Status\": \"PROCESSING_FORM\"\n              }\n            }\n          },\n          \"Type\": \"INITIAL_STATE\"\n        }\n      },\n      {\n        \"Step 2\": {\n          \"StateMachine\": {\n            \"FlowState\": {\n              \"Name\": \"Prueba params\",\n              \"Version\": 0,\n              \"PageState\": {\n                \"PageId\": \"5409aed3-7c85-47a8-aa87-2a84947d8b5d\",\n                \"FormFilled\": true,\n                \"Name\": \"Prueba params\",\n                \"Status\": \"TRANSITION_ROUTING\"\n              },\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\"\n            }\n          },\n          \"Type\": \"STATE_MACHINE\"\n        }\n      }\n    ]\n  },\n  \"intentDetectionConfidence\": 1,\n  \"languageCode\": \"es\",\n  \"match\": {\n    \"confidence\": 1,\n    \"matchType\": \"PARAMETER_FILLING\",\n    \"parameters\": {\n      \"intent_param\": \"Tarjetas\"\n    },\n    \"parametersOriginalValues\": {\n      \"intent_param\": \"Pl\u00e1stico\"\n    },\n    \"resolvedInput\": \"Pl\u00e1stico\"\n  },\n  \"parameters\": {\n    \"intent_param\": \"Tarjetas\"\n  },\n  \"redactedParameters\": [\n    \"intent_param\"\n  ],\n  \"responseMessages\": [\n    {\n      \"interactiveVoiceResponseSettings\": {\n        \"audioExportGcsDestination\": {},\n        \"speechSettings\": {\n          \"endpointerSensitivity\": 90,\n          \"noSpeechTimeout\": \"5s\"\n        }\n      }\n    }\n  ],\n  \"text\": \"Pl\u00e1stico\"\n}\n\n\u00a0Response for no roquired parameter (Event handler is activated, but no parameter is collected):\n\n{\n  \"advancedSettings\": {\n    \"audioExportGcsDestination\": {},\n    \"loggingSettings\": {\n      \"enableInteractionLogging\": true\n    },\n    \"speechSettings\": {\n      \"endpointerSensitivity\": 90,\n      \"noSpeechTimeout\": \"5s\"\n    }\n  },\n  \"currentPage\": {\n    \"displayName\": \"End Session\",\n    \"name\": \"projects\/dev-bbva-dialogflow-poc\/locations\/us-central1\/agents\/57dc60ad-5e59-4913-9c5a-dcef53842159\/flows\/9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\/pages\/END_SESSION\"\n  },\n  \"diagnosticInfo\": {\n    \"Execution Sequence\": [\n      {\n        \"Step 1\": {\n          \"InitialState\": {\n            \"Event\": \"sys.no-match-1\",\n            \"FlowState\": {\n              \"PageState\": {\n                \"Name\": \"Prueba params\",\n                \"Status\": \"TRANSITION_ROUTING\",\n                \"PageId\": \"5409aed3-7c85-47a8-aa87-2a84947d8b5d\",\n                \"FormFilled\": true\n              },\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\",\n              \"Name\": \"Prueba params\",\n              \"Version\": 0\n            }\n          },\n          \"Type\": \"INITIAL_STATE\"\n        }\n      },\n      {\n        \"Step 2\": {\n          \"Type\": \"STATE_MACHINE\",\n          \"FunctionExecution\": {\n            \"Responses\": [\n              {\n                \"responseType\": \"HANDLER_PROMPT\",\n                \"text\": {\n                  \"redactedText\": [\n                    \"No se a qu\u00e9 te refieres ex\u00e1ctamente, pero tiene que ver con $session.params.intent_param\"\n                  ],\n                  \"text\": [\n                    \"No se a qu\u00e9 te refieres ex\u00e1ctamente, pero tiene que ver con $session.params.intent_param\"\n                  ]\n                },\n                \"source\": \"VIRTUAL_AGENT\"\n              }\n            ]\n          },\n          \"StateMachine\": {\n            \"FlowState\": {\n              \"Name\": \"Prueba params\",\n              \"PageState\": {\n                \"PageId\": \"5409aed3-7c85-47a8-aa87-2a84947d8b5d\",\n                \"Name\": \"Prueba params\",\n                \"FormFilled\": true,\n                \"Status\": \"TRANSITION_ROUTING\"\n              },\n              \"Version\": 0,\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\"\n            },\n            \"TriggeredEvent\": \"sys.no-match-1\",\n            \"TriggeredEventHandlerId\": \"f6760455-fb9b-49fb-acae-69142ec33188\"\n          }\n        }\n      },\n      {\n        \"Step 3\": {\n          \"StateMachine\": {\n            \"FlowState\": {\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\",\n              \"PageState\": {\n                \"Name\": \"End Session\",\n                \"PageId\": \"END_SESSION\",\n                \"Status\": \"ENTERING_PAGE\"\n              },\n              \"Name\": \"Prueba params\",\n              \"Version\": 0\n            }\n          },\n          \"Type\": \"STATE_MACHINE\"\n        }\n      }\n    ],\n    \"Alternative Matched Intents\": [],\n    \"Session Id\": \"946ef0-346-0ee-be7-ec290fb95\",\n    \"Unfulfilled Parameters\": [\n      \"$session.params.intent_param\"\n    ],\n    \"Transition Targets Chain\": [\n      {\n        \"TargetPage\": \"END_SESSION\"\n      }\n    ],\n    \"Triggered Transition Names\": [\n      \"f6760455-fb9b-49fb-acae-69142ec33188\"\n    ]\n  },\n  \"intentDetectionConfidence\": 0.3,\n  \"languageCode\": \"es\",\n  \"match\": {\n    \"confidence\": 0.3,\n    \"event\": \"sys.no-match-1\",\n    \"matchType\": \"NO_MATCH\"\n  },\n  \"responseMessages\": [\n    {\n      \"responseType\": \"HANDLER_PROMPT\",\n      \"source\": \"VIRTUAL_AGENT\",\n      \"text\": {\n        \"redactedText\": [\n          \"No se a qu\u00e9 te refieres ex\u00e1ctamente, pero tiene que ver con $session.params.intent_param\"\n        ],\n        \"text\": [\n          \"No se a qu\u00e9 te refieres ex\u00e1ctamente, pero tiene que ver con $session.params.intent_param\"\n        ]\n      }\n    },\n    {\n      \"interactiveVoiceResponseSettings\": {\n        \"audioExportGcsDestination\": {},\n        \"speechSettings\": {\n          \"endpointerSensitivity\": 90,\n          \"noSpeechTimeout\": \"5s\"\n        }\n      }\n    },\n    {\n      \"endInteraction\": {}\n    }\n  ],\n  \"text\": \"Pl\u00e1stico\"\n}"
            },
            {
                "Answer_creation_date":"2022-11-18T08:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This seems to be not reproducible on my end.\u00a0If you have premium support, you can check with\u00a0GCP Support\u00a0to further check your issue since this is specific to your project."
            }
        ]
    },
    {
        "Question_title":"timeSegments vs timeSegmentAnnotations",
        "Question_creation_date":"2022-11-16T08:02:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/timeSegments-vs-timeSegmentAnnotations\/td-p\/490092\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Video Intelligence API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":47,
        "Question_body":"timeSegments vs timeSegmentAnnotationsCan anyone explain what's the difference between these 2 fields described here? https:\/\/storage.cloud.google.com\/google-cloud-aiplatform\/schema\/dataset\/ioformat\/video_action_recogn...why would I want to tag timeSegments? what's the objective of this? associate a label to a time segment?  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-17T15:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"timeSegments is a parameter that should be included to your schema's YAML and JSONL files so that it can be used to determine the timestamps of the operations, not something that should be made from the terminal. I.e., a section of the film that contains a number of actions or annotations. And when you import data into your dataset later, you add those files.\n\nHowever, I checked timeSegmentAnnotations and found that although I set the endTime to be different from startTime, the action is only labeled on the startTime, so it doesn't seem to be that useful (hence, one frame)."
            }
        ]
    },
    {
        "Question_title":"Using text recognition while also using object detection",
        "Question_creation_date":"2022-11-16T21:48:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Using-text-recognition-while-also-using-object-detection\/td-p\/490329\/jump-to\/first-unread-message",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":37,
        "Question_body":"Can you use visionAI text recognition while using object detection, or will they have to be two separate calls the Vertex AI?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nYou will be needing calling text recognition and object detection separately.\u00a0Endpoints for text recognition and object detection are separate hence you need to call them separately. See text recognition example and object detection example."
            }
        ]
    },
    {
        "Question_title":"Dialogflow CX Intergration with Messenger from Facebook",
        "Question_creation_date":"2022-11-15T20:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-CX-Intergration-with-Messenger-from-Facebook\/td-p\/489873\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":39,
        "Question_body":"Hi, I have some issue when I integrate dialogflow cx with messenger. \nThe issue is I didn't get response from my bot, I have a suspect that dialogflow failed to send message to user on messenger.\nSo, my problem now is how to check sending message process in dialogflow to get the detail of error?Thanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-17T09:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"To see logs for DialogFlow, you would need to enable Cloud Logging\u00a0in your agent\u2019s general settings. After enabling logging, you\u2019d be able to see DialogFlow logs for requests and responses (including for webhooks). Let me know if you have additional questions."
            }
        ]
    },
    {
        "Question_title":"Do Training Jobs Run in Parallel? (VERTEX AI)",
        "Question_creation_date":"2022-11-15T07:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Do-Training-Jobs-Run-in-Parallel-VERTEX-AI\/td-p\/489639\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":70,
        "Question_body":"I am wondering if training jobs on vertex AI run in parallel, based on my tests it seems they do but wondering if anyone can confirm this is true as the number of concurrent jobs grows past say 1000. Thanks! ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-15T11:57:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes training jobs run in parallel but the concurrency is subject to quota. See Vertex AI quota document.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-15T11:57:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes training jobs run in parallel but the concurrency is subject to quota. See Vertex AI quota document."
            },
            {
                "Answer_creation_date":"2022-11-16T06:58:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Cool thanks,\n\nAre those quotas liftable or are they the hard cap.\n\n\u00a0\n\nThanks!"
            },
            {
                "Answer_creation_date":"2022-11-16T09:06:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes it is possible but is subject to approval. Kindly see this document on how to request a quota increase."
            }
        ]
    },
    {
        "Question_title":"Google Cloud Translate API",
        "Question_creation_date":"2022-11-14T02:52:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-Translate-API\/td-p\/489124\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":66,
        "Question_body":"Hi,i am use free trails of Google Cloud Translate send request on this URL  https:\/\/translation.googleapis.com\/language\/translate\/v2 with API key with body rowget error response kindly see below\"code\": 403,\n\"message\": \"The request is missing a valid API key.\",\n\"errors\":\n\n\"message\": \"The request is missing a valid API key.\",\n\"domain\": \"global\",\n\"reason\": \"forbidden\"\n\"status\": \"PERMISSION_DENIED\"",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-15T09:16:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, mjunaid,\n\nThe key you're using might not have the permission to use Translate APIs.\n\nTo fix this:\n\nGo to the Google Cloud Platform console\nChoose your project from the drop-down menu in the top bar\nGo to API & Services > Library\nSearch for Cloud Translation API and click on it\nEnable it\n\nGo to API & Services > Credentials\nSelect the key you are using in your Android App\nFrom the menu called Restrict key, choose Cloud Translation API\nSave your edit.\n\nNow the APIs should work properly.\n\nAdditionally, please note that the documentation\u00a0mentions that the structure of the HTTP method should be something like:\n\nhttps:\/\/translation.googleapis.com\/language\/translate\/v2?key=[yourAPIkey]&target=language\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-15T09:16:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, mjunaid,\n\nThe key you're using might not have the permission to use Translate APIs.\n\nTo fix this:\n\nGo to the Google Cloud Platform console\nChoose your project from the drop-down menu in the top bar\nGo to API & Services > Library\nSearch for Cloud Translation API and click on it\nEnable it\n\nGo to API & Services > Credentials\nSelect the key you are using in your Android App\nFrom the menu called Restrict key, choose Cloud Translation API\nSave your edit.\n\nNow the APIs should work properly.\n\nAdditionally, please note that the documentation\u00a0mentions that the structure of the HTTP method should be something like:\n\nhttps:\/\/translation.googleapis.com\/language\/translate\/v2?key=[yourAPIkey]&target=language"
            },
            {
                "Answer_creation_date":"2022-11-15T22:20:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks"
            }
        ]
    },
    {
        "Question_title":"Dialogflow cx sdk pricing",
        "Question_creation_date":"2022-11-12T02:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-cx-sdk-pricing\/td-p\/488718\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":55,
        "Question_body":"Hi all! \nI'm using Dialogflox cx python libraries to make some tests with intents matching. To do these tests, I'm using the match_intent method of the SessionClient class. I digged in the pricing table of Dialogflow CX but as far as I searched I didn't understand if there's a pricing for request made with SessionClient, and I'm here to ask for your help.\n\nThank you in advance!",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-14T16:44:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThank you for reaching out. Will look into this."
            },
            {
                "Answer_creation_date":"2022-11-15T09:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I created a public issue tracker regarding your question. You can track the progress of the issue using the link I have provided.\u00a0Please keep in mind that the issue has to be analyzed and considered by the product team and I can't provide you an ETA for it."
            }
        ]
    },
    {
        "Question_title":"Cloud Translation Permission",
        "Question_creation_date":"2022-11-15T07:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-Translation-Permission\/td-p\/489632\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":53,
        "Question_body":"So I'm pulling my hair out over this and reaching out here for help. I'm trying to set up a service account with Cloud Translation, and Text-to-speech enabled, but we keep getting this response:I have confirmed that the service account has the \"cloudtranslate.generalModels.predict\" permission, and showing the \"Cloud Translation API User\" role. We've also confirmed that it works with a different Service account that my colleague set up in his personal Google console profile. But, we need this setup with an account through our org. I did verify that the service account has the permission from the https:\/\/console.cloud.google.com\/iam-admin\/troubleshooter so and that my organization's admin sees that the service account is granted access through ancestor policies.  So what else can we check? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-15T08:30:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Ok, turned out we had a hard-coded value for resource location, which was set to the wrong project. So of course it was coming back as permission denied.\u00a0\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-15T08:30:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Ok, turned out we had a hard-coded value for resource location, which was set to the wrong project. So of course it was coming back as permission denied."
            }
        ]
    },
    {
        "Question_title":"Issues with importing aiplatform",
        "Question_creation_date":"2022-11-14T01:10:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Issues-with-importing-aiplatform\/td-p\/489087\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":93,
        "Question_body":"Hi, I am following this tutorial on model deployment (https:\/\/codelabs.developers.google.com\/vertex-image-deploy#6), but I ran into a issue when importing the aiplatform library.When running \"from google.cloud import aiplatform\", I get the following error message:The versions of the concerned libraries are shown below.I have tried grpcio versions 1.26, 1.27.2, and even the latest 1.50, but all of them had import errors (concerning importing of aio module for 1.26 and 127.2 and AbortError module for 1.50). Are there any additional steps or libraries that I need to take to avoid these import errors?Thank you!",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-14T17:15:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thank you for your reply. I am running the code on Vertex AI.\n\nI realised I had to restart the kernel to refresh the package after updating grpcio, and I could then import aiplatform without any issues as shown below:\n\nfrom google.cloud import aiplatform\nprint(\"aiplatform version: \", aiplatform.__version__)\n\naiplatform version:  1.17.0\n\nThanks again for your help!\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-14T15:37:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI tried the code labs link and I did not encounter your error.\u00a0 I ran the code in a \"Managed Notebook\" as shown in the labs. Here are the versions of the libraries in my notebook:\n\ngoogle-api-core ==\u00a02.8.0\ngoogle-api-python-client ==\u00a02.65.0\ngoogle-cloud-aiplatform == 1.18.2\ngrpcio == 1.50.0\ngrpcio-gcp == 0.2.2\ngrpcio-status == 1.48.2\n\nJust to confirm, where did you run the code?"
            },
            {
                "Answer_creation_date":"2022-11-14T17:15:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thank you for your reply. I am running the code on Vertex AI.\n\nI realised I had to restart the kernel to refresh the package after updating grpcio, and I could then import aiplatform without any issues as shown below:\n\nfrom google.cloud import aiplatform\nprint(\"aiplatform version: \", aiplatform.__version__)\n\naiplatform version:  1.17.0\n\nThanks again for your help!"
            },
            {
                "Answer_creation_date":"2022-11-15T08:18:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"You can mark this as solved so future readers can easily determine the solution."
            }
        ]
    },
    {
        "Question_title":"Matching Engine: Queries with filtering do not work as expected",
        "Question_creation_date":"2022-11-10T07:31:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Matching-Engine-Queries-with-filtering-do-not-work-as-expected\/td-p\/488086\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":75,
        "Question_body":"I tried to run this notebook: https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/community\/matching_engi...\nI got an issue with the filtering step:\nLet's say glove100.json is:If I try to filter in this way:I do not get any response (empty result). If from the above code I remove the \"restrict block\", it works (of course without filtering).response:But, if I add a new vector by Vertex SDK for Python (link ), in this way:and then I try to filter in the same way above with filter class == \"3\", I get the right response.It seems like the allow_tokens are \"seen\" by vertex only when I insert a new vector by Vertex SDK and not when I specify them in the initial glove100.json.Moreover, if I update a datapoint where the filter did not work, for example id=1:The filter for class=1 starts to work.Is there a way to know what is actually stored in the index? I mean a kind of \"SELECT * FROM myindex\" in order to check embeddings and tokens stored.Any ideas on how to solve this issue?Thanks in advanceSpecificationsI tried from local and from workbench, the result is the same.- Version: Python 3.7.9\n- Platform: Matching Engine. zone: europe-west1",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-11T14:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThank you for reaching out, you can create a public issue tracker for this question since it might be an unexpected behavior and you have a workaround to show for."
            },
            {
                "Answer_creation_date":"2022-11-15T02:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0@ricconoel\u00a0,\nThank you for replying!\u00a0\n\nSince I do not see a \"Matching Engine\" section,\u00a0 in which one do you suggest to open an issue?"
            }
        ]
    },
    {
        "Question_title":"Google Cloud Vision broken for English?",
        "Question_creation_date":"2022-11-12T13:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-Vision-broken-for-English\/td-p\/488836\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":40,
        "Question_body":"Has anyone else noticed that the Google Cloud Vision OCR that processes the text in images operates starting top to bottom, then left to right for English?  And that it didn't used to?\n\nThe problem with this is generally:\n\nWe write in English like this.\nSo we want to read the lines from left to right, top to bottom.We          write\ndo           english\nnot         like\nreally      thisTop to bottom, left to right.  Which is how you're reading it.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-14T15:49:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"To report an issue, it is better to do it at Issue Tracker, rather than write a post at this forum.\n\nYou can submit your report here:\n\nCreate new Cloud Vision issue\nIssue reports\n\nGoogle reviews every new issue report submitted by users. Sometimes one of our staff will ask for clarification or followup. After we're able to replicate the issue, we'll tell you that it's been forwarded to the appropriate team.\n\nDepending on the circumstances, we may be able to provide periodic updates while an issue is being looked at, but usually we cannot provide too many specifics about the exact cause of an issue, or when it will be fixed.\n\nWhen we've fixed an issue in production, we'll indicate this and then we'll close the issue.\n\nSee also:\n\nWhat to expect after you've opened an issue."
            }
        ]
    },
    {
        "Question_title":"Eliminacion de fondos personalizados",
        "Question_creation_date":"2022-11-12T05:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Eliminacion-de-fondos-personalizados\/td-p\/488739\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":21,
        "Question_body":"Hay documentos que tienen un fondo personalizado ya sea con logos o texto referencial a la empresa o al proceso que se lleva a cabo, es o ser\u00e1 posible eliminar estas caracter\u00edsticas y as\u00ed poder hacer m\u00e1s eficiente el nivel de eficiencia del OCR",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-12T05:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hay documentos que tienen un fondo personalizado ya sea con logos o texto referencial a la empresa o al proceso que se lleva a cabo, es o ser\u00e1 posible eliminar estas caracter\u00edsticas y as\u00ed poder hacer m\u00e1s eficiente el nivel de eficiencia del OCR"
            }
        ]
    },
    {
        "Question_title":"Month-to-date total cost (VertexA\u0131) keeps increasing even though I delete all my projects and billin",
        "Question_creation_date":"2022-11-11T01:46:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Month-to-date-total-cost-VertexA%C4%B1-keeps-increasing-even-though-I\/td-p\/488385\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":76,
        "Question_body":" ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-11T01:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello. I am a student and only use GCP for learning. But even though there is no project in my profile and\nI have closed my billing account, the Month-to-date total cost (VertexA\u0131) is constantly increasing. \nI tried everything but couldn't find a solution. I would be very happy if you could help me what to do."
            }
        ]
    },
    {
        "Question_title":"Python API to view\/list Vertex AI Feature Store ingestion jobs",
        "Question_creation_date":"2022-10-13T11:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Python-API-to-view-list-Vertex-AI-Feature-Store-ingestion-jobs\/td-p\/477834\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":186,
        "Question_body":"It's possible to view currently running feature ingestion jobs in the console (https:\/\/console.cloud.google.com\/vertex-ai\/ingestion-jobs). How can I list currently running ingestion jobs using a Python API? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-17T14:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As shown in the documentation,\n\nuse the Google Cloud console to view batch ingestion jobs.\n\nBy now, this is the way to view ingestion jobs."
            },
            {
                "Answer_creation_date":"2022-10-18T08:05:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"OK, weird. How can I make sure that there isn't an ingestion job running on an entity_type_id before I starting a new ingestion job on the same entity_type_id?"
            },
            {
                "Answer_creation_date":"2022-11-10T14:55:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You could request a code sample by creating a new issue at the googleapis\/python-aiplatform GitHub repository.\n\nFor questions about programming languages, you could ask in Stack Overflow."
            }
        ]
    },
    {
        "Question_title":"Error in GCP Doc AI project",
        "Question_creation_date":"2022-11-09T03:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-in-GCP-Doc-AI-project\/td-p\/487561\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":40,
        "Question_body":"Good evening . My peer while try to access Document AI page is getting the below error . Facing this issue from 2 PM yesterday. We are working for a POC project from LTI organization. Basically, it should show some processors or specialized processors. Please can you guide us.Regards,Vamsi ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-10T13:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For this kind of issue, please contact Google Cloud support.\n\nFile a support case"
            }
        ]
    },
    {
        "Question_title":"Vertex AI Batch Predictions: Bigquery format must be used as input and output simultaneously",
        "Question_creation_date":"2022-11-01T15:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Batch-Predictions-Bigquery-format-must-be-used-as\/td-p\/484734\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":70,
        "Question_body":"I'm encountering an error when I try to create a batch prediction job with a bigquery table as my input, and a JSONL output in a GCS bucket. The documentation for batch predictions seems to indicate that I can do so, but I still see an error.I'm trying to create a batch prediction job on the Vertex AI console, and I see this error. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-02T16:33:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The documentation does seem unclear about this error, do you see the same issue if you test selecting a different output format, for instance CSV? This so I can investigate further and contact the appropriate teams with this inquiry."
            },
            {
                "Answer_creation_date":"2022-11-10T08:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If you use BigQuery as your batch prediction input you only can store the batch prediction results in BigQuery (input and output has to be the same)"
            }
        ]
    },
    {
        "Question_title":"Vertex Matching Engine deny list tokens",
        "Question_creation_date":"2022-08-24T12:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-Matching-Engine-deny-list-tokens\/td-p\/459559\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":1,
        "Question_view_count":171,
        "Question_body":"How does the Vertex matching engine deny list work?\n\nLet's say I have a class fruit which will ONLY have deny list tokens (no allow) such as \"apple\", \"mango\", etc. How do I filter out \"mango\" in the query (search all fruits except mango)? I have tried the following method but it does not work as expected:\n\njson\n{\"id\": \"1\", \"embedding\":[0.002792,0.000492], \"restricts\": [{\"namespace\": \"fruit\", \"deny\": [\"mango\"]}]}\n\nquery\ndeny_namespace = match_service_pb2.Namespace()\ndeny_namespace.name = \"fruit\"\ndeny_namespace.deny_tokens.append(\"mango\")\nrequest.restricts.append(deny_namespace)\n\nI have coded this similar to allow list which has worked for me but with deny tokens it does not seem to skip deny tokens even after completely overwriting the index. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-30T08:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Based on the documentation that you shared about the filters and the code you are sharing, it looks like there\u2019s a formatting error on your code, based on the doc the JSON should look like the example I\u2019m providing you below.\n\n{\"id\": \"42\", \"embedding\": [0.5, 1.0], \"restricts\": [{\"namespace\": \"class\",\u00a0\"allow\": [\"cat\", \"pet\"]},{\"namespace\": \"category\", \"allow\": [\"feline\"]}]}"
            },
            {
                "Answer_creation_date":"2022-08-31T06:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"@Eduardo_Ortiz\u00a0Thanks for looking into this!\nYes this is for allow list, but I'm specifically asking for deny list. When I changed the \"deny\" to \"allow\" it seems to work but it fails for \"deny\". Can you or someone from the team please help me with this?"
            },
            {
                "Answer_creation_date":"2022-10-03T09:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Did you try to add deny tokens onto your case?"
            },
            {
                "Answer_creation_date":"2022-11-10T07:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Eduardo_Ortiz\u00a0,\n\nI tried what you said but it does not work anyway. For a more details, I opened an issue on github:\u00a0 https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/issues\/1230"
            }
        ]
    },
    {
        "Question_title":"Auto ML Edge failing if highest accuracy option is selected",
        "Question_creation_date":"2022-10-31T17:08:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Auto-ML-Edge-failing-if-highest-accuracy-option-is-selected\/td-p\/484251\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":36,
        "Question_body":"Hello all,I am doing an automl training for edge ad if I pick the higher accuracy option training fails after about 3 hours with the following error. Training completes with no issues if I pick the best trade-off option. I have opened a ticket but has received zero support from Google so posting here. Has anyone seen this issue and know how to fix it?\u2003I have tried multiple times with the same error. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-08T15:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"To report an issue, it is better to do it at Issue Tracker, rather than write a post at this forum.\n\nYou can submit your report here:\n\nCreate new Vertex AI AutoML Vision issue\nIssue reports\n\nGoogle reviews every new issue report submitted by users. Sometimes one of our staff will ask for clarification or followup. After we're able to replicate the issue, we'll tell you that it's been forwarded to the appropriate team.\n\nDepending on the circumstances, we may be able to provide periodic updates while an issue is being looked at, but usually we cannot provide too many specifics about the exact cause of an issue, or when it will be fixed.\n\nWhen we've fixed an issue in production, we'll indicate this and then we'll close the issue.\n\nSee also:\n\nWhat to expect after you've opened an issue."
            }
        ]
    },
    {
        "Question_title":"GCP Idle Model Charging",
        "Question_creation_date":"2022-11-07T04:10:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/GCP-Idle-Model-Charging\/td-p\/486604\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud TPU",
            "Contact Center AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":113,
        "Question_body":"Hello!\nI would like to deploy the ML Model into GCP.Most of the time the model will be sleeping. Sometimes I should use it through Endpoint for some seconds.\nI don't want to pay for full-time GPU instance and I need fast responses at the same time, without deployment from scratch everytime I need it.Is this possible in GCP ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-08T15:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"According to the Pricing for AutoML models documentation:\n\nPricing for AutoML models\n\nFor Vertex AI AutoML models, you pay for three main activities:\n\nTraining the model\nDeploying the model to an endpoint\nUsing the model to make predictions\n\nVertex AI uses predefined machine configurations for Vertex AutoML models, and the hourly rate for these activities reflects the resource usage. ... You pay for each model deployed to an endpoint, even if no prediction is made. You must undeploy your model to stop incurring further charges. Models that are not deployed or have failed to deploy are not charged.\n\nYou pay only for compute hours used; if training fails for any reason other than a user-initiated cancellation, you are not billed for the time. You are charged for training time if you cancel the operation.\n\nCustom-trained models\nTraining\n\nThe tables Machine types and Accelerators provide the approximate price per hour of various training configurations. You can choose a custom configuration of selected machine types. To calculate pricing, sum the costs of the virtual machines you use.\n\nIf you use Compute Engine machine types and attach accelerators, the cost of the accelerators is separate. To calculate this cost, multiply the prices in the table of accelerators below by how many machine hours of each type of accelerator you use.\n\nFor further information about pricing, please refer to the Vertex AI pricing documentation, or you can connect with our sales team to get a custom quote."
            }
        ]
    },
    {
        "Question_title":"Vertex AI endpoint deployment",
        "Question_creation_date":"2022-11-04T04:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-endpoint-deployment\/td-p\/485783\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Video Intelligence API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":77,
        "Question_body":"How can I utilize the mega GPU during endpoint deployment  for vertex ai work? Are there any model for examples or other resources that I can use to better grasp this?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-07T11:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What kind of model are you deploying on the endpoint? Can you clarify on what you mean in this statement \"utilizing the GPU during endpoint deployment\"?"
            },
            {
                "Answer_creation_date":"2022-11-08T00:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for responding. It is a simple tensorflow tabular classification model, and deployment takes about 18-20 minutes after model registration. I decided to use a mega GPU since I want to shorten this time as much as I can; perhaps this decision will shorten the time for deployment."
            },
            {
                "Answer_creation_date":"2022-11-08T09:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for clarifying. As far as I know the deployment of an endpoint is handled at the backend of GCP so it is not possible to use a GPU in order to shorten the deployment time."
            },
            {
                "Answer_creation_date":"2022-11-08T11:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"okay thanks , but when I use another account for the same , it's done within 2-3 min only !!!!"
            }
        ]
    },
    {
        "Question_title":"Authentication errors running vaictl in container",
        "Question_creation_date":"2022-11-07T15:09:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Authentication-errors-running-vaictl-in-container\/td-p\/486888\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":37,
        "Question_body":"I'm trying to run vaictl on OSX inside a docker container based on these Vertex AI Vision instructions, but hitting the following auth error:  I've run gcloud auth login in the container and saved the authorization code.Are there any extra steps needed to make this work?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-08T10:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"How did you reproduce the error? Can you provide the reproduction steps? Just so I can reproduce it on my end."
            }
        ]
    },
    {
        "Question_title":"Error 524 on jupyterlab",
        "Question_creation_date":"2022-11-05T02:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-524-on-jupyterlab\/td-p\/486115\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":71,
        "Question_body":"Hi,I cannot access Jupyterlab by web interface. It still works by ssh. I've followed the support documentations, but nothing works.My best guess is that the main issue is with the opened ports of docker.       I have the full result of the following command available, but i'm not sure if it's good idea to post it in public.I think the main error is from:      Thanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-07T11:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"One possible solution is to perform disk check and repair using this command:\u00a0sudo fsck \/dev\/sdb \u00a0then reboot your machine.\n\nYou can also migrate data of\u00a0\/home\/jupyter\/ folder and upload it to a new instance as a workaround."
            },
            {
                "Answer_creation_date":"2022-11-07T21:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThis solution doesn't work\n\nPlease have a look at that thread:\u00a0https:\/\/stackoverflow.com\/questions\/74326566\/jupyter-internal-api-is-not-active-vertex-ai-jupyterlab...\n\n\n\nthanks"
            },
            {
                "Answer_creation_date":"2022-11-08T09:28:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Since documentation and the workaround does not help, you may file a 1:1 Cloud Support here:\u00a0https:\/\/cloud.google.com\/support\u00a0\n\nA support resource that has access to your project will be able to check more thoroughly some components around your Jupyter notebook and can give you more comprehensive answers and suggestions."
            }
        ]
    },
    {
        "Question_title":"Vision API Product search",
        "Question_creation_date":"2022-11-02T10:49:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vision-API-Product-search\/td-p\/485081\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":1,
        "Question_view_count":79,
        "Question_body":"Following is vision API product search request jsonFor ImageContext, ProductCategories(apparel in this request) is mandatory in API. My concern is if I want product search from all the available ProductCategories, do I need to set multiple requests?For example, addProductCategories(\"apparel\") can have only one productcategory at a time. But I want product search from all the category something like addProductCategories(\"apparel-v2\").addProductCategories(\"toys-v2\").addProductCategories(\"general-v1\") etc.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-03T17:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As shown in the documentation, it will \u201conly consider the first category\u201d:\n\nThe list of product categories to search in. Currently, we only consider the first category, and either \"homegoods-v2\", \"apparel-v2\", \"toys-v2\", \"packagedgoods-v1\", or \"general-v1\" should be specified. The legacy categories \"homegoods\", \"apparel\", and \"toys\" are still supported but will be deprecated. For new products, please use \"homegoods-v2\", \"apparel-v2\", or \"toys-v2\" for better product search accuracy. It is recommended to migrate existing products to these categories as well.\n\nSee also:\n\njava-vision\/ProductSearchParams.java"
            },
            {
                "Answer_creation_date":"2022-11-03T22:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes we have migrated product to\u00a0\"homegoods-v2\", \"apparel-v2\", \"toys-v2\",\u00a0\"packagedgoods-v1\",\u00a0\"general-v1\" etc. but basic issue is, if we have data-set of multiple category Vision-API don't have provision of product search. So it is dependent on product category whereas filter is optional. It is a blocker since we have to request vision API multiple times based on category and all the responses need to be combined and reprocess further for actual response. So please provide any alternates Google Team already working on this scenario."
            },
            {
                "Answer_creation_date":"2022-11-06T07:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Also considered another scenario where we want safe search over this data-set, again we need to collect all the previous response, reprocess the previous response by adding\n\nFeature.Type.SAFE_SEARCH_DETECTION\n\n\u00a0Only after that we will get any results. Looks like currently vision API is limited to work on these scenario. Individual has to manage it at application level rather than API itself support it."
            },
            {
                "Answer_creation_date":"2022-11-07T23:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"exactly, it make application slow by requesting multiple times and reprocess the request to display end results."
            }
        ]
    },
    {
        "Question_title":"What is the limit of ProductSet per location",
        "Question_creation_date":"2022-11-03T13:21:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-is-the-limit-of-ProductSet-per-location\/td-p\/485590\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":30,
        "Question_body":"When using Google Vision's Product Search API, does anyone have an idea the maximum number of ProductSets allowed in a location(region)?This documentation shares limits on reference images per ProductSet, but it says nothing about ProductSets per location",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-04T11:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, iola,\n\nIn your Google Cloud Project, type \u201cCloud Vision API\u201d in the search bar.\nOn the left, click \u201cEnabled APIs and services\u201d > Quotas.\n\nIn the Quota column it is listed the different types of actions, accompanied by their limit in the Limit column.\n\nPlease tell me if this information is useful."
            }
        ]
    },
    {
        "Question_title":"Endpoint in GCP",
        "Question_creation_date":"2022-10-14T12:37:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Endpoint-in-GCP\/td-p\/478360\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":77,
        "Question_body":"In GCP I was deploying a model which obtain from training a dataset and after success full Vertex AI Model Registry. It takes too much time around 10 min to create endpoint for model. How can I reduce creation time when creating endpoints on GCP? What factors affected endpoint creation ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-20T16:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This video would be a good starting point:\n\nDeploying quick, cost-effective ML models with Vertex AI\n\nManaged notebook environments make it easier, faster, and more cost-effective to get high-quality models into production without having to set up infrastructure or install libraries. In this session, we\u2019ll demo how to use Vertex AI to get batch and online predictions and use the Vertex AI Python SDK to upload models to Vertex AI Model Registry and deploy to an endpoint with little code."
            },
            {
                "Answer_creation_date":"2022-11-04T04:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"thanks for\u00a0 reply but given resource does not work for me !!!"
            }
        ]
    },
    {
        "Question_title":"Using other API to translate PDF documents",
        "Question_creation_date":"2022-11-01T23:17:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Using-other-API-to-translate-PDF-documents\/td-p\/484845\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":45,
        "Question_body":"Hello all, \n\nI am trying to find a way to translate English PDF documents to a target language(Korean) without messing up the original PDF page format(pictures, headers, tables, etc.)\n\nThe only problem with the default google translation is that many of the words that appear in the document are very industry-specific and need to be translated accordingly through AutoML translation. \n\nHowever, we'd like to use our own language model (i.e. fine-tuned GPT3) to translate just the text and feed the translated text to the output stream to get the final pdf output.\n\nI'm yet to see any other company that maintains PDF formatting as well as Google while translating, so I'd really like to use Cloud Translation API with our own translation module for optimal accuracy.\n\nIs there a way to do this? I've tried reaching out to the local Google branch to no avail. Please help!",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-03T15:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It is possible to use a glossary\u00a0in Cloud Translation to provide the API with custom translations for terms that appear in texts. This would help when industry-specific terminology needs to be translated in a specific way.\n\nAs for using a custom language recognition model, you would be able to create a Feature Request for Cloud Translate API\u00a0in Google\u2019s public issue tracker."
            }
        ]
    },
    {
        "Question_title":"Vocal emojis in Speech-to-Text",
        "Question_creation_date":"2022-11-03T07:41:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vocal-emojis-in-Speech-to-Text\/td-p\/485418\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":25,
        "Question_body":"Hello! I am majoring in Theoretical Linguistics this year and I would like to write my dissertation on Google Cloud API and the vocal emojis supported, delving into the neural network to find out how they are translated. I have seen that my native language is missing and could build a dataset of spoken forms. Following the tutorial for using the Speech-to-Text API with Phyton I found out that very little information on this project are public.Should I contact some specific person\/service via my institutional account to receive material for a study case?Thank you!",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-03T07:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello! I am majoring in Theoretical Linguistics this year and I would like to write my dissertation on Google Cloud API and the vocal emojis supported, delving into the neural network to find out how they are translated. I have seen that my native language is missing and could build a dataset of spoken forms. Following the tutorial for using the Speech-to-Text API with Phyton I found out that very little information on this project are public.\n\nShould I contact some specific person\/service via my institutional account to receive material for a study case?\n\nThank you!"
            }
        ]
    },
    {
        "Question_title":"Version 2 model in natural language API",
        "Question_creation_date":"2022-11-01T11:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Version-2-model-in-natural-language-API\/td-p\/484641\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":63,
        "Question_body":"Hi, could anyone share the python code on how to get  natural language API to use version 2 classify text  categories?I can get it working well with the default (version 1) categories but can't figure out where to adapt the standard code (as here: https:\/\/cloud.google.com\/natural-language\/docs\/samples\/language-classify-text-tutorial-classify?hl=e...)  to  use model version 2.Many thanks ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-02T16:27:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"From the Classifying Content guide, you can include classification_model_options\u00a0within the request\u00a0dictionary argument to the classify_text()\u00a0function. In these options, you can define the model and version to use for content categories.\n\n\/\/ ...\ncontent_categories_version = (\n        language_v1.ClassificationModelOptions.V2Model.ContentCategoriesVersion.V2) \/\/ Assigning the v2 model type\n    response = client.classify_text(request = {\n        \"document\": document,\n        \"classification_model_options\": {\n            \"v2_model\": {\n                \"content_categories_version\": content_categories_version\n            }\n        }\n    })\n\/\/ ...\n\n\nYou can also check ClassificationModelOptions\u00a0reference for available options.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-02T16:27:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"From the Classifying Content guide, you can include classification_model_options\u00a0within the request\u00a0dictionary argument to the classify_text()\u00a0function. In these options, you can define the model and version to use for content categories.\n\n\/\/ ...\ncontent_categories_version = (\n        language_v1.ClassificationModelOptions.V2Model.ContentCategoriesVersion.V2) \/\/ Assigning the v2 model type\n    response = client.classify_text(request = {\n        \"document\": document,\n        \"classification_model_options\": {\n            \"v2_model\": {\n                \"content_categories_version\": content_categories_version\n            }\n        }\n    })\n\/\/ ...\n\n\nYou can also check ClassificationModelOptions\u00a0reference for available options."
            }
        ]
    },
    {
        "Question_title":"Vertex AI image classification models lose accuracy when being placed in a python dictionary",
        "Question_creation_date":"2022-10-26T10:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-image-classification-models-lose-accuracy-when-being\/td-p\/482475\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud TPU",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":106,
        "Question_body":"I have made a  model using vertex AI's image classification. Exported as EdgeTPU tflite model to my Raspberry pi 4 with Coral USB accelerator. When I used the Pycoral's example code https:\/\/github.com\/google-coral\/pycoral\/blob\/master\/examples\/classify_image.py  to run my model, I get a perfect prediction result. But when I passed them to a python dictionary in my script, the prediction accuracy is way off. https:\/\/github.com\/hillyuyichu\/Pycoral-python-API\/blob\/main\/pycoral_classification.py   Here is a screenshot of the prediction results on my python classification.py:The label in row 1 is always the most active. The one in the last rows are the least active and most inaccurate.ex: In picture 2, the label empty_pan barely ever cross 0.10 mark when it should have been more than 0.50",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-31T12:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It seems Vertex AI is not supposed to be placed in a Python directory.\n\nIf this is impacting your application or your business, you can file a feature request using the following link. File the feature request, and they could assist you with the feature you are trying to implement."
            },
            {
                "Answer_creation_date":"2022-11-02T09:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Comaro!\n\nThanks for the reply! I was able to find a way to work around it."
            },
            {
                "Answer_creation_date":"2022-11-02T11:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you share the workaround, Hillyu?"
            }
        ]
    },
    {
        "Question_title":"Get Cloud Vision API as good as Google Lens",
        "Question_creation_date":"2022-06-24T13:24:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Get-Cloud-Vision-API-as-good-as-Google-Lens\/td-p\/434624\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":375,
        "Question_body":"As part of a student team, I am building a system to classify used shoes.I know that Google Lens is doing a really good job here.I came across Google Cloud Vision API (which should be a similar thing) and implemented this in python.For clean, well-angled images like this Air Force One:  I am getting really promising results:If however, i input real-world images like this old used Nike Tanjun:  Things fall apart:But if I upload the image to google lens, I could still figure out the right label:  Logo detection (Nike) almost always works. And using this, I could for example search after the most often occurring word after the Logo (Tanjun) to figure out the model.It must be mentioned that the data of our system will be better than that, there will be multiple images taken from different angles and very good lighting conditions.Now i am trying to figure out how toEITHER: Get Vision API working in the same way as Google LensOR: Acces Google Lens data in a somehow convenient way (should in the best case run from a raspberry pi)   ",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-26T05:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"push. I urgently need help."
            },
            {
                "Answer_creation_date":"2022-10-06T02:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I'm in the same shoes. The real answer is, the API does not work so well."
            },
            {
                "Answer_creation_date":"2022-11-01T23:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, i'm facing the same problem, do you find any solution to it?"
            }
        ]
    },
    {
        "Question_title":"Auto ML edge training failure",
        "Question_creation_date":"2022-10-30T16:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Auto-ML-edge-training-failure\/td-p\/483746\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":36,
        "Question_body":"I am training an edge model in vertex AI. It is failing after a few hours. Details in the screenshot below. Tried 4 times and failed all 4 times. I cannot see to see any detail at all on the error. Can someone from Vertex AI please help? Training fails after about 3 hours if I pick the highest accuracy option but seems to process if I pick the 'best trade-off' options.  Screenshot of the of the failed jobs below.Screenshot upload fails just like getting any support from Google.  The training pipeline id is 2116799302125748224",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-01T15:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For this type of inquiry the appropriate support channel would be creating a support case\u00a0directly with Google Cloud. This would enable support to directly work with you and your project for solutions, specially when logs are not available for the community in this forum."
            }
        ]
    },
    {
        "Question_title":"AI\/ML Research Paper Publish",
        "Question_creation_date":"2022-10-31T08:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AI-ML-Research-Paper-Publish\/td-p\/484051\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":21,
        "Question_body":"How should get into research about AI\/ML to get some international research intern offer?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-31T08:32:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"How should get into research about AI\/ML to get some international research intern offer?"
            }
        ]
    },
    {
        "Question_title":"Vertex AI quota policy exceed when training custom model",
        "Question_creation_date":"2022-09-26T02:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-quota-policy-exceed-when-training-custom-model\/td-p\/470907\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":169,
        "Question_body":"Hello team,Can anyone please help me with this,I have been trying to run the custom model training in vertex ai and gives an error saying\"Training pipeline failed with error message: The following quota metrics exceed quota limits: aiplatform.googleapis.com\/custom_model_training_cpus\"Followed the below steps to solve it but didn't help me at all,1. Changed the region (As it mentioned in one comment of Stack Overflow for this error)2. Increased CPU instances in the work pool as well as notebooks but didn't help me at all.I have gone through the IAM & API Services, and then when I checked the quotas for the Vertex AI API for all resources in it, none of them had exceeded the quota limit. I'm still confused as to why it was showing a quota exceed error when I was training the custom model.Please help me on this issue, how to solve it.",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-27T11:22:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You need to contact Billing Support."
            },
            {
                "Answer_creation_date":"2022-10-30T14:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I have the same problem, can you tell me how solved it??\u00a0@Praneeth5533"
            }
        ]
    },
    {
        "Question_title":"Dialogflow cx caller abandoned call event",
        "Question_creation_date":"2022-10-26T05:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-cx-caller-abandoned-call-event\/td-p\/482361\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":2,
        "Question_view_count":98,
        "Question_body":"Is there a way to trigger a webhook, as soon as the caller abandons the call?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Currently working with your question."
            },
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"In regards to your main question, the best option would be to create a Cloud Function. You can actually review the Quickstart: Create a webhook.\n\nWhen the call ends, there must be some variable that you can grab to start the function.\n\nIf we get more information for your main issue, it will be shared with you as soon as possible."
            }
        ]
    },
    {
        "Question_title":"deploying model on vertex ai deploymentResourcePool to an endpoint located in another project.",
        "Question_creation_date":"2022-10-26T00:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/deploying-model-on-vertex-ai-deploymentResourcePool-to-an\/td-p\/482309\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":91,
        "Question_body":"I'am trying to deploy a custom trained model to a deployment resource pool that is located in project-1 to an endpoint located in project-2 , I have granted the editor role for project-1 to user account (u1) which also has editor role in project-2. when I try to deploy the model from user account (u1) ,I get the following error:grpc_message:\"DeploymentResourcePool 'projects\/{project-1}\/locations\/us-central1\/deploymentResourcePools\/drlpool' does not exist.*the deployment resource pool (drlpool) exists and also deploys successfully if the endpoint and the deployment Resource Pool are in the same project.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-27T14:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you please check the roles granted to your service account as advised in this Stack Overflow question:\n\nFor example you have Project A and Project B, assuming that Project A hosts the model.\n\nAdd service account of Project B in Project A and provide at least roles\/aiplatform.user predefined role. See predefined roles and look for roles\/aiplatform.user to see complete roles it contains.\n\nThis role contains aiplatform.endpoints.* and aiplatform.batchPredictionJobs.* as these are the roles needed to run predictions.\n\nSee IAM permissions for Vertex AI\n\n|Resource|Operation|Permissions needed| |---|---|---| |batchPredictionJobs|Create a batchPredictionJob|aiplatform.batchPredictionJobs.create (permission needed on the parent resource)| |endpoints|Predict an endpoint|aiplatform.endpoints.predict (permission needed on the endpoint resource)|\n\nWith this set up, Project B will be able to use the model in Project A to run predictions.\n\nNote: Just make sure that the script of Project B points to the resources in Project A like project_id and endpoint_id.\n\nIf after that are you still having issuesIf after that you are still having issues it would be better to export the model from project-1 and import into project-2, as shown in the documentation:\n\nThe Model and Endpoint components expose the functionalities of the Vertex AI endpoint and model resources. You can import existing model resources that you've trained outside of Vertex AI, or that you've trained using Vertex AI and exported. After you import your model, this resource is available in Vertex AI. You can deploy this model to an endpoint and then send prediction requests to this resource."
            }
        ]
    },
    {
        "Question_title":"Dialogflow cx v3 DetectIntentRequest returning no-match",
        "Question_creation_date":"2022-10-26T13:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-cx-v3-DetectIntentRequest-returning-no-match\/td-p\/482545\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":32,
        "Question_body":"I am trying to create and manage agents using exclusively the api.  I have created an agent with one intent only:name: \"projects\/???\/locations\/global\/agents\/1828e34b-78bc-48f5-9212-6dd83497d409\/intents\/b9e91883-f358-46ea-9661-a8a39c7d2557\"\ndisplay_name: \"test-age\"\ntraining_phrases {\nparts {\ntext: \" I am \"\n}\nparts {\ntext: \" 23 \"\nparameter_id: \"p0\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" my age is \"\n}\nparts {\ntext: \" 68 \"\nparameter_id: \"p1\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" I am \"\n}\nparts {\ntext: \" 44 \"\nparameter_id: \"p2\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" age \"\n}\nparts {\ntext: \" 81 \"\nparameter_id: \"p3\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" age is \"\n}\nparts {\ntext: \" 35 \"\nparameter_id: \"p4\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" the age is \"\n}\nparts {\ntext: \" 29 \"\nparameter_id: \"p5\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" 37 \"\nparameter_id: \"p6\"\n}\nparts {\ntext: \" years of age \"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" 45 \"\nparameter_id: \"p7\"\n}\nparts {\ntext: \" years \"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" 52 \"\nparameter_id: \"p8\"\n}\nparts {\ntext: \" years old \"\n}\nrepeat_count: 1\n}\nparameters {\nid: \"p0\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p1\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p2\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p3\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p4\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p5\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p6\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p7\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p8\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\npriority: 500000However, when I try to detect that intent using the DetectIntentRequest as shown in the github samples I keep getting no-match results:====================\nQuery Text: ' I am 55 '\nDetected Intent: text: \" I am 55 \"\nlanguage_code: \"en\"\nresponse_messages {\ntext {\ntext: \"Sorry, could you say that again?\"\n}\n}\ncurrent_page {\nname: \"projects\/???\/locations\/global\/agents\/1828e34b-78bc-48f5-9212-6dd83497d409\/flows\/00000000-0000-0000-0000-000000000000\/pages\/START_PAGE\"\ndisplay_name: \"Start Page\"\n}\nintent_detection_confidence: 0.3\ndiagnostic_info {\nfields {\nkey: \"Alternative Matched Intents\"\nvalue {\nlist_value {\n}\n}\n}I did train the agent in advance. Appreciate any help",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-27T10:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, mihai527,\n\nI understand that you are experiencing the issue with the transcription which is not responding as expected, and this is a transient issue. Instead of identifying the user age, it is Invoking the No-Match event. Please let me know if I have misunderstood.\n\nHere it seems like an issue with the speech adaption. In regards to that, can you please Enable speech adaptation? The auto speech adaptation feature improves the speech recognition accuracy of your agent by automatically using conversation state to pass relevant entities and training phrases as speech context hints for all detect intent requests. This feature is disabled by default.\n\nYou may follow this doc\u00a0to achieve this. Please let me know if this resolves your issue or not. Also, you may follow this doc, which talks about Voice agent design best practices.\n\nPlease let me know if you have any questions regarding the information provided above. I will be happy to assist you.\n\nI will be looking forward to your response."
            }
        ]
    },
    {
        "Question_title":"Using RegEx Entity with other entitiy in Traning Phrase gives empty value for the parameter",
        "Question_creation_date":"2022-10-19T02:16:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Using-RegEx-Entity-with-other-entitiy-in-Traning-Phrase-gives\/td-p\/479671\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":101,
        "Question_body":"n Dialogflow ES I am using a Regular Expression for the date format (DD\/MM\/YYYY) validation. If I have the training phrase as 22\/05\/2021 it works perfectly.But I need to have the training phrase as 22\/05\/2021 sample@sample.com. When I use like that, for the date it gives empty value.Not even for this mydate validation, this is not working if I use any RegEx entity along with other entity in the same training phrase.myDigit RegEx is ^[0-9]$So can't it be used Regex entity along with other entity in the same training phrase in Dialogflow?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-26T10:18:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Sorry for the delay in replying, I see that your regular expression is matching the end of the line with \u201c$\u201d after the digit (^[0-9]$). This would explain why you are able to capture the data when the training phrase contains only the digit, but not when additional data is located after (for example, \u201c2 sample@sample.com\u201d does not contain the EOL metacharacter after \u201c2\u201d, but having only \u201c2\u201d as the training phrase does).\n\nIf your date regular expression matches the end of the line as well, you\u2019d see the same behavior. I made a quick intent using this expression to match \u201cDD\/MM\/YYYY\u201d: ^[0-9]{2}\\\/[0-9]{2}\\\/[0-9]{4}. As shown below, it captures both the date and Email:\n\n\u00a0\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-10-20T11:08:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Do you experience this problem when adding multiple entities of any kind into a single phrase? Do you also see any difference if you edit the regular expression?"
            },
            {
                "Answer_creation_date":"2022-10-20T20:12:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes. I only face this issue when adding RegExp entity with multiple other entities in single training phrase. It works fine if I have only this RegExp entity in the training phrase. I tried changing the regular expression; but the issue remains the same."
            },
            {
                "Answer_creation_date":"2022-10-26T10:18:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Sorry for the delay in replying, I see that your regular expression is matching the end of the line with \u201c$\u201d after the digit (^[0-9]$). This would explain why you are able to capture the data when the training phrase contains only the digit, but not when additional data is located after (for example, \u201c2 sample@sample.com\u201d does not contain the EOL metacharacter after \u201c2\u201d, but having only \u201c2\u201d as the training phrase does).\n\nIf your date regular expression matches the end of the line as well, you\u2019d see the same behavior. I made a quick intent using this expression to match \u201cDD\/MM\/YYYY\u201d: ^[0-9]{2}\\\/[0-9]{2}\\\/[0-9]{4}. As shown below, it captures both the date and Email:"
            },
            {
                "Answer_creation_date":"2022-10-26T22:23:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you very much for your solution. It worked perfectly when I removed $ from my Regular Expression.\n\nI am posting the RegExp used in case someone else needs it (only get the valid dates only, avoid dates like 31\/02\/2022, 35\/18\/2022). Got it from https:\/\/stackoverflow.com\/a\/20773444\/1719133\n\n(^(((0[1-9]|1[0-9]|2[0-8])[\\\/](0[1-9]|1[012]))|((29|30|31)[\\\/](0[13578]|1[02]))|((29|30)[\\\/](0[4,6,9]|11)))[\\\/](19|[2-9][0-9])\\d\\d)|(^29[\\\/]02[\\\/](19|[2-9][0-9])(00|04|08|12|16|20|24|28|32|36|40|44|48|52|56|60|64|68|72|76|80|84|88|92|96))"
            }
        ]
    },
    {
        "Question_title":"Vonage Smart Number",
        "Question_creation_date":"2022-10-25T00:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vonage-Smart-Number\/td-p\/481819\/jump-to\/first-unread-message",
        "Question_topic":[
            "Contact Center AI",
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":113,
        "Question_body":"Trying to find a way to link a Vonage Smart Number (Vonage Communications, not API) to Dialogflow ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-26T08:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can use Contact Center AI\n\nContact Center AI (CCAI) is an extension of Dialogflow services that helps create contact center solutions. You need to request access to Contact Center AI documentation. For information, see the Contact Center AI solution overview.\n\nAs shown in this Google Cloud Blog entry Deliver an exceptional customer experience with Contact Center AI, now GA:\n\nYou can now integrate Contact Center AI with your existing workflows and start seeing results within 3-6 months, thanks to integrations with partners such as Avaya and Mitel, who are GA today, as well as 8x8, Cisco, Five9, Genesys, NICE inContact, Salesforce, Twilio, and Vonage.\n\n\u2026\n\nTo find out how Contact Center AI can increase CSAT, deflection rates, and operational efficiency, visit our site, contact your Google sales representative, or request to be contacted."
            }
        ]
    },
    {
        "Question_title":"What's the order for the labels in txt file after I have exported my tflite model from Vertex AI",
        "Question_creation_date":"2022-10-21T12:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-s-the-order-for-the-labels-in-txt-file-after-I-have\/td-p\/480804\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":116,
        "Question_body":"I have exported my trained tflite model. But I noticed the order of the labels in the txt file matters. I'm using image classification models. The ones with only two labels, it's an easy fix. I just switch the two. But when I have more than two labels, I notice the predictions are way off. Does it say in Vertex AI or is there a general rule to what label should go first, second, third..etc in the txt file that we create on our own? ",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"After reviewing more about Export AutoML Edge models, you can see the following TensorFlow documentation to learn more about extracting this information.\n\nTensorFlow Lite inference with metadata\nGenerate model interfaces with TensorFlow Lite code generator\nAdding metadata to TensorFlow Lite models\n\nThe documentation that might help more for your question is the last one \u201cAdding metadata to TensorFlow Lite Models\u201d.\n\nBut what I can suggest to you is to send an email to tensorflow-enterprise-support@google.com with your question, and hopefully they can give you a direct solution to your concerns.\n\nAdditionally, I found this Stack Overflow question to create labels.txt manually.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-10-25T10:25:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I am still reviewing documentation to determine if there is one way to create a rule.\n\nAs soon as I collect more information about your main concern, I will share it with you as soon as possible."
            },
            {
                "Answer_creation_date":"2022-10-25T15:27:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"After reviewing more about Export AutoML Edge models, you can see the following TensorFlow documentation to learn more about extracting this information.\n\nTensorFlow Lite inference with metadata\nGenerate model interfaces with TensorFlow Lite code generator\nAdding metadata to TensorFlow Lite models\n\nThe documentation that might help more for your question is the last one \u201cAdding metadata to TensorFlow Lite Models\u201d.\n\nBut what I can suggest to you is to send an email to tensorflow-enterprise-support@google.com with your question, and hopefully they can give you a direct solution to your concerns.\n\nAdditionally, I found this Stack Overflow question to create labels.txt manually."
            },
            {
                "Answer_creation_date":"2022-10-25T17:31:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks! I was able to use unzip command in my terminal and extract the label file."
            }
        ]
    },
    {
        "Question_title":"Converting TIFF files to base64 using Java",
        "Question_creation_date":"2022-10-24T08:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Converting-TIFF-files-to-base64-using-Java\/td-p\/481476\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":50,
        "Question_body":"Hi I have two instances where I'm converting a TIFF file before sending the data to google vision AI. Using CLI, the base64 string works fine. I get the expected responseWhen I use Java I'm getting a different out, which causes my API call to fail. The base64 output is different.  I'm looking for suggestions on how to convert a file (tiff, pdf, png) to base64 using plain Java ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-25T14:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You could convert your images as shown in this sample code from this Stack Overflow question:\n\n    File File = new File(args[2]);\n    String ImageString;\n\n    FileInputStream fileInputStreamReader = new FileInputStream(File);\n    byte[] bytes = new byte[(int)File.length()];\n    fileInputStreamReader.read(bytes);\n    ImageString = Base64.getEncoder().encodeToString(bytes);\n\n\nSee also:\n\nBase64 Encoding - Using client libraries"
            }
        ]
    },
    {
        "Question_title":"Confirmation page \/ custom text",
        "Question_creation_date":"2022-10-22T03:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Confirmation-page-custom-text\/td-p\/480915\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":36,
        "Question_body":"Hi All,I'm just migrating over from AWS to CX, and so far I think its great. However - the tutorial section I'm working through kind of hit a 'draw the rest of the owl' meme - if you don't know it, look it up.The difficult bit is where it gets to 'confirmation page' in the quick start - here: ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-25T13:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"In order to fulfill the create confirmation page step, you could follow the instructions given in the Create the location page section.\n\nIn order to get the example working, please double check that all steps are completed and the variable names are the same as used in order to test the completed agent.\n\nThis article could be helpful to create A Conversational Agent with Dialogflow.\n\nSome important concepts used in the quickstart:\n\nIntent\nParameters\nEntity types\nSession parameters\nConditions"
            }
        ]
    },
    {
        "Question_title":"Will Google provide MTQP in Cloud Translation API?",
        "Question_creation_date":"2022-10-25T12:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Will-Google-provide-MTQP-in-Cloud-Translation-API\/td-p\/482115\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":41,
        "Question_body":"Hi, I discovered with interest that your Google Translation Hub advanced tier offers document post-editing features, and, as part of that, includes an MTQP quality prediction score on a segment by segment basis. \n\nThis would be a very interesting feature to include in Cloud Translation API, particularly for TMS and CAT tools like Trados\/MemoQ\/Memsource that could then provide that information to the translator, similar to what a fuzzy match is for traditional Translation Memory technology.\n\nIt could also be very useful to decide whether a raw machine translation process (without review) is suitable for a document, or to identify the few segments that absolutely must go through human editing depending on your acceptable quality profile.So my question is whether Google is looking at making this available in the API, or whether Google is treating that as proprietary information that you guys do not want to make available outside of your Google Translation Hub?  I really hope the answer is the former, not the latter...\n\nThank you.\n\nMichel Farhi\nPrincipal Localization Engineer\nNI (formerly National Instruments)",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-25T12:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\u00a0\n\nI discovered with interest that your Google Translation Hub advanced tier offers document post-editing features, and, as part of that, includes an MTQP quality prediction score on a segment by segment basis.\u00a0\n\nThis would be a very interesting feature to include in Cloud Translation API, particularly for TMS and CAT tools like Trados\/MemoQ\/Memsource that could then provide that information to the translator, similar to what a fuzzy match is for traditional Translation Memory technology.\n\nIt could also be very useful to decide whether a raw machine translation process (without review) is suitable for a document, or to identify the few segments that absolutely must go through human editing depending on your acceptable quality profile.\n\nSo my question is whether Google is looking at making this available in the API, or whether Google is treating that as proprietary information that you guys do not want to make available outside of your Google Translation Hub?\u00a0 I really hope the answer is the former, not the latter...\n\nThank you.\n\nMichel Farhi\nPrincipal Localization Engineer\nNI (formerly National Instruments)"
            }
        ]
    },
    {
        "Question_title":"Short glossary terms not respected in the Translation API",
        "Question_creation_date":"2022-10-20T11:04:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Short-glossary-terms-not-respected-in-the-Translation-API\/td-p\/480322\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":37,
        "Question_body":"We are seeing that some glossary terms are not respected in the translation API. For example, we have \"IT\" defined in our glossary for both English and Spanish. However,  it is being translated to \"TI\" when translating from English to Spanish. Other glossary terms are behaving as expected. Is anyone else seeing this? It's causing a lot of issues with our translations.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-24T07:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This behavior is caused by the word \u201cit\u201d being included as an English stopword\u00a0for the Translate API. Any stopwords used as entries in a glossary will be ignored\u00a0by the API. I created a glossary to replicate this, and I also saw the same results.\n\nGiven that entries containing only the stopword will be ignored, you could instead pair the word \u201cIT\u201d in multiple entries with additional words (e.g. \u201cIT industry\u201d). Another possibility would be to use another abbreviation for \u201cIT\u201d such as \u201cI.T.\u201d"
            }
        ]
    },
    {
        "Question_title":"SSML to read Date in German Language not working",
        "Question_creation_date":"2022-04-21T14:39:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/SSML-to-read-Date-in-German-Language-not-working\/td-p\/415908\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API",
            "Contact Center AI",
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":77,
        "Question_body":"Hi - I am working on converting Text to Speech using SSML via Google Speech API. Below is the request to the API. This perfectly works when language Code is En-US , however for code de-DE and to hear in German voice, the output is totally random. Please help me in checking this issue,  TTS Request JSON :: {\"voice\":{\"ssmlGender\":\"MALE\",\"name\":\"de-DE-Wavenet-E\",\"languageCode\":\"de-DE\"},\"input\":{\"ssml\":\"<speak><say-as interpret-as=\\\"date\\\" format=\\\"yyyymmdd\\\"> 20220506<\\\/say-as><\\\/speak>\"},\"audioConfig\":{\"sampleRateHertz\":8000,\"volumeGainDb\":0,\"speakingRate\":1,\"audioEncoding\":\"LINEAR16\",\"pitch\":0,\"effectsProfileId\":[\"telephony-class-application\"]}} The same request when changeing the name and Language code works perfectly.",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-06T07:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You will want to see this documentation where it\u2019s explained how to use different languages instead of english in SSML they also provide some code examples as the one i\u2019m sharing where it explains how to use the Voice tag in SSML.\n\n\u00a0\n\n<speak>The dog is friendly<voice name=\"fr-CA-Wavenet-B\">mais la chat est\u00a0mignon<\/voice><break time=\"250ms\"\/> said a pet shop\u00a0owner<\/speak>"
            },
            {
                "Answer_creation_date":"2022-10-22T09:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Eduardo,\n\nyou may have a look at this as well. The google asr has still problems with german date transcription:\n\nhttps:\/\/stackoverflow.com\/questions\/66799469\/google-speech-recognition-weak-date-transcription\n\nBest Regards\n\nAndre"
            }
        ]
    },
    {
        "Question_title":"Vertex Workbench Managed Notebook vs Quotas",
        "Question_creation_date":"2022-08-03T08:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-Workbench-Managed-Notebook-vs-Quotas\/td-p\/450055\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":138,
        "Question_body":"Hi to allA little help need it... Im trying to create a Managed Notebook with the next configuration for what I request a quota increase as you can see in the following imagesa2-highgpu-1g (Accelerator Optimized: 1 NVIDIA Tesla A100 GPU, 12 vCPUs, 85GB Ram) The problem is that although I got the quota increase I have not been able to create the notebook in any us regions as:  US Central (Iowa1), Us West (Oregon), always get the same error: Could not create instance: Quota limit 'GPUsA100PerProjectPerRegion' has been exceeded. Limit: 0 in region us-central1.What Im doing wrong? How much quota do I need to get so I can use this type of machine?",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-04T14:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For quotas error you can contact Billing support."
            },
            {
                "Answer_creation_date":"2022-10-22T05:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It's the same problem for me. Let us know if you were able to solve it"
            }
        ]
    },
    {
        "Question_title":"Working with Context for different intent",
        "Question_creation_date":"2022-09-19T10:24:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Working-with-Context-for-different-intent\/td-p\/468253\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":138,
        "Question_body":"Hello,\ni'm really new in DialogFlow and would like to dig deep my knowledge about this topic.\nMy question right now is about context. So for my case, i build a Conversational Bot for a Fitness Center and trying to create intent related to an individual's program goal\n\nSo for the training phrases would be\"i want to get ideal weight\"\n\"i want to build muscle\"\n\"i want to be more healthy\"\n\"i want to lose weight\"\n\"i want to gain weight\"\n\nI Called the entity \"Individual-goal\"\nTha Output Context for this is \"Fitness-Goal\"Now for my question:\ni would like to segment OR create the \"Sub-Context\" for this Fitness Goal, in following category:\nHealth - Gain Weight\nHealth - Lose Weight\nHealth - General\nFitness - Muscle Building\nFitness - General\n\nFor this case:\n1. Is it better for me to create multiple Intent ?\n2. Is there a way to put a context based on the response, like \"IF Individual goal contain 'gain weight' then Output Context set to \"Health - Gain Weight\"\n\nWhats the best scenario for this ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-28T11:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It is better to create separate intents as shown in the examples of this documentation."
            },
            {
                "Answer_creation_date":"2022-10-21T08:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Its a while since you asked this so you may have already worked it out. You probably need to create an intent for each category like 'gain weight; so another one for 'fitness building'.\n\nAs CX is a 'state machine' (think of it this as lots of rooms off a corridor) the conversation depends what room your in. So if your in a 'lose weight room' your intent keyword of 'weight' will mean 'lose weight in that room'. But in a 'gain weight' room any conversation around weight will pick up trained phrases that interpret this in a way that relates to adding on weight.\u00a0\n\nHence you need to chose how many separate 'rooms' (different topics) you need and build the dialog specific to each room through intent to get you in there, and then build up your fulfilment from it too. Each room is standalone really. CX only finds the trained answers for that specific room when it is in it. This is the 'state machine' in action.\n\nFrom that map of rooms you then link your rooms together through pages \/ routes.\u00a0\n\nThe map starts in the 'default start page' so all rooms connected to start page ('routed') lead off it like a big entrance hall. User initially chatting 'gain weight' will be taken into that room (state) by CX. Once in there, unless you build a route directly from the gain weight room to the lose weight room, the visitor won't be able to access lose weight. They'd have to go back to the entrance hall to have a door into lose weight.\n\nSo you'll need to build a network of rooms through intent and pages, route them off a central entrance hallway and if you want them to interconnect you'll have to build a route network between them too.\n\nIt can get messy but it's genius when you get your head round it. Do the logical design first or frankly it can hurt"
            }
        ]
    },
    {
        "Question_title":"Google Translate API and Serbian Latin script",
        "Question_creation_date":"2022-10-11T02:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-API-and-Serbian-Latin-script\/td-p\/476723\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":128,
        "Question_body":"Hi there,In Serbia we are using 2 scripts side by side - Cyrillic and Latin script.I am heaving an issue with translation to Serbian Latin.\nBy default Google translate offer translation to Serbian Cyrillic , but bellow that default translation there is a translation to Serbian Latin.\nTake a look at this example:\nhttps:\/\/translate.google.com\/?sl=en&tl=sr&text=Hello%20world!&op=translateI have found this post from early 2019.\nhttps:\/\/support.google.com\/translate\/thread\/1836538?hl=enLike in that post my question is the same:\nI need it to support Serbian Latin, for some projects I don`t use the Cyrillic script. Also there is a problem with translating pages or similar plugins, e.g.: Google Language Translator for WordPress and some others CMS system like Kopage you can translate only to Serbian Cyrillic script.As I found this post on stackoverflow:\nhttps:\/\/stackoverflow.com\/questions\/73699065\/google-cloud-translate-serbian-latin-not-workingIt seems, according to the poster of that article, that there was a workaround.\nInstead of \"sr\" ISO-639 code you can put \"sr_Latn\" - and you will get translation into Serbian Latin script.\nBut that workaround stop working several weeks ago - according to the poster.Is there a workaround to translate into Serbian Latin characters rather into Serbian Cyrillic characters?Regards,\nBranislav",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-12T08:12:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"It appears that translation to the Serbian Latin Alphabet is not officially supported by the Cloud Translate API, as discussed in this recent issue. Therefore it\u2019s not assured that any possible workaround will be functional or reliable. You can see the list of supported language codes for translation here.\n\nYou can, however, submit a Feature Request to the public Google issue tracker for Cloud Translation API. The higher the number of users who bring attention to this request, the more likely it is for it to be eventually built into the API.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-10-19T12:17:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"You can just used a rules-based local library to reliably transliterate the sr-Cyrl that Google produces to sr-Latn.\n\nGoogle Translate never supported\u00a0translation\u00a0to sr-Latn.\u00a0 The feature you see at translate.google.com and in the mobile app is rules-based transliteration.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-10-12T08:12:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"It appears that translation to the Serbian Latin Alphabet is not officially supported by the Cloud Translate API, as discussed in this recent issue. Therefore it\u2019s not assured that any possible workaround will be functional or reliable. You can see the list of supported language codes for translation here.\n\nYou can, however, submit a Feature Request to the public Google issue tracker for Cloud Translation API. The higher the number of users who bring attention to this request, the more likely it is for it to be eventually built into the API."
            },
            {
                "Answer_creation_date":"2022-10-19T12:17:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"You can just used a rules-based local library to reliably transliterate the sr-Cyrl that Google produces to sr-Latn.\n\nGoogle Translate never supported\u00a0translation\u00a0to sr-Latn.\u00a0 The feature you see at translate.google.com and in the mobile app is rules-based transliteration."
            }
        ]
    },
    {
        "Question_title":"Meetup on machine translation for low-resource languages this Friday!",
        "Question_creation_date":"2022-10-19T12:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Meetup-on-machine-translation-for-low-resource-languages-this\/td-p\/479955\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":1,
        "Question_view_count":19,
        "Question_body":"The last machine translation meetup featured a PM for the Google Cloud Translation API in person.The next machine translation meetup is all about low-resource machine translation and it'll be online.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-19T12:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The last machine translation meetup featured a PM for the Google Cloud Translation API in person.\n\nThe next machine translation meetup is all about low-resource machine translation\u00a0and it'll be online.\n\n\u00a0\nmachinetranslate.org\/meetup\n\u00a0\nThe 25-minute panel features guests from Meta AI,\u00a0NeuralSpace, LoResMT, and Masakhane!\n\nRegister to join us\u00a0this Friday at 8am PST"
            }
        ]
    },
    {
        "Question_title":"Too many pages",
        "Question_creation_date":"2022-10-17T05:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Too-many-pages\/td-p\/478806\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":42,
        "Question_body":"I sent a 13 page pdf thru a document ai parser.  GCP, instead of populating the errors collection of the result with an error indicating too many pages, instead throws a runtime error causing a crash.Is try...except... really the best solution for this as I've not seen use of try...except in any of Google parser examples.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-17T16:04:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For this kind of issues, you could file a report as shown in the documentation:\n\n\nIssue reports\n\nGoogle reviews every new issue report submitted by users. Sometimes one of our staff will ask for clarification or follow up. After we're able to replicate the issue, we'll tell you that it's been forwarded to the appropriate team.\n\nDepending on the circumstances, we may be able to provide periodic updates while an issue is being looked at, but usually we cannot provide too many specifics about the exact cause of an issue, or when it will be fixed.\n\nWhen we've fixed an issue in production, we'll indicate this and then we'll close the issue.\n\nYou can create a new Document AI issue here."
            }
        ]
    },
    {
        "Question_title":"No results with is_final true for single utterance set to true",
        "Question_creation_date":"2022-10-11T06:18:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/No-results-with-is-final-true-for-single-utterance-set-to-true\/td-p\/476809\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":72,
        "Question_body":"I am using below configuration to identify my voice input stream (Hindi language)  :",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-12T09:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Have you confirmed whether changing the set_interim_results()\u00a0property to `false` changes the output result? Based on the documentation, using false\u00a0as the argument will only return results with is_final=true."
            },
            {
                "Answer_creation_date":"2022-10-13T06:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for your response.\n\nI do not get any results if I change set_interim_results() property to false.\u00a0\n\nI did get some interim results when the property was set to true and\u00a0\n\nspeech_event_type() did return 1. Usually, I get response with is_final set to true, but this does not happen in this case . Below is the log from my application when\u00a0set_interim_results() is set to true\u00a0:\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\nhlpr_start_stream() ----> !!!!!!!!!!!!!! Vaibhav :: single_utternace :  ======== : 0\n\n2022-10-11 09:24:15:824114 [INFO]    hlpr_start_stream() --> printing results : 0.900000\n\n2022-10-11 09:24:15:824126 [INFO]   hlpr_start_stream() ---> !!!!!!!!!!!!!! inside 2nd if -------------------------------------\n\n2022-10-11 09:24:15:824132 [INFO]    ########## hlpr_start_stream() printing interim results transcript  #####: \u0907\u0938\n\n2022-10-11 09:24:15:824139 [INFO]    hlpr_start_stream() -----Vaibhav :: time_since_epoch() = 0 \n\n2022-10-11 09:24:18:257357 [INFO]   hlpr_start_stream() ----> !!!!!!!!!!!!!! Vaibhav :: single_utternace :  ======== : 1\n\n\u00a0\n\nMy application keeps on waiting for response till I close the stream."
            },
            {
                "Answer_creation_date":"2022-10-17T13:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As your application remains waiting until you close the stream, have you verified that the final result of the transcription is not merely taking additional time? As an example, this issue\u00a0shows similar behavior involving not receiving the final transcription quickly, depending on the language. Are you experiencing the same behavior even when using a different language?"
            }
        ]
    },
    {
        "Question_title":"Poor OCR results from PDF files compared to TIFFs",
        "Question_creation_date":"2022-10-14T03:18:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Poor-OCR-results-from-PDF-files-compared-to-TIFFs\/td-p\/478060\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":1,
        "Question_view_count":63,
        "Question_body":"Hi,We're using DOCUMENT_TEXT_DETECTION in production to perform OCR on documents. We've found  the quality of OCR of PDF documents compared to the exact same TIFF to be very poor (with missing characters, extra whitespace etc).I've attached an example test image in both PDF and TIFF formats. You can see the text is very legible and the OCR from the TIFF is 100% correct. The OCR from the PDF has multiple missing characters.This leads me to believe that the internal rendering of PDFs performed by the cloud vision API is buggy.Can anyone shed any light?Correct OCR results from TIFF:Poor read from PDF:See missing hyphen, missing 'ME' from 'PAYMENT', and various lost hash\/pound characters with extra newlines.The pdf and tiff can be found in this shared gdrive: https:\/\/drive.google.com\/drive\/folders\/1M4VZ3cT3YDoEn5o565fdWP6_47Y_KISL?usp=sharingHere's a screenshot of the PDF for ease: ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-17T09:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, phildrip,\n\nCould you try TEXT_DETECTION instead of DOCUMENT_TEXT_DETECTION and share your results?\n\nTo update your model, simply set the 'model' value to \"builtin\/latest\", e.g code sample:\n\nclient = vision.ImageAnnotatorClient()\nfeature = vision.types.Feature(\ntype=vision.enums.Feature.Type.TEXT_DETECTION, model=\"builtin\/latest\")\n\nI will be awaiting your response."
            }
        ]
    },
    {
        "Question_title":"Triton on Vertex AI does not support multiple models?",
        "Question_creation_date":"2022-08-25T07:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Triton-on-Vertex-AI-does-not-support-multiple-models\/td-p\/459822\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":107,
        "Question_body":"Currently, I want to deploy a Triton server to Vertex AI endpoint. However I received this error message.\"failed to start Vertex AI service: Invalid argument - Expect the model repository contains only a single model if default model is not specified\"Is this mean that the Triton server deploy only support one model? It is different from what I have read in this document about concurrent model executionhttps:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/using-nvidia-triton",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-07T13:44:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The error message suggest that you haven't selected a default model."
            },
            {
                "Answer_creation_date":"2022-10-17T07:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I have the same issue and I couldn't find how to set a default model. Could you please link a guide about it or explain how to do that? Thanks"
            }
        ]
    },
    {
        "Question_title":"How to connect Elasticsearch to Jupyter Notebook on GCP",
        "Question_creation_date":"2022-10-08T02:28:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-connect-Elasticsearch-to-Jupyter-Notebook-on-GCP\/td-p\/475882\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":105,
        "Question_body":"Hi,I am working on an ML project which requires to use Transformers and Elasticsearch.For Transformers, I have created a Jupyter Notebook instance on GCP.For Elasticsearch I will create another instance on CGP.As part of project requirement, I need to access Elasticsearch in Jupyter Notebook through port 9200. I need to ingest data in Elasticsearch and run search queries which can fetch relevant information from Elasticsearch DB and give it in Notebook.My question is that if I create two separate instances of Notebook and Elasticsearch and if i try to connect Elasticsearch through Jupyter Notebook via port 9200, will i be able to connect and perform the above mentioned operations ?If NO, then what is the procedure to do so ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-10T15:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you elaborate on how you have set up the Elasticsearch and Jupyter notebook instances? On which compute service is your Elasticsearch instance running?"
            },
            {
                "Answer_creation_date":"2022-10-12T02:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nBelow is the Screenshots of the way i have setup Jupyter Notebook instance and Elasticsearch instance.\n\n1.\n\nVertex AI Workbench - Jupyter Notebook\n\nThis is a link of the screenshot of the Vertex AI workbench where I have created a Jupyter Notebook instance.\n\n2. Below is the screenshots of the way I have accessed Elasticsearch through marketplace. Once I click on the service provider, the second screenshot is the landing page of Elasticsearch Cloud where also, I have signed and created the account.\n\nElasticsearch in Market Place\nLanding Page of Elasticsearch once we click on provider\n\n\u00a03. I want to access the Elasticsearch through \"http\" request made through my Jupyter Notebook and the screenshot of the codes which I want to run in my Jupyter Notebook is attached in below links.\n\nCode Snippet 3\n\n\u00a0\n\nCode Snippet 2\n\n\u00a0\n\nCode Snippet 1\n\n\u00a0Please Note that I want to access Elasticsearch version 8 onwards, as version 8 onwards, there is a facility to ingest \"Dense Vector\" in the database."
            },
            {
                "Answer_creation_date":"2022-10-14T15:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Using the Elasticsearch managed service from the GCP marketplace, you would need to use the [provided guide\u00a0to connect using a Python environment (in this case being the Jupyter notebook). Additional methods of connecting to the JSON API of the service are also included\u00a0in the documentation.\n\nIf you would like to exclusively connect directly to the deployment using port 9200, creating a deployment within a VM instance in GCE\u00a0should be more appropriate. This is due to the fact that a Vertex Workbench Notebook is also hosted on a GCE instance, and can be set up to be in the same VPC as a VM hosting Elasticsearch."
            }
        ]
    },
    {
        "Question_title":"Does Vertex AI support multiple model instances in Same Endpoint Node.",
        "Question_creation_date":"2021-09-13T04:57:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Does-Vertex-AI-support-multiple-model-instances-in-Same-Endpoint\/td-p\/169614\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":84,
        "Question_body":"We are trying to deploy the model in Vertex Endpoint with GPU support. \nHere we are facing two problems, GPU memory is fully reserved by a single model but GPU poweris underutilize. \n\nSo can we deploy multiple Workers in the Same Node and also how to allow the worker to reserve VRAM only up to it required?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-14T15:28:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can deploy more than one model to the same endpoint (documentation), however the resources are\u00a0associated with the model rather than the endpoint."
            }
        ]
    },
    {
        "Question_title":"How to set multiple series identifier columns on tabular forecast?",
        "Question_creation_date":"2021-08-11T22:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-set-multiple-series-identifier-columns-on-tabular\/td-p\/166959\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":108,
        "Question_body":"Hello,I tried BigQuery ML's ARIMA+ to predict sales data, but the results were not particularly good.So, I wanted to try adding weather as a feature to the dataset. This requires the use of Vertex AI Tabular forecast (AutoML).The dataset looks like this.When using ARIMA+, multiple columns can be specified by using the following statement. How to set multiple series identifier columns on AutoML? Should I consider merging the store and product columns into one column(eg: tokyo_pixel6)?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-14T15:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I found this section of the documentation, which might be helpful:\u00a0\n\nOne of your columns in your training data for a forecasting model must be specified as the time series identifier. Forecasting training data usually includes multiple time series, and the identifier tells Vertex AI which time series a given observation in the training data is part of. All of the rows in a given time series have the same value in the time series identifier column.\n\nSome common time series identifiers might be the product ID, a store ID, or a region. When you have multiple time series in your training data, there should be a specific column that differentiates them.\n\nYou can train a forecasting model on a single time series (in other words, the time series identifier column contains the same value for all rows). However, Vertex AI is a better fit for training data that contains two or more time series. For best results, you should have at least 10 time series for every column used to train the model."
            }
        ]
    },
    {
        "Question_title":"How to use Recommendations AI(Retail API) for multiple stores?",
        "Question_creation_date":"2022-10-12T04:51:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-use-Recommendations-AI-Retail-API-for-multiple-stores\/td-p\/477225\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Recommendations AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":39,
        "Question_body":"Hi Guys,We are trying to build an e-commerce personalized recommendation system. we want to make it worthwhile for our clients.  We are trying to use the recommendations API(retail API) for multiple e-commerce stores. But in the retail API, it seems we can use retail API under one project per store. Importing catalogs, creating models, and getting recommendations are only applicable to a single store under one project.One solution is to create separate projects per store only to use retail API, which is not the right way for numerous customers.So, is there any way to do this or any other GCP service that we can go for? Please suggest. Thanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-14T11:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If you are currently working to build an e-commerce system, one suggestion as an alternative GCP service is to follow the Building an e-commerce recommendation system by using BigQuery ML.\n\n\nAdditionally, here is a guide written by Polong Lin\u00a0using the documentation referred above."
            }
        ]
    },
    {
        "Question_title":"Exempt few words within paragraph while translating through Google Translation clod API",
        "Question_creation_date":"2022-10-13T08:54:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Exempt-few-words-within-paragraph-while-translating-through\/td-p\/477744\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":48,
        "Question_body":"I have a use case where I need to translate biographies of some Doctors. I am using cloud API for translation but I want to exempt few words like degree or school of degree and some other specific terms and some html tags. How can we restrict those not to be translated. Glossary works only for exact match. How can I exempt words within paragraph? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-14T09:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As mentioned\u00a0here,\u00a0you can use the following HTML tags:\n\n<span translate=\"no\"> <\/span>\n\n<span class=\"notranslate\"> <\/span>\n\nThis functionality requires the source text to be submitted in HTML.\n\nMore on this can be found in\u00a0this Stack Overflow post\u00a0and\u00a0this group post"
            }
        ]
    },
    {
        "Question_title":"Dialogflow should have its own official facebook app for integration",
        "Question_creation_date":"2022-10-13T21:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-should-have-its-own-official-facebook-app-for\/td-p\/477998\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":32,
        "Question_body":"Current dialogflow integration is sensible, however it was very tedious for anyone to must become facebook developer and create their own facebook app. While most of the page's owner are not developer and just want to link some of their page to dialogflowI want to propose that dialogflow should have facebook app with `manage_pages` permission. Have button for oauth with facebook for integration. And just allow user to choose some of their pages to link with dialogflow project. Then all the process in the guideline can be automated. Dialogflow could also config the settings for Webhooks channels it needI want to comment that this was a very roadblock that I have faced when I try to start integrate facebook. The message was not get to dialogflow properly and I don't know I also need `messaging_postbacks` channel, not only `messages`. If Dialogflow app will manage these for us it will be the far much better integration experienceps. Please also add label `Dialogflow` and `Dialogflow ES` to the available label",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-13T21:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Current dialogflow integration is sensible, however it was very tedious for anyone to must become facebook developer and create their own facebook app. While most of the page's owner are not developer and just want to link some of their page to dialogflow\n\nI want to propose that dialogflow should have facebook app with `manage_pages` permission. Have button for oauth with facebook for integration. And just allow user to choose some of their pages to link with dialogflow project. Then all the process in the guideline can be automated. Dialogflow could also config the\u00a0settings for\u00a0Webhooks channels it need\n\nI want to comment that this was a very roadblock that I have faced when I try to start integrate facebook. The message was not get to dialogflow properly and I don't know I also need `messaging_postbacks` channel, not only `messages`. If Dialogflow app will manage these for us it will be the far much better integration experience\n\nps. Please also add label `Dialogflow` and `Dialogflow ES` to the available label"
            }
        ]
    },
    {
        "Question_title":"Speech-to-Text billing optimization",
        "Question_creation_date":"2022-10-11T20:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-to-Text-billing-optimization\/td-p\/477135\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API",
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":35,
        "Question_body":"Hi AllAnyone knows if with the Speech-to-Text API \u00bfCan we do a committed consume contract similar with other GCP services to get fees or billing optimization by month?Thanks in advance for your response",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-11T20:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi All\n\nAnyone knows if with the Speech-to-Text API \u00bfCan we do a committed consume contract similar with other GCP services to get fees or billing optimization by month?\n\nThanks in advance for your response"
            }
        ]
    },
    {
        "Question_title":"Due to an error, Vertex AI was unable to train model \"some_model",
        "Question_creation_date":"2022-10-09T07:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Due-to-an-error-Vertex-AI-was-unable-to-train-model-quot-some\/td-p\/476128\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":61,
        "Question_body":"Hi Team\nWe are trying to train the model, but we are getting the below error after running 2 hrs.Region       : us-centerl1(IOWA) Algorithm : AutoML\nObjective  : Image classification (Single-label)\nData split:   Randomly assigned (80\/10\/10)Due to an error, Vertex AI was unable to train model \"some_model\".\nAdditional Details:\nOperation State: Failed with errors\nResource Name: \nprojects\/1096088445304\/locations\/us-central1\/trainingPipelines\/8154185764406558720\nError Messages: INTERNALKindly help us to resolve the issue. \nThanks & Regards\nJambu ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-11T08:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you please share more information on the error message that you are receiving, since the information you are sharing isn\u2019t enough to properly help with the issue you are facing.\n\nThe internal errors occur when there\u2019s an issue with your system. The error could be transient, try to resubmit the CustomJob, HyperparameterTuningJob or TrainingPipeline, if the error persists what is recommended that you do is to contact support."
            }
        ]
    },
    {
        "Question_title":"Tabular Forecasting Model in Vertex AI - Cannot deploy model to endpoint",
        "Question_creation_date":"2022-10-08T03:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Tabular-Forecasting-Model-in-Vertex-AI-Cannot-deploy-model-to\/td-p\/475893\/jump-to\/first-unread-message",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":45,
        "Question_body":"I'm getting started with Vertex AI, and the model I'd like to use is a Tabular Forecasting Model. After spending hours tweaking the model that I wanted to deploy, I came across this error message. \"The default version cannot be deployed\". I can deploy a normal Tabular model to an endpoint, but not the Tabular Forecasting model. Does anyone know if there is a way to deploy a Tabular Forecasting Model? If not, is Google planning on adding this functionality anytime soon? Thanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-10T14:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You are able to use Tabular Forecasting on Vertex AI the issue you are facing might be occurring since it was omitted one step from the guide that google offers. I recommend you to check the hyperlink I attached since it outlines how to properly achieve this.\n\nAlso a couple of points that you might want to be aware of are the next ones:\n\nYou can export AutoML tabular classification and regression models only. Exporting AutoML tabular forecasting models is not supported.\nVertex Explainable AI is not available using exported tabular models. If you need to use Vertex Explainable AI, you must serve predictions from a model hosted by Vertex AI.\nThe exported tabular model can run only on x86 architecture CPUs that support Advanced Vector Extensions (AVX) instruction sets."
            }
        ]
    },
    {
        "Question_title":"Does Vertex AI support multi model endpoints",
        "Question_creation_date":"2021-07-07T03:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Does-Vertex-AI-support-multi-model-endpoints\/td-p\/163169\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":7,
        "Question_upvote_count":2,
        "Question_view_count":858,
        "Question_body":"We have 100's of models and deploying each one to its independent endpoint is very expensive.We are looking for a way to deploy multiple models to a single endpoint.Our docker image will have all the models and we will be having custom logic to invoke the models based on the request from the endpoint.Similar functionality is available in AWS SageMaker.",
        "Answers":[
            {
                "Answer_creation_date":"2021-07-08T06:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I read the following Vertex AI documentation page:\n\nhttps:\/\/cloud.google.com\/vertex-ai\/docs\/general\/deployment#models-endpoint\n\nThis page seems to say that we can deploy multiple models to the same endpoint.\u00a0 If I understand that correctly, you can then serve multiple models from the same endpoint nodes."
            },
            {
                "Answer_creation_date":"2021-07-08T07:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I think this means deploying multiple versions of the same model and not completely independent model."
            },
            {
                "Answer_creation_date":"2021-07-14T07:33:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi there,\n\nYou may deploy totally different models to the same endpoint on Vertex AI and split the traffic as you wish. There is no technical restriction. From a business point of view, you may prefer to have the same (or similar) targeting goals for the models in order to support your decisions."
            },
            {
                "Answer_creation_date":"2021-11-07T16:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, how would that work though, as in, if the endpoint is the same, how do we make sure that we request a specific model prediction. For example, if we deploy 2 different models, say model1 and model2, to the same endpoint, with a traffic split of 50%, then what this means is that all requests to this endpoint are split to the two models with a probability of 0.5, i.e., if a we make a request, sometimes we will be served by model1 and sometimes by model2. How do we make sure we are served by a specific model in this scenario?"
            },
            {
                "Answer_creation_date":"2021-11-16T08:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"you can actually deploy a multi model endpoint and to call a specific model, just add the argument \"TargetModel\": 'yourmodelname.tar.gz'.\n\nfor more information refer to this link :\u00a0https:\/\/towardsdatascience.com\/deploy-multiple-tensorflow-models-to-one-endpoint-65bea81c3f2f"
            },
            {
                "Answer_creation_date":"2021-11-16T09:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes that option is available in amazon sagemaker as the article suggests.Is it also possible with vertex ai"
            },
            {
                "Answer_creation_date":"2022-10-10T06:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nCould you please suggest how to do this using the Python API? (https:\/\/googleapis.dev\/python\/aiplatform\/latest\/aiplatform.html)\n\nI have been trying but when specifying a `traffic_split` dict, the keys of this dict have to be\u00a0Deployed Model IDs, which makes no sense because the models are not deployed yet when calling `model.deploy()`\n\nThank you!"
            }
        ]
    },
    {
        "Question_title":"CX Phone gateway caller_id lost when forwarding to US-number",
        "Question_creation_date":"2022-10-06T04:46:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/CX-Phone-gateway-caller-id-lost-when-forwarding-to-US-number\/td-p\/475112\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":61,
        "Question_body":"Hello everyoneWe use dialogflow cx with the cx phone gateway. But because we aren't based in the US we used a local phone number which we forward to the US-number from the gateway.This worked great for some days, but now we are experiencing the following issue:\nThe caller_id from the original caller does not get sent in the webhook response anymore. It only sends the number which forwards the call.Does someone know how to prevent this from happening?Thanks for your help!- Federico",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-07T08:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"In this Stackoverflow post\u00a0you might find useful information. As Dialogflow CX Phone Gateway is in Preview. You may also consider reporting this issue here\u00a0to improve this feature. Take a look at this issue tracker information about how to report issues. Because it uses the number of \"stars\" (people who have indicated interest in an issue) to prioritize work on the platform, you should search existing issues before you make a new entry."
            },
            {
                "Answer_creation_date":"2022-10-10T00:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for your response.\nUnfortunately the Stackoverflow post you mentioned does not help me because I already get a caller_id but its not the right one."
            }
        ]
    },
    {
        "Question_title":"AI Augmented Sensory Headset",
        "Question_creation_date":"2022-10-07T20:18:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AI-Augmented-Sensory-Headset\/td-p\/475836\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":20,
        "Question_body":"Wondering when Google will develop olfactory sensor addition to VR headsets and technology. In laymens terms, adding the sense of smell to VR headsets using an add on similar to a printer ink cartridge, but designed specifically for the sense of smell. Theoretically, it is possible, but to manufacture it in a large scale. It can change the way programs, especially helping boost the food and hospitality industry as well as giving everyday people a very good reason to smell fresh food and drink... from their phone! Where and how can we further this research for this wonderful idea?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-07T20:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Wondering when Google will develop olfactory sensor addition to VR headsets and technology. In laymens terms, adding the sense of smell to VR headsets using an add on similar to a printer ink cartridge, but designed specifically for the sense of smell. Theoretically, it is possible, but to manufacture it in a large scale. It can change the way programs, especially helping boost the food and hospitality industry as well as giving everyday people a very good reason to smell fresh food and drink... from their phone! Where and how can we further this research for this wonderful idea?"
            }
        ]
    },
    {
        "Question_title":"Text to speech data residency",
        "Question_creation_date":"2022-10-05T12:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Text-to-speech-data-residency\/td-p\/474727\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":84,
        "Question_body":"Compliance team is asking for Data residency for text to speech data. On Google website, it says,\u201cText-to-Speech is both stateless and resourceless. This means Data Access and System Event data don't apply. As a result, Text-to-Speech is out of the scope of Client Access Licenses (CAL). Google does not log any customer Text-to-Speech text or audio data.\u201dDoes logging here refer to data storage. We do not want to store any data in the cloud. Regards,",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-07T08:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Reviewing the documentation you shared, you might also want to review Data Logging.\n\nYou will find that if you enable the information log, it helps to enhance speech to text, but not all the information you will use will be preserved, so, the log will only be saved if you actually want to use it or not."
            }
        ]
    },
    {
        "Question_title":"Advanced NLU v\/s Standard NLU",
        "Question_creation_date":"2022-10-06T08:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Advanced-NLU-v-s-Standard-NLU\/td-p\/475233\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":87,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-06T16:16:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As shown in the Dialogflow CX - Agents documentation, in the NLU type section:\n\nNLU type\n\nThis can be one of:\n\nStandard\nStandard NLU technology.\nAdvanced\nAdvanced NLU technology. This NLU type works better than standard, especially for large agents and flows. Model training takes longer, so automatic training is disabled. You need to train the flows manually or via API.\n\nTherefore, the NLU advanced is recommended for large agents and flows. Note that the training model takes longer, so automatic training is disabled, and should be done through manual flows or using the API.\n\nThis article discusses further about Dialogflow CX."
            }
        ]
    },
    {
        "Question_title":"Google Vision API pricing",
        "Question_creation_date":"2022-06-10T09:35:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Vision-API-pricing\/td-p\/430454\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":185,
        "Question_body":"Hello,I'm currently using the service of the Google Cloud Vision API. On the website it says that the first 1000 Request are for free every month. But for that I need a Billing account which is not for free if I understand correctly.  So basically you can't use the Cloud Vision API completely for free. Am I right or can you use the service without any costs?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"A Cloud Billing account is set up in Google Cloud and is used to define who pays for a given set of Google Cloud resources.This is needed in Google Vision API because if it passes the request limit these needs to be charged. The Billing account is needed because it tracks all of the costs (charges and usage credits) incurred by your Google Cloud usage."
            },
            {
                "Answer_creation_date":"2022-10-06T02:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The first 1000 credits can be used each month without charge, but a billing account is required."
            }
        ]
    },
    {
        "Question_title":"Vertex AI - Custom Job (with GPU) froze without errors",
        "Question_creation_date":"2022-10-05T10:54:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Custom-Job-with-GPU-froze-without-errors\/td-p\/474701\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":46,
        "Question_body":"Hi all,I ran into an issue yesterday when submitting a custom job in Vertex AI. The job successfully started (as evident by the logs reported) but at some point, just before the script starts using the GPU on the machine, we stopped receving any logs. I let the job run for 20 minutes, but it did not procide any more logs - as well as there was no indication of the machine having any issues.  I then stopped the job manually,  re-created the exact same job by running the same script (using the google-cloud-aiplatform package in Python) with the exact same parameters, and the job ran successfully.Is there any way I can figure out what went wrong in the first job? I am looking for a stable solution to manage custom jobs, but the fact that this happened within my first 5 runs seems very concerning to me, especially since there was no indication that the job was frozen as it could have ran until it hit the max time which would have costed a lot of money.Thanks!",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-05T10:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi all,\n\nI ran into an issue yesterday when submitting a custom job in Vertex AI. The job successfully started (as evident by the logs reported) but at some point, just before the script starts using the GPU on the machine, we stopped receving any logs. I let the job run for 20 minutes, but it did not procide any more logs - as well as there was no indication of the machine having any issues.\u00a0 I then stopped the job manually,\u00a0 re-created the exact same job by running the same script (using the google-cloud-aiplatform package in Python) with the exact same parameters, and the job ran successfully.\n\nIs there any way I can figure out what went wrong in the first job? I am looking for a stable solution to manage custom jobs, but the fact that this happened within my first 5 runs seems very concerning to me, especially since there was no indication that the job was frozen as it could have ran until it hit the max time which would have costed a lot of money.\n\nThanks!"
            }
        ]
    },
    {
        "Question_title":"C# handwritten text detection using google.cloud.Vision.v1 Api. why can't detect language?",
        "Question_creation_date":"2022-10-02T23:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/C-handwritten-text-detection-using-google-cloud-Vision-v1-Api\/td-p\/473437\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API",
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":74,
        "Question_body":"hello mam\/sir,I was used google.cloud.Visiion.v1 for handwritten text recognition for Indian languages .  this code is work but only for Marathi, Hindi languages. but other language like Malayalam, Tamil, Kaneda Telegu its not return a 100 percent result.For Example- i have a 12 months handwritten name(Malayalam, Kaneda etc.) but its recognize only 7 to 8 correct word detection .can you please help me to 100 percent  accurate word detection.please give me a solution .thanks and regards,Bhagyashri ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-03T13:10:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Bjagyashri, I think that you would find a better help on StackOverflow\u00a0since your issue seems to be on your code and people there is specialized on programming."
            },
            {
                "Answer_creation_date":"2022-10-03T23:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"okay\n\nthank you for advice."
            }
        ]
    },
    {
        "Question_title":"exporting a google autoML translate model",
        "Question_creation_date":"2022-09-27T12:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/exporting-a-google-autoML-translate-model\/td-p\/471646\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":81,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"1.- No.\n\n2.- You can create a Feature Request at\u00a0Issue Tracker\u00a0and\u00a0add a description about the feature you want(Export Translation Models), and the engineer team will look at it. You can see here how it is more likely that the team prioritize the work of the Feature Request\/Issues.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-09-29T08:57:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"At the moment AutoML Translation does not support ML model exporting. If you are using AutoML Tables, you may export your ML Model."
            },
            {
                "Answer_creation_date":"2022-09-30T02:17:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I see, thank you so much for your reply. If I'm not using AutoML tables, is there a way to convert my model to AutoML tables?\n\nAlso, is exporting AutoML Tranlsation models a feature you would consider adding some time in the near future?"
            },
            {
                "Answer_creation_date":"2022-09-30T15:57:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"1.- No.\n\n2.- You can create a Feature Request at\u00a0Issue Tracker\u00a0and\u00a0add a description about the feature you want(Export Translation Models), and the engineer team will look at it. You can see here how it is more likely that the team prioritize the work of the Feature Request\/Issues."
            }
        ]
    },
    {
        "Question_title":"Mount gcsfuse in gcloud ai custom-jobs local-run",
        "Question_creation_date":"2022-09-28T00:51:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Mount-gcsfuse-in-gcloud-ai-custom-jobs-local-run\/td-p\/471834\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":96,
        "Question_body":"When locally testing my custom-job through \"gcloud ai custom-jobs local-run\" command, I would like to have access to a bucket mounted though gcsFuse as it happens when I launch the same containerized job from GCloud console. Is there the option to have the same access locally?Thank you for helping",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-30T08:43:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"What you could do is use cloud storage as a file system within ai training, since while using fuse your training jobs on both of the platforms can access your data that is stored on Cloud Storage as files on your local file system, also the documentation I shared provides you useful information as the problems you might encounter, permissions, a brief description of cloud storage fuse, performance related information, the restrictions this method has and also how you can make use of the logs.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-09-30T08:43:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"What you could do is use cloud storage as a file system within ai training, since while using fuse your training jobs on both of the platforms can access your data that is stored on Cloud Storage as files on your local file system, also the documentation I shared provides you useful information as the problems you might encounter, permissions, a brief description of cloud storage fuse, performance related information, the restrictions this method has and also how you can make use of the logs."
            }
        ]
    },
    {
        "Question_title":"How does google cloud speech to text api deals with invalid inputs ?",
        "Question_creation_date":"2022-09-25T10:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-does-google-cloud-speech-to-text-api-deals-with-invalid\/td-p\/470810\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":59,
        "Question_body":"I am using google cloud stream(AsyncStreamingRecognize) for speech to text conversion in my applications. I have gone through the below link to understand the structure of response returned by the apis :StreamingRecognizeResponse  I can have various scenarios where I can end up with various invalid scenarios and I do not understand what could be the responses. I can invalid scenarios like :- User speaks in a different language than what is passed in configuration .- User does not speak anything \/ no input- Only noise gets passed \/ Data lossIs there any parameter inside my response which can point to above scenarios ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-27T14:56:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"1.- If a user speaks a different language you can use language recognition in audio requests. Speech-to-Text supports alternative language codes for all speech recognition methods. Also, one good practice is to show a phrase that can be used or advice on what language you select to be recognized by Speech-to-Text.\u00a0\n\n2.- There are multiple ways that Speech to text can return an empty response. The source of the problem could be the RecognitionConfig\u00a0or the audio itself.\n\n3.-To avoid that only the noise gets passed and the data is lost you can pre-process the audio just as the best practices doc\u00a0mentions.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-09-27T14:56:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"1.- If a user speaks a different language you can use language recognition in audio requests. Speech-to-Text supports alternative language codes for all speech recognition methods. Also, one good practice is to show a phrase that can be used or advice on what language you select to be recognized by Speech-to-Text.\u00a0\n\n2.- There are multiple ways that Speech to text can return an empty response. The source of the problem could be the RecognitionConfig\u00a0or the audio itself.\n\n3.-To avoid that only the noise gets passed and the data is lost you can pre-process the audio just as the best practices doc\u00a0mentions."
            }
        ]
    },
    {
        "Question_title":"Emotional mobiles",
        "Question_creation_date":"2022-09-26T23:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Emotional-mobiles\/td-p\/471342\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":18,
        "Question_body":"My idea is to create emotional mobiles. Were we cannot buy mobiles with only money,mobile must choose us for buy and unique emotional between specific person and his new mobile . An intimacy between mobile and human. Like a puppy or understanding couples mobile and human sinking using AI. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-26T23:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"My idea is to create emotional mobiles. Were we cannot buy mobiles with only money,mobile must choose us for buy and unique emotional between specific person and his new mobile . An intimacy between mobile and human. Like a puppy or understanding couples mobile and human sinking using AI."
            }
        ]
    },
    {
        "Question_title":"What's the route after conversion action's sunset",
        "Question_creation_date":"2022-09-22T09:16:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-s-the-route-after-conversion-action-s-sunset\/td-p\/469678\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":43,
        "Question_body":"Hello,i learn dialogflow with one of the goal to connect with Google Assistant. But i just found out the conversion actions will be sunset.\n\nCan anyone route me on the path to take for the next step of dialogflow integration?\n\nThanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-26T15:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"In the next Documentation I\u2019m sharing with you, you can read what are the next steps you might want to follow when conversation actions sunsets."
            }
        ]
    },
    {
        "Question_title":".",
        "Question_creation_date":"2022-09-22T14:16:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/unreadable-title\/td-p\/469789\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":63,
        "Question_body":".",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-26T09:10:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I found this stackoverflow question that already has an answer and I thought it might help you, since it\u2019s a similar use case, as the one you are presenting."
            }
        ]
    },
    {
        "Question_title":"Getting started DialogFlow CX",
        "Question_creation_date":"2022-09-24T12:41:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Getting-started-DialogFlow-CX\/td-p\/470603\/jump-to\/first-unread-message",
        "Question_topic":[
            "Contact Center AI",
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":51,
        "Question_body":"Looking into starting a project using DialogFlow CX. Seems rather promising but have one issue I cannot seem to find an answer for. The agent will be connected to via IVR (from Flex\/Callcenter). I need to gather some information on start so that I can identify the hotel\/property that will be referenced in the conversation.  I found session parameters but those are isolated to the session from start to finish but not passed to the start of a session. We are starting with about 60 properties and when the agent starts, it needs to \"know\" what property it is dealing with. Another quick question - will I need a separate telephony integration number to run multiple concurrent instances? I am really new to all this so my language may be off. Thanks in advance!!Robert ",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-24T13:28:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Howdy Robert,\n\nI think the answer to the puzzle will be to look in detail at how the integration from your IVR to DialogFlow will happen.\u00a0 From what I can tell, at the DialogFlow API level, there is a call called \"detectIntent\" ... this is where the audio\/text is passed in and the DialogFlow engine processes a part of the conversation.\u00a0 Looking at the API we find:\n\nhttps:\/\/cloud.google.com\/dialogflow\/cx\/docs\/reference\/rest\/v3\/projects.locations.agents.environments...\n\nwhich has a query parameters set of options.\u00a0 That all said, can you explain some more about how you see the overall flow happening?\u00a0 Will the hotel\/property be somehow passed in before the call or will the identification of the hotel be part of the start of the conversation?\u00a0 Depending on your overall goals, you might also consider contacting Google Cloud sales.\u00a0 They will always be delighted to hear from a prospective customer and be able to guide you on how to understand and get assistance with CCAI.\u00a0 \u00a0It is also possible that your IVR supplier may be able to offer assistance and have an existing relationship with Google Cloud for services and support."
            }
        ]
    },
    {
        "Question_title":"Vertex AI - Text entity extraction response format",
        "Question_creation_date":"2022-09-18T11:50:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Text-entity-extraction-response-format\/td-p\/467926\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Cloud Natural Language API",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":76,
        "Question_body":"Hello!I would like to ask if it's possible to get the same output format from the Vertex AI entity extraction REST API as from the Google Natural Language API?Because now in the response of Vertex AI we get only a list with the confidence scores, displayNames and the start\/end offsets of the textSegments, but the entities itself are not in the json (in the NLP response there is also \"content\" with the entity). So this is how I would like to get the response from the Vertex AI for each entity:{\n\"annotationSpecId\": \" \",\n\"displayName\": \"date\",\n\"textExtraction\": {\n\"score\": 0.69745916,\n\"textSegment\": {\n\"startOffset\": \"382\",\n\"endOffset\": \"392\",\n\"content\": \"12.07.2022\"\n}Can you help please how I could achive this?Thank you for your help in advance!Zsolt",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-23T12:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"So if my understanding is correct you want the result to be the same as GNL while using vertex. You could read more about how to properly prepare the text you will use on the documentation that I\u2019m providing you."
            },
            {
                "Answer_creation_date":"2022-09-24T09:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Dear Eduardo,\n\nthank you for your reply!\nNo, I didn't mean the input. I already have a dataset with labels and annotations and I already trained a model, but when I make an API call with a text, the field \"content\" is missing in the response. I only get a list of \"displayNames\", \"startoffsets\" and \"endoffsets\", but I also need the field \"content\", where I see the entity that belongs to those \"displayName\", \"startoffset\" and \"endoffset\" fields.\nIs it possible to get a json from the Vertex AI API that also has this \"content\" field?"
            }
        ]
    },
    {
        "Question_title":"Short polish inputs recognized but not returned by ASR.",
        "Question_creation_date":"2022-09-22T01:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Short-polish-inputs-recognized-but-not-returned-by-ASR\/td-p\/469439\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX",
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":36,
        "Question_body":"Hi,",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For some languages STT engine requires a longer time to decide the end of a single utterance, so you could use some Fast recognition."
            }
        ]
    },
    {
        "Question_title":"How to use ARIMA coefficients from BigQuery",
        "Question_creation_date":"2022-09-19T12:20:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-use-ARIMA-coefficients-from-BigQuery\/td-p\/468311\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":48,
        "Question_body":"I am trying to use Auto ARIMA from BigQuery and I just want to understand the results. That's what BigQuery is giving me:Store ACoeficients from Store AI trained the model using weekly incomeHow to fit this information in an equation?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-23T13:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"All I could find is this documentation that explains how to properly use the arima coefficient function on BigQuery."
            }
        ]
    },
    {
        "Question_title":"Custom container image not found by Vertex AI for model upload",
        "Question_creation_date":"2022-09-16T07:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Custom-container-image-not-found-by-Vertex-AI-for-model-upload\/td-p\/467487\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":40,
        "Question_body":"Hi,1. I have pushed a custom container to gcr.io\/<project id>\/reponame\/imagename:latest\nfrom gcloud cli on local WSL + podman.2. Then from google console\\ vertex ai\\ model registry, i tried to import the custom container as new model and new version. I'm able to browse to the container image and select the image URI.3. Then once I click finish, i get error container Image not found.\nSame is the error with gcloud  ai models upload command executed from the notebook.Please suggest, how to debug the issue and identify root cause.Thanks in advance.  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-23T11:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can read how to properly export a custom container into vertex AI on the documentation I\u2019m sharing with you.\n\nAlso to use a model with a custom container you should also provide a docker container image as the basis of that container."
            }
        ]
    },
    {
        "Question_title":"Billing & Cloud Vision API issue with \"Recognize Text\" on Android system",
        "Question_creation_date":"2022-09-21T23:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Billing-amp-Cloud-Vision-API-issue-with-quot-Recognize-Text-quot\/td-p\/469422\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":1,
        "Question_view_count":29,
        "Question_body":"Hi there,Here I got a billing problem with Cloud Vision API.First, I follow this link to setup my Firebase project to enable the feature of \"Recognize Text\".https:\/\/firebase.google.com\/docs\/ml\/android\/recognize-textThen all the functions used are normal. I call the function of \"annotateImage\" in Cloud Functions to invoke the Cloud Vision API, then can also used successful.Absolutely, I have trace the flow and requests on Cloud Vision API, it is just looks reasonable.But the issue I encountered is, \"it still charges when I'm not using it\", also when it has no any flow and requests! Billing, September 1-22, 2022 (the project has billing alerts set up now) :Cloud Vision API, 30 days to 9\/22\/2022 : It would be so gratefull if there any good suggestions !",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-21T23:22:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi there,\n\nHere I got a billing problem with Cloud Vision API.\n\nFirst, I follow this link to setup my Firebase project to enable the feature of \"Recognize Text\".\n\nhttps:\/\/firebase.google.com\/docs\/ml\/android\/recognize-text\n\nThen all the functions used are normal. I call the function of \"annotateImage\" in Cloud Functions to invoke the Cloud Vision API, then can also used successful.\n\nAbsolutely, I have trace the flow and requests on Cloud Vision API, it is just looks reasonable.But the issue I encountered is, \"it still charges when I'm not using it\", also when it has no any flow and requests!\u00a0\n\nBilling, September 1-22, 2022 (the project has billing alerts set up now) :\n\nCloud Vision API, 30 days to 9\/22\/2022 :\n\n\u00a0\n\nIt would be so gratefull if there any good suggestions !"
            }
        ]
    },
    {
        "Question_title":"vertex AI Workbench is hanging with error \"Opening notebook with JupyterLab\" for more than a day",
        "Question_creation_date":"2022-09-08T08:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/vertex-AI-Workbench-is-hanging-with-error-quot-Opening-notebook\/td-p\/464300\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":112,
        "Question_body":"I am trying to follow instructions in https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/jupyter-notebooks (vertex AI Jupyter Notebooks tutorials). Steps done1. For the first notebook \"Text Classification model\" I have clicked on \"Vertex AI Workbench\". It takes me to GCP console & workbench.2. I am supposed to click on the \"Create\" button, which I did.3. THen the message \"Opening notebook with JupyterLab\" will come. But it is there for past 1 day, and still it hasn't finished creating. So I canceled the same. I tried once more the same thing happens. Not sure why?I have screen shots, but can't see anywhere to attach.Have anyone tried this tutorial, especially in workbench? Thanks,",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-08T22:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\u00a0\n\nAnybody active on these forums?\n\nIdeally some GCP reps should be there. Especially with newer offering like vertexAI - fundamental issues should be easy to solve!!"
            },
            {
                "Answer_creation_date":"2022-09-09T00:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Today I have retried the same. It worked at least creation of notebook.\n\nBut when executing step\n\nInstall additional packages\n\nInstall the following packages for executing this notebook.\n\nI am getting error:\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-recommendations-ai 0.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.8.1 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 9.0.0 which is incompatible.\n\n\u00a0\n\nAny help?"
            },
            {
                "Answer_creation_date":"2022-09-20T14:32:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"After searching for a solution for your case, it seems to be more an issue of the package version.\n\nI found a GitHub repository dealing with a similar problem to yours; there, you will likely find solutions to resolve it."
            }
        ]
    },
    {
        "Question_title":"How to disable TLS 1.0 and 1.1 in dialogflow?",
        "Question_creation_date":"2022-09-16T08:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-disable-TLS-1-0-and-1-1-in-dialogflow\/td-p\/467528\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":32,
        "Question_body":"Need to disable TLS 1.0 and 1.1 for oauth api and events api in the dialogflow. We get those apis while integrating with slack.",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-16T08:32:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Need to disable TLS 1.0 and 1.1 for oauth api and events api in the dialogflow. We get those apis while integrating with slack."
            }
        ]
    },
    {
        "Question_title":"Google translator is free or has any kind of pricing?",
        "Question_creation_date":"2022-09-05T23:52:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-translator-is-free-or-has-any-kind-of-pricing\/td-p\/463225\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":64,
        "Question_body":"I'm using this code for translating my website in my angular project. I'm not using translate API provided by google cloud. So, I just need to confirm that the source I'm using is paid for publicly available (free)?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-15T11:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"TRANSLATION is a basic free Google service for users to translate their website content on the web browser side. There are some disadvantages using this such as the Search Engine Optimization and there are limits while using it."
            }
        ]
    },
    {
        "Question_title":"Translate service error - Unsupported language pair",
        "Question_creation_date":"2022-08-25T04:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Translate-service-error-Unsupported-language-pair\/td-p\/459774\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":13,
        "Question_upvote_count":3,
        "Question_view_count":526,
        "Question_body":"Our application started to have some strange error from 25th of August which was working properly until today. Some very basic translation requests get the \"Status(StatusCode=\"InvalidArgument\", Detail=\"Unsupported language pair.\" error. For example the words \"loan\", \"excellent\", \"wonderful\" get the errors from service. I checked the release notes of the service but found nothing. Could you please help about the issue?",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-25T05:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We get the same error for order numbers ABC123 for example will return \"Unsupported language pair.\" But\u00a0ABC1234 works, ABC12 works, ABC123 return error, ABC1233 return error."
            },
            {
                "Answer_creation_date":"2022-08-25T23:49:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Our company also has the same problem unfortunately, one of our internal tools basically cannot be used at all since yesterday."
            },
            {
                "Answer_creation_date":"2022-08-26T00:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We have a similar problem\n\ncode = InvalidArgument desc = Unsupported language pair."
            },
            {
                "Answer_creation_date":"2022-08-26T06:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We are having similar problems with specific language pairs."
            },
            {
                "Answer_creation_date":"2022-08-26T09:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We're having this issue since August, 24 at 01:07 AM.\n\nGoogle.GoogleApiException: Google.Apis.Requests.RequestError\nBad language pair: {0} [400]\nErrors [\n    Message[Bad language pair: {0}] Location[ - ] Reason[badRequest] Domain[global]\n]\nat Google.Apis.Requests.ClientServiceRequest`1.ParseResponse(HttpResponseMessage response)\nat Google.Apis.Requests.ClientServiceRequest`1.ExecuteAsync(CancellationToken cancellationToken)\nat Google.Cloud.Translation.V2.TranslationClientImpl.TranslateHtmlAsync(IEnumerable`1 htmlItems, String targetLanguage, String sourceLanguage, Nullable`1 model, CancellationToken cancellationToken)"
            },
            {
                "Answer_creation_date":"2022-08-29T12:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Has this been corrected?"
            },
            {
                "Answer_creation_date":"2022-08-29T22:04:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I believe so, I tested yesterday and had no issues."
            },
            {
                "Answer_creation_date":"2022-09-01T03:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The same error!\n\nExample of translated text: \"\u041c\u0430\u0441\u043b\u043e MITASU 5W30 PLATINUM PAO SN Dexos2 1L\"\n\nTranslation to Romanian from autodetect using NeuralMachineTranslation.\n\nif the word \"PAO\" is removed, it translate ok."
            },
            {
                "Answer_creation_date":"2022-09-07T06:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It has been fixed. Thanks"
            },
            {
                "Answer_creation_date":"2022-09-07T21:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Issue still exist for English to Romanian translation. appreciate any thoughts."
            },
            {
                "Answer_creation_date":"2022-09-09T01:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Unfortunately we started to get same exception (Unsupported language pair.)\u00a0 with the following inputs while translating to English (en-US) Is there any new deployment to the service? Could you please check?\n\nSome Sample Problematic Inputs :\u00a0\"Ok\" , \"1000\", \"wonderful\""
            },
            {
                "Answer_creation_date":"2022-09-09T12:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Unclear if it's related, but a well known Trados plug-in for Google AutoML machine translation engine is also failing with the same error and this is also new.\u00a0 See\u00a0https:\/\/community.rws.com\/product-groups\/trados-portfolio\/rws-appstore\/f\/rws-appstore\/43110\/mt-enhan....\u00a0 \u00a0This is with V3 Advanced API, but looks like what is reported her is happening with V2 Basic API."
            },
            {
                "Answer_creation_date":"2022-09-13T13:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We found a solution for this issue.\n\nFor OpenSay, when we used Cloud Translation's REST API's analyzeText method with an English content and a target language type 'en-US' it failed with \"Unsupported language pair.\".\u00a0\n\nIt took some tinkering, but eventually we changed the 'en-US' to 'en' and it worked."
            }
        ]
    },
    {
        "Question_title":"How does it work underhood: Predictions of multiple instances (Batch) to Vertex AI online serving",
        "Question_creation_date":"2022-08-31T21:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-does-it-work-underhood-Predictions-of-multiple-instances\/td-p\/462022\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":59,
        "Question_body":"Hello,Vertex AI online serving:When multiple instances are passed for prediction to an endpoint, Does prepackaged container serve the inferences in the same manner as TFX Serving does with enable_batching.  If so how do we optimize batching parameters with multiple instances sent to Vertex AI online.If multi_instances prediction is different from TFX serving batching, how do we gain GPU resources efficient usage optimization with prepackaged serving container.On a general note, how to handle efficient GPU usage for both prepackaged container and custom container using a custom trained model.Please guide.Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-12T11:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Depending on how you perform the custom training you\u2019ll need to set the WorkerPoolSpec. See this document\u00a0to see what how to create a custom job and what it includes."
            }
        ]
    },
    {
        "Question_title":"Vertex AI Notebook deleting cells",
        "Question_creation_date":"2022-08-30T08:54:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Notebook-deleting-cells\/td-p\/461480\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":41,
        "Question_body":"Hello everyone, I have been facing an issue for the past few months where on occasion my vertex AI notebooks will completely wipe and delete all the cells in a .ipynb file. This happens at what appears to be random times. Context to reproduce: N96 High Memory instance 624 gb of ramIdle time: 1440single user only notebook What happens: notebook with shutdown in the midst of running. Once the notebook is back up and running all the cells in the ipynb file are gone. There is no error message If anyone has faced this issue in the past and knows how to resolve I would really appreciate and information! Thank you ",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-09T14:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This seems that it\u2019s an issue that you are facing only applies to your use case, so what I would recommend to you is that you raise a support ticket to receive better support."
            }
        ]
    },
    {
        "Question_title":"Output filename for Translate Document API",
        "Question_creation_date":"2022-08-26T08:07:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Output-filename-for-Translate-Document-API\/td-p\/460318\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":43,
        "Question_body":"Hello,I have been developing an iOS mobile app to translate PDF documents and currently using Google Translate documents API without any issue.Is there any way, we can update or change the output filename coming from the API? Currently, the output file name includes all the attributes starting from the project name, bucket name and finally the file name. This won't be appropriate for the users to showcase these things.Is there any configuration to change this filename to more user friendly format?e.g. Input file name - Test_Translation_En_Fr_Sp.pdfOutput filename from Translate API -scantranslatorapp.appspot.com_uploaded_documents_FuOrb0L4tudAZvhZ99IwsFYg83M2_Test_Translation_En_Fr_Sp_fr_translations.pdfIt would be appropriate to showcase only - Test_Translation_En_Fr_Sp_fr_translations.pdf",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-09T08:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can change the output file prefix for this you need to do a REST request to the as a POST to the API URL:\n\n\n\nhttps:\/\/translation.googleapis.com\/v3\/projects\/PROJECT_NUMBER_OR_ID\/locations\/LOCATION:translateDocument\n\nWith the following request JSON body:\n\n\n\n{\n  \"source_language_code\": \"SOURCE_LANGUAGE\",\n  \"target_language_code\": \"TARGET_LANGUAGE\",\n  \"document_input_config\": {\n    \"mimeType\": \"MIME_TYPE\",\n    \"content\": \"INPUT_BYTE_STREAM\"\n  },\n  \"document_output_config\": {\n    \"gcsDestination\": {\n      \"outputUriPrefix\": \"gs:\/\/OUTPUT_FILE_PREFIX\"\n    }\n  }\n}"
            }
        ]
    },
    {
        "Question_title":"Vertex pipeline model training component stuck running forever because of metadata issue",
        "Question_creation_date":"2022-09-09T02:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-pipeline-model-training-component-stuck-running-forever\/td-p\/464631\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":71,
        "Question_body":"'m attempting to run a Vertex pipeline (custom model training) which I was able to run successfully in a different project. As far as I'm aware, all the pieces of infrastructure (service accounts, buckets, etc.) are identical.The error appears in a gray box in the pipeline UI when I click on the model training component and reads the following:I've looked into the log explorer and found that the error logs are audit logs have the following associated tags with them:protoPayload.methodName=\"google.cloud.aiplatform.internal.MetadataService.RefreshLineageSubgraph\"protoPayload.resourceName=\"projects\/724306335858\/locations\/europe-west4\/metadataStores\/defaultLeading me to think that there's an issue with the Vertex Metadatastore or the way my pipeline is using it. The audit logs are automatic though, so I'm not sure.I've tried purging the metadata store as well as deleting it completely. I've also tried running a different model training pipeline that worked before in a different project as well but with no luck.",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-09T02:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"'m attempting to run a Vertex pipeline (custom model training) which I was able to run successfully in a different project. As far as I'm aware, all the pieces of infrastructure (service accounts, buckets, etc.) are identical.\n\nThe error appears in a gray box in the pipeline UI when I click on the model training component and reads the following:\n\nRetryable error reported. System is retrying.\ncom.google.cloud.ai.platform.common.errors.AiPlatformException: code=ABORTED, message=Specified Execution `etag`: `1662555654045` does not match server `etag`: `1662555533339`, cause=null System is retrying.\n\nI've looked into the log explorer and found that the error logs are audit logs have the following associated tags with them:\n\nprotoPayload.methodName=\"google.cloud.aiplatform.internal.MetadataService.RefreshLineageSubgraph\"\n\nprotoPayload.resourceName=\"projects\/724306335858\/locations\/europe-west4\/metadataStores\/default\n\nLeading me to think that there's an issue with the Vertex Metadatastore or the way my pipeline is using it. The audit logs are automatic though, so I'm not sure.\n\nI've tried purging the metadata store as well as deleting it completely. I've also tried running a different model training pipeline that worked before in a different project as well but with no luck."
            }
        ]
    },
    {
        "Question_title":"Time to deploy model",
        "Question_creation_date":"2022-09-06T07:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Time-to-deploy-model\/td-p\/463368\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":35,
        "Question_body":"I asked to deploy my AutoML model over an hour ago but it is processing the request....  How long should this take?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-06T08:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Answering my own question: \u00a0it took almost 2 hours to deploy a very simple model."
            },
            {
                "Answer_creation_date":"2022-09-08T23:36:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes. I also have seen such behaviour. Not sure whether this is because in most of the cloud services there is a concept of most used services will work fast. They are already in memory and works - probably currently the vertexAPI usage is low now, so the delay."
            }
        ]
    },
    {
        "Question_title":"Batch prediction on custom model",
        "Question_creation_date":"2022-07-13T11:39:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Batch-prediction-on-custom-model\/td-p\/442147\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":439,
        "Question_body":"Hi,I used custom containers for training and prediction to create a model on Vertex AI. Now I want to run batch prediction against it but get error message that says \"Unable to start batch prediction job due to the following error: A model using a third-party image must specify PredictRoute and HealthRoute in ContainerSpec.\"I checked documentation, AIP_HEALTH_ROUTE = \/v1\/endpoints\/ENDPOINT\/deployedModels\/DEPLOYED_MODELDoes this mean that the model has to be deployed to an endpoint in order to generate the value of the AIP_ENDPOINT_ID variable?However, the documentation \u201cGet batch predictions\u201d says \u201cRequesting a batch prediction is an asynchronous request (as opposed to online prediction, which is a synchronous request). You request batch predictions directly from the model resource; you don't need to deploy the model to an endpoint.I am confused whether in my situation, the model has to be deployed first. Also, is there any resources regarding hosting custom models for batch predictions?",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-18T11:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If you are using a custom container, you can read this information about how to use a custom container for prediction.\n\nAbout your confusion, if you are using an API to create batch prediction, you need to send the request to a\u00a0 service endpoint.\n\n\u00a0\u201cTo create batch predictions, we recommend that you select input and output locations that are in the same region as your model. If you use the API to create batch predictions, send requests to a service endpoint (such as https:\/\/us-central1-aiplatform.googleapis.com) that is in the same region or geographically close to your input and output locations.\u201d"
            },
            {
                "Answer_creation_date":"2022-07-19T10:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the reply. The\u00a0custom\u00a0container link you shared is about using a custom container for (online) prediction. Now my confusion is that, if I only want the model to be trained to serve batch predictions rather than online predictions, do I still need a custom prediction container. Would a deployed model with only training container suffice?"
            },
            {
                "Answer_creation_date":"2022-08-03T12:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can upload your models in two ways:\n\n1. With a pre-build container (supported TensorFlow, XGBoost, scikit-learn)\n2. With a custom container\n\nBoth options support batch predictions. With batch predictions, you don't need to deploy your model to an endpoint. Uploading it to Vertex AI is enough.\u00a0\n\nA custom container is only needed if you use another ML framework that is not supported with the pre-build containers. Or you need additional logic as part of your prediction like pre or post processing for example."
            },
            {
                "Answer_creation_date":"2022-09-08T05:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I don't know if u have solved your probem but hopefully this helps. I can see how this is confusing, it was the same for me. So batch prediction under the hood is similar to vertex ai endpoint prediction. When you start a batch job a\u00a0a model endpoint to serve model predictions, and a Dataflow job to fetch the data is created, This is then split it into batches, get predictions from the endpoint, and return the results to GCS or BigQuery. All of this is done in a Google-managed project, so you won\u2019t see the model endpoint or the Dataflow job in your own project. So in the custom container you will need to have your model server code that runs your model. You can build your own model server using flask or Fastapi. Or you can also use custom prediction routines which does all that for you and u can focus only on the model logic. So to answer your question for the predict route and health route u need to mention '\/predict' and '\/health' or whatever name you are giving your routes. I am also working on this currently. So if I am wrong about anything I have told above pls correct me."
            }
        ]
    },
    {
        "Question_title":"Using Service Account Keys on different machines",
        "Question_creation_date":"2022-08-25T00:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Using-Service-Account-Keys-on-different-machines\/td-p\/459716\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":44,
        "Question_body":"It is a little unclear to me on how to use the AutoML translation model I created on different machines. I generated a service account key and reference it when calling the API and it works fine on my machine. However, when another user uses the same service account key on their machine, occasionally the following error occurs. The odd part is it doesn't happen all the time.Status(StatusCode=Unavailable, Detail=\"Permission Denied: automl.models.predict\"I had two questions:\n1. When using the service account key on another machine, is there anything else I need to do to authenticate the user?\n2. I know Google advises against sharing keys, however I am using a third-party translation software that requires you set a JSON file key to use the API. Any advice on other methods for allowing other users to use the AutoML translation model would be appreciated.",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-01T12:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I will try to answer both questions.\n\nNo, you don\u2019t need anything more to do to authenticate the user, just provide the correct service account and the key to the user.\nNo, the only way to do this is by using the JSON that IAM provides, but also note that sharing the service account key is like sharing a password."
            },
            {
                "Answer_creation_date":"2022-09-06T18:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"@Eduardo_Ortiz\u00a0\nThanks for answering my question. I was able to solve my permission problem by generating separate JSON for each machine. From my observations, it appears if you try to use the same JSON key on different machines permission issues occur randomly although this is not documented anywhere."
            }
        ]
    },
    {
        "Question_title":"Need help for compute engine pricing",
        "Question_creation_date":"2022-09-06T05:11:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Need-help-for-compute-engine-pricing\/td-p\/463295\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":36,
        "Question_body":"GPU: nvidia-a100-80gb has no pricing but  nvidia-tesla-a100 has",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-06T05:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"GPU:\u00a0nvidia-a100-80gb has no pricing but\u00a0\u00a0nvidia-tesla-a100 has"
            }
        ]
    },
    {
        "Question_title":"hi-Latn Language Detect Error",
        "Question_creation_date":"2022-09-05T01:51:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/hi-Latn-Language-Detect-Error\/td-p\/463002\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Cloud Natural Language API",
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":75,
        "Question_body":"I keep getting this language as detected language code but i can't seem to find this code in official docs of google translate api Please Help",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-05T01:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I keep getting this language as detected language code but i can't seem to find this code in official docs of google translate api\n\n\u00a0\n\nPlease Help"
            }
        ]
    },
    {
        "Question_title":"What difference environments\/domains does vertex ai is being in use ?",
        "Question_creation_date":"2022-09-02T02:03:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-difference-environments-domains-does-vertex-ai-is-being-in\/td-p\/462390\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Vertex AI Model Registry",
            "Video Intelligence API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":31,
        "Question_body":"I wanna learn more about how to use vertex ai in more domains than in recognition and things , so i can learn how to use Vertex ai in other fields and domain , I want to learn like projects using live vertex ai auto ml or realated to those .",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-02T02:03:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I wanna learn more about how to use vertex ai in more domains than in recognition and things , so i can learn how to use Vertex ai in other fields and domain ,\u00a0\n\nI want to learn like projects using live vertex ai auto ml or realated to those ."
            }
        ]
    },
    {
        "Question_title":"Google Cloud Translate API & Referer Restriction Issue",
        "Question_creation_date":"2021-12-31T17:43:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-Translate-API-amp-Referer-Restriction-Issue\/td-p\/181705\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":730,
        "Question_body":"Hello Dear Community !I have a frustrating issue with the Google Cloud Translate API.I set up correctly the restriction of the API key to some domains including *.example.com\/* I launch the script on the URL https:\/\/www.example.com\/translate and i have the following message :     When i remove the restriction, everything works, but i need the restriction to avoid misuse\/abuse.\nI tried to change the restriction to *.example.com, www.example.com, example.com\/*, even with the dedicated URL, but nothing works, always the same error message.Do you have any ideas or any ways to investigate better this issue ? How i can know the referrer Google get when i launch my request ? It's driving me crazy !Thanks a lot and happy new year to everybody !!!",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-03T13:10:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The API key being used seems to have some type of HTTP restriction [1], and needs to be properly referred.\n\nYou should recreate a new API key, without an IP referrer, as it doesn't seem related to either roles\/permissions.\n\nYou could also try adding the full URL, including \"https\" as mentioned in the examples [2].\n\nHere are some Stack Overflow examples [3][4].\n\n[1] https:\/\/cloud.google.com\/docs\/authentication\/api-keys#adding_http_restrictions\n[2] https:\/\/cloud.google.com\/docs\/authentication\/api-keys#:~:text=Allow%20any%20subdomain,least%20two%20....\n[3] https:\/\/stackoverflow.com\/questions\/70013973\/error-when-using-iap-external-identities-sign-in-page\n[4] https:\/\/stackoverflow.com\/questions\/69803590\/error-api-key-http-referrer-blocked-ocurred-at-using-yo..."
            },
            {
                "Answer_creation_date":"2022-01-12T10:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for your reply, i created a new API Key with no restriction => It worked\nThen i added a basic restriction : *.domain.com\/* and it stopped to work with the same error message as before.\u00a0\nI tried to add the exact full URL with https included, and same error also.\n\nI don't know what to do. In the meantime, we implemented another translate solution from your main competitor and it worked in 5 minutes...\n\nSo it's a bit depressing, especially when we speak about billions of caracters to translate each month with money for you (Google) at the end.\u00a0\n\nThe last time we had an issue with Google API it was for the Maps API, hopefully there was a a chat support included and it was an issue from Google' side regarding country restriction linked to our account.\u00a0 It was solved in few minutes by your technical staff...\n\nBut for the translation API we feel a bit lonely to fix that..."
            },
            {
                "Answer_creation_date":"2022-01-08T02:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Same issue still no fix to this.\n\n\u00a0\n\nMyCCPay"
            },
            {
                "Answer_creation_date":"2022-09-01T06:05:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I have a key google translate message like this but don't know how to handle it, please help.\n\n\n{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Requests from referer \\u003cempty\\u003e are blocked.\",\n    \"errors\": [\n      {\n        \"message\": \"Requests from referer \\u003cempty\\u003e are blocked.\",\n        \"domain\": \"global\",\n        \"reason\": \"forbidden\"\n      }\n    ],\n    \"status\": \"PERMISSION_DENIED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com\/google.rpc.ErrorInfo\",\n        \"reason\": \"API_KEY_HTTP_REFERRER_BLOCKED\",\n        \"domain\": \"googleapis.com\",\n        \"metadata\": {\n          \"service\": \"translate.googleapis.com\",\n          \"consumer\": \"projects\/281599394813\"\n        }\n      }\n    ]\n  }\n}"
            }
        ]
    },
    {
        "Question_title":"Unable to use audio to text transcribe",
        "Question_creation_date":"2022-03-20T00:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unable-to-use-audio-to-text-transcribe\/td-p\/405132\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":97,
        "Question_body":"I am new to this Google Audio transcription and I have set up the whole Google Free Trial thing and I have tried to use the function of Google's Audio to Speech transcript and well so far my customer experience has been so hard.  I have two files and *.mpa and a *.mp4 file and no matter what i do i keep getting an error that it cannot transcribe.Can someone  please help me with this.  Here are the errors I am getting.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-31T23:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can try another variant of\u00a0audio transcription -Audext.\u00a0I like that the software supports various audio file formats like Mp3, WAV, and M4A and it allows editing of the transcript."
            }
        ]
    },
    {
        "Question_title":"Deep Learning VM Config to connect to Google Colab",
        "Question_creation_date":"2022-05-19T10:06:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Deep-Learning-VM-Config-to-connect-to-Google-Colab\/td-p\/424603\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":1,
        "Question_view_count":298,
        "Question_body":"Morning to allIm trying to connect a google colab file to a Google Deep Learning VM with any results. My guess is that I need to configure something inside the VM or the google console but not sure how to do so.I get the error that you will find in image 1 that says:\"The VM requested does not exist. Check out our guide to set up GCE VMs in Colab\"and has a the next link in which theres not much info on how to solve the situation:  https:\/\/research.google.com\/colaboratory\/marketplace.htmlOn image 2 and 3 you will find the info that I add to the colab file that is the same as the VM configuration that you will fins on image 3.What I\u00b4m doing wrong? Do I need to asing special permits to the VM? Any comments or advice is more than appreciatedImage 1Image 2\nImage 3",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-20T17:55:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Did you confirm that the VM does exist in the project you typed down? If so, is its name correctly spelled and is the VM turned on?"
            },
            {
                "Answer_creation_date":"2022-06-02T02:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I solve the issus by changing VM configuration(decrease or increase ram for exemple)"
            },
            {
                "Answer_creation_date":"2022-08-30T16:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi All,\n\nI too am experiencing the same issue as the original poster\u00a0@holguinmora\u00a0\n\nWould be very helpful to know the steps\/configuration to overcome this issue\u00a0@bentalla"
            }
        ]
    },
    {
        "Question_title":"Commercial usage of Google Cloud TTS",
        "Question_creation_date":"2022-08-21T18:48:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Commercial-usage-of-Google-Cloud-TTS\/td-p\/458420\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":2,
        "Question_view_count":117,
        "Question_body":"Hi,I wish to use Google cloud's Wavenet TTS (TextToSpeech) for commercial use for my company. Can anyone please confirm whether it is allowed or not?RegardsUtkarsh Dubey",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-21T22:59:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am sure its not allowed, you can use it only if you choose to use for informative or project purpose, if you wanna use it for commercial purpose get it by being in touch with google cloud partner coordinator here.\u00a0\u00a0Enroll and proceed with further steps.\n\n- Nihal"
            },
            {
                "Answer_creation_date":"2022-08-22T00:04:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What is covered under informative\/project use?\nBy commercial use, i meant we will be using it to develop voice-over for our videos. The videos will be used in marketing. Need confirmation on wether it allowed or not."
            },
            {
                "Answer_creation_date":"2022-08-30T10:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I actually have this exact same question. Someone from chat support was meant to get back to me but I never heard back"
            }
        ]
    },
    {
        "Question_title":"Translation of MySQL data in 6 different language",
        "Question_creation_date":"2022-08-17T02:00:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Translation-of-MySQL-data-in-6-different-language\/td-p\/454758\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":77,
        "Question_body":"I have 20K record in 1 Table of MySQL DBThis table is having a Description column and 6 different columns as TLang1, TLang2, Tlang3....I have to translate the data in Description column in 6 Different Languages and insert them in TLang1, TLang2, Tlang3.... columns in the same row.What approach I can use to do this since the current approach is taking too long.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-24T09:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What is your current approach?"
            },
            {
                "Answer_creation_date":"2022-08-26T02:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am taking 1 row at a time and calling the translate API 6 times to get 6 different text translations and then updating the row."
            },
            {
                "Answer_creation_date":"2022-08-29T09:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You could do a Program that uses a Loop to translate each record and keep it in a Dataframe and then update the fields or replace the Table. There could be a case that you'll need to do this by parts by the Limits that Translation API have."
            }
        ]
    },
    {
        "Question_title":"Vertex AI create endpoint error - FAILED_PRECONDITION: Project xxxxxxxx is not active.",
        "Question_creation_date":"2022-08-27T00:45:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-create-endpoint-error-FAILED-PRECONDITION-Project\/td-p\/460565\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":144,
        "Question_body":"Hi, I'm stuck at following error message when I try to create vertex-ai endpoint from workbench notebook.  I have enabled aiplatform.googleapis.com.Command:\ngcloud ai endpoints create \\\n--project=XXXXX\n--region=us-central1 \\\n--display-name=ld-test-resnet-classifierUsing endpoint [https:\/\/us-central1-aiplatform.googleapis.com\/]\nERROR: (gcloud.ai.endpoints.create) FAILED_PRECONDITION: Project XXXXXXXXXX is not active.Please suggest what am I missing.   ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-27T04:38:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\nThe issue is resolved.\nAt least one model has to be uploaded first to model registry for this command to work.\nThe official documentation titled \"Deploy a model using the Vertex AI API\" - implies deploy a model uploaded to model registry\".\n\nThanks for the views.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-08-27T04:38:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\nThe issue is resolved.\nAt least one model has to be uploaded first to model registry for this command to work.\nThe official documentation titled \"Deploy a model using the Vertex AI API\" - implies deploy a model uploaded to model registry\".\n\nThanks for the views."
            }
        ]
    },
    {
        "Question_title":"Cloud translations with glossary drops words after glossary item.",
        "Question_creation_date":"2022-08-12T05:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-translations-with-glossary-drops-words-after-glossary-item\/td-p\/453337\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":139,
        "Question_body":"We use the cloud translation API, supplemented with a glossary, to translate English to Dutch. On some occasions the glossary translation drops part of the translation if it is a two part ducht construct, where part 2 follows immediately after the glossary item.For example \"add\" in English becomes \"voeg toe\" in Dutch.  In a sentence with a glossary item for \"tomato passata -> \"tomaten passata\" this becomes:English: Then add the tomato passata and simmer for 10 minutes.Dutch with glossary: Voeg vervolgens de tomaten passata en laat 10 minuten sudderen.Dutch without glossary: Voeg vervolgens de tomatenpassata toe en laat 10 minuten sudderen.In this case the \"toe\" is required but somehow missing in the glossary translation. Any idea what goes wrong here?",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-22T14:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There are sometimes that the translations can be inaccurate. For this you can become a contributor\u00a0and help translate to be improved.\n\nNote: While using the translation from dutch to English the phrase given from Dutch with no glossary returns the English value and the Dutch with glossary returns also the same English value, so this could be an interpretation mismatch while using glossaries."
            },
            {
                "Answer_creation_date":"2022-08-24T23:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\u00a0\n\nThanks\u00a0@josegutierrez\u00a0 for the response.\n\nIn this particular case the issue is not so much with the (quality) of the translation itself but with the usage of the glossary and then specifically the non-glossary text around the glossary item.\u00a0\n\nI have looked at contributing but I don't think that will help with the specific issue we are experiencing.\u00a0 As a paying customer of the translate API we would appreciate if someone is able to provide some input on the specific issue of words being dropped in the translated glossary sentences ,while they are okay when translating the same sentence without the glossary. At this moment this is really hurting the value we are getting from the google translate api."
            },
            {
                "Answer_creation_date":"2022-08-25T11:43:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As I mentioned before Translation can sometimes be inaccurate, and this could be an interpretation mismatch while using glossaries. Please file a support case, so we can do a detailed review and help you with this issue."
            }
        ]
    },
    {
        "Question_title":"Bigquery ML billiing support",
        "Question_creation_date":"2022-08-19T01:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Bigquery-ML-billiing-support\/td-p\/455616\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":44,
        "Question_body":"I have been working on Demand Forecasting in Bigquery ML and i have been creating model with different datasets but recently for a particular dataset price spiked up for the CREATE MODEL query while working on the dataset can anyone help me regarding training model it is because of dataset or any other matter associated with it",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Please contact Cloud Billing regarding this issue."
            }
        ]
    },
    {
        "Question_title":"computational instances at the tool Vertex AI",
        "Question_creation_date":"2022-08-18T04:02:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/computational-instances-at-the-tool-Vertex-AI\/td-p\/455213\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":37,
        "Question_body":"Hello,\nI have a question about the computational instances at the tool Vertex AI in the field of image classification. What are the underlying instances of the process or where can I find out? I'm looking for Information comparable to these syntax for example: Virtual Machine (CPU: Intel Xeon E5-2690 v3, 6 vCPUs, GPU: NVIDIA Tesla K80, 56 GB RAM, 380 GB SSD)\nThanks\nArndt",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You could look at this comparison table\u00a0of machine types, I think the machine types you are looking for are the N1+GPU and the A2 since these two are the VMs that supports GPU and that can be used for Vertex.\n\nAdditionally check the GPUs document\u00a0to see the details of every GPU."
            }
        ]
    },
    {
        "Question_title":"WARN BlockManager: Block rdd_6_0 already exists on this machine; not re-adding it",
        "Question_creation_date":"2022-08-04T06:45:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/WARN-BlockManager-Block-rdd-6-0-already-exists-on-this-machine\/td-p\/450462\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":57,
        "Question_body":"Hi there.\nI am working with Vertex AI Jupyterlab Notebook.\nThere were a few such warningson this as the model was getting trained.\nMay I know if we are safe to ignore this?\nWhat do they mean actually?\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-23T10:20:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"No, you should not worry since this is just a warning that tells you that those two blocks will not be re added to your notebook.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-08-23T10:20:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"No, you should not worry since this is just a warning that tells you that those two blocks will not be re added to your notebook."
            },
            {
                "Answer_creation_date":"2022-08-23T11:51:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for confirming."
            }
        ]
    },
    {
        "Question_title":"PyTorch is using the GPU on a container on my local machine, but is unable to use the GPU on Vertex",
        "Question_creation_date":"2022-08-23T07:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/PyTorch-is-using-the-GPU-on-a-container-on-my-local-machine-but\/td-p\/458980\/jump-to\/first-unread-message",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":25,
        "Question_body":"Expected Behavior\nI want to use a GPU on a component of Vertex AI.Actual Behavior\nUnfortunately, `torch.cuda.is_available()` is returning `False`. Also, `nvidia-smi` is not working if ran in the container of Vertex AI.\nNote: both commands also don't work locally in the container if I'm not specifying the `--gpus all` flag in the command `docker run --rm -it --gpus all ee97db5bbd98 \/bin\/bash`. However, I can't find any option to add the `--gpus all` flag for Vertex AI. Would this be required?Steps to Reproduce the ProblemMy YAML file: My pipeline:Visualized in the browser:",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-23T07:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Expected Behavior\nI want to use a GPU on a component of Vertex AI.\n\nActual Behavior\nUnfortunately, `torch.cuda.is_available()` is returning `False`. Also, `nvidia-smi` is not working if ran in the container of Vertex AI.\nNote: both commands also don't work locally in the container if I'm not specifying the `--gpus all` flag in the command `docker run --rm -it --gpus all ee97db5bbd98 \/bin\/bash`. However, I can't find any option to add the `--gpus all` flag for Vertex AI. Would this be required?\n\nSteps to Reproduce the Problem\n\nMy YAML file:\n\nname: Processing\ndescription: Process all the found HTML\n\ninputs:\n- name: friendly_name\ntype: String\ndescription: The name of the company\n- name: language\ntype: String\ndescription: The language to process\n- name: models\ntype: String\ndescription: The models that will be used (all, genre, or standard)\nimplementation:\ncontainer:\nimage: eu.gcr.io\/uman-interns\/backend:v1.7\ncommand:\n[\npython,\nbackend\/pages\/III_Process_website_data\/process_website_data.py,\n--friendly_name,\n{ inputValue: friendly_name },\n--language,\n{ inputValue: language },\n--models,\n{ inputValue: models }\n]\n\n\u00a0\n\nMy pipeline:\n\nrom kfp.v2 import compiler, dsl\nimport kfp.components as comp\n\nfrom config import GCS_ARTIFACT_BUCKET, VARS\n\nprocessing = comp.load_component_from_file(\"scraping\/components\/processing.yaml\")\nembeddings = comp.load_component_from_file(\"scraping\/components\/embeddings.yaml\")\n\n\ndef compile_pipeline(file_name: str, tag: str):\n@dsl.pipeline(\nname=\"scraping\",\ndescription=\"Scrape a site and extract meaningful topics\",\npipeline_root=f\"gs:\/\/{GCS_ARTIFACT_BUCKET}\/scraping\/{tag}\",\n)\ndef pipeline(\nfriendly_name: str, url: str, language: str, google: bool, models: str) :\nPROJECT_ID = VARS[\"PROJECT_ID\"]\n\nprocess = (\nprocessing(friendly_name, language, models)\n.set_display_name(\"URL processing\")\n.set_env_variable(\"PROJECT_ID\", PROJECT_ID)\n.set_caching_options(enable_caching=False)\n.set_cpu_limit(\"4\")\n.set_memory_limit(\"16G\")\n.add_node_selector_constraint(\n\"cloud.google.com\/gke-accelerator\", \"NVIDIA_TESLA_T4\"\n)\n.set_gpu_limit(1)\n).after(crawling)\nembed = (\nembeddings(friendly_name, language, models)\n.set_display_name(\"Create embeddings\")\n.set_env_variable(\"PROJECT_ID\", PROJECT_ID)\n.set_caching_options(enable_caching=False)\n.set_cpu_limit(\"4\")\n.set_memory_limit(\"16G\")\n.add_node_selector_constraint(\n\"cloud.google.com\/gke-accelerator\", \"NVIDIA_TESLA_T4\"\n)\n.set_gpu_limit(1)\n).after(process)\n\ncompiler.Compiler().compile(pipeline, file_name)\n\n\nVisualized in the browser:"
            }
        ]
    },
    {
        "Question_title":"I am trying to use google vision api in c++ to read local images",
        "Question_creation_date":"2022-08-12T15:24:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/I-am-trying-to-use-google-vision-api-in-c-to-read-local-images\/td-p\/453466\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":68,
        "Question_body":"I have tried using c++ to use google vision api to read local files, but I have no experience with google, and I am mainly a c++ developer, so changing languages is not that of an option. Do any one knows how to do it in this language. Furthermore, any written documentation or tutorial in my language(c++) will be extremely helpful.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There is a library of Vision API in C++ you can use google-cloud-cpp quickstart."
            }
        ]
    },
    {
        "Question_title":"Batch prediction forecasting",
        "Question_creation_date":"2022-08-08T09:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Batch-prediction-forecasting\/td-p\/451758\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":65,
        "Question_body":"Dear ALL;I have made a sales and demand forecasting autoML model. It trained well and is working. I am looking for a way to format input data for batch prediction forecasting where I would like to do more than one forecast horizon predictions.Basically my model uses monthly data granularity with 12 month context length and 6 month forecast horizon. (I have 15 covariate features and predict for 14 separate identifiers).What I would like to do is configure the input data for a batch forecasting where the forecasting would start 3 month earlier than where the feature data end and make forecasts for these three time periods AND when the feature data ends do the normal 6 month forecasting so I end up with 3 month forecasting where I know the actuals and the normal 6 month forecasting.At this point no matter how I format my input data I only get the 6 month forecast horizon.Thanks ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-17T11:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I searched for a document which explain how batch prediction results work within Google Cloud, and I hope it helps you."
            }
        ]
    },
    {
        "Question_title":"Google ML kit",
        "Question_creation_date":"2022-08-10T08:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-ML-kit\/td-p\/452579\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Video Intelligence API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":1,
        "Question_view_count":106,
        "Question_body":"I know Google provides an ML kit supported by android that we can integrate into an app. The ML Kit provides many Vision and NLP APIs that can help us make our own Google-like Lens.Anyone can give me more information on how to get the ML kit?I am the CEO and I am looking for a CTO to my company, must be good in Python, A.I., Machine Learning, IoT and Robotics.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-15T10:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"ML Kit is a mobile SDK that brings Google's on-device machine learning expertise to Android and iOS apps. To use ML Kit on Android you\u2019ll need to add the libraries to your module's app-level gradle file. To use on Ios you need to include the ML Kit pods in your Podfile.\n\nYou can use this document\u00a0to see the whole product's quickstarts.\n\nAdditionally see the left menu guides\u00a0for each product and how to use it on Ios or Android."
            },
            {
                "Answer_creation_date":"2022-08-16T20:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello\n\nThank you for the information."
            }
        ]
    },
    {
        "Question_title":"Join us on August 4! Machine Learning Day on Google Open Source Live",
        "Question_creation_date":"2022-07-28T06:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Join-us-on-August-4-Machine-Learning-Day-on-Google-Open-Source\/td-p\/447714\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":3,
        "Question_view_count":93,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-16T20:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Lauren_vdv\u00a0\n\nThank you for the post, can I register on demand??"
            }
        ]
    },
    {
        "Question_title":"Google Translate javascript API",
        "Question_creation_date":"2022-08-06T01:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-javascript-API\/td-p\/451250\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":1,
        "Question_view_count":94,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-11T13:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If my understanding is correct, you only want to use that part of the script to translate a web page, right?\u00a0\n\nIf yes I think you can use it as long as you don\u2019t meet the quotas described on this documentation free of charge, and also if you have doubts on how to implement the script you are sharing, you could look up for tutorials online on how to properly make use of it."
            },
            {
                "Answer_creation_date":"2022-08-16T17:08:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThank you for your kind reply.\u00a0\n\nYes, you're right, I only want to use the script to translate a webpage.\n\nI'll go through the document you have referred to.\n\nMinoru Kume"
            }
        ]
    },
    {
        "Question_title":"WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB",
        "Question_creation_date":"2022-08-04T06:52:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/WARN-DAGScheduler-Broadcasting-large-task-binary-with-size-2-2\/td-p\/450466\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":794,
        "Question_body":"Hi there.\nThere were quite a number of such warnings as the model was getting trained.May I know if we are safe to ignore them?\nWhat does it mean actually?\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-15T12:03:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There is a limit of MB while broadcasting a task (10 MB), while using your VM that has enough resources if you don\u2019t pass this limit its going to be OK, but if your VM has low resources this could create a timeout.\n\nYou can mitigate it by reducing the task size => reduce the data its handling\n\nFirst, check number of partitions in dataframe via df.rdd.getNumPartitions() After, increase partitions: df.repartition(100)"
            }
        ]
    },
    {
        "Question_title":"AutoML Translation models response time",
        "Question_creation_date":"2022-08-04T05:49:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-Translation-models-response-time\/td-p\/450442\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":60,
        "Question_body":"Hi,We have several AutoML Translation models and we are facing timeout issues when the first translation requests are sent. We have to retry a second time to get the translations back. After this first request, it seems the model is kept  \"online\", and subsequent requests to the same model are performing well.What we don't really know is how long the models are kept online and ready for quick response times and how many models can be online simultaneously. We would like to have more information about this in order to handle the translation requests in a proper and controlled way.Thank you,Julian ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-12T11:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Normally when we use the custom models, we will load the model to the chip, if there are more frequent custom models, the least frequent models will be evicted from the chip, and the next when we use the evicted custom models, we need to reload the model to the chip, it will take around 15s. So what happens to the batch translation is that the customers tried to call batch translation with custom models, however, this is the first time for the model to be loaded into the chip, it will take 15s to be loaded, because they have the empty sentences in the output. But for the second try, the model has already been loaded, so we don't need to wait for 15s and we have all translated sentences in the output.\n\nIf there is an inconsistency should be related to the replicas, if we have multiple replicas loading the models at the same time, it is possible that one replica loads the model successfully before others and it starts serving the first request, however the second request is routed to other replicas."
            }
        ]
    },
    {
        "Question_title":"Unable to get textStyle in JSON response with Document ai",
        "Question_creation_date":"2022-08-04T05:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unable-to-get-textStyle-in-JSON-response-with-Document-ai\/td-p\/450434\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":46,
        "Question_body":"I was trying to get text style or Font style with document ai but was getting null list..This is the file I wanted text style to be extractedThis was the response I received.can someone help me with this?",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-10T10:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I previously answered on this Stack Overflow post"
            }
        ]
    },
    {
        "Question_title":"Unable to create model",
        "Question_creation_date":"2022-08-04T02:08:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unable-to-create-model\/td-p\/450348\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":75,
        "Question_body":"I am working on demand forecasting where my timestamp duration is 15 minutes and i have attached sample output to below documents.The issue i am facing is despite setting DATA_FREQUENCY = [AUTO_FREQUENCY].ii am getting the error \"Invalid time series: the finest data frequency supported is PER_MINUTE. All input time intervals must be at least one minute\" and the query for create model is given below  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-08T15:48:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"What is happening is that using \u201cAUTO_FREQUENCY\u201d is trying to send the Information as \u201cPER_MINUTE\u201d because of your data, and this needs to have an interval value per minute in each HOUR. You could try with \u201cHOURLY\u201d instead of \u201cAUTO_FREQUENCY\u201d, and it should work.\n\nInstead of:\nDATA_FREQUENCY = 'AUTO_FREQUENCY'\n\nUse \u201cHOURLY\u201d or any other DATA_FREQUENCY:\u00a0\n\nDATA_FREQUENCY = 'HOURLY'\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-08-08T15:48:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"What is happening is that using \u201cAUTO_FREQUENCY\u201d is trying to send the Information as \u201cPER_MINUTE\u201d because of your data, and this needs to have an interval value per minute in each HOUR. You could try with \u201cHOURLY\u201d instead of \u201cAUTO_FREQUENCY\u201d, and it should work.\n\nInstead of:\nDATA_FREQUENCY = 'AUTO_FREQUENCY'\n\nUse \u201cHOURLY\u201d or any other DATA_FREQUENCY:\u00a0\n\nDATA_FREQUENCY = 'HOURLY'"
            }
        ]
    },
    {
        "Question_title":"Next Step from Google Colab +Pro",
        "Question_creation_date":"2022-05-10T08:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Next-Step-from-Google-Colab-Pro\/td-p\/421797\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Cloud TPU",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":231,
        "Question_body":"Hi, I'm using Google Colab +pro and unfortunately I`m getting several Ram calls and have not been able to move forward or train some modelsWhich is the next tool that I should get in order to be able to run the Google Colab models without the Ram calls?Should I get a Google Compute Engine and try to connect the google colab files to it?Should I up load the model to vertex AI?What characteristics should I need to take into consideration before I select any of the different tools?",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-13T11:42:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI have provided a few links to help you through configuring your Google Colab Model.\n\nThis link below contains all Google Colab related questions on Stack Overflow:\n\nhttps:\/\/stackoverflow.com\/search?q=colab&s=7e8e7982-76a3-4765-8bad-63af4a9415fb\n\nThe following link explains how to double the Ram in Google Colab:\n\nhttps:\/\/towardsdatascience.com\/double-your-google-colab-ram-in-10-seconds-using-these-10-characters-...\n\nThe last link is a HOW-TO guide:\n\nhttps:\/\/neptune.ai\/blog\/how-to-use-google-colab-for-deep-learning-complete-tutorial#:~:text=Open%20a....\n\nRegards\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-05-13T11:42:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI have provided a few links to help you through configuring your Google Colab Model.\n\nThis link below contains all Google Colab related questions on Stack Overflow:\n\nhttps:\/\/stackoverflow.com\/search?q=colab&s=7e8e7982-76a3-4765-8bad-63af4a9415fb\n\nThe following link explains how to double the Ram in Google Colab:\n\nhttps:\/\/towardsdatascience.com\/double-your-google-colab-ram-in-10-seconds-using-these-10-characters-...\n\nThe last link is a HOW-TO guide:\n\nhttps:\/\/neptune.ai\/blog\/how-to-use-google-colab-for-deep-learning-complete-tutorial#:~:text=Open%20a....\n\nRegards"
            },
            {
                "Answer_creation_date":"2022-05-16T15:14:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks a lot!!!"
            },
            {
                "Answer_creation_date":"2022-05-17T13:25:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Ulisses hi, had the oportunity to review all the links that you send me but still not very sure what to do next.\n\nI have a ML model that runs in a Google Colab Pro+ that always went down do to Ram consumption.\n\nThe next step in order to be able to run the entire Google Colab Notebook is to connect the notebook to a Google Cloud virtual machine? Should I upload the notebook to a container and then to\u00a0 Vertex AI and see if all the functions from the notebook runs?\n\nWhat will be your recommendation if Im looking for a step by step escalation?"
            },
            {
                "Answer_creation_date":"2022-08-08T12:08:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello\u00a0holguinmora\n\nThe\u00a0Google Workspace Community\u00a0is the most appropriate\u00a0place to\u00a0ask troubleshooting questions and get answers from Google Workspace\u00a0product experts and other administrators considering Google Colab Pro+ is a Workspace product."
            }
        ]
    },
    {
        "Question_title":"Relation Google node hour to Azure computing hour",
        "Question_creation_date":"2022-08-05T06:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Relation-Google-node-hour-to-Azure-computing-hour\/td-p\/450911\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":27,
        "Question_body":"Hey there,I am writing my masters thesis at the moment. In my master thesis I compare the machine learning services of Google and Microsoft for image classification. This also includes the costs. Google uses node hours and Microsoft computing hours for the calculation. Is it possible to compare these units? This would be a crucial part of the comparison.\nThanks a lot! ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-05T06:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hey there,\n\nI am writing my masters thesis at the moment.\u00a0In my master thesis I compare the machine learning services of Google and Microsoft for image classification. This also includes the costs. Google uses node hours and Microsoft computing hours for the calculation. Is it possible to compare these units? This would be a crucial part of the comparison.\nThanks a lot!"
            }
        ]
    },
    {
        "Question_title":"Document AI Form Processor Parse Table Structure Incorrectly",
        "Question_creation_date":"2022-08-01T20:17:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Document-AI-Form-Processor-Parse-Table-Structure-Incorrectly\/td-p\/449252\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":93,
        "Question_body":"Hi All,We are currently using Document AI for form parsing some PDF document and half of times the default former processor either missing a col or messed up some col structure.Let's say the expected file headerSales | Dollar Volume | Average Price For example, I saw cases like1. Missing HeaderSales|Average Price2. Wrong structureSalesDollar|Volume|Average PriceThe content of first two cols are messed up as well. The cell could be missing value or incomplete value.Any recommendation to improve this? If no easy way, any guidance with examples to train or deploy one's own form processor? PS: the document has the same structure. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-04T10:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can improve the data results by using Document AI Parser with AI Platform Notebooks. Also you can use Vision AI to create your own Parser."
            }
        ]
    },
    {
        "Question_title":"Feature Engineering Vertex AI\/AutoML",
        "Question_creation_date":"2022-07-28T09:18:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Feature-Engineering-Vertex-AI-AutoML\/td-p\/447814\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":88,
        "Question_body":"Hey There,I am writing my Master Thesis at the moment. I am comparing AutoML products for image classification. There I compare the product Vertex AI with Azure from Microsoft. However, I can't find the concrete methods of feature engineering and model selection from the documentation. Does anybody know these methodes used for Google AutoML for image classification?Thanks a lot!Arndt",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-03T15:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Think you are looking for this documentation it describes how feature engineering works within autoML and how it supports it in different ways."
            }
        ]
    },
    {
        "Question_title":"Model Selection \/ Feature Engineering",
        "Question_creation_date":"2022-08-02T05:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Model-Selection-Feature-Engineering\/td-p\/449387\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":40,
        "Question_body":"Hey There,I am writing my Master Thesis at the moment. I am comparing AutoML products for image classification. There I compare the product Vertex AI with to Azure. However, I can't find the concrete methods of feature engineering and model selection from the documentation.Thanks a lot!",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-03T14:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Using Vertex Ai You can train models on Vertex AI by using AutoML, or if you need the wider range of customization options available in AI Platform Training, use custom training.\n\nIn custom training, you can select from among many different machine types to power your training jobs, enable distributed training, use hyperparameter tuning, and accelerate with GPUs. See the full custom training documentation here.\u00a0\n\nAdditionally there are 4 other models:\n\nImage Data.\nTabular Data.\nText Data.\nVideo Data."
            }
        ]
    },
    {
        "Question_title":"Document AI fails for one particular image, else works great",
        "Question_creation_date":"2022-05-02T13:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Document-AI-fails-for-one-particular-image-else-works-great\/td-p\/419233\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":7,
        "Question_upvote_count":0,
        "Question_view_count":84,
        "Question_body":"We are delivering a platform to a customer based on Document AI. The use case it to send a lottery ticket via API and return the structure information using Document AI. We tried for several hundred images and the Document AI OCR worked great (95%+ times captured right string, only errors were line feeds and Q turning into O etc. that we could resolve using a post-processor). But for one set of images (from DC), the OCR fails miserably.  This is a corner case that seems to throw the Document AI engine off the mark.I will appreciate greatly if anyone can help explain it.See one particular image which is the most problematic.",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-09T11:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you please share the output that you are receiving, and what errors are the ones that you are presenting?"
            },
            {
                "Answer_creation_date":"2022-05-10T00:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Eduardo,\n\nThe error is that several characters that are on the image are not captured by OCR (whereas it does capture in case of several other images).\n\nRefer to the screenshot attached. See the right side after line \"DCLOTTERY.COM\".\u00a0 You will notice lines \"8\", \"B. 4\" etc.\n\nLine \"8\", the rest of the characters 0 1 1 4 STRAIGHT ... are missing.\n\nLine \"4 0\", characters 2 8 4 STRAIGHT ... are missing.\n\nSame for following 3 lines.\n\n----"
            },
            {
                "Answer_creation_date":"2022-05-13T16:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I could find this guide that might seem helpful for your case, if not, please give me more time so I can provide you a proper answer for the issue you are facing."
            },
            {
                "Answer_creation_date":"2022-05-13T22:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Sorry, you missed the entire point, the issue is that the core OCR engine is failing to process the image properly. If the product team takes a look at the image and result, it may give a clue. Hopefully they may be able to find a corner case that will improve the OCR results.\n\nWe are quite familiar with the documents and how to parse the result of the DOcument AI."
            },
            {
                "Answer_creation_date":"2022-06-21T07:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Anil, sorry it took me so long to answer you, couldn't find any information on why the OCR is failing for that image that you specify, so my best recommendation for you, is that you file an issue tracker or open a support ticket since this seems like an issue that you are only facing."
            },
            {
                "Answer_creation_date":"2022-06-27T21:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What DocAI processor are you using?\u00a0 What, if anything, is returned from the processing?"
            },
            {
                "Answer_creation_date":"2022-08-03T12:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Deskewing the image in a pre processing step is doing the trick"
            }
        ]
    },
    {
        "Question_title":"How to determin which GCP VM do I need for ML",
        "Question_creation_date":"2022-07-26T13:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-determin-which-GCP-VM-do-I-need-for-ML\/td-p\/447075\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":73,
        "Question_body":"Hi to allIm trying to run a procedure looking to reduce the number of features for a model.The first try was with google Colab pro+ but it keep crashing and nver run the entire process, then I got a VM n1-highmem-8 that has: GPUs1 x NVIDIA Tesla V100  +  n1-highmem-8 (vCPUs: 8, RAM: 52GB)and still not getting the process done.The question is how to determin which type of machine should I use? Can I get any metric from the cell that is runing in colab and be able to determin the Type of VM that I need?",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-01T10:31:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"There are a few things to take in consideration:\n\nHave you installed all the necessary drivers for the GPU? Here is a complete guide that you can follow.\nI do not see any Python wrapper for CUDA in your code. The way you specify when to use the GPU for specific tasks is through this wrapper, it seems to me that you are using the CPU instead and that is why the task keeps crashing. Now, converting your code to a CUDA version is not a trivial task, and it involves a deeper knowledge on how a GPU works. If you are in a hurry, you could try the Py2CUDA github project, but I would strongly recommend taking a look at the Getting Started Blogs.\u00a0\u00a0\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-08-01T10:31:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"There are a few things to take in consideration:\n\nHave you installed all the necessary drivers for the GPU? Here is a complete guide that you can follow.\nI do not see any Python wrapper for CUDA in your code. The way you specify when to use the GPU for specific tasks is through this wrapper, it seems to me that you are using the CPU instead and that is why the task keeps crashing. Now, converting your code to a CUDA version is not a trivial task, and it involves a deeper knowledge on how a GPU works. If you are in a hurry, you could try the Py2CUDA github project, but I would strongly recommend taking a look at the Getting Started Blogs."
            },
            {
                "Answer_creation_date":"2022-08-03T06:39:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I sincerely appreciate your response, you cannot imagine how important and valuable your help has been"
            }
        ]
    },
    {
        "Question_title":"How to assign specialist for specialist",
        "Question_creation_date":"2022-07-27T09:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-assign-specialist-for-specialist\/td-p\/447380\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":51,
        "Question_body":"Hello,I configured Document AI processor with HITL, No filter(self-validate). Using a python code, I am sending specific document to hitl queue to be processed by a specialist.I can clearly see that there are documents to be reviewed as \"Queued for review\" column with 2 documents.I also configured the specialist assignment assigning to all tasks (P0, audit, P1) to all the available specialists as it is shown in the image:Howevere, accesing to specialist platform, I cannot see any of the documents in the queue.What am I missing here?Thanks for your help. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-02T13:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Follow the steps from 4 to 7 from the following codelab."
            },
            {
                "Answer_creation_date":"2022-08-02T14:49:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks"
            }
        ]
    },
    {
        "Question_title":"Tenserflow model not detecting plants correctly",
        "Question_creation_date":"2022-07-27T05:35:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Tenserflow-model-not-detecting-plants-correctly\/td-p\/447276\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":46,
        "Question_body":"Hi there,We are using AutoML skd with Tenserflow model (https:\/\/tfhub.dev\/google\/lite-model\/aiy\/vision\/classifier\/plants_V1\/3) for detecting plants. The model return results, but they are not accurate. I wanted to see if there are any pre-trained TenserFlow models for detecting plant type? Similar to plant.id. Thanks  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-02T11:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There is a TensorFlow Model for Flowers you can see this quickstart\u00a0using this model.\n\nMore specific about the model you can see the training in the following document."
            }
        ]
    },
    {
        "Question_title":"Vertex AI Datasets & batch predictions",
        "Question_creation_date":"2022-07-24T13:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Datasets-amp-batch-predictions\/td-p\/446346\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":134,
        "Question_body":"Hi all,I just started to play with Vartex AI. I am working with \"Tabular\" - \"Forecasting\" and currently struggling with few things and i hope you can help me in order i can continue. I tried to organize my questions to three categories:1) Datasets for training:      a) \"series identifier\" define to which time series data are belonging ... lets assume that i have two series identifier - one is called \"A\" and one is called \"B\". Does this means that AI treats them as completely separate and noncorrelated - this means any data that belongs to series A don't have any correlation to B, right? This give me possibility to train different dataset with one shot right? Otherwise i would need to make (in my case) two trainings - one for A and one for B.2) Training new model --> Model detailsa) Is possible to predict more then one target column? b) lets assume that my dataset data granularity is 1 day. Can i use data granularity of \"5min\" for Forecast configuration or can this setup decrease quality of my forecast? Should it be more correct to use already at beginning lets say dataset granularity of 5 minute and afterwards it could be more flexible when setting data granularity for forecast configuration without influencing forecast quality?c) If I set Forecast horizon of 7 and context window 30, does this means that this setting limit my forecast to maximum 7 time steps and requesting always exactly 30 time steps of historical data as input when forecasting on existing trained model?3) Batch predictionsa) Batch Source fileLets assume that i have data with 15 columns from which one is \"serial identifier\" , one is \"time step\" - actually date and one of those columns is target column. Rest of 12 columns are used as influencer and used to train my model. I know that i need to have same structure for batch source file - i read that i can use same file as i used for training, but i just need to add in my case a 2x7 new rows with adding 7 dates and serial identification (in my case 7x A and 7xB) and target column need to be empty. But what should i do with data of rest 12 columns? Do i need manually to enter data for those new rows (2x7) of those 12 columns which values should be for future? But what if i don't have those data? Does this means i cannot do prediction?I tried to make prediction without those future data and i got following message:\"There are rows with non-empty target values after this row. The time series has been excluded from predictions.\"I hope you can help me with above questions. Tnx in advance! Regards, Arny ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-01T09:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"A)\nYes, that's correct you can train different datasets with the same shot (only if there is a specific column that differentiates them). Follow this document\u00a0for best practices.\n\nB)\nNo, for datasets that train AutoML models, one column must be the target, and there must be at least one feature available to train the model.\n\nWhen you train a forecasting model, you specify the data granularity, or the time interval between the training data rows. It can be hourly, daily, weekly, monthly, or yearly. In addition, it can be every 1, 5, 10, 15, or 30 minutes.\u00a0 Vertex AI treats the interim day as missing data, which can degrade model performance.\n\nC)\nFor this error what you could do is to copy the table into another and set the value to NULL to the other columns or set the data values manually."
            }
        ]
    },
    {
        "Question_title":"Google translate API gave a mixed language translation result?",
        "Question_creation_date":"2022-07-11T00:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-translate-API-gave-a-mixed-language-translation-result\/td-p\/440841\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":105,
        "Question_body":"I am using Google Translate API for translating a Japanese sentence to Portuguese.On July 6 to 8, the translation result was a sentence of mixed English and Portuguese words, but on July 9 the result seems to be a correct Portuguese sentence.Was there any event on July 6 to 8 such that Google Translate API gave a mixed language translation result?Thank you for your time. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-13T15:33:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"The issue was generated due our service update and multiple service languages including Portuguese were affected. Our Translate API engineer team detected the root cause of the issue, and it was mitigated by a roll back recently performed.\n\nOur engineers confirmed that the issue is officially mitigated and you should not be experiencing any service misbehavior at this point.\n\nWe apologize for any inconvenience this may have caused on your operation.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-07-13T15:33:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"The issue was generated due our service update and multiple service languages including Portuguese were affected. Our Translate API engineer team detected the root cause of the issue, and it was mitigated by a roll back recently performed.\n\nOur engineers confirmed that the issue is officially mitigated and you should not be experiencing any service misbehavior at this point.\n\nWe apologize for any inconvenience this may have caused on your operation."
            },
            {
                "Answer_creation_date":"2022-07-31T06:46:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Dear josequtierrez,\n\nThank you very much for your response and explanation.\n\nWe really appreciate it.\n\nThank you and best regards,\n\nIvan"
            }
        ]
    },
    {
        "Question_title":"Strange behaviour of ARIMA model",
        "Question_creation_date":"2022-07-22T08:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Strange-behaviour-of-ARIMA-model\/td-p\/445988\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":70,
        "Question_body":"Hi guys, I'm working with ARIMA Model and I found a strange behaviour.I have two dataset called Then I create two model in this waysample_10_arimasample_11_arimaThen I call the ML.FORECAST function for both in that wayResult for sample_10:Result for sample_11:In the first case sample_10_arima the standard_error is low (around 2.8) but in the sample_11_arima the standard_error is high (between 60 and 101). Why this difference occour? The time series are very similarThanks, Marcello",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-29T14:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you please file an issue\u00a0 at issue tracker according to this behavior shown?"
            }
        ]
    },
    {
        "Question_title":"Vertex AI data lost on VM stop",
        "Question_creation_date":"2022-07-22T08:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-data-lost-on-VM-stop\/td-p\/445990\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":131,
        "Question_body":"I am new to Vertex AI and wanted to try it out for a Kaggle competition. I was able to get a GPU machine up and running, as well as download the data to the machine. The download script was automatically generated when uploading my notebook to Vertex AI. I ran the script and 5 hours later all of the data was there successfully (to the boot disk -  standard persistent disk with 1000 GB). I then ran a first iteration of my model and everything worked great. When I was done, I went back to GCP and stopped my VM, assuming all of my data would be saved. It was not!I then started over and once the data was on the machine I took a snapshot so I wouldn't have to redownload the data a third time. I then made some edits to my model and ran it again. After I was done, I again stopped my VM to not leave it running. All of the data was lost again, but less surprisingly this time. I thought a snapshot could be used as a backup to the original machine, but the documentation makes it seem like it is only for creating a new VM from the boot disk. I then made a new machine but cannot figure out how to use it. I also tried looking for a way to make a new notebook on Vertex with the disk snapshot, but it did not look possible. Questions: ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-29T08:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Create a snapshot\n\ngcloud compute snapshots create SNAPSHOT_NAME \\\n\n--source-disk SOURCE_DISK \\\n\n--source-disk-zone SOURCE_DISK_ZONE\n\nssh instance and run command: sudo umount \/dev\/disk\/by-id\/google-<INSTANCE NAME>\nStop the instance\nDetach data disk\n\ngcloud compute instances detach-disk $INSTANCE_NAME --disk $DATA_DISK_NAME --zone $ZONE\n\nDelete data disk\n\ngcloud compute disks delete $DATA_DISK_NAME --zone $ZONE\n\nCreate the new disk using the snapshot created: gcloud compute disks create $DATA_DISK_NAME $DATA_DISK_SIZE --source-snapshot=$SNAPSHOT_NAME $DATA_DISK_TYPE --zone $ZONE\nAttach the disk into the notebook instances: gcloud compute instances attach-disk $INSTANCE_NAME --disk $DATA_DISK_NAME --zone $ZONE\nCreate directory that serves as the mount point sudo mkdir -p \/mnt\/disks\/MOUNT_DIR\nMount the disk sudo mount -o discard,defaults \/dev\/DEVICE_NAME \/mnt\/disks\/MOUNT_DIR\nStart the VM"
            },
            {
                "Answer_creation_date":"2022-07-29T09:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks, that is helpful but I still do not understand why the data was deleted in the first place? It says it is a persistent disk"
            }
        ]
    },
    {
        "Question_title":"VertexAI- Auto ML training model failed without giving the reason",
        "Question_creation_date":"2022-07-21T00:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/VertexAI-Auto-ML-training-model-failed-without-giving-the-reason\/td-p\/445439\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":1,
        "Question_view_count":110,
        "Question_body":"After an hour of training Auto ML with Vertex AI, it failed without mentioning the reason. I have received the following email;\n\"Due to an error, Vertex AI was unable to train model \"some_model\".\nAdditional Details:\nOperation State: Failed with errors\nResource Name: \nprojects\/xxxxxxxxxxxxxxx\/locations\/region\/trainingPipelines\/xxxxxxxxxxxxxxxxxxxxxxxx\nError Messages: Internal error occurred. Please retry in a few minutes. If \nyou still experience errors, contact Vertex AI.\"Would you please help me with it?\nThanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-27T10:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There was an issue with Europe West 2 Servers during that day, does your training model was in that region?\nIs this still an issue or is it fixed now?"
            },
            {
                "Answer_creation_date":"2022-07-28T06:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Not at that region and still the same error."
            },
            {
                "Answer_creation_date":"2022-07-28T13:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What could be happening is due to a permission error.\n\nFix custom training permission issues.\n1. use default compute account of model preprocessing tenant projects to run training jobs\n2. Grant default compute account storage.admin role to batch prediction\/prediction\/training tps during provisioning"
            }
        ]
    },
    {
        "Question_title":"VM Ram vs Google Colab Ram",
        "Question_creation_date":"2022-07-27T12:51:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/VM-Ram-vs-Google-Colab-Ram\/td-p\/447466\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":61,
        "Question_body":"Hi, @Eduardo_Ortiz  @josegutierrez sorry to bother but I`m completely lostDays a go I bought a VM that has the next configurations, when I connect to the VM with Google Colab get the next results as you can see in the next image.VM Configuration : GPUs1 x NVIDIA Tesla V100  +  n1-highmem-8 (vCPUs: 8, RAM: 52GB)Ram obtained in Google Colab from the VM: 1.31 Gb \/ 51.01 Gb Disc 43.79 \/ 186.52As you realized,  althoug I have buy a better configuration than Google Coalb Pro+ Im getting fewer RAM from the VM instance....What could be the error or situation? How can I get into colab the real VM capacity bought? Or which configuration do I need in order to have better performance than Google Colab pro+?In the next screen shot the ram and disck that I got from Google Colab:Thanks a lot for any help ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-27T12:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, @Eduardo_Ortiz\u00a0 @josegutierrez\u00a0sorry to bother but I`m completely lost\n\nDays a go I bought a VM that has the next configurations, when I connect to the VM with Google Colab get the next results as you can see in the next image.\n\nVM Configuration : GPUs1 x NVIDIA Tesla V100\u00a0 +\u00a0\u00a0n1-highmem-8 (vCPUs: 8, RAM: 52GB)\n\nRam obtained in Google Colab from the VM: 1.31 Gb \/ 51.01 Gb Disc 43.79 \/ 186.52\n\nAs you realized,\u00a0 althoug I have buy a better configuration than Google Coalb Pro+ Im getting fewer RAM from the VM instance....\n\nWhat could be the error or situation? How can I get into colab the real VM capacity bought? Or which configuration do I need in order to have better performance than Google Colab pro+?\n\nIn the next screen shot the ram and disck that I got from Google Colab:\n\nThanks a lot for any help"
            }
        ]
    },
    {
        "Question_title":"Error while trying to get explanation from (custom container) model deployed on Vertex AI",
        "Question_creation_date":"2022-07-26T01:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-while-trying-to-get-explanation-from-custom-container\/td-p\/446817\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":166,
        "Question_body":"Hi,I created a custom docker container to deploy my model on Vertex AI. The model uses LightGBM, so I can't use the pre-built container images available for TF\/SKL\/XGBoost. I was able to deploy the model and get predictions, but I get errors while trying to get explainable predictions from the model. I have tried to follow the Vertex AI guidelines to configure the model for explanations.\nThe example below shows a simplified version of the model that still reproduces the issue, with only two input features 'A' and 'B'.Please take a look and tell me if the explanation metadata is supposed to be set differently, or if there is something wrong with this approach.https:\/\/cloud.google.com\/vertex-ai\/docs\/explainable-ai\/configuring-explanations#custom-container(Model output is unkeyed. The Vertex AI guide suggests using any memorable string for output key.)",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-26T01:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI created a custom docker container to deploy my model on Vertex AI. The model uses LightGBM, so I can't use the pre-built container images available for TF\/SKL\/XGBoost. I was able to deploy the model and get predictions, but I get errors while trying to get\u00a0explainable\u00a0predictions from the model. I have tried to follow the Vertex AI guidelines to configure the model for explanations.\nThe example below shows a simplified version of the model that still reproduces the issue, with only two input features 'A' and 'B'.\n\nPlease take a look and tell me if the explanation metadata is supposed to be set differently, or if there is something wrong with this approach.\n\nEnvironment details\nGoogle Cloud Notebook\nPython version: 3.7.12\npip version: 21.3.1\ngoogle-cloud-aiplatform\u00a0version: 1.15.0\nReference\n\nhttps:\/\/cloud.google.com\/vertex-ai\/docs\/explainable-ai\/configuring-explanations#custom-container\n\nexplanation-metadata.json\n\n(Model output is unkeyed. The Vertex AI guide suggests using any memorable string for output key.)\n\n{\n    \"inputs\": {\n        \"A\": {},\n        \"B\": {}\n    },\n    \"outputs\": {\n        \"Y\": {}\n    }\n}\nModel upload with explanation parameters and metadata\n! gcloud ai models upload \\\n  --region=$REGION \\\n  --display-name=$MODEL_NAME \\\n  --container-image-uri=$PRED_IMAGE_URI \\\n  --artifact-uri=$ARTIFACT_LOCATION_GCS \\\n  --explanation-method=sampled-shapley \\\n  --explanation-path-count=10 \\\n  --explanation-metadata-file=explanation-metadata.json\nPrediction\/Explanation Input\ninstances = [{\"A\": 1.1, \"B\": 20}, {\"A\": 2.2, \"B\": 21}]\n# Prediction (works fine):\nendpoint.predict(instances=instances)\n# Prediction output: predictions=[0, 1], deployed_model_id='<>', model_version_id='', model_resource_name='<>', explanations=None\nendpoint.explain(instances=instances) # Returns error (1) shown in stack trace below\n\n# Another example\ninstances_2 = [[1.1,20], [2.2,21]]\n# Prediction (works fine):\nendpoint.predict(instances=instances_2)\n# Prediction output: predictions=[0, 1], deployed_model_id='<>', model_version_id='', model_resource_name='<>', explanations=None\nendpoint.explain(instances=instances_2) # Returns error\n# Error: Nameless inputs are allowed only if there is a single input in the explanation metadata.\nPrediction Server (Flask)\n# Custom Flask server to serve online predictions\n# Input for prediction\nraw_input = request.get_json()\ninput = raw_input['instances']\ndf = pd.DataFrame(input, columns = ['A', 'B'])\n# Prediction from model (loaded from GCP bucket)\npredictions = model.predict(df).tolist() # [0, 1]\nresponse = jsonify({\"predictions\": predictions})\nreturn response\nStack trace of error (1)\n---------------------------------------------------------------------------\n_InactiveRpcError                         Traceback (most recent call last)\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/grpc_helpers.py in error_remapped_callable(*args, **kwargs)\n     49         try:\n---> 50             return callable_(*args, **kwargs)\n     51         except grpc.RpcError as exc:\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in __call__(self, request, timeout, metadata, credentials, wait_for_ready, compression)\n    945                                       wait_for_ready, compression)\n--> 946         return _end_unary_response_blocking(state, call, False, None)\n    947 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in _end_unary_response_blocking(state, call, with_call, deadline)\n    848     else:\n--> 849         raise _InactiveRpcError(state)\n    850 \n\n_InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"{\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\"\n\tdebug_error_string = \"{\"created\":\"@1658310559.755090975\",\"description\":\"Error received from peer ipv4:74.125.133.95:443\",\"file\":\"src\/core\/lib\/surface\/call.cc\",\"file_line\":1069,\"grpc_message\":\"{\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\",\"grpc_status\":3}\"\n>\n\nThe above exception was the direct cause of the following exception:\n\nInvalidArgument                           Traceback (most recent call last)\n\/tmp\/ipykernel_2590\/4024017963.py in <module>\n----> 3 print(endpoint.explain(instances=instances, parameters={}))\n\n~\/.local\/lib\/python3.7\/site-packages\/google\/cloud\/aiplatform\/models.py in explain(self, instances, parameters, deployed_model_id, timeout)\n   1563             parameters=parameters,\n   1564             deployed_model_id=deployed_model_id,\n-> 1565             timeout=timeout,\n   1566         )\n   1567 \n\n~\/.local\/lib\/python3.7\/site-packages\/google\/cloud\/aiplatform_v1\/services\/prediction_service\/client.py in explain(self, request, endpoint, instances, parameters, deployed_model_id, retry, timeout, metadata)\n    917             retry=retry,\n    918             timeout=timeout,\n--> 919             metadata=metadata,\n    920         )\n    921 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/gapic_v1\/method.py in __call__(self, timeout, retry, *args, **kwargs)\n    152             kwargs[\"metadata\"] = metadata\n    153 \n--> 154         return wrapped_func(*args, **kwargs)\n    155 \n    156 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/grpc_helpers.py in error_remapped_callable(*args, **kwargs)\n     50             return callable_(*args, **kwargs)\n     51         except grpc.RpcError as exc:\n---> 52             raise exceptions.from_grpc_error(exc) from exc\n     53 \n     54     return error_remapped_callable\n\nInvalidArgument: 400 {\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\n---------------------------------------------------------------------------\n# https:\/\/github.com\/googleapis\/python-aiplatform\/issues\/1526"
            }
        ]
    },
    {
        "Question_title":"503 on translations",
        "Question_creation_date":"2022-07-20T05:46:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/503-on-translations\/td-p\/445069\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":71,
        "Question_body":"I started to see this error on multiple clusters in America. But there is nothing in the status page. I don't think we had any updates to our code.google.api_core.exceptions.ServiceUnavailable: 503 POST https:\/\/translation.googleapis.com\/language\/translate\/v2?prettyPrint=false: The service is unavailable at this time.I guess I need to wait, but posting here just to raise it",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-25T15:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Sometimes this issue happens because the Product is getting an Update.\nOthers it's because you are sending too many requests, and to mitigate this issue the recommendation is to split up the code."
            }
        ]
    },
    {
        "Question_title":"Google Cloud Translation language support for bcp-47",
        "Question_creation_date":"2022-07-20T20:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-Translation-language-support-for-bcp-47\/td-p\/445359\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":73,
        "Question_body":"Google Speech to Text supports languages using bcp 47 codes like es-MX for mexican spanish and pt-BR for Brazilian Portugese.I am using transcription and translation in a pipeline.Is there any support for bcp 47 languages in Google Cloud Translation. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-25T15:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Any BCP47 input or most legacy versions language codes should just work and there is no need to convert to a particular standard.\nAdditionally you can see here the full list of particular ISO languages codes.\n\nNote that ISO 639-1 on its own isn't sufficient to differentiate between written languages; mix up zh-CH and zh-TW ."
            }
        ]
    },
    {
        "Question_title":"Streaming Ingestion into Vertex AI Feature Store",
        "Question_creation_date":"2022-07-12T09:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Streaming-Ingestion-into-Vertex-AI-Feature-Store\/td-p\/441577\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":256,
        "Question_body":"I'm just wondering if Vertex AI Feature Store supports streaming ingestions rather than just batch ingestion as seen here (https:\/\/cloud.google.com\/vertex-ai\/docs\/featurestore\/ingesting-batch). I figured that the presence of an online store (https:\/\/cloud.google.com\/vertex-ai\/pricing) means that there is a way to store the most up-to-date data and serve them.Thanks!",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello, at the moment it\u2019s impossible to stream ingestion onto vertex, what you could do is to create a feature request.\n\nIf you find an issue or feature request that matches yours, star it.\n\nIf you don't see a matching issue or feature request, you can create one:\n\nIn the following tables of issue trackers, locate the product.\nClick on the link to create a new issue.\nIn the form's Template drop-down menu, select either Defect report to report an issue or Feature request to request a feature.\nIn the Description text box, complete the rest of the form using the prompts provided.\nClick Create."
            },
            {
                "Answer_creation_date":"2022-07-15T03:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Eduardo,\n\nThanks for the reply! Then could I check, what features would populate the online store then? Would it just be the latest features from any batch ingestion?"
            },
            {
                "Answer_creation_date":"2022-07-15T03:32:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Also, what is the online store based on? Is it a BigTable?"
            },
            {
                "Answer_creation_date":"2022-07-21T16:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You would need to wait for the Release note since i don't really have an answer for your first question, secondly, the store is based on cloud storage if i'm not mistaken."
            }
        ]
    },
    {
        "Question_title":"Retail API predict call saves the userEvent. It should NOT!",
        "Question_creation_date":"2022-07-17T17:45:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Retail-API-predict-call-saves-the-userEvent-It-should-NOT\/td-p\/443911\/jump-to\/first-unread-message",
        "Question_topic":[
            "Recommendations AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":62,
        "Question_body":"According to document, the userEvent sent as part of the predict body is not recorded.  https:\/\/cloud.google.com\/retail\/docs\/predict#recommendHowever, I noticed this was not TRUE.  Here is how to reproduce thisBecause both \"FAKE_SESSION_ID_1\" and \"FAKE_SESSION_ID_2\" are never used before this experient.   The recommendation result for the same sku should be same or very similar.  But they diff a lot.  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-20T12:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I reproduce this and it gives me similar results from what you say, so I decided to investigate this, and I found that this usually is not a great test of the prediction capabilities unless you use real, live data, but you can try this using sample data but it is possible that you get different results.\n\n\nFor using sample data to test prediction capabilities it is recommended to use the following demo."
            }
        ]
    },
    {
        "Question_title":"Run Colab with Mulitple GPUs using Drive Files OR workaround",
        "Question_creation_date":"2022-07-18T15:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Run-Colab-with-Mulitple-GPUs-using-Drive-Files-OR-workaround\/td-p\/444346\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":312,
        "Question_body":"Hi,I am trying to run my ML model in Colab utilizing a custom VM with multiple GPUs. I can successfully spin up a 2 GPU DeepLearning VM and connect to a Colab notebook via port-forwarding to a locally-hosted connection (Jupyter Notebook), as shown here.Although I can connect to custom runtimes directly WITHOUT port-forwarding to a locally-hosted connection, I can only access 1 of the 2 GPUs this way (i.e. I can successfully connect to a locally-hosted, port-forwarded runtime and verify that the notebook can access the 2 GPUs; however I am running into issues when trying to mount my Google Drive.I know that ocamlfuse was offered as a suggestion to this Drive issue,  however, none of the download options work. Specifically, it seems like a locally-hosted port-forwarded runtime doesn't allow terminal inputs, so I can't \"Press [ENTER]\" to allow the download, as shown below:User import cursor shows up for a direct connection to a custom or hosted runtime:User import cursor fails to show up\/accept inputs in a locally-hosted, port-forwarded custom VM.In general, it seems like terminal commands don't work in Colab in a locally-hosted runtime.  Another option is PyDrive, which I've used in the past. However, since PyDrive relies on authentication through a local port, I can't get it to work on my locally-hosted custom VM.In short I'm looking for tips\/suggestions for any of the following issues:1) An alternative workflow to run my ML model using multiple GPUs (i.e. that's not through port-forwarding to a locally-hosted connection)2) How to get that user cursor to show up (enabling me to download ocamlfuse)3) How to authenticate in PyDrive, given I'm already using a local port connection to host my runtime.4) Alternatives to accessing my Drive\/Drive files.  Thank you so much!     ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-18T15:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI am trying to run my ML model in Colab utilizing a custom VM with multiple GPUs. I can successfully spin up a 2 GPU DeepLearning VM and connect to a Colab notebook via port-forwarding to a locally-hosted connection (Jupyter Notebook), as shown here.\n\nAlthough I can connect to custom runtimes directly WITHOUT port-forwarding to a locally-hosted connection, I can only access 1 of the 2 GPUs this way (i.e.\u00a0\n\nlen(tf.config.list_physical_devices('GPU')) always returns 1); hence, I'm tied to port-forwarding, unless there's an alternative option.\n\nI can successfully connect to a locally-hosted, port-forwarded runtime and verify that the notebook can access the 2 GPUs; however I am running into issues when trying to mount my Google Drive.\n\nI know that ocamlfuse was offered as a suggestion to this Drive issue,\u00a0 however, none of the download options work. Specifically, it seems like a locally-hosted port-forwarded runtime doesn't allow terminal inputs, so I can't \"Press [ENTER]\" to allow the download, as shown below:\n\nUser import cursor shows up for a direct connection to a custom or hosted runtime:\n\nUser import cursor fails to show up\/accept inputs in a locally-hosted, port-forwarded custom VM.\n\nIn general, it seems like terminal commands don't work in Colab in a locally-hosted runtime.\n\n\u00a0\n\n\u00a0\n\nAnother option is\u00a0PyDrive, which I've used in the past. However, since\u00a0PyDrive\u00a0relies on authentication through a local port, I can't get it to work on my locally-hosted custom VM.\n\nIn short I'm looking for tips\/suggestions for any of the following issues:\n\n1) An alternative workflow to run my ML model using multiple GPUs (i.e. that's not through port-forwarding to a locally-hosted connection)\n\n2) How to get that user cursor to show up (enabling me to download\u00a0ocamlfuse)\n\n3) How to authenticate in PyDrive, given I'm already using a local port connection to host my runtime.\n\n4) Alternatives to accessing my Drive\/Drive files.\u00a0\n\n\u00a0\n\nThank you so much!"
            }
        ]
    },
    {
        "Question_title":"Retail product catalog not sync with Merchant Center after initial import",
        "Question_creation_date":"2022-07-17T15:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Retail-product-catalog-not-sync-with-Merchant-Center-after\/td-p\/443901\/jump-to\/first-unread-message",
        "Question_topic":[
            "Recommendations AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":46,
        "Question_body":"I followed the documents to import product catalog from Merchant Center Sync. It seems to work at the beginning - but I recently notice it has not synced for last seven days. There is no error I can see that explains why.- There is a warnig on the Product Catalog integration page saying Last import is more than 1 week old.- If I click Import button, select merchant account and branch 0 . It says The branch already has a data source. But it is not syncing at all.I have daily new products added to merchant center so this is serious issue for me as many events become unjoined and recommendations on those new products are all messed up.  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-17T15:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"And the Import Activity tab shows no activity of any Product catalog import activity. In fact I never see any entry here despite it was syncing last week."
            }
        ]
    },
    {
        "Question_title":"Vertex AI training pricing",
        "Question_creation_date":"2022-03-09T22:00:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-training-pricing\/td-p\/402031\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":1,
        "Question_view_count":395,
        "Question_body":"I recently tried out Vertex AI and used AutoML to train my image classification model. I did train 3 sets and noticed from the billing that i was billed for 24 node hours. Is it so that i will be billed for the 8 node hours per model regardless if the training takes only one hour?",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-15T13:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I passed by the same situation. My training was finished in 45 minutes, but the billing is reporting 8 hours of usage, that was the specified budget. 8 hours is the minimum value allowed."
            },
            {
                "Answer_creation_date":"2022-07-15T19:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I also used it and the same issue is there with me too.\n\nMaybe gcloud server is down."
            }
        ]
    },
    {
        "Question_title":"Normalised Text from TTS",
        "Question_creation_date":"2022-07-13T01:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Normalised-Text-from-TTS\/td-p\/441871\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":51,
        "Question_body":"Is there a way for the Google TTS service to return the normalised text along with the generated speech file? For example, if \"This is 1993\" is sent to the service, can it return the verbalised for \"This is nineteen ninety three\"?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes, you can verbalize the year like ordinal numbers or cardinal numbers. You can see this example:\n\nI can speak in cardinals. Your number is <say-as interpret-as=\"cardinal\">10<\/say-as>.\n\nOr I can speak in ordinals. You are <say-as interpret-as=\"ordinal\">10<\/say-as> in line.\n\n\u00a0\n\nHere is the official documentation about how Text-to-Speech synthesizes the text:"
            }
        ]
    },
    {
        "Question_title":"About the extended model \"phone_call\" of Speech-to-Text",
        "Question_creation_date":"2022-07-11T18:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/About-the-extended-model-quot-phone-call-quot-of-Speech-to-Text\/td-p\/441346\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":56,
        "Question_body":"I am using Speech-to-Text from a server application developed with Node.js using gRPC.When using the extended model phone_call in Japanese and recognizing it for a long time,\nThe voice recognition result of the intermediate result may be rewound, or if you think that it does not return for about 1 to 2 seconds, it may return at once in one sentence.I've incorporated the Speech-to-Text API into my C # app before, and I used the extended model phone_call as well, but I didn't see anything like this in my C # app.\nDo you know what is causing it?The API setting value (Recognition Config) is the same for both Node.js and C #.Thank you.(I am sorry if it is rude or inappropriate to you, since I use the online translation site.)",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can see this document about Speech-To-Text troubleshooting. It has information about unexpected results from speech recognition, and this document is about best practices."
            }
        ]
    },
    {
        "Question_title":"Vertex AI explain with a custom trained scikit-learn classification model",
        "Question_creation_date":"2022-06-30T09:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-explain-with-a-custom-trained-scikit-learn\/td-p\/436711\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":1,
        "Question_view_count":282,
        "Question_body":"Hi Google Community,I was wondering, has anyone been able to successfully train and deploy a custom trained scikit-learn classification model and deploy it to a vertex endpoint with the feature attribution through the explain endpoint working?Every time i define my instances, predictions and explanation_spec while uploading my model, i get errors on the endpoint for the :explain method. Specifically, i get '400 bad request' with no information on why it was a bad request.I am using the v1beta1 ai platform python SDK and also am using a custom basic serving container. The custom container works for :predict but :explain does not work. Is there some example code out there? Is scikit-learn not supported for feature attribution? Thanks! Ryan",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-14T16:51:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"For anyone looking back on this, i was able to use the following notebook to solve my problem. It seems we need to use encoding BAG_OF_FEATURES. I am not to sure why this is required, but it seems to have done the trick for me.\n\nhttps:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/community\/ml_ops\/stage4...\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-07-06T13:32:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"The easiest (and recommended) way to create a training application package uses gcloud to package and upload the application when you submit your training job.\n\nHere\u00a0you can see documentation that will guide you through all of the steps that you need to follow to implement your scikit trained model."
            },
            {
                "Answer_creation_date":"2022-07-14T16:51:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"For anyone looking back on this, i was able to use the following notebook to solve my problem. It seems we need to use encoding BAG_OF_FEATURES. I am not to sure why this is required, but it seems to have done the trick for me.\n\nhttps:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/community\/ml_ops\/stage4..."
            }
        ]
    },
    {
        "Question_title":"[Vertex AI] Bug - Failed to download file",
        "Question_creation_date":"2022-07-07T07:35:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Bug-Failed-to-download-file\/td-p\/439222\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":69,
        "Question_body":"Vertex AI recently fails to download any file greater than 30M. Any downloaded file will be trimmed at 30M. The download speed is also way slower recently (200k\/s). It was working a few days ago. (downloads files of 100+M at 5M\/s) Any ideas?",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-14T07:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can see this documentation about troubleshooting with vertex, it mentions working with files that are truncated or do not complete downloading and possible solutions."
            }
        ]
    },
    {
        "Question_title":"A100 ram limitations",
        "Question_creation_date":"2022-07-07T10:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/A100-ram-limitations\/td-p\/439296\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":71,
        "Question_body":"Can someone please help me understand why the best GPUs google offer (A100) have a fixed CPU RAM of 85GB (only 2x that of the GRAM) and all the other poorer GPU options can go over 300GB. It's terribly frustrating for large dataset training pipelines. Especially when mmdetection libraries don't work well on mutiple GPUs and would rather just use the 1",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-13T15:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The NVIDIA A100 GPU must use the a2 Machine series, the lower CPU that a `a2 Machine` is 85GB and the highest a2 machine memory is 1360GB.\n\nAlso, You can attach up to 257 TB of local storage to these machine types in this series for applications that require higher storage performance.\n\nYou can also use Optional local SSD support: you can get up to 3 TB of Local SSD with `a2 machine` types. This can be used as fast scratch disks or for feeding data into the A100 GPUs while preventing I\/O bottlenecks.\n\nYou can see further details about the `a2 Machine` series here."
            }
        ]
    },
    {
        "Question_title":"Using Vison ML via REST API",
        "Question_creation_date":"2022-07-06T02:03:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Using-Vison-ML-via-REST-API\/td-p\/438619\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":185,
        "Question_body":"I'm taking my first steps with Vision ML and using the REST interface (https:\/\/vision.googleapis.com\/v1\/files:annotate). As API key I provide the key from the Firebase project settings. In the Authorization Bearer, I supply the token from Firebase-Auth after sign-in.When accessing Annotate I get a 403 (Permission_Denied) error message back:\nError opening file: gs:\/\/######.appspot.com\/MyFile.tiff.The object is available in the corresponding bucket and it is not blocked due to the Firebase Storage rules.Can I pass a Firebase token in this REST interface at all?How do I make sure that the service account can access the storage?\n\nThank you for any hint\n\nAuthor of FB4D GitHub Project (A Delphi Library for access Firebase Services via REST).",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-11T10:07:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The issue seems to be with the permissions or the Firebase rules that are being used. Could you please share the permissions and Firebase rules that you are using?\u00a0\u00a0\u00a0\n\nHere is document that you can use for the Firebase security rules:\n\nhttps:\/\/firebase.google.com\/docs\/storage\/security\u00a0\n\nhttps:\/\/stackoverflow.com\/questions\/38671444\/user-does-not-have-permission-to-access-this-object-fir...\n\nHere is another document that you can use for the IAM permissions:\n\nhttps:\/\/cloud.google.com\/storage\/docs\/access-control\/iam-permissions\u00a0\n\nYou can also use a service account to authenticate to Firebase storage:\n\nhttps:\/\/stackoverflow.com\/questions\/72565059\/cloud-api-product-search-asked-for-storing-the-images-i..."
            },
            {
                "Answer_creation_date":"2022-07-12T01:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"That was also my first thought, so I have the rule that only a known user can use the storage, removed for all types of readers released.\n\nrules_version = '2';\nservice firebase.storage {\n  match \/b\/{bucket}\/o {\n    match \/testML\/{img} {\n      allow read: if true; \/\/ if request.auth != null;\n      allow write: if request.auth != null;\n    }\n  }\n}\n\nI suppose this rules out your first assumption.\n\nOn the second point, yes, I've also tried giving more privileges to the executing service account. In the Google Cloud Console, I see three other principals in addition to my email address as the owner. Which one is used by the ML vision Service?\n\n<ProjectID>@appspot.gserviceaccount.com\nfirebase-adminsdk-zog2s@<ProjectID>.iam.gserviceaccount.com\nfirebase-service-account@firebase-sa-management.iam.gserviceaccount.com\n\nI have already assigned \"Storage admin\" rights to all these 3 accounts. Unfortunately, this did not solve the problem.\n\nThank you for a further hint."
            }
        ]
    },
    {
        "Question_title":"Just curious, can I use cloud bigtable as a feature store instead of using vertex AI feature store?",
        "Question_creation_date":"2022-06-28T03:43:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Just-curious-can-I-use-cloud-bigtable-as-a-feature-store-instead\/td-p\/435633\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":237,
        "Question_body":"I am trying to migrate my features table stored in bigquery to a feature store with lower latency. I'm choosing whether I should make use of vertex AI feature store or just cloud bigtable.My features tables are <10MB, and it is used for real time prediction hence a database with low latency is sufficient.Im just wondering aside from pricing, and ease of exporting data (bigtable requires more steps than vertex ai feature store), what is the difference between the 2 options?Also, what type of database (eg: bigtable or redis?) is vertex AI feature store behind the scenes, when I am creating the feature store using the web UI?  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-04T15:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, Chiayi,\n\nThe main difference between these 2, is that Vertex AI Feature Store is not considered a database as such, it is more like a product that provides a centralized repository for organizing, storing, and serving ML features [1]. In the other hand, Cloud Bigtable is a scalable NoSQL database service for large analytical and operational workloads [2]. More about [1][2].\n\n[1] https:\/\/cloud.google.com\/vertex-ai\/docs\/featurestore\/overview\n[2] https:\/\/cloud.google.com\/bigtable\/docs\/overview"
            }
        ]
    },
    {
        "Question_title":"Can i show alias instead of voice name?",
        "Question_creation_date":"2022-06-22T23:31:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Can-i-show-alias-instead-of-voice-name\/td-p\/434016\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":114,
        "Question_body":"[ ko-KR-Wavenet-A ] This name is so awkward for me.Can i show alias instead of that voice name?like this. [ ko-KR-Wavenet-A ] -> [ Jinsung ]------------------------------------------------------I'm developing a web service that can edit videos on the web.I will provide Google TTS on that web service.I show the Google (source of the voice) on the side, just wanna alias.",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-01T13:43:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The issue you are facing is happening since somewhere within your code something is calling the API in that form and not on the one you are trying to do so, also google cloud community isn\u2019t the best place to make questions about coding, my recommendation for you would be that you post your question on StackOverflow."
            }
        ]
    },
    {
        "Question_title":"Memory issue",
        "Question_creation_date":"2022-06-21T02:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Memory-issue\/td-p\/433242\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud TPU",
            "Cloud Vision API",
            "Recommendations AI",
            "Speech-to-Text",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":221,
        "Question_body":"Hi friends, Iam facing this error recently - The replica workerpool0-0 ran out-of-memory and exited with a non-zero status of 137(SIGKILL). Kindly help me , i am using 800GB , still getting this error   ",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-29T07:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This error normally indicates an issue with the code rather than being an Out Of Memory Exception in the service side.\n\nIs there any other error that you can share that is showing in the VM logs?"
            }
        ]
    },
    {
        "Question_title":"Error uploading csv file to Vertex DataSets",
        "Question_creation_date":"2022-06-17T09:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-uploading-csv-file-to-Vertex-DataSets\/td-p\/432499\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":66,
        "Question_body":"Hi to allTrying to upload a .csv file to AutoMl for training.Not sure what Im doing wrong, I save the file as csv encode utf 8 and values separated by comma and with both cases getting the error that you will find in the next image.Do I need to upload the files to Cloud Storage or Google BigQuery before using them for training? When trying to create and train the model got the warning from the next image:",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-27T14:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This could be occurring because you have formatting errors in your dataset, could you trim newlines and extra white spaces\u00a0on your dataset, remember that Vertex wants the text inside of your CSV to look like the examples I'm sharing.\n\n\"this is a sentence, with a comma\", 0\n\nAlso which dataframe are you using? Are you for any chance using Pandas?"
            }
        ]
    },
    {
        "Question_title":"Google Translate API - Laotian Translation Failures",
        "Question_creation_date":"2022-06-13T12:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-API-Laotian-Translation-Failures\/td-p\/431021\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":1,
        "Question_view_count":101,
        "Question_body":"Description:    Inquiries: Code Example:Resulting Translation:",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-22T12:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you please raise an issue tracker, since I couldn\u2019t find any bugs regarding the outage you are presenting, it might be due to something you are doing, or could you please share your code.\n\nAlso note that the community maintains google translate."
            },
            {
                "Answer_creation_date":"2022-06-23T13:10:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I have just updated this with a code example and the resulting translations and bugs. Additionally, I have create an issue tracker here.\u00a0\n\nPlease let me know what else we can provide to help get this resolved, thanks!"
            }
        ]
    },
    {
        "Question_title":"Google Vision release notes",
        "Question_creation_date":"2022-06-14T00:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Vision-release-notes\/td-p\/431130\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":65,
        "Question_body":"From here https:\/\/cloud.google.com\/vision\/docs\/release-notes it says that there was an upgrade on OCR model for TEXT_DETECTION and DOCUMENT_TEXT_DETECTION. What is the recent model improvement compare to legacy model (is there some metrics used)?",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-21T15:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As part of the best effort, can I make a suggestion for you on modifying the model field of Feature object into either \"builtin\/legacy\" or \"builtin\/latest\". Though the OCR model will automatically be upgraded to the new model when there's an update on \"builtin\/stable\" (default). This means that google implemented the newest versions of TEXT_DETECTION and DOCUMENT_TEXT_DETECTION to work without a problem for future updates"
            }
        ]
    },
    {
        "Question_title":"Custom container in vertex workbench",
        "Question_creation_date":"2022-06-10T10:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Custom-container-in-vertex-workbench\/td-p\/430464\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":236,
        "Question_body":"I noticed that you can use a custom container from the container registry when creating user-managed notebook, but I couldn't find any documentation on the required configuration\/dockerfile specs for it to work with jupyterlab in a similar fashion to launcing a regular workbench environment (e.g. python 3). Should I open default jupyter lab port? anything else?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"1. Create the initial Dockerfile and run modification commands.\n\u00a0 To start, you create a Deep Learning Containers container using one of the available image types. Then use conda, pip, or Jupyter commands to modify the\u00a0 \u00a0container image for your needs, you can add extra packages when you create your custom container.\n\nFROM gcr.io\/deeplearning-platform-release\/tf-gpu:latest\nRUN pip install -y tensorflow\u00a0\n\n\u00a0 \u00a02.Build and push the container image.\n\u00a0 \u00a0Build the container image, and then push it to somewhere that is accessible to your Compute Engine service account.\n\nexport PROJECT=$(gcloud config list project --format \"value(core.project)\")\ndocker build . -f Dockerfile.example -t \"gcr.io\/${PROJECT}\/tf-custom:latest\"\ndocker push \"gcr.io\/${PROJECT}\/tf-custom:latest\"\n\n\n\nSpecify the container when launching the execution Custom container."
            }
        ]
    },
    {
        "Question_title":"AI scientist",
        "Question_creation_date":"2022-06-19T15:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AI-scientist\/td-p\/432867\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":44,
        "Question_body":"I'm from Ukraine. Therefore, I write with the help of a translator. I immediately apologize for any mistakes.I am a doctor. I am interested in many areas of science that are related to medicine. But because of their volume and complexity, it is impossible to learn by one person.I propose to create an AI that will analyze information on the Internet (video lectures, articles, books, audio books, images ...) and find relationships. For example, the electrophysical properties of DNA are analyzed through all known theories of physics. And a concrete example: Academician P. Garyaev's \"Linguistic Wave Genome\" through V. Atsyukovsky's \"Ether Theory\".This tool needs to be made multifunctional and accessible to all users. This will revolutionize science by combining all knowledge.\nIt is important that there is a convenient voice interface and a personal account where studies are saved.Thank you for attention. Sincerely, Sukhachov Denis.\u042f \u0441 \u0423\u043a\u0440\u0430\u0438\u043d\u044b. \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u044f \u043f\u0438\u0448\u0443 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0447\u0438\u043a\u0430. \u0421\u0440\u0430\u0437\u0443 \u0438\u0437\u0432\u0438\u043d\u044f\u044e\u0441\u044c \u0437\u0430 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0435 \u043e\u0448\u0438\u0431\u043a\u0438.\u042f \u0434\u043e\u043a\u0442\u043e\u0440. \u041c\u0435\u043d\u044f \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u0443\u044e\u0442 \u043c\u043d\u043e\u0433\u0438\u0435 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u043d\u0430\u0443\u043a\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u0432\u044f\u0437\u0430\u043d\u044b \u0441 \u043c\u0435\u0434\u0438\u0446\u0438\u043d\u043e\u0439. \u041d\u043e \u0438\u0437-\u0437\u0430 \u0438\u0445 \u043e\u0431\u044a\u0435\u043c\u0430 \u0438 \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u0438 \u0438\u0445 \u043d\u0435\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043e\u0441\u0432\u043e\u0438\u0442\u044c \u043e\u0434\u043d\u043e\u043c\u0443 \u0447\u0435\u043b\u043e\u0432\u0435\u043a\u0443.\u041f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u044e \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0418\u0418, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u0432 \u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442\u0435 (\u0432\u0438\u0434\u0435\u043e\u043b\u0435\u043a\u0446\u0438\u0438, \u0441\u0442\u0430\u0442\u044c\u0438, \u043a\u043d\u0438\u0433\u0438, \u0430\u0443\u0434\u0438\u043e\u043a\u043d\u0438\u0433\u0438, \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f...) \u0438 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u0438. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u0444\u0438\u0437\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430 \u0414\u041d\u041a \u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0432\u0441\u0435\u0445 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u0445 \u0444\u0438\u0437\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0442\u0435\u043e\u0440\u0438\u0439. \u0418 \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u044b\u0439 \u043f\u0440\u0438\u043c\u0435\u0440: \u00ab\u041b\u0438\u043d\u0433\u0432\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0432\u043e\u043b\u043d\u043e\u0432\u043e\u0439 \u0433\u0435\u043d\u043e\u043c\u00bb \u0430\u043a\u0430\u0434\u0435\u043c\u0438\u043a\u0430 \u041f. \u0413\u0430\u0440\u044f\u0435\u0432\u0430 \u0447\u0435\u0440\u0435\u0437 \u00ab\u0422\u0435\u043e\u0440\u0438\u044e \u044d\u0444\u0438\u0440\u0430\u00bb \u0412. \u0410\u0446\u044e\u043a\u043e\u0432\u0441\u043a\u043e\u0433\u043e.\u042d\u0442\u043e\u0442 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043c\u043d\u043e\u0433\u043e\u0444\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u044b\u043c \u0438 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u043c \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439. \u042d\u0442\u043e \u043f\u0440\u043e\u0438\u0437\u0432\u0435\u0434\u0435\u0442 \u0440\u0435\u0432\u043e\u043b\u044e\u0446\u0438\u044e \u0432 \u043d\u0430\u0443\u043a\u0435, \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u0432 \u0432\u0441\u0435 \u0437\u043d\u0430\u043d\u0438\u044f.\n\u0412\u0430\u0436\u043d\u043e \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0443\u0434\u043e\u0431\u043d\u043e\u0433\u043e \u0433\u043e\u043b\u043e\u0441\u043e\u0432\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441\u0430 \u0438 \u043b\u0438\u0447\u043d\u043e\u0433\u043e \u043a\u0430\u0431\u0438\u043d\u0435\u0442\u0430, \u0433\u0434\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u044e\u0442\u0441\u044f \u0437\u0430\u043d\u044f\u0442\u0438\u044f.\u0421\u043f\u0430\u0441\u0438\u0431\u043e \u0437\u0430 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435. \u0421 \u0443\u0432\u0430\u0436\u0435\u043d\u0438\u0435\u043c, \u0421\u0443\u0445\u0430\u0447\u0435\u0432 \u0414\u0435\u043d\u0438\u0441.",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-19T15:22:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I'm from Ukraine. Therefore, I write with the help of a translator. I immediately apologize for any mistakes.\n\nI am a doctor. I am interested in many areas of science that are related to medicine. But because of their volume and complexity, it is impossible to learn by one person.\n\nI propose to create an AI that will analyze information on the Internet (video lectures, articles, books, audio books, images ...) and find relationships. For example, the electrophysical properties of DNA are analyzed through all known theories of physics. And a concrete example: Academician P. Garyaev's \"Linguistic Wave Genome\" through V. Atsyukovsky's \"Ether Theory\".\n\nThis tool needs to be made multifunctional and accessible to all users. This will revolutionize science by combining all knowledge.\nIt is important that there is a convenient voice interface and a personal account where studies are saved.\n\nThank you for attention. Sincerely, Sukhachov Denis.\n\n\u042f \u0441 \u0423\u043a\u0440\u0430\u0438\u043d\u044b. \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u044f \u043f\u0438\u0448\u0443 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0447\u0438\u043a\u0430. \u0421\u0440\u0430\u0437\u0443 \u0438\u0437\u0432\u0438\u043d\u044f\u044e\u0441\u044c \u0437\u0430 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0435 \u043e\u0448\u0438\u0431\u043a\u0438.\n\n\u042f \u0434\u043e\u043a\u0442\u043e\u0440. \u041c\u0435\u043d\u044f \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u0443\u044e\u0442 \u043c\u043d\u043e\u0433\u0438\u0435 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u043d\u0430\u0443\u043a\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u0432\u044f\u0437\u0430\u043d\u044b \u0441 \u043c\u0435\u0434\u0438\u0446\u0438\u043d\u043e\u0439. \u041d\u043e \u0438\u0437-\u0437\u0430 \u0438\u0445 \u043e\u0431\u044a\u0435\u043c\u0430 \u0438 \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u0438 \u0438\u0445 \u043d\u0435\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u043e\u0441\u0432\u043e\u0438\u0442\u044c \u043e\u0434\u043d\u043e\u043c\u0443 \u0447\u0435\u043b\u043e\u0432\u0435\u043a\u0443.\n\n\u041f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u044e \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0418\u0418, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u0432 \u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442\u0435 (\u0432\u0438\u0434\u0435\u043e\u043b\u0435\u043a\u0446\u0438\u0438, \u0441\u0442\u0430\u0442\u044c\u0438, \u043a\u043d\u0438\u0433\u0438, \u0430\u0443\u0434\u0438\u043e\u043a\u043d\u0438\u0433\u0438, \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f...) \u0438 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u0438. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u0444\u0438\u0437\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430 \u0414\u041d\u041a \u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0432\u0441\u0435\u0445 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u044b\u0445 \u0444\u0438\u0437\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0442\u0435\u043e\u0440\u0438\u0439. \u0418 \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u044b\u0439 \u043f\u0440\u0438\u043c\u0435\u0440: \u00ab\u041b\u0438\u043d\u0433\u0432\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0432\u043e\u043b\u043d\u043e\u0432\u043e\u0439 \u0433\u0435\u043d\u043e\u043c\u00bb \u0430\u043a\u0430\u0434\u0435\u043c\u0438\u043a\u0430 \u041f. \u0413\u0430\u0440\u044f\u0435\u0432\u0430 \u0447\u0435\u0440\u0435\u0437 \u00ab\u0422\u0435\u043e\u0440\u0438\u044e \u044d\u0444\u0438\u0440\u0430\u00bb \u0412. \u0410\u0446\u044e\u043a\u043e\u0432\u0441\u043a\u043e\u0433\u043e.\n\n\u042d\u0442\u043e\u0442 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043c\u043d\u043e\u0433\u043e\u0444\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u044b\u043c \u0438 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u043c \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439. \u042d\u0442\u043e \u043f\u0440\u043e\u0438\u0437\u0432\u0435\u0434\u0435\u0442 \u0440\u0435\u0432\u043e\u043b\u044e\u0446\u0438\u044e \u0432 \u043d\u0430\u0443\u043a\u0435, \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0438\u0432 \u0432\u0441\u0435 \u0437\u043d\u0430\u043d\u0438\u044f.\n\u0412\u0430\u0436\u043d\u043e \u043d\u0430\u043b\u0438\u0447\u0438\u0435 \u0443\u0434\u043e\u0431\u043d\u043e\u0433\u043e \u0433\u043e\u043b\u043e\u0441\u043e\u0432\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441\u0430 \u0438 \u043b\u0438\u0447\u043d\u043e\u0433\u043e \u043a\u0430\u0431\u0438\u043d\u0435\u0442\u0430, \u0433\u0434\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u044e\u0442\u0441\u044f \u0437\u0430\u043d\u044f\u0442\u0438\u044f.\n\n\u0421\u043f\u0430\u0441\u0438\u0431\u043e \u0437\u0430 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435. \u0421 \u0443\u0432\u0430\u0436\u0435\u043d\u0438\u0435\u043c, \u0421\u0443\u0445\u0430\u0447\u0435\u0432 \u0414\u0435\u043d\u0438\u0441."
            }
        ]
    },
    {
        "Question_title":"BigQuery ARIMA Model - What changed?",
        "Question_creation_date":"2022-05-09T12:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/BigQuery-ARIMA-Model-What-changed\/td-p\/421507\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":7,
        "Question_upvote_count":0,
        "Question_view_count":113,
        "Question_body":"I have published an open source project using the ARIMA model available in Big Query to predict the price of BTC using a free API.The results are displayed in a Datastudio dashboard.Something changed on the 28th of March of 2022. I suggest selecting the date range: from 2022-03-26 to 2022-03-31.I failed to find the answer in any of Google's documentation.Does anyone know what changed?Regards,",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-12T13:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello, I searched for documentation that I could share for your case but I couldn't find anything as you mentioned. What you could do is raise an issue tracker and wait for them to tell you an in-depth reason why it isn\u2019t working."
            },
            {
                "Answer_creation_date":"2022-05-13T06:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi @Eduardo_Ortiz\u00a0,\n\nThank you for your answer. How can I raise an issue tracker?\n\nThank you!"
            },
            {
                "Answer_creation_date":"2022-05-13T07:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello\u00a0@CaueBertolino\u00a0\n\nNo problem, you can raise an issue tracher in the next link\n\nhttps:\/\/issuetracker.google.com\/"
            },
            {
                "Answer_creation_date":"2022-05-16T09:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you,\u00a0@Eduardo_Ortiz.\n\nI have raised an issue tracker, I will post the solution here once I have an answer."
            },
            {
                "Answer_creation_date":"2022-06-15T09:43:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Caue, was your issue tracker resolved?"
            },
            {
                "Answer_creation_date":"2022-06-17T03:08:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0@Eduardo_Ortiz,\u00a0thanks for following up.\n\nNo answer yet on the issue tracker. Please, find the link for the issue created here:\u00a0https:\/\/issuetracker.google.com\/issues\/232742210\n\nThanks,"
            },
            {
                "Answer_creation_date":"2022-06-17T06:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"No problem\u00a0@CaueBertolino\n\nThank you for providing the issuetracker link, i'll keep an eye on it."
            }
        ]
    },
    {
        "Question_title":"Node hours vs actual time",
        "Question_creation_date":"2022-06-16T01:10:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Node-hours-vs-actual-time\/td-p\/431897\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":153,
        "Question_body":"What is meant by node hours in VertexAI?I set the budget in VertexAI AUtoML to a 1 node hour but my model has been training for 1 hr and 30+ minutes. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-16T01:10:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What is meant by node hours in VertexAI?\n\nI set the budget in VertexAI AUtoML to a 1 node hour but my model has been training for 1 hr and 30+ minutes."
            }
        ]
    },
    {
        "Question_title":"NLP Classification Categories",
        "Question_creation_date":"2022-06-07T11:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/NLP-Classification-Categories\/td-p\/429420\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "Cloud Natural Language API",
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":75,
        "Question_body":"When using the NLP API and in particular the documents.classifyText, it will obviously be classified under one of the categories listed here. My question is, do we know what was used to create these categories? Were they created from different datasets\/corpora like Wikipedia, Gigaword, and Freebase? Does the Word2Vec term embedding relate to category embeddings at all? Any information, references or resources would be greatly appreciated.",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-13T12:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"By using NLP, text classification can automatically analyze text and then assign a set of predefined tags or categories based on its context. NLP is used for sentiment analysis, topic detection, and language detection. There are mainly three text classification approaches.\n\n\u00a0\n\nRule-based System,\nMachine System\nHybrid System."
            }
        ]
    },
    {
        "Question_title":"Authentication for the Document AI",
        "Question_creation_date":"2022-06-03T10:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Authentication-for-the-Document-AI\/td-p\/428530\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":60,
        "Question_body":"First off, please be kind, as I'm not a developer and may struggle with some basics concepts.\n\nI'm trying to build a AI Invoice reader to collect invoice data in a spreadsheet, using Integromat \/ make.com (no-code platform) and Google Cloud Services.\nUsually, there are integrations for what I need in Integromat or I use simple REST calls. \n\nWith the Document AI, afaik I have to use OAuth. I have my \"processor\" and the I've been searching the Google Cloud documentation for a while, but for a non-dev it's quite confusing. Where can I find the two URLs needed?\n\nThank you very much for your help!",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-10T14:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can see this post[1] you can see here how they get the environment endpoint that I think that what you mean by Authorize URI also here is a step on how to get the Access Token (Token URI) additionally the step to get the access token is here in the documentation[2] you have to use the Cloud SDK and use the following command:\n\n\u00a0 \u00a0 - gcloud auth application-default print-access-token\n\n[1]https:\/\/clincher.medium.com\/create-a-document-ai-service-rest-api-processor-in-google-cloud-2710f583...\u00a0\n\n[2]https:\/\/cloud.google.com\/document-ai\/docs\/setup#auth-test"
            }
        ]
    },
    {
        "Question_title":"Idle shutdown for user-managed notebook (vertex-AI)",
        "Question_creation_date":"2022-06-02T07:10:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Idle-shutdown-for-user-managed-notebook-vertex-AI\/td-p\/428171\/jump-to\/first-unread-message",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":188,
        "Question_body":"There are two types of notebooks in Vertex-AI1) managed notebook: https:\/\/cloud.google.com\/vertex-ai\/docs\/workbench\/managed\/introduction2) user-managed notebook: https:\/\/cloud.google.com\/vertex-ai\/docs\/workbench\/user-managed\/introductionI see that the former has a useful function called \"idle shutdown\" that help manage costs: managed notebooks instances shut down after being idle for a specific time period by default.Why we didn't make it available for user-managed notebook as well? Thanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-02T22:36:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the feedback here. We are aware of the request and this is further to prioritize this work. Happy to get back when we have a concrete plan for this feature."
            }
        ]
    },
    {
        "Question_title":"Google cloud transcription API",
        "Question_creation_date":"2022-05-26T21:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-cloud-transcription-API\/td-p\/426546\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API",
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":71,
        "Question_body":"I would like to calculate the time duration for every speaker in a two way conversation call with speaker tag, transcription, time stamp of speaker duration and confidence of it.For example: I have mp3 file of a customer care support with 2 speaker count. I would like to know the time duration of the speaker with speaker tag, transcription and confidence of the transcription.I am facing issues with end time and confidence of the transcription. I'm getting confidence as 0 in transcription and end time is not appropriate with actual end time.audio link: https:\/\/drive.google.com\/file\/d\/1OhwQ-xI7Rd-iKNj_dKP2unNxQzMIYlNW\/view?usp=sharing ",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-02T15:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, we noticed that you posted the same question in StackOverflow, and since this seems like an issue in your code, I encourage you to follow this up in that forum."
            }
        ]
    },
    {
        "Question_title":"cloud vision API",
        "Question_creation_date":"2022-05-23T08:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/cloud-vision-API\/td-p\/425445\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":123,
        "Question_body":"Hello everyone,\nMy question is really hypothetical.  I am right now using Cloud vision api with feature web detection. Desc: Detect topical entities such as news, events, or celebrities within the image, and find similar images on the web using the power of Google Image Search.Does profile login effects the results that web detection will return. For example if I type in google search python, I will get python programming language, while my mum will snake. Does the same logic works for cloud vision API web detection ? \n\nWhy this question even raised, because same image executed from 2 different profiles ( I have 2 accounts on cloud Vision API) the model return different probabilities. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-30T10:25:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes, it is indeed an intended behavior getting different results even if you use the same image.\n\nThe API returns matching results with their respective scores. The scenario you are experiencing would entail that the scores are relatively close to one another and the API cannot properly select which is a better representation of the image being provided. For more accurate results, we would advise using product reference images with bounding poly coordinates[1].\n\n[1]https:\/\/cloud.google.com\/vision\/product-search\/docs\/tutorial#5_create_a_products_reference_image\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-05-30T10:25:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes, it is indeed an intended behavior getting different results even if you use the same image.\n\nThe API returns matching results with their respective scores. The scenario you are experiencing would entail that the scores are relatively close to one another and the API cannot properly select which is a better representation of the image being provided. For more accurate results, we would advise using product reference images with bounding poly coordinates[1].\n\n[1]https:\/\/cloud.google.com\/vision\/product-search\/docs\/tutorial#5_create_a_products_reference_image"
            },
            {
                "Answer_creation_date":"2022-05-30T23:47:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Grateful for your answer Jose !"
            }
        ]
    },
    {
        "Question_title":"speech-to-text demo",
        "Question_creation_date":"2021-11-25T10:24:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/speech-to-text-demo\/td-p\/176523\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":1,
        "Question_view_count":230,
        "Question_body":" https:\/\/cloud.google.com\/speech-to-text\n\nspeech to text demo doesn't work for a while now ! annoying .. I'd like to play with it. Can you fix, please.  ",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-25T15:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for reporting this. I forwarded your issue to the product team and you can follow this thread\u00a0as all\u00a0further updates should occur there."
            },
            {
                "Answer_creation_date":"2022-05-26T06:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Google Cloud Text-to-Speech is not working again.\n\nthe language tab is not clickable"
            }
        ]
    },
    {
        "Question_title":"Text-to-Speech",
        "Question_creation_date":"2022-05-25T02:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Text-to-Speech\/td-p\/425961\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":1,
        "Question_view_count":56,
        "Question_body":"Hi every one, Google Text-to-Speech seems not to be working again",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-26T06:03:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"That's right.\n\nThe language tab is not clickable"
            }
        ]
    },
    {
        "Question_title":"The new languages are missing",
        "Question_creation_date":"2022-05-17T01:43:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/The-new-languages-are-missing\/td-p\/423648\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":89,
        "Question_body":"Google cloud translation have added new languages. About 24 new languages has been added to Google Translate. Very good job, well done. But they are not listed on this link.\nhttps:\/\/cloud.google.com\/translate\/docs\/languages\n\nI tried to access it using basic v2 API code, but no response came to my translation request. When will this new languages be available to be accessed by v2 APIs? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-18T16:00:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"These are the new 24 languages[1].\n\nIn that post there is a research paper[2] where you can see the codes it begins on page 57.\n\nThe document that you shared it is in an internal Work in Progress with no launch date yet.\n\n[1]https:\/\/blog.google\/products\/translate\/24-new-languages\/\u00a0\n\n[2]https:\/\/arxiv.org\/pdf\/2205.03983.pdf\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-05-18T16:00:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"These are the new 24 languages[1].\n\nIn that post there is a research paper[2] where you can see the codes it begins on page 57.\n\nThe document that you shared it is in an internal Work in Progress with no launch date yet.\n\n[1]https:\/\/blog.google\/products\/translate\/24-new-languages\/\u00a0\n\n[2]https:\/\/arxiv.org\/pdf\/2205.03983.pdf"
            },
            {
                "Answer_creation_date":"2022-05-22T09:33:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for the update. I hope they do it soon. That would be good."
            }
        ]
    },
    {
        "Question_title":"Imbalance DataSet for Tabular AutoML",
        "Question_creation_date":"2022-04-18T10:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Imbalance-DataSet-for-Tabular-AutoML\/td-p\/414630\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":182,
        "Question_body":"Hi, I would like to know if in case of having a tabular database,  with binary data (class 0 and Class 1), that has an imbalance between class 0 and class 1, as it occurs in scenarios of fraud in financial transactions.Does AutoML solves automatically the imbalance situation? Or is it possible to add SMOTE or ADASYN to the AutoML model?  Any comments to advice more than appreciated",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-21T09:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There are several ways of handling imbalanced datasets:\n\nUpsampling and\/or Downsampling: In case of Upsampling, instances from the minority classes are duplicated in the training dataset at random. In case of Downsampling, certain instances of the majority classes are randomly left out of the training dataset. Upsampling of minority class and downsampling of the majority class can be done at the same time.\n\n\nUpweighting and\/or Downweighting: In Upweighting, sample weight greater than 1 is given to instances from the minority classes. In case of Downweighting, sample weight less than 1 is given to instances from the majority classes. The sample weights are taken into account when computing the loss function. Upweighting and Downweighting can be used together.\n\n\nData Augmentation: In this approach, data augmentation techniques are used to generate synthetic instances of the minority class to better balance the training dataset."
            },
            {
                "Answer_creation_date":"2022-05-02T06:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Jos\u00e9 hi, thanks for your answer but is not very clear.....\n\nThe question is if I can upload a data set with imbalance situation to AutoML or I need to fix somehow the situation before uploading the data into AutoML or AutoML can handle in very good way Imbalance data sets?"
            },
            {
                "Answer_creation_date":"2022-05-20T04:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am also interested in the same question."
            }
        ]
    },
    {
        "Question_title":"When will Hebrew language be available in Text-To-Speech API?",
        "Question_creation_date":"2022-05-18T06:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/When-will-Hebrew-language-be-available-in-Text-To-Speech-API\/td-p\/424088\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":111,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-19T08:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There is no information about when Hebrew will be available in Cloud Text-to-Speech you can file a feature request in Issue Tracker[1].\n\n[1] https:\/\/issuetracker.google.com\/issues\/new?component=451645&template=1161363"
            }
        ]
    },
    {
        "Question_title":"Feature Store Calculations",
        "Question_creation_date":"2022-05-12T13:49:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Feature-Store-Calculations\/td-p\/422580\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":57,
        "Question_body":"Hi,I have a Google Colab notebook with some functions (Python) that been used to calculate the features for a model.The functions use as inputs data from an API.The question is if I can or should calculate the features inside a Features Store and feed the results to the Model?Or in which Instance do I need to make the calculations and then feed the results into the model?",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-17T11:05:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It is possible to use Vertex AI Features Store to Fetch the data, so you can use it as a part of the Vertex AI Workflow to train Custom or AutoML models in Vertex.\n\nYou can see here[1] the Vertex AI workflow.\n\n[1]https:\/\/cloud.google.com\/vertex-ai\/docs\/beginner\/beginners-guide#workflow"
            },
            {
                "Answer_creation_date":"2022-05-17T13:04:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for your comments\n\nAfter reading the documents, I understand that the data that should be\nstored in the Feature Store is \"static data\".\n\nBy static I mean data from previously loaded databases and not calculated\nwithin the Feature Store.\n\nFor example I wanted to add a simple average of the last 30 data entries\nobtained from an API that sends data in real time in 5 minute intervals I\nshould::\n\nConnect the API to the feature Store, store each data entry from the API\nand then calculate the average inside the Feature Store?\n\nOr should I connect the API to Goolge BiGQuery, store the data in Google\nBigQuery, calculate the average and then send the data to the model deploy\nin the end point?\n\nOr connect a google colab notebook to the API, perform the calculations,\nupload the Notebook to a container and send the data to the endpoint in\nwhich the model was deployed?\n\nAnce again thanks for your help"
            }
        ]
    },
    {
        "Question_title":"Vision AI labels",
        "Question_creation_date":"2022-05-12T13:17:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vision-AI-labels\/td-p\/422564\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":48,
        "Question_body":"Where can I find list of all labels what could be detected in Vision AI ?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can read this documentation\u00a0about labels with Vision AI."
            }
        ]
    },
    {
        "Question_title":"AutoML Features",
        "Question_creation_date":"2022-05-12T12:36:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-Features\/td-p\/422551\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":42,
        "Question_body":"HiAssume that I create a model using AutoML with 50 features from the Vertex AI Feature Store and after training I found that from the 50 original features, 10 has a very low incidence over the model.Looking to increase the accuracy, reduce the consumption of resources and increase the speed of the model:Do I need to remove the 10 features from the Feature Store and deploy the model to the endpoint?Should I retrain the model with the 40 features and deploy it to the end point?Any comments more than appreciated",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-17T08:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I wouldn't delete the features because there are some features that can be used to share, discover, and re-use ML features at scale, which can increase the velocity of developing and deploying new ML applications."
            }
        ]
    },
    {
        "Question_title":"Trying to do multiple voice files with speech-to-text",
        "Question_creation_date":"2022-05-11T18:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Trying-to-do-multiple-voice-files-with-speech-to-text\/td-p\/422295\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":57,
        "Question_body":"Hello.I'm someone who's trying to make speech-to-text work without being a coder in any way whatsoever. I have let's say hundreds of individual audio files and they go from 30 seconds to a minute and a half. The problem is that uploading them to the bucket makes it so there's hundreds of individual ones. And I need to create a transcriptions individually. what do I do? can I not just transcribe everything in one folder?",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-13T22:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It requires coding - you load files in a bucket (say in 'input' folder) and run a background job to produce a \"txt\" file for each using speech-to-text API (say in 'output' folder).\u00a0 If you have files formats such as mp4 then use transcoding. This is the step roughly."
            },
            {
                "Answer_creation_date":"2022-05-15T21:36:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Understood. But do you have any idea how I'd code that? Of course I am\u00a0 unfamiliar with how to code... but anyway no problem at all if you cannot help there."
            },
            {
                "Answer_creation_date":"2022-05-15T22:10:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Coding it will not be easy if you are not a programmer. It requires a bunch of technology and tools. Roughly steps would be:\n\n1. Using gsutil tool of the GCP, upload files to a bucket.\n\n2. Write a program to read file from the bucket and invoke\u00a0 Speech-to-Text API. It will require you to acquire an access-token (OAuth2).\u00a0\n\n3. If files are small then you could do 2 without uploading files to the bucket.\u00a0\n\nYou can find the example programs here:\u00a0https:\/\/cloud.google.com\/speech-to-text\/docs\/samples"
            }
        ]
    },
    {
        "Question_title":"Total Novice",
        "Question_creation_date":"2022-05-10T19:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Total-Novice\/td-p\/421957\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":41,
        "Question_body":"Friends,Can I submit a file for conversion from speech to text without having to learn computer coding - even if it is at a very simple level? Can I just submit the file somewhere for transcription?Thank You,Just, simply, a consumer",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes you can and I would also appreciate help.\n\nMake a bucket, go through the settings and be sure it's a private bucket.\n\nSearch up text to speech in the main screen. It's probably one audio channel and for hz you can either open the audio file with alt + enter to see if it shows you what the Hz is or use audacity audio software and load the file into audacity.\n\nAs someone who doesn't understand anything about code, my problem is that my audio files are and should all be contained individually, each in one file."
            },
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi ,\n\nYes you can do that. Just upload your audio file\u00a0 , click button and download your transcript audio file.\n\nhttps:\/\/cloud.google.com\/speech-to-text"
            }
        ]
    },
    {
        "Question_title":"Form Parsing in Document AI",
        "Question_creation_date":"2022-05-05T02:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Form-Parsing-in-Document-AI\/td-p\/420076\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":144,
        "Question_body":"Hi All,We are currently using Document AI for form parsing scanned documents and we are now required to capture the checkboxes data from the form.",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-06T16:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I think that you would find this laboratory that google offers helpful since it explain step by step how form parsing works within google Document AI."
            },
            {
                "Answer_creation_date":"2022-05-10T00:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for your response. I have gone through the lab course but still couldn't find answers on the checkbox count limitation of the Form-parsing using Document AI.\nIs that limitation due to Pricing? Can you please help me with this?"
            },
            {
                "Answer_creation_date":"2022-05-13T15:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I found this guide that you might found useful, i couldn't find any information about limitations, so i would say that it shouldn't limit you, or maybe the documentation wasn't processed succsesfully."
            }
        ]
    },
    {
        "Question_title":"Why is sample rate optional only for FLAC or WAV file and not other formats?",
        "Question_creation_date":"2022-04-21T05:49:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Why-is-sample-rate-optional-only-for-FLAC-or-WAV-file-and-not\/td-p\/415704\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_upvote_count":0,
        "Question_view_count":78,
        "Question_body":"So for example at my work we are using WEBM_OPUS encoding, which from what I understand, specificies the sample rate in audio stream metadata itself? Yet from here: https:\/\/cloud.google.com\/speech-to-text\/docs\/basics#sample-rates it says the field is only optional  for FLAC or WAV formats.And indeed, when I try the GSTT API with some example code (Streaming Recognition and a WEBM_OPUS encoded at 48000 sample rate), the GSTT actually accepts sample rates other than 48000 - and depending on the recognition model, produces different results depending on the sample rate selected!",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-06T13:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Did you try to put 8000 hz within your data that you are sending to speech-to-text? Answering your question those two files are optionals since they are the most commonly used."
            },
            {
                "Answer_creation_date":"2022-05-09T05:59:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What \"two files\"? ..."
            },
            {
                "Answer_creation_date":"2022-05-09T06:55:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I was refering to WAV and FLAC audio files"
            },
            {
                "Answer_creation_date":"2022-05-10T04:09:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes, it's optional for WAV and FLAC - but my question was about using WEBM_OPUS format..."
            },
            {
                "Answer_creation_date":"2022-05-13T12:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It's because google uses auto defined sample rates that are the next ones.\u00a0Sample rate must be one of 8000 Hz, 12000 Hz, 16000 Hz, 24000 Hz, or 48000 Hz, also you can see this documentation here."
            }
        ]
    },
    {
        "Question_title":"Why does Jupyter Notebooks not recognize changes in my .py files?",
        "Question_creation_date":"2022-05-09T11:24:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Why-does-Jupyter-Notebooks-not-recognize-changes-in-my-py-files\/td-p\/421489\/jump-to\/first-unread-message",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":20,
        "Question_body":"Hello, When working locally, I usually put routine tasks inside functions held in a .py file and import those.  When I need to make a change, I change the function, reimport and moving on with the main script.   GCP's jupyter instance does not recognize when I make the change an re-import the function.  I have to restart the kernel each time.  Is there a way around this?",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-09T11:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\u00a0\n\nWhen working locally, I usually put routine tasks inside functions held in a .py file and import those.\u00a0 When I need to make a change, I change the function, reimport and moving on with the main script.\u00a0\u00a0\n\n\u00a0\n\nGCP's jupyter instance does not recognize when I make the change an re-import the function.\u00a0 I have to restart the kernel each time.\u00a0 Is there a way around this?"
            }
        ]
    },
    {
        "Question_title":"Steps to get Real life data into the features section",
        "Question_creation_date":"2022-04-29T15:39:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Steps-to-get-Real-life-data-into-the-features-section\/td-p\/418695\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":34,
        "Question_body":"Hi, I already create a tabular classification model using AutoML. All ready have the features created in a Goolge colab and now I need to get the real life data from a Public API to feed the features, then pass the features into the Model and finally get the classifications.The question is are the steps and which tools should I use in order to connect to the API in order to receive the real time data? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-09T11:05:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I think you are looking for this documentation that can help you understand how you can create datasets and import the data into AutoML. The documentation will provide you with the steps you need to follow."
            }
        ]
    },
    {
        "Question_title":"Create an instance of TextToSpeechClient() and ApplicationDefaultCredentials ...",
        "Question_creation_date":"2022-05-01T16:07:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Create-an-instance-of-TextToSpeechClient-and\/td-p\/418964\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":146,
        "Question_body":"Hi Folks,My first post here. This was posted on stackoverflow without much feedback - it is a little specific to the TextToSpeechClient and using ApplicationDefaultCredentials.  The link to the stackoverflow article is below just for reference.https:\/\/stackoverflow.com\/questions\/72074724\/trying-to-create-an-instance-of-googles-class-texttospe...I'm attempting to Create an instance of TextToSpeechClient() and an getting an exception - Could not construct ApplicationDefaultCredentials. I was able to get the php sample code provided on your github site running from the command line. I'm now executing in a browser session on an apache server. I have added the putenv() function to set the GOOGLE_APPLICATION_CREDENTIALS value.Below is the code sample <?php\nheader(\"Content-Type: application\/json; charset=UTF-8\");\nheader(\"Access-Control-Allow-Methods: POST\");\nheader(\"Access-Control-Max-Age: 3600\");\nheader(\"Access-Control-Allow-Headers: Content-Type, Access-Control-Allow- Headers, Authorization, X-Requested-With\");require_once '\/home\/macgowan\/vendor\/autoload.php';\/\/ [START tts_synthesize_text]\nuse Google\\Cloud\\TextToSpeech\\V1\\AudioConfig;\nuse Google\\Cloud\\TextToSpeech\\V1\\AudioEncoding;\nuse Google\\Cloud\\TextToSpeech\\V1\\SsmlVoiceGender;\nuse Google\\Cloud\\TextToSpeech\\V1\\SynthesisInput;\nuse Google\\Cloud\\TextToSpeech\\V1\\TextToSpeechClient;\nuse Google\\Cloud\\TextToSpeech\\V1\\VoiceSelectionParams;putenv('GOOGLE_APPLICATION_CREDENTIALS=\/Users\/macgowan\/google_cloud\/service-account-text-to-speech-test-00.json');try\n{putenv('GOOGLE_APPLICATION_CREDENTIALS=\/Users\/macgowan\/google_cloud\/service-account-text-to-speech-test-00.json');\n\/\/ $client->useApplicationDefaultCredentials();$ip = getenv('GOOGLE_APPLICATION_CREDENTIALS');\nprintf(\"Get env var - GOOGLE_APPLICATION_CREDENTIALS: %s<br \/>\", $ip);$ip = getenv('APACHE_RUN_USER');\nprintf(\"Get env var - APACHE_RUN_USER: %s<br \/>\", $ip);\/\/ *** FAILS HERE ***\n$client = new TextToSpeechClient();$text = \"Hello Joe\";print('Set input text using the SynthesisInput() object' . PHP_EOL);\n$input_text = (new SynthesisInput())\n->setText($text);$voice = (new VoiceSelectionParams())\n->setLanguageCode('en-US')\n->setSsmlGender(SsmlVoiceGender::FEMALE);$audioConfig = (new AudioConfig())\n->setAudioEncoding(AudioEncoding::MP3);$response = $client->synthesizeSpeech($input_text, $voice, $audioConfig);\n$audioContent = $response->getAudioContent();file_put_contents('\/home\/macgowan\/output.mp3', $audioContent);\n$client->close();\n}\ncatch (Exception $e)\n{\nprintf(\"Caught exception: %s<br \/>\", $e->getMessage());\n}\n?>Thanks for your help - Chris   ",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-09T09:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, this might be occurring because you don\u2019t have the proper composer package in your composer json file. You need to have the next package installed within your JSON..\n\n{\n\n\u00a0 \u00a0\u00a0\"require\": {\u00a0\n\n\u00a0 \u00a0 \u00a0 \u00a0\"google\/cloud-text-to-speech\": \"^1.0\"\n\n\u00a0 \u00a0}\n\n\u00a0}"
            }
        ]
    },
    {
        "Question_title":"translate api may give different translation variations in response to the same request",
        "Question_creation_date":"2022-04-27T05:54:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/translate-api-may-give-different-translation-variations-in\/td-p\/417588\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":1,
        "Question_view_count":49,
        "Question_body":"I am using Google cloud translate api v3 NMT to translate sentences from English to Hebrew. I noted that for the same source sentence I may get slightly different results on subsequent calls. I see these going back and forth in a short time frame, so it is NOT a result of the model being updated. For my application I would like to either get all possible variations or at least get reproducible results. Is there an option to get all variations or to set the random seed? Or must I resort to multiple polling and caching on my side?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, what I would recommend to you is, as you said in your second question, to implement multiple polling and store it on your side so that you have a better knowledge of what's going on on your end."
            }
        ]
    },
    {
        "Question_title":"Vertex AI Custom Training Job Container not finding my module: Error while finding module for '...'",
        "Question_creation_date":"2022-04-25T02:48:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Custom-Training-Job-Container-not-finding-my-module\/td-p\/416620\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":152,
        "Question_body":"Hello,I have a PyTorch training job that I am packaging in a Python software distribution (.tar.gz file). I upload the sdist to a GCS bucket and run it in a container using the gcloud ai custom-jobs create CLI.Up until a couple of weeks ago this worked fine but in recent days my jobs consistently fail with messages like these appearing in their logs:Running command: python3 -m MyPackage.MyModule --job-dir=gs:\/\/my-bucket\/my-job\/model --model-name=my-model\n\n\/opt\/conda\/bin\/python3: Error while finding module specification for 'MyPackage.MyModule' (ModuleNotFoundError: No module named 'MyPackage.MyModule') MyPackage.MyModule is my module where my training code runs, naturally.As I've mentioned above the same procedure worked until recently. There have not been any changes to it and I can clearly see that MyModule.py is located under MyPackage in my .tar.gz file.The container image that I am using is us-docker.pkg.dev\/vertex-ai\/training\/pytorch-gpu.1-9:latest and from what I can tell it has not changed since the time I successfully used it before.Why is the Vertex AI container not finding my training module? How can I further debug and fix this?",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-06T15:03:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Check this documentation[1] to see how to fix ModuleNotFoundError.\n\n[1] https:\/\/towardsdatascience.com\/how-to-fix-modulenotfounderror-and-importerror-248ce5b69b1c"
            },
            {
                "Answer_creation_date":"2022-05-08T05:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Jose,\n\nThank you for trying to help. Alas, I've already followed all suggestions in the linked article, to no avail. There is something funky going on between the Vertex AI python code that looks for my module and the way I structured my .tar.gz. At this point, without being able to access the Vertex AI code, I don't see how to debug this."
            }
        ]
    },
    {
        "Question_title":"Appsheet with Google Cloud Vision",
        "Question_creation_date":"2022-04-26T05:00:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Appsheet-with-Google-Cloud-Vision\/td-p\/417105\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":60,
        "Question_body":"Hello,\n\nHow can I integrate Google Cloud Vision in Appsheet to create  a Facial recognition CHECK IN system where the staff can just take photos of themselves on a device and the image captured is compared with the stored image in the Google Drive. If the Face is detected or matched with the stored image, it should automatically CHECK IN OR CHECK OUT the staff.\n\nPlease kindly help.",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-06T16:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Please have a look into this documentation that appsheet offers."
            }
        ]
    },
    {
        "Question_title":"Product Specifications or Product Recommendation in the Support Section",
        "Question_creation_date":"2022-04-21T08:07:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Product-Specifications-or-Product-Recommendation-in-the-Support\/td-p\/415770\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":38,
        "Question_body":"HiAny ones knows if I could get Product Specifications or Product Recommendation in the Support Section from Google Cloud: ",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-06T07:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, you should be able to get product specifications and product recommendations every time you contact Google support and also chat with a support agent via chat."
            }
        ]
    },
    {
        "Question_title":"Connect API to AutoML Model",
        "Question_creation_date":"2022-05-02T06:33:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Connect-API-to-AutoML-Model\/td-p\/419081\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":111,
        "Question_body":"Hi, I already have the classification model created using AutoML, I have a Google Colab file in which I calculate the different features based from the information received from a public APIWhat Google tool should I use to be able to connect Google Vertex to the API?What module \/ section of Vertex AI should I connect the API to in order to receive live data?To which instance \/ section should I upload the Google Colab notebook with the calculations of the features?What tool should I use to connect the model created in AutoML to the feature data?Finally, if I wanted to export the predictions to an API, which tool should I use?Thanks alot for any help you may provide",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-05T14:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The next Google tutorial will provide you a step by step guide in how to connect the API into AutoML.\n\nIt explains how you can connect the vision API into AutoML, how yo can install your custom library and also how to upload them."
            }
        ]
    },
    {
        "Question_title":"Deploying AutoML tabular model changes feature column types to text",
        "Question_creation_date":"2022-03-15T03:21:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Deploying-AutoML-tabular-model-changes-feature-column-types-to\/td-p\/403658\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":1,
        "Question_view_count":49,
        "Question_body":"I\u2019ve trained an AutoML tabular model using a pretty simple CSV file of numeric data. When I ran the training I ensured each feature column was set as numeric. When viewing the column meta data of the trained model, all columns show as numeric. However, when I deploy the model they all show as text and will only accept strings. What am I doing wrong?",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-29T07:33:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The possible cause may be the incorrect format of the used data type .You can find some examples of the the valid and invalid numeric formats in documentation [1] that can be used in AutoML Tables dataset.\n\n[1] https:\/\/cloud.google.com\/automl-tables\/docs\/data-types#numeric"
            }
        ]
    },
    {
        "Question_title":"Removed voices from German standard text to speech (tts)",
        "Question_creation_date":"2022-02-17T06:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Removed-voices-from-German-standard-text-to-speech-tts\/td-p\/394397\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":124,
        "Question_body":"We have a problem related to the Cloud text to speech API.\nWe develop an AI based chatbot system, and we have lot of different chatbot which speak in English and German also.\nWe are using two different voices 'de-DE-Standard-B' (male) and 'de-DE-Standard-C' (female) in the case of German bots, but both bots speak in same vois at now.\nWe detected the problem at 2022-02-16.Could you give me some information about this problem?",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-22T12:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI understand you have selected 2 different German Language voices[ 'de-DE-Standard-B' (male) and 'de-DE-Standard-C' (female) ] from the list of available voices[0] that can be used for synthetic speech, however both voices are coming out the same.\n\nAs you have rightly indicated, these voices are different. However, it will be nice to understand how you are creating the voice audio files[1]. As indicated in the article[1], it is not only possible selecting a unique voice, you can also make certain modifications depending on your implementation. For example, you can modulate the output in pitch, volume, speaking rate, and sample rate. If you are using SSML in your audio synthesis, you would even have a finer-grain control over how the audio output.\n\nSo, please give more insight to your setup and how these voices are selected.\n\n\u00a0\n\n[0]https:\/\/cloud.google.com\/text-to-speech\/docs\/voices\n\n[1]https:\/\/cloud.google.com\/text-to-speech\/docs\/create-audio#text-to-speech-ssml-java"
            },
            {
                "Answer_creation_date":"2022-04-21T14:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Oakinlaja - There seem to be an issue when using SSML to read date using the German langauge. It plays randomly different message. Please help. This is the below request to Google speech to text.\n\n\u00a0\n\nTTS Request JSON :: {\"voice\":{\"ssmlGender\":\"MALE\",\"name\":\"de-DE-Wavenet-E\",\"languageCode\":\"de-DE\"},\"input\":{\"ssml\":\"<speak><say-as interpret-as=\\\"date\\\" format=\\\"yyyymmdd\\\"> 20220506<\\\/say-as><\\\/speak>\"},\"audioConfig\":{\"sampleRateHertz\":8000,\"volumeGainDb\":0,\"speakingRate\":1,\"audioEncoding\":\"LINEAR16\",\"pitch\":0,\"effectsProfileId\":[\"telephony-class-application\"]}}"
            },
            {
                "Answer_creation_date":"2022-04-21T14:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"In English it works correctly. For english , i pass languageCode : En-US"
            }
        ]
    },
    {
        "Question_title":"Google assistant and cloud speech API not working",
        "Question_creation_date":"2022-04-06T04:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-assistant-and-cloud-speech-API-not-working\/td-p\/410871\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":94,
        "Question_body":"I am having problem using Google cloud platform.I bought Google AIY voice kit from AliExpress.com. I discovered it was an old version. Two weeks ago, I used Etcher to flash aiyprojects-2021-04-02.img.xz from GitHub on an SD card and set up my voice kit. Hardware testing was good. I then created a project, named \u201cVoice Kit\u201d, on google cloud following directions given on \"aiyprojects.withgoogle.com\/voice-v1\/\". I had the following experience:It would be appreciated if I could be educated on the following:",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-20T18:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI see you have concerns relating to the Google AIY Projects and your configurations. I think your Questions will be better supported by the Google AIY Support team[0]. The help page[1] also includes help links on various forums that may have the type of information that you need. For example, your Question about your Question 2, you explained that you are unsure which of the Cloud Speech APIs to use. Whether the Cloud speech-to-text API or the Cloud text-to speech API? Well, the help page seems to include an hyperlink[2] for the Cloud Speech API to use.\n\nAgain, I think your Questions will be better supported by the Google AIY Support team.\n\nI hope this information helps.\n\n[0]support-aiyprojects@google.com.\n[1]https:\/\/aiyprojects.withgoogle.com\/help\/\n[2]https:\/\/cloud.google.com\/speech-to-text\/docs\/"
            }
        ]
    },
    {
        "Question_title":"Google Cloud Platform - Vertex AI - Workbench JupyterLab - Spark\/Hadoop - JAVA_HOME is not set error",
        "Question_creation_date":"2022-04-13T15:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-Platform-Vertex-AI-Workbench-JupyterLab-Spark\/td-p\/413482\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":382,
        "Question_body":"Hi All,I am trying to connect to a SparkSession on Vertex AI's Workbench JupyterLab, but receive this error. Locally, my JAVA_HOME system environments and path environments are already set, and can work when I run Jupyter locally. But only on Vertex AI's Workbench JupyterLab I get this error. Code: \n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n.appName('Jupyter BigQuery Storage')\\\n.config('spark.jars', 'gs:\/\/spark-lib\/bigquery\/spark-bigquery-latest_2.12.jar') \\\n.getOrCreate()Full Error:Do let me know if you have advice or help, thank you!",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-20T13:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You would need to have Java installed on your Mac, Linux or Windows, without Java installation & not having JAVA_HOME environment variable set with Java installation path or not having PYSPARK_SUBMIT_ARGS, you would get this Exception.\n\n\u00a0\n\nYou need to Set PYSPARK_SUBMIT_ARGS with master, this resolves Exception: Java gateway process exited before sending the driver its port number.\n\n\u00a0\n\nexport PYSPARK_SUBMIT_ARGS=\"--master local[3] pyspark-shell\"\n\nvi ~\/.bashrc , add the above line and reload the bashrc file using source ~\/.bashrc\n\n\u00a0\n\nIn case the issue is still not\u00a0 resolved, check your Java installation and JAVA_HOME environment variable.\n\n\u00a0\n\nYou can see this troubleshooting documentation[1].\n\n\n[1] https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/troubleshooting"
            }
        ]
    },
    {
        "Question_title":"Deep Reinforcement Learning",
        "Question_creation_date":"2022-04-13T06:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Deep-Reinforcement-Learning\/td-p\/413277\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":73,
        "Question_body":"Hi is it possible to implement Deep Reinforcement Learning for structured data frames? If son can someone help me with an example?",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-20T13:38:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Deep Learning delivers a seamless notebook experience with integrated support for JupyterLab[1], so you can load data frames as a normal notebook. Additionally, it depends on what instance you are using Deep Learning.\u00a0\n\nIf you are using TensorFlow, you can see this[2] to know how to load a data frame to TensorFlow.\n\nIf you are using Pytorch tensor, you can see this[3] example of how to load the data frame.\n\n\u00a0\n\n[1] https:\/\/cloud.google.com\/deep-learning-vm\/docs\/jupyter\u00a0\n\n[2] https:\/\/www.tensorflow.org\/tutorials\/load_data\/pandas_dataframe\u00a0\n\n[3] https:\/\/stackoverflow.com\/a\/50308132\/16929358\u00a0\n\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-04-20T13:38:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Deep Learning delivers a seamless notebook experience with integrated support for JupyterLab[1], so you can load data frames as a normal notebook. Additionally, it depends on what instance you are using Deep Learning.\u00a0\n\nIf you are using TensorFlow, you can see this[2] to know how to load a data frame to TensorFlow.\n\nIf you are using Pytorch tensor, you can see this[3] example of how to load the data frame.\n\n\u00a0\n\n[1] https:\/\/cloud.google.com\/deep-learning-vm\/docs\/jupyter\u00a0\n\n[2] https:\/\/www.tensorflow.org\/tutorials\/load_data\/pandas_dataframe\u00a0\n\n[3] https:\/\/stackoverflow.com\/a\/50308132\/16929358"
            }
        ]
    },
    {
        "Question_title":"Pipeline failed to deploy model: \"service_account cannot be specified for deploying AutoML models\"",
        "Question_creation_date":"2022-04-11T12:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Pipeline-failed-to-deploy-model-quot-service-account-cannot-be\/td-p\/412645\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":92,
        "Question_body":"I made a pipeline that almost mirrors step 6 of Intro to Vertex Pipelines which has managed to get past every step up until the model deployment side of things. The code snippet for my model deploy op is here:   And the associated error message in the logs for the deployment part of the pipeline was:RuntimeError: Failed to create the resource. Error: {'code': 400, 'message': 'service_account cannot be specified for deploying AutoML Models.', 'status': 'FAILED_PRECONDITION'} Does it have to do with a specific permission I need to give my service account? I don't know how to interpret this error.  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-18T14:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You are sure you can specify a service account here like this? Do you have any reference that uses service account here?\n\n[1] https:\/\/cloud.google.com\/blog\/topics\/developers-practitioners\/use-vertex-pipelines-build-automl-..."
            }
        ]
    },
    {
        "Question_title":"Over fitting during RL or DRL when using tabular data",
        "Question_creation_date":"2022-04-18T10:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Over-fitting-during-RL-or-DRL-when-using-tabular-data\/td-p\/414640\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Document AI",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":73,
        "Question_body":"HiI will like to know how the Vertex Api handles or warns about models with over fitting conditions when using Reinforcement Learning or Deep Reinforcement Learning ? If so can you help me with the documents where you explain this situations when using the Vertex Api for tabular dataframes?",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-18T10:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\n\nI will like to know how the Vertex Api handles or warns about models with over fitting conditions when using Reinforcement Learning or Deep Reinforcement Learning ? If so can you help me with the documents where you explain this situations when using the Vertex Api for tabular dataframes?"
            }
        ]
    },
    {
        "Question_title":"Vertex AI Training: Auto-packaged Custom Training Job Yields Very Large Docker Image",
        "Question_creation_date":"2022-02-27T02:57:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Training-Auto-packaged-Custom-Training-Job-Yields-Very\/td-p\/397685\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":441,
        "Question_body":"Hello,I am trying to run a Custom Training Job in the Vertex AI Training service.The job is based on a tutorial for that fine-tuning a pre-trained BERT model (from HuggingFace).When I use the `gcloud` CLI tool to auto-package my training code into a Docker image and deploy it to the Vertex AI Training service like so:$BASE_GPU_IMAGE=\"us-docker.pkg.dev\/vertex-ai\/training\/pytorch-gpu.1-7:latest\"\n$BUCKET_NAME = \"my-bucket\"gcloud ai custom-jobs create `\n--region=us-central1 `\n--display-name=fine_tune_bert `\n--args=\"--job_dir=$BUCKET_NAME,--num-epochs=2,--model-name=finetuned-bert-classifier\" `\n--worker-pool-spec=\"machine-type=n1-standard-4,replica-count=1,accelerator-type=NVIDIA_TESLA_V100,executor-image-uri=$BASE_GPU_IMAGE,local-package-path=.,python-module=trainer.task\"... I end up with a Docker image that is roughly 18GB (!) and takes a very long time to upload to the GCP registry.Granted the base image is around 6.5GB but where do the additional >10GB come from? Is there a way for me to avoid incurring the added size increase?Please note that my job loads the training data using the `datasets` Python package at run time and AFAIK does not include it in the auto-packaged docker image. Thanks,\nurig",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-17T08:03:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Ismail,\n\n\u00a0\n\nThank you for your help.\n\nI've checked and to the best of my knowledge there are no data or log files being picked up into my custom docker image.\n\nAccording to an answer that I've received on stackoverflow.com, it's likely that the 18GB size that I'm seeing is the size of my image after extraction. Apparently the ~6.8GB size is for the image compressed.\n\n\u00a0\n\nCheers,\n\n@urig\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-04-07T10:36:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Urig,\n\nIs it possible that you have local files in the current directory such as data or log files that are getting picked up, specifically this line local-package-path=.\n\nIf this persists, I highly recommend for you to file a Public Issue\u00a0as you can high a private thread created to you and we would be able to further support you there."
            },
            {
                "Answer_creation_date":"2022-04-17T08:03:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Ismail,\n\n\u00a0\n\nThank you for your help.\n\nI've checked and to the best of my knowledge there are no data or log files being picked up into my custom docker image.\n\nAccording to an answer that I've received on stackoverflow.com, it's likely that the 18GB size that I'm seeing is the size of my image after extraction. Apparently the ~6.8GB size is for the image compressed.\n\n\u00a0\n\nCheers,\n\n@urig"
            }
        ]
    },
    {
        "Question_title":"Optimization Variables \/ Inputs",
        "Question_creation_date":"2022-04-12T07:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Optimization-Variables-Inputs\/td-p\/412877\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":41,
        "Question_body":"Hi is it possible to implement Optimization Problems using AutoML or other Google Cloud application different than regular google Colab \/ Jupiter Notebooks? ",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you try creating AutoML models using the Command Line using [1]?\n\n[1] https:\/\/cloud.google.com\/vertex-ai\/docs\/training\/automl-api#train_an_automl_model_using_the_api"
            },
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, saw the link but did not found anything related to optimization\nprocess, is it possible to send more detail information?\n\n--\nSaludos\n\n*Alejandro Holguin M **\/ Business Developer*\n*Cel +57 3106668252 \/ correo electr\u00f3nico: alejandro@inflexion.com.co\n*\n*Skype: holguinmora*"
            }
        ]
    },
    {
        "Question_title":"Translating streaming audio into text",
        "Question_creation_date":"2022-04-11T14:33:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Translating-streaming-audio-into-text\/td-p\/412679\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":33,
        "Question_body":"Hi, I'm using @Google-cloud\/media-translation in node with express js server. I want to translate media file (\".wav\" format) with media-translation. At first, i got an error because of authentication and I fixed it with env variable as specified in documentation, I followed each and every step exactly told in the documentation but I'm getting no response from server. When i looked into APIs & Services tab it only recorded my failed auth attempts no other API calls are recorded. Please help because there is no help available online about this product and it doesn't even send error responses so i can debug. ",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nWould you please share with us the error message ? Please make sure there are PII in it.\n\nYou can also share the reproduction steps?\n\nThanks"
            }
        ]
    },
    {
        "Question_title":"Vision API quota\/budget limit and API key help",
        "Question_creation_date":"2022-04-01T09:33:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vision-API-quota-budget-limit-and-API-key-help\/td-p\/409566\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":66,
        "Question_body":"Hello, I have never used Vision API before but I recently found it very powerful for a project of mine. However I have two concerns regarding its budget limiting, in order to not get an unexpected bill:Thanks everyone for any help!",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-14T12:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0\n\nYou can set a cap of api usage\u00a0or a billing budget might help you on this issue. Does it meet your needs?\n\nAbout your security question about \"hard code the key in Android\/iOS\", I recommend you to discuss\u00a0on Stack Overflow for better help."
            }
        ]
    },
    {
        "Question_title":"How should the input JSONL look for a batch prediction job?",
        "Question_creation_date":"2022-04-04T10:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-should-the-input-JSONL-look-for-a-batch-prediction-job\/td-p\/410193\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":109,
        "Question_body":"I can't find any examples online of how an input jsonl is supposed to look for a batch training job. When I tried with this:  I got an error email saying  Error Messages: BatchPrediction could not start because no valid instances \nwere found in the input file. Is there some other way this should look for it to work? Maybe like      ",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-08T13:36:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hell sangersteel,\nIt is not possible to use a JSONL file for batch prediction of text classification. Only a CSV file format is accepted for text classification. This is indicated in the [1] [AutoML Natural Language documentation] The CSV file should only contain 1 file (input file) per row. The CSV file and each input file needs to be stored in your Cloud Storage bucket.\n\n[1]\u00a0https:\/\/cloud.google.com\/natural-language\/automl\/docs\/predict#batch_prediction."
            }
        ]
    },
    {
        "Question_title":"Speech-to-Text for many langages",
        "Question_creation_date":"2022-03-28T06:33:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-to-Text-for-many-langages\/td-p\/407723\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":53,
        "Question_body":"Hello,I'm testing bunch of variety of the Speech-to-Text API to transcribe audio from microphone but I'm going through two issues:Note: I didn't see anywhere how to use utf-8 for transcriptionHow can I fix it I used the code found here https:\/\/github.com\/googleapis\/python-speech\/blob\/main\/samples\/microphone\/transcribe_streaming_infini...",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-05T10:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I solved the first part of my problem, if anyone is going through the same problem\n\nIn windows terminal you can type: chcp 1256 . This allow arabic characters in terminal"
            }
        ]
    },
    {
        "Question_title":"Action Needed | OAuth Google Cloud platform | multiple unique domains",
        "Question_creation_date":"2022-04-04T02:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Action-Needed-OAuth-Google-Cloud-platform-multiple-unique\/td-p\/410024\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":93,
        "Question_body":"Hi,I am carrying out the OAuth verification in Google Cloud Platform, I received an email that said:\n\"Thanks for your patience while we reviewed your project.Your project pc-api-XXXXXXXXXXXXXXX-XX has multiple unique domains in the redirect URI and origin URLs, many of which have unrelated applications. This is in direct violation of the Google API Services: User Data Policy, which requires that projects accurately represent their identity and intent to Google and to our users when they request access to Google user data.Please follow the instructions on the Google API Console to:You can find more information in the OAuth Application Verification FAQ.  To make sure we don't miss your messages, respond directly to this email to continue with the verification process.\"I have a web server, which checks the validity (domain-1.com) in-app purchases, and I also have a site with a different domain containing: privacy-policy and terms-of-service (domain-2.com).My settings are as follows:OAuth consent screen:\n- Home page application: https:\/\/www.domain-2.com\/\n- Privacy Policy: https:\/\/www.domain-2.com\/privacy-policy\/\n- Terms of Service: https:\/\/www.domain-2.com\/terms-of-service\/\n\nAuthorized domains:\n- domain-2.com\n- domain-1.comID client OAuth 2.0 -> Authorized Redirect URIs:\n- https:\/\/game.domain-1.com:8443I have a working service account.\nI have successfully verified all 2 domains.Where is the mistake?",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-04T21:08:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I have found the solution:\n\nI had 2 Google Cloud Platform projects for the same application.\n\nI deleted a Google Cloud Platform.\nI implemented all the configurations of the deleted project in the other project, and it worked!\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-04-04T21:08:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I have found the solution:\n\nI had 2 Google Cloud Platform projects for the same application.\n\nI deleted a Google Cloud Platform.\nI implemented all the configurations of the deleted project in the other project, and it worked!"
            }
        ]
    },
    {
        "Question_title":"Create TPU Node - Malformed Name",
        "Question_creation_date":"2022-02-26T05:03:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Create-TPU-Node-Malformed-Name\/td-p\/397566\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud TPU"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_upvote_count":1,
        "Question_view_count":180,
        "Question_body":"Hi! Im trying to create a Google Cloud TPU node using TPU client API and I cannot figure out the parent resource name of a TPU node in Google Cloud.I tried all the possible combinations, for example:And I always get the same error (google.api_core.exceptions.InvalidArgument: 400 Malformed name) :        Below you can find the full code I'm using to create the node. Im using Python 3.8, google-cloud-tpu v1.2.1, on a Conda virtualenv. Any help would be much apprecciated!",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-02T06:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It appears that you have created a StackOverflow thread where a Google Cloud Platform Engineer has already replied.\u00a0\n\nHe has suggested you that\u00a0you can find the expected format of\u00a0parent\u00a0in the documentation for the underlying API method:\u00a0projects.locations.nodes.create.parent\u00a0should be formatted as\u00a0projects\/*\/locations\/*. That is, change\u00a0zones\u00a0to\u00a0locations\u00a0and remove the\u00a0\/tpus\u00a0from the end which you had included at the StackOverflow thread.\n\nThe Google Cloud Platform Engineer has further suggested you to remove\u00a0nodes\u00a0from the path. i.e. change\u00a0projects\/my-project-id\/locations\/europe-west4-a\/nodes\/\u00a0that is shown at the stack trace to\u00a0projects\/my-project-id\/locations\/europe-west4-a\/."
            },
            {
                "Answer_creation_date":"2022-03-03T23:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi!\n\nAs I answered in the same stackoverflow, it appears that following the recommended parent=projects\/*\/locations\/* (to be 100% clear: without \/nodes\/ ) does not work and gives the error actually shared by the authors.\n\nWe cannot remove a \/nodes\/ that we do not set in the first place.\n\nLibraries version:\ngoogle-api-core 2.6.0\ngoogle-auth 2.6.0\ngoogle-cloud-tpu 1.3.1\ngoogleapis-common-protos 1.55.0"
            },
            {
                "Answer_creation_date":"2022-03-07T13:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The Google Cloud Engineer has updated the response along with the code here. Please let us know if you can use the code and whether that works."
            },
            {
                "Answer_creation_date":"2022-03-11T12:21:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, it worked.\n\nWhen cleaning the resources though, there seems to be an issue with the lib:\n\n\u00a0\n\nNAME = f\"projects\/{manifest.tpu.gcpProject}\/locations\/{manifest.tpu.gcpZone}\/nodes\/{manifest.name}\"\n\nclient = tpu_v2alpha1.TpuClient()\n        \nrequest = tpu_v2alpha1.DeleteNodeRequest(\n    name=NAME,\n)\n\n# Make the request\noperation = client.delete_node(request=request)\n\nlogging.info(\"Waiting for operation to complete...\")\nresponse = operation.result()\n\n\u00a0\n\n\nThe TPU VM is successfully deleted, but the python code eventually fails:\n\n\u00a0\n\nCleaning TPU\nWaiting for operation to complete...\nTraceback (most recent call last):\nFile \"\/argo\/staging\/script\", line 29, in <module>\nresponse = operation.result()\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/future\/polling.py\", line 132, in result\nself._blocking_poll(timeout=timeout, **kwargs)\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/future\/polling.py\", line 110, in _blocking_poll\nretry_(self._done_or_raise)(**kwargs)\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/retry.py\", line 283, in retry_wrapped_func\nreturn retry_target(\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/retry.py\", line 190, in retry_target\nreturn target()\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/future\/polling.py\", line 88, in _done_or_raise\nif not self.done(**kwargs):\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/operation.py\", line 170, in done\nself._refresh_and_update(retry)\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/operation.py\", line 159, in _refresh_and_update\nself._set_result_from_operation()\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/operation.py\", line 130, in _set_result_from_operation\nresponse = protobuf_helpers.from_any_pb(\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/protobuf_helpers.py\", line 65, in from_any_pb\nraise TypeError(\nTypeError: Could not convert Any to Node"
            },
            {
                "Answer_creation_date":"2022-03-23T07:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"@Mohammad_I\u00a0could you please have a look at my response, I also created a github ticket:\u00a0https:\/\/github.com\/googleapis\/python-tpu\/issues\/92\nIt creates wrong fail warnings in our Pipelines today"
            }
        ]
    },
    {
        "Question_title":"Recover deleted Vertex AI resources",
        "Question_creation_date":"2022-03-22T22:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Recover-deleted-Vertex-AI-resources\/td-p\/405934\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":210,
        "Question_body":"Hi,In order to save on billing, I deleted most of the resources in the data sources, workbench, pipelines in Vertex AI.Is there a way I can recover them??",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-22T22:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nIn order to save on billing, I deleted most of the resources in the data sources, workbench, pipelines in Vertex AI.\n\nIs there a way I can recover them??"
            }
        ]
    },
    {
        "Question_title":"Text to speech Google Cloud Python",
        "Question_creation_date":"2022-03-22T18:48:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Text-to-speech-Google-Cloud-Python\/td-p\/405883\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":156,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-22T18:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I would like to calculate the time duration for sentences when I convert text to speech in Google Cloud in Python. For example, if I have three sentences converted to audio, I would like to know when the first sentence starts in the audio, the second one, etc.\n\nExample:\n\ntext= 'Hello, World. I can speak any language. I would like to help you.'\n\nHello, World: starts 00:00 ends 00:03\n\nI can speak any language: starts 00:04 ends 00:09\n\nI would like to help you: starts 00:10 ends 00:13\n\nIs there something for that in python? here is the main code:\n\n\u00a0\n\n\"\"\"Synthesizes speech from the input string of text or ssml.\n\nNote: ssml must be well-formed according to:\n    https:\/\/www.w3.org\/TR\/speech-synthesis\/\n\"\"\"\nfrom google.cloud import texttospeech\n\n# Instantiates a client\nclient = texttospeech.TextToSpeechClient()\n\n# Set the text input to be synthesized\nsynthesis_input = texttospeech.types.SynthesisInput(text=\"Hello, World. I can speak any language. I would like to help you.\")\n\n# Build the voice request, select the language code (\"en-US\") and the ssml\n# voice gender (\"neutral\")\nvoice = texttospeech.types.VoiceSelectionParams(\n    language_code=\"en-US\", ssml_gender=texttospeech.enums.SsmlVoiceGender.NEUTRAL\n)\n\ntexttospeech_v1beta1.types.cloud_tts_pb2\n\n# Select the type of audio file you want returned\naudio_config = texttospeech.types.AudioConfig(\n    audio_encoding=texttospeech.enums.AudioEncoding.MP3\n)\n\n# Perform the text-to-speech request on the text input with the selected\n# voice parameters and audio file type\nresponse = client.synthesize_speech(\n    input_=synthesis_input, voice=voice, audio_config=audio_config\n)\n\n# The response's audio_content is binary.\nwith open(\".\/output.mp3\", \"wb\") as out:\n    # Write the response to the output file.\n    out.write(response.audio_content)\n    print('Audio content written to file \"output.mp3\"')"
            }
        ]
    },
    {
        "Question_title":"How can I deploy a pretrained fasttext model?",
        "Question_creation_date":"2022-03-13T01:31:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-deploy-a-pretrained-fasttext-model\/td-p\/403114\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":235,
        "Question_body":"Hi, I have this code : \"",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-16T17:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nSeeing that there is already an existing post [1] on Stack Overflow, kindly follow up on that post to avoid any work duplication.\u00a0\n\n\u00a0\n\n[1]\u00a0https:\/\/stackoverflow.com\/questions\/71455187\/how-can-i-deploy-a-fasttext-model-on-google-cloud"
            },
            {
                "Answer_creation_date":"2022-03-17T22:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi! Thanks for answering, that question actually is mine, and there hasn't been an answer yet. Anyways I have a question, all I want to do, is deploy a couple pretrained fasttext models :\u00a0\n\nimport fasttext\nft = fasttext.load_model('pretrainedmodelpath')\nJust that, a couple times and be able to have an api get word vectors for words, which google cloud service would best be suited for this task? Most of the google cloud services want me to train my own model and don't let me just load a pretrained one. And in for example Dataflow, I can't just send text via the API and get an answer because it wants a file input. Any ideas? Thanks!"
            }
        ]
    },
    {
        "Question_title":"[Vertex AI] Bug - Failed to create endpoint due to the error: INTERNAL",
        "Question_creation_date":"2022-03-15T06:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Bug-Failed-to-create-endpoint-due-to-the-error\/td-p\/403711\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":338,
        "Question_body":"When attempting to create a new Vertex AI endpoint in us-central1 using a healthy model, I keep getting the error: \"Failed to create endpoint \"NAME\" due to the error: INTERNAL\"\n\nI expected the endpoint to get deployed successfully.  In fact, up to about 7 days ago, this operation worked perfectly.\n\nSteps to reproduce:\nAttempt to deploy a health Vertex AI model to a new endpoint in us-central1\n\nI'm currently trying to figure out if this INTERNAL error is specific to a region (or not), but it will take me hours before I can determine if the region is a factor.  I suspect there's some other global issue that's the problem.Has anyone else encountered this problem?",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-17T10:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0Darien,\u00a0\n\nI see that you have already reported this on our Public Issue Tracker\u00a0here and I am glad that you are no longer having this issue."
            }
        ]
    },
    {
        "Question_title":"hello custom training tutorial failed on cloud function deploy",
        "Question_creation_date":"2022-03-10T15:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/hello-custom-training-tutorial-failed-on-cloud-function-deploy\/td-p\/402689\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":385,
        "Question_body":"Hi guys I'm following this tutorial to get my had around Vertex AI - https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/image-recognition-custom\/ On step  - https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/image-recognition-custom\/serving#2_deploy_a   since I'm new on GCP anyone tried this tutorial and have the same error? any tips on how to fix this?thank you very much guys",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-15T18:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The gcloud tool comes with a set of options which are not easily to spot but offer features like verbosity. Add -- verbosity debug to your deplyment command in order to debug the deployment process with more meaningful logs.\n\nFind all the options here:[1]\n\n[1] https:\/\/cloud.google.com\/sdk\/gcloud\/reference\/functions\/deploy"
            }
        ]
    },
    {
        "Question_title":"AutoML tables - sample size of an average",
        "Question_creation_date":"2022-02-25T06:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-tables-sample-size-of-an-average\/td-p\/397276\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":66,
        "Question_body":"Hi everyonesI'm new to google automl tables and have a basic question about which data is worthwhile including in the training of my model.I have a dataset of golfers and will be looking at the averages of scores over different periods. For example, average over the past 3 months, 6 months, 1 year etc.My question is, is it worthwhile also including the sample size for each date range for each player. For example, over the past 3 months, some players will have a sample size of 28 while some will only have 2. Those players that have 28 rounds will have more accurate averages than those with 2. However, I didn't know whether google automl tables would pick up this link automatically, whether I could create a different weighting\/reliability variable, or whether there's a way to specify a link between columns? Or if this automated type of automl isn't really suitable or just leave out that sample size variable?Thanks in advance",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-11T11:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nGoogle Groups are reserved for general product discussion, StackOverflow for technical questions whereas Issue Tracker for product bugs (unexpected behaviors) and feature requests. To get a better support you should post to the relevant forum, thus please read the Community Support article for better understanding."
            }
        ]
    },
    {
        "Question_title":"Save audio file from speech to text stream",
        "Question_creation_date":"2022-03-03T07:35:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Save-audio-file-from-speech-to-text-stream\/td-p\/398993\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":57,
        "Question_body":"I am using @Google-cloud\/speech for streaming audio from the browser to my nodejs backend.\nI would like to save the recorded audio.\nI see no option to do so. Any suggestions? Thanks.",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-08T13:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hey,\u00a0\n\nYou shall probably use other packages for recording such as recordrtc as mentioned at [1].\u00a0\u00a0\n\n[1]\u00a0https:\/\/www.leeboonstra.dev\/chatbots\/building-your-own-voice-ai-3\/"
            }
        ]
    },
    {
        "Question_title":"Being told to contact Vertex AI support but we don't have a support contract?!",
        "Question_creation_date":"2022-03-08T11:34:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Being-told-to-contact-Vertex-AI-support-but-we-don-t-have-a\/td-p\/401449\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":51,
        "Question_body":"Getting an internal error when training a model on Vertex AI.I have gotten repeated emails from Google telling me to contact Vertex AI support about this.We don't pay for a support contract.It seems odd that there is no way to report issues like this to Vertex AI without a support contract.",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-08T11:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Getting an internal error when training a model on Vertex AI.\n\nI have gotten repeated emails from Google telling me to contact Vertex AI support about this.\n\nWe don't pay for a support contract.\n\nIt seems odd that there is no way to report issues like this to Vertex AI without a support contract."
            }
        ]
    },
    {
        "Question_title":"Dialogflow quota reset",
        "Question_creation_date":"2022-03-02T01:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-quota-reset\/td-p\/398513\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":42,
        "Question_body":"Hello,I have a Dialogflow ES agent, and I'm sending a few thousand (~5k) DetectIntent requests asynchronously. Our quota is 9k requests per minute, so it shouldn't be a problem. However what I'm seeing is that even after waiting for 10 minutes or more, when I run another batch (also ~5k), I get a resource exhausted error. If the quota is 9k per minute, why is the resource still exhausted after 10 minutes? And is there a way to know by what time I should try again?",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-02T01:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI have a Dialogflow ES agent, and I'm sending a few thousand (~5k) DetectIntent requests asynchronously. Our quota is 9k requests per minute, so it shouldn't be a problem. However what I'm seeing is that even after waiting for 10 minutes or more, when I run another batch (also ~5k), I get a resource exhausted error. If the quota is 9k per minute, why is the resource still exhausted after 10 minutes? And is there a way to know by what time I should try again?"
            }
        ]
    },
    {
        "Question_title":"load a .h5 trained model directly from GCS ?",
        "Question_creation_date":"2022-02-21T03:57:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/load-a-h5-trained-model-directly-from-GCS\/td-p\/395442\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_upvote_count":0,
        "Question_view_count":242,
        "Question_body":"Hello, it's the fist time I actually try to put in a production environment a locally trained .h5 model. I have a website hosted on a cloud run container and I'm trying to run an Image processing pipeline every-time a file is uploaded to GCS via the website (that's why I want to use a cloud function that triggers when a new file is created).my issue:I have found a way to load my .h5 model from GCS but It's taking way too mush time and I'm sure there's surely a better way to do what i'm trying to do:almost 1 minute to load on my local machine. Do you have any recommendation on how to trigger the prediction of my trained model + (pre\/post processing) easily upon file upload from my website (in a serverless context) ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-23T17:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nCan you kindly advise of your complete workflow. Additionally, how big are these h5 files?\n\nRegards"
            },
            {
                "Answer_creation_date":"2022-02-28T12:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am using a could run docker container. And instead of packaging the model inside the container I would prefer to tell the code to load it directly from GCS (in python). Model .h5 size is 22.4Mo"
            },
            {
                "Answer_creation_date":"2022-03-01T17:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nGCS does offer low latency which applies to all storage classes. If your app and GCS buckets are in the same region, I suggest to file an official support [1] so we can take a look at it in details using our internal tooling.\n\nRegards,\n\n[1]\u00a0https:\/\/cloud.google.com\/support-hub"
            },
            {
                "Answer_creation_date":"2022-03-01T17:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Additionally,\u00a0\n\nHave you tried comparing the results when fetching the same file directly through gsutil?"
            }
        ]
    },
    {
        "Question_title":"Use GCP Endpoints as reverse proxy for Vertex Ai Endpoint",
        "Question_creation_date":"2022-02-24T08:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Use-GCP-Endpoints-as-reverse-proxy-for-Vertex-Ai-Endpoint\/td-p\/396912\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":343,
        "Question_body":"I am using GCP Endpoints to work as a reverse proxy to a Vertex Ai Endpoint. I can authenticate to GCP Endpoints with api keys, service account... but I get the following error code. Yet, am able to get a successful response from Vertex Ai Endpoint directly. # Error code when requesting to GCP Endpoints (API is authenticated)   Even using the flag \"--allow-unauthenticated\" when setting up ESPv2 still fails. The request   openapi.json (host and address removed for privacy)   Any help would be greatly appreciated",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-01T07:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nCould be for different reasons:\n\nFor testing purposes, grant the service account the \u2018owner\u2019 role as advice in [1] document, and see if you still get the error.\u00a0\nIf everything was working fine before, please try to generate another <access_token> for your service account as mentioned in [2].\nMake sure you followed all the steps form document [3]\n\nThank you\n\n[1]: https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/image-recognition-automl#before_you_begin\n\n[2] https:\/\/developers.google.com\/identity\/protocols\/oauth2#5.-refresh-the-access-token,-if-necessary.\n\n[3]: https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/custom-service-account"
            }
        ]
    },
    {
        "Question_title":"AI & MLOps Garage (Demos + Hands-on w\/ Prizes) - March 9th",
        "Question_creation_date":"2022-02-27T10:11:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AI-amp-MLOps-Garage-Demos-Hands-on-w-Prizes-March-9th\/td-p\/397728\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":2,
        "Question_view_count":93,
        "Question_body":" Join Google Cloud Industry experts for a half-day dedicated to the possibilities of MLOps & AI. Dig deeper into how you can mature your current Machine Learning & AI practices. Not a Data Scientist or a ML Engineer? No worries! Let us help you get started with modern ML technologies like AutoML and ML w\/ SQL. End the day\u2019s learning by building an MLOps pipeline to automate data engineering, model training & model deployment.   Registration Link : https:\/\/inthecloud.withgoogle.com\/machine-learning-ai-garage-series\/register.html   Through conversations and hands-on workshops, you\u2019ll explore:   The newest AI and ML innovations, use cases, and best practices How to build high-quality ML models with minimal effort How to use automation to your advantage    Running AI and ML solutions both in the cloud and on-premises  LinkedIn Event  Registration Page",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-27T10:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Join Google Cloud Industry experts for a half-day dedicated to the possibilities of MLOps & AI. Dig deeper into how you can mature your current Machine Learning & AI practices. Not a Data Scientist or a ML Engineer? No worries! Let us help you get started with modern ML technologies like AutoML and ML w\/ SQL. End the day\u2019s learning by building an MLOps pipeline to automate data engineering, model training & model deployment.\n\n\u00a0\n\n\u00a0\n\n\u00a0Registration Link : https:\/\/inthecloud.withgoogle.com\/machine-learning-ai-garage-series\/register.html\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\nThrough conversations and hands-on workshops, you\u2019ll explore:\n\n\u00a0\n\n\u00a0\n\n\u00a0The newest AI and ML innovations, use cases, and best practices\n\n\u00a0How to build high-quality ML models with minimal effort\n\n\u00a0How to use automation to your advantage\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\u00a0Running AI and ML solutions both in the cloud and on-premises\n\n\u00a0\n\n\u00a0LinkedIn Event\u00a0\n\n\u00a0Registration Page"
            }
        ]
    },
    {
        "Question_title":"Viewing model architecture",
        "Question_creation_date":"2022-02-23T14:36:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Viewing-model-architecture\/td-p\/396608\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":57,
        "Question_body":"Hello! How can I interpret the feedforward NN model architecture described in AutoML logs (after training a model using AutoML in VertexAI)?I understand the base structure described in https:\/\/cloud.google.com\/automl-tables\/docs\/loggingBut I am not sure this describes the full architecture. For example, if num_neurons = 256, and num_layers = 2, how do I know how many neurons on each layer? Or for dropout = 0.5, in which layer is the dropout happening?Any sources your recommend that might explain this a bit better?Thank you very much in advance for your help! I have been researching this and have found no clear explanation ",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-26T13:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nIt seems the doc[1] you shared is the only one I can find\u00a0 that describes the feedforward NN model architecture.\n\nKeep in mind that AutoML Tables \u00a0is covered by the Pre-GA Offerings Terms of the Google Cloud Terms of Service.\u00a0\u00a0\n\nBut I encourage you to file a feature request here[2] to have the full\u00a0 model architecture details added to the log entries.\n\n[1]:\u00a0https:\/\/cloud.google.com\/automl-tables\/docs\/logging\n\n[2]: https:\/\/cloud.google.com\/support\/docs\/issue-trackers?hl=en"
            }
        ]
    },
    {
        "Question_title":"Vertex AI integration with mlflow ?",
        "Question_creation_date":"2022-02-18T03:57:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-integration-with-mlflow\/td-p\/394738\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":918,
        "Question_body":"Is there any way to integrate vertex AI with mlflow ? \nAny articles or resources I can go through ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-18T04:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0avinashbhawnani,\u00a0\n\nI would suggest to have a look at MLflow plugin for Google Cloud Vertex AI\n\nhttps:\/\/pypi.org\/project\/google-cloud-mlflow\/\n\nFeel free to reach out in case of questions\n\nThanks"
            },
            {
                "Answer_creation_date":"2022-02-20T23:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0\u00a0ilnardo92,\n\nThanks for sharing the resource, will have a look into it and reach out in case of any queries.\n\nThanks"
            },
            {
                "Answer_creation_date":"2022-02-26T06:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi!... i saw right now this post and tanks to sharing...\u00a0\n\nYou know if is possible to share another container registry how to \"nexus\" instead of GCR ?"
            }
        ]
    },
    {
        "Question_title":"Vertex AI workbench and Google cloud storage problems accesing files",
        "Question_creation_date":"2022-02-07T05:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-workbench-and-Google-cloud-storage-problems-accesing\/td-p\/390712\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":353,
        "Question_body":"I am trying to create a ML project in which the job is a classification task of videos, so I upload those videos in Google cloud storage, and then I create a notebook on the workbench of vertex AI, for making data balancing, and then train my respective ML algorithm. But I have this problem:1. I want to use the video files from GCS without the need of downloading them again(that was the purpose of uploading them in GCS), but I don't know how can i do this?.I also try uploading de videos into the dataset space of the vertex AI workbench but still don't know how to acces to this files without downloading them again.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If I'm not mistaken, you simply need to provide a schema file to set the structure and then provide the json input file with the right paths according to the schema file you've uploaded.\nWhat do you mean by this?:\n\nwithout the need of downloading them again\n\nI'm not aware of any requirement to download a file in order to use it in Vertex AI, the learning algorithm should access the files on Cloud Storage and use them as needed."
            }
        ]
    },
    {
        "Question_title":"No more Wavenet for fr-FR lang",
        "Question_creation_date":"2022-02-09T00:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/No-more-Wavenet-for-fr-FR-lang\/td-p\/391415\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":60,
        "Question_body":"Hi,I have been using Google cloud API for text-to-speech to generate audio based on text for some days using the Wavenet voices and it worked great. The vast majority of my text is French and I have been using the fr-FR-Wavenet-C voice for it. I can't find it anymore. Even the page https:\/\/cloud.google.com\/text-to-speech\/ doesn't show up in the demo section. That's seems to be the case for all fr-FR-Wavenet voices. Have they been deleted?",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-09T00:32:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI have been using Google cloud API for text-to-speech to generate audio based on text for some days using the Wavenet voices and it worked great. The vast majority of my text is French and I have been using the fr-FR-Wavenet-C voice for it. I can't find it anymore. Even the page https:\/\/cloud.google.com\/text-to-speech\/ doesn't show up in the demo section. That's seems to be the case for all fr-FR-Wavenet voices. Have they been deleted?"
            }
        ]
    },
    {
        "Question_title":"Where is Visual Inspection AI?",
        "Question_creation_date":"2022-01-04T06:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Where-is-Visual-Inspection-AI\/td-p\/181914\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":179,
        "Question_body":"Does anybody know where to get started with the Visual Inspection AI?  It has been advertised for more than 6 months, but I cannot find where it is available.   The landing page is here: https:\/\/cloud.google.com\/solutions\/visual-inspection-ai  However, it has never shown up in my Google Cloud Platform Console. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-17T08:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It involves the analysis of products on the production line for quality control. Visual inspection can also be used for internal and external assessment of the various equipment in a production facility, such as storage tanks, pressure vessels, piping, and other equipment.\nArtificial intelligence (AI) is one of the most exciting and fastest-growing fields in computer science. If you're starting to learn about it, you'll need a solid E-Learning Platform by Edureka. This is an Artificial Intelligence course program accredited by E&ICT academy, NIT Warangal, India."
            },
            {
                "Answer_creation_date":"2022-02-02T16:09:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I think you should ask Google's sales team."
            }
        ]
    },
    {
        "Question_title":"Make deep learning VM JupyterLab publicly available?",
        "Question_creation_date":"2022-01-27T11:02:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Make-deep-learning-VM-JupyterLab-publicly-available\/td-p\/386576\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":96,
        "Question_body":"I was able to create a deep learning VM from the marketplace and when I open up the VM instance in the Console I see a metadata tag called `proxy-url` which has a format like `https:\/\/[alphanumeric string]-dot-us-central1.notebooks.googleusercontent.com\/lab`\n\nClicking on that link takes me to a JupyterLab UI that is running on my VM. Amazing! Unfortunately, when I try opening that link on an incognito window, I'm asked to sign in. If I sign in, I get a 403 forbidden.\n\nMy question now is, how can I make that link available to someone else?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi gopalv\n\nAs far as I understand, it sounds like your Jupyter Notebook isn't configured for remote access. since it doesn't work when trying to access it from the incognito window with a 403 error.\n\nYou can try looking here and here for details on how to set up a publicly accessible\/remote access notebook. There are additional troubleshooting steps in our documentation here as well.\n\nHope this helps!\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I think the problem was that I had selected the option to enable access via URL and this only grants access to users who are Editors or Owners in the workspace (step 9 here)\u00a0\n\n\u00a0\n\nhttps:\/\/cloud.google.com\/deep-learning-vm\/docs\/tensorflow_start_instance#creating_ainstance_from_the\n\u00a0\n\n\nWhen I created a new VM and left this option unchecked, I was able to use my public SSH cert to get access.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-01-31T13:58:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi gopalv\n\nAs far as I understand, it sounds like your Jupyter Notebook isn't configured for remote access. since it doesn't work when trying to access it from the incognito window with a 403 error.\n\nYou can try looking here and here for details on how to set up a publicly accessible\/remote access notebook. There are additional troubleshooting steps in our documentation here as well.\n\nHope this helps!"
            },
            {
                "Answer_creation_date":"2022-01-31T14:09:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I think the problem was that I had selected the option to enable access via URL and this only grants access to users who are Editors or Owners in the workspace (step 9 here)\u00a0\n\n\u00a0\n\nhttps:\/\/cloud.google.com\/deep-learning-vm\/docs\/tensorflow_start_instance#creating_ainstance_from_the\n\u00a0\n\n\nWhen I created a new VM and left this option unchecked, I was able to use my public SSH cert to get access."
            }
        ]
    },
    {
        "Question_title":"How can I use this specific voice? (English (en-gb-x-gbg-network)",
        "Question_creation_date":"2022-01-20T22:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-use-this-specific-voice-English-en-gb-x-gbg-network\/td-p\/184984\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":169,
        "Question_body":"Goal: Given text, generate mp3 files using Google Cloud tts servicesProblem: Unable to find specific voice I am used to hearing English (en-gb-x-gbg-network). Other info: I've been using this tts app on android in which I can select the aforementioned Voice Type from the Google TTS engine on android. I have since created a Google Cloud account, and followed the tutorial to setup a project to which I can use their selection of voices. However, when I went through the list of voice that I can use, the en-gb-x-gbg-network was not available to use. AFAIK, en-gb-x-gbg-network is not a premium WaveNet voice type. I suspect it has something to do with android but I can't not see why I can't use this voice on the Google Cloud Platform. Many thanks for any helpful info or any nudge that can point me to the right directionCheers, Welp",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-24T07:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Welp,\n\nI will like to point you to this article[0] that highlights the supported voices and languages available in Cloud Text-to-Speech on GCP.\n\nApparently, while there are other en-gb voices supported, the en-gb-x-gbg-network is not supported at this time. This explains why you could not find this specific voice[en-gb-x-gbg-network] on your GCP project because it seems unsupported at this time.\n\nPerhaps you can go through the supported voices and the samples provided on the link[0] to check for other alternatives?\n\n[0]https:\/\/cloud.google.com\/text-to-speech\/docs\/voices"
            }
        ]
    },
    {
        "Question_title":"Speech changes to a more robotic feel if I use certain phonemes",
        "Question_creation_date":"2022-01-17T00:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-changes-to-a-more-robotic-feel-if-I-use-certain-phonemes\/td-p\/184068\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":47,
        "Question_body":"I am using phonemes for some speaks, to make them sound more natural, but some phonemes change the rest of the sentence feel. I have made a demo here.Using these settings:In the speak below I have two identical speaks, where one word is replaced with a phoneme. Notice how the end of the sentence changes to a more robotic feel in the first. How do I avoid this?<speak>\nIn this training, you will learn more about how you sell <phoneme alphabet=\"ipa\" ph=\"k\u0251\u02d0d\">placeholder<\/phoneme> as a solution for companies that want to minimize out-of-pocket spending and have better control of company spending by employees.In this training, you will learn more about how you sell card as a solution for companies that want to minimize out-of-pocket spending and have better control of company spending by employees.\n<\/speak>",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-20T04:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi! I see there is an issue already open regarding this. I\u2019ve tested your SSML and I understand what the issue is and it seems like unintended behavior. I tried to workaround it but I didn\u2019t find a way to do so. Any updates regarding your issue will be on the issue tracker"
            },
            {
                "Answer_creation_date":"2022-01-23T23:28:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes. I created the issue. Thx for the reply"
            }
        ]
    },
    {
        "Question_title":"BatchAnnotateImagesResponse images info (context support) for web based images",
        "Question_creation_date":"2021-12-23T01:21:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/BatchAnnotateImagesResponse-images-info-context-support-for-web\/td-p\/181129\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":128,
        "Question_body":"Hi all. How could one know in what exact web based image the text was detected when multiple web based images are sent to the cloud vision api in a single request using BatchAnnotateImagesRequest? BatchAnnotateImagesResponse doesn't return that information which is kinda odd... It has ImageAnnotationContext, which holds image details, but it's reserved only for files and not web based images.\n\nIs there some way to do this? Maybe like preserving order of images in request \/ response or something down that line.",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-27T13:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nlooking to our documentation [1] the batch annotation images response return an Individual responses to image annotation requests within the batch as AnnotateImageResponse [2].\n\nImageAnnotationContext, if present, contextual information is needed to understand where this image comes from.[1]https:\/\/cloud.google.com\/vision\/docs\/reference\/rpc\/google.cloud.vision.v1#batchannotateimagesrespons...\n[2]https:\/\/cloud.google.com\/vision\/docs\/reference\/rpc\/google.cloud.vision.v1#annotateimageresponse"
            },
            {
                "Answer_creation_date":"2022-01-11T00:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, abdelilahf\n\nSorry to see response a bit late. I was on vacation.\nAs I wrote, last time we checked, contextual information was just implemented to return image information about file based images, not web based images, and we only can check batches of images fetched from image service via api \"on the fly\".\n\nDo you maybe know if this will be implemented any time soon for web images? Is there some way to request this feature from Google? Also, is there some workaround in the meantime to cover our use case?"
            },
            {
                "Answer_creation_date":"2022-01-18T06:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Solved with this answer. Thanks!"
            }
        ]
    },
    {
        "Question_title":"Order of entries in BatchAnnotateImagesResponse",
        "Question_creation_date":"2022-01-11T01:43:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Order-of-entries-in-BatchAnnotateImagesResponse\/td-p\/182949\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":93,
        "Question_body":"Given a list of image urls I want to annotate each image, i.e. extract text from each image. For that, I want to use Google Cloud Vision API client library in Java. Here is my pseudocode:Now from batchResponse I can get a list of AnnotateImageResponse. The questions are, does the number of AnnotateImageResponse correspond to the number of requests? Does the order of responses correspond to the order of requests? Can I safely assume that by doing soI will get annotations for the right image on each iteration of the for loop? This is something that is not clear to me from the documentation.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nHave you tried to use AsyncBatchAnnotateImages instead of batchAnnotateImages? As the response contains the context of each image mentioning the uri, eg:\n\n\u00a0\"context\": {\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"uri\": \"gs:\/\/cloud-samples-data\/vision\/document_understanding\/image1.png\"\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n\n\u00a0\n\nThe responses should be in the order of the requests."
            },
            {
                "Answer_creation_date":"2022-01-13T00:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Nasif,\n\nAsyncBatchAnnotateImages doesn't fit to my usecase. If you say the responses should be in the order of the request, then I'll go for it with\u00a0BatchAnnotateImagesResponse."
            }
        ]
    },
    {
        "Question_title":"Google Speech-to-text for live audio",
        "Question_creation_date":"2022-01-10T04:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Speech-to-text-for-live-audio\/td-p\/182518\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":89,
        "Question_body":"I was working with google speech to text for transcribing live audio. I was able to use the auto detect feature to detect user's language he\/she is speaking in. it worked perfectly when transcribing an audio file but i was not able to achieve the same result when doing the same with live audio. I followed every sample and documentation made available by google but still no luck.\nPlatform: Python 3.9\nHere is my snippet:Any help will be appreciated. Thanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-12T15:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It's not much clear what is not same with live audio, can you please clarify a bit.\u00a0\n\n1) What differences you noticed in your results?\n\n2) Which documentation you followed?\n\nThere are whole lot of different issues for example:\n\n- with the speaker diarization (multiple speaker recognition), can not identify different speakers\n\n- can not determine the spaces\/pauses, start or end of the speech.\u00a0\n\n- can not recognize some special words. etc.\n\n\u00a0\n\nThere are a lot of factors and RecognitionConfig parameters for example:encoding, sampleRateHertz, language code, speechContext, length of the speech etc. that take into accounts while transcribing an audio.\n\n\u00a0\n\nYou may find the following documentation helpful:\n\n[1] https:\/\/cloud.google.com\/speech-to-text\/docs\/concepts\n[2] https:\/\/cloud.google.com\/speech-to-text\/docs\/basics\n[3] https:\/\/cloud.google.com\/speech-to-text\/docs\/best-practices\n[4] https:\/\/cloud.google.com\/speech-to-text\/docs\/adaptation-model\n[5] https:\/\/cloud.google.com\/architecture\/architecture-for-production-ready-live-transcription-tutorial\n[6] https:\/\/github.com\/googleapis\/python-speech\/blob\/main\/samples\/microphone\/transcribe_streaming_infini..."
            }
        ]
    },
    {
        "Question_title":"AutoML Vision - Error type - No valid preprocessed examples",
        "Question_creation_date":"2022-01-11T13:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-Vision-Error-type-No-valid-preprocessed-examples\/td-p\/183067\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":81,
        "Question_body":"I have set up an Image classification (Single-label).The model trained for 18 min 25 sec before I recieved the following error:Due to one or more errors, this training job was canceled on Jan 11, 2022 at 07:34AM Batch prediction job GAF-prediction-test encountered the following errors: No valid preprocessed examples.There is no documentation that I could find that explains this error type. Anyone with any ideas what this means?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, Thank you for reporting this behavior.\u00a0 \u00a0\n\nPlease note that\u00a0Groups is reserved for general product discussions. If you require further technical support it is recommended to post your detailed question on Stack Overflow which i can see that you have correctly did. [1].\n\n\u00a0\n\n[1]:https:\/\/stackoverflow.com\/questions\/70673890\/automl-vision-error-no-valid-preprocessed-examples\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-01-12T13:24:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, Thank you for reporting this behavior.\u00a0 \u00a0\n\nPlease note that\u00a0Groups is reserved for general product discussions. If you require further technical support it is recommended to post your detailed question on Stack Overflow which i can see that you have correctly did. [1].\n\n\u00a0\n\n[1]:https:\/\/stackoverflow.com\/questions\/70673890\/automl-vision-error-no-valid-preprocessed-examples"
            }
        ]
    },
    {
        "Question_title":"CUstom Container in Vertex AI pipeline",
        "Question_creation_date":"2022-01-07T06:16:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/CUstom-Container-in-Vertex-AI-pipeline\/td-p\/182237\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":146,
        "Question_body":"Hi,I wanted to check that is it possible to create a custom container in a Vertex AI pipeline and Push it to Artifact registery?",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-12T06:16:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It's a good question and i hope yes, because artifact registry is a \"new version\" of container registry. But is intersting read how to transition to artifact..\u00a0\n\n\u00a0\n\nhttps:\/\/cloud.google.com\/artifact-registry\/docs\/transition\/transition-from-gcr"
            }
        ]
    },
    {
        "Question_title":"DTMF working in dialogflow cx telephony gateway",
        "Question_creation_date":"2022-01-05T22:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/DTMF-working-in-dialogflow-cx-telephony-gateway\/td-p\/182110\/jump-to\/first-unread-message",
        "Question_topic":[
            "Contact Center AI",
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":235,
        "Question_body":"Hi,\nI want to know that whether we can integrate  bot to Dialogflow CX Phone Gateway and then we can make something like press 1 for this and press 2 for this? and then that bot should work on numbers entered by user? Actually i have done a research regarding this and found that we have dtmf option which let us take input from the user but that is not working , so can you please let me know if something like this is supported?",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-10T17:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I would recommend you to have clarification for the issue and give a detailed use case with any documentation that you are following.\n\nGoogle Groups are reserved for general product discussion, StackOverflow for technical questions whereas Issue Tracker for product issues (unexpected behaviors) and feature requests.\n\nAs this is quite a technical question I would recommend you using the StackOverflow channel, the scope of the questions reach a greater tech community so they are likely to be answered faster.\n\nPlease read the Community Support article [1] for better understanding.\n\n[1] https:\/\/cloud.google.com\/support\/docs\/community"
            }
        ]
    },
    {
        "Question_title":"Google Translate API",
        "Question_creation_date":"2021-12-30T10:46:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-API\/td-p\/181620\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":272,
        "Question_body":"Hi,I would like to use Google Translate API in plain javascript.As far as I understand from this guide, the supported languages are : ... and some additional languages :Does translate API is supported for Javascript as well? If so, where is the guide?Thanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-10T14:09:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Here is a third-party solution you may find useful [1].\u00a0You may also report it to the Public Issue Tracker (PIT) [2]\u00a0 as well as feature request.\n\n[1]\u00a0 https:\/\/github.com\/topics\/javascript-translate\n\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-12-30T17:04:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I could not find any official documentation\/tutorial on Google Translate API for plain JavaScript. It looks like the previously used \"Google Transliterate API\" which was officially deprecated as of May 26, 2011 had support for plain JavaScript [1].\nThe client libraries are currently available for seven popular programming languages \u2013 C#, Go, Java, Node.js, PHP, Python, and Ruby.\n\nHowever, the following un-official link [2] (July 20, 2021) may help.\n\n[1] https:\/\/developers.google.com\/transliterate\/v1\/getting_started\n[2] https:\/\/rapidapi.com\/blog\/google-translate-api-tutorial\/"
            },
            {
                "Answer_creation_date":"2021-12-31T05:36:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the reply sf.\u00a0\n\nHow can it be that there is not documentation for one of the most popular programming languages such as Javascript?"
            },
            {
                "Answer_creation_date":"2022-01-10T14:09:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Here is a third-party solution you may find useful [1].\u00a0You may also report it to the Public Issue Tracker (PIT) [2]\u00a0 as well as feature request.\n\n[1]\u00a0 https:\/\/github.com\/topics\/javascript-translate\n\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers"
            }
        ]
    },
    {
        "Question_title":"Vision API - Text detection training",
        "Question_creation_date":"2022-01-05T03:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vision-API-Text-detection-training\/td-p\/182002\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":0,
        "Question_view_count":75,
        "Question_body":"Hi there,I'd like to train my Vision Project to improve document text detection for manuscript books. I couldn't find the solution anywhere. The current result is awful. The language is Portuguese.Please advise. Thanks.",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-10T06:49:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\u00a0\n\nI hope I understand your concern. The issue seems to be about the Quality of the result observed.\u00a0\n\nCould you give more insights and details on what you observed? As per this doc[0], Portuguese is one of the Supported languages by the Cloud Vision API's text recognition feature. So, if the result is not what you expected, perhaps sharing more info about your use-case, your image\/file and the output observed, will help to understand how we could help.\u00a0You can share a screenshot as an example, while describing what you observed and what you expected.\n\n\u00a0\n\n[0]https:\/\/cloud.google.com\/vision\/docs\/languages"
            },
            {
                "Answer_creation_date":"2022-01-10T06:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Please ensure that whatever Documents or Screenshots added to this thread does not include PII or SPII.\u00a0\n\nThank you."
            },
            {
                "Answer_creation_date":"2022-01-10T12:49:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Oakinlaja,\n\nThanks for replying. I'm sending to you my code, image file and result. It does not include PII or SPII. Please advise.\nhttps:\/\/1drv.ms\/u\/s!Ap4FzqZLgHXGpYlNTp8Y8Q6eP_7jiw?e=3tGSIx"
            }
        ]
    },
    {
        "Question_title":"BatchPredict could not start due to empty input CSV file",
        "Question_creation_date":"2021-12-31T03:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/BatchPredict-could-not-start-due-to-empty-input-CSV-file\/td-p\/181685\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Cloud Natural Language API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":49,
        "Question_body":"Hello,\nI have a problem with batch prediction for text classification.\nAccording to the documentation I have created a csv file in which every single line refers to a PDF in my bucket. However I get the error message \"InvalidArgument: 400 BatchPredict could not start due to empty input CSV file\".I would be infinitely grateful for help in this case....",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-03T09:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hey,\u00a0\n\nI would suggest that you consider reaching the\u00a0StackOverflow for technical questions as\u00a0Google Groups are reserved for general product discussion.\u00a0\n\nTo get a better support you should post to the relevant forum, thus please read the Community Support article for better understanding."
            }
        ]
    },
    {
        "Question_title":"Can Google Cloud Vision work as fast as Google lens for OCR?",
        "Question_creation_date":"2021-12-29T12:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Can-Google-Cloud-Vision-work-as-fast-as-Google-lens-for-OCR\/td-p\/181569\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":474,
        "Question_body":"Hello, I am using Google Cloud Vision for text recognition, but the processing speed is quite slow (5 to 15 seconds). I would like to know how does Google lens work so fast and if there's any way to make Google Vision as fast.Edit: My photos that go through Vision are stored in Firebase Storage. (As I've read in some posts this is the quickest way to process them). Thanks in advance!",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-30T11:55:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"=> For uploading\u00a0 images to Google Cloud\u00a0 Vision you can use one of the following options:\n\n1) Directly upload the image as binary (is the slowest)\n\n2) Upload the image as base64 encoded (is ~25% faster)\n\n3) Use a pre-uploaded image stored on Google Cloud Storage [1] (is the fastest)\n\n- Please refer to the documentation [2] for best practices for Cloud Vision API\n\n- Also, the response time of Vision API depends on the resource status or network latency.\u00a0 (network IO, file transfer to Vision API, etc).\u00a0\n\n[1] https:\/\/cloud.google.com\/storage\/\n\n\u00a0[2] https:\/\/cloud.google.com\/vision\/docs\/supported-files"
            },
            {
                "Answer_creation_date":"2022-01-03T02:21:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Google Cloud Vision API work? Google image recognition API\u00a0will identify images from pre-trained models on large datasets of images and then it classifies the images into thousands of categories to detect the objects, places, people and faces in the images.\n\n\u00a0\n\nMyAccountAccess"
            }
        ]
    },
    {
        "Question_title":"BigQueryML Explainability Apparently Not Working",
        "Question_creation_date":"2021-12-22T09:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/BigQueryML-Explainability-Apparently-Not-Working\/td-p\/181036\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":319,
        "Question_body":"I'm using BigQueryML to train an XGBoost model on some of my data. When I create the model, I set the ENABLE_GLOBAL_EXPLAIN flag to TRUE, the model then trains properly and I can evaluate it. However there is no Interpretability tab on the model's page, and when I try to query the model with the ML.GLOBAL_EXPLAIN command, I get an error that says: Is this a bug or am I doing something wrong?Here's my create model code: ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-29T17:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You are using the right syntax for creating the model\u00a0 as per the examples mentioned in documentation[1].\n\n=> Some possibilities for the error are :\n\n- Models with the same id were re-training again with the script during the evaluation.\n\n- Evaluation data was not provided (might have been explicitly disabled)\n\nYou can \u00a0open up details about the model in the UI in BigQuery, under Evaluation and verify what details it shows.\u00a0Also, you can try to rerun the model again (creating, training, evaluating) and verify if it works for you.\n\n[1] https:\/\/cloud.google.com\/bigquery-ml\/docs\/reference\/standard-sql\/bigqueryml-syntax-create#create_mod..."
            },
            {
                "Answer_creation_date":"2021-12-30T09:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0@dikaur\u00a0\n\nThanks so much for your response!\n\nI did try to train new models with new names, and as you can tell from the code above, we do provide the \"RANDOM\" method for data evaluation. In addition, on the model's page, there is information about the model's evaluation, so I believe it is receiving an evaluation dataset. I've also tried several other models with several different datasets and unfortunately they are all seeing the same error.\n\nThis was working about 2 months ago so it's possible that something changed recently.\n\nAre there any other possible explanations for something that I'm doing wrong?\n\nThanks!"
            }
        ]
    },
    {
        "Question_title":"VertexAI: a way to post-process results without usign custom containers?",
        "Question_creation_date":"2021-12-24T10:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/VertexAI-a-way-to-post-process-results-without-usign-custom\/td-p\/181244\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":74,
        "Question_body":"Hello,I have been searching on how to deploy models on VertexAI in AI Platform manner. Most tutorials shows using pre-built container which seems to load the model and return inference results.My current requirement needs to post-process. This was easy to do with AI platform's Predictor class. Is something like that doable with pre-built containers on VertexAI (where we upload a package for inference by inheriting Predictor class and specifyinh the class name)? Using custom container makes it complex to handle and response to requests.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Pre-built containers are convenient to deploy models as Vertex AI provides many pre-built containers but they don\u2019t offer you a chance to customize your workflow beyond the SavedModel. For your scenario, a custom container is the solution as you can build it in your preferred way but it has to comply with several rules required by Vertex AI. [1]\n\n[1] https:\/\/blog.ml6.eu\/deploy-ml-models-on-vertex-ai-using-custom-containers-c00f57efdc3c"
            }
        ]
    },
    {
        "Question_title":"Google Translate Cloud API",
        "Question_creation_date":"2021-12-06T05:03:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-Cloud-API\/td-p\/177308\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API",
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":208,
        "Question_body":"Hi All,I have recently started using Google cloud translate API with python. M having trouble converting this word in the Telugu language which is written in English \"parishkaram chesamu\".  In general internet or mobile the application google translate which we use is giving correctly. But API is returning the same word again.Google Cloud translate API:Input text: parishkaram chesamuOutput text: parishkaram chesamuparameters : text ='''parishkaram chesamu'''\ntarget = \"en\"\noutput = translate_client.translate(text)print(output) --> {'translatedText': 'parishkaram chesamu', 'detectedSourceLanguage': 'te', 'input': 'parishkaram chesamu'}================================Mobile or Internet google translate:Input text : parishkaram chesamuOutput text: We have solved",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-28T14:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Aditya,\n\nYou are writing Telugu language in English \"parishkaram chesamu\" instead of \"\u0c2a\u0c30\u0c3f\u0c37\u0c4d\u0c15\u0c3e\u0c30\u0c02 \u0c1a\u0c47\u0c38\u0c3e\u0c2e\u0c41\"\n\nCurrently the Translate app has the \"Spell check feature\" that responds with both the \"Did you mean\" phrase identified and the corresponding translated result, as oppose to the Translation API.\n\nThe \"did you mean\" text comes from Google's spell check API (the same one that suggests alternative searches when using Google search). When you use the translate API directly you are skipping the spell checking, and that's why you don't get a translation.\n\nThere's already a feature request\u00a0to have a spell check feature in the Translation API response."
            }
        ]
    },
    {
        "Question_title":"Speech to Text for Tamil audio file",
        "Question_creation_date":"2021-12-23T22:24:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-to-Text-for-Tamil-audio-file\/td-p\/181208\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":152,
        "Question_body":"Hi,I am trying to convert an audio file to text.Language: TamilAudio type: Phone callBut when  I look at the support documentation for this API the Model=\"phone call\" is not available for this language. Because of this I am getting very low accuracy after the conversion. please let me know this model would be available in the future. And is there any alternate way to achieve this. ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-27T15:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nUnfortunately the Tamil Language is not supported for phone call as the documentation is showing [1].\n\nI would recommend you to file a feature request by following the steps in the documentation [2].\n\nThanks.\n\n[1]https:\/\/cloud.google.com\/speech-to-text\/docs\/languages\n[2]https:\/\/cloud.google.com\/support\/docs\/issue-trackers#feature_requests"
            }
        ]
    },
    {
        "Question_title":"NLP",
        "Question_creation_date":"2021-12-27T02:06:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/NLP\/td-p\/181365\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":53,
        "Question_body":"https:\/\/colab.research.google.com\/drive\/1U26EA63hocAzyGFLsNP3u-nQUCFYVbpz",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0@Shivaay\u00a0can you provide more context?"
            }
        ]
    },
    {
        "Question_title":"How can I avoid being charged for Tensorboard?",
        "Question_creation_date":"2021-12-21T12:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-avoid-being-charged-for-Tensorboard\/td-p\/180658\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":2,
        "Question_view_count":331,
        "Question_body":"Today I received an email from GCP saying that my account will be charged for using Vertex AI Tensorboard from February. It is quite expensive and I want to stop using the service and avoid being charged.How can I do that? There is no option for Tensorboard in the API dashboard (just one for Vertex AI generally). I only have \"basic support\" so I cannot contact technical support, and I am not the billing administrator so I cannot contact billing support. Is there any way I can disable Tensorboard?Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-23T12:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out regarding Vertex AI TensorBoard pricing, and disabling the service.\u00a0\n\nTensorBoard is currently free of charge as it is a preview product. Vertex AI will launch a new generally available (GA) pricing model for Vertex AI TensorBoard in February 2022, as you mentioned, which will be charged per user, per month.\u00a0\n\n\n\n=> You will be charged for a user if they view the Vertex AI TensorBoard webapp during a given billing period, and the VertexAI product teams plan will be to have this gated by a custom IAM role.\u00a0\n\n=> Given that Tensorboard is part of the VertexAI API, it cannot be disabled without also disabling\u00a0all of VertexAI. It may however be possible to avoid\u00a0being charged by setting all the TensorBoard quotas to zero in the Google Cloud Platform Quotas page [1], and restricting\u00a0what users get assigned\u00a0the IAM role once it is available.\n\n\u00a0\n\n[1] GCP quotas:\u00a0console.cloud.google.com\/iam-admin\/quotas"
            },
            {
                "Answer_creation_date":"2021-12-23T14:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I think I have a super user role, so it sounds like I should set the quotas to zero when they become available. Thank you slando."
            }
        ]
    },
    {
        "Question_title":"Cloud Vision model change",
        "Question_creation_date":"2021-12-13T05:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-Vision-model-change\/td-p\/178017\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":95,
        "Question_body":"Hello, The changes for the Vision API's model from latest -> stable and stable -> legacy are scheduled around Dec 30th\/Jan 1st. Is there a more concrete date and time for this planned change?I'd like to use the currently stable model for the time being, which would involve switching from \"stable\" to \"legacy\". Since this could have an impact on some environments, I will need to make this swap shortly after the model references are being changed. Thanks!",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Please follow the Release Notes for official updates, as Google does not disclose any updates otherwise."
            }
        ]
    },
    {
        "Question_title":"Python Code example to transcribe 2 audio inputs into speech at the same time",
        "Question_creation_date":"2021-12-21T00:07:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Python-Code-example-to-transcribe-2-audio-inputs-into-speech-at\/td-p\/180446\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":105,
        "Question_body":"I'm trying to create a piece of python code that can take 2 audio inputs, 1. from my microphone2. virtual input from zoomat the same timehowever, i am not sure how to transcribe them simultaneously.any help would be appreciated, thank you!",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-21T17:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThe following doc [1]\u00a0describes how to use Speech-to-Text to transcribe audio files that include more than one channel. Multi-channel recognition is available for most, but not all, audio encodings supported by Speech-to-Text.\n\nI hope this would help, thanks.\n\n[1]https:\/\/cloud.google.com\/speech-to-text\/docs\/multi-channel#speech_transcribe_multichannel_gcs-python"
            },
            {
                "Answer_creation_date":"2021-12-21T19:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thank you for the reply, but if I am not wrong, this only applies to 1 audio input\/audio file. Or could this code be modified to use 2 audio streams?"
            }
        ]
    },
    {
        "Question_title":"Text-to-Speech seems to ignore SSML input",
        "Question_creation_date":"2021-12-17T08:20:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Text-to-Speech-seems-to-ignore-SSML-input\/td-p\/179629\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":127,
        "Question_body":"Greetings, all! Since getting started with the TTS service, I have had good success with submitting JSON files that specify simple text input. I am using the instructions for PowerShell as described here:https:\/\/cloud.google.com\/text-to-speech\/docs\/quickstart-protocol#windowsWhen submitting JSON files that specify SSML input, however, it seems that some of the SSML elements are being ignored by the speech synthesizer. I'd like to use the <prosody> and <emphasis> elements, but the output isn't reflecting the values I specified. Here's an example:It doesn't seem to matter how I specify the rate and pitch attributes\u2014the output comes back with no alteration.Thank you for taking the time to read this. If you have information or suggestions, please reply with your ideas!",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-20T14:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"When submitting JSON files with SSML input, you can use the Prosody tag in the following format[1][2].\n\nExample:\n\n```\n\n<prosody rate=\"slow\" pitch=\"-2st\">Can you hear me now?<\/prosody>\n\n```\n\n[1] https:\/\/cloud.google.com\/text-to-speech\/docs\/ssml#prosody\n\n[2] https:\/\/www.w3.org\/TR\/speech-synthesis11\/#:~:text=3.2.4%20prosody%20Element"
            }
        ]
    },
    {
        "Question_title":"Getting Error Deadline Exceeded when deploying model from Cloud Firestoer functions",
        "Question_creation_date":"2021-12-03T11:17:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Getting-Error-Deadline-Exceeded-when-deploying-model-from-Cloud\/td-p\/177128\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":1,
        "Question_view_count":860,
        "Question_body":"Hello,I currently have a firebase function that is set to deploy my AutoML tables model everyday at 5am. This has been working fine for the past month, up until the last week. I have been getting the following error below when the function attempts to deploy the model.I watched a google tutorial and it recommend to return a promise from my cloud function. That seemed to work for 1 day, but I received the error again this morning.I am going to try to implement a retry function, but I figured I would ask on here as well. Also, I am thinking that moving from autoML to VertexAI might help alleviate my issues. Any guidance here is helpful.See below for my deploy model code:  ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-03T12:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Is deploying the model fails via Cloud Functions only, or does it also fail when the model is deployed manually, or by any other means?"
            },
            {
                "Answer_creation_date":"2021-12-03T15:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Manually (through the cloud console) it usually works. I have been testing using an http call in Firebase functions. Sometimes (not consistantly) that fails if I have recently undeployed the model. Although, I do not get any type of error notification, I just know it fails by checking the cloud console.\n\nThe deploy model function only runs once a day though, and the model has typically been undeployed for at least 20 hours before that, so I don't think I am getting that error because I am calling it too often."
            },
            {
                "Answer_creation_date":"2021-12-09T10:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"So after further investigation it looks like the model is failing when I am requesting predictions through firebase functions. I get the same error \"DEADLINE_EXCEEDED\". This is not consistent though, it worked for the previous 2 days before this and today failed again. I haven't changed anything.\n\nI have 2 questions:\n\n1) is it possible that congestion on the network is causing these to fail? Would it help if I moved the prediction to a different time? Currently I have it set at 6am PST.\n\n2) Since autoML is beta, would it help if I moved the model to VertexAI? I can make that move if it helps"
            }
        ]
    },
    {
        "Question_title":"How to use trained vision model in App Inventor",
        "Question_creation_date":"2021-12-05T04:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-use-trained-vision-model-in-App-Inventor\/td-p\/177222\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":91,
        "Question_body":"I have trained a cloud image model with a set of images, I want to use this model to make a mobile app through MIT App Inventor 2. Please suggest how to do this.",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-08T16:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\nAccording to this MIT App Inventor response\u00a0you can use an exported model that has a format compatible with Tensorflow.js.\nPlease find here how to export\u00a0your model in a TensorFlow.js format with\u00a0AutoML Vision Edge and further details about\u00a0building and deploying TensorFlow.js models with AutoML\u00a0here."
            }
        ]
    },
    {
        "Question_title":"\u062a\u062d\u0633\u064a\u0646 \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0628\u062d\u062b",
        "Question_creation_date":"2021-12-01T21:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/%D8%AA%D8%AD%D8%B3%D9%8A%D9%86-%D8%B9%D9%85%D9%84%D9%8A%D8%A9-%D8%A7%D9%84%D8%A8%D8%AD%D8%AB\/td-p\/176885\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":37,
        "Question_body":"\u0627\u0633\u0639\u062f \u0627\u0644\u0644\u0647 \u0635\u0628\u0627\u062d\u0643\u0645\u0641\u064a \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0628\u062d\u062b \u0641\u064a \u0627\u0644\u0623\u0633\u0626\u0644\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0648 \u0627\u0644\u0623\u0633\u0626\u0644\u0629 \u0627\u0644\u062a\u064a \u062a\u062c\u0639\u0644 \u0627\u0644\u0634\u062e\u0635 \u0644\u0627 \u064a\u0639\u0628\u0631 \u0639\u0646 \u0633\u0624\u0627\u0644\u0647 \u0623\u0648 \u0645\u0648\u0636\u0648\u0639\u0647 \u0647\u0648 \u0639\u062f\u0645 \u0627\u0644\u0648\u0635\u0648\u0644 \u0625\u0644\u0649 \u0627\u0644\u0643\u062a\u0627\u0628\u0647 \u0627\u0644\u062e\u0637\u064a\u0629 \u0628\u0634\u0643\u0644 \u0635\u062d\u064a\u062d \u0623\u0648 \u0639\u0646\u062f\u0645\u0627 \u064a\u0633\u0623\u0644 \u0633\u0624\u0627\u0644 \u0644\u0627 \u064a\u0633\u062a\u0637\u064a\u0639 \u0634\u0631\u062d\u0647\u0627 \u0639\u0646 \u0637\u0631\u064a\u0642 \u0627\u0644\u0643\u0644\u0627\u0645)\u0627\u0642\u062a\u0631\u062d \u0639\u0646\u062f\u0645\u0627 \u064a\u062a\u0643\u0644\u0645 \u0627\u0644\u0628\u0627\u062d\u062b \u0639\u0646 \u0645\u0639\u0644\u0648\u0645\u0629 \u0623\u0648 \u0633\u0624\u0627\u0644 \u064a\u062a\u0643\u0644\u0645\u0647\u0627 \u0627\u0644\u0628\u0627\u062d\u062b \u0628\u0627\u0644\u0635\u0648\u062a \u0648\u0639\u0644\u0649 \u0637\u0631\u064a\u0642\u062a\u0647 \u0627\u0644\u0639\u0627\u0645\u064a\u0629 \u0648\u0627\u0644\u0643\u0644\u0627\u0645 \u0627\u0644\u0645\u062a\u062f\u0627\u0648\u0644 \u0639\u0644\u064a\u0647 \u0641\u064a \u0645\u0646\u0637\u0642\u062a\u0647 \u0648\u064a\u0643\u0648\u0646 \u0647\u0646\u0627\u0644\u0643 \u0627\u0634\u062e\u0627\u0635  \u0645\u0646 \u0646\u0641\u0633 \u0627\u0644\u0645\u0646\u0637\u0642\u0629 \u064a\u0641\u0647\u0645 \u0644\u063a\u0629 \u0627\u0644\u0645\u062a\u0643\u0644\u0645 \u0648\u064a\u062c\u064a\u0628\u0647 \u0639\u0644\u0649 \u0627\u0633\u0627\u0633\u0647\u0627 \u0648\u064a\u0648\u062c\u062f \u0627\u0634\u062e\u0627\u0635 \u0643\u062b\u0631 \u0645\u062a\u0637\u0648\u0639\u064a\u0646 \u0641\u064a \u0646\u0634\u0631 \u0627\u0644\u0645\u0639\u0644\u0648\u0645\u0629 \u0648\u0627\u0644\u062e\u064a\u0631 \u0628\u0627\u0644\u0645\u062c\u0627\u0646 \u0633\u0648\u0627\u0621 \u0643\u0627\u0646\u062a \u0627\u0644\u0637\u0628 \u0627\u0648 \u0627\u0644\u0647\u0646\u062f\u0633\u0629 \u0627\u0648 \u0639\u0644\u0645 \u0645\u0639\u064a\u0646 \u0627\u0648 \u0627\u064a \u0639\u0644\u0645 \u0648\u0645\u0639\u0644\u0648\u0645\u0629\u0627\u0644\u0645\u062e\u062a\u0635\u0631 \u0639\u0646\u062f\u0645\u0627 \u0627\u062a\u0643\u0644\u0645 \u0645\u0646 \u0627\u0644\u062e\u0627\u062f\u0645 \u062d\u0648\u062c\u0644 \u0635\u0648\u062a \u0644\u0627 \u064a\u062a\u0643\u0644\u0645 \u0628\u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0627\u0644\u0641\u0635\u062d\u0649 \u0648\u0644\u0643\u0646 \u064a\u0648\u062c\u062f \u0627\u0634\u062e\u0627\u0635 \u0643\u0627\u062f\u0645 \u062d\u0648\u062c\u0644 \u064a\u062d\u0644\u0644\u0648\u0646 \u0627\u0644\u0643\u0644\u0627\u0645 \u0628\u0644\u063a\u0629 \u0627\u0644\u0634\u062e\u0635 \u0627\u0644\u0645\u062a\u0643\u0644\u0645 \u0643\u0644\u064b \u062d\u0633\u0628 \u0645\u0646\u0637\u0642\u062a\u0647..\u0627\u062a\u0645\u0646\u0627 \u0648\u0635\u0644\u062a \u0627\u0644\u0645\u0639\u0644\u0648\u0645\u0629 \u0648\u0627\u0630\u0627 \u0628\u062f\u0643\u0645 \u0627\u062d\u0643\u064a\u0647\u0627 \u0635\u0648\u062a \u0648\u0627\u0634\u0631\u062d\u0647\u0627 \u0627\u0641\u0636\u0644 \u064a\u0627\u0631\u064a\u062a \u062a\u062e\u0628\u0631\u0648\u0646\u064a \u0648\u0627\u062a\u0648\u0627\u0635\u0644 \u0645\u0639\u0643\u0645 ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-07T09:07:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I would like to inform you that Arabic\u00a0 is not a supported language [1]. I would recommend you to re-formulate your issue in English and we will be very happy to help you.\n\n\u00a0\n\nThanks\n\n[1]\n\nhttps:\/\/cloud.google.com\/support\/docs\/language-working-hours#language_support"
            },
            {
                "Answer_creation_date":"2021-12-07T09:08:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I would like to inform you that Arabic\u00a0 is not a supported language [1]. I would recommend you to re-formulate your issue in English and we will be very happy to help you.\n\n\u00a0\n\nThanks\n\n[1]\n\nhttps:\/\/cloud.google.com\/support\/docs\/language-working-hours#language_support"
            }
        ]
    },
    {
        "Question_title":"Unstructured data in Vertex AI feature store",
        "Question_creation_date":"2021-11-30T16:34:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unstructured-data-in-Vertex-AI-feature-store\/td-p\/176796\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":312,
        "Question_body":"Does Vertex AI feature store support ingestion, transformation and storage of unstructured data like images and audio?",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-01T13:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nAs per source data requirements [1] regarding Vertex AI Feature Store, it does not look like that you'll be able to ingest unstructured data.\n\n\"Vertex AI Feature Store can ingest data from tables in BigQuery or files in Cloud Storage. For files in Cloud Storage, they must be in the Avro or CSV format.\"\n\n[1]\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/featurestore\/source-data"
            }
        ]
    },
    {
        "Question_title":"3D object detection using mobile camera or 3D scanner using cloud vision",
        "Question_creation_date":"2021-11-23T00:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/3D-object-detection-using-mobile-camera-or-3D-scanner-using\/td-p\/176320\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":58,
        "Question_body":"The use case is, I want detect the 3d model through mobile camera or 3d scanner with dimensions to verify the scanned model is available or not in cloud storage. If model is not available it should list the model with approx model with percentage. ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-01T07:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\n\nHere is a general guide on training Edge models, that you can export to Edge devices, for on-prem use.\n\nI also found this list of more detailed guides on training, and deploying the model either on an Edge device, or online. It includes this page which talks about training Edge exportable models."
            }
        ]
    },
    {
        "Question_title":"About Object Localization in Vision API",
        "Question_creation_date":"2021-11-25T02:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/About-Object-Localization-in-Vision-API\/td-p\/176494\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":0,
        "Question_view_count":120,
        "Question_body":"Hi,We are considering using the Object Localization feature in the Vision API, however, we cannot find any information about supported object classes. Is the information open to the public? If Yes, where can we find the information?Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-29T12:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nwould you please give more details about the object classes and its meaning? if you give an example with other services will be very helpful. The bellow information is my findings and I need to confirm if that what you have being asking about?\n\nThe public documentation [1], mentions only that Object localization identifies multiple objects in an image and provides a LocalizedObjectAnnotation for each object in the image.\n\nThe only place where classes are mentioned, for instance:\n.net client library, all operations are performed through the following client classes: ImageAnnotatorClient, ProductSearchClient\n\nJava client library, shows the classes supported [3].\n\n\u00a0\n\n[1]https:\/\/cloud.google.com\/vision\/docs\/object-localizer\n[2]https:\/\/cloud.google.com\/dotnet\/docs\/reference\/Google.Cloud.Vision.V1\/latest\/index\n[3]https:\/\/googleapis.dev\/java\/google-cloud-vision\/latest\/index.html"
            },
            {
                "Answer_creation_date":"2021-11-29T18:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\u00a0abdelilahf,\n\nThanks for your detailed information. Sorry for not giving a clear description of my inquiry. I would like to know what kind of objects (for example, bicycles and doors) will be detected in the Object Localization feature of the Vision API. If Google can provide a list of supported objects, that would be helpful.\n\nThank you."
            }
        ]
    },
    {
        "Question_title":"Can anyone tell what is the approximate SLOC of Google Vertex AI? For my comparative analysis study.",
        "Question_creation_date":"2021-11-28T16:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Can-anyone-tell-what-is-the-approximate-SLOC-of-Google-Vertex-AI\/td-p\/176629\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":74,
        "Question_body":"I am doing a comparative analysis of predictive analytics software for my Project. I am looking for approximate lines of code for the Google Vertex AI product.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\u00a0\n\nSLOC will be different depending on your specific use case, and you should be in the best position to figure out the approximate SLOC for your scenarios. That being said, you might look into the sample code and notebooks for Vertex AI, the end-to-end machine learning platform on Google Cloud at [1].\n\n[1]\u00a0https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-11-29T12:59:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\u00a0\n\nSLOC will be different depending on your specific use case, and you should be in the best position to figure out the approximate SLOC for your scenarios. That being said, you might look into the sample code and notebooks for Vertex AI, the end-to-end machine learning platform on Google Cloud at [1].\n\n[1]\u00a0https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples"
            }
        ]
    },
    {
        "Question_title":"Manage Labeling Assignments on DataCompute",
        "Question_creation_date":"2021-11-11T20:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Manage-Labeling-Assignments-on-DataCompute\/td-p\/175499\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":1,
        "Question_view_count":416,
        "Question_body":"Our team has started to use the DataCompute console to assign labelers to labeling tasks created in Vertex AI. Currently, the Assignments tab requires the Labeling Manager to Populate the Specialists Column and Populate the Tasks Column I wanted to highlight some issues we are facing and ask if there's any plan to implement fixes.Issues: 1. The dropdown for task selection does not order the tasks alphabetically so it is difficult to find a specific task.2. There's no \"Select All\" option, instead, the manager must select each task individually.3. There is no drop down for the specialist emails even though they are available under the Specialists tab.Generally, it would be nice to see the entire assignment table by default rather than nothing on this page.Let me know if some of these issues can be addressed! ",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-25T15:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for your input. Can you provide the reproduction steps so we can update it on this thread\u00a0\nPlease note that such issues are usually submitted and handled by the product teams via Public Issue Tracker. Therefore, I just submitted your request to the Vertex AI product team on\u00a0this thread, and I recommend you to star it as all future updates will occur there."
            }
        ]
    },
    {
        "Question_title":"is there any list of brands\/logos supported by google vision api?",
        "Question_creation_date":"2021-11-10T21:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/is-there-any-list-of-brands-logos-supported-by-google-vision-api\/td-p\/175425\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":233,
        "Question_body":"is there anyplace i can see the list of brands\/logos that are currently supported by the google vision api's logo recognition service?",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-23T11:41:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"The product team does not currently publish such a list. I recommend for you to submit a Feature Request to the Vision API product team.\u00a0\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-11-23T11:41:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"The product team does not currently publish such a list. I recommend for you to submit a Feature Request to the Vision API product team."
            }
        ]
    },
    {
        "Question_title":"Speech to Text using Microphone",
        "Question_creation_date":"2021-11-21T22:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-to-Text-using-Microphone\/td-p\/176201\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":99,
        "Question_body":"Hi there, Was trying to use convert speech to text using a microphone, getting a pop-up security error saying \"failed to construct 'worker': script at ..........\"Any idea why?Also, how can I use the speech to text service with microphone input, I tested uploading a video file and worked perfectly, but no idea how to use the service with microphone input?Please let me know AJ",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-22T15:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"- The error message [1] can be seen in Chrome as Chrome doesn't let you load web workers when running scripts from a local file. You can try using a different web browser like Firefox and verify if it works for you.\n\n- In order to read from microphone, you can install PyAudio in your machine.\n\nYou can refer to the documentation [2] [3] to use the speech to text service with microphone input.\n\n[1] \"failed to construct 'worker': script at\n\n[2] https:\/\/www.thepythoncode.com\/article\/using-speech-recognition-to-convert-speech-to-text-python\n\n[3] https:\/\/pypi.org\/project\/SpeechRecognition\/"
            }
        ]
    },
    {
        "Question_title":"How to package custom prediction code and serve it using an Endpoint in Vertex AI ?",
        "Question_creation_date":"2021-10-25T11:36:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-package-custom-prediction-code-and-serve-it-using-an\/td-p\/173876\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":2,
        "Question_view_count":204,
        "Question_body":"Goal: serve prediction request from a Vertex AI Endpoint by executing custom prediction logic.Expected Workflow:1. Upload a pretrained image_quality.pb model (developed in a non vertex-ai pythonic environment) in a gcs bucket2. Port existing image inference logic into a container and serve the prediction functionality through a vertex AI endpoint. 3. Use Vertex AI api for logging and capturing metrics inside the  custom inference logic.4. Finally we want to pass a list of images (stored in another gcs bucket) to that endpoint.5. We also want to see the logs and metrics in tensorboard.Existing Vertex AI code samples provide examples for custom training , invoking model.batch_predict \/ endpoint.predict , but don't mention how to execute custom prediction code.It would be great if someone can provide guidelines and links to documents\/code in order to implement the above steps.Thanks  ",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-19T07:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Please find the following guides respective of the points\n\n1.\n[1] Import model:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/import-model\n[2] What cannot be migrated:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/start\/migrating-to-vertex-ai#migration-exceptions\n2.\n[3] Custom containers:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/training\/containers-overview\n[4] https:\/\/cloud.google.com\/vertex-ai\/docs\/training\/create-custom-container\n3.\n[5] About metrics:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/monitoring-metrics\n4.\n[6] Passing list of images:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/datasets\/create-dataset-api\n5.\n[7] Metrics in Tensorboard:\u00a0https:\/\/cloud.google.com\/architecture\/ml-on-gcp-best-practices?hl=en#use-vertex-tensorboard-to-visua...\n\n\nAs there is no existing unifying guide for these operations, I created a documentation feature request to have one, and asked the documentation team to post updates here."
            }
        ]
    },
    {
        "Question_title":"ML",
        "Question_creation_date":"2021-11-12T04:50:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/ML\/td-p\/175533\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud Natural Language API",
            "Contact Center AI",
            "Document AI",
            "Recommendations AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":311,
        "Question_body":"How to start my journey for being an ML\/AI or data science engineer?",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-12T04:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"How to start my journey for being an ML\/AI or data science engineer?"
            }
        ]
    },
    {
        "Question_title":"Speech to text work",
        "Question_creation_date":"2021-11-08T00:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-to-text-work\/td-p\/175139\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Cloud Translation API",
            "Contact Center AI",
            "Dialogflow CX",
            "Recommendations AI",
            "Speech-to-Text",
            "Text-to-Speech",
            "Video Intelligence API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":325,
        "Question_body":"  I am a user of Speech to Text. I use it in order to get a written text from the interviews and courses I shoot myself. After that I correct the text manually. So, in Russian it works fine, however, 20-30 percents of the words are incorrect. Moreover, there are no Russian punctuation at all.  So I get the speech to text transcript, then I create the perfect transcript out of this with correct words and punctuations. All I want to know is how I can improve Speech toText by using the perfect transcript I have already corrected? Where I can send that data to?",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-09T09:36:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\u00a0\n\nIf you're using the Google Cloud Speech-to-Text API [1] and encounter text quality problem, I would suggest that you can report the issue at the Issue Tracker [2] with the reproduction details for the support to further look into issue with you to improve the quality.\u00a0\n\n[1]\u00a0https:\/\/cloud.google.com\/speech-to-text\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers"
            }
        ]
    },
    {
        "Question_title":"speech-to-text improvements",
        "Question_creation_date":"2021-11-01T09:36:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/speech-to-text-improvements\/td-p\/174445\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":331,
        "Question_body":"Good afternoon!I am a user of Speech-to-Text. I use it in order to get a written text from the interviews and courses I shoot myself. After that I correct the text manually.So, in Russian it works fine, however, 30-40 percents of the words are incorrect. Moreover, there are no Russian punctuation at all.  So I get the speech-to-text transcript, then I create the perfect transcript out of this with correct words and punctuations.All I want to know is how I can improve Speech-to-Text by using the perfect transcript I have already corrected? Where I can send that data to?P.S. Sorry for my English. I hope You can understand me",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-05T07:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\u00a0\n\nIf you're using the Google Cloud Speech-to-Text API [1] and encounter text quality problem, I would suggest that you can report the issue at the Issue Tracker [2] with the reproduction details for the support to further look into issue with you to improve the quality.\u00a0\n\n[1]\u00a0https:\/\/cloud.google.com\/speech-to-text\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers"
            }
        ]
    },
    {
        "Question_title":"Recommendations AI - catalog update not reflecting in console",
        "Question_creation_date":"2021-11-02T22:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Recommendations-AI-catalog-update-not-reflecting-in-console\/td-p\/174619\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Recommendations AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":319,
        "Question_body":"In Recommendations AI, I tried uploading the catalog from GCS. On uploading the catalog, I could see the catalog products showing up in the console but there is a warning notification stating the catalog is not integrated and the total product count is always zero.I have tried both recommended methods of uploading the catalog data from GCS directly through the GCP console and also through the CLI but still, this issue persists. I have followed every instruction provided in this GCP documentation but still, I couldn't figure out the actual issue and not much information is available in the public domain as well \n\nCan someone help with this??\nThanks ",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-04T18:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nCan you go over the troubleshooting guide\u00a0and see if you can get more details on the issue from the Cloud logging logs or from any API errors there might be?\n\nYou might also try to inspect your browser's log network activity when retrying to upload the catalog with the console method."
            }
        ]
    },
    {
        "Question_title":"Does Vertex AI support labels for counting?",
        "Question_creation_date":"2021-10-25T08:47:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Does-Vertex-AI-support-labels-for-counting\/td-p\/173840\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":404,
        "Question_body":"I have an image where I have to do a multi-label classification and additionally count the number of a specific item in each image. I'm trying to setup a labeling task so I can enter a continuous number (0-100 for example), but there doesn't seem to be support for it.  Additionally, does the labeling have capabilities to pre-choose a \"default\"  value? Does anyone have an idea?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nAs you have rightly mentioned, Vertex AI does not presently support object counting in an image. Please feel free to reach out to submit a feature request via the issue tracker link[0] to the Vertex AI product team about such implementations.\n\nAs mentioned in this article[1], there are only three ways to assign labels to your training data items:\n\n-- Add the data items to your dataset with their labels already assigned, for example using a commercially available dataset\n-- Assign labels to the data items using the Cloud Console\n-- Request to have human labelers add labels to the data items\n\nAt this time, none of these options provide ways to pre-choose a \"default\" value. May be there may be workarounds to explore using your own human labelers via your instructions.\n\n\n[0]https:\/\/developers.google.com\/issue-tracker\/#public_users\n[1]https:\/\/cloud.google.com\/vertex-ai\/docs\/datasets\/data-labeling-job"
            }
        ]
    },
    {
        "Question_title":"Is there a way to resend invitation emails to labelers inside a Vertex AI Labeler group?",
        "Question_creation_date":"2021-10-26T09:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Is-there-a-way-to-resend-invitation-emails-to-labelers-inside-a\/td-p\/173962\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":348,
        "Question_body":"I have added a Labeler Group to my Labeling task in Vertex AI but none of the members of the labeler group received an invite email.How can I ensure this invite email is sent?",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-04T13:03:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi izvonkov,\n\nYou can try to delete and re-add labelers in the Manager Console under 'Specialists' page.\n\nPlease keep in mind that it takes some time for Vertex AI to generate the resources for labelers to work with. Once the resources are ready, your designated group manager and labelers will receive the email notification with the link to access their Specialist page.\n\nI hope the provided information is useful for you.\n\nBest Regards,\nKailong\nGoogle Cloud Platform Support, Montreal"
            }
        ]
    },
    {
        "Question_title":"Model adaptation - Speech-to-Text - GA?",
        "Question_creation_date":"2021-10-19T08:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Model-adaptation-Speech-to-Text-GA\/td-p\/173368\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":365,
        "Question_body":"Hello,I'd like to know if Model adaptation feature is ready to use in production (custom classes, phrase sets, etc). Official web documentation (https:\/\/cloud.google.com\/speech-to-text\/docs\/model-adaptation) says it is a preview feature (Pre-GA). Also, REST resources are inside namespace v1p1beta1 (https:\/\/cloud.google.com\/speech-to-text\/docs\/reference\/rest).On the other hand, release notes web page (https:\/\/cloud.google.com\/speech-to-text\/docs\/release-notes#May_07_2021) says \"The Speech-to-Text model adaptation  feature is now a GA feature\".Thank you very much,Pablo Gomez",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Pablo\n\nThe documentation [1] was just updated 2021-10-27 UTC, and there is no 'preview feature' mentioned in it.\n\nAlso release notes are always more reliable source of information regarding feature updates for Google Cloud Platform\n\nBest Regards,\nKailong\nGoogle Cloud Platform Support, Montreal\n\n[1] https:\/\/cloud.google.com\/speech-to-text\/docs\/model-adaptation"
            }
        ]
    },
    {
        "Question_title":"Model changes",
        "Question_creation_date":"2021-10-19T12:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Model-changes\/td-p\/173396\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":322,
        "Question_body":"It appears that the default model for GCP Cloud Vision API has changed. Specifically, the current API results lack localized objects that were available previously, say around June 2021. How does the team communicate, if at all, what entities the model supports? Thanks.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As per the release notes [1], it doesn't seem like there was any change to the default model.\n\nFrom all of the available models [2], for your use case you can use the object localizer [3].\n\n[1] https:\/\/cloud.google.com\/vision\/docs\/release-notes\n[2] https:\/\/cloud.google.com\/vision\/docs\/reference\/rest\/v1\/Feature#type\n[3] https:\/\/cloud.google.com\/vision\/docs\/object-localizer"
            }
        ]
    },
    {
        "Question_title":"AutoML Tables for model where comparison is required?",
        "Question_creation_date":"2021-09-29T05:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-Tables-for-model-where-comparison-is-required\/td-p\/171520\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":361,
        "Question_body":"Hi there,I have used GCP for a while now, and have trained quite a few models using AutoML Tables - all of these have been fairly simple datasets with probably a maximum of 20 columns. I now have a problem that I would like to solve, but the dataset is a lot more complicated. I want to be able to predict the results of Greyhound Racing, or at least the % chances of each Greyhound winning a given race, compared to the other greyhounds running in that same race. To be able to do this I need to feed multiple pieces of data for each Greyhound in each given race, to be able to predict the winning chance of that greyhound in that day's race.However, I am very stuck on how to structure my data. Using AutoML Tables - would I need to structure the data in a tabular form with many columns? Or is there a better way to tackle this problem.Here is an example of the data I would be using:Race:Example data for each Greyhound in the race: Does anyone please have any advice of how to tackle this kind of problem, and how best to structure the data to attempt to predict the winning chance of each Greyhound for that day's race, based on that greyhound's previous data, compared to the other greyhounds in that day's race? Thanks,\nRob",
        "Answers":[
            {
                "Answer_creation_date":"2021-10-16T08:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, this is tabular data and hence has to be structured as a tabular data. I know this will call for lot of data prep work."
            }
        ]
    },
    {
        "Question_title":"Google cloud text to speech",
        "Question_creation_date":"2021-09-26T06:11:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-cloud-text-to-speech\/td-p\/171231\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":771,
        "Question_body":"I registered myself for the google cloud text-to-speech service recently. Speech Studio worked just fine for the first few days, but today, to my dismay, there is distortion in the text reader's voice.What can I do about it?Thanks.  ",
        "Answers":[
            {
                "Answer_creation_date":"2021-10-01T14:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Speech Studio is not a Google product. TTS voices are always the same though and do not change over time if the same one is selected."
            }
        ]
    },
    {
        "Question_title":"About Speech-to-Text support area",
        "Question_creation_date":"2021-09-26T04:34:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/About-Speech-to-Text-support-area\/td-p\/171226\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":325,
        "Question_body":"Does Speech-to-Text have any nodes in Hong Kong?",
        "Answers":[
            {
                "Answer_creation_date":"2021-10-01T14:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Speech to text is available as a global or multi regional service. You can select a region by specifying a particular endpoint.\u00a0\u00a0https:\/\/cloud.google.com\/speech-to-text\/docs\/endpoints\n\n\u00a0\n\nHong Kong is not currently available as a standalone region."
            }
        ]
    },
    {
        "Question_title":"Issues with Handover Protocols - Facebook & Dialogflow",
        "Question_creation_date":"2021-09-29T18:02:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Issues-with-Handover-Protocols-Facebook-amp-Dialogflow\/td-p\/171609\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":343,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2021-09-29T18:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We're currently experiencing an ongoing issue where Bot conversations in our Facebook inbox are moving from \u2018Main\u2019 to \u2018Done\u2019 without any manual agent involvement. This means that conversations being escalated to the Main folder from the Bot will revert to the Done folder and the Bot will answer again.\n\u00a0\nOnce the conversation with the bot has been escalated to a human, there should be no further Bot involvement.\n\u00a0\nThis issue originally started after we noticed a failed payment on our Dialogflow account, where we went in, updated payment information and successfully charged the card to resume services. However, once we initiated a few test conversations, we noticed the above.. any advice or suggestions?"
            }
        ]
    },
    {
        "Question_title":"Vertex AI dataset permissions",
        "Question_creation_date":"2021-09-20T07:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-dataset-permissions\/td-p\/170536\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":432,
        "Question_body":"Is there a way to assign IAM roles to datasets in Vertex AI so only certain people have access to certain datasets?",
        "Answers":[
            {
                "Answer_creation_date":"2021-09-20T07:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Is there a way to assign IAM roles to datasets in Vertex AI so only certain people have access to certain datasets?"
            }
        ]
    },
    {
        "Question_title":"Fast Start GPU for AI training",
        "Question_creation_date":"2021-09-02T02:41:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Fast-Start-GPU-for-AI-training\/td-p\/168768\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":1,
        "Question_view_count":341,
        "Question_body":"Is there a way to fast start-up GPU (like Cloud RUN) if there is training request come-in?Due to GPU cost is high, turn-on 24 hours\/day does not make sense.Pre-empted GPU cloud be another option but offer only 1st minute free.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I made a 4000-word guide for people looking to build Nvidia Ampere prosumer workstations and servers, including:\n\n\u00a0\n\nDifferent budget tiers\n\nWhere to place them, home, office, data center, etc.\n\nConstraints with consumer GPUs\n\n\u00a0\n\nMy CC Pay"
            }
        ]
    },
    {
        "Question_title":"cloud vision text coordinates format",
        "Question_creation_date":"2021-09-15T23:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/cloud-vision-text-coordinates-format\/td-p\/170059\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API",
            "Document AI"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":322,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2021-09-15T23:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Team,\n\u00a0\nI was going through the vision api document https:\/\/cloud.google.com\/vision\/docs\/pdf to understand the format of the coordinates of the text.\u00a0 I was a bit confused regarding the normalized values.\n\u00a0\nCould you please clarify on how to find the original coordinates with respect the dimension of the document.\n\u00a0\nThanks,\nArun"
            }
        ]
    },
    {
        "Question_title":"Artificial Intelligence - list of APIs",
        "Question_creation_date":"2021-07-23T18:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Artificial-Intelligence-list-of-APIs\/td-p\/164618\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "Document AI",
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_upvote_count":1,
        "Question_view_count":485,
        "Question_body":"Good day.Is it possible to list the Google APIs in the Artificial Intelligence, especially in the Voice recognitions, comparison, analytics etc? Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2021-07-25T12:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Let's try this link for a start ...\nhttps:\/\/cloud.google.com\/products\/ai\n\nThis appears to list all the various GCP products related to AI and, if one were to delve into each product, one would find the corresponding APIs."
            },
            {
                "Answer_creation_date":"2021-08-02T03:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"And take a look at the \"Google Cloud in\u00a0 Words\" cheat sheet\n\nhttps:\/\/github.com\/gregsramblings\/google-cloud-4-words\/blob\/master\/Brochure.pdf"
            },
            {
                "Answer_creation_date":"2021-08-22T20:43:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"@pascal_reddig\u00a0wrote: mcdvoice\n\n\nAnd take a look at the \"Google Cloud in\u00a0 Words\" cheat sheet\n\nhttps:\/\/github.com\/gregsramblings\/google-cloud-4-words\/blob\/master\/Brochure.pdf\n\nCarry on, don\u2019t stop posting like this"
            }
        ]
    },
    {
        "Question_title":"How to advise Safe Search",
        "Question_creation_date":"2021-08-20T14:00:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-advise-Safe-Search\/td-p\/167893\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":372,
        "Question_body":"I'm using Safe Search API in Cloud Vision to detect adult or harmful pictures and don't let them pass to be published in my project. But sometimes pictures are recognized wrong - not adult picture tagged so. Is it possible to \"teach\" Vision API, or mark a file as safe for my project? ",
        "Answers":[
            {
                "Answer_creation_date":"2021-08-20T14:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I'm using Safe Search API in Cloud Vision to detect adult or harmful pictures and don't let them pass to be published in my project. But sometimes pictures are recognized wrong - not adult picture tagged so. Is it possible to \"teach\" Vision API, or mark a file as safe for my project?"
            }
        ]
    },
    {
        "Question_title":"enhanced speech feature",
        "Question_creation_date":"2021-08-19T01:34:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/enhanced-speech-feature\/td-p\/167747\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API",
            "Dialogflow CX",
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":414,
        "Question_body":"Hi I have a queryIn Dailogflow if we enable enhanced speech feature, specifically, credit card info (i.e. number), if that is spoken by user, is that stored by Google. Please help",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI understand you are looking to use the enhanced model in Dialogflow and you are looking to understand the Data Security. Please let me know if my understanding is wrong.\n\nIf that is what you are looking for, then I think you should read this section of this article[0] which addresses this concern. As explained in the doc[0], Google uses the data sent to Dialogflow on the project with data logging enabled. Google uses this data solely to train and improve Google products and services. So, while you'll maintain full ownership of all data that you upload to a project with data logging enabled, there are some terms[1] which I think you should be aware of.\n\n[0]https:\/\/cloud.google.com\/dialogflow\/es\/docs\/speech-enhanced-models#data-security\n[1]https:\/\/cloud.google.com\/dialogflow\/docs\/data-logging-terms\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-08-20T06:59:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI understand you are looking to use the enhanced model in Dialogflow and you are looking to understand the Data Security. Please let me know if my understanding is wrong.\n\nIf that is what you are looking for, then I think you should read this section of this article[0] which addresses this concern. As explained in the doc[0], Google uses the data sent to Dialogflow on the project with data logging enabled. Google uses this data solely to train and improve Google products and services. So, while you'll maintain full ownership of all data that you upload to a project with data logging enabled, there are some terms[1] which I think you should be aware of.\n\n[0]https:\/\/cloud.google.com\/dialogflow\/es\/docs\/speech-enhanced-models#data-security\n[1]https:\/\/cloud.google.com\/dialogflow\/docs\/data-logging-terms"
            }
        ]
    },
    {
        "Question_title":"NLP is hard",
        "Question_creation_date":"2021-08-15T22:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/NLP-is-hard\/td-p\/167242\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "Cloud Natural Language API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":328,
        "Question_body":"Who else thinks NLP is the hardest subset of AI to build?",
        "Answers":[
            {
                "Answer_creation_date":"2021-08-15T22:44:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Who else thinks NLP is the hardest subset of AI to build?"
            }
        ]
    },
    {
        "Question_title":"Can we Download an AutoML Model after training?",
        "Question_creation_date":"2021-08-05T11:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Can-we-Download-an-AutoML-Model-after-training\/td-p\/166258\/jump-to\/first-unread-message",
        "Question_topic":[

        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":273,
        "Question_body":"Is there a way to Download the AutoML Model after training?",
        "Answers":[
            {
                "Answer_creation_date":"2021-08-05T11:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Is there a way to Download the AutoML Model after training?"
            }
        ]
    },
    {
        "Question_title":"Voice\/language options during conversion of long text files to speech",
        "Question_creation_date":"2021-08-02T19:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Voice-language-options-during-conversion-of-long-text-files-to\/td-p\/165947\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_upvote_count":0,
        "Question_view_count":375,
        "Question_body":"The voice\/language options during conversion of long text files to speech. Can anyone help with the doc\/sample for the same.",
        "Answers":[
            {
                "Answer_creation_date":"2021-08-03T15:53:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Howdy Ram56.\u00a0 Could you perhaps elaborate on what you are looking for?\u00a0 We'll be delighted to try and assist.\u00a0\u00a0\n\nHere is the home page for the GCP Text To Speech materials with links to docs:\n\nhttps:\/\/cloud.google.com\/text-to-speech\n\nI fully realize that is a fluffy response ... so if you can add a little more detail to the voice\/language query in your question, we'll get back to you ASAP.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-08-03T15:53:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Howdy Ram56.\u00a0 Could you perhaps elaborate on what you are looking for?\u00a0 We'll be delighted to try and assist.\u00a0\u00a0\n\nHere is the home page for the GCP Text To Speech materials with links to docs:\n\nhttps:\/\/cloud.google.com\/text-to-speech\n\nI fully realize that is a fluffy response ... so if you can add a little more detail to the voice\/language query in your question, we'll get back to you ASAP."
            }
        ]
    },
    {
        "Question_title":"7 days left: learn new skills with free access to data, ML and AI labs!",
        "Question_creation_date":"2021-08-02T09:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/7-days-left-learn-new-skills-with-free-access-to-data-ML-and-AI\/td-p\/165897\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":0,
        "Question_view_count":369,
        "Question_body":"Don't miss this great, free ML\/AI learning opportunity! Crossposting from the Learning Forums:https:\/\/www.googlecloudcommunity.com\/gc\/Learning-Forums\/Your-mission-should-you-choose-to-accept-it\/...  ",
        "Answers":[
            {
                "Answer_creation_date":"2021-08-02T09:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Don't miss this great, free ML\/AI learning opportunity!\n\n\u00a0\n\nCrossposting from the Learning Forums:\n\nhttps:\/\/www.googlecloudcommunity.com\/gc\/Learning-Forums\/Your-mission-should-you-choose-to-accept-it\/..."
            }
        ]
    },
    {
        "Question_title":"Should I custom split my image data?",
        "Question_creation_date":"2021-07-05T04:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Should-I-custom-split-my-image-data\/td-p\/163031\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_upvote_count":1,
        "Question_view_count":461,
        "Question_body":"Even with auto Ml, should carefully custom split my data to my satisfaction or just leave it to AutoML? And what difference does it make?",
        "Answers":[
            {
                "Answer_creation_date":"2021-07-14T06:16:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Ayoola\n\nIf your data is large enough and have wide representation of each category, you may go with the automated split in AutoML. That would save time and perform well.\n\nIf you have some specific needs, such as the representation of certain observations in a specific category is important and limited within the data, you may want to make sure that it is well distributed for validation and test. And custom split would help for that. Another reason of using custom split could be for comparison of your model performance with external models so you use exactly the same training\/test datasets and make an apples to apples comparison.\n\nHere are some tips I find useful in this doc:\n\nhttps:\/\/cloud.google.com\/vision\/automl\/docs\/beginners-guide#distribute_examples_equally_across_categ...\n\nCheers\n\nTuba.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-07-14T06:16:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Ayoola\n\nIf your data is large enough and have wide representation of each category, you may go with the automated split in AutoML. That would save time and perform well.\n\nIf you have some specific needs, such as the representation of certain observations in a specific category is important and limited within the data, you may want to make sure that it is well distributed for validation and test. And custom split would help for that. Another reason of using custom split could be for comparison of your model performance with external models so you use exactly the same training\/test datasets and make an apples to apples comparison.\n\nHere are some tips I find useful in this doc:\n\nhttps:\/\/cloud.google.com\/vision\/automl\/docs\/beginners-guide#distribute_examples_equally_across_categ...\n\nCheers\n\nTuba."
            },
            {
                "Answer_creation_date":"2021-07-15T23:26:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks so much for the response."
            }
        ]
    },
    {
        "Question_title":"AutoML - pre-trained models?",
        "Question_creation_date":"2021-07-01T12:49:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-pre-trained-models\/td-p\/162864\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_upvote_count":1,
        "Question_view_count":496,
        "Question_body":"I know that for AutoML, the user has to train the model. But are there existing \"pre-trained\" models that you can leverage to identify sentiments or classifications like profanity, irony, and bullying? ",
        "Answers":[
            {
                "Answer_creation_date":"2021-07-01T23:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you please add more details about the sample text\/document that you are trying?. The powerful pre-trained models of the\u00a0Natural Language API\u00a0\u00a0empowers developers to easily apply natural language understanding (NLU) to their applications with features including sentiment analysis, entity analysis, entity sentiment analysis, content classification, and syntax analysis.\n\nSamples: https:\/\/cloud.google.com\/natural-language\/automl\/docs\/samples"
            }
        ]
    },
    {
        "Question_title":"Vertex AI - Any trainings ?",
        "Question_creation_date":"2021-06-23T16:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Any-trainings\/td-p\/161842\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_upvote_count":2,
        "Question_view_count":551,
        "Question_body":"Hi CommunityFirstly I would like to congratulate all for the announcement of VertexAI.I am interested to know that with the advent of VertexAI, is the AI-Platform planned to be deprecated completely ? How can existing AIP ML engineers easily transit to VertexAI as there's a huge list of topics and things which VertexAI has brought in and has changed the way GCP is doing ML going forward.Do we have any free Qwiklabs notebooks specifically for VertexAI as now I find myself a lot unaware about new GCP ML( VertexAI ) stack even though I am a GCP ML certified Engineer. This is I am sure an issue with a lot of customers and engineers who were building on AIP since a long time.Hope someone can understand and provide their advice. @rseshadri @Former Community Member what are your thoughts ?",
        "Answers":[
            {
                "Answer_creation_date":"2021-06-24T00:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There has been data cloud summits workshops\/events recently by google and you can get a lot of information there. And they are all on-demand."
            },
            {
                "Answer_creation_date":"2021-06-24T15:33:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0@rafiqhasan\u00a0Check out some of these resources:\n\nVideos:\n\nWhat is Vertex AI?\u00a0\nIntro to Vertex I\/O technical session\nML Summit\n\nCodelabs:\n\nTraining a tabular model with AutoML\u00a0\nBuild an AutoML forecasting model with Vertex AI\u00a0\n\nGood luck!"
            }
        ]
    },
    {
        "Question_title":"What are you looking forward to in Google Cloud NEXT '21?",
        "Question_creation_date":"2021-06-23T09:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-are-you-looking-forward-to-in-Google-Cloud-NEXT-21\/td-p\/161539\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":2,
        "Question_view_count":372,
        "Question_body":"Google Cloud Next conference is happening this year on October 12-14, 2021!What exciting new technologies are you looking forward to?",
        "Answers":[
            {
                "Answer_creation_date":"2021-06-23T09:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Google Cloud Next conference is happening this year on October 12-14, 2021!\n\nWhat exciting new technologies are you looking forward to?"
            }
        ]
    },
    {
        "Question_title":"AI\/ML",
        "Question_creation_date":"2021-06-18T13:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AI-ML\/td-p\/31\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud Natural Language API",
            "Cloud TPU",
            "Cloud Translation API",
            "Cloud Vision API",
            "Contact Center AI",
            "Dialogflow CX",
            "Document AI",
            "Recommendations AI",
            "Speech-to-Text",
            "Text-to-Speech",
            "Video Intelligence API"
        ],
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_upvote_count":10,
        "Question_view_count":532,
        "Question_body":"This is the discussion space to talk about all things AI\/ML related.",
        "Answers":[
            {
                "Answer_creation_date":"2021-06-18T13:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This is the discussion space to talk about all things AI\/ML related."
            }
        ]
    }
]