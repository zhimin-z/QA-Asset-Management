[
    {
        "Question_title":"Optuna - what is a suitable metric for TFKerasPruningCallback?",
        "Question_body":"<p>I've been using optuna to perform a hyperparameter search for a Keras neural network model (using scikit-learn's wrapper, KerasRegressor). I have been trying to implement the TFKerasPruningCallback function to prune unpromising trials, but keep getting the following error: <code>UserWarning: The metric 'val_accuracy' is not in the evaluation logs for pruning. Please make sure you set the correct metric name.<\/code><\/p>\n<p>A recommended metric provided in the <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.integration.TFKerasPruningCallback.html\" rel=\"nofollow noreferrer\">docs<\/a> is 'val_acc', or 'val_accuracy' for tensorflow version &gt; 2 as shown in <a href=\"https:\/\/github.com\/optuna\/optuna-examples\/blob\/main\/tfkeras\/tfkeras_integration.py#L90\" rel=\"nofollow noreferrer\">this example<\/a>. I'm using v2.9.1.<\/p>\n<p>Here's a simplified version of my code:<\/p>\n<pre><code>    def nn(n_layers, neurons):\n    \n        model = Sequential()\n        model.add(Dense(neurons, input_dim=3, activation='relu'))\n        model.add(Dense(1, activation='linear'))\n        model.compile(loss='mean_absolute_error', optimizer='Adam')\n    \n        return model\n    \n    \n    def objective(trial, X_train, y_train):\n    \n        # callbacks\n        cb =  [TFKerasPruningCallback(trial,'val_accuracy')]\n            \n        params =  {'neurons': trial.suggest_int('neurons', 1, 10, 1),\n                   'batch_size': trial.suggest_int('batch_size', 10, 200, 10),\n                   'epochs': trial.suggest_int('epochs', 100, 500, 20),\n                   'callbacks': cb}\n    \n        # create model and perform cross-validation\n        model = KerasRegressor(model=nn, **params)\n        score = np.mean(cross_val_score(model, X_train, y_train, cv=5,\n                                        scoring='neg_root_mean_squared_error'))\n    \n        return score\n\n    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(n_startup_trials=5))\n    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=100)\n<\/code><\/pre>\n<p>Everything works fine if I don't bother to implement the callback. I haven't found any reports of this issue so it might be something really silly that I've overlooked, but I'm stuck. Any advice?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1655383902150,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":61.0,
        "Poster_created_time":1655375540670,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72646172",
        "Tool":"Optuna",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"suitabl metric tfkeraspruningcallback perform hyperparamet search kera neural network model scikit learn wrapper kerasregressor try implement tfkeraspruningcallback function prune unpromis trial get follow error userwarn metric val accuraci evalu log prune sure set correct metric recommend metric provid doc val acc val accuraci tensorflow version shown exampl simplifi version code def layer neuron model sequenti model add dens neuron input dim activ relu model add dens activ linear model compil loss mean absolut error optim adam return model def object trial train train callback tfkeraspruningcallback trial val accuraci param neuron trial suggest int neuron batch size trial suggest int batch size epoch trial suggest int epoch callback creat model perform cross valid model kerasregressor model param score mean cross val score model train train score neg root mean squar error return score studi creat studi direct maxim pruner pruner medianprun startup trial studi optim lambda trial object trial train train trial work fine bother implement callback haven report issu silli overlook stuck advic",
        "Question_preprocessed_content":"suitabl metric perform hyperparamet search kera neural network model try implement function prune unpromis trial metric provid doc tensorflow version shown exampl simplifi version code work fine bother implement haven report stuck advic",
        "Question_gpt_summary_original":"The user is using Optuna for hyperparameter search in a Keras neural network model and is trying to implement the TFKerasPruningCallback function to prune unpromising trials. However, they are getting an error message stating that the metric 'val_accuracy' is not in the evaluation logs for pruning. The recommended metric provided in the Optuna documentation is 'val_acc' or 'val_accuracy' for TensorFlow version > 2. The user has provided a simplified version of their code and is seeking advice on how to resolve the issue.",
        "Question_gpt_summary":"user hyperparamet search kera neural network model try implement tfkeraspruningcallback function prune unpromis trial get error messag state metric val accuraci evalu log prune recommend metric provid document val acc val accuraci tensorflow version user provid simplifi version code seek advic resolv issu"
    },
    {
        "Question_title":"AzureML Scoring Script fails with ImportError: no known parent package",
        "Question_body":"<p>On trying to deploy a Model as a Container, endpoint gets created, however, scoring script fails with an error:<\/p>\n<blockquote>\n<p>ImportError: attempted relative import with no known parent package<\/p>\n<\/blockquote>\n<p>This is because i'm referencing another module (packaged in the docker image using source_directory) with a relative path from scoring file.<\/p>\n<p>Can you help me in resolving this error?<\/p>\n<p>Files\\modules structure (a simplified version):<\/p>\n<p>project  <br \/>\n-&gt;src  <br \/>\n-&gt; scoring.py  <br \/>\n-&gt; module1.py  <br \/>\n-&gt; common  <br \/>\n-&gt; module2.py, etc  <br \/>\n-&gt; <strong>init<\/strong>.py  <br \/>\n-&gt; <strong>init<\/strong>.py  <br \/>\n-&gt; configs  <br \/>\n-&gt; conda_env.yml<\/p>\n<p>In scoring.py,  <br \/>\nfrom .module1.py import SomeClass  <br \/>\n..  <br \/>\n..<\/p>\n<p>In module1.py,  <br \/>\nfrom .common.module2.py importSC2  <br \/>\n...  <br \/>\n..<\/p>\n<p>And below is how an Inference config is initialized:  <br \/>\ninference_config = InferenceConfig(source_directory=&quot;.\/&quot;,  <br \/>\nruntime= &quot;python&quot;,  <br \/>\nentry_script=&quot;src\/scoring.py&quot;,  <br \/>\nconda_file=&quot;configs\/conda_env.yml&quot;  <br \/>\n)<\/p>\n<p>I could not pass entry_script as &quot;src.scoring&quot; as this fails the Validation and relative path to scoring file is expected<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1603969996160,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/144492\/azureml-scoring-script-fails-with-importerror-no-k",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"score script fail importerror known parent packag try deploi model contain endpoint get creat score script fail error importerror attempt rel import known parent packag referenc modul packag docker imag sourc directori rel path score file help resolv error file modul structur simplifi version project src score modul common modul init init config conda env yml score modul import someclass modul common modul importsc infer config initi infer config inferenceconfig sourc directori runtim python entri script src score conda file config conda env yml pass entri script src score fail valid rel path score file expect",
        "Question_preprocessed_content":"score script fail known parent packag try deploi model contain endpoint get creat score script fail rel import known parent packag referenc modul rel path score file help resolv structur project src config import importsc infer config initi runtim python fail valid rel path score file expect",
        "Question_gpt_summary_original":"The user is encountering an error while trying to deploy a model as a container in AzureML. The scoring script fails with an ImportError due to a relative path issue when referencing another module. The user has provided the file and module structure and is seeking help to resolve the error.",
        "Question_gpt_summary":"user encount error try deploi model contain score script fail importerror rel path issu referenc modul user provid file modul structur seek help resolv error"
    },
    {
        "Question_title":"Defining routes in MLflow serving",
        "Question_body":"<p>When we serve mlflow model we define different ports for each serving and to access these models we use IP:port\/invocations<\/p>\n<p>ex:<\/p>\n<p>app 1 : IP:2020\/invocations<\/p>\n<p>app 2 : IP:2021\/invocations<\/p>\n<p>But I want to serve 2 mlflow models at same port with different routes.<\/p>\n<p>ex:<\/p>\n<p>app 1 : IP:2020\/app1<\/p>\n<p>app 2 : IP:2020\/app2<\/p>\n<p>How can I achieve it using MLflow.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1640763158347,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1640842613347,
        "Question_score_count":0.0,
        "Question_view_count":56.0,
        "Poster_created_time":1504498312456,
        "Poster_location":null,
        "Poster_reputation_count":334.0,
        "Poster_view_count":24.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70516388",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"defin rout serv serv model defin differ port serv access model us port invoc app invoc app invoc want serv model port differ rout app app app app achiev",
        "Question_preprocessed_content":"defin rout serv serv model defin port serv model us want serv model port rout achiev",
        "Question_gpt_summary_original":"The user is trying to serve two MLflow models on the same port with different routes, but is unsure how to achieve this using MLflow.",
        "Question_gpt_summary":"user try serv model port differ rout unsur achiev"
    },
    {
        "Question_title":"Unable to access data from S3 bucket to jupyter notebook of aws sagemaker",
        "Question_body":"<p>I need to train a model on aws sagemaker. I'm unable to access data in Jupiter notebook of sagemaker from S3 bucket. My bucket name is &quot;riceleaf&quot; there are four folders in the bucket named as s1,s2,s3,s4 and each folder contains 330 images named as 1.jpg and so on. It is created in Us-east zone. Bucket is private.<\/p>\n<p>One way i did was to access the object and when i displayed the key it shows me 1.jpg and so on. But when i try to open that image it didn't work. So i think I'm unable to get exact data path.<\/p>\n<p>In my code I need exact data path since I'm doing some random data generation in the code so need to access different folders. Therefore, I need a path till bucket so i can change next folder name and image name randomly in my code.<\/p>\n<p>Please help me to so that I can access the images in the Jupiter notebook of sagemaker.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1647841162080,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1647863096848,
        "Question_score_count":0.0,
        "Question_view_count":733.0,
        "Poster_created_time":1647840996452,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71553217",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl access data bucket jupyt notebook need train model unabl access data jupit notebook bucket bucket riceleaf folder bucket name folder contain imag name jpg creat east zone bucket privat wai access object displai kei show jpg try open imag work think unabl exact data path code need exact data path random data gener code need access differ folder need path till bucket chang folder imag randomli code help access imag jupit notebook",
        "Question_preprocessed_content":"unabl data bucket jupyt train model unabl data jupit bucket bucket riceleaf folder bucket name folder contain imag name creat zone bucket privat wai object displai kei show try open imag work think unabl exact data path code exact data path random data gener code folder path bucket chang folder imag randomli code help imag jupit",
        "Question_gpt_summary_original":"The user is facing challenges in accessing data from an S3 bucket to a Jupyter notebook of AWS Sagemaker. The bucket contains four folders with 330 images each, and the user needs to access different folders for random data generation in their code. The user has tried accessing the object, but it did not work, and they need help in getting the exact data path to access the images in the Jupyter notebook.",
        "Question_gpt_summary":"user face challeng access data bucket jupyt notebook bucket contain folder imag user need access differ folder random data gener code user tri access object work need help get exact data path access imag jupyt notebook"
    },
    {
        "Question_title":"Redshift ML \/ SageMaker - Deploy an existing model artifact to a Redshift Cluster",
        "Question_body":"Is it possible to deploy an existing model artifact from SageMaker to Redshift ML? \n\nFor example, with an **Aurora ML** you can reference a SageMaker endpoint and then use it as a UDF in a `SELECT` statement. \n**Redshift ML** works a bit differently - when you call `CREATE MODEL` - the model is trained with **SageMaker Autopilot** and then deployed to the **Redshift Cluster**. \n\nWhat if I already have a trained model, can i deploy it to a Redshift Cluster and then use a UDF for Inference?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1609954586000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668536452452,
        "Question_score_count":0.0,
        "Question_view_count":148.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"As of January 30 2021, you can't deploy an existing model artifact from SageMaker to Redshift ML directly with currently announced Redshift ML preview features. But you can reference  sagemaker endpoint through a lambda function and use that lambda function as an user defined function in Redshift.\n\nBelow would be the steps:\n\n1. Train and deploy your SageMaker model in a SageMaker Endpoint. \n2. Use Lambda function to [reference sagemaker endpoint](https:\/\/aws.amazon.com\/blogs\/machine-learning\/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda\/). \n3. Create a [Redshift Lambda UDF](https:\/\/aws.amazon.com\/blogs\/big-data\/accessing-external-components-using-amazon-redshift-lambda-udfs\/) referring above lambda function to run predictions.",
        "Answer_comment_count":0.0,
        "Question_closed_time":1609955532000,
        "Answer_last_edit_time":1612026491936,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUCMYCx28qRe-MOCIfj91Y2g\/redshift-ml-sagemaker-deploy-an-existing-model-artifact-to-a-redshift-cluster",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"redshift deploi exist model artifact redshift cluster possibl deploi exist model artifact redshift exampl aurora refer endpoint us udf select statement redshift work bit differ creat model model train autopilot deploi redshift cluster train model deploi redshift cluster us udf infer",
        "Question_preprocessed_content":"redshift deploi exist model artifact redshift cluster deploi exist model artifact redshift exampl aurora refer endpoint us udf statement redshift work bit model train autopilot deploi redshift cluster train model deploi redshift cluster us udf infer",
        "Question_gpt_summary_original":"The user is asking if it is possible to deploy an existing model artifact from SageMaker to Redshift ML and use it as a UDF for inference. Redshift ML works differently from Aurora ML, as the model is trained with SageMaker Autopilot and then deployed to the Redshift Cluster when `CREATE MODEL` is called. The user wants to know if they can deploy a pre-trained model to Redshift Cluster and use it as a UDF for inference.",
        "Question_gpt_summary":"user ask possibl deploi exist model artifact redshift us udf infer redshift work differ aurora model train autopilot deploi redshift cluster creat model call user want know deploi pre train model redshift cluster us udf infer"
    },
    {
        "Question_title":"SageMaker XGBoost Parquet Example Code Fails and Errors out. Bug?",
        "Question_body":"Hi, \nI'm trying to run the SageMaker XGBoost Parquet example [linked here](https:\/\/sagemaker-examples.readthedocs.io\/en\/latest\/introduction_to_amazon_algorithms\/xgboost_abalone\/xgboost_parquet_input_training.html). I followed the exact same steps but using my own data. I uploaded my data, converted it to a pandas df. The train_df shape is (15279798, 32) while the test_df shape is (150848, 32). I then converted it to parquet files and uploaded it to an S3 bucket - per example instructions. \n\nMy error is as follows:\n\n```\nFailure reason\nAlgorithmError: framework error: Traceback (most recent call last): File \"\/miniconda3\/lib\/python3.7\/site-packages\/sagemaker_xgboost_container\/data_utils.py\", line 422, in _get_parquet_dmatrix_pipe_mode data = np.vstack(examples) File \"<__array_function__ internals>\", line 6, in vstack File \"\/miniconda3\/lib\/python3.7\/site-packages\/numpy\/core\/shape_base.py\", line 283, in vstack return _nx.concatenate(arrs, 0) File \"<__array_function__ internals>\", line 6, in concatenate ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 32 and the array at index 1 has size 9 During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"\/miniconda3\/lib\/python3.7\/site-packages\/sagemaker_containers\/_trainer.py\", line 84, in train entrypoint() File \"\/miniconda3\/lib\/python3.7\/site-packages\/sagemaker_xgboost_container\/training.py\", line 94, in main train(framework.tr\n\n```\nBut I'm confused because the train and test are the same shape and I added no extra code. My code below:\n\n\n```\n# requires PyArrow installed\ntrain.to_parquet(\"Xgb_train.parquet\")\ntest.to_parquet(\"Xgb_test.parquet\")\n\n%%time\nsagemaker.Session().upload_data(\n    \"Xgb_train.parquet\", bucket=bucket, key_prefix=prefix + \"\/\" + \"Ptrain\"\n)\n\nsagemaker.Session().upload_data(\n    \"Xgb_test.parquet\", bucket=bucket, key_prefix=prefix + \"\/\" + \"Ptest\"\n)\n\ncontainer = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-2\")\n\n%%time\nimport time\nfrom time import gmtime, strftime\n\njob_name = \"xgboost-parquet-example-training-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nprint(\"Training job\", job_name)\n\n# Ensure that the training and validation data folders generated above are reflected in the \"InputDataConfig\" parameter below.\n\ncreate_training_params = {\n    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"Pipe\"},\n    \"RoleArn\": role,\n    \"OutputDataConfig\": {\"S3OutputPath\": bucket_path + \"\/\" + prefix + \"\/single-xgboost\"},\n    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.m5.2xlarge\", \"VolumeSizeInGB\": 20},\n    \"TrainingJobName\": job_name,\n    \"HyperParameters\": {\n        \"max_depth\": \"5\",\n        \"eta\": \"0.2\",\n        \"gamma\": \"4\",\n        \"min_child_weight\": \"6\",\n        \"subsample\": \"0.7\",\n        \"objective\": \"reg:linear\",\n        \"num_round\": \"10\",\n        \"verbosity\": \"2\",\n    },\n    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 3600},\n    \"InputDataConfig\": [\n        {\n            \"ChannelName\": \"train\",\n            \"DataSource\": {\n                \"S3DataSource\": {\n                    \"S3DataType\": \"S3Prefix\",\n                    \"S3Uri\": bucket_path + \"\/\" + prefix + \"\/Ptrain\",\n                    \"S3DataDistributionType\": \"FullyReplicated\",\n                }\n            },\n            \"ContentType\": \"application\/x-parquet\",\n            \"CompressionType\": \"None\",\n        },\n        {\n            \"ChannelName\": \"validation\",\n            \"DataSource\": {\n                \"S3DataSource\": {\n                    \"S3DataType\": \"S3Prefix\",\n                    \"S3Uri\": bucket_path + \"\/\" + prefix + \"\/Ptest\",\n                    \"S3DataDistributionType\": \"FullyReplicated\",\n                }\n            },\n            \"ContentType\": \"application\/x-parquet\",\n            \"CompressionType\": \"None\",\n        },\n    ],\n}\n\n\nclient = boto3.client(\"sagemaker\", region_name=region)\nclient.create_training_job(**create_training_params)\nprint(client)\nstatus = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\nprint(status)\nwhile status != \"Completed\" and status != \"Failed\":\n    time.sleep(60)\n    status = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n    print(status)\n```",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1648146766576,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668604200244,
        "Question_score_count":0.0,
        "Question_view_count":306.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"I just changed my bucket name and file names. It worked now.",
        "Answer_comment_count":0.0,
        "Question_closed_time":1648149098276,
        "Answer_last_edit_time":1648149098276,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUqqbIbodsT42efRxxi1FLzw\/sagemaker-xgboost-parquet-example-code-fails-and-errors-out-bug",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"xgboost parquet exampl code fail error bug try run xgboost parquet exampl link http exampl readthedoc latest introduct amazon algorithm xgboost abalon xgboost parquet input train html follow exact step data upload data convert panda train shape test shape convert parquet file upload bucket exampl instruct error follow failur reason algorithmerror framework error traceback recent file miniconda lib python site packag xgboost contain data util line parquet dmatrix pipe mode data vstack exampl file line vstack file miniconda lib python site packag numpi core shape base line vstack return concaten arr file line concaten valueerror input arrai dimens concaten axi match exactli dimens arrai index size arrai index size handl except except occur traceback recent file miniconda lib python site packag contain trainer line train entrypoint file miniconda lib python site packag xgboost contain train line main train framework confus train test shape ad extra code code requir pyarrow instal train parquet xgb train parquet test parquet xgb test parquet time session upload data xgb train parquet bucket bucket kei prefix prefix ptrain session upload data xgb test parquet bucket bucket kei prefix prefix ptest contain imag uri retriev xgboost region time import time time import gmtime strftime job xgboost parquet exampl train strftime gmtime print train job job ensur train valid data folder gener reflect inputdataconfig paramet creat train param algorithmspecif trainingimag contain traininginputmod pipe rolearn role outputdataconfig soutputpath bucket path prefix singl xgboost resourceconfig instancecount instancetyp xlarg volumesizeingb trainingjobnam job hyperparamet max depth eta gamma min child weight subsampl object reg linear num round verbos stoppingcondit maxruntimeinsecond inputdataconfig channelnam train datasourc sdatasourc sdatatyp sprefix suri bucket path prefix ptrain sdatadistributiontyp fullyrepl contenttyp applic parquet compressiontyp channelnam valid datasourc sdatasourc sdatatyp sprefix suri bucket path prefix ptest sdatadistributiontyp fullyrepl contenttyp applic parquet compressiontyp client boto client region region client creat train job creat train param print client statu client train job trainingjobnam job trainingjobstatu print statu statu complet statu fail time sleep statu client train job trainingjobnam job trainingjobstatu print statu",
        "Question_preprocessed_content":"parquet exampl code fail bug try run parquet exampl exact step data upload data convert panda shape shape convert parquet file upload bucket exampl instruct confus train test shape extra code code",
        "Question_gpt_summary_original":"The user is encountering an error while running the SageMaker XGBoost Parquet example code. The error message indicates a concatenation issue due to mismatched input array dimensions. The user has followed the example instructions and uploaded their own data, which has the same shape for both train and test data. The user is unsure why the error is occurring and has provided their code for reference.",
        "Question_gpt_summary":"user encount error run xgboost parquet exampl code error messag indic concaten issu mismatch input arrai dimens user follow exampl instruct upload data shape train test data user unsur error occur provid code refer"
    },
    {
        "Question_title":"Why do i get :NotLabeledDataset: There is no label column in",
        "Question_body":"<p>Hello I am trying to make a classification model using the ml designer.  <\/p>\n<p>I registert a dataset whit images. Maybe i did it wrong?   <br \/>\nI used the sample that Microsoft designer suplies densnet for image classification. I only changed the dataset whit one that i made.    <\/p>\n<p>I have 5 classes and each one is in thier own subfolder i uploaded the folder. a file type.   <\/p>\n<p>i keep getting the message <\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1.0,
        "Question_created_time":1622732290603,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/421203\/why-do-i-get-notlabeleddataset-there-is-no-label-c",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"notlabeleddataset label column hello try classif model design registert dataset whit imag mayb wrong sampl microsoft design supli densnet imag classif chang dataset whit class thier subfold upload folder file type get messag",
        "Question_preprocessed_content":"label column try model design registert dataset whit imag mayb wrong sampl microsoft design supli densnet imag chang dataset whit thier subfold upload folder file type",
        "Question_gpt_summary_original":"The user is encountering an issue with creating a classification model using the ml designer. They registered a dataset with images but keep getting the error message \"NotLabeledDataset: There is no label column\". They have 5 classes and each one is in their own subfolder, uploaded as a file type.",
        "Question_gpt_summary":"user encount issu creat classif model design regist dataset imag get error messag notlabeleddataset label column class subfold upload file type"
    },
    {
        "Question_title":"How to get image classification prediction from GCP AIPlatform in ruby?",
        "Question_body":"<p>I'm new with ruby and I want to use GCP AIPlatform but I'm struggeling with the payload.<\/p>\n<p>So far, I have :<\/p>\n<pre class=\"lang-rb prettyprint-override\"><code>client = ::Google::Cloud::AIPlatform::V1::PredictionService::Client.new do |config|\n  config.endpoint = &quot;#{location}-aiplatform.googleapis.com&quot;\nend\n\nimg = File.open(imgPath, 'rb') do |img|\n  'data:image\/png;base64,' + Base64.strict_encode64(img.read)\nend\n\ninstance = Instance.new(:content =&gt; img)\n\nrequest = Google::Cloud::AIPlatform::V1::PredictRequest.new(\n  endpoint: &quot;projects\/#{project}\/locations\/#{location}\/endpoints\/#{endpoint}&quot;,\n  instances: [instance]\n)\n\nresult = client.predict request\np result\n<\/code><\/pre>\n<p>Here is my proto<\/p>\n<pre><code>message Instance {\n  required bytes content = 1;\n};\n<\/code><\/pre>\n<p>But I have the following error : <code>Invalid type Instance to assign to submessage field 'instances'<\/code><\/p>\n<p>I read the documentation but for ruby SDK it's a bit light.\nThe parameters are OK, the JS example here : <a href=\"https:\/\/github.com\/googleapis\/nodejs-ai-platform\/blob\/main\/samples\/predict-image-object-detection.js\" rel=\"nofollow noreferrer\">https:\/\/github.com\/googleapis\/nodejs-ai-platform\/blob\/main\/samples\/predict-image-object-detection.js<\/a> is working with those parameters<\/p>\n<p>What am I doing wrong ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1656671602857,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":54.0,
        "Poster_created_time":1656670919183,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":"<p>I managed it<\/p>\n<pre class=\"lang-rb prettyprint-override\"><code>client = Google::Cloud::AIPlatform::V1::PredictionService::Client.new do |config|\n  config.endpoint = &quot;#{location}-aiplatform.googleapis.com&quot;\nend\n\nimg = File.open(imgPath, 'rb') do |img|\n  Base64.strict_encode64(img.read)\nend\n\ninstance = Google::Protobuf::Value.new(:struct_value =&gt; {:fields =&gt; {\n  :content =&gt; {:string_value =&gt; img}\n}})\nendpoint = &quot;projects\/#{project}\/locations\/#{location}\/endpoints\/#{endpoint}&quot;\n\n\nrequest = Google::Cloud::AIPlatform::V1::PredictRequest.new(\n  endpoint: endpoint,\n  instances: [instance]\n)\n\nresult = client.predict request\np result\n<\/code><\/pre>\n<p>The use of the Google::Protobuf::Value looks ugly to me but it works<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1656947266916,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1656670919183,
        "Answerer_location":null,
        "Answerer_reputation_count":1.0,
        "Answerer_view_count":2.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72827960",
        "Tool":"Vertex AI",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"imag classif predict gcp aiplatform rubi new rubi want us gcp aiplatform struggel payload far client googl cloud aiplatform predictionservic client new config config endpoint locat aiplatform googleapi com end img file open imgpath img data imag png base base strict encod img read end instanc instanc new content img request googl cloud aiplatform predictrequest new endpoint project project locat locat endpoint endpoint instanc instanc result client predict request result proto messag instanc requir byte content follow error invalid type instanc assign submessag field instanc read document rubi sdk bit light paramet exampl http github com googleapi nodej platform blob main sampl predict imag object detect work paramet wrong",
        "Question_preprocessed_content":"imag predict gcp aiplatform rubi new rubi want us gcp aiplatform payload far proto read document rubi sdk bit light paramet exampl work paramet wrong",
        "Question_gpt_summary_original":"The user is new to Ruby and is trying to use GCP AIPlatform for image classification prediction. They are struggling with the payload and are encountering an error message \"Invalid type Instance to assign to submessage field 'instances'\". The user has provided their code and proto and is seeking help to identify the issue.",
        "Question_gpt_summary":"user new rubi try us gcp aiplatform imag classif predict struggl payload encount error messag invalid type instanc assign submessag field instanc user provid code proto seek help identifi issu"
    },
    {
        "Question_title":"Why are shh keys lost on reboot of AWS ec2 instance (sage maker)?",
        "Question_body":"<p>I have an AWS SageMaker notebook running some ML stuff for work, and I have a private github repo with some of my commonly used functions which is formatted in such a way to be pip install-able, so I set up an SSH key by doing this:<\/p>\n<pre><code>ssh-keygen \n\n-t rsa -b 4096 -C &quot;danielwarfield1@gmail.com&quot;\n<\/code><\/pre>\n<p>enter, enter, enter (default save location no password)<\/p>\n<pre><code>eval $(ssh-agent -s)\nssh-add ~\/.ssh\/id_rs\n<\/code><\/pre>\n<p>then I copy the public key into github, then I run this to install my library<\/p>\n<pre><code>$PWD\/pip install git+ssh:\/\/git@github.com\/...\n<\/code><\/pre>\n<p>where <code>$PWD<\/code> is the directory containing pip for the conda env I'm using (tensorflow2_p36 specifically, the one that AWS provides)<\/p>\n<p>this works fine, until I restart the EC2, then it appears my shh key (along with all my other installs) are lost, and I have to repeat the process. I expect the modules to be lost, I know SageMaker manages the environments, but me loosing my ssh key seems peculiar, is there a place I can save my ssh key wher it wont get lost, but I can still find it when I pip install?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1596230563253,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":278.0,
        "Poster_created_time":1545360696800,
        "Poster_location":"Earth",
        "Poster_reputation_count":1011.0,
        "Poster_view_count":93.0,
        "Answer_body":"<p>The <code>\/home\/ec2-user\/SageMaker<\/code> location is persisted even when you switch down the notebook instance, you can try saving things here to get them persisted. Things saved elsewhere will be lost when you switch off the instance<\/p>\n<p>Regarding private git integration, you can use the <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/nbi-git-repo.html\" rel=\"nofollow noreferrer\">SageMaker git Notebook integration<\/a>, which uses Secrets Manager to safely handle your credentials<\/p>\n<p>You can perform steps automatically when the notebook starts with a <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/notebook-lifecycle-config.html\" rel=\"nofollow noreferrer\">lifecycle configuration<\/a>. This is useful for example to standardise and automatise copying of data and environment customization<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1596232881236,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1442180190107,
        "Answerer_location":null,
        "Answerer_reputation_count":3203.0,
        "Answerer_view_count":400.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63199239",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"shh kei lost reboot aw instanc sage maker notebook run stuff work privat github repo commonli function format wai pip instal abl set ssh kei ssh keygen rsa danielwarfield gmail com enter enter enter default save locat password eval ssh agent ssh add ssh copi public kei github run instal librari pwd pip instal git ssh git github com pwd directori contain pip conda env tensorflow specif aw provid work fine restart appear shh kei instal lost repeat process expect modul lost know manag environ loos ssh kei peculiar place save ssh kei wher wont lost pip instal",
        "Question_preprocessed_content":"kei lost aw instanc work privat github repo function wai pip abl set kei enter enter enter copi public kei github run librari directori contain pip conda env work fine restart kei lost repeat expect modul lost know manag environ kei peculiar place save kei wher wont lost pip",
        "Question_gpt_summary_original":"The user is facing an issue with losing their SSH key on reboot of their AWS SageMaker notebook instance, which is affecting their ability to install commonly used functions from a private GitHub repo. They have tried setting up the SSH key and copying the public key into GitHub, but the key is lost on reboot, along with all other installs. The user is seeking a solution to save their SSH key in a place where it won't get lost but can still be found when pip installing.",
        "Question_gpt_summary":"user face issu lose ssh kei reboot notebook instanc affect abil instal commonli function privat github repo tri set ssh kei copi public kei github kei lost reboot instal user seek solut save ssh kei place won lost pip instal"
    },
    {
        "Question_title":"SageMaker Inference Recommendation",
        "Question_body":"We have an application that processes customer survey responses to determine the overall sentiment of it. (negative, neutral, positive). We are leveraging SageMaker Sentiment analysis for this.\n\nBelow are some key datapoints of our current usage.\n\n1. We have 4 real time endpoints each having the below properties\n    1. Multi Model:\n        1. Model A is 6 GB\n        2. Model B is 9.4 GB\n    2. Runtime configuration:\n        1. ml.c5.2xlarge (8 vCPU, 16 GiB memory)\n    3. Image responsible for handling the inference is of size 4.5gb\n2. The reason we have 4 endpoints is so that we can make concurrent requests to SageMaker. For this we have our load balancing logic that determines which endpoint to call.\n\n\nThis pattern will not continue working for us during 2023 as we scale up our survey ingestion pipeline. From running a load test of our system, the maximum TPS to Sagemaker we can support currently is 5.333; anything beyond that causes SageMaker to send 5XX responses (because we max out the CPU on all the available cores). Furthermore, our call pattern is of batch so there is no need for us to have the endpoints running 24\/7.\n\nFor 2023, we have predicted that we want to start handling a TPS of up to 200 during peaks. Before we start designing a new workflow to support this TPS, we wanted to get the SageMaker\u2019s teams\/community's feedback on alternatives. While we could try to scale vertically and horizontally this setup, we don\u2019t believe deploying bigger hosts and creating more realtime endpoints is the right solution in terms of total costs (given our intermittent batch call pattern to Sagemaker). Specifically, we want to know which Inference Flavor would better fit our use case based on the above description of the system.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1671556563217,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1671903753372,
        "Question_score_count":0.0,
        "Question_view_count":93.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUDPxlldhzS1GNaSLn4ebRxw\/sagemaker-inference-recommendation",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"infer recommend applic process custom survei respons determin overal sentiment neg neutral posit leverag sentiment analysi kei datapoint current usag real time endpoint have properti multi model model model runtim configur xlarg vcpu gib memori imag respons handl infer size reason endpoint concurr request load balanc logic determin endpoint pattern continu work scale survei ingest pipelin run load test maximum tp support current caus send respons max cpu avail core furthermor pattern batch need endpoint run predict want start handl tp peak start design new workflow support tp want team commun feedback altern try scale vertic horizont setup dont believ deploi bigger host creat realtim endpoint right solut term total cost given intermitt batch pattern specif want know infer flavor better fit us case base descript",
        "Question_preprocessed_content":"infer custom survei respons determin sentiment leverag sentiment analysi kei datapoint usag real time endpoint have properti multi model model model runtim configur imag respons handl infer size reason endpoint request load balanc logic determin endpoint continu work scale survei ingest pipelin load test maximum tp caus send respons furthermor batch endpoint predict want start handl tp peak start design new workflow tp want altern try scale setup dont believ deploi host creat realtim endpoint right solut term total cost want know infer flavor fit us case base descript",
        "Question_gpt_summary_original":"The user is currently using SageMaker Sentiment analysis to process customer survey responses and determine overall sentiment. They have 4 real-time endpoints with multi-model and runtime configurations, and are using load balancing logic to make concurrent requests. However, they have found that their system can only support a maximum TPS of 5.333 and are looking for alternatives to support a TPS of up to 200 during peaks in 2023. They are seeking feedback from the SageMaker community on which Inference Flavor would better fit their use case.",
        "Question_gpt_summary":"user current sentiment analysi process custom survei respons determin overal sentiment real time endpoint multi model runtim configur load balanc logic concurr request support maximum tp look altern support tp peak seek feedback commun infer flavor better fit us case"
    },
    {
        "Question_title":"Feature Request: Embed only a table\/report",
        "Question_body":"<p>I intend to do a series of blog posts which use W&amp;B reports like this one:<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/write.farook.org\/stable-diffusion-parameter-variations\/\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/31da22c8b3786e20cdf0326872a564cdf70efa6d.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/write.farook.org\/stable-diffusion-parameter-variations\/\" target=\"_blank\" rel=\"noopener nofollow ugc\">write.farook.org<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690\/199;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_690x199.jpeg\" class=\"thumbnail\" width=\"690\" height=\"199\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_690x199.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_1035x298.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_1380x398.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/e5563ba054b6d9637277a5f0369fed9909c580da_2_10x10.png\"><\/div>\n\n<h3><a href=\"https:\/\/write.farook.org\/stable-diffusion-parameter-variations\/\" target=\"_blank\" rel=\"noopener nofollow ugc\">Stable Diffusion Parameter Variations \u2013 Meandering Musings<\/a><\/h3>\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>As you\u2019ll notice, I have multiple reports in the blog post. The current embed with an IFRAME takes up way too much space because of the header and the footer where you can comment etc. I\u2019d prefer to have the ability to just embed a table (or preferably) the content section of a report.<\/p>\n<p>Does this ability currently exist? I checked the documentation but couldn\u2019t find anything like that.<\/p>\n<p>If the functionality does not exist, being able to do so in future would be a great help for me and probably for others too.<\/p>\n<p>I currently take screenshots of the relevant part of the report and then link to the full report on W&amp;B. But I hope you\u2019d agree that having the interactivity of the W&amp;B report in the post itself would be much more preferable <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_answer_count":7,
        "Question_comment_count":null,
        "Question_created_time":1661902937612,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":246.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/feature-request-embed-only-a-table-report\/3037",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"featur request emb tabl report intend seri blog post us report like write farook org stabl diffus paramet variat meander muse youll notic multipl report blog post current emb ifram take wai space header footer comment prefer abil emb tabl prefer content section report abil current exist check document like function exist abl futur great help probabl current screenshot relev report link report hope youd agre have interact report post prefer",
        "Question_preprocessed_content":"featur request emb intend seri blog post us report like stabl paramet variat meander muse notic multipl report blog post emb ifram take wai space header prefer abil emb tabl content section report abil exist check document like function exist abl futur great help probabl relev report link report hope youd have interact report post prefer",
        "Question_gpt_summary_original":"The user is requesting a feature to embed only a table or the content section of a report from W&B, as the current embed with an IFRAME takes up too much space due to the header and footer. The user currently takes screenshots of the relevant part of the report and links to the full report on W&B, but having the interactivity of the W&B report in the post itself would be much more preferable.",
        "Question_gpt_summary":"user request featur emb tabl content section report current emb ifram take space header footer user current take screenshot relev report link report have interact report post prefer"
    },
    {
        "Question_title":"Vision API Product search",
        "Question_body":"Following is vision API product search request json\n\n{\n \"requests\": [\n{\n  \"image\": {\n    \"content\": base64-encoded-image\n  },\n  \"features\": [\n    {\n      \"type\": \"PRODUCT_SEARCH\",\n      \"maxResults\": 5\n    }\n  ],\n  \"imageContext\": {\n    \"productSearchParams\": {\n      \"productSet\": \"projects\/project-id\/locations\/location-id\/productSets\/product-set-id\",\n      *\"productCategories\": [\n           \"apparel\"\n      ]*,\n      \"filter\": \"style = womens\"\n    }\n  }\n}\n]\n}\n\nFor ImageContext, ProductCategories(apparel in this request) is mandatory in API. My concern is if I want product search from all the available\u00a0ProductCategories, do I need to set multiple requests?\n\n ImageContext imageContext =\n    ImageContext.newBuilder()\n        .setProductSearchParams(\n            ProductSearchParams.newBuilder()\n                .setProductSet(productSetPath)\n                .addProductCategories(\"apparel-v2\")\n                .setFilter(filter))\n        .build();\n\nFor example, addProductCategories(\"apparel\") can have only one productcategory at a time. But I want product search from all the category something like addProductCategories(\"apparel-v2\").addProductCategories(\"toys-v2\").addProductCategories(\"general-v1\") etc.",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1667386140000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":287.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vision-API-Product-search\/m-p\/485081#M718",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"vision api product search follow vision api product search request json request imag content base encod imag featur type product search maxresult imagecontext productsearchparam productset project project locat locat productset product set productcategori apparel filter style women imagecontext productcategori apparel request mandatori api concern want product search availableproductcategori need set multipl request imagecontext imagecontext imagecontext newbuild setproductsearchparam productsearchparam newbuild setproductset productsetpath addproductcategori apparel setfilt filter build exampl addproductcategori apparel productcategori time want product search categori like addproductcategori apparel addproductcategori toi addproductcategori gener",
        "Question_preprocessed_content":"vision api product search vision api product search request json request imagecontext imagecontext productcategori mandatori api concern want product search availableproductcategori set multipl request imagecontext imagecontext setproductsearchparam setproductset setfilt build exampl productcategori time want product search categori like",
        "Question_gpt_summary_original":"The user is facing a challenge with the Vision API product search request JSON. The issue is that the productCategories parameter is mandatory in the API, and the user wants to search for products from all available categories. However, the API only allows for one product category to be added at a time. The user is wondering if they need to set multiple requests to search for products from all categories.",
        "Question_gpt_summary":"user face challeng vision api product search request json issu productcategori paramet mandatori api user want search product avail categori api allow product categori ad time user wonder need set multipl request search product categori"
    },
    {
        "Question_title":"How to alter shared memory for SageMaker Docker containers?",
        "Question_body":"<p>I have a Docker image in Elastic Container Registry (ECR). It was created via a simple Dockerfile which I have control over.<\/p>\n<p>The image itself is fine, but I have a problem where the shared memory is insufficient when working inside a container in SageMaker Studio. Therefore I need to raise the shared memory of these containers.<\/p>\n<p>To raise the shared memory of a container, I believe the usual method is to pass the <code>--shm-size<\/code> argument to the <code>docker run<\/code> command when starting the container. However, I do not have control over this command, as SageMaker is doing that bit for me. The <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms-training-algo-dockerfile.html\" rel=\"nofollow noreferrer\">docs<\/a> say that SageMaker is running <code>docker run &lt;image&gt; train<\/code> when starting a container.<\/p>\n<p>Is it possible to work around this problem? Either via somehow providing additional arguments to the command, or specifying something when creating the Docker image (such as in the Dockerfile, deployment script to ECR).<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1648550512340,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":456.0,
        "Poster_created_time":1352838205400,
        "Poster_location":null,
        "Poster_reputation_count":718.0,
        "Poster_view_count":43.0,
        "Answer_body":"<p>As pointed out by @rok (thank you!) it is not possible in this situation to pass arguments to <code>docker run<\/code>, although it would be if switching to ECS.<\/p>\n<p>It is however possible to pass the <code>--shm-size<\/code> argument to <code>docker build<\/code> when building the image to push to ECR. This seems to have fixed the problem, albeit it does require a new Docker image to be built and pushed whenever wanting to change this parameter.<\/p>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1648732366736,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1352838205400,
        "Answerer_location":null,
        "Answerer_reputation_count":718.0,
        "Answerer_view_count":43.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71660619",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"alter share memori docker contain docker imag elast contain registri ecr creat simpl dockerfil control imag fine problem share memori insuffici work insid contain studio need rais share memori contain rais share memori contain believ usual method pass shm size argument docker run command start contain control command bit doc run docker run train start contain possibl work problem provid addit argument command specifi creat docker imag dockerfil deploy script ecr",
        "Question_preprocessed_content":"alter share memori docker contain docker imag elast contain registri creat simpl dockerfil control imag fine problem share memori work insid contain studio rais share memori contain rais share memori contain believ usual method argument start contain control bit doc start contain work problem provid argument specifi creat docker imag",
        "Question_gpt_summary_original":"The user has a Docker image in Elastic Container Registry (ECR) and needs to increase the shared memory of the containers in SageMaker Studio. However, they do not have control over the <code>docker run<\/code> command as it is done by SageMaker. The user is looking for a workaround to provide additional arguments to the command or specify something in the Docker image or deployment script to ECR.",
        "Question_gpt_summary":"user docker imag elast contain registri ecr need increas share memori contain studio control docker run command user look workaround provid addit argument command specifi docker imag deploy script ecr"
    },
    {
        "Question_title":"Send request as Json on UWP",
        "Question_body":"<p>I have deployed an AzureML published experiment with deployed web service. I tried to use the <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-consume-web-services\/\" rel=\"nofollow\">sample code provided in the configuration page<\/a>, but universal apps do not implement Http.Formatting yet, thus I couldn't use <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/hh944521(v=vs.118).aspx\" rel=\"nofollow\">postasjsonasync<\/a>.<\/p>\n\n<p>I tried to follow the sample code as much as possible, but I'm getting statuscode of 415 \"Unsupported Media Type\", What's the mistake I'm doing?<\/p>\n\n<pre><code>var client = new HttpClient();\nclient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", apiKey);\n\/\/ client.BaseAddress = uri;\n\nvar scoreRequest = new\n{\n            Inputs = new Dictionary&lt;string, StringTable&gt;() {\n                    {\n                        \"dataInput\",\n                        new StringTable()\n                        {\n                            ColumnNames = new [] {\"Direction\", \"meanX\", \"meanY\", \"meanZ\"},\n                            Values = new [,] {  { \"\", x.ToString(), y.ToString(), z.ToString() },  }\n                        }\n                    },\n                },\n            GlobalParameters = new Dictionary&lt;string, string&gt;() { }\n };\n var stringContent = new StringContent(scoreRequest.ToString());\n HttpResponseMessage response = await client.PostAsync(uri, stringContent);\n<\/code><\/pre>\n\n<p>Many Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1452005613750,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":3194.0,
        "Poster_created_time":1352139399460,
        "Poster_location":"Cyprus",
        "Poster_reputation_count":820.0,
        "Poster_view_count":256.0,
        "Answer_body":"<p>You'll need to serialize the object to a JSON string (I recommend using NewtonSoft.Json to make it easier) and set the content type accordingly. Here's an implementation I'm using in my UWP apps (note that <code>_client<\/code> is an <code>HttpClient<\/code>):<\/p>\n\n<pre><code>    public async Task&lt;HttpResponseMessage&gt; PostAsJsonAsync&lt;T&gt;(Uri uri, T item)\n    {\n        var itemAsJson = JsonConvert.SerializeObject(item);\n        var content = new StringContent(itemAsJson);\n        content.Headers.ContentType = new MediaTypeHeaderValue(\"application\/json\");\n\n        return await _client.PostAsync(uri, content);\n    }\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1452007973623,
        "Answer_last_edit_time":null,
        "Answer_score_count":3.0,
        "Answerer_created_time":1395422283667,
        "Answerer_location":null,
        "Answerer_reputation_count":1411.0,
        "Answerer_view_count":45.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34614582",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"send request json uwp deploi publish experi deploi web servic tri us sampl code provid configur page univers app implement http format couldn us postasjsonasync tri follow sampl code possibl get statuscod unsupport media type mistak var client new httpclient client defaultrequesthead author new authenticationheadervalu bearer apikei client baseaddress uri var scorerequest new input new dictionari datainput new stringtabl columnnam new direct meanx meani meanz valu new tostr tostr tostr globalparamet new dictionari var stringcont new stringcont scorerequest tostr httpresponsemessag respons await client postasync uri stringcont thank",
        "Question_preprocessed_content":"send request json uwp deploi publish experi deploi web servic tri us sampl code provid configur page univers implement couldn us postasjsonasync tri sampl code statuscod media type mistak thank",
        "Question_gpt_summary_original":"The user is facing challenges while trying to send a request as JSON on UWP for an AzureML published experiment with a deployed web service. The sample code provided in the configuration page is not working as universal apps do not implement Http.Formatting yet, resulting in a status code of 415 \"Unsupported Media Type\". The user is seeking help to identify the mistake in the code.",
        "Question_gpt_summary":"user face challeng try send request json uwp publish experi deploi web servic sampl code provid configur page work univers app implement http format result statu code unsupport media type user seek help identifi mistak code"
    },
    {
        "Question_title":"How to debug mlflow artificat connection?",
        "Question_body":"Hi, I am running into a problem where the mlflow server does not load the data from the artifact storage (which is a Minio for me) for a given run. Is there a way to debug mlflow side of communication with Minio server by enabling mlflow debug flags?\n\n\nFrom the tables I know the artifact location and I am able to retrieve objects from the Minio server for that same artifact bucket and path.\u00a0\n\n\nmlflow_db=# select * from experiments ;\n\u00a0experiment_id |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| artifact_location | lifecycle_stage\u00a0\n---------------+-------------------------+-------------------+-----------------\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a01 | wine-pyfile-model\u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/1\u00a0 \u00a0 \u00a0| deleted\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02 | wine-pyfile-model-minio | s3:\/\/mlflow\/2\u00a0 \u00a0 \u00a0| deleted\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a03 | mlflow-wine\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/3\u00a0 \u00a0 \u00a0| active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a04 | mlflow-wine-minio\u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/4\u00a0 \u00a0 \u00a0| active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a05 | rest-wine-1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/5\u00a0 \u00a0 \u00a0| active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a07 | rest-wine-2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/7\u00a0 \u00a0 \u00a0| active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00 | rest-wine-2-updated\u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/0\u00a0 \u00a0 \u00a0| active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a08 | Default\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/8\u00a0 \u00a0 \u00a0| active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a09 | rest-wine-3\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/9\u00a0 \u00a0 \u00a0| deleted\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 13 | rest-wine-4\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/13\u00a0 \u00a0 | active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 14 | rest-wine-5\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/14\u00a0 \u00a0 | active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 15 | rest-wine-51\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | s3:\/\/mlflow\/15\u00a0 \u00a0 | active\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 16 | rest-wine-6\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| s3:\/\/mlflow\/16\u00a0 \u00a0 | deleted\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 17 | rest-wine-61\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | s3:\/\/mlflow\/17\u00a0 \u00a0 | active\n\n\nAny debugging ideas?\n\n\nThanks\nShounak",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1638472803000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":814.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/b0UFc00NzK0",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"debug artificat connect run problem server load data artifact storag minio given run wai debug commun minio server enabl debug flag tabl know artifact locat abl retriev object minio server artifact bucket path select experi experi artifact locat lifecycl stage wine pyfil model delet wine pyfil model minio delet wine activ wine minio activ rest wine activ rest wine activ rest wine updat activ default activ rest wine delet rest wine activ rest wine activ rest wine activ rest wine delet rest wine activ debug idea thank shounak",
        "Question_preprocessed_content":"debug artificat problem server load data artifact storag given run wai debug minio server enabl debug flag tabl know artifact locat abl retriev object minio server artifact bucket path select experi delet delet wine activ activ activ activ activ default activ delet activ activ activ delet activ idea thank shounak",
        "Question_gpt_summary_original":"The user is facing an issue where the mlflow server is not loading data from the artifact storage (Minio) for a given run. The user is seeking help to debug the mlflow side of communication with the Minio server by enabling mlflow debug flags. The user has provided the artifact location and is able to retrieve objects from the Minio server for the same artifact bucket and path.",
        "Question_gpt_summary":"user face issu server load data artifact storag minio given run user seek help debug commun minio server enabl debug flag user provid artifact locat abl retriev object minio server artifact bucket path"
    },
    {
        "Question_title":"Can I mount EFS in SageMaker processing job?",
        "Question_body":"<p>We are running some predictions using processing jobs in SageMaker. Before, we added some models into Docker image that was used by SageMaker processing job. Now, as we have more models (&gt;= 6Gb), it is quite a bad design to add them to Docker image.<\/p>\n<p>At first, we thought to download huge models from S3, but then realised, that it will cost a fortune. Then, an idea came to my mind. What if we use EFS with all heavy models and connect it to the running processing job so that python code can reference and use them?<\/p>\n<p>I did a search and couldn't find any working solution for this. UI in AWS doesn't allow to connect EFS, and I couldn't find any working solution how to connect to EFS from the docker container. All suggest to use Docker volumes, but there is no way to configure this when create a processing job.<\/p>\n<p>Question is is there any way to mount EFS to processing job in SageMaker? If no, what are the alternatives to host and use heavy models in the processing jobs? Maybe there are some other alternatives?<\/p>\n<p>Thank you for any input.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662945203473,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":36.0,
        "Poster_created_time":1307457791456,
        "Poster_location":"Sydney, Australia",
        "Poster_reputation_count":537.0,
        "Poster_view_count":49.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73683651",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"mount ef process job run predict process job ad model docker imag process job model bad design add docker imag thought download huge model realis cost fortun idea came mind us ef heavi model connect run process job python code refer us search couldn work solut aw allow connect ef couldn work solut connect ef docker contain suggest us docker volum wai configur creat process job question wai mount ef process job altern host us heavi model process job mayb altern thank input",
        "Question_preprocessed_content":"mount ef job predict job model docker imag job model bad design docker imag thought download huge model realis cost fortun idea came mind us ef heavi model job python code refer us search couldn work solut aw ef couldn work solut ef docker contain us docker volum wai configur creat job question wai mount ef job altern host us heavi model job mayb altern thank input",
        "Question_gpt_summary_original":"The user is facing challenges in hosting heavy models for predictions using processing jobs in SageMaker. They are looking for alternatives to adding the models to the Docker image, as the models are now over 6GB. The user considered using EFS to connect to the running processing job, but couldn't find a working solution to connect EFS to the Docker container. They are seeking input on whether it is possible to mount EFS to processing jobs in SageMaker or if there are any alternative solutions.",
        "Question_gpt_summary":"user face challeng host heavi model predict process job look altern ad model docker imag model user consid ef connect run process job couldn work solut connect ef docker contain seek input possibl mount ef process job altern solut"
    },
    {
        "Question_title":"Saving an Matlabplot as an MLFlow artifact",
        "Question_body":"<p>I am using DataBricks and Spark 7.4ML,<\/p>\n<p>The following code successfully logs the params and metrics, and I can see the ROCcurve.png in the MLFLOW gui (just the item in the tree below the model). But the actually plot is blank. Why?<\/p>\n<pre><code>with mlflow.start_run(run_name=&quot;logistic-regression&quot;) as run:\n  pipeModel = pipe.fit(trainDF)\n  mlflow.spark.log_model(pipeModel, &quot;model&quot;)\n  predTest = pipeModel.transform(testDF)\n  predTrain = pipeModel.transform(trainDF)\n  evaluator=BinaryClassificationEvaluator(labelCol=&quot;arrivedLate&quot;)\n  trainROC = evaluator.evaluate(predTrain)\n  testROC = evaluator.evaluate(predTest)\n  print(f&quot;Train ROC: {trainROC}&quot;)\n  print(f&quot;Test ROC: {testROC}&quot;)\n  mlflow.log_param(&quot;Dataset Name&quot;, &quot;Flights &quot; + datasetName)\n  mlflow.log_metric(key=&quot;Train ROC&quot;, value=trainROC)\n  mlflow.log_metric(key=&quot;Test ROC&quot;, value=testROC)\n\n  lrModel = pipeModel.stages[3]\n  trainingSummary = lrModel.summary\n  roc = trainingSummary.roc.toPandas()\n  plt.plot(roc['FPR'],roc['TPR'])\n  plt.ylabel('False Positive Rate')\n  plt.xlabel('True Positive Rate')\n  plt.title('ROC Curve')\n  plt.show()\n  plt.savefig(&quot;ROCcurve.png&quot;)\n  mlflow.log_artifact(&quot;ROCcurve.png&quot;)\n  plt.close()\n  \n  display(predTest.select(stringCols + [&quot;arrivedLate&quot;, &quot;prediction&quot;]))\n<\/code><\/pre>\n<p>What the notebook shows:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/sCIN9.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sCIN9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What the MLFlow shows:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oXk8Y.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oXk8Y.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1607094596640,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1607191847983,
        "Question_score_count":8.0,
        "Question_view_count":5219.0,
        "Poster_created_time":1316705139196,
        "Poster_location":"Boston, MA",
        "Poster_reputation_count":6711.0,
        "Poster_view_count":819.0,
        "Answer_body":"<p>Put <code>plt.show()<\/code> after <code>plt.savefig()<\/code> - <code>plt.show()<\/code> will remove your plot because it is shown already.<\/p>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1607094854147,
        "Answer_last_edit_time":null,
        "Answer_score_count":7.0,
        "Answerer_created_time":1598380609848,
        "Answerer_location":"Oxford, UK",
        "Answerer_reputation_count":38531.0,
        "Answerer_view_count":4137.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65145994",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save matlabplot artifact databrick spark follow code successfulli log param metric roccurv png gui item tree model actual plot blank start run run logist regress run pipemodel pipe fit traindf spark log model pipemodel model predtest pipemodel transform testdf predtrain pipemodel transform traindf evalu binaryclassificationevalu labelcol arrivedl trainroc evalu evalu predtrain testroc evalu evalu predtest print train roc trainroc print test roc testroc log param dataset flight datasetnam log metric kei train roc valu trainroc log metric kei test roc valu testroc lrmodel pipemodel stage trainingsummari lrmodel summari roc trainingsummari roc topanda plt plot roc fpr roc tpr plt ylabel fals posit rate plt xlabel true posit rate plt titl roc curv plt plt savefig roccurv png log artifact roccurv png plt close displai predtest select stringcol arrivedl predict notebook show show",
        "Question_preprocessed_content":"save matlabplot artifact databrick spark code log param metric png gui plot blank show show",
        "Question_gpt_summary_original":"The user is trying to save a Matplotlib plot as an MLFlow artifact in DataBricks and Spark 7.4ML. The code successfully logs the params and metrics, and the ROCcurve.png is visible in the MLFLOW gui, but the plot is blank. The user is seeking help to understand why this is happening.",
        "Question_gpt_summary":"user try save matplotlib plot artifact databrick spark code successfulli log param metric roccurv png visibl gui plot blank user seek help understand happen"
    },
    {
        "Question_title":"Keras sequential model results not reproducible with wildly inconsistent results on same dataset and parameters optimized using Optuna",
        "Question_body":"<p>I am running a Keras sequential model as a regressor with tensorflow backend. I am using Optuna to optimize it's hyper-paramters and reducing the rmse in the Optuna optimizer.\nHowever, when I re-create the Keras model with the best parameters from Optuna and use the same dataset for re-fitting and predicting as the one used in the Optuna objective function, I get wildly inconsistent results.<\/p>\n<p>I'm aware that neural nets are stochastic in nature with an element of randomness. In order to make it deterministic I tried setting the seeds for both numpy and tensorflow in the following manner at beginning of my script, but it doesn't work,<\/p>\n<pre><code>from numpy.random import seed\nseed(1)\nimport tensorflow\ntensorflow.random.set_seed(2)\n<\/code><\/pre>\n<p>Following is my code and the output-<\/p>\n<pre><code>def create_model(trial):   \n    n_layers = trial.suggest_int(&quot;layers_number&quot;, 4,  8)#4\n    model = keras.Sequential()\n    for i in range(n_layers):\n        num_hidden = trial.suggest_int(&quot;n_units_l_{}&quot;.format(i), 10, 16)\n        activation = trial.suggest_categorical('activation_l_{}'.format(i), ['linear'])#, 'relu', 'sigmoid', 'tanh', 'elu'\n        model.add(layers.Dense(num_hidden, activation=activation, kernel_initializer = 'uniform'))\n        dropout = trial.suggest_uniform(&quot;dropout_l_{}&quot;.format(i), 0.1, 0.4)\n        model.add(layers.Dropout(dropout))\n    model.add(layers.Dense(1, activation='linear'))\n\n    lr = trial.suggest_loguniform(&quot;lr&quot;, 1e-5, 1e-1)\n\n    model.compile(\n        loss='mean_squared_error',\n        optimizer=keras.optimizers.Adam(lr=lr),\n        metrics=['mse']\n    )\n\n    return model\n<\/code><\/pre>\n<pre><code>def objective(trial):\n    keras.backend.clear_session()\n    model = create_model(trial)\n    \n    epochs = trial.suggest_int(&quot;epochs&quot;, 3, 4)#50\n    batch = trial.suggest_int(&quot;batch&quot;, 1, 2)\n    \n    model.fit(\n        X_train.values,\n        y_train.values, \n        batch_size=batch, \n        epochs=epochs, \n        verbose=0,\n        shuffle=False\n    )\n    y_pred_test = model.predict(X_test)\n    test_copy['pred_scaled'] = y_pred_test\n    rmse = inverse_transform(test_copy, y_pred_test, df_copy) #inverse transforms the transformed target and calculates rmse\n\n    return rmse\n<\/code><\/pre>\n<pre><code>study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=2)\n<\/code><\/pre>\n<p>Output- best trial screenshot\n<a href=\"https:\/\/i.stack.imgur.com\/2JAwJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2JAwJ.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>RMSE of best trial is 110.90926282554379<\/p>\n<p>Refitting and predicting using best params.<\/p>\n<pre><code>def KerasRegressor(parameters):\n    print(parameters)\n    model = keras.Sequential()\n    layers_number = int(parameters['layers_number'])\n\n    for i in range(layers_number):\n        model.add(layers.Dense(int(parameters['n_units_l_' + str(i)]), activation=parameters['activation_l_' + str(i)], kernel_initializer = 'uniform'))\n        model.add(layers.Dropout(int(parameters['dropout_l_' + str(i)])))\n    model.add(layers.Dense(1, activation='linear'))\n    model.compile(\n        loss='mean_squared_error',\n        optimizer=keras.optimizers.Adam(lr=float(parameters['lr'])),\n        metrics=['mse'])\n        \n    return model\n<\/code><\/pre>\n<pre><code>params = study.best_trial.params\nepochs = params['epochs']\nbatch = params['batch']\ndel params['epochs']\ndel params['batch']\n\nseed(1)\ntensorflow.random.set_seed(2)\nmodel = KerasRegressor(params)\nmodel.fit(X_train.values, y_train.values, epochs=epochs, batch_size=batch, shuffle=False)\n\ny_pred_test = model.predict(X_test)\ntest_copy['pred_scaled'] = y_pred_test\nrmse = inverse_transform(test_copy, y_pred_test, df_copy)#inverse transforms the transformed target and calculates rmse\nprint(rmse)\n<\/code><\/pre>\n<p>New rmse on same dataset as used in Optuna objective function with best hyperparameters-\n<a href=\"https:\/\/i.stack.imgur.com\/PXv6F.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PXv6F.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>New rmse - 227892.23560327655<\/p>\n<p>Small differences in rmse are acceptable but not this large a difference.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1647324297490,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1647879472192,
        "Question_score_count":0.0,
        "Question_view_count":94.0,
        "Poster_created_time":1475693346256,
        "Poster_location":"Hyderabad, Telangana, India",
        "Poster_reputation_count":35.0,
        "Poster_view_count":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71477693",
        "Tool":"Optuna",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"kera sequenti model result reproduc wildli inconsist result dataset paramet optim run kera sequenti model regressor tensorflow backend optim hyper paramt reduc rmse optim creat kera model best paramet us dataset fit predict object function wildli inconsist result awar neural net stochast natur element random order determinist tri set seed numpi tensorflow follow manner begin script work numpi random import seed seed import tensorflow tensorflow random set seed follow code output def creat model trial layer trial suggest int layer number model kera sequenti rang layer num hidden trial suggest int unit format activ trial suggest categor activ format linear relu sigmoid tanh elu model add layer dens num hidden activ activ kernel initi uniform dropout trial suggest uniform dropout format model add layer dropout dropout model add layer dens activ linear trial suggest loguniform model compil loss mean squar error optim kera optim adam metric mse return model def object trial kera backend clear session model creat model trial epoch trial suggest int epoch batch trial suggest int batch model fit train valu train valu batch size batch epoch epoch verbos shuffl fals pred test model predict test test copi pred scale pred test rmse invers transform test copi pred test copi invers transform transform target calcul rmse return rmse studi creat studi direct minim studi optim object trial output best trial screenshot rmse best trial refit predict best param def kerasregressor paramet print paramet model kera sequenti layer number int paramet layer number rang layer number model add layer dens int paramet unit str activ paramet activ str kernel initi uniform model add layer dropout int paramet dropout str model add layer dens activ linear model compil loss mean squar error optim kera optim adam float paramet metric mse return model param studi best trial param epoch param epoch batch param batch del param epoch del param batch seed tensorflow random set seed model kerasregressor param model fit train valu train valu epoch epoch batch size batch shuffl fals pred test model predict test test copi pred scale pred test rmse invers transform test copi pred test copi invers transform transform target calcul rmse print rmse new rmse dataset object function best hyperparamet new rmse small differ rmse accept larg differ",
        "Question_preprocessed_content":"kera sequenti model result reproduc wildli inconsist result dataset paramet optim kera sequenti model tensorflow backend optim reduc rmse optim kera model best paramet us dataset predict object function wildli inconsist result awar neural net stochast natur element order determinist tri numpi tensorflow script work code output output best trial rmse best trial predict best param new rmse dataset object function best hyperparamet new rmse rmse larg",
        "Question_gpt_summary_original":"The user is encountering inconsistent results while using Keras sequential model as a regressor with tensorflow backend. The user is using Optuna to optimize hyper-parameters and reduce the rmse, but when the user re-creates the Keras model with the best parameters from Optuna and uses the same dataset for re-fitting and predicting as the one used in the Optuna objective function, the user gets wildly inconsistent results. The user has tried to make the neural nets deterministic by setting the seeds for both numpy and tensorflow, but it doesn't work. The user has provided the code and output for reference.",
        "Question_gpt_summary":"user encount inconsist result kera sequenti model regressor tensorflow backend user optim hyper paramet reduc rmse user creat kera model best paramet us dataset fit predict object function user get wildli inconsist result user tri neural net determinist set seed numpi tensorflow work user provid code output refer"
    },
    {
        "Question_title":"DVC support for the local storage",
        "Question_body":"<p>HI<br>\nCan we add local storage for DVC. like (i dont want to store it on s3 or gcp, need  to only point to local storage)<br>\nex :<\/p>\n<ol>\n<li>dvc add file:\\\\ xxx.xx.xx.x\\images\\annex\\dvc-storage<br>\nor<\/li>\n<li>dvc add X:\/annex\/dvc-storage\/data.xml ( local storage)<br>\nAfter trying above option. i am getting error.<br>\nInitialization error: Config file error: Unsupported URL.<br>\nPlease provide an appropriate solution or syntax<\/li>\n<\/ol>\n<p>Note : storage is tyron.   the storage location is mounted to window or on linux.<\/p>\n<p>With ref : <a href=\"https:\/\/discuss.dvc.org\/t\/does-dvc-fit-in-a-local-area-network-infrastucture-where-git-repos-are-not-in-the-computing-server\/24\/3\" class=\"inline-onebox\">Does DVC fit in a Local Area Network infrastucture where git repos are not in the computing server?<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1534489981766,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":2330.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-support-for-the-local-storage\/71",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"support local storag add local storag like dont want store gcp need point local storag add file xxx imag annex storag add annex storag data xml local storag try option get error initi error config file error unsupport url provid appropri solut syntax note storag tyron storag locat mount window linux ref fit local area network infrastuctur git repo comput server",
        "Question_preprocessed_content":"local storag local storag like try option initi config file url provid solut syntax note storag tyron storag locat mount window linux ref fit local area network infrastuctur git repo comput server",
        "Question_gpt_summary_original":"The user is facing an issue with adding local storage for DVC and is looking for a solution to only point to local storage. They have tried adding the local storage but are getting an error message stating \"Unsupported URL\". The storage location is mounted to both Windows and Linux.",
        "Question_gpt_summary":"user face issu ad local storag look solut point local storag tri ad local storag get error messag state unsupport url storag locat mount window linux"
    },
    {
        "Question_title":"Organizations using MLFlow",
        "Question_body":"Hi\n\n\u00a0\n\nWe at Genpact (https:\/\/www.genpact.com) are using MLFlow extensively in an in-house Machine Learning platform and would like to contribute to it. Please add our organization to the list on your website.\n\n\u00a0\n\nRegards\n\nDhanesh\n\n\u00a0\n\n--\u00a0\n\n\u00a0\n\nDhanesh Padmanabhan\n\nVP, Cora Analytics & ML Products\n\nGenpact Digital\n\n\u00a0\n\n\u00a0\n\n\n______________________________________________________________________\nThis e-mail (and any attachments), is confidential and may be privileged. It may be read, copied and used only by intended recipients. Unauthorized access to this e-mail (or attachments) and disclosure or copying of its contents or any action taken in reliance on it is unlawful. Unintended recipients must notify the sender immediately by e-mail\/phone & delete it from their system without making any copies or disclosing it to a third person.\n______________________________________________________________________",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1605066810000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":34.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/vZStty0zqYo",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"organ genpact http www genpact com extens hous machin learn platform like contribut add organ list websit regard dhanesh dhanesh padmanabhan cora analyt product genpact digit mail attach confidenti privileg read copi intend recipi unauthor access mail attach disclosur copi content action taken relianc unlaw unintend recipi notifi sender immedi mail phone delet make copi disclos person",
        "Question_preprocessed_content":"organ genpact extens machin learn platform like contribut organ list websit regard dhanesh dhanesh padmanabhan cora analyt product genpact digit confidenti privileg read copi intend recipi unauthor disclosur copi content action taken relianc unlaw unintend recipi notifi sender delet make copi disclos person",
        "Question_gpt_summary_original":"The user, Dhanesh from Genpact, has requested to add their organization to the list of companies using MLFlow on the website as they are using it extensively in their in-house Machine Learning platform and would like to contribute to it.",
        "Question_gpt_summary":"user dhanesh genpact request add organ list compani websit extens hous machin learn platform like contribut"
    },
    {
        "Question_title":"Sweep error - AttributeError: 'SettingsStatic' object has no attribute 'git_root'",
        "Question_body":"<p>When trying to make a new sweep I get the following error<br>\n<code>AttributeError: 'SettingsStatic' object has no attribute 'git_root'<\/code><\/p>\n<p>Seems to be repeated no matter what I try.<br>\nThe full log from <code>debug-internal.log<\/code><\/p>\n<pre><code class=\"lang-bash\">2022-10-27 21:15:00,236 INFO    StreamThr :3165542 [internal.py:wandb_internal():88] W&amp;B internal server running at pid: 3165542, started at: 2022-10-27 21:15:00.235637\n2022-10-27 21:15:00,237 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: status\n2022-10-27 21:15:00,374 DEBUG   SenderThread:3165542 [sender.py:send_request():317] send_request: status\n2022-10-27 21:15:00,376 DEBUG   SenderThread:3165542 [sender.py:send():303] send: header\n2022-10-27 21:15:00,376 INFO    WriterThread:3165542 [datastore.py:open_for_write():75] open: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/run-xj06c5a6.wandb\n2022-10-27 21:15:00,376 DEBUG   SenderThread:3165542 [sender.py:send():303] send: run\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [dir_watcher.py:__init__():216] watching files in: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [sender.py:_start_run_threads():928] run started: xj06c5a6 with start time 1666905300.0\n2022-10-27 21:15:00,760 DEBUG   SenderThread:3165542 [sender.py:send():303] send: summary\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [sender.py:_save_file():1171] saving file wandb-summary.json with policy end\n2022-10-27 21:15:00,761 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: check_version\n2022-10-27 21:15:00,761 DEBUG   SenderThread:3165542 [sender.py:send_request():317] send_request: check_version\n2022-10-27 21:15:01,040 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: run_start\n2022-10-27 21:15:01,044 DEBUG   HandlerThread:3165542 [meta.py:__init__():34] meta init\n2022-10-27 21:15:01,381 INFO    WriterThread:3165542 [datastore.py:close():279] close: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/run-xj06c5a6.wandb\n2022-10-27 21:15:01,761 INFO    Thread-14 :3165542 [dir_watcher.py:_on_file_created():275] file\/dir created: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/wandb-summary.json\n2022-10-27 21:15:02,031 INFO    SenderThread:3165542 [sender.py:finish():1331] shutting down sender\n2022-10-27 21:15:02,031 INFO    SenderThread:3165542 [dir_watcher.py:finish():362] shutting down directory watcher\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():392] scan: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():406] scan save: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/wandb-summary.json wandb-summary.json\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():406] scan save: \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/config.yaml config.yaml\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [file_pusher.py:finish():168] shutting down file pusher\n2022-10-27 21:15:02,764 INFO    SenderThread:3165542 [file_pusher.py:join():173] waiting for file pusher\n2022-10-27 21:15:04,333 INFO    Thread-19 :3165542 [upload_job.py:push():143] Uploaded file \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/config.yaml\n2022-10-27 21:15:04,349 INFO    Thread-18 :3165542 [upload_job.py:push():143] Uploaded file \/home\/cin\/Projects\/MotionLatentSpace\/wandb\/run-20221027_211500-xj06c5a6\/files\/wandb-summary.json\n2022-10-27 21:15:04,954 ERROR   StreamThr :3165542 [internal.py:wandb_internal():163] Thread HandlerThread:\nTraceback (most recent call last):\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 50, in run\n    self._run()\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 263, in _process\n    self._hm.handle(record)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 130, in handle\n    handler(record)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 140, in handle_request\n    handler(record)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 672, in handle_request_run_start\n    run_meta = meta.Meta(settings=self._settings, interface=self._interface)\n  File \"\/home\/cin\/.local\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/meta.py\", line 40, in __init__\n    root=self._settings.git_root,\nAttributeError: 'SettingsStatic' object has no attribute 'git_root'\n<\/code><\/pre>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1666905593478,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":170.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi Leslie,<\/p>\n<p>Found the issue! I was even though I had the correct conda env activated running the <code>wandb sweep<\/code> command with my local new version of wandb while the python code and env where running with and old 12.XX version.<\/p>\n<p>I changed it to use the same install for both and now it works.<\/p>",
        "Answer_comment_count":null,
        "Question_closed_time":1666942353022,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-error-attributeerror-settingsstatic-object-has-no-attribute-git-root\/3335",
        "Tool":"Weights & Biases",
        "Question_self_closed":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sweep error attributeerror settingsstat object attribut git root try new sweep follow error attributeerror settingsstat object attribut git root repeat matter try log debug intern log info streamthr intern intern intern server run pid start debug handlerthread handler handl request handl request statu debug senderthread sender send request send request statu debug senderthread sender send send header info writerthread datastor open write open home cin project motionlatentspac run xjca run xjca debug senderthread sender send send run info senderthread dir watcher init watch file home cin project motionlatentspac run xjca file info senderthread sender start run thread run start xjca start time debug senderthread sender send send summari info senderthread sender save file save file summari json polici end debug handlerthread handler handl request handl request check version debug senderthread sender send request send request check version debug handlerthread handler handl request handl request run start debug handlerthread meta init meta init info writerthread datastor close close home cin project motionlatentspac run xjca run xjca info thread dir watcher file creat file dir creat home cin project motionlatentspac run xjca file summari json info senderthread sender finish shut sender info senderthread dir watcher finish shut directori watcher info senderthread dir watcher finish scan home cin project motionlatentspac run xjca file info senderthread dir watcher finish scan save home cin project motionlatentspac run xjca file summari json summari json info senderthread dir watcher finish scan save home cin project motionlatentspac run xjca file config yaml config yaml info senderthread file pusher finish shut file pusher info senderthread file pusher join wait file pusher info thread upload job push upload file home cin project motionlatentspac run xjca file config yaml info thread upload job push upload file home cin project motionlatentspac run xjca file summari json error streamthr intern intern thread handlerthread traceback recent file home cin local lib python site packag sdk intern intern util line run self run file home cin local lib python site packag sdk intern intern util line run self process record file home cin local lib python site packag sdk intern intern line process self handl record file home cin local lib python site packag sdk intern handler line handl handler record file home cin local lib python site packag sdk intern handler line handl request handler record file home cin local lib python site packag sdk intern handler line handl request run start run meta meta meta set self set interfac self interfac file home cin local lib python site packag sdk intern meta line init root self set git root attributeerror settingsstat object attribut git root",
        "Question_preprocessed_content":"object try new repeat try log",
        "Question_gpt_summary_original":"The user is encountering a sweep error while trying to create a new sweep, with the error message \"AttributeError: 'SettingsStatic' object has no attribute 'git_root'\". The error seems to persist despite the user's attempts, and the full log from debug-internal.log shows that the issue is related to the 'git_root' attribute.",
        "Question_gpt_summary":"user encount sweep error try creat new sweep error messag attributeerror settingsstat object attribut git root error persist despit user attempt log debug intern log show issu relat git root attribut"
    },
    {
        "Question_title":"Azure ML Model Deployment- POST Body Type",
        "Question_body":"<p>I had registered a CNN model on Azure ML and would like to have and endpoint API that returns the predictions based on the image it receives and I also would like to send some metadata along the image itself. So, I prefer to POST the data in form-data format. However,The official tutorials mention application-json or binary data only.   <br \/>\nHow can I POST data in form-data format to an API in Azure ML ?  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1602526641177,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/123960\/azure-ml-model-deployment-post-body-type",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model deploy post bodi type regist cnn model like endpoint api return predict base imag receiv like send metadata imag prefer post data form data format offici tutori mention applic json binari data post data form data format api",
        "Question_preprocessed_content":"model deploy post bodi type regist model like endpoint api return predict base imag receiv like send metadata imag prefer post data format tutori mention json binari data post data format api",
        "Question_gpt_summary_original":"The user has registered a CNN model on Azure ML and wants to create an endpoint API that returns predictions based on the image it receives along with some metadata. However, the user is facing challenges in POSTing the data in form-data format as the official tutorials only mention application-json or binary data. The user is seeking guidance on how to POST data in form-data format to an API in Azure ML.",
        "Question_gpt_summary":"user regist cnn model want creat endpoint api return predict base imag receiv metadata user face challeng post data form data format offici tutori mention applic json binari data user seek guidanc post data form data format api"
    },
    {
        "Question_title":"Track train script version along with hyperaparams (ideally automated)",
        "Question_body":"<p>I\u2019m just getting started with experiments, my goal is to ablation-study some potentially new methods for finetuning NLP models. I use HuggingFace trainer and the W&amp;B integration works flawlessly, so the hyperparams are super easy to track. I\u2019m going to be doing some experimentation within the training code though - is there an easy way to track the training script version\/content along with the experiments, ideally integrated with Github?  Thanks! Darek<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1638831742465,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":234.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/track-train-script-version-along-with-hyperaparams-ideally-automated\/1479",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"track train script version hyperaparam ideal autom get start experi goal ablat studi potenti new method finetun nlp model us huggingfac trainer integr work flawlessli hyperparam super easi track go experiment train code easi wai track train script version content experi ideal integr github thank darek",
        "Question_preprocessed_content":"track train script version hyperaparam start experi goal new method finetun nlp model us trainer integr work hyperparam super easi track go experiment train code easi wai track train script experi integr github thank darek",
        "Question_gpt_summary_original":"The user is looking for a way to track the training script version and content along with experiments, ideally integrated with Github, while using HuggingFace trainer and W&B integration for ablation-study of potentially new methods for finetuning NLP models.",
        "Question_gpt_summary":"user look wai track train script version content experi ideal integr github huggingfac trainer integr ablat studi potenti new method finetun nlp model"
    },
    {
        "Question_title":"Where do augmentations in ClearML run?",
        "Question_body":"<p>In ClearML Dataviews, it is possible to add <a href=\"https:\/\/clear.ml\/docs\/latest\/docs\/hyperdatasets\/dataviews\/#data-augmentation\" rel=\"nofollow noreferrer\">augmentations<\/a>.<\/p>\n<p>Where do these augmentations run?<\/p>\n<p>Options<\/p>\n<ol>\n<li>Original data gets downloaded to local, then runs (on which device? How is multiprocessing handled?)<\/li>\n<li>Only augmented data gets downloaded to local cache, augmentations run remotely (who pays for compute? How fast? Should pipelines be changed accordingly?)<\/li>\n<\/ol>\n<p>I couldn't find this in the docs.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1658746321690,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":22.0,
        "Poster_created_time":1314313109232,
        "Poster_location":"Technion, Israel",
        "Poster_reputation_count":18777.0,
        "Poster_view_count":2000.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73108016",
        "Tool":"ClearML",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"augment run dataview possibl add augment augment run option origin data get download local run devic multiprocess handl augment data get download local cach augment run remot pai comput fast pipelin chang accordingli couldn doc",
        "Question_preprocessed_content":"augment run dataview augment augment run option origin data get download local run augment data get download local cach augment run remot couldn doc",
        "Question_gpt_summary_original":"The user is seeking clarification on where augmentations in ClearML Dataviews run, and presents two possible options: whether the original data is downloaded locally and run on a device (with questions about multiprocessing), or if only augmented data is downloaded to a remote location (with questions about cost, speed, and pipeline changes). The user notes that they were unable to find this information in the documentation.",
        "Question_gpt_summary":"user seek clarif augment dataview run present possibl option origin data download local run devic question multiprocess augment data download remot locat question cost speed pipelin chang user note unabl inform document"
    },
    {
        "Question_title":"How to Cancel Upload? - Azure Machine Learning Studio",
        "Question_body":"<p>Hi,  <\/p>\n<p>Please will you tell me how to cancel a dataset upload?  <\/p>\n<p>I tried to upload a small (321kb) CSV to Azure Machine Learning Studio.  The upload has been running for more than 1 hour, but it still says uploading.  <\/p>\n<p>I tried to upload other files (different names), and they are hanging too....same symptoms.  <\/p>\n<p>It seems the first problem is blocking all subsequent upload attempts.  <\/p>\n<p>Until today uploads worked perfectly.....multiple file types, multiple sizes, multiple dates, were all OK.  <\/p>\n<p>I have plenty of space left in my environment.  <\/p>\n<p>I tried closing and restarting my browser....same problem.  I accessed my AMLS via a different computer...same problem.  <\/p>\n<p>Thanks in advance for any advice you can give.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1592921687557,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Well, I don't know if you (<a href=\"\/users\/na\/?userid=d67fe4ea-5ec6-4e6b-b93c-404092429abd\">@GiftA-MSFT  <\/a>) did something to help, but it's solved!  Thanks if you did take that initiative, I appreciate it.  :-)    <\/p>\n<p>...or it could be that after 4-5 hours the upload just completed.  My internet connection was fine (it's a 40Mb line), so I'm not sure what the solution was.  Perhaps patience alone is the answer.    <\/p>\n<p>Anyway, thanks for taking an interest in my problem either way.      <\/p>\n<p>Best wishes.  :-)<\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1592933611232,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/39201\/how-to-cancel-upload-azure-machine-learning-studio",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"cancel upload studio tell cancel dataset upload tri upload small csv studio upload run hour sai upload tri upload file differ name hang symptom problem block subsequ upload attempt todai upload work perfectli multipl file type multipl size multipl date plenti space left environ tri close restart browser problem access aml differ problem thank advanc advic",
        "Question_preprocessed_content":"cancel upload studio cancel dataset upload tri upload csv studio upload hour sai upload tri upload file hang symptom problem block subsequ upload todai upload work file type multipl size multipl date plenti space left environ tri close restart problem aml problem thank advanc advic",
        "Question_gpt_summary_original":"The user is facing challenges in cancelling a dataset upload on Azure Machine Learning Studio. The upload has been running for over an hour and subsequent upload attempts are also failing. The user has tried accessing AMLS from a different computer and restarting the browser, but the problem persists. The user is seeking advice on how to cancel the upload.",
        "Question_gpt_summary":"user face challeng cancel dataset upload studio upload run hour subsequ upload attempt fail user tri access aml differ restart browser problem persist user seek advic cancel upload"
    },
    {
        "Question_title":"How to Visualize a custom metrics for a ProcessingStep on Sagemaker Pipeline UI",
        "Question_body":"When selecting a step from a running Sagemaker pipeline, the right-side panel has an \"Output\" tab.  We know that if the step is created from an `Estimator`, we can display all metrics from specifying `metric_definitions` parameter.  However there is no equivalent parameter for `Processor` or other types of steps.  How can we display metrics for a Sagemaker ProcessingStep then?\n![Enter image description here](\/media\/postImages\/original\/IMBajf2v2YRlaUn7mb-5dL8g)",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1675807829771,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1676154282550,
        "Question_score_count":0.0,
        "Question_view_count":42.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUYNUBZ3ELREybZ50_n469iQ\/how-to-visualize-a-custom-metrics-for-a-processingstep-on-sagemaker-pipeline-ui",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"visual custom metric processingstep pipelin select step run pipelin right panel output tab know step creat estim displai metric specifi metric definit paramet equival paramet processor type step displai metric processingstep enter imag descript media postimag origin imbajfvyrlaunmb dlg",
        "Question_preprocessed_content":"visual custom metric pipelin select step pipelin panel output tab know step creat displai metric specifi paramet equival paramet type step displai metric",
        "Question_gpt_summary_original":"The user is facing a challenge in visualizing custom metrics for a Sagemaker ProcessingStep on the Sagemaker Pipeline UI as there is no equivalent parameter for `Processor` or other types of steps to display metrics.",
        "Question_gpt_summary":"user face challeng visual custom metric processingstep pipelin equival paramet processor type step displai metric"
    },
    {
        "Question_title":"Output filename for Translate Document API",
        "Question_body":"Hello,\n\nI have been developing an iOS mobile app to translate PDF documents and currently using Google Translate documents API without any issue.\n\nIs there any way, we can update or change the output filename coming from the API? Currently, the output file name includes all the attributes starting from the project name, bucket name and finally the file name. This won't be appropriate for the users to showcase these things.\n\nIs there any configuration to change this filename to more user friendly format?\n\ne.g. Input file name -\u00a0Test_Translation_En_Fr_Sp.pdf\n\nOutput filename from Translate API -scantranslatorapp.appspot.com_uploaded_documents_FuOrb0L4tudAZvhZ99IwsFYg83M2_Test_Translation_En_Fr_Sp_fr_translations.pdf\n\nIt would be appropriate to showcase only -\u00a0Test_Translation_En_Fr_Sp_fr_translations.pdf",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1661501220000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":72.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Output-filename-for-Translate-Document-API\/m-p\/460318#M541",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"output filenam translat document api hello develop io mobil app translat pdf document current googl translat document api issu wai updat chang output filenam come api current output file includ attribut start project bucket final file won appropri user showcas thing configur chang filenam user friendli format input file test translat pdf output filenam translat api scantranslatorapp appspot com upload document fuorbltudazvhziwsfygm test translat translat pdf appropri showcas test translat translat pdf",
        "Question_preprocessed_content":"output filenam translat document api develop io mobil translat pdf document translat document api wai updat chang output filenam come api output file includ start project bucket file won user showcas thing configur chang filenam user friendli format input file output filenam translat api showcas",
        "Question_gpt_summary_original":"The user is developing an iOS mobile app to translate PDF documents using Google Translate documents API. However, the output filename generated by the API includes all the attributes starting from the project name, bucket name, and finally the file name, which is not appropriate for users. The user is looking for a way to change the output filename to a more user-friendly format.",
        "Question_gpt_summary":"user develop io mobil app translat pdf document googl translat document api output filenam gener api includ attribut start project bucket final file appropri user user look wai chang output filenam user friendli format"
    },
    {
        "Question_title":"GPT-3 access",
        "Question_body":"<p>I'd like to use GPT-3 for my application.  I understand MS has licensed GPT-3 from OpenAI, and that there is pricing too.  So how do I get to use GPT-3?  <\/p>\n<p>Chris Powell<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1605179070400,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=912f72cd-88e9-416f-bbe1-5a7356385053\">@Crispy  <\/a> Thanks for the question, Innovations from our GPT-3 workstreams will be incorporated in later versions of Azure. In the meantime, If you are interested in participation in the OpenAI GPT-3 and Azure Service partnership please fill out this <a href=\"https:\/\/forms.office.com\/Pages\/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbRyj5DlT4gqZKgEsfbkRQK5xUQVlSVlJITkxDQkRaOVdESjJGN0dONkQzNy4u\">form<\/a> to submit a request.    <\/p>\n<p>Ignite blog announcement: <a href=\"https:\/\/blogs.microsoft.com\/ai-for-business\/ai-at-scale-ignite\/\">https:\/\/blogs.microsoft.com\/ai-for-business\/ai-at-scale-ignite\/<\/a>    <\/p>\n",
        "Answer_comment_count":2.0,
        "Question_closed_time":1605182707940,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/160489\/gpt-3-access",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"gpt access like us gpt applic understand licens gpt openai price us gpt chri powel",
        "Question_preprocessed_content":" like us understand licens openai price us chri",
        "Question_gpt_summary_original":"The user is seeking information on how to access GPT-3 for their application, including details on Microsoft's licensing and pricing.",
        "Question_gpt_summary":"user seek inform access gpt applic includ detail microsoft licens price"
    },
    {
        "Question_title":"Is it possible to check that the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file?",
        "Question_body":"<p>My team has a set up wherein we track datasets and models in DVC, and have a GitLab repository for tracking our code and DVC metadata files. We have a job in our dev GitLab pipeline (run on each push to a merge request) that has the goal of checking to be sure that the developer remembered to run <code>dvc push<\/code> to keep DVC remote storage up-to-date. Right now, the way we do this is by running <code>dvc pull<\/code> on the GitLab runner, which will fail with errors telling you which files (new files or latest versions of existing files) were not found.<\/p>\n<p>The downside to this approach is that we are loading the entirety of our data stored in DVC onto a GitLab runner, and we've run into out-of-memory issues, not to mention lengthy run time to download all that data. Since the path and md5 hash of the objects are stored in the DVC metadata files, I would think that's all the information that DVC would need to be able to answer the question &quot;is the remote storage system up-to-date&quot;.<\/p>\n<p>It seems like <code>dvc status<\/code> is similar to what I'm asking for, but compares the cache or workspace and remote storage. In other words, it requires the files to actually be present on whatever filesystem is making the call.<\/p>\n<p>Is there some way to achieve the goal I laid out above (&quot;inform the developer that they need to run <code>dvc push<\/code>&quot;) without pulling everything from DVC?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1622232629793,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1622257491983,
        "Question_score_count":5.0,
        "Question_view_count":488.0,
        "Poster_created_time":1618255062696,
        "Poster_location":null,
        "Poster_reputation_count":75.0,
        "Poster_view_count":2.0,
        "Answer_body":"<blockquote>\n<p>It seems like dvc status is similar to what I'm asking for<\/p>\n<\/blockquote>\n<p><code>dvc status --cloud<\/code> will give you a list of &quot;new&quot; files if they that haven't been pushed to the (default) remote. It won't error out though, so your CI script should fail depending on the stdout message.<\/p>\n<p>More info: <a href=\"https:\/\/dvc.org\/doc\/command-reference\/status#options\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/status#options<\/a><\/p>\n<p>I'd also ask everyone to run <code>dvc install<\/code>, which will setup some Git hooks, including automatic <code>dvc push<\/code> with <code>git push<\/code>.<\/p>\n<p>See <a href=\"https:\/\/dvc.org\/doc\/command-reference\/install\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/install<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1622257759208,
        "Answer_last_edit_time":1622503453296,
        "Answer_score_count":3.0,
        "Answerer_created_time":1305851487736,
        "Answerer_location":null,
        "Answerer_reputation_count":5993.0,
        "Answerer_view_count":457.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67744934",
        "Tool":"DVC",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl check version file track metadata file exist remot storag pull file team set track dataset model gitlab repositori track code metadata file job dev gitlab pipelin run push merg request goal check sure develop rememb run push remot storag date right wai run pull gitlab runner fail error tell file new file latest version exist file downsid approach load entireti data store gitlab runner run memori issu mention lengthi run time download data path hash object store metadata file think inform need abl answer question remot storag date like statu similar ask compar cach workspac remot storag word requir file actual present filesystem make wai achiev goal laid inform develop need run push pull",
        "Question_preprocessed_content":"check version file track metadata file exist remot storag file team set track dataset model gitlab repositori track code metadata file job dev gitlab pipelin goal check sure develop rememb run remot storag right wai gitlab fail file downsid load entireti data store gitlab run mention lengthi run time download data path hash object store metadata file think inform abl answer question remot storag like similar ask compar cach workspac remot storag word requir file present filesystem make wai achiev goal laid",
        "Question_gpt_summary_original":"The user's team tracks datasets and models in DVC and has a GitLab repository for tracking code and DVC metadata files. They have a job in their dev GitLab pipeline that checks if the developer has run \"dvc push\" to keep DVC remote storage up-to-date. Currently, they run \"dvc pull\" on the GitLab runner, which loads the entirety of their data stored in DVC onto the runner, causing out-of-memory issues and lengthy run time. The user is looking for a way to check if the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file.",
        "Question_gpt_summary":"user team track dataset model gitlab repositori track code metadata file job dev gitlab pipelin check develop run push remot storag date current run pull gitlab runner load entireti data store runner caus memori issu lengthi run time user look wai check version file track metadata file exist remot storag pull file"
    },
    {
        "Question_title":"How to solve \"Encountered unresolved custom op: edgetpu-custom-op\" exception",
        "Question_body":"<p>Im trying to implement my custom ML model in a kotlin app.<\/p>\n<p>I first make and train my model in GCP Vertex AI.\nAfter my model was ready i've export it as tensor flow model to the edge and then upload to my Firebase Machine Learning proyect.<\/p>\n<p>After that i follow the <a href=\"https:\/\/firebase.google.com\/docs\/ml\/android\/use-custom-models?hl=es&amp;authuser=0\" rel=\"nofollow noreferrer\">guide to implement a custom model of tensor flow lite on android.<\/a><\/p>\n<p>Then when i execute my app it crash on this part of the code:<\/p>\n<pre><code>val conditions = CustomModelDownloadConditions.Builder()\n        .requireWifi()  \/\/ Also possible: .requireCharging() and .requireDeviceIdle()\n        .build()\nFirebaseModelDownloader.getInstance()\n        .getModel(&quot;your_model&quot;, DownloadType.LOCAL_MODEL_UPDATE_IN_BACKGROUND,\n            conditions)\n        .addOnSuccessListener { model: CustomModel? -&gt;\n            \/\/ Download complete. Depending on your app, you could enable the ML\n            \/\/ feature, or switch from the local model to the remote model, etc.\n\n            \/\/ The CustomModel object contains the local path of the model file,\n            \/\/ which you can use to instantiate a TensorFlow Lite interpreter.\n            val modelFile = model?.file\n            if (modelFile != null) {\n                interpreter = Interpreter(modelFile) \/\/ this line crash\n            }\n        }\n<\/code><\/pre>\n<p>More specific at the line &quot;interpreter = Interpreter(modelFile)&quot;.\nI get the following exception:<\/p>\n<blockquote>\n<p>java.lang.IllegalStateException: Internal error: Unexpected failure\nwhen preparing tensor allocations: Encountered unresolved custom op:\nedgetpu-custom-op. See instructions:\n<a href=\"https:\/\/www.tensorflow.org\/lite\/guide\/ops_custom\" rel=\"nofollow noreferrer\">https:\/\/www.tensorflow.org\/lite\/guide\/ops_custom<\/a>  Node number 0\n(edgetpu-custom-op) failed to prepare.<\/p>\n<\/blockquote>\n<p>What is the meaning of this error?  How can i solve it?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1663959349290,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":21.0,
        "Poster_created_time":1345651822772,
        "Poster_location":null,
        "Poster_reputation_count":109.0,
        "Poster_view_count":21.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73831871",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"solv encount unresolv custom edgetpu custom except try implement custom model kotlin app train model gcp model readi export tensor flow model edg upload firebas machin learn proyect follow guid implement custom model tensor flow lite android execut app crash code val condit custommodeldownloadcondit builder requirewifi possibl requirecharg requiredeviceidl build firebasemodeldownload getinst getmodel model downloadtyp local model updat background condit addonsuccesslisten model custommodel download complet depend app enabl featur switch local model remot model custommodel object contain local path model file us instanti tensorflow lite interpret val modelfil model file modelfil null interpret interpret modelfil line crash specif line interpret interpret modelfil follow except java lang illegalstateexcept intern error unexpect failur prepar tensor alloc encount unresolv custom edgetpu custom instruct http www tensorflow org lite guid op custom node number edgetpu custom fail prepar mean error solv",
        "Question_preprocessed_content":"solv encount unresolv custom except try implement custom model kotlin train model gcp model readi export tensor flow model edg upload firebas machin learn proyect guid implement custom model tensor flow lite android execut crash code specif line interpret interpret except intern unexpect failur prepar tensor encount unresolv custom instruct node number fail prepar mean solv",
        "Question_gpt_summary_original":"The user is trying to implement a custom ML model in a Kotlin app by following the guide to implement a custom model of TensorFlow Lite on Android. However, the app crashes at the line \"interpreter = Interpreter(modelFile)\" with the exception \"Encountered unresolved custom op: edgetpu-custom-op.\" The user is seeking help to understand the meaning of this error and how to solve it.",
        "Question_gpt_summary":"user try implement custom model kotlin app follow guid implement custom model tensorflow lite android app crash line interpret interpret modelfil except encount unresolv custom edgetpu custom user seek help understand mean error solv"
    },
    {
        "Question_title":"Deployed an mlflow sklearn model to Azure ACI using Databrics how to get the prediction probabilities",
        "Question_body":"I have deployed the model to Azure Container Instance using model.pkl file along with conda.yaml and MLproject file created by mlflow. I can get the output class for input data by hitting the endpoint\u00a0http:\/\/1fa00837-1734-487c-998e-82b402c2451a.eastasia.azurecontainer.io\/score  \nhowever I am interested in getting the prediction probabilities that we get in scikit learn model.predict_proba(). Can anyone suggest how I can do that.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1570153632000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":14.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/0yQ7tWc1Pgc",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi sklearn model azur aci databr predict probabl deploi model azur contain instanc model pkl file conda yaml mlproject file creat output class input data hit endpointhttp bca eastasia azurecontain score interest get predict probabl scikit learn model predict proba suggest",
        "Question_preprocessed_content":"deploi sklearn model azur aci databr predict probabl deploi model azur contain instanc file mlproject file creat output input data interest predict probabl scikit learn",
        "Question_gpt_summary_original":"The user has successfully deployed an mlflow sklearn model to Azure ACI using Databrics, but is facing challenges in getting the prediction probabilities that are obtained in scikit learn model.predict_proba(). The user is seeking suggestions on how to obtain these probabilities.",
        "Question_gpt_summary":"user successfulli deploi sklearn model azur aci databr face challeng get predict probabl obtain scikit learn model predict proba user seek suggest obtain probabl"
    },
    {
        "Question_title":"AWS SageMaker + Tensorflow + GPU",
        "Question_body":"<p>I'm trying to extract ELMo embeddings and running the code on AWS SageMaker and TensorFlow. The code runs fine on cpu instance in SageMaker <strong>but I want to run it on GPU<\/strong>. Below are the steps I performed and error listed:<\/p>\n\n<ol>\n<li>Started AWS SageMaker instance: ml.p3.8xlarge - it has 8 GPUs <\/li>\n<li>Started JuperterLab and selected conda_tensorflow_p36 for the notebook<\/li>\n<li>Ran the following code:<\/li>\n<\/ol>\n\n<p>!pip3 install <strong>tensorflow-gpu==1.15<\/strong>.<br>\n!pip3 install \"tensorflow-hub&lt;0.5.0\"<\/p>\n\n<pre><code>url = \"https:\/\/tfhub.dev\/google\/elmo\/2\"\nembed = hub.Module(url)\n\ndef defineEmbeddings(start, end, extractions):    \n    embeddings = embed(extractions[start:end],signature=\"default\",as_dict=True)[\"default\"]\n    return embeddings\ndef scoreExtractions (embeddings):\n\n    config = tf.compat.v1.ConfigProto(log_device_placement=True)\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.9\n    with tf.compat.v1.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(tf.tables_initializer())\n        x = sess.run(embeddings)\n    return x\n<\/code><\/pre>\n\n<p>I get the following error with sess.run(embeddings)<\/p>\n\n<p>UnknownError: 2 root error(s) found.\n  (0) Unknown: <strong>Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.<\/strong>\n     [[{{node module_apply_default_1\/bilm\/CNN_1\/Conv2D}}]]\n     [[module_apply_default_1\/truediv\/_155]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n     [[{{node module_apply_default_1\/bilm\/CNN_1\/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored.<\/p>\n\n<p>But following works with the above setup:<\/p>\n\n<pre><code>with tf.device('\/device:GPU:3'):\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n    c = tf.matmul(a, b)\nwith tf.Session() as sess:\n    print(sess.run(c))\n<\/code><\/pre>\n\n<p>Based on my reading up on this issue on StackOverflow, I also tried to use <strong>tensorflow-gpu = 1.8.0<\/strong> also and with that, I'm getting the error in import tensorflow as tf :<\/p>\n\n<p><strong>ImportError<\/strong>: libcublas.so.9.0: cannot open shared object file: No such file or directory<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1588094390093,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":454.0,
        "Poster_created_time":1568045612272,
        "Poster_location":null,
        "Poster_reputation_count":97.0,
        "Poster_view_count":17.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61486115",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tensorflow gpu try extract elmo embed run code tensorflow code run fine cpu instanc want run gpu step perform error list start instanc xlarg gpu start juperterlab select conda tensorflow notebook ran follow code pip instal tensorflow gpu pip instal tensorflow hub url http tfhub dev googl elmo emb hub modul url def defineembed start end extract embed emb extract start end signatur default dict true default return embed def scoreextract embed config compat configproto log devic placement true config gpu option allow growth true config gpu option process gpu memori fraction compat session config config sess sess run global variabl initi sess run tabl initi sess run embed return follow error sess run embed unknownerror root error unknown fail convolut algorithm probabl cudnn fail initi try look warn log messag print node modul appli default bilm cnn convd modul appli default truediv unknown fail convolut algorithm probabl cudnn fail initi try look warn log messag print node modul appli default bilm cnn convd success oper deriv error ignor follow work setup devic devic gpu constant shape constant shape matmul session sess print sess run base read issu stackoverflow tri us tensorflow gpu get error import tensorflow importerror libcubla open share object file file directori",
        "Question_preprocessed_content":"tensorflow gpu try extract elmo code tensorflow code run fine cpu instanc want run gpu step perform list start instanc gpu start juperterlab select ran code pip pip run unknown fail convolut algorithm probabl fail initi try warn log print unknown fail convolut algorithm probabl fail initi try warn log print oper deriv ignor work setup base read stackoverflow tri us import tensorflow open share object file file directori",
        "Question_gpt_summary_original":"The user is trying to extract ELMo embeddings using TensorFlow and AWS SageMaker on a GPU instance. The code runs fine on a CPU instance, but when running on a GPU instance, the user encounters an error related to cuDNN initialization. The user has tried using different versions of TensorFlow-gpu and also encountered an error related to libcublas.so.9.0.",
        "Question_gpt_summary":"user try extract elmo embed tensorflow gpu instanc code run fine cpu instanc run gpu instanc user encount error relat cudnn initi user tri differ version tensorflow gpu encount error relat libcubla"
    },
    {
        "Question_title":"Not able to log artifacts from Windows client to mlflow server running on GCP VM instance",
        "Question_body":"<p>I installed mlflow on GCP VM and started the server by running this command on VM <code>mlflow server --host x.x.x.x<\/code>, here x.x.x.x is the internal IP of the VM<\/p>\n\n<p>Set the tracking URI using <code>mlflow.set_tracking_uri(\"http:\/\/x.x.x.x:5000\/\")<\/code>, here x.x.x.x is the external ip of the VM<\/p>\n\n<p>I'm running this code now to log parameters and artifacts on GCP VM where my mlflow server is running:<\/p>\n\n<pre><code>def eval_metrics(actual, pred):\n        rmse = np.sqrt(mean_squared_error(actual, pred))\n        mae = mean_absolute_error(actual, pred)\n        r2 = r2_score(actual, pred)\n        return rmse, mae, r2\n<\/code><\/pre>\n\n<pre><code>with mlflow.start_run():\n        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n        lr.fit(train_x, train_y)\n        predicted_qualities = lr.predict(test_x)\n        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n        print(\"  RMSE: %s\" % rmse)\n        print(\"  MAE: %s\" % mae)\n        print(\"  R2: %s\" % r2)\n        mlflow.log_param(\"alpha\", alpha)\n        mlflow.log_param(\"l1_ratio\", l1_ratio)\n        mlflow.log_metric(\"rmse\", rmse)\n        mlflow.log_metric(\"r2\", r2)\n        mlflow.log_metric(\"mae\", mae)\n        mlflow.log_artifacts(lr)\n<\/code><\/pre>\n\n<p>Parameters and Metrics I'm able to get on <a href=\"https:\/\/x.x.x.x:5000\" rel=\"nofollow noreferrer\">https:\/\/x.x.x.x:5000<\/a>, where x.x.x.x is external IP of the VM, but at the last line of the code i.e., <code>mlflow.log_artifacts(lr)<\/code> facing the error given below:<\/p>\n\n<p><img src=\"https:\/\/user-images.githubusercontent.com\/10863620\/76417135-517a5b80-63c2-11ea-8235-2f6c7c2d5324.png\" alt=\"image\"><\/p>\n\n<p>When executed <code>mlflow.get_artifact_uri()<\/code>, the path returned is <code>.\/mlruns\/0\/6073b44bbac842e5axxxxxxxxxxxxxxxxxx\/artifacts<\/code><\/p>\n\n<p>Is there something wrong with the artifact path and any idea how can I resolve this to log artifacts on VM from code running on local jupyter notebook?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1583994838227,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1583995374870,
        "Question_score_count":2.0,
        "Question_view_count":154.0,
        "Poster_created_time":1451124057623,
        "Poster_location":"India",
        "Poster_reputation_count":736.0,
        "Poster_view_count":234.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60648742",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"abl log artifact window client server run gcp instanc instal gcp start server run command server host intern set track uri set track uri http extern run code log paramet artifact gcp server run def eval metric actual pred rmse sqrt mean squar error actual pred mae mean absolut error actual pred score actual pred return rmse mae start run elasticnet alpha alpha ratio ratio random state fit train train predict qualiti predict test rmse mae eval metric test predict qualiti print elasticnet model alpha ratio alpha ratio print rmse rmse print mae mae print log param alpha alpha log param ratio ratio log metric rmse rmse log metric log metric mae mae log artifact paramet metric abl http extern line code log artifact face error given execut artifact uri path return mlrun bbbaceaxxxxxxxxxxxxxxxxxx artifact wrong artifact path idea resolv log artifact code run local jupyt notebook",
        "Question_preprocessed_content":"abl log artifact window client server gcp instanc gcp start server intern set track uri extern code log paramet artifact gcp server paramet metric abl extern line code face given execut path return wrong artifact path idea resolv log artifact code local jupyt",
        "Question_gpt_summary_original":"The user is facing an issue while trying to log artifacts from a Windows client to an mlflow server running on a GCP VM instance. The user is able to log parameters and metrics on the server but is encountering an error while trying to log artifacts. The error message suggests that the path to the artifact is incorrect. The user is seeking help to resolve the issue and log artifacts on the VM from code running on a local Jupyter notebook.",
        "Question_gpt_summary":"user face issu try log artifact window client server run gcp instanc user abl log paramet metric server encount error try log artifact error messag suggest path artifact incorrect user seek help resolv issu log artifact code run local jupyt notebook"
    },
    {
        "Question_title":"SageMaker Model Registry - how to set the Stage column of a Model Package?",
        "Question_body":"Each version of a model (i.e. versioned `Model Package`) in a `Model Package Group` in SageMaker Model Registry has some metadata attached to it. You can see its `Status`, `Short description`, `Modified by` as well as `Stage` it is currently deployed on.\n\nThis can be seen in the docs [here](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-registry-deploy-history.html) on the screenshot below the 5. point on that list.\n\nMy question is - how do we explicitly (or implictly) set the `Stage` of a given `Model Package`? I know that changing the approval status can be done by calling [update_model_package](https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.update_model_package) method. What about the `Stage`?\n\nIt magically happens when we use provided MLOps templates, but even after a thorough browsing of every generated file (SM Pipelines, CodePipeline, CodeBuild etc.) I could not find the exact API call. It probably has something to do with the `sagemaker:deployment-stage` Tag but setting it up on `Endpoint`, `Endpoint Config` or `Model` (the old construct of pre-2020 SageMaker that is still used by SageMaker Inference) did not work. You can't set tags on a `Model Package`.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1638530817367,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1668626223376,
        "Question_score_count":1.0,
        "Question_view_count":902.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUI07MHIlPSbSwALreeEJ28g\/sagemaker-model-registry-how-to-set-the-stage-column-of-a-model-package",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model registri set stage column model packag version model version model packag model packag group model registri metadata attach statu short descript modifi stage current deploi seen doc http doc aw amazon com latest model registri deploi histori html screenshot point list question explicitli implictli set stage given model packag know chang approv statu call updat model packag http boto amazonaw com document api latest refer servic html client updat model packag method stage magic happen us provid mlop templat thorough brows gener file pipelin codepipelin codebuild exact api probabl deploy stage tag set endpoint endpoint config model old construct pre infer work set tag model packag",
        "Question_preprocessed_content":"model registri set stage column model packag version model model registri metadata deploi doc point list question explicitli set given know chang statu method us provid mlop templat thorough brows gener file exact api probabl tag work set tag",
        "Question_gpt_summary_original":"The user is seeking information on how to set the `Stage` column of a `Model Package` in SageMaker Model Registry. They have tried to find the API call for this but have been unsuccessful, and setting up the `sagemaker:deployment-stage` tag on other constructs did not work.",
        "Question_gpt_summary":"user seek inform set stage column model packag model registri tri api unsuccess set deploy stage tag construct work"
    },
    {
        "Question_title":"Executing existing Python Code in Azure ML",
        "Question_body":"<p>I have a code written Python and I need to deploy it on Azure ML. The python code consists of many function and returns the output in Jason format.<\/p>\n\n<p>However when implemented on Azure ML, there are no errors. But, there is no result as such generated. It is displaying the input dataset for both Result Dataset and Python device dataset.<\/p>\n\n<p>Can I know, how to go about it. I'm new to Azure ML, and have no clue how to go about it<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1483524253643,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1483525625560,
        "Question_score_count":1.0,
        "Question_view_count":111.0,
        "Poster_created_time":1479194627132,
        "Poster_location":null,
        "Poster_reputation_count":2713.0,
        "Poster_view_count":358.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41461066",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"execut exist python code code written python need deploi python code consist function return output jason format implement error result gener displai input dataset result dataset python devic dataset know new clue",
        "Question_preprocessed_content":"execut exist python code code python deploi python code consist function return output jason format implement result gener displai input dataset result dataset python devic dataset know new clue",
        "Question_gpt_summary_original":"The user is facing challenges in deploying existing Python code on Azure ML. Although there are no errors, the output is not generated and only the input dataset is displayed for both Result Dataset and Python device dataset. The user is seeking guidance on how to proceed as they are new to Azure ML.",
        "Question_gpt_summary":"user face challeng deploi exist python code error output gener input dataset displai result dataset python devic dataset user seek guidanc proce new"
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml.train'",
        "Question_body":"<p>I am following the chalenge: &quot;How to predict many protein structures with AlphaFold2 at-scale in Azure Machine Learning&quot; <\/p>\n<p><a href=\"https:\/\/colbyford.medium.com\/how-to-predict-many-protein-structures-with-alphafold2-at-scale-in-azure-machine-learning-c1e0ece4e99f\">https:\/\/colbyford.medium.com\/how-to-predict-many-protein-structures-with-alphafold2-at-scale-in-azure-machine-learning-c1e0ece4e99f<\/a><\/p>\n<p>I run the pipeline below: <\/p>\n<p><em>from azureml.core import Experiment, ScriptRunConfig, Environment<\/em><\/p>\n<p><em>from azureml.core.conda_dependencies import CondaDependencies<\/em><\/p>\n<p><em>from azureml.train.hyperdrive import GridParameterSampling, RandomParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice<\/em><\/p>\n<p><em>from azureml.widgets import RunDetails<\/em><\/p>\n<p><em>## Create a Python environment for the experiment<\/em><\/p>\n<p><em>alphafold2_env = Environment(&quot;alphafold2&quot;)<\/em><\/p>\n<p><em>alphafold2_env.docker.base_image = &quot;cford38\/alphafold2_aml:latest&quot;<\/em><\/p>\n<p><em>alphafold2_env.python.user_managed_dependencies = True<\/em><\/p>\n<p><em>## Create a script config<\/em><\/p>\n<p><em>script_config = ScriptRunConfig(source_directory = &quot;.&quot;,<\/em><\/p>\n<pre><code>                            *script='predict.py',*\n\n                            *arguments = ['--msa_mode', &quot;MMseqs2 (UniRef+Environmental)&quot;,*\n\n                                         *'--num_models', 1,*\n\n                                         *'--num_recycles', 3,*\n\n                                         *'--stop_at_score', 90],*\n\n                            *environment = alphafold2_env,*\n\n                            *compute_target = training_cluster)*\n<\/code><\/pre>\n<p><em>## Sample a range of parameter values<\/em><\/p>\n<p><em>params = GridParameterSampling({ '--sequence_id': choice('alpha_b117_6xc2', 'beta_b1351_7vx1', 'delta_b1617_7v70', 'omicron_b11529_7t9j') })<\/em><\/p>\n<p><em>## Configure hyperdrive settings<\/em><\/p>\n<p><em>hyperdrive = HyperDriveConfig(run_config = script_config,<\/em> <\/p>\n<pre><code>                          *hyperparameter_sampling = params,* \n\n                          *policy = None,* \n\n                          *primary_metric_name = 'complete',* \n\n                          *primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,* \n\n                          *max_total_runs = 4,*\n\n                          *max_concurrent_runs = 3)*\n<\/code><\/pre>\n<p><strong>I receive the following notifications at the end:<\/strong><\/p>\n<pre><code>ModuleNotFoundError                       Traceback (most recent call last)\nInput In [10], in &lt;cell line: 3&gt;()\n      1 from azureml.core import Experiment, ScriptRunConfig, Environment\n      2 from azureml.core.conda_dependencies import CondaDependencies\n----&gt; 3 from azureml.train.hyperdrive import GridParameterSampling, RandomParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n      4 from azureml.widgets import RunDetails\n      6 ## Create a Python environment for the experiment\n\nModuleNotFoundError: No module named 'azureml.train'\n<\/code><\/pre>\n<p>It appears that &quot;azureml.train&quot; is an uninstalled module. But I did set it up.<\/p>\n<p>Best <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1675732052720,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1168278\/modulenotfounderror-no-module-named-azureml-train",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"modulenotfounderror modul name train follow chaleng predict protein structur alphafold scale http colbyford medium com predict protein structur alphafold scale azur machin learn ceeceef run pipelin core import experi scriptrunconfig environ core conda depend import condadepend train hyperdr import gridparametersampl randomparametersampl hyperdriveconfig primarymetricgo choic widget import rundetail creat python environ experi alphafold env environ alphafold alphafold env docker base imag cford alphafold aml latest alphafold env python user manag depend true creat script config script config scriptrunconfig sourc directori script predict argument msa mode mmseq uniref environment num model num recycl stop score environ alphafold env comput target train cluster sampl rang paramet valu param gridparametersampl sequenc choic alpha beta delta omicron configur hyperdr set hyperdr hyperdriveconfig run config script config hyperparamet sampl param polici primari metric complet primari metric goal primarymetricgo maxim max total run max concurr run receiv follow notif end modulenotfounderror traceback recent input core import experi scriptrunconfig environ core conda depend import condadepend train hyperdr import gridparametersampl randomparametersampl hyperdriveconfig primarymetricgo choic widget import rundetail creat python environ experi modulenotfounderror modul name train appear train uninstal modul set best",
        "Question_preprocessed_content":"modul name chaleng predict protein structur alphafold run pipelin core import experi scriptrunconfig environ import condadepend import gridparametersampl randomparametersampl hyperdriveconfig primarymetricgo choic widget import rundetail creat python environ experi environ true creat script config sampl rang paramet valu param gridparametersampl configur hyperdr hyperdr receiv notif end modul set best",
        "Question_gpt_summary_original":"The user encountered a ModuleNotFoundError while running a pipeline for predicting protein structures with AlphaFold2 in Azure Machine Learning. The error message indicates that the 'azureml.train' module is not installed, despite being set up by the user.",
        "Question_gpt_summary":"user encount modulenotfounderror run pipelin predict protein structur alphafold error messag indic train modul instal despit set user"
    },
    {
        "Question_title":"Azure ML Studio vs Azure ML Classic - K-Means",
        "Question_body":"<p>Hi,     <br \/>\nWe have been using ML Classic and are testing and deploying to Azure ML Studio. As per the documentation for migration (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview<\/a> ) we decided to test the output results using the same algorithm (K-Means) and using the same dataset and parameters. The output was then compared and the results differ. Can someone help me understand why or why not this is expected and any other topics to consider between the two enviornments?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1632846849270,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569616\/azure-ml-studio-vs-azure-ml-classic-k-means",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio classic mean classic test deploi studio document migrat http learn microsoft com azur machin learn migrat overview decid test output result algorithm mean dataset paramet output compar result differ help understand expect topic consid enviorn",
        "Question_preprocessed_content":"studio test deploi studio document migrat decid test output result algorithm dataset paramet output compar result help understand expect topic consid enviorn",
        "Question_gpt_summary_original":"The user is facing challenges while migrating from Azure ML Classic to Azure ML Studio. They tested the output results using the same algorithm (K-Means) and dataset with the same parameters, but the results differed. The user is seeking help to understand why this happened and any other topics to consider between the two environments.",
        "Question_gpt_summary":"user face challeng migrat classic studio test output result algorithm mean dataset paramet result differ user seek help understand happen topic consid environ"
    },
    {
        "Question_title":"How to perform Real Time Object Detection with trained AWS model",
        "Question_body":"<p>After successfully training object detection model with AWS SageMaker, how do I use this model to perform real time object detection on RTSP video?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1613826543790,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":162.0,
        "Poster_created_time":1597047251990,
        "Poster_location":null,
        "Poster_reputation_count":139.0,
        "Poster_view_count":46.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66291913",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"perform real time object detect train aw model successfulli train object detect model us model perform real time object detect rtsp video",
        "Question_preprocessed_content":"perform real time object detect train aw model train object detect model us model perform real time object detect rtsp video",
        "Question_gpt_summary_original":"The user has trained an object detection model with AWS SageMaker and is now seeking guidance on how to use the model for real-time object detection on RTSP video.",
        "Question_gpt_summary":"user train object detect model seek guidanc us model real time object detect rtsp video"
    },
    {
        "Question_title":"how to retrain model and deploy (if new model is better) by schedule or trigger with Azure MLops ?",
        "Question_body":"<p>Hi  <\/p>\n<p>i am beginner of azure.  <\/p>\n<p>i am trying to use mlops.  <\/p>\n<p>it is not easy to not programmer...  <\/p>\n<p>but i want to practice mlops.  <\/p>\n<p>i want to retrain model by  scheduling.   <\/p>\n<p>please let me know <em><strong>how to retrain model and deploy (if new model is better) by schedule or trigger with Azure MLops<\/strong><\/em>  <\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0.0,
        "Question_created_time":1592185292417,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/35810\/how-to-retrain-model-and-deploy-(if-new-model-is-b",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retrain model deploi new model better schedul trigger op beginn azur try us mlop easi programm want practic mlop want retrain model schedul let know retrain model deploi new model better schedul trigger op",
        "Question_preprocessed_content":"retrain model deploi schedul op azur try us mlop easi want practic mlop want retrain model schedul let know retrain model deploi schedul op",
        "Question_gpt_summary_original":"The user is a beginner in Azure and is trying to use MLOps to retrain and deploy a model by schedule or trigger. They are seeking guidance on how to accomplish this task with Azure MLOps.",
        "Question_gpt_summary":"user beginn azur try us mlop retrain deploi model schedul trigger seek guidanc accomplish task op"
    },
    {
        "Question_title":"How to set spark configuration parameters in PySparkProcessor() in sagemaker processing job?",
        "Question_body":"Hi folks,\nI'm trying to set the spark executor instances & memory, driver memory and switch of dynamic allocation. What is the correct way to do it?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1656608387774,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668533410958,
        "Question_score_count":0.0,
        "Question_view_count":474.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUhyE6RyH-QwaUsVFnslKjlg\/how-to-set-spark-configuration-parameters-in-pysparkprocessor-in-sagemaker-processing-job",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"set spark configur paramet pysparkprocessor process job folk try set spark executor instanc memori driver memori switch dynam alloc correct wai",
        "Question_preprocessed_content":"set spark configur paramet job folk try set spark executor instanc memori driver memori switch dynam wai",
        "Question_gpt_summary_original":"The user is seeking guidance on how to set spark configuration parameters such as executor instances, memory, driver memory, and dynamic allocation in PySparkProcessor() for a Sagemaker processing job.",
        "Question_gpt_summary":"user seek guidanc set spark configur paramet executor instanc memori driver memori dynam alloc pysparkprocessor process job"
    },
    {
        "Question_title":"How can dvc pipeline recognize when to use encoding pipeline while new data added for the modeling?",
        "Question_body":"<p>I have created separate pipelines for feature encoding and feature scaling in DVC.\nNow, when I will input new data from my flask API, how these DVC pipelines will automatically run and encode and scale data for modelling?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1654017845533,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":25.0,
        "Poster_created_time":1654016718443,
        "Poster_location":null,
        "Poster_reputation_count":9.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72451922",
        "Tool":"DVC",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pipelin recogn us encod pipelin new data ad model creat separ pipelin featur encod featur scale input new data flask api pipelin automat run encod scale data model",
        "Question_preprocessed_content":"pipelin recogn us encod pipelin new data model creat separ pipelin featur encod featur scale input new data flask api pipelin run encod scale data",
        "Question_gpt_summary_original":"The user has created separate pipelines for feature encoding and scaling in DVC and is wondering how these pipelines will automatically run and encode and scale new data for modeling when inputted from their Flask API.",
        "Question_gpt_summary":"user creat separ pipelin featur encod scale wonder pipelin automat run encod scale new data model input flask api"
    },
    {
        "Question_title":"Can I make Amazon SageMaker deliver a recommendation based on historic data instead of a probability score?",
        "Question_body":"<p>We have a huge set of data in CSV format, containing a few numeric elements, like this:<\/p>\n\n<pre><code>Year,BinaryDigit,NumberToPredict,JustANumber, ...other stuff\n1954,1,762,16, ...other stuff\n1965,0,142,16, ...other stuff\n1977,1,172,16, ...other stuff\n<\/code><\/pre>\n\n<p>The thing here is that there is a strong correlation between the third column and the columns before that. So I have pre-processed the data and it's now available in a format I think is perfect:<\/p>\n\n<pre><code>1954,1,762\n1965,0,142\n1977,1,172\n<\/code><\/pre>\n\n<p>What I want is a predicition on the value in the third column, using the first two as input. So in the case above, I want the input 1965,0 to return 142. In real life this file is thousands of rows, but since there's a pattern, I'd like to retrieve the most possible value.<\/p>\n\n<p>So far I've setup a train job on the CSV file using the L<em>inear Learner<\/em> algorithm, with the following settings:<\/p>\n\n<pre><code>label_size = 1\nfeature_dim = 2\npredictor_type = regression\n<\/code><\/pre>\n\n<p>I've also created a model from it, and setup an endpoint. When I invoke it, I get a score in return.<\/p>\n\n<pre><code>    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n                                   ContentType='text\/csv',\n                                   Body=payload)\n<\/code><\/pre>\n\n<p>My goal here is to get the third column prediction instead. How can I achieve that? I have read a lot of the documentation regarding this, but since I'm not very familiar with AWS, I might as well have used the wrong algorithms for what I am trying to do.<\/p>\n\n<p>(Please feel free to edit this question to better suit AWS terminology)<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1552553455710,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1552895653107,
        "Question_score_count":1.0,
        "Question_view_count":271.0,
        "Poster_created_time":1411464641600,
        "Poster_location":"\u00d6rebro, Sverige",
        "Poster_reputation_count":205.0,
        "Poster_view_count":38.0,
        "Answer_body":"<p>For csv input, the label should be in the first column, as mentioned <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/cdf-training.html\" rel=\"nofollow noreferrer\">here<\/a>:  So you should preprocess your data to put the label (the column you want to predict) on the left.<\/p>\n\n<p>Next, you need to decide whether this is a regression problem or a classification problem. <\/p>\n\n<p>If you want to predict a number that's as close as possible to the true number, that's regression. For example, the truth might be 4, and the model might predict 4.15. If you need an integer prediction, you could round the model's output.<\/p>\n\n<p>If you want the prediction to be one of a few categories, then you have a classification problem. For example, we might encode 'North America' = 0, 'Europe' = 1, 'Africa' = 2, and so on. In this case, a fractional prediction wouldn't make sense. <\/p>\n\n<p>For regression, use <code>'predictor_type' = 'regressor'<\/code> and for classification with more than 2 classes, use <code>'predictor_type' = 'multiclass_classifier'<\/code> as documented <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ll_hyperparameters.html\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>The output of regression will contain only a <code>'score'<\/code> field, which is the model's prediction. The output of multiclass classification will contain a <code>'predicted_label'<\/code> field, which is the model's prediction, as well as a <code>'score'<\/code> field, which is a vector of probabilities representing the model's confidence. The index with the highest probability will be the one that's predicted as the <code>'predicted_label'<\/code>. The output formats are documented <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/LL-in-formats.html\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1553880598532,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1373375969332,
        "Answerer_location":"New York, NY, USA",
        "Answerer_reputation_count":126.0,
        "Answerer_view_count":16.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55158307",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deliv recommend base histor data instead probabl score huge set data csv format contain numer element like year binarydigit numbertopredict justanumb stuff stuff stuff stuff thing strong correl column column pre process data avail format think perfect want predicit valu column input case want input return real life file thousand row pattern like retriev possibl valu far setup train job csv file linear learner algorithm follow set label size featur dim predictor type regress creat model setup endpoint invok score return respons runtim invok endpoint endpointnam endpoint contenttyp text csv bodi payload goal column predict instead achiev read lot document familiar aw wrong algorithm try feel free edit question better suit aw terminolog",
        "Question_preprocessed_content":"deliv base histor data instead probabl score huge set data csv format contain numer element like thing strong column column data avail format think perfect want predicit valu column input case want input return real life file thousand row like retriev valu far setup train job csv file linear learner algorithm creat model setup endpoint invok score return goal column predict instead achiev read lot document familiar aw wrong algorithm try edit question suit aw terminolog",
        "Question_gpt_summary_original":"The user has a large dataset in CSV format with a strong correlation between the third column and the columns before it. They have pre-processed the data and want to use the first two columns as input to predict the value in the third column. The user has set up a train job using the Linear Learner algorithm with regression settings and created a model and endpoint. However, when invoking the endpoint, they receive a score instead of the predicted value. The user is seeking guidance on how to achieve their goal of getting the predicted value instead of a score.",
        "Question_gpt_summary":"user larg dataset csv format strong correl column column pre process data want us column input predict valu column user set train job linear learner algorithm regress set creat model endpoint invok endpoint receiv score instead predict valu user seek guidanc achiev goal get predict valu instead score"
    },
    {
        "Question_title":"I am not able to create a feature store in vertexAI using labels",
        "Question_body":"<p>I am passing the values of lables as below to create a featurestore with labels. But after creation of the featurestore, I do not see the featurestore created with labels. Is it still not supported in VertexAI<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>    fs = aiplatform.Featurestore.create(\n        featurestore_id=featurestore_id,\n        labels=dict(project='retail', env='prod'),\n        online_store_fixed_node_count=online_store_fixed_node_count,\n        sync=sync\n    )\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/viOSu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/viOSu.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1651616413553,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1651623411107,
        "Question_score_count":0.0,
        "Question_view_count":83.0,
        "Poster_created_time":1530457174832,
        "Poster_location":null,
        "Poster_reputation_count":1043.0,
        "Poster_view_count":212.0,
        "Answer_body":"<p>As mentioned in this <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/featurestore\/managing-featurestores\" rel=\"nofollow noreferrer\">featurestore documentation<\/a>:<\/p>\n<blockquote>\n<p>A <strong>featurestore<\/strong> is a top-level container for entity types, features,\nand feature values.<\/p>\n<\/blockquote>\n<p>With this, the GCP console UI &quot;labels&quot; are the &quot;labels&quot; at the <strong>Feature<\/strong> level.<\/p>\n<p>Once a <strong>featurestore<\/strong> is created, you will need to create an <strong>entity<\/strong> and then create a <strong>Feature<\/strong> that has the <em>labels<\/em> parameter as shown on the below sample python code.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from google.cloud import aiplatform\n\ntest_label = {'key1' : 'value1'}\n\ndef create_feature_sample(\n    project: str,\n    location: str,\n    feature_id: str,\n    value_type: str,\n    entity_type_id: str,\n    featurestore_id: str,\n):\n\n    aiplatform.init(project=project, location=location)\n\n    my_feature = aiplatform.Feature.create(\n        feature_id=feature_id,\n        value_type=value_type,\n        entity_type_name=entity_type_id,\n        featurestore_id=featurestore_id,\n        labels=test_label,\n    )\n\n    my_feature.wait()\n\n    return my_feature\n\ncreate_feature_sample('your-project','us-central1','test_feature3','STRING','test_entity3','test_fs3')\n<\/code><\/pre>\n<p>Below is the screenshot of the GCP console which shows that <em>labels<\/em> for <strong>test_feature3<\/strong> feature has the values defined in the above sample python code.\n<a href=\"https:\/\/i.stack.imgur.com\/7S2oa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7S2oa.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>You may refer to this <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/featurestore\/managing-features#create-feature\" rel=\"nofollow noreferrer\">creation of feature documentation<\/a> using python for more details.<\/p>\n<p>On the other hand, you may still view the <em>labels<\/em> you defined for your featurestore using the REST API as shown on the below sample.<\/p>\n<pre><code>curl -X GET \\\n-H &quot;Authorization: Bearer &quot;$(gcloud auth application-default print-access-token) \\\n&quot;https:\/\/&lt;your-location&gt;-aiplatform.googleapis.com\/v1\/projects\/&lt;your-project&gt;\/locations\/&lt;your-location&gt;\/featurestores&quot;\n<\/code><\/pre>\n<p>Below is the result of the REST API which also shows the value of the <em>labels<\/em> I defined for my &quot;test_fs3&quot; featurestore.\n<a href=\"https:\/\/i.stack.imgur.com\/gW45X.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gW45X.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1651709813300,
        "Answer_last_edit_time":1651710305260,
        "Answer_score_count":0.0,
        "Answerer_created_time":1639972620503,
        "Answerer_location":null,
        "Answerer_reputation_count":1653.0,
        "Answerer_view_count":1212.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72106030",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"abl creat featur store vertexai label pass valu labl creat featurestor label creation featurestor featurestor creat label support vertexai aiplatform featurestor creat featurestor featurestor label dict project retail env prod onlin store fix node count onlin store fix node count sync sync",
        "Question_preprocessed_content":"abl creat featur store vertexai label valu labl creat featurestor label creation featurestor featurestor creat label vertexai",
        "Question_gpt_summary_original":"The user is unable to create a feature store in VertexAI using labels. They have passed the values of labels to create a feature store, but after creation, they are unable to see the feature store created with labels. The user is unsure if this feature is supported in VertexAI.",
        "Question_gpt_summary":"user unabl creat featur store vertexai label pass valu label creat featur store creation unabl featur store creat label user unsur featur support vertexai"
    },
    {
        "Question_title":"Mono repo Kedro project",
        "Question_body":"<p>I started a Kedro project a while ago and started to build different parts of the pipeline which only tangentially interact with each other. In some cases not much at all.<\/p>\n<p>As a consequence, as the project grew, I am starting to get issues with the dependencies given that the installation process uses requirement.txt<\/p>\n<p>Thus I wanted to ask if Kedro was meant to be designed as a mono repo or not.\nIf so, is there an example of how this could be done, please?\nThanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1650877645533,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":68.0,
        "Poster_created_time":1384332648270,
        "Poster_location":null,
        "Poster_reputation_count":158.0,
        "Poster_view_count":22.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71997005",
        "Tool":"Kedro",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"mono repo project start project ago start build differ part pipelin tangenti interact case consequ project grew start issu depend given instal process us requir txt want ask meant design mono repo exampl thank advanc",
        "Question_preprocessed_content":"mono repo project start project ago start build part pipelin interact case consequ project grew start depend given us want ask meant design mono repo exampl thank advanc",
        "Question_gpt_summary_original":"The user started a Kedro project with different parts of the pipeline that have minimal interaction with each other. As the project grew, the user encountered dependency issues during installation using requirement.txt. The user is now asking if Kedro is designed to be a mono repo and if there are examples of how to do it.",
        "Question_gpt_summary":"user start project differ part pipelin minim interact project grew user encount depend issu instal requir txt user ask design mono repo exampl"
    },
    {
        "Question_title":"how to create diff environments for different python packages in production",
        "Question_body":"<p> We have couple of libraries which are created to be used by user while working on their azure ML workspace. <\/p>\n<p>Now, both of these libraries have diff packages which could be different then what a user is using. Eg : User might be using an environment which is using numpy x.1 but package A might be using x.2 and package B needs x.3. This is a possibility since all these packages are developed by different teams.<\/p>\n<p>Now, what could be the best way to handle this problem in real world. So far, I am able to come up with below approaches :<\/p>\n<ol>\n<li> Install these files in different docker container where the needed packages are installed. And get the desired output done in separate environments.<\/li>\n<li> Use Custom Environment options provided by Azure itself. And run the incompatibles ones in different environment.<\/li>\n<\/ol>\n<p>So, I wanted to know if there is any right way of doing this in real world. I see that we should create a different environment for each project but what about the case when we have different packages which needs different versions of common dependencies. How to handle such case?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1685288180313,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1293107\/how-to-create-diff-environments-for-different-pyth",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat diff environ differ python packag product coupl librari creat user work workspac librari diff packag differ user user environ numpi packag packag need possibl packag develop differ team best wai handl problem real world far abl come approach instal file differ docker contain need packag instal desir output separ environ us custom environ option provid azur run incompat on differ environ want know right wai real world creat differ environ project case differ packag need differ version common depend handl case",
        "Question_preprocessed_content":"creat environ python packag product coupl librari creat user work workspac librari packag user user environ numpi packag packag packag develop team best wai handl problem real world far abl come file docker contain packag desir output separ environ us custom environ option provid azur run incompat on environ want know right wai real world creat environ project case packag version depend handl case",
        "Question_gpt_summary_original":"The user is facing a challenge of creating different environments for different Python packages in production. They have two libraries with different packages that may conflict with the user's environment. The user is considering two approaches: installing the files in different Docker containers or using custom environment options provided by Azure. They are seeking advice on the best way to handle this problem in the real world, especially when different packages need different versions of common dependencies.",
        "Question_gpt_summary":"user face challeng creat differ environ differ python packag product librari differ packag conflict user environ user consid approach instal file differ docker contain custom environ option provid azur seek advic best wai handl problem real world especi differ packag need differ version common depend"
    },
    {
        "Question_title":"Adding values manually to run",
        "Question_body":"<p>Hey!<\/p>\n<p>I have some metrics which I cannot log during a run, but would like to attach to afterwards to also plot it. Is there a ways through the website or the CLI to manually attach a new value or metric?<\/p>\n<p>Greetings,<br>\nPatrick<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1648052810276,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":508.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/adding-values-manually-to-run\/2146",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"ad valu manual run hei metric log run like attach plot wai websit cli manual attach new valu metric greet patrick",
        "Question_preprocessed_content":"valu run hei metric log run like plot wai websit cli new valu metric patrick",
        "Question_gpt_summary_original":"The user is looking for a way to manually attach new values or metrics to a run after it has already taken place, as they were unable to log certain metrics during the run. They are seeking a solution through the website or CLI.",
        "Question_gpt_summary":"user look wai manual attach new valu metric run taken place unabl log certain metric run seek solut websit cli"
    },
    {
        "Question_title":"Trying to invoke an AWS sagemaker endpoint for a locally trained Object detection model (with .pb file). Facing this issue while invoking",
        "Question_body":"<p>I have created a multi model endpoint and facing issue while invoking the object detection model alone. The OD model has only .pb file and no variables folder in the saved model dir. While trying to invoke the endpoint with a sample image, I am getting this error:\n<a href=\"https:\/\/i.stack.imgur.com\/H4I3v.png\" rel=\"nofollow noreferrer\">Error in Cloudwatch:<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1631791432093,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":32.0,
        "Poster_created_time":1605887877220,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69207550",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"try invok endpoint local train object detect model file face issu invok creat multi model endpoint face issu invok object detect model model file variabl folder save model dir try invok endpoint sampl imag get error error cloudwatch",
        "Question_preprocessed_content":"try invok endpoint train object detect model face invok creat multi model endpoint face invok object detect model model file variabl folder save model dir try invok endpoint sampl imag cloudwatch",
        "Question_gpt_summary_original":"The user is facing an issue while trying to invoke an AWS Sagemaker endpoint for a locally trained object detection model with only a .pb file and no variables folder in the saved model directory. The user is receiving an error while trying to invoke the endpoint with a sample image.",
        "Question_gpt_summary":"user face issu try invok endpoint local train object detect model file variabl folder save model directori user receiv error try invok endpoint sampl imag"
    },
    {
        "Question_title":"AzureML Error on Linux: \"Unable to retrieve .NET dependencies. Please make sure you are connected ...\"",
        "Question_body":"<p>I am getting this error on a Linux box (Gentoo w\/ .NET via Mono properly installed)<\/p>\n<p><strong>&quot;Unable to retrieve .NET dependencies. Please make sure you are connected to the Internet and have a stable network connection.&quot;<\/strong><\/p>\n<p>The error is triggered when creating a dataset from a directory using<\/p>\n<p>&quot;dataset = Dataset.File.from_files(path=(datastore, path_to_dataset_in_datastore))&quot;<\/p>\n<p>Some system info:  <br \/>\nPython: 3.8.8.  <br \/>\nazureml-automl-core 1.26.0  <br \/>\nazureml-core 1.26.0  <br \/>\nazureml-dataprep 2.13.2  <br \/>\nazureml-dataprep-native 32.0.0  <br \/>\nazureml-dataprep-rslex 1.11.2  <br \/>\nazureml-dataset-runtime 1.26.0  <br \/>\nazureml-pipeline 1.26.0  <br \/>\nazureml-pipeline-core 1.26.0  <br \/>\nazureml-pipeline-steps 1.26.0  <br \/>\nazureml-sdk 1.26.0  <br \/>\nazureml-telemetry 1.26.0  <br \/>\nazureml-train 1.26.0  <br \/>\nazureml-train-automl-client 1.26.0  <br \/>\nazureml-train-core 1.26.0  <br \/>\nazureml-train-restclients-hyperdrive 1.26.0<\/p>\n<p>.NET Info:  <br \/>\nMono JIT compiler version 6.6.0.161 (tarball Sat Apr 10 16:41:12 PDT 2021)  <br \/>\nCopyright (C) 2002-2014 Novell, Inc, Xamarin Inc and Contributors. <a href=\"https:\/\/www.mono-project.com\">www.mono-project.com<\/a>  <br \/>\nTLS: __thread  <br \/>\nSIGSEGV: altstack  <br \/>\nNotifications: epoll  <br \/>\nArchitecture: amd64  <br \/>\nDisabled: none  <br \/>\nMisc: softdebug  <br \/>\nInterpreter: yes  <br \/>\nLLVM: supported, not enabled.  <br \/>\nSuspend: hybrid  <br \/>\nGC: sgen (concurrent by default)<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_created_time":1618767312437,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=48487b4e-cd4d-4b5e-aae5-dcf8dfaf50c4\">@Victor Fragoso  <\/a>  Thanks for the details. Gentoo is not a 'natively' supported distribution of linux for Datasets. The Exception message doesn't link to a .NET docs page with instructions on installing the system dependencies required for .NET to work. Though it seems a different one is being thrown related to not being able to connect to out blob storage which has pre-prepared dependency sets for some linux distros (not gentoo).    <\/p>\n<p>This page <a href=\"https:\/\/learn.microsoft.com\/en-us\/dotnet\/core\/install\/linux\">Install .NET on Linux Distributions | Microsoft Learn<\/a> does not detail support for .NET on gentoo.    <br \/>\nYou can get the names of the missing dependencies themselves by running:    <\/p>\n<pre><code>from dotnetcore2 import runtime  \nruntime._enable_debug_logging()  \nruntime.ensure_dependencies()  \n<\/code><\/pre>\n<p>This code snippet should print the libraies missing required by .NET core 2.1.    <br \/>\nIf the above does not print anything, other than the Exception, then instead this should:    <\/p>\n<pre><code>from dotnetcore2 import runtime  \nprint(runtime._gather_dependencies(runtime._get_bin_folder()))  \n<\/code><\/pre>\n",
        "Answer_comment_count":5.0,
        "Question_closed_time":1619068615363,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/361522\/azureml-error-on-linux-unable-to-retrieve-net-depe",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error linux unabl retriev net depend sure connect get error linux box gentoo net mono properli instal unabl retriev net depend sure connect internet stabl network connect error trigger creat dataset directori dataset dataset file file path datastor path dataset datastor info python automl core core dataprep dataprep nativ dataprep rslex dataset runtim pipelin pipelin core pipelin step sdk telemetri train train automl client train core train restclient hyperdr net info mono jit compil version tarbal sat apr pdt copyright novel xamarin contributor www mono project com tl thread sigsegv altstack notif epol architectur amd disabl misc softdebug interpret ye llvm support enabl suspend hybrid sgen concurr default",
        "Question_preprocessed_content":"linux unabl retriev net depend sure linux box unabl retriev net depend sure internet stabl network creat dataset directori dataset info python core dataprep pipelin sdk telemetri train net info mono jit compil version copyright xamarin contributor tl sigsegv altstack notif architectur amd disabl misc softdebug interpret ye enabl suspend hybrid sgen",
        "Question_gpt_summary_original":"The user is encountering an error on a Linux box while creating a dataset from a directory using AzureML. The error message states that it is unable to retrieve .NET dependencies and suggests checking the internet connection and network stability. The system information and .NET info are also provided.",
        "Question_gpt_summary":"user encount error linux box creat dataset directori error messag state unabl retriev net depend suggest check internet connect network stabil inform net info provid"
    },
    {
        "Question_title":"How to disable logs in Kedro",
        "Question_body":"<p>I have been unsuccessful in disabling kedro logs.  I have tried adding <code>disable_existing_loggers: True<\/code> to the logging.yml file as well as <code>disable:True<\/code> to all of the existing logs and it still appears to be saving log files.  Any suggestions?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1573137628147,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":410.0,
        "Poster_created_time":1479159384132,
        "Poster_location":"Illinois, United States",
        "Poster_reputation_count":513.0,
        "Poster_view_count":113.0,
        "Answer_body":"<p>If you want <code>kedro<\/code> to stop logging you can override the <code>_setup_logging<\/code> in <code>ProjectContext<\/code> in <code>src\/&lt;package-name&gt;\/run.py<\/code> as per the <a href=\"https:\/\/kedro.readthedocs.io\/en\/latest\/04_user_guide\/07_logging.html#configure-logging\" rel=\"nofollow noreferrer\">documentation<\/a>. For example:<\/p>\n\n<pre><code>class ProjectContext(KedroContext):\n    \"\"\"Users can override the remaining methods from the parent class here, or create new ones\n    (e.g. as required by plugins)\n\n    \"\"\"\n\n    project_name = \"&lt;PACKGE-NAME&gt;\"\n    project_version = \"0.15.4\"\n\n    def _get_pipelines(self) -&gt; Dict[str, Pipeline]:\n        return create_pipelines()\n\n    def _setup_logging(self) -&gt; None:\n        import logging\n        logging.disable()\n<\/code><\/pre>\n\n<p>If you want it to still log to the console, but not save to <code>logs\/info.log<\/code> then you can do <code>def _setup_logging(self) -&gt; None: pass<\/code>.<\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1573141908796,
        "Answer_last_edit_time":1573142581883,
        "Answer_score_count":3.0,
        "Answerer_created_time":1530092504712,
        "Answerer_location":"London, United Kingdom",
        "Answerer_reputation_count":915.0,
        "Answerer_view_count":288.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58751122",
        "Tool":"Kedro",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"disabl log unsuccess disabl log tri ad disabl exist logger true log yml file disabl true exist log appear save log file suggest",
        "Question_preprocessed_content":"disabl log disabl log tri yml file exist log save log file",
        "Question_gpt_summary_original":"The user is having trouble disabling logs in Kedro despite trying to add \"disable_existing_loggers: True\" to the logging.yml file and \"disable:True\" to existing logs. They are seeking suggestions to resolve the issue.",
        "Question_gpt_summary":"user have troubl disabl log despit try add disabl exist logger true log yml file disabl true exist log seek suggest resolv issu"
    },
    {
        "Question_title":"webhook timeouts debugging issue",
        "Question_body":"Hi there,\n\nWhen users are interacting with our agent it will randomly timeout during the conversation. There seems to be no immediate pattern to the timeouts, and it tends to occur at different points in the conversation flow, making it hard to debug.\u00a0\n\nCould anyone outline to me common reasons for agent\/webhook timeouts? And any steps I can take to resolve\/pinpoint the issue?\u00a0\n\nThank you in advance,\n\nVicky",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1675319040000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":81.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/webhook-timeouts-debugging-issue\/m-p\/516923#M1176",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"webhook timeout debug issu user interact agent randomli timeout convers immedi pattern timeout tend occur differ point convers flow make hard debug outlin common reason agent webhook timeout step resolv pinpoint issu thank advanc vicki",
        "Question_preprocessed_content":"timeout user interact agent randomli timeout convers timeout tend point convers flow make hard debug outlin reason timeout step thank advanc vicki",
        "Question_gpt_summary_original":"The user is experiencing random timeouts during conversations with their agent, with no clear pattern or specific point of occurrence. They are seeking advice on common reasons for agent\/webhook timeouts and steps to resolve or pinpoint the issue.",
        "Question_gpt_summary":"user experienc random timeout convers agent clear pattern specif point occurr seek advic common reason agent webhook timeout step resolv pinpoint issu"
    },
    {
        "Question_title":"How to access file system in Sagemaker notebook instance from outside of that instance (ie via Python Sagemaker Estimator training call)",
        "Question_body":"Hi,\n\nI have large image dataset stored in a Sagemaker notebook instance, in the file system. I was hoping to learn how I could access this data from outside of that particular notebook instance. I have done quite a bit of researching but can't seem to find much - I am relatively new to this.\n\nI want to be able to access the data in that notebook in a fast manner as I will be using the data to train an AI model. Is there any recommended way to do this? \n\nI originally uploaded the data within that notebook instance to train a model within that instance in exactly the same file system. Note that it is a reasonably large dataset which I had to do some preprocessing on within Sagemaker. \n\nWhat is the best way to store data when using the Sagemaker estimators from training AI models? \n\nMany thanks \n\nTim",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1638914293851,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1668630486323,
        "Question_score_count":0.0,
        "Question_view_count":1538.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Hi Tim, when you create a sagemaker training job using the estimator, the general best practice is to store your data on S3 and the training job will launch instances as requested by the training job configuration. As now we support fast file mode, which allows faster training job start compared to the file mode (which downloads the data from s3 to the training instance). But when you say you used sagemaker notebook instance to train the model, I assume you were not using SageMaker Training jobs but rather running the notebook (.ipynb) on the SageMaker notebook instance. Please note that as SageMaker is a fully managed service, the notebook instance (also training instances, hosting instances etc.) are launched in the service account, so you will not have directly access to those instance. The SageMaker notebook instance use EBS to store data and the EBS volume is mounted to the \/home\/ec2-user\/SageMaker. Please note that the EBS volume used by a SageMaker notebook instance can only be increased but not decrease. If you want to reduce the EBS volume, you need to create a new notebook instance with a smaller volume and move your data from the previous instance via s3. You will not be able to access that EBS volume from outside of the SageMaker notebook instance. The general best practice is to store large dataset on s3 and only use sample data on the SageMaker notebook instance (reduce the storage). Then use that small amount of sample data to test\/build your code. Then when you are ready to train on the whole dataset, you can launch a SageMaker training job and use the whole dataset stored on s3. Note that, running the training on the whole dataset on a SageMaker notebook instance will require you to use a big instance with enough computing power and also will not be able to perform distributed training with multiple instances. Comparatively, if you run the training job use SageMaker training instances, it gives you more flexibility of choosing the instance type and allow you to run on multiple instances for distributed training. Lastly, once the SageMaker training job is done, all the resources will be terminated which will save cost compared to continue using the big instance with a SageMaker notebook instance. Hope this has helped answer your question",
        "Answer_comment_count":2.0,
        "Question_closed_time":1638917636668,
        "Answer_last_edit_time":1638917636668,
        "Answer_score_count":2.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU3yXAL7d7Sl--kKO3TTZf1g\/how-to-access-file-system-in-sagemaker-notebook-instance-from-outside-of-that-instance-ie-via-python-sagemaker-estimator-training-call",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"access file notebook instanc outsid instanc python estim train larg imag dataset store notebook instanc file hope learn access data outsid particular notebook instanc bit research rel new want abl access data notebook fast manner data train model recommend wai origin upload data notebook instanc train model instanc exactli file note reason larg dataset preprocess best wai store data estim train model thank tim",
        "Question_preprocessed_content":"file instanc outsid instanc larg imag dataset store instanc file hope learn data outsid particular instanc bit research rel new want abl data fast data train model wai upload data instanc train model instanc exactli file note reason larg dataset best wai store data estim train model thank tim",
        "Question_gpt_summary_original":"The user is seeking guidance on how to access a large image dataset stored in a Sagemaker notebook instance from outside of that instance, specifically via Python Sagemaker Estimator training call. The user wants to access the data in a fast manner to train an AI model and is looking for the recommended way to do this. The user also wants to know the best way to store data when using Sagemaker estimators for training AI models.",
        "Question_gpt_summary":"user seek guidanc access larg imag dataset store notebook instanc outsid instanc specif python estim train user want access data fast manner train model look recommend wai user want know best wai store data estim train model"
    },
    {
        "Question_title":"Unable to install Detectron2 Azure ML 3.8",
        "Question_body":"<p>I have created a NC6_SV3 compute  <br \/>\nCreated new conda environment in terminal   <br \/>\nThis command : python -m pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'  <br \/>\nIs giving error :   <br \/>\nERROR: Command errored out with exit status 1: \/anaconda\/envs\/darthgo\/bin\/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-req-build-x6bevf0j\/setup.py'&quot;'&quot;'; <strong>file<\/strong>='&quot;'&quot;'\/tmp\/pip-req-build-x6bevf0j\/setup.py'&quot;'&quot;';f = getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(<strong>file<\/strong>) if os.path.exists(<strong>file<\/strong>) else io.StringIO('&quot;'&quot;'from setuptools import setup; setup()'&quot;'&quot;');code = f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, <strong>file<\/strong>, '&quot;'&quot;'exec'&quot;'&quot;'))' install --record \/tmp\/pip-record-4_jvac6y\/install-record.txt --single-version-externally-managed --compile --install-headers \/anaconda\/envs\/darthgo\/include\/python3.8\/detectron2 Check the logs for full command output.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1624259210607,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/444357\/unable-to-install-detectron2-azure-ml-3-8",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl instal detectron creat comput creat new conda environ termin command python pip instal git http github com facebookresearch detectron git give error error command error exit statu anaconda env darthgo bin python import sy setuptool token sy argv tmp pip req build xbevfj setup file tmp pip req build xbevfj setup getattr token open open file path exist file stringio setuptool import setup setup code read replac close exec compil code file exec instal record tmp pip record jvaci instal record txt singl version extern manag compil instal header anaconda env darthgo includ python detectron check log command output",
        "Question_preprocessed_content":"unabl detectron creat comput creat new conda environ termin python pip give exit statu import sy token import setup setup code file exec check log output",
        "Question_gpt_summary_original":"The user is unable to install Detectron2 Azure ML 3.8 using the command \"python -m pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'\" due to an error with exit status 1. The logs should be checked for the full command output.",
        "Question_gpt_summary":"user unabl instal detectron command python pip instal git http github com facebookresearch detectron git error exit statu log check command output"
    },
    {
        "Question_title":"How to return a Dataframe in Azure ML from a python script",
        "Question_body":"<p>I have the below Python script. And I'm trying to return the new Dataframe created. Unfortunately, I'm getting \"NotImplementedError:\"<\/p>\n\n<p>Please let me know, how to return a Dataframe in Azure ML from a python script<\/p>\n\n<p>Code:<\/p>\n\n<pre><code>def azureml_main(df) :\n\n    therm_patterns,therm_missed_patterns = thermostat_phase(df)\n    th_pat = json.loads(therm_patterns)\n    missed_th_pat = json.loads(therm_missed_patterns)\n\n    light_patterns, light_missed_patterns = light_phase(df)\n    lt_pat = json.loads(light_patterns)\n    missed_lt_pat = json.loads(light_missed_patterns)\n\n    for j in range (0,len(lt_pat)):\n        for i in range (0,len(lt_pat[0]['John'])):\n            th_pat[0]['John'].append(lt_pat[0]['John'][i])\n    for j in range (0,len(lt_pat)):\n        for i in range (0,len(lt_pat[0]['Jane'])):\n            th_pat[0]['Jane'].append(lt_pat[0]['Jane'][i])\n    for j in range (0,len(lt_pat)):\n        for i in range (0,len(lt_pat[0]['Jen'])):\n            th_pat[0]['Jen'].append(lt_pat[0]['Jen'][i])\n\n    for j in range (0,len(missed_lt_pat)):\n        for i in range (0,len(missed_lt_pat[0]['John'])):\n            missed_th_pat[0]['John'].append(missed_lt_pat[0]['John'][i])\n    for j in range (0,len(missed_lt_pat)):\n        for i in range (0,len(missed_lt_pat[0]['Jane'])):\n            missed_th_pat[0]['Jane'].append(missed_lt_pat[0]['Jane'][i])\n    for j in range (0,len(missed_lt_pat)):\n        for i in range (0,len(missed_lt_pat[0]['Jen'])):\n            missed_th_pat[0]['Jen'].append(missed_lt_pat[0]['Jen'][i])\n\n    output = json.dumps(th_pat)\n\n    df = pd.DataFrame.from_dict({k: v[0] for k, v in json.loads(output) \n    [0].items()}, 'index' ).rename_axis('User').reset_index()\n\n\n    return df         \n<\/code><\/pre>\n\n<p>Error:<\/p>\n\n<pre><code>  Error 0085: The following error occurred during script evaluation, please  \n  view the output log for more information:\n\n   ---------- Start of error message from Python interpreter ----------\n   Caught exception while executing function: Traceback (most recent call  \n   last):\n\n       File \"C:\\server\\invokepy.py\", line 211, in batch\n       xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True)\n\n       File \"C:\\server\\XDRReader\\xdrutils.py\", line 54, in DataFrameToRFile\n       xdrwriter.write_attribute_list(attributes)\n\n       File \"C:\\server\\XDRReader\\xdrwriter2.py\", line 155, in   \n       write_attribute_list\n       self.write_object(value)\n\n       File \"C:\\server\\XDRReader\\xdrwriter2.py\", line 215, in write_object\n       write_func(flags, converted, missingIndices)\n\n       File \"C:\\server\\XDRReader\\xdrwriter2.py\", line 185, in write_objects\n       self.write_object(value)\n\n       File \"C:\\server\\XDRReader\\xdrwriter2.py\", line 200, in write_object\n       raise NotImplementedError('Python Bridge conversion table not    \n       implemented for type [{0}]'.format(value.getType()))\n\n       NotImplementedError: Python Bridge conversion table not implemented  \n       for type [&lt;type 'list'&gt;]\n\n       Process returned with non-zero exit code 1\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1484124401607,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1484584933627,
        "Question_score_count":3.0,
        "Question_view_count":1101.0,
        "Poster_created_time":1479194627132,
        "Poster_location":null,
        "Poster_reputation_count":2713.0,
        "Poster_view_count":358.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41586275",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"return datafram python script python script try return new datafram creat unfortun get notimplementederror let know return datafram python script code def main therm pattern therm miss pattern thermostat phase pat json load therm pattern miss pat json load therm miss pattern light pattern light miss pattern light phase pat json load light pattern miss pat json load light miss pattern rang len pat rang len pat john pat john append pat john rang len pat rang len pat jane pat jane append pat jane rang len pat rang len pat jen pat jen append pat jen rang len miss pat rang len miss pat john miss pat john append miss pat john rang len miss pat rang len miss pat jane miss pat jane append miss pat jane rang len miss pat rang len miss pat jen miss pat jen append miss pat jen output json dump pat datafram dict json load output item index renam axi user reset index return error error follow error occur script evalu view output log inform start error messag python interpret caught except execut function traceback recent file server invokepi line batch xdrutil xdrutil dataframetorfil outlist outfil true file server xdrreader xdrutil line dataframetorfil xdrwriter write attribut list attribut file server xdrreader xdrwriter line write attribut list self write object valu file server xdrreader xdrwriter line write object write func flag convert missingindic file server xdrreader xdrwriter line write object self write object valu file server xdrreader xdrwriter line write object rais notimplementederror python bridg convers tabl implement type format valu gettyp notimplementederror python bridg convers tabl implement type process return non zero exit code",
        "Question_preprocessed_content":"return datafram python script python script try return new datafram creat unfortun let know return datafram python script code",
        "Question_gpt_summary_original":"The user is trying to return a new Dataframe created in a Python script in Azure ML, but is encountering a \"NotImplementedError\" and is unable to do so. The error message suggests that the Python Bridge conversion table is not implemented for the type \"list\".",
        "Question_gpt_summary":"user try return new datafram creat python script encount notimplementederror unabl error messag suggest python bridg convers tabl implement type list"
    },
    {
        "Question_title":"Run a Vertex AI model locally",
        "Question_body":"<p>Using the Vertex AI product at GCP training was very easy, I uploaded a data set and it returned a model which is saved in a gcp bucket, I downloaded the files and the tree has these files<\/p>\n<pre><code>\u251c\u2500\u2500 environment.json\n\u251c\u2500\u2500 feature_attributions.yaml\n\u251c\u2500\u2500 final_model_structure.pb\n\u251c\u2500\u2500 instance.yaml\n\u251c\u2500\u2500 predict\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 001\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 assets\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 PVC_vocab\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 assets.extra\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 tf_serving_warmup_requests\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 saved_model.pb\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 variables\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 variables.data-00000-of-00001\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 variables.index\n\u251c\u2500\u2500 prediction_schema.yaml\n\u251c\u2500\u2500 tables_server_metadata.pb\n\u2514\u2500\u2500 transformations.pb\n<\/code><\/pre>\n<p>I would like to serve this model locally from a dockerized python application, but I don't know enough TF to do this and I am very confused about which <code>.pb<\/code> file is the actual one that has the neural network I need.<\/p>\n<p>Thanks for any tips.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_created_time":1649554815260,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":261.0,
        "Poster_created_time":1483057875592,
        "Poster_location":"St. Louis, MO, USA",
        "Poster_reputation_count":710.0,
        "Poster_view_count":175.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71813169",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run model local product gcp train easi upload data set return model save gcp bucket download file tree file environ json featur attribut yaml final model structur instanc yaml predict asset pvc vocab asset extra serv warmup request save model variabl variabl data variabl index predict schema yaml tabl server metadata transform like serv model local docker python applic know confus file actual neural network need thank tip",
        "Question_preprocessed_content":"run model product gcp train easi upload data set return model save gcp bucket download file file like serv model docker python know confus file actual neural network thank tip",
        "Question_gpt_summary_original":"The user has successfully trained a model using Vertex AI product at GCP and downloaded the model files from a GCP bucket. However, the user is facing challenges in serving the model locally from a dockerized python application due to lack of knowledge in TensorFlow and confusion about which .pb file contains the required neural network. The user is seeking tips to overcome this challenge.",
        "Question_gpt_summary":"user successfulli train model product gcp download model file gcp bucket user face challeng serv model local docker python applic lack knowledg tensorflow confus file contain requir neural network user seek tip overcom challeng"
    },
    {
        "Question_title":"How to implement customized AbstractADLSDatastore in Azure ML SDK",
        "Question_body":"<p>Hi AzureML team,   <\/p>\n<p>I'm from Linkedin. We are exploring the option of enabling AzureML to training models on our production data. Also we are using ADLS gen2, we have our customized authentication logic to access the data. We probability need to implement customized ADLSDatastore so that training applications can have access to the data. I'm is there a way to do such customization and contribute the AzureML Data SDK?   <\/p>\n<p>Thanks a lot!<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1.0,
        "Question_created_time":1650999035973,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/827239\/how-to-implement-customized-abstractadlsdatastore",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"implement custom abstractadlsdatastor sdk team linkedin explor option enabl train model product data adl gen custom authent logic access data probabl need implement custom adlsdatastor train applic access data wai custom contribut data sdk thank lot",
        "Question_preprocessed_content":"implement custom abstractadlsdatastor sdk team linkedin explor option enabl train model product data adl gen custom authent logic data probabl implement custom adlsdatastor train data wai custom contribut data sdk thank lot",
        "Question_gpt_summary_original":"The user is seeking guidance on how to implement a customized AbstractADLSDatastore in Azure ML SDK to enable training models on their production data, which is stored in ADLS gen2 and requires customized authentication logic to access. They are also interested in contributing to the AzureML Data SDK.",
        "Question_gpt_summary":"user seek guidanc implement custom abstractadlsdatastor sdk enabl train model product data store adl gen requir custom authent logic access interest contribut data sdk"
    },
    {
        "Question_title":"Disable Azure Datastore download message",
        "Question_body":"<p>Is there any way to disable the warning presented whenever a file is loaded for the first time in Azure ML using datastores?<\/p>\n<pre><code>Downloaded path: \/tmp\/tmp5dto5vq4\/path\/to\/file.txt is different from target path: \/tmp\/tmp5dto5vq4\/path\/to\/file.txt\n<\/code><\/pre>\n<p>I connect to the Datastore following the azure tutorial:<\/p>\n<pre><code>ws = Workspace.from_config()\nmounted_path = tempfile.mkdtemp()\ndataset = Dataset.get_by_name(workspace = ws, name = 'name')\nmount_context = dataset.mount(mounted_path)\n\nmount_context.start()\n\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1644884590780,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":106.0,
        "Poster_created_time":1490704811283,
        "Poster_location":"K\u00f8benhavn, Danmark",
        "Poster_reputation_count":94.0,
        "Poster_view_count":22.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71119807",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"disabl azur datastor download messag wai disabl warn present file load time datastor download path tmp tmpdtovq path file txt differ target path tmp tmpdtovq path file txt connect datastor follow azur tutori workspac config mount path tempfil mkdtemp dataset dataset workspac mount context dataset mount mount path mount context start",
        "Question_preprocessed_content":"disabl azur datastor download wai disabl warn present file load time datastor datastor azur tutori",
        "Question_gpt_summary_original":"The user is encountering a warning message when loading a file for the first time in Azure ML using datastores. They are looking for a way to disable this warning message. The user is following the Azure tutorial to connect to the Datastore.",
        "Question_gpt_summary":"user encount warn messag load file time datastor look wai disabl warn messag user follow azur tutori connect datastor"
    },
    {
        "Question_title":"trains with grid search",
        "Question_body":"<p>I would like to test <a href=\"https:\/\/github.com\/allegroai\/trains\" rel=\"nofollow noreferrer\">trains<\/a> usage during grid search and it not clear how to do so.<\/p>\n\n<pre><code>from trains import Task \nTask.init(project_name=\"project name\", task_name='name')\n<\/code><\/pre>\n\n<p>creates an experiment in the demo server and logs all but you can't call init twice no matter the 'task_name' and <\/p>\n\n<pre><code>from trains import Task \nTask.create(project_name=\"project name\", task_name='name')\n<\/code><\/pre>\n\n<p>can be called with different 'task_name' but thus not log any data into the server and creates only 'Draft'.<\/p>\n\n<p>here is a sample code:<\/p>\n\n<pre><code> epochs=[160,300]\n for epoch in epochs:\n    model = define_model_run(epoch)\n    model.fit(x_train,y_train)\n    score = model.score(...)\n<\/code><\/pre>\n\n<p>my final try was:<\/p>\n\n<pre><code> epochs=[160,300]\n task=Task.init(project_name=\"demo\", task_name='search')\n for epoch in epochs:\n    task.create(project_name=\"demo\", task_name=f'search_{epoch}')\n    model = define_model_run(epoch)\n    model.fit(x_train,y_train)\n    score = model.score(...)\n<\/code><\/pre>\n\n<p>which logs all information under the experiments tab and none under the 'Draft'.\nI tried the last two hour the read the few documentations provided and reading the source code, but no luck.<\/p>\n\n<p>any help? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1566218806593,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1609778640296,
        "Question_score_count":1.0,
        "Question_view_count":121.0,
        "Poster_created_time":1416942229380,
        "Poster_location":null,
        "Poster_reputation_count":161.0,
        "Poster_view_count":58.0,
        "Answer_body":"<p>Declaimer: I'm a member of TRAINS team<\/p>\n\n<p>Yes, that's exactly the answer.\nThe idea is that you always have one main Task, in order to create a new one you need to close the running Task, and re-initialize with a new name.\nKudos on solving it so quickly :)<\/p>\n\n<p>BTW: You can see examples <a href=\"https:\/\/stackoverflow.com\/q\/56744397\/11682840\">here<\/a>\/<a href=\"https:\/\/github.com\/allegroai\/trains\/blob\/master\/docs\/faq.md#can-i-create-a-graph-comparing-hyper-parameters-vs-model-accuracy-\" rel=\"nofollow noreferrer\">and here<\/a>, showing how to send accuracy logs so it is easier to compare the experiments, especially when running hyper-parameter search.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1566240704540,
        "Answer_last_edit_time":1566242122212,
        "Answer_score_count":0.0,
        "Answerer_created_time":1561143508792,
        "Answerer_location":"TRAINS Station",
        "Answerer_reputation_count":489.0,
        "Answerer_view_count":60.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57557070",
        "Tool":"ClearML",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train grid search like test train usag grid search clear train import task task init project project task creat experi demo server log init twice matter task train import task task creat project project task call differ task log data server creat draft sampl code epoch epoch epoch model defin model run epoch model fit train train score model score final try epoch task task init project demo task search epoch epoch task creat project demo task search epoch model defin model run epoch model fit train train score model score log inform experi tab draft tri hour read document provid read sourc code luck help",
        "Question_preprocessed_content":"train grid search like test train usag grid search clear creat experi demo server log init twice log data server creat draft sampl code final try log inform experi tab draft tri hour read document provid read sourc code luck help",
        "Question_gpt_summary_original":"The user is trying to use the Trains library for grid search but is having trouble logging data into the server. They have tried different methods, including calling the 'init' and 'create' functions with different task names, but have not been successful. They are seeking help to resolve the issue.",
        "Question_gpt_summary":"user try us train librari grid search have troubl log data server tri differ method includ call init creat function differ task name success seek help resolv issu"
    },
    {
        "Question_title":"Experiments disappear when adding --backend-store-uri",
        "Question_body":"<p>I have an EC2 instance running a mlflow server using the following command:<\/p>\n<pre><code>mlflow server -h 0.0.0.0 --default-artifact-root s3:\/\/xxxx\n<\/code><\/pre>\n<p>After running multiple experiments, I was trying to register the best one. However, when trying to register or accessing the tab &quot;Models&quot;, I get the following error:<\/p>\n<blockquote>\n<p>INVALID_PARAMETER_VALUE: Model registry functionality is unavailable; got unsupported URI '.\/mlruns' for model registry data storage. Supported URI schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. See <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage<\/a> for how to run an MLflow server against one of the supported backend storage locations.<\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/63255631\/mlflow-invalid-parameter-value-unsupported-uri-mlruns-for-model-registry-s\">This SO answer<\/a> suggested adding a <code>backend-store-uri<\/code>:<\/p>\n<pre><code>mlflow server -h 0.0.0.0 --default-artifact-root --backend-store-uri sqlite:\/\/\/mlflow.db\n<\/code><\/pre>\n<p>That solved the above issue, however, now all experiments are gone. The Experiments tab is blank. Is there a way to add a <code>backend-store-uri<\/code> after running multiple experiments while keeping all of them?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1651906154493,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":208.0,
        "Poster_created_time":1394900987340,
        "Poster_location":"Curitiba, State of Paran\u00e1, Brazil",
        "Poster_reputation_count":1490.0,
        "Poster_view_count":346.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72150148",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"experi disappear ad backend store uri instanc run server follow command server default artifact root xxxx run multipl experi try regist best try regist access tab model follow error invalid paramet valu model registri function unavail got unsupport uri mlrun model registri data storag support uri scheme postgresql mysql sqlite mssql http www org doc latest track html storag run server support backend storag locat answer suggest ad backend store uri server default artifact root backend store uri sqlite solv issu experi gone experi tab blank wai add backend store uri run multipl experi keep",
        "Question_preprocessed_content":"experi instanc server multipl experi try regist best try regist tab model model registri function unavail got uri model registri data storag uri scheme run server backend storag locat answer solv experi gone experi tab blank wai multipl experi",
        "Question_gpt_summary_original":"The user encountered an issue with MLflow server where the Model registry functionality was unavailable due to an unsupported URI. They followed a suggestion to add a backend-store-uri which solved the issue but caused all experiments to disappear. The user is seeking a solution to add a backend-store-uri without losing their experiments.",
        "Question_gpt_summary":"user encount issu server model registri function unavail unsupport uri follow suggest add backend store uri solv issu caus experi disappear user seek solut add backend store uri lose experi"
    },
    {
        "Question_title":"consolidatedAnnotation attribute is null error from AWS SageMaker Ground Truth",
        "Question_body":"<p>I have used AWS SageMaker Ground Truth to annotate an image using Mechanical Turk.<\/p>\n\n<p>The labelling job failed with the following error in the output manifest:<\/p>\n\n<pre><code>{\"source-ref\":\"&lt;MYIMAGE&gt;\",\"Test1-ref-metadata\":{\"retry-count\":1,\"failure-reason\":\"Error in Annotation Consolidation Response :  consolidatedAnnotation attribute is null\",\"human-annotated\":\"true\"}}\n<\/code><\/pre>\n\n<p>Does anyone have an idea if this is a bug or if I made a mistake?<\/p>\n\n<p>Thanks\nChris<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1543547061310,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":328.0,
        "Poster_created_time":1270006662236,
        "Poster_location":"Perth, Australia",
        "Poster_reputation_count":1094.0,
        "Poster_view_count":91.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53550636",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"consolidatedannot attribut null error ground truth ground truth annot imag mechan turk label job fail follow error output manifest sourc ref test ref metadata retri count failur reason error annot consolid respons consolidatedannot attribut null human annot true idea bug mistak thank chri",
        "Question_preprocessed_content":"ground truth ground truth imag mechan turk job fail output manifest idea bug mistak thank chri",
        "Question_gpt_summary_original":"The user encountered an error while using AWS SageMaker Ground Truth to annotate an image using Mechanical Turk. The error message in the output manifest stated that the \"consolidatedAnnotation\" attribute was null, causing the labeling job to fail. The user is seeking help to determine if this is a bug or a mistake on their part.",
        "Question_gpt_summary":"user encount error ground truth annot imag mechan turk error messag output manifest state consolidatedannot attribut null caus label job fail user seek help determin bug mistak"
    },
    {
        "Question_title":"Azure machine learning",
        "Question_body":"<p>Is there any way to integrate MS Dynamics Customer Insights with Azure Machine Learning (designer)?I know there is an integration between CI and Azure Machine Learning studio (classic). Please help to integrate these two services.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1656618921300,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello @Yasuo-9899     <\/p>\n<p>Thanks for reaching out to us for this question. Are you looking for this document? <a href=\"https:\/\/learn.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments\">https:\/\/learn.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments<\/a>    <\/p>\n<p>I have found one pic which is described the structure well:    <br \/>\n<img src=\"https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/raw\/main\/images\/workshop-playbook\/media\/image2.png\" alt=\"image2.png\" \/>    <\/p>\n<p>And also a repo you may want to refer to: <a href=\"https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md\">https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md<\/a>    <\/p>\n<p>Please let us know more details you are interested in so that we can help. Thanks.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1656632594976,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/909965\/azure-machine-learning",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":" wai integr dynam custom insight design know integr studio classic help integr servic",
        "Question_preprocessed_content":" wai integr dynam custom insight know integr studio help integr servic",
        "Question_gpt_summary_original":"The user is seeking help to integrate MS Dynamics Customer Insights with Azure Machine Learning (designer) as there is already an integration between CI and Azure Machine Learning studio (classic).",
        "Question_gpt_summary":"user seek help integr dynam custom insight design integr studio classic"
    },
    {
        "Question_title":"Python support for Azure ML -- speed issue",
        "Question_body":"<p>We are trying to create an Azure ML web-service that will receive a (.csv) data file, do some processing, and return two similar files. The Python support recently added to the azure ML platform was very helpful and we were able to successfully port our code, run it in experiment mode and publish the web-service.<\/p>\n\n<p>Using the \"batch processing\" API, we are now able to direct a file from blob-storage to the service and get the desired output. However, run-time for small files (a few KB) is significantly slower than on a local machine, and more importantly, the process seems to never return for slightly larger input data files (40MB). Processing time on my local machine for the same file is under 1 minute. <\/p>\n\n<p>My question is if you can see anything we are doing wrong, or if there is a way to get this to speed up. Here is the DAG representation of the experiment:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/MalhQ.png\" alt=\"The DAG representation of the experiment\"><\/p>\n\n<p>Is this the way the experiment should be set up? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1425837068693,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1425890468080,
        "Question_score_count":0.0,
        "Question_view_count":491.0,
        "Poster_created_time":1419868247680,
        "Poster_location":null,
        "Poster_reputation_count":877.0,
        "Poster_view_count":55.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/28929813",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"python support speed issu try creat web servic receiv csv data file process return similar file python support recent ad platform help abl successfulli port code run experi mode publish web servic batch process api abl direct file blob storag servic desir output run time small file significantli slower local machin importantli process return slightli larger input data file process time local machin file minut question wrong wai speed dag represent experi wai experi set",
        "Question_preprocessed_content":"python try creat receiv data file return similar file python recent platform help abl port code run experi mode publish batch api abl direct file servic desir output file significantli slower local machin importantli return slightli larger input data file time local machin file minut question wrong wai dag represent experi wai experi set",
        "Question_gpt_summary_original":"The user is facing speed issues while using Python support for Azure ML to create a web-service that processes CSV files and returns two similar files. While the Python support was helpful in porting the code and running it in experiment mode, the run-time for small files is slower than on a local machine, and the process never returns for slightly larger input data files. The user is seeking advice on whether they are doing anything wrong or if there is a way to speed up the process. The user has also shared the DAG representation of the experiment and is asking if it is set up correctly.",
        "Question_gpt_summary":"user face speed issu python support creat web servic process csv file return similar file python support help port code run experi mode run time small file slower local machin process return slightli larger input data file user seek advic wrong wai speed process user share dag represent experi ask set correctli"
    },
    {
        "Question_title":"Deploying ml model using azureml and mlflow",
        "Question_body":"<p>I'm new to databricks and deploying models using mlflow and azureml, I'm trying to deploy my model but haven't found a lot of documentation or examples.<\/p>\n\n<p>I have my model which I save using:<\/p>\n\n<pre><code>mlflow.sklearn.save_model(model, model_path, \n                          conda_env=conda_env_file_name)\n<\/code><\/pre>\n\n<p>I created the workspace and the aci webservice, the next step is to create the image and the webservice:<\/p>\n\n<pre><code># image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n                                                    runtime = \"python\", \n                                                    conda_file = conda_env_file_name)\n\n# Webservice creation\nmyservice = AciWebservice.deploy_from_model(\n  workspace=ws, \n  name=\"service\",\n  deployment_config = aciconfig,\n  models = [model_path],\n  image_config = myimage_config)\n\nmyservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n\n<p>However when I try to create the webservice I receive an error and looking at the log:<\/p>\n\n<pre><code>mlflow.exceptions.MlflowException: Could not find an \"MLmodel\" configuration file at \"mode_path\"\n<\/code><\/pre>\n\n<p>My score file init function is like this:<\/p>\n\n<pre><code>def init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('model_path')\n    model = joblib.load(model_path)\n<\/code><\/pre>\n\n<p>It seems like it cannot find the path to the model. I'm not sure in the moment the image is saved, the model is not saved in it and thus it cannot be found by sklearn.load_model. I'm quite confused cause I've seen that a model can be deployed using mlflow or azureml. I think the problems is that mlflow.save_model does not register the model and then there's no path. Have someone been able to solve this? What is the best way to deploy a model?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1559175361693,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1559831718176,
        "Question_score_count":3.0,
        "Question_view_count":933.0,
        "Poster_created_time":1461539594160,
        "Poster_location":null,
        "Poster_reputation_count":737.0,
        "Poster_view_count":116.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56370096",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi model new databrick deploi model try deploi model haven lot document exampl model save sklearn save model model model path conda env conda env file creat workspac aci webservic step creat imag webservic imag creation core imag import containerimag myimag config containerimag imag configur execut script driver file runtim python conda file conda env file webservic creation myservic aciwebservic deploi model workspac servic deploy config aciconfig model model path imag config myimag config myservic wait deploy output true try creat webservic receiv error look log except except mlmodel configur file mode path score file init function like def init global model retreiv path model file model model path model model path model path model joblib load model path like path model sure moment imag save model save sklearn load model confus caus seen model deploi think problem save model regist model path abl solv best wai deploi model",
        "Question_preprocessed_content":"deploi model new databrick deploi model try deploi model haven lot document exampl model save creat workspac aci webservic step creat imag webservic try creat webservic receiv log score file init function like like path model sure moment imag save model save confus caus model deploi think problem regist model path abl solv best wai deploi model",
        "Question_gpt_summary_original":"The user is new to deploying models using mlflow and azureml and is encountering an error while creating a webservice. The error message suggests that the \"MLmodel\" configuration file cannot be found at the specified model path. The user suspects that the model is not saved in the image and thus cannot be found by sklearn.load_model. The user is seeking advice on the best way to deploy a model and if anyone has been able to solve this issue.",
        "Question_gpt_summary":"user new deploi model encount error creat webservic error messag suggest mlmodel configur file specifi model path user suspect model save imag sklearn load model user seek advic best wai deploi model abl solv issu"
    },
    {
        "Question_title":"Stored artifact is not h5 file",
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m using tensorflow with the python callback. The callback stores several files automatically for each run:<\/p>\n<ul>\n<li>saved_model.pb<\/li>\n<li>keras_metadata.pb<\/li>\n<\/ul>\n<p>I would like to automatically store the weights h5 file as well. Is there an option for this? Do I have to do it manually?<br>\nNote that I can find best-model.h5 in the wand folder of each run, but for some reason it is not uploaded to the server.<\/p>\n<p>Thank you,<br>\nArnaud<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1666706847698,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":565.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/stored-artifact-is-not-h5-file\/3322",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"store artifact file tensorflow python callback callback store file automat run save model kera metadata like automat store weight file option manual note best model wand folder run reason upload server thank arnaud",
        "Question_preprocessed_content":"store artifact file tensorflow python store file run like store weight file option note wand folder run reason upload server thank arnaud",
        "Question_gpt_summary_original":"The user is facing an issue with storing the weights h5 file automatically while using tensorflow with the python callback. The callback is storing saved_model.pb and keras_metadata.pb files automatically for each run, but the user is unable to find the best-model.h5 file in the server even though it is present in the wand folder of each run.",
        "Question_gpt_summary":"user face issu store weight file automat tensorflow python callback callback store save model kera metadata file automat run user unabl best model file server present wand folder run"
    },
    {
        "Question_title":"Switching from Keras to tf.keras spams my screen with #010",
        "Question_body":"<p>I've built a simple Keras model for experimentation within Amazon SageMaker. I'm using Python 3.5 TensorFlow 1.12.0. Recently I switched my model to use TensorFlow.keras, but doing so has resulted in the printing of <code>#010<\/code> repeatedly followed by <code>#015<\/code>,  while downloading image net weights and displaying batch accuracy during the fit call.<\/p>\n\n<p>For example, with verbose=1 in <code>model.fit<\/code>:<\/p>\n\n<blockquote>\n  <p>Epoch 1\/1<\/p>\n  \n  <h1>015   1\/1563 [..............................] - ETA: 5:50:36 - loss: 2.2798 - acc: 0.1875#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015<\/h1>\n  \n  <p>3\/1563 [..............................] - ETA: 1:57:18 - loss: 2.3002\n  - acc: 0.1146#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015\n  5\/1563 [..............................] - ETA: 1:10:36 - loss: 2.3088\n  - acc: 0.1062#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010<\/p>\n<\/blockquote>\n\n<p>Does anyone know why this might be happening or how I can prevent this? Reproducing with a minimal example may require running through SageMaker, but the code I switched from Keras to tf.keras is from <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/tree\/master\/hyperparameter_tuning\/keras_bring_your_own\" rel=\"nofollow noreferrer\">this example<\/a>, and specifically the <code>trainer\/start.py<\/code> file:<\/p>\n\n<pre><code># Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http:\/\/aws.amazon.com\/apache2.0\/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nimport os\nimport numpy as np\n\nfrom trainer.environment import create_trainer_environment\n\nNUM_CLASSES = 10\nEPOCHS = 10\nNUM_PREDICTIONS = 20\nMODEL_NAME = 'keras_cifar10_trained_model.h5'\n\n# the trainer environment contains useful information about\nenv = create_trainer_environment()\nprint('creating SageMaker trainer environment:\\n%s' % str(env))\n\n# getting the hyperparameters\nbatch_size = env.hyperparameters.get('batch_size', object_type=int)\ndata_augmentation = env.hyperparameters.get('data_augmentation', default=True, object_type=bool)\nlearning_rate = env.hyperparameters.get('learning_rate', default=.0001, object_type=float)\nwidth_shift_range = env.hyperparameters.get('width_shift_range', object_type=float)\nheight_shift_range = env.hyperparameters.get('height_shift_range', object_type=float)\nEPOCHS = env.hyperparameters.get('epochs', default=10, object_type=int)\n\n# reading data from train and test channels\ntrain_data = np.load(os.path.join(env.channel_dirs['train'], 'cifar-10-npz-compressed.npz'))\n(x_train, y_train) = train_data['x'], train_data['y']\n\ntest_data = np.load(os.path.join(env.channel_dirs['test'], 'cifar-10-npz-compressed.npz'))\n(x_test, y_test) = test_data['x'], test_data['y']\n\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(NUM_CLASSES))\nmodel.add(Activation('softmax'))\n\n# initiate RMSprop optimizer\nopt = keras.optimizers.rmsprop(lr=learning_rate, decay=1e-6)\n\n# Let's train the model using RMSprop\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255\nx_test \/= 255\n\nif not data_augmentation:\n    print('Not using data augmentation.')\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=EPOCHS, validation_data=(x_test, y_test), shuffle=True)\nelse:\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and real time data augmentation:\n    data_generator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=width_shift_range,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=height_shift_range,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    data_generator.fit(x_train)\n\n    # Fit the model on the batches generated by data_generator.flow().\n    data_generator_flow = data_generator.flow(x_train, y_train, batch_size=batch_size)\n    model.fit_generator(data_generator_flow, epochs=EPOCHS, validation_data=(x_test, y_test), workers=4)\n\n# Save model and weights\nmodel_path = os.path.join(env.model_dir, MODEL_NAME)\nmodel.save(model_path)\nprint('Saved trained model at %s ' % model_path)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1544642065947,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":305.0,
        "Poster_created_time":1361339272692,
        "Poster_location":"NYC",
        "Poster_reputation_count":6281.0,
        "Poster_view_count":958.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53749877",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"switch kera kera spam screen built simpl kera model experiment python tensorflow recent switch model us tensorflow kera result print repeatedli follow download imag net weight displai batch accuraci fit exampl verbos model fit epoch eta loss acc eta loss acc eta loss acc know happen prevent reproduc minim exampl requir run code switch kera kera exampl specif trainer start file copyright amazon com affili right reserv licens apach licens version licens us file complianc licens copi licens locat http aw amazon com apach licens file accompani file file distribut basi warranti condit kind express impli licens specif languag govern permiss limit licens futur import absolut import futur import print function import kera kera preprocess imag import imagedatagener kera model import sequenti kera layer import dens dropout activ flatten kera layer import convd maxpoolingd import import numpi trainer environ import creat trainer environ num class epoch num predict model kera cifar train model trainer environ contain us inform env creat trainer environ print creat trainer environ str env get hyperparamet batch size env hyperparamet batch size object type int data augment env hyperparamet data augment default true object type bool learn rate env hyperparamet learn rate default object type float width shift rang env hyperparamet width shift rang object type float height shift rang env hyperparamet height shift rang object type float epoch env hyperparamet epoch default object type int read data train test channel train data load path join env channel dir train cifar npz compress npz train train train data train data test data load path join env channel dir test cifar npz compress npz test test test data test data model sequenti model add convd pad input shape train shape model add activ relu model add convd model add activ relu model add maxpoolingd pool size model add dropout model add convd pad model add activ relu model add convd model add activ relu model add maxpoolingd pool size model add dropout model add flatten model add dens model add activ relu model add dropout model add dens num class model add activ softmax initi rmsprop optim opt kera optim rmsprop learn rate decai let train model rmsprop model compil loss categor crossentropi optim opt metric accuraci train train astyp float test test astyp float train test data augment print data augment model fit train train batch size batch size epoch epoch valid data test test shuffl true print real time data augment preprocess real time data augment data gener imagedatagener featurewis center fals set input mean dataset samplewis center fals set sampl mean featurewis std normal fals divid input std dataset samplewis std normal fals divid input std zca whiten fals appli zca whiten rotat rang randomli rotat imag rang degre width shift rang width shift rang randomli shift imag horizont fraction total width height shift rang height shift rang randomli shift imag vertic fraction total height horizont flip true randomli flip imag vertic flip fals randomli flip imag comput quantiti requir featur wise normal std mean princip compon zca whiten appli data gener fit train fit model batch gener data gener flow data gener flow data gener flow train train batch size batch size model fit gener data gener flow epoch epoch valid data test test worker save model weight model path path join env model dir model model save model path print save train model model path score train model score model evalu test test verbos print test loss score print test accuraci score",
        "Question_preprocessed_content":"switch kera spam built simpl kera model experiment python tensorflow recent switch model us result print repeatedli download imag net weight displai batch fit exampl verbos epoch eta eta eta know prevent reproduc minim exampl requir code switch kera exampl file",
        "Question_gpt_summary_original":"The user has switched from Keras to TensorFlow.keras and is encountering an issue where the screen is being spammed with #010 and #015 while downloading image net weights and displaying batch accuracy during the fit call. The user is seeking help to understand why this is happening and how to prevent it.",
        "Question_gpt_summary":"user switch kera tensorflow kera encount issu screen spam download imag net weight displai batch accuraci fit user seek help understand happen prevent"
    },
    {
        "Question_title":"Properly return a label in post-annotation lambda for AWS SageMaker Ground Truth custom labeling job",
        "Question_body":"<p>I'm working on a SageMaker labeling job with custom datatypes. For some reason though, I'm not getting the correct label in the AWS web console. It should have the selected label which is &quot;Native&quot;, but instead, I'm getting the <a href=\"https:\/\/github.com\/aws-samples\/aws-sagemaker-ground-truth-recipe\/blob\/master\/aws_sagemaker_ground_truth_sample_lambda\/annotation_consolidation_lambda.py#L65\" rel=\"nofollow noreferrer\"><code>&lt;labelattributename&gt;<\/code><\/a> which is &quot;new-test-14&quot;.<\/p>\n<p>After Ground Truth runs the post-annotation lambda, it seems to modify the metadata before returning a data object. The data object it returns doesn't contain a class-name key inside the metadata attribute, even when I hard-code the lambda to return an object that contains it.<\/p>\n<p>My manifest file looks like this:<\/p>\n<pre><code>{&quot;source-ref&quot; : &quot;s3:\/\/&lt;file-name&gt;&quot;, &quot;text&quot; : &quot;Hello world&quot;}\n{&quot;source-ref&quot; : &quot;s3:\/\/&quot;&lt;file-name&gt;&quot;, &quot;text&quot; : &quot;Hello world&quot;}\n<\/code><\/pre>\n<p>And the worker response looks like this:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{&quot;answers&quot;:[{&quot;acceptanceTime&quot;:&quot;2021-05-18T16:08:29.473Z&quot;,&quot;answerContent&quot;:{&quot;new-test-14&quot;:{&quot;label&quot;:&quot;Native&quot;}},&quot;submissionTime&quot;:&quot;2021-05-18T16:09:15.960Z&quot;,&quot;timeSpentInSeconds&quot;:46.487,&quot;workerId&quot;:&quot;private.us-east-1.ea05a03fcd679cbb&quot;,&quot;workerMetadata&quot;:{&quot;identityData&quot;:{&quot;identityProviderType&quot;:&quot;Cognito&quot;,&quot;issuer&quot;:&quot;https:\/\/cognito-idp.us-east-1.amazonaws.com\/us-east-1_XPxQ9txEq&quot;,&quot;sub&quot;:&quot;edc59ce1-e09d-4551-9e0d-a240465ea14a&quot;}}}]}\n<\/code><\/pre>\n<p>That worker response gets processed by my post-annotation lambda which is modeled after <a href=\"https:\/\/github.com\/aws-samples\/aws-sagemaker-ground-truth-recipe\/blob\/master\/aws_sagemaker_ground_truth_sample_lambda\/annotation_consolidation_lambda.py\" rel=\"nofollow noreferrer\">this aws sample ground truth recipe<\/a>. Here's my code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import json\nimport sys\nimport boto3\nfrom datetime import datetime\n\n\n\ndef lambda_handler(event, context):\n\n\n    # Event received\n    print(&quot;Received event: &quot; + json.dumps(event, indent=2))\n\n    labeling_job_arn = event[&quot;labelingJobArn&quot;]\n    label_attribute_name = event[&quot;labelAttributeName&quot;]\n\n    label_categories = None\n    if &quot;label_categories&quot; in event:\n        label_categories = event[&quot;labelCategories&quot;]\n        print(&quot; Label Categories are : &quot; + label_categories)\n\n    payload = event[&quot;payload&quot;]\n    role_arn = event[&quot;roleArn&quot;]\n\n    output_config = None # Output s3 location. You can choose to write your annotation to this location\n    if &quot;outputConfig&quot; in event:\n        output_config = event[&quot;outputConfig&quot;]\n\n    # If you specified a KMS key in your labeling job, you can use the key to write\n    # consolidated_output to s3 location specified in outputConfig.\n    # kms_key_id = None\n    # if &quot;kmsKeyId&quot; in event:\n    #     kms_key_id = event[&quot;kmsKeyId&quot;]\n\n    # # Create s3 client object\n    # s3_client = S3Client(role_arn, kms_key_id)\n    s3_client = boto3.client('s3')\n\n    # Perform consolidation\n    return do_consolidation(labeling_job_arn, payload, label_attribute_name, s3_client)\n\n\ndef do_consolidation(labeling_job_arn, payload, label_attribute_name, s3_client):\n    &quot;&quot;&quot;\n        Core Logic for consolidation\n\n    :param labeling_job_arn: labeling job ARN\n    :param payload:  payload data for consolidation\n    :param label_attribute_name: identifier for labels in output JSON\n    :param s3_client: S3 helper class\n    :return: output JSON string\n    &quot;&quot;&quot;\n\n    # Extract payload data\n    if &quot;s3Uri&quot; in payload:\n        s3_ref = payload[&quot;s3Uri&quot;]\n        payload_bucket, payload_key = s3_ref.split('\/',2)[-1].split('\/',1)\n        payload = json.loads(s3_client.get_object(Bucket=payload_bucket, Key=payload_key)['Body'].read())\n#         print(payload)\n\n    # Payload data contains a list of data objects.\n    # Iterate over it to consolidate annotations for individual data object.\n    consolidated_output = []\n    success_count = 0  # Number of data objects that were successfully consolidated\n    failure_count = 0  # Number of data objects that failed in consolidation\n\n    for p in range(len(payload)):\n        response = None\n\n        dataset_object_id = payload[p]['datasetObjectId']\n        log_prefix = &quot;[{}] data object id [{}] :&quot;.format(labeling_job_arn, dataset_object_id)\n        print(&quot;{} Consolidating annotations BEGIN &quot;.format(log_prefix))\n\n        annotations = payload[p]['annotations']\n#             print(&quot;{} Received Annotations from all workers {}&quot;.format(log_prefix, annotations))\n\n        # Iterate over annotations. Log all annotation to your CloudWatch logs\n        annotationsFromAllWorkers = []\n        for i in range(len(annotations)):\n            worker_id = annotations[i][&quot;workerId&quot;]\n            anotation_data = annotations[i][&quot;annotationData&quot;]\n            annotation_content = anotation_data[&quot;content&quot;]\n            annotation_content_json = json.loads(annotation_content)\n            annotation_job = annotation_content_json[&quot;new_test&quot;]\n            annotation_label = annotation_job[&quot;label&quot;]\n            consolidated_annotation= {\n                &quot;workerId&quot;: worker_id,\n                &quot;annotationData&quot;: {\n                    &quot;content&quot;: {\n                        &quot;annotatedResult&quot;: {\n                            &quot;instances&quot;: [{&quot;label&quot;:annotation_label }]    \n                        }\n                    }\n                }\n            }\n            annotationsFromAllWorkers.append(consolidated_annotation)\n\n        consolidated_annotation = {&quot;annotationsFromAllWorkers&quot;: annotationsFromAllWorkers} # TODO : Add your consolidation logic\n\n        # Build consolidation response object for an individual data object\n        response = {\n            &quot;datasetObjectId&quot;: dataset_object_id,\n            &quot;consolidatedAnnotation&quot;: {\n                &quot;content&quot;: {\n                    label_attribute_name: consolidated_annotation,\n                    label_attribute_name+ &quot;-metadata&quot;: {\n                        &quot;class-name&quot;: &quot;Native&quot;,\n                        &quot;confidence&quot;: 0.00,\n                        &quot;human-annotated&quot;: &quot;yes&quot;,\n                        &quot;creation-date&quot;: datetime.strftime(datetime.now(), &quot;%Y-%m-%dT%H:%M:%S&quot;),\n                        &quot;type&quot;: &quot;groundtruth\/custom&quot;\n                    }\n \n                }\n            }\n        }\n\n        success_count += 1\n#             print(&quot;{} Consolidating annotations END &quot;.format(log_prefix))\n\n        # Append individual data object response to the list of responses.\n        if response is not None:\n            consolidated_output.append(response)\n\n\n        failure_count += 1\n        print(&quot; Consolidation failed for dataobject {}&quot;.format(p))\n        print(&quot; Unexpected error: Consolidation failed.&quot; + str(sys.exc_info()[0]))\n\n    print(&quot;Consolidation Complete. Success Count {}  Failure Count {}&quot;.format(success_count, failure_count))\n\n    print(&quot; -- Consolidated Output -- &quot;)\n    print(consolidated_output)\n    print(&quot; ------------------------- &quot;)\n    return consolidated_output\n<\/code><\/pre>\n<p>As you can see above, the <code>do_consolidation<\/code> method returns an object hard-coded to include a class-name of &quot;Native&quot;, and the <code>lambda_handler<\/code> method returns that same object. Here's the post-annotation function response:<\/p>\n<pre><code>[{\n    &quot;datasetObjectId&quot;: &quot;4&quot;,\n    &quot;consolidatedAnnotation&quot;: {\n        &quot;content&quot;: {\n            &quot;new-test-14&quot;: {\n                &quot;annotationsFromAllWorkers&quot;: [{\n                    &quot;workerId&quot;: &quot;private.us-east-1.ea05a03fcd679cbb&quot;,\n                    &quot;annotationData&quot;: {\n                        &quot;content&quot;: {\n                            &quot;annotatedResult&quot;: {\n                                &quot;instances&quot;: [{\n                                    &quot;label&quot;: &quot;Native&quot;\n                                }]\n                            }\n                        }\n                    }\n                }]\n            },\n            &quot;new-test-14-metadata&quot;: {\n                &quot;class-name&quot;: &quot;Native&quot;,\n                &quot;confidence&quot;: 0,\n                &quot;human-annotated&quot;: &quot;yes&quot;,\n                &quot;creation-date&quot;: &quot;2021-05-19T07:06:06&quot;,\n                &quot;type&quot;: &quot;groundtruth\/custom&quot;\n            }\n        }\n    }\n}]\n<\/code><\/pre>\n<p>As you can see, the post-annotation function return value has the class-name of &quot;Native&quot; in the metadata so I would expect the class-name to be present in the data object metadata, but it's not. And here's a screenshot of the data object summary:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wHpEl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wHpEl.png\" alt=\"Labeled object summary\" \/><\/a><\/p>\n<p>It seems like Ground Truth overwrote the metadata, and now the object doesn't contain the correct label. I think perhaps that's why my label is coming through as the label attribute name &quot;new-test-14&quot; instead of as the correct label &quot;Native&quot;. Here's a screenshot of the labeling job in the AWS web console:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/yOdfP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yOdfP.png\" alt=\"labeling job\" \/><\/a><\/p>\n<p>The web console is supposed to show the label <strong>&quot;Native&quot;<\/strong> inside the &quot;Label&quot; column but instead I'm getting the <a href=\"https:\/\/github.com\/aws-samples\/aws-sagemaker-ground-truth-recipe\/blob\/master\/aws_sagemaker_ground_truth_sample_lambda\/annotation_consolidation_lambda.py#L65\" rel=\"nofollow noreferrer\"><code>&lt;labelattributename&gt;<\/code><\/a> <strong>&quot;new-test-14&quot;<\/strong> in the label column.<\/p>\n<p>Here is the output.manifest file generated by Ground Truth at the end:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n    &quot;source-ref&quot;: &quot;s3:\/\/&lt;file-name&gt;&quot;,\n    &quot;text&quot;: &quot;Hello world&quot;,\n    &quot;new-test-14&quot;: {\n        &quot;annotationsFromAllWorkers&quot;: [{\n            &quot;workerId&quot;: &quot;private.us-east-1.ea05a03fcd679ert&quot;,\n            &quot;annotationData&quot;: {\n                &quot;content&quot;: {\n                    &quot;annotatedResult&quot;: {\n                        &quot;label&quot;: &quot;Native&quot;\n                    }\n                }\n            }\n        }]\n    },\n    &quot;new-test-14-metadata&quot;: {\n        &quot;type&quot;: &quot;groundtruth\/custom&quot;,\n        &quot;job-name&quot;: &quot;new-test-14&quot;,\n        &quot;human-annotated&quot;: &quot;yes&quot;,\n        &quot;creation-date&quot;: &quot;2021-05-18T12:34:17.400000&quot;\n    }\n}\n<\/code><\/pre>\n<p>What should I return from the Post-Annotation function? Am I missing something in my response? How do I get the proper label to appear in the AWS web console?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1621410650207,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1622189648607,
        "Question_score_count":3.0,
        "Question_view_count":430.0,
        "Poster_created_time":1621405531012,
        "Poster_location":null,
        "Poster_reputation_count":31.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67599026",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"properli return label post annot lambda ground truth custom label job work label job custom datatyp reason get correct label aw web consol select label nativ instead get new test ground truth run post annot lambda modifi metadata return data object data object return contain class kei insid metadata attribut hard code lambda return object contain manifest file look like sourc ref text hello world sourc ref text hello world worker respons look like answer acceptancetim answercont new test label nativ submissiontim timespentinsecond workerid privat east eaafcdcbb workermetadata identitydata identityprovidertyp cognito issuer http cognito idp east amazonaw com east xpxqtxeq sub edcc aeaa worker respons get process post annot lambda model aw sampl ground truth recip code import json import sy import boto datetim import datetim def lambda handler event context event receiv print receiv event json dump event indent label job arn event labelingjobarn label attribut event labelattributenam label categori label categori event label categori event labelcategori print label categori label categori payload event payload role arn event rolearn output config output locat choos write annot locat outputconfig event output config event outputconfig specifi km kei label job us kei write consolid output locat specifi outputconfig km kei kmskeyid event km kei event kmskeyid creat client object client sclient role arn km kei client boto client perform consolid return consolid label job arn payload label attribut client def consolid label job arn payload label attribut client core logic consolid param label job arn label job arn param payload payload data consolid param label attribut identifi label output json param client helper class return output json string extract payload data suri payload ref payload suri payload bucket payload kei ref split split payload json load client object bucket payload bucket kei payload kei bodi read print payload payload data contain list data object iter consolid annot individu data object consolid output success count number data object successfulli consolid failur count number data object fail consolid rang len payload respons dataset object payload datasetobjectid log prefix data object format label job arn dataset object print consolid annot begin format log prefix annot payload annot print receiv annot worker format log prefix annot iter annot log annot cloudwatch log annotationsfromallwork rang len annot worker annot workerid anot data annot annotationdata annot content anot data content annot content json json load annot content annot job annot content json new test annot label annot job label consolid annot workerid worker annotationdata content annotatedresult instanc label annot label annotationsfromallwork append consolid annot consolid annot annotationsfromallwork annotationsfromallwork todo add consolid logic build consolid respons object individu data object respons datasetobjectid dataset object consolidatedannot content label attribut consolid annot label attribut metadata class nativ confid human annot ye creation date datetim strftime datetim type groundtruth custom success count print consolid annot end format log prefix append individu data object respons list respons respons consolid output append respons failur count print consolid fail dataobject format print unexpect error consolid fail str sy exc info print consolid complet success count failur count format success count failur count print consolid output print consolid output print return consolid output consolid method return object hard code includ class nativ lambda handler method return object post annot function respons datasetobjectid consolidatedannot content new test annotationsfromallwork workerid privat east eaafcdcbb annotationdata content annotatedresult instanc label nativ new test metadata class nativ confid human annot ye creation date type groundtruth custom post annot function return valu class nativ metadata expect class present data object metadata screenshot data object summari like ground truth overwrot metadata object contain correct label think label come label attribut new test instead correct label nativ screenshot label job aw web consol web consol suppos label nativ insid label column instead get new test label column output manifest file gener ground truth end sourc ref text hello world new test annotationsfromallwork workerid privat east eaafcdert annotationdata content annotatedresult label nativ new test metadata type groundtruth custom job new test human annot ye creation date return post annot function miss respons proper label appear aw web consol",
        "Question_preprocessed_content":"properli return label lambda ground truth custom label job work label job custom datatyp reason label aw web consol select label nativ instead ground truth run lambda modifi metadata return data object data object return contain kei insid metadata lambda return object contain manifest file like worker respons like worker respons get lambda model aw sampl ground truth recip code method return object includ nativ method return object function respons function return valu nativ metadata expect present data object metadata data object like ground truth overwrot metadata object contain label think label come label instead label nativ label job aw web consol web consol label nativ insid label column instead label column file gener ground truth end return function respons proper label aw web consol",
        "Question_gpt_summary_original":"The user is encountering an issue with a SageMaker labeling job with custom datatypes. The post-annotation lambda is not returning the correct label in the AWS web console, instead returning the label attribute name. The metadata is being modified by Ground Truth, and the data object does not contain the correct label. The user is unsure of what to return from the Post-Annotation function and how to get the proper label to appear in the AWS web console.",
        "Question_gpt_summary":"user encount issu label job custom datatyp post annot lambda return correct label aw web consol instead return label attribut metadata modifi ground truth data object contain correct label user unsur return post annot function proper label appear aw web consol"
    },
    {
        "Question_title":"Azure ML Dataset Versioning: What is Different if it Points to the Same Data?",
        "Question_body":"<p><strong>Context<\/strong><\/p>\n<p>In AzureML, we are facing an error when running a pipeline. It fails on <code>to_pandas_dataframe<\/code> because a particular dataset &quot;could not be read beyond end of stream&quot;. On its own, this seems to be an issue with the parquet file that is being registered, maybe special characters being misinterpreted.<\/p>\n<p>However, when we explicitly load a previous &quot;version&quot; of this Dataset--which points to the exact same location of data--it works as expected. In the documentation (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-version-track-datasets#versioning-best-practice\" rel=\"nofollow noreferrer\">here<\/a>), Azure says that &quot;when you load data from a dataset, the current data content referenced by the dataset is always loaded.&quot; This makes me think that a new version of the dataset with the same schema will be, well, the same.<\/p>\n<p><strong>Questions<\/strong><\/p>\n<ol>\n<li><p>What makes a Dataset version <em>different<\/em> from another version when both point to the same location? Is it only the schema definition?<\/p>\n<\/li>\n<li><p>Based on these differences, is there a way to figure out why one version would be succeeding and another failing?<\/p>\n<\/li>\n<\/ol>\n<p><strong>Attempts<\/strong><\/p>\n<ul>\n<li>The schemas of the two versions are identical. We can profile both in AzureML, and all the fields have the same profile information.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1639665519797,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":245.0,
        "Poster_created_time":1591385782727,
        "Poster_location":"Chicago, IL, USA",
        "Poster_reputation_count":594.0,
        "Poster_view_count":53.0,
        "Answer_body":"<p>As rightly suggested by @Anand Sowmithiran in comment section, This looks more like a bug with the SDK.<\/p>\n<p>You can raise <a href=\"https:\/\/azure.microsoft.com\/en-us\/support\/create-ticket\/\" rel=\"nofollow noreferrer\">Azure support ticket<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1641212437096,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1550902509267,
        "Answerer_location":null,
        "Answerer_reputation_count":2669.0,
        "Answerer_view_count":3292.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70380861",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"dataset version differ point data context face error run pipelin fail panda datafram particular dataset read end stream issu parquet file regist mayb special charact misinterpret explicitli load previou version dataset point exact locat data work expect document azur sai load data dataset current data content referenc dataset load make think new version dataset schema question make dataset version differ version point locat schema definit base differ wai figur version succeed fail attempt schema version ident profil field profil inform",
        "Question_preprocessed_content":"dataset version point data context face pipelin fail particular dataset read end stream parquet file regist mayb special charact misinterpret explicitli load previou version point exact locat work expect document azur sai load data dataset data content referenc dataset make think new version dataset schema question make dataset version version point locat schema definit base wai figur version fail schema version ident profil field profil inform",
        "Question_gpt_summary_original":"The user is facing an error in AzureML while running a pipeline, which fails on to_pandas_dataframe. However, when they load a previous version of the dataset that points to the same location of data, it works as expected. The user is questioning what makes a dataset version different from another version when both point to the same location and if there is a way to figure out why one version would be succeeding and another failing. The user has attempted to compare the schemas of the two versions, and they are identical.",
        "Question_gpt_summary":"user face error run pipelin fail panda datafram load previou version dataset point locat data work expect user question make dataset version differ version point locat wai figur version succeed fail user attempt compar schema version ident"
    },
    {
        "Question_title":"Deployment timeout while deploying the ML model in the Azure Container Instance with the azure pipeline",
        "Question_body":"<p>Our code was working fine till yesterday while deploying the ML model on Azure ACI, but facing the deployment timeout or sometimes 400 (Bad response) today.<\/p>\n<p>Is there any issue with microsoft datcenters or there is something else ?<\/p>\n<p>The errors are given below<\/p>\n<blockquote>\n<p>&quot;message&quot;: &quot;Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Thu, 06 Aug 2020 21:05:31 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '8aa4dcafb0ec40ef822b55fc4c7a196f', 'x-ms-client-session-id': 'bf2decff-8879-4a9c-bb5f-2fae7034946c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-request-time': '0.044', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{&quot;code&quot;:&quot;BadRequest&quot;,&quot;statusCode&quot;:400,&quot;message&quot;:&quot;The request is invalid.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;InvalidOverwriteRequest&quot;,&quot;message&quot;:&quot;Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;8aa4dcafb0ec40ef822b55fc4c7a196f&quot;}}'&quot;<\/p>\n<\/blockquote>\n<blockquote>\n<p>&quot;message&quot;: &quot;Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nOperation ID: 1b6746b3-cdb6-4e0c-a43d-b31b34ac99b2\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n &quot;code&quot;: &quot;DeploymentTimedOut&quot;,\\n &quot;statusCode&quot;: 504,\\n &quot;message&quot;: &quot;The deployment operation polling has TimedOut. The service creation is taking longer than our normal time. We are still trying to achieve the desired state for the web service. Please check the webservice state for the current webservice health. You can run print(service.state) from the python SDK to retrieve the current state of the webservice.&quot;\\n}&quot;<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1596785856050,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1596790304580,
        "Question_score_count":0.0,
        "Question_view_count":606.0,
        "Poster_created_time":1593185044876,
        "Poster_location":"Lahore, Pakistan",
        "Poster_reputation_count":11.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63297308",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploy timeout deploi model azur contain instanc azur pipelin code work fine till yesterdai deploi model azur aci face deploy timeout bad respons todai issu microsoft datcent error given messag receiv bad respons model manag servic nrespons code nheader date thu aug gmt content type applic json transfer encod chunk connect aliv request context appid cid dee eea client request aadcafbecefbfccaf client session bfdecff bbf faec api support version preview request time strict transport secur max ag includesubdomain preload ncontent code badrequest statuscod messag request invalid detail code invalidoverwriterequest messag invalid overwrit request updat contain resourc requir dn label deploy type delet redeploi servic correl requestid aadcafbecefbfccaf messag servic deploy poll reach non success termin state current servic state unhealthi noper cdb bbacb nmore inform log nerror code deploymenttimedout statuscod messag deploy oper poll timedout servic creation take longer normal time try achiev desir state web servic check webservic state current webservic health run print servic state python sdk retriev current state webservic",
        "Question_preprocessed_content":"deploy timeout deploi model azur contain instanc azur pipelin code work fine yesterdai deploi model azur aci face deploy timeout todai microsoft datcent given receiv bad respons model manag code requestid dcafb servic deploy reach termin state servic state inform code statuscod deploy oper timedout servic creation take longer normal time try achiev desir state web servic check webservic state webservic health run python sdk retriev state",
        "Question_gpt_summary_original":"The user is facing deployment timeout or 400 (Bad response) errors while deploying an ML model on Azure ACI. The error messages indicate that the deployment operation polling has timed out and the service creation is taking longer than normal. The user is unsure if there is an issue with Microsoft data centers or if there is something else causing the problem.",
        "Question_gpt_summary":"user face deploy timeout bad respons error deploi model azur aci error messag indic deploy oper poll time servic creation take longer normal user unsur issu microsoft data center caus problem"
    },
    {
        "Question_title":"Is it possible to use smddp in notebook?",
        "Question_body":"I recently tried the smddp v1.4.0 on SageMaker notebook instance (not sagemaker studio), using 8-GPU instances `ml.p3.16xlarge`, by directly using `smddp` as backend in the training scripts. I launched the estimator by setting `instance_type` to `local_gpu` and ended up with smddp error. Corresponding errors are attached below, saying an initialization error.\n\n```\n42u1m0wni0-algo-1-36bbw | Traceback (most recent call last):\n42u1m0wni0-algo-1-36bbw |   File \"true_main_notebook.py\", line 636, in <module>\n42u1m0wni0-algo-1-36bbw | main()\n42u1m0wni0-algo-1-36bbw |   File \"true_main_notebook.py\", line 178, in main\n42u1m0wni0-algo-1-36bbw | dist.init_process_group(backend=args.dist_backend)\n42u1m0wni0-algo-1-36bbw |   File \"\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/distributed\/distributed_c10d.py\", line 576, in init_process_group\n42u1m0wni0-algo-1-36bbw | store, rank, world_size = next(rendezvous_iterator)\n42u1m0wni0-algo-1-36bbw |   File \"\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/distributed\/rendezvous.py\", line 219, in _env_rendezvous_handler\n42u1m0wni0-algo-1-36bbw | rank = int(_get_env_or_raise(\"RANK\"))\n42u1m0wni0-algo-1-36bbw |   File \"\/opt\/conda\/lib\/python3.8\/site-packages\/torch\/distributed\/rendezvous.py\", line 203, in _get_env_or_raise\n42u1m0wni0-algo-1-36bbw |     raise _env_error(env_var)\n42u1m0wni0-algo-1-36bbw | ValueError: Error initializing torch.distributed using env:\/\/ rendezvous: environment variable RANK expected, but not set\n42u1m0wni0-algo-1-36bbw | Environment variable SAGEMAKER_INSTANCE_TYPE is not set\n42u1m0wni0-algo-1-36bbw | Running smdistributed.dataparallel v1.4.0\n42u1m0wni0-algo-1-36bbw | Error in atexit._run_exitfuncs:\n42u1m0wni0-algo-1-36bbw | Traceback (most recent call last):\n42u1m0wni0-algo-1-36bbw |   File \"\/opt\/conda\/lib\/python3.8\/site-packages\/smdistributed\/dataparallel\/torch\/torch_smddp\/__init__.py\", line 51, in at_exit_smddp\n42u1m0wni0-algo-1-36bbw | hm.shutdown()\n42u1m0wni0-algo-1-36bbw | RuntimeError: Was this script started with smddprun? For more info on using smddprun, run smddprun -h\n42u1m0wni0-algo-1-36bbw | 2022-04-03 16:07:30,005 sagemaker-training-toolkit ERROR    Reporting training FAILURE\n42u1m0wni0-algo-1-36bbw | 2022-04-03 16:07:30,005 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n42u1m0wni0-algo-1-36bbw | ExitCode 1\n42u1m0wni0-algo-1-36bbw | ErrorMessage \"ValueError: Error initializing torch.distributed using env:\/\/ rendezvous: environment variable RANK expected, but not set\n42u1m0wni0-algo-1-36bbw |  Environment variable SAGEMAKER_INSTANCE_TYPE is not set Error in atexit._run_exitfuncs: Traceback (most recent call last):   File \"\/opt\/conda\/lib\/python3.8\/site-packages\/smdistributed\/dataparallel\/torch\/torch_smddp\/__init__.py\", line 51, in at_exit_smddp hm.shutdown() RuntimeError: Was this script started with smddprun? For more info on using smddprun, run smddprun -h\"\n```\n\nThe original goal is to launch a single-node smddp for debugging. \n\nDoes the smddp only support launched by AWS python SDK rather than the notebook? Or if something I've done is not correct?",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1649002671694,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668434752192,
        "Question_score_count":0.0,
        "Question_view_count":59.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUselhJbg7SAShCfx3-8WU9Q\/is-it-possible-to-use-smddp-in-notebook",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl us smddp notebook recent tri smddp notebook instanc studio gpu instanc xlarg directli smddp backend train script launch estim set instanc type local gpu end smddp error correspond error attach sai initi error umwni algo bbw traceback recent umwni algo bbw file true main notebook line umwni algo bbw main umwni algo bbw file true main notebook line main umwni algo bbw dist init process group backend arg dist backend umwni algo bbw file opt conda lib python site packag torch distribut distribut line init process group umwni algo bbw store rank world size rendezv iter umwni algo bbw file opt conda lib python site packag torch distribut rendezv line env rendezv handler umwni algo bbw rank int env rais rank umwni algo bbw file opt conda lib python site packag torch distribut rendezv line env rais umwni algo bbw rais env error env var umwni algo bbw valueerror error initi torch distribut env rendezv environ variabl rank expect set umwni algo bbw environ variabl instanc type set umwni algo bbw run smdistribut dataparallel umwni algo bbw error atexit run exitfunc umwni algo bbw traceback recent umwni algo bbw file opt conda lib python site packag smdistribut dataparallel torch torch smddp init line exit smddp umwni algo bbw shutdown umwni algo bbw runtimeerror script start smddprun info smddprun run smddprun umwni algo bbw train toolkit error report train failur umwni algo bbw train toolkit error executeuserscripterror umwni algo bbw exitcod umwni algo bbw errormessag valueerror error initi torch distribut env rendezv environ variabl rank expect set umwni algo bbw environ variabl instanc type set error atexit run exitfunc traceback recent file opt conda lib python site packag smdistribut dataparallel torch torch smddp init line exit smddp shutdown runtimeerror script start smddprun info smddprun run smddprun origin goal launch singl node smddp debug smddp support launch aw python sdk notebook correct",
        "Question_preprocessed_content":"us recent tri instanc instanc directli backend train script launch estim end sai initi origin goal launch launch aw python sdk",
        "Question_gpt_summary_original":"The user encountered an error while trying to use smddp v1.4.0 on a SageMaker notebook instance using 8-GPU instances `ml.p3.16xlarge` by directly using `smddp` as a backend in the training scripts. The user launched the estimator by setting `instance_type` to `local_gpu` and ended up with an smddp error. The error message suggests an initialization error, and the user is unsure if smddp only supports being launched by AWS python SDK rather than the notebook. The original goal was to launch a single-node smddp for debugging.",
        "Question_gpt_summary":"user encount error try us smddp notebook instanc gpu instanc xlarg directli smddp backend train script user launch estim set instanc type local gpu end smddp error error messag suggest initi error user unsur smddp support launch aw python sdk notebook origin goal launch singl node smddp debug"
    },
    {
        "Question_title":"Is it possible to load a Scala\/Spark PipelineModel by mlflow?",
        "Question_body":"<p>I try to use <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/_modules\/mlflow\/spark.html#load_model\" rel=\"nofollow noreferrer\">mlflow<\/a> to load a serialized Scala\/Spark <a href=\"https:\/\/spark.apache.org\/docs\/latest\/api\/java\/org\/apache\/spark\/ml\/PipelineModel.html\" rel=\"nofollow noreferrer\">PipelineModel<\/a>.<\/p>\n<p>From <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.spark.html#mlflow.spark.load_model\" rel=\"nofollow noreferrer\">mlflow document<\/a> it seems it only supports <strong>Py<\/strong>Spark. Is this the case?<\/p>\n<p>Is it possible to load a serialized Scala\/Spark PipelineModel in mlflow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1600724655090,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1600988955576,
        "Question_score_count":0.0,
        "Question_view_count":175.0,
        "Poster_created_time":1510578501763,
        "Poster_location":null,
        "Poster_reputation_count":1529.0,
        "Poster_view_count":150.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64000348",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl load scala spark pipelinemodel try us load serial scala spark pipelinemodel document support pyspark case possibl load serial scala spark pipelinemodel",
        "Question_preprocessed_content":"load pipelinemodel try us load serial pipelinemodel document pyspark case load serial pipelinemodel",
        "Question_gpt_summary_original":"The user is trying to load a serialized Scala\/Spark PipelineModel using mlflow, but is unsure if mlflow only supports PySpark and is seeking clarification on whether it is possible to load a serialized Scala\/Spark PipelineModel in mlflow.",
        "Question_gpt_summary":"user try load serial scala spark pipelinemodel unsur support pyspark seek clarif possibl load serial scala spark pipelinemodel"
    },
    {
        "Question_title":"Unable to get auto speech adaption to work",
        "Question_body":"(this is actually Dialogflow ES, wouldn't let me label it that way)\n\n\u00a0\n\nTrying to get dialogflow auto speech adaption to take a 9 digit number consistently when being spoken.\u00a0 But no matter what I do it keeps trying to convert what I say to a 10 digit phone number (adding in extra numbers).\u00a0 I am speaking as slow as I possibly can clearly delineating the numbers, yet it'll add an extra number randomly to make it a phone number.\u00a0 Any assistance would be helpful.\n\nI have a relatively empty dialogflow agent (enabled for ES\/speech adaption\/all the right settings turned on). with a single intent\u00a0\n\nThe single intent is set to highest priority, no input contexts, The NineDigitNumber entity is set up as a parameter that is marked as required, no matter what I do a number like 200733201 is getting turned into 2007-332-201.\u00a0 I've tried using input contexts, spot filling, tried using synonyms to define (2007) as a prefix entity and 0-9 as \"number\" entities and do \"@prefix\u00a0@number\u00a0@number\" etc, nothing seems to work.\u00a0 I have another entity where it starts R12345678 and that one works fine, i just can't get dialogflow to just stop turning 9 digit numbers into phone numbers.\u00a0 Any ideas would be appreciated.\u00a0 Even if there was a way to use CSTT rather than Dialogflow to do the transcription is acceptable, but needing to get the engine to preference a 9 digit response.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1675771380000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":70.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unable-to-get-auto-speech-adaption-to-work\/m-p\/519495#M1241",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl auto speech adapt work actual dialogflow wouldn let label wai try dialogflow auto speech adapt digit number consist spoken matter keep try convert digit phone number ad extra number speak slow possibl clearli delin number add extra number randomli phone number assist help rel dialogflow agent enabl speech adapt right set turn singl intent singl intent set highest prioriti input context ninedigitnumb entiti set paramet mark requir matter number like get turn tri input context spot fill tri synonym defin prefix entiti number entiti prefix number number work entiti start work fine dialogflow stop turn digit number phone number idea appreci wai us cstt dialogflow transcript accept need engin prefer digit respons",
        "Question_preprocessed_content":"unabl auto adapt work try dialogflow auto adapt digit number consist spoken try convert digit phone number speak slow clearli delin number extra number randomli phone number help rel dialogflow agent singl intent singl intent set highest prioriti input context ninedigitnumb entiti set paramet mark requir number like turn tri input context spot tri synonym defin prefix entiti number entiti work entiti start work fine dialogflow stop turn digit number phone number idea wai us dialogflow transcript engin prefer digit respons",
        "Question_gpt_summary_original":"The user is facing challenges with Dialogflow's auto speech adaption feature while trying to consistently recognize a 9 digit number. Despite speaking slowly and clearly, the system keeps adding an extra number to make it a 10 digit phone number. The user has tried various methods, including using input contexts and synonyms, but nothing seems to work. The user is seeking assistance to either resolve the issue with Dialogflow or use an alternative transcription engine that can recognize 9 digit responses.",
        "Question_gpt_summary":"user face challeng dialogflow auto speech adapt featur try consist recogn digit number despit speak slowli clearli keep ad extra number digit phone number user tri method includ input context synonym work user seek assist resolv issu dialogflow us altern transcript engin recogn digit respons"
    },
    {
        "Question_title":"Git bash command prompt hanging when running dvc push to DAGsHub",
        "Question_body":"<p>I'm having problems pushing files with DVC to DAGsHub.<\/p>\n<p>Workflow:<\/p>\n<ul>\n<li>I used my email to signup to DAGsHub.<\/li>\n<li>I created a repo and clone it to my computer.<\/li>\n<li>I added files to the repo and track them using DVC and Git to track the pointer files.<\/li>\n<li>Running DVC push -r origin, it asks me for my password. When I enter the password and hit enter - nothing happens.<\/li>\n<\/ul>\n<p>It sits and waits, barring me from even canceling the operation with Ctrl+C.\nI'm forced to manually close the terminal, open a new one, ending the &quot;Python&quot; process in task manager and delete the lock file in .dvc\/tmp\/lock.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1620537862843,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1620625906412,
        "Question_score_count":5.0,
        "Question_view_count":254.0,
        "Poster_created_time":1620537484800,
        "Poster_location":null,
        "Poster_reputation_count":53.0,
        "Poster_view_count":2.0,
        "Answer_body":"<p><strong>Short answer<\/strong><\/p>\n<p>Do not use <code>ask_password<\/code>.\nInstead, save your token in the local config by running once:<\/p>\n<pre><code>dvc remote modify origin --local --unset ask_password\ndvc remote modify origin --local password &lt;--access token--&gt;\n<\/code><\/pre>\n<p><code>dvc push -r origin<\/code> should work then.<\/p>\n<p><strong>Long answer<\/strong><\/p>\n<p><a href=\"https:\/\/www.atlassian.com\/git\/tutorials\/git-bash#:%7E:text=What%20is%20Git%20Bash%3F,operating%20system%20through%20written%20commands.\" rel=\"nofollow noreferrer\">Git Bash<\/a> is not running the regular Windows command prompt but an emulated Unix-style bash prompt. From the information in your question, I cannot know for sure, but this is probably causing the <code>msvcrt<\/code> package used by DVC to prompt the password on windows machines to fail\/hang.<\/p>\n<p>There are potentially 3 ways to deal with the issue:<\/p>\n<ol>\n<li>Run <code>dvc pull<\/code> from the regular Windows cmd prompt.<\/li>\n<li>Find a way to make Git Bash wrap Python calls with <code>winpty<\/code> - I am not 100% positive about how to do this, but not using <code>winpty<\/code> seems to be the reason <code>msvcrt<\/code> fails at prompting for your password.<\/li>\n<li>The simplest solution - Do not use <code>ask_password<\/code>.\nInstead, save your token in the local config by running once:\n<pre><code>dvc remote modify origin --local --unset ask_password\ndvc remote modify origin --local password &lt;--access token--&gt;\n<\/code><\/pre>\nYou can get your access token by clicking on the question mark beside the DVC\nremote of your DAGsHub repository, then click on &quot;Reveal my token&quot;.<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1620591578072,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1427953176670,
        "Answerer_location":null,
        "Answerer_reputation_count":145.0,
        "Answerer_view_count":13.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67454531",
        "Tool":"DVC",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"git bash command prompt hang run push dagshub have problem push file dagshub workflow email signup dagshub creat repo clone ad file repo track git track pointer file run push origin ask password enter password hit enter happen sit wait bar cancel oper ctrl forc manual close termin open new end python process task manag delet lock file tmp lock",
        "Question_preprocessed_content":"git bash prompt hang push dagshub have problem push file dagshub workflow email signup dagshub creat repo clone file repo track git track pointer file push origin ask enter hit enter sit wait cancel oper ctrl forc close termin open new end python task manag delet lock file",
        "Question_gpt_summary_original":"The user is facing issues while pushing files with DVC to DAGsHub. The Git bash command prompt hangs when the user runs DVC push -r origin, and it asks for a password. However, when the user enters the password and hits enter, nothing happens, and the operation cannot be canceled with Ctrl+C. The user is forced to manually close the terminal, end the \"Python\" process in task manager, and delete the lock file in .dvc\/tmp\/lock.",
        "Question_gpt_summary":"user face issu push file dagshub git bash command prompt hang user run push origin ask password user enter password hit enter happen oper cancel ctrl user forc manual close termin end python process task manag delet lock file tmp lock"
    },
    {
        "Question_title":"Is there a way to list out my datastores if I've deployed to a VNET?",
        "Question_body":"<p>I followed the instructions in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-enable-virtual-network\" rel=\"nofollow noreferrer\">MSFT Docs<\/a>, but now I can't list our my Datastores either via the SDK nor the Azure Machine Learning studio. <\/p>\n\n<p>Instead, in the studio I see this:\n<a href=\"https:\/\/i.stack.imgur.com\/im2oe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/im2oe.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Is there a way to make this work? Did I miss a step?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1573145127473,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":164.0,
        "Poster_created_time":1529439461716,
        "Poster_location":null,
        "Poster_reputation_count":392.0,
        "Poster_view_count":39.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58753430",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wai list datastor deploi vnet follow instruct msft doc list datastor sdk studio instead studio wai work miss step",
        "Question_preprocessed_content":"wai list datastor deploi vnet instruct msft doc list datastor sdk studio instead studio wai work step",
        "Question_gpt_summary_original":"The user followed the instructions in the MSFT Docs to deploy to a VNET, but is now unable to list out their Datastores using the SDK or Azure Machine Learning studio. They are seeking assistance to make this work and wondering if they missed a step.",
        "Question_gpt_summary":"user follow instruct msft doc deploi vnet unabl list datastor sdk studio seek assist work wonder miss step"
    },
    {
        "Question_title":"Convert `String Feature` DataFrame into Float in Azure ML Using Python Script",
        "Question_body":"<p>I am trying to understand how to convert azure ml <code>String Feature<\/code> data type into float using python script. my data set is contain \"HH:MM\" data time format. It recognized as <code>String Feature<\/code> like the following img:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/gy4A7.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gy4A7.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/aB4P6.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/aB4P6.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I want to convert it into float type which will divide the timestamp by  84600 ( 24 hour) so <code>17:30<\/code> will be converted into <code>0,729166666666667<\/code>, so I write python script to convert that. This is my script:<\/p>\n\n<pre><code>import pandas as pd\nimport numpy as np \n\ndef timeToFloat(x):\n    frt = [3600,60]\n    data = str(x)\n    result = float(sum([a*b for a,b in zip(frt, map(int,data.split(':')))]))\/86400\n    return result if isNotZero(x) else 0.0\n\ndef isNotZero(x):\n    return (x is \"0\")\n\ndef azureml_main(dataframe1 = None):\n\n    df = pd.DataFrame(dataframe1)\n    df[\"Departure Time\"] = pd.to_numeric(df[\"Departure Time\"]).apply(timeToFloat)\n\n    print(df[\"Departure Time\"])\n\n    return df,\n<\/code><\/pre>\n\n<p>When I run the script it was failed. Then I try to check whether it is <code>str<\/code> or not, but it returns <code>None<\/code>.<\/p>\n\n<p>can we treat <code>String Feature<\/code> as <code>String<\/code>? or how should I covert this data correctly?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1529548568263,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":299.0,
        "Poster_created_time":1446250907867,
        "Poster_location":"Depok, Depok City, West Java, Indonesia",
        "Poster_reputation_count":123.0,
        "Poster_view_count":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50959561",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"convert string featur datafram float python script try understand convert string featur data type float python script data set contain data time format recogn string featur like follow img want convert float type divid timestamp hour convert write python script convert script import panda import numpi def timetofloat frt data str result float sum zip frt map int data split return result isnotzero def isnotzero return def main datafram datafram datafram departur time numer departur time appli timetofloat print departur time return run script fail try check str return treat string featur string covert data correctli",
        "Question_preprocessed_content":"convert datafram float python script try understand convert data type float python script data set contain data time format recogn like img want convert float type divid timestamp convert write python script convert script run script fail try check return treat covert data",
        "Question_gpt_summary_original":"The user is trying to convert a `String Feature` data type into float using a Python script in Azure ML. The data set contains time data in \"HH:MM\" format, which is recognized as a `String Feature`. The user wants to convert it into a float type by dividing the timestamp by 84600 (24 hours). However, the Python script failed to run, and the user is unsure how to correctly convert the data.",
        "Question_gpt_summary":"user try convert string featur data type float python script data set contain time data format recogn string featur user want convert float type divid timestamp hour python script fail run user unsur correctli convert data"
    },
    {
        "Question_title":"Is there a cross-sectional, unified security check list for Azure?",
        "Question_body":"<p>I have been used Azure for the first time, and I am overwelmed by the huge quantity of information about Azure.    <\/p>\n<p>I think that the information about security on Azure is not unified.    <\/p>\n<p>For example, in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/fundamentals\/identity-management-best-practices\">Identity Management and access control security best practices<\/a> page, sometimes there are multiple best practices per one section header.    <br \/>\nHowever, in <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/security-recommendations?toc=\/azure\/security\/fundamentals\/toc.json&amp;bc=\/azure\/security\/breadcrumb\/toc.json\">Security recommendations for Blob storage<\/a> page,security recommendations are documented in the form of table, one issue per one row.    <\/p>\n<p>I wish there was a cross-sectional, unified security check list for Azure as follows.    <\/p>\n<ul>\n<li> We could select Azure services we use.    <\/li>\n<li> When we select the services, the security check list are displayed or could be downloaded as text file.    <\/li>\n<li> The security check list are documented so that we can easily understand what we should do. (where on the Azure portal UI, which item, or how to do set the item which is related to security, etc)    <\/li>\n<\/ul>\n<p>I have used Azure services as follows.    <\/p>\n<ul>\n<li> Azure Data Factory    <\/li>\n<li> Azure Data Lake Storage Gen2    <\/li>\n<li> Azure Functions (App Service)    <\/li>\n<li> Azure Database for MySQL    <\/li>\n<li> Azure Machine Learning    <\/li>\n<li> Azure Monitor (for Application Insights)    <\/li>\n<\/ul>\n<p>Even if I take one service (for example, Azure Data Lake Storage Gen2), I think that I have to check at least two pages (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/storage\/blobs\/security-recommendations?toc=\/azure\/security\/fundamentals\/toc.json&amp;bc=\/azure\/security\/breadcrumb\/toc.json\">here<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/fundamentals\/paas-applications-using-storage\">here<\/a> ).    <br \/>\nHowever, I'm not sure if it's covered. Do you have any good ideas?    <\/p>\n<p>Regards.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1638435378937,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=c624669d-08b4-4372-b158-6b43fc05d41a\">@Makoto Oda  <\/a>,    <\/p>\n<p>Thanks for using Microsoft Q&amp;A!!    <\/p>\n<p>I do not think that we have a single document which can provide you a consolidated view of security across all Azure services.  You may need to go through the documentation available for individual services to get the required information.  However, you can try checking - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/security\/\">Azure security documentation<\/a> and <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/framework\/security\/overview\">Security considerations for Azure Architecture center<\/a> if this helps you getting anything specific you are looking in Azure at higher level.     <\/p>\n<p>Hope this helps.    <\/p>\n<p>Thanks    <br \/>\nSaurabh    <\/p>\n",
        "Answer_comment_count":2.0,
        "Question_closed_time":1638553979008,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/648921\/is-there-a-cross-sectional-unified-security-check",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"cross section unifi secur check list azur azur time overwelm huge quantiti inform azur think inform secur azur unifi exampl ident manag access control secur best practic page multipl best practic section header secur recommend blob storag page secur recommend document form tabl issu row wish cross section unifi secur check list azur follow select azur servic us select servic secur check list displai download text file secur check list document easili understand azur portal item set item relat secur azur servic follow azur data factori azur data lake storag gen azur function app servic azur databas mysql azur monitor applic insight servic exampl azur data lake storag gen think check page sure cover good idea regard",
        "Question_preprocessed_content":"section unifi secur check list azur azur time overwelm huge quantiti inform azur think inform secur azur unifi exampl ident manag control secur best practic page multipl best practic section header secur blob storag page secur document form tabl row wish section unifi secur check list azur select azur servic us select servic secur check list displai download text file secur check list document easili understand azur servic azur data factori azur data lake storag gen azur function azur databas mysql azur monitor servic think check page sure cover idea regard",
        "Question_gpt_summary_original":"The user is overwhelmed by the amount of information available on Azure and finds that the security information is not unified. They wish for a cross-sectional, unified security checklist for Azure that would allow them to select the services they use and display or download the relevant security checklist. The user has used several Azure services and finds that they have to check at least two pages for each service to ensure security. They are seeking suggestions for a better approach.",
        "Question_gpt_summary":"user overwhelm inform avail azur find secur inform unifi wish cross section unifi secur checklist azur allow select servic us displai download relev secur checklist user azur servic find check page servic ensur secur seek suggest better approach"
    },
    {
        "Question_title":"How to force dvc get",
        "Question_body":"<p>From my CI pipeline, I would like to download some files tracked using DVC.<\/p>\n<pre><code class=\"lang-auto\">data\n\u2514\u2500\u2500 test_data\n    \u251c\u2500\u2500 tests_subfolder_1\n    \u2502   \u251c\u2500\u2500 file1.test\n    \u2502   \u2514\u2500\u2500 file2.test\n    \u251c\u2500\u2500 tests_subfolder_1.dvc\n    \u251c\u2500\u2500 tests_subfolder_2\n<\/code><\/pre>\n<p>\u2026 etc.<\/p>\n<p>When I run <code>dvc get . data\/test_data --out data\/<\/code>, I get the error:<\/p>\n<pre><code class=\"lang-bash\">ERROR: failed to get 'data\/test_data\/' from '.' - unable to remove 'data\/test_data\/test_subfolder.dvc' without a confirmation. Use `-f` to force.\n<\/code><\/pre>\n<p>This is surprising to me, because I would expect <code>test_subfolder.dvc<\/code> and <code>test_subfolder\/<\/code> to be able to coexist.<\/p>\n<p>However, I don\u2019t know where to put the <code>-f<\/code> argument? I tried:<\/p>\n<ul>\n<li><code>dvc -f get . data\/test_data --out data\/<\/code><\/li>\n<li><code>dvc get . data\/tests_data --out data\/ --force<\/code><\/li>\n<\/ul>\n<p>I also tried to work around the problem with:<br>\n<code>dvc get . data\/test_data\/* --out data\/<\/code><\/p>\n<p>However, my final solution was:<br>\n<code>ls data\/test_data\/*.dvc | sed -e 's\/\\.dvc$\/\/' | xargs -I {} dvc get . {} --out data\/test_data\/<\/code><\/p>\n<p>This work-around feels over-complicated. What was I supposed to do?<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_created_time":1593011149596,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":997.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/how-to-force-dvc-get\/417",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"forc pipelin like download file track data test data test subfold file test file test test subfold test subfold run data test data data error error fail data test data unabl remov data test data test subfold confirm us forc surpris expect test subfold test subfold abl coexist dont know argument tri data test data data data test data data forc tri work problem data test data data final solut data test data sed xarg data test data work feel complic suppos",
        "Question_preprocessed_content":"forc pipelin like download file track run surpris expect abl coexist dont know argument tri tri work problem final solut",
        "Question_gpt_summary_original":"The user is trying to download some files tracked using DVC from their CI pipeline, but they encounter an error message when running the command \"dvc get . data\/test_data --out data\/\". The error message suggests using the \"-f\" argument to force the removal of \"test_subfolder.dvc\", but the user is unsure where to put the argument. The user tries different variations of the command with the \"-f\" argument but is unsuccessful. The user resorts to a complicated workaround involving the \"sed\" and \"xargs\" commands to solve the issue. The user is seeking guidance on the correct way to resolve the issue.",
        "Question_gpt_summary":"user try download file track pipelin encount error messag run command data test data data error messag suggest argument forc remov test subfold user unsur argument user tri differ variat command argument unsuccess user resort complic workaround involv sed xarg command solv issu user seek guidanc correct wai resolv issu"
    },
    {
        "Question_title":"AML VS Code integration with synapse spark pool as attached computes",
        "Question_body":"<p>Hey!    <br \/>\nThe VS code integration in the AML ecosystem is great.    <br \/>\nIs it possible to debug using the synapse spark pool as it attached compute (like I am running notebook on it)    <br \/>\nCurrently from the VS code only compute instance is supported .    <br \/>\nAm I missing something?    <\/p>\n<p>Thanks,    <br \/>\nMaya<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1669791827530,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=ce96d2b0-635e-4ed7-b685-15e43ebb5007\">@Maya Shauli  <\/a>,    <\/p>\n<p>Thanks for the question and using MS platform.    <\/p>\n<blockquote>\n<p>Unfortunately,  synapse spark pool as it attached compute on Visual Code is no longer supported.    <\/p>\n<\/blockquote>\n<p>Appreciate if you could share the feedback on our <a href=\"https:\/\/feedback.azure.com\/d365community\/idea\/184e6a07-14fa-ec11-a81b-6045bd853c94\">feedback channel<\/a>. Which would be open for the user community to upvote &amp; comment on. This allows our product teams to effectively prioritize your request against our existing feature backlog and gives insight into the potential impact of implementing the suggested feature.    <\/p>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is jhow you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/support\/community-champions-program\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1669871984343,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1109976\/aml-vs-code-integration-with-synapse-spark-pool-as",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"aml code integr synaps spark pool attach comput hei code integr aml ecosystem great possibl debug synaps spark pool attach comput like run notebook current code comput instanc support miss thank maya",
        "Question_preprocessed_content":"aml code integr synaps spark comput hei code integr aml ecosystem great debug synaps spark comput code comput instanc thank maya",
        "Question_gpt_summary_original":"Maya is using VS code integration in the AML ecosystem and wants to know if it is possible to debug using the synapse spark pool as an attached compute. Currently, only compute instance is supported in VS code.",
        "Question_gpt_summary":"maya code integr aml ecosystem want know possibl debug synaps spark pool attach comput current comput instanc support code"
    },
    {
        "Question_title":"VSCode cannot see packages on a GCP VM",
        "Question_body":"<p>I have an issue where vscode when connected to a VM on GCP cannot see packages installed in <code>\/opt\/conda\/lib\/python3.7\/site-packages.<\/code> I have created the VM using Vertex AI. When I open the jupyter notebook through the UI in a the browser I can see all the packages via <code>pip3 list<\/code>. But when I am connected to the VM through SSH in vscode I cannot see the packages installed such as nltk, spacy etc. and when I try to load it gives me <code>ModuleNotFoundError<\/code>. This error does not show up when I use the jupyter notebook from the Vertex AI UI. The site-packages folder is in my system path and the python that I am using is <code>\/opt\/conda\/bin\/python3<\/code>.<\/p>\n<p>Any help is appreciated. Please do let me know if my question is clear.<\/p>\n<p>EDIT: I figured out that my packages are running on a container in the VM. Is there a way for me to access those packages via jupyter notebook in vscode?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1638473538253,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1638550660460,
        "Question_score_count":0.0,
        "Question_view_count":230.0,
        "Poster_created_time":1580840045043,
        "Poster_location":null,
        "Poster_reputation_count":85.0,
        "Poster_view_count":16.0,
        "Answer_body":"<p>Posting the answer as community wiki. As confirmed by @Abhishek, he was able to make it work by installing a docker extension on the VM then attach VS code to the container.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1638843453688,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1606724007903,
        "Answerer_location":null,
        "Answerer_reputation_count":5969.0,
        "Answerer_view_count":2590.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70205432",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"vscode packag gcp issu vscode connect gcp packag instal opt conda lib python site packag creat open jupyt notebook browser packag pip list connect ssh vscode packag instal nltk spaci try load give modulenotfounderror error us jupyt notebook site packag folder path python opt conda bin python help appreci let know question clear edit figur packag run contain wai access packag jupyt notebook vscode",
        "Question_preprocessed_content":"vscode packag gcp vscode gcp packag creat open jupyt browser packag vscode packag nltk spaci try load give us jupyt folder path python help let know question clear edit figur packag contain wai packag jupyt vscode",
        "Question_gpt_summary_original":"The user is facing an issue where VSCode, when connected to a VM on GCP, cannot see packages installed in \/opt\/conda\/lib\/python3.7\/site-packages. The packages are running on a container in the VM, and the user is looking for a way to access those packages via Jupyter Notebook in VSCode. The error message received is ModuleNotFoundError.",
        "Question_gpt_summary":"user face issu vscode connect gcp packag instal opt conda lib python site packag packag run contain user look wai access packag jupyt notebook vscode error messag receiv modulenotfounderror"
    },
    {
        "Question_title":"Saving partitioned parquet on AzureML",
        "Question_body":"<p>I'm working at a company that only allows us to use AzureMl.<\/p>\n<p>The output for one of our models is data enrichment: we read a table with customer information, segment it and then return a pandas DataFrame with <code>customer_id<\/code>, <code>segment_name<\/code>, <code>segment_type<\/code>, <code>reference_dt<\/code> and <code>processed_dt<\/code>.<\/p>\n<p>I wanted to save this information as parquet files, at the Azure blob storage, with <code>reference_dt<\/code> as partition.<\/p>\n<p>I can't find in the Docs how to do this. What I did find was the <code>Dataset.Tabular.register_pandas_dataframe<\/code> that stores the data in a non-customizable path, with an un-human-readable UIUD as the folder name.<\/p>\n<p>Whenever we update that segmentation, that method creates another version of the dataset, whose file path is under a different UIUD.<\/p>\n<p>Is there a way for me to have control on where the data will be stored so that I can later safely automate this procedure?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1635184123353,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":319.0,
        "Poster_created_time":1372453042100,
        "Poster_location":"Lisbon, Portugal",
        "Poster_reputation_count":394.0,
        "Poster_view_count":183.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69712598",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save partit parquet work compani allow us output model data enrich read tabl custom inform segment return panda datafram custom segment segment type refer process want save inform parquet file azur blob storag refer partit doc dataset tabular regist panda datafram store data non customiz path human readabl uiud folder updat segment method creat version dataset file path differ uiud wai control data store later safe autom procedur",
        "Question_preprocessed_content":"save partit parquet work compani us output model data enrich read tabl custom inform segment return panda datafram want save inform parquet file azur blob storag partit doc store data path uiud folder updat segment method creat version dataset file path uiud wai control data store later safe autom procedur",
        "Question_gpt_summary_original":"The user is working on a project using AzureML and needs to save data as parquet files on Azure blob storage with a specific partition. However, they are unable to find documentation on how to do this and the method they found creates non-customizable paths with unreadable folder names. The user is looking for a way to have control over where the data is stored to automate the procedure safely.",
        "Question_gpt_summary":"user work project need save data parquet file azur blob storag specif partit unabl document method creat non customiz path unread folder name user look wai control data store autom procedur safe"
    },
    {
        "Question_title":"AWS Sagemaker Spark S3 access issue",
        "Question_body":"<p>I am new in AWS sagemaker. I created a notebook in a VPC with private subnet, kms default encrypted key, root access, no direct internet access. I have attached policy which have full access to Sagemaker and S3 in IAM as per documentations.  Now while one of data scientist trying to run his code in jupyter, getting below error. I can see jar files (\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker_pyspark\/jars\/), I have even given access key and secret key in code, is there anything we are doing wrong here<\/p>\n\n<pre><code>import os\nimport boto3\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nimport sagemaker\nfrom sagemaker import get_execution_role\nimport sagemaker_pyspark\nimport pyspark\n\nrole = get_execution_role()\nspark = SparkSession.builder \\\n            .appName(\"app_name2\") \\\n            .getOrCreate()\n\nsc=pyspark.SparkContext.getOrCreate()\nsc.setSystemProperty(\"com.amazonaws.services.s3.enableV4\", \"true\")\n\nhadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", 'access_key')\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", 'secret_key')\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-2.amazonaws.com\")\nspark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3a.enableV4\", \"true\")\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\");\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\ndf= spark.read.csv(\"s3a:\/\/mybucket\/ConsolidatedData\/my.csv\",header=\"true\")\n\n\nPy4JJavaError: An error occurred while calling o579.csv.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n    at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n    at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n    at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n    at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n    at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:709)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1583781550823,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1583817907990,
        "Question_score_count":0.0,
        "Question_view_count":933.0,
        "Poster_created_time":1513883236660,
        "Poster_location":"Noida, Uttar Pradesh, India",
        "Poster_reputation_count":465.0,
        "Poster_view_count":46.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60607041",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"spark access issu new creat notebook vpc privat subnet km default encrypt kei root access direct internet access attach polici access iam document data scientist try run code jupyt get error jar file home user anaconda env python lib python site packag pyspark jar given access kei secret kei code wrong import import boto pyspark import sparkcontext sparkconf pyspark sql import sparksess import import execut role import pyspark import pyspark role execut role spark sparksess builder appnam app getorcr pyspark sparkcontext getorcr setsystemproperti com amazonaw servic enablev true hadoop conf spark sparkcontext jsc hadoopconfigur spark jsc hadoopconfigur set access kei access kei spark jsc hadoopconfigur set secret kei secret kei spark jsc hadoopconfigur set endpoint east amazonaw com spark jsc hadoopconfigur set com amazonaw servic enablev true spark jsc hadoopconfigur set connect ssl enabl fals spark jsc hadoopconfigur set impl org apach hadoop safilesystem spark read csv mybucket consolidateddata csv header true pyjjavaerror error occur call csv java lang runtimeexcept java lang classnotfoundexcept class org apach hadoop safilesystem org apach hadoop conf configur getclass configur java org apach hadoop filesystem getfilesystemclass filesystem java org apach hadoop filesystem createfilesystem filesystem java org apach hadoop filesystem access filesystem java org apach hadoop filesystem cach getintern filesystem java org apach hadoop filesystem cach filesystem java org apach hadoop filesystem filesystem java org apach hadoop path getfilesystem path java org apach spark sql execut datasourc datasourc org apach spark sql execut datasourc datasourc checkandglobpathifnecessari datasourc scala",
        "Question_preprocessed_content":"spark new creat vpc privat subnet km default encrypt kei direct internet polici iam document data scientist try run code jupyt jar file given kei secret kei code wrong",
        "Question_gpt_summary_original":"The user is encountering an issue while trying to access S3 from AWS Sagemaker Spark. The user has attached a policy with full access to Sagemaker and S3 in IAM, and has given access key and secret key in the code. However, while running the code in Jupyter, the user is getting a \"ClassNotFoundException\" error for \"org.apache.hadoop.fs.s3a.S3AFileSystem\".",
        "Question_gpt_summary":"user encount issu try access spark user attach polici access iam given access kei secret kei code run code jupyt user get classnotfoundexcept error org apach hadoop safilesystem"
    },
    {
        "Question_title":"What is the role of feature type in AzureML?",
        "Question_body":"<p>I want to know what is the difference between <code>feature numeric<\/code> and <code>numeric<\/code> columns in Azure Machine Learning Studio.<\/p>\n\n<p>The <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/edit-metadata\" rel=\"nofollow noreferrer\">documentation site<\/a> states: <\/p>\n\n<blockquote>\n  <p>Because all columns are initially treated as features, for modules\n  that perform mathematical operations, you might need to use this\n  option to prevent numeric columns from being treated as variables.<\/p>\n<\/blockquote>\n\n<p>But nothing more. Not what a feature is, in which modules you need features. Nothing. <\/p>\n\n<p>I specifically would like to understand if the <code>clear feature<\/code> dropdown option in the <code>fields<\/code> in the <code>edit metadata<\/code>-module has any effect. Can somebody give me a szenario where this <code>clear feature<\/code>-operation changes the ML outcome? Thank you<\/p>\n\n<p>According to the documentation in ought to have an effect:<\/p>\n\n<blockquote>\n  <p>Use the Fields option if you want to change the way that Azure Machine\n  Learning uses the data in a model.<\/p>\n<\/blockquote>\n\n<p>But what can this effect be? Any example might help<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1538054010173,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1538054394440,
        "Question_score_count":1.0,
        "Question_view_count":70.0,
        "Poster_created_time":1368739128832,
        "Poster_location":"Riga, Latvia",
        "Poster_reputation_count":1763.0,
        "Poster_view_count":380.0,
        "Answer_body":"<p>As you suspect, setting a column as <code>feature<\/code> does have an effect, and it's actually quite important - when training a model, the algorithms will only take into account columns with the <code>feature<\/code> flag, effectively ignoring the others. <\/p>\n\n<p>For example, if you have a dataset with columns <code>Feature1<\/code>, <code>Feature2<\/code>, and <code>Label<\/code> and you want to try out just <code>Feature1<\/code>, you would apply <code>clear feature<\/code> to the <code>Feature2<\/code> column (while making sure that <code>Feature1<\/code> has the <code>feature<\/code> label set, of course).<\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1538116098500,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1250158552416,
        "Answerer_location":"Romania",
        "Answerer_reputation_count":7916.0,
        "Answerer_view_count":801.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52537861",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"role featur type want know differ featur numer numer column studio document site state column initi treat featur modul perform mathemat oper need us option prevent numer column treat variabl featur modul need featur specif like understand clear featur dropdown option field edit metadata modul effect somebodi szenario clear featur oper chang outcom thank accord document ought effect us field option want chang wai azur machin learn us data model effect exampl help",
        "Question_preprocessed_content":"role featur type want know column studio document site state column treat featur modul perform mathemat oper us option prevent numer column treat variabl featur modul featur like understand dropdown option modul somebodi szenario oper chang outcom thank document ought us field option want chang wai azur machin learn us data model exampl help",
        "Question_gpt_summary_original":"The user is seeking clarification on the difference between \"feature numeric\" and \"numeric\" columns in Azure Machine Learning Studio. They are also unsure about the purpose of the \"clear feature\" dropdown option in the \"edit metadata\" module and how it affects the ML outcome. The documentation provides limited information on these topics, and the user is looking for specific scenarios or examples.",
        "Question_gpt_summary":"user seek clarif differ featur numer numer column studio unsur purpos clear featur dropdown option edit metadata modul affect outcom document provid limit inform topic user look specif scenario exampl"
    },
    {
        "Question_title":"Sagemaker Studio Pyspark example fails",
        "Question_body":"<p>When I try to run the Sagemaker provided examples with PySpark in Sagemaker Studio<\/p>\n<pre><code>import os\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nimport sagemaker\nfrom sagemaker import get_execution_role\nimport sagemaker_pyspark\n\nrole = get_execution_role()\n\n# Configure Spark to use the SageMaker Spark dependency jars\njars = sagemaker_pyspark.classpath_jars()\n\nclasspath = &quot;:&quot;.join(sagemaker_pyspark.classpath_jars())\n\n# See the SageMaker Spark Github repo under sagemaker-pyspark-sdk\n# to learn how to connect to a remote EMR cluster running Spark from a Notebook Instance.\nspark = SparkSession.builder.config(&quot;spark.driver.extraClassPath&quot;, classpath)\\\n    .master(&quot;local[*]&quot;).getOrCreate()\n<\/code><\/pre>\n<p>I get the following exception:<\/p>\n<pre><code>    ---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\n&lt;ipython-input-6-c8f6fff0daaf&gt; in &lt;module&gt;\n     19 # to learn how to connect to a remote EMR cluster running Spark from a Notebook Instance.\n     20 spark = SparkSession.builder.config(&quot;spark.driver.extraClassPath&quot;, classpath)\\\n---&gt; 21     .master(&quot;local[*]&quot;).getOrCreate()\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/sql\/session.py in getOrCreate(self)\n    171                     for key, value in self._options.items():\n    172                         sparkConf.set(key, value)\n--&gt; 173                     sc = SparkContext.getOrCreate(sparkConf)\n    174                     # This SparkContext may be an existing one.\n    175                     for key, value in self._options.items():\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/context.py in getOrCreate(cls, conf)\n    361         with SparkContext._lock:\n    362             if SparkContext._active_spark_context is None:\n--&gt; 363                 SparkContext(conf=conf or SparkConf())\n    364             return SparkContext._active_spark_context\n    365 \n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/context.py in __init__(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\n    127                     &quot; note this option will be removed in Spark 3.0&quot;)\n    128 \n--&gt; 129         SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n    130         try:\n    131             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/context.py in _ensure_initialized(cls, instance, gateway, conf)\n    310         with SparkContext._lock:\n    311             if not SparkContext._gateway:\n--&gt; 312                 SparkContext._gateway = gateway or launch_gateway(conf)\n    313                 SparkContext._jvm = SparkContext._gateway.jvm\n    314 \n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/java_gateway.py in launch_gateway(conf)\n     44     :return: a JVM gateway\n     45     &quot;&quot;&quot;\n---&gt; 46     return _launch_gateway(conf)\n     47 \n     48 \n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/java_gateway.py in _launch_gateway(conf, insecure)\n    106 \n    107             if not os.path.isfile(conn_info_file):\n--&gt; 108                 raise Exception(&quot;Java gateway process exited before sending its port number&quot;)\n    109 \n    110             with open(conn_info_file, &quot;rb&quot;) as info:\n\nException: Java gateway process exited before sending its port number\n<\/code><\/pre>\n<p>Before running the example I installed pyspark and sagemaker_pyspark with pip from the notebook. I am also using SparkMagic kernel from the kernels library of SageMaker.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_created_time":1610957989217,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1827.0,
        "Poster_created_time":1452190055592,
        "Poster_location":"Germany",
        "Poster_reputation_count":247.0,
        "Poster_view_count":49.0,
        "Answer_body":"<p>Maybe, you are having this issue because this notebook was designed to run when you have an EMR cluster. I suggest you start a notebook with conda_python3 kernel on Sagemaker instead of the SparkMagic kernel. You will need to install <code>pyspark<\/code> and <code>sagemaker_pyspark<\/code> using pip, but it should work with the code you posted.<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1611005573523,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1489170718523,
        "Answerer_location":"Toronto, ON, Canada",
        "Answerer_reputation_count":81.0,
        "Answerer_view_count":5.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65770913",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio pyspark exampl fail try run provid exampl pyspark studio import pyspark import sparkcontext sparkconf pyspark sql import sparksess import import execut role import pyspark role execut role configur spark us spark depend jar jar pyspark classpath jar classpath join pyspark classpath jar spark github repo pyspark sdk learn connect remot emr cluster run spark notebook instanc spark sparksess builder config spark driver extraclasspath classpath master local getorcr follow except except traceback recent learn connect remot emr cluster run spark notebook instanc spark sparksess builder config spark driver extraclasspath classpath master local getorcr opt conda lib python site packag pyspark sql session getorcr self kei valu self option item sparkconf set kei valu sparkcontext getorcr sparkconf sparkcontext exist kei valu self option item opt conda lib python site packag pyspark context getorcr cl conf sparkcontext lock sparkcontext activ spark context sparkcontext conf conf sparkconf return sparkcontext activ spark context opt conda lib python site packag pyspark context init self master appnam sparkhom pyfil environ batchsiz serial conf gatewai jsc profil cl note option remov spark sparkcontext ensur initi self gatewai gatewai conf conf try self init master appnam sparkhom pyfil environ batchsiz serial opt conda lib python site packag pyspark context ensur initi cl instanc gatewai conf sparkcontext lock sparkcontext gatewai sparkcontext gatewai gatewai launch gatewai conf sparkcontext jvm sparkcontext gatewai jvm opt conda lib python site packag pyspark java gatewai launch gatewai conf return jvm gatewai return launch gatewai conf opt conda lib python site packag pyspark java gatewai launch gatewai conf insecur path isfil conn info file rais except java gatewai process exit send port number open conn info file info except java gatewai process exit send port number run exampl instal pyspark pyspark pip notebook sparkmag kernel kernel librari",
        "Question_preprocessed_content":"studio pyspark exampl fail try run provid exampl pyspark studio except exampl pyspark pip sparkmag kernel kernel librari",
        "Question_gpt_summary_original":"The user is encountering an exception while trying to run Sagemaker provided examples with PySpark in Sagemaker Studio. The exception is related to the Java gateway process which exited before sending its port number. The user has installed pyspark and sagemaker_pyspark with pip and is using SparkMagic kernel from the kernels library of SageMaker.",
        "Question_gpt_summary":"user encount except try run provid exampl pyspark studio except relat java gatewai process exit send port number user instal pyspark pyspark pip sparkmag kernel kernel librari"
    },
    {
        "Question_title":"Wandb sync confusing personal project for team project",
        "Question_body":"<p>I have a project \u201cfoo\u201d on my personal wandb account (entity \u201cuser\u201d). However, I am also a member of a team (\u201cteam\u201d). When I try to sync an offline run using <code>wandb sync path\/to\/foo\/run<\/code>, I want it to be saved in project \u201cfoo\u201d on my personal account. However, wandb creates a new project \u201cfoo\u201d that is owned by \u201cteam\u201d.<\/p>\n<p>Is there any way I can fix this? Do I need to change the way I\u2019m logged in to my wandb account? wandb says that I am logged in as <code>user (team)<\/code>, but I\u2019m not sure how to change that.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1682957058371,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":103.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/adamoyoung\">@adamoyoung<\/a> thanks for reporting this issue. Could you please provide the <code>--entity<\/code> and <code>--project<\/code> arguments as follows:<br>\n<code>wandb sync -e personal -p foo path\/to\/foo\/run<\/code><\/p>\n<p>Would this work for you? There\u2019s a <code>Project Defaults<\/code> section in your <a href=\"https:\/\/wandb.ai\/settings\">personal settings page<\/a> where this in your case seems to be configured for your team entity. You may change that if you wanted the default to be your personal account.<\/p>",
        "Answer_comment_count":null,
        "Question_closed_time":1683034536819,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-sync-confusing-personal-project-for-team-project\/4315",
        "Tool":"Weights & Biases",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sync confus person project team project project foo person account entiti user member team team try sync offlin run sync path foo run want save project foo person account creat new project foo own team wai fix need chang wai log account sai log user team sure chang",
        "Question_preprocessed_content":"sync confus person project team project project person member team try sync run want save project person creat new project own team wai fix chang wai sai sure chang",
        "Question_gpt_summary_original":"The user has a personal project named \"foo\" on their Wandb account, but when they try to sync an offline run using \"wandb sync path\/to\/foo\/run\", it creates a new project named \"foo\" owned by their team instead of saving it in their personal account. The user is looking for a solution to fix this issue and is unsure if they need to change their login credentials.",
        "Question_gpt_summary":"user person project name foo account try sync offlin run sync path foo run creat new project name foo own team instead save person account user look solut fix issu unsur need chang login credenti"
    },
    {
        "Question_title":"Where are the variables quotients after doing a regression run in ML?",
        "Question_body":"<p>Having done my first Azure ML Studio session, the presented output metrics are global (Spearman, Explained variance, etc) are somewhat secondary to my requirement of knowing how each of my hundreds of variables have contributed to these. But I cannot find them. I would appreciate some guidance to where such numbers are - I know they have to be somewhere, as they (in total) provide the shown metrics.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1617200123477,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/339422\/where-are-the-variables-quotients-after-doing-a-re",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"variabl quotient regress run have studio session present output metric global spearman explain varianc somewhat secondari requir know hundr variabl contribut appreci guidanc number know total provid shown metric",
        "Question_preprocessed_content":"variabl quotient run have studio present output metric global somewhat secondari requir know hundr variabl contribut guidanc number know provid shown metric",
        "Question_gpt_summary_original":"The user has completed a regression run in Azure ML Studio and is unable to locate the variables quotients that contributed to the global output metrics such as Spearman and Explained variance. The user is seeking guidance to locate these numbers as they are important for their analysis.",
        "Question_gpt_summary":"user complet regress run studio unabl locat variabl quotient contribut global output metric spearman explain varianc user seek guidanc locat number import analysi"
    },
    {
        "Question_title":"Use images in s3 with SageMaker without .lst files",
        "Question_body":"<p>I am trying to create (what I thought was) a simple image classification pipeline between s3 and SageMaker.<\/p>\n\n<p>Images are stored in an s3 bucket with their class labels in their file names currently, e.g.<\/p>\n\n<p><strong>My-s3-bucket-dir<\/strong><\/p>\n\n<pre><code>cat-1.jpg\ndog-1.jpg\ncat-2.jpg\n..\n<\/code><\/pre>\n\n<p>I've been trying to leverage several related example .py scripts, but most seem to be download data sets already in .rec format or containing special manifest or annotation files I don't have.<\/p>\n\n<p>All I want is to pass the images from s3 to the SageMaker image classification algorithm that's located in the same region, IAM account, etc. I suppose this means I need a <code>.lst<\/code> file<\/p>\n\n<p>When I try to manually create the <code>.lst<\/code> it doesn't seem to like it and it also takes too long doing manual work to be a good practice.<\/p>\n\n<p>How can I automatically generate the <code>.lst<\/code> file (or otherwise send the images\/classes for training)? <\/p>\n\n<p>Things I read made it sound like <code>im2rec.py<\/code> was a solution, but I don't see how. The example I'm working with now is <\/p>\n\n<p><code>Image-classification-fulltraining-highlevel.ipynb<\/code><\/p>\n\n<p>but it seems to download the data as <code>.rec<\/code>, <\/p>\n\n<pre><code>download('http:\/\/data.mxnet.io\/data\/caltech-256\/caltech-256-60-train.rec')\ndownload('http:\/\/data.mxnet.io\/data\/caltech-256\/caltech-256-60-val.rec')\n<\/code><\/pre>\n\n<p>which just skips working with the .jpeg files. I found another that converts them to <code>.rec<\/code> but again it has essentially the <code>.lst<\/code> already as <code>.json<\/code> and just converts it.<\/p>\n\n<p>I have mostly been working in a Python Jupyter notebook within the AWS console (in my browser) but I have also tried using their GUI. <\/p>\n\n<p>How can I simply and automatically generate the <code>.lst<\/code> or otherwise get the data\/class info into SageMaker without manually creating a <code>.lst<\/code> file?<\/p>\n\n<p><strong><em>Update<\/em><\/strong><\/p>\n\n<p>It looks like im2py can't be run against s3. You'd have to completely download everything from all s3 buckets into the notebook's storage...<\/p>\n\n<blockquote>\n  <p>Please note that [...] im2rec.py is running locally,\n  therefore cannot take input from the S3 bucket. To generate the list\n  file, you need to download the data and then use the im2rec tool. - AWS SageMaker Team<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1559921851153,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1560181849816,
        "Question_score_count":2.0,
        "Question_view_count":937.0,
        "Poster_created_time":1399301338467,
        "Poster_location":"Columbia, MD, USA",
        "Poster_reputation_count":21413.0,
        "Poster_view_count":6465.0,
        "Answer_body":"<p>There are 3 options to provide annotated data to the Image Classification algo: (1) packing labels in recordIO files, (2) storing labels in a JSON manifest file (\"augmented manifest\" option), (3) storing labels in a list file. All options are documented here: <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/image-classification.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/image-classification.html<\/a>.<\/p>\n\n<p>Augmented Manifest and .lst files option are quick to do since they just require you to create an annotation file with a usually quick <code>for<\/code> loop for example. RecordIO requires you to use <code>im2rec.py<\/code> tool, which is a little more work.<\/p>\n\n<p>Using .lst files is <strong>another option<\/strong> that is reasonably easy: you just need to create annotation them with a quick for loop, like this:<\/p>\n\n<pre><code># assuming train_index, train_class, train_pics store the pic index, class and path\n\nwith open('train.lst', 'a') as file:\n    for index, cl, pic in zip(train_index, train_class, train_pics):\n        file.write(str(index) + '\\t' + str(cl) + '\\t' + pic + '\\n')\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1559948298332,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1442180190107,
        "Answerer_location":null,
        "Answerer_reputation_count":3203.0,
        "Answerer_view_count":400.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56497428",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us imag lst file try creat thought simpl imag classif pipelin imag store bucket class label file name current bucket dir cat jpg dog jpg cat jpg try leverag relat exampl script download data set rec format contain special manifest annot file want pass imag imag classif algorithm locat region iam account suppos mean need lst file try manual creat lst like take long manual work good practic automat gener lst file send imag class train thing read sound like imrec solut exampl work imag classif fulltrain highlevel ipynb download data rec download http data mxnet data caltech caltech train rec download http data mxnet data caltech caltech val rec skip work jpeg file convert rec essenti lst json convert work python jupyt notebook aw consol browser tri gui simpli automat gener lst data class info manual creat lst file updat look like impi run complet download bucket notebook storag note imrec run local input bucket gener list file need download data us imrec tool team",
        "Question_preprocessed_content":"us imag lst file try creat simpl imag pipelin imag store bucket label file name try leverag relat exampl script download data set rec format contain special manifest file want imag imag algorithm locat region iam mean file try creat like take long manual work practic gener file thing read sound like solut exampl work download data skip work jpeg file convert convert work python jupyt aw consol tri gui simpli gener info creat file updat like run complet download bucket note input bucket gener list file download data us rec team",
        "Question_gpt_summary_original":"The user is trying to create an image classification pipeline between s3 and SageMaker, but is having trouble generating a .lst file to pass the images to the algorithm. They have tried leveraging example .py scripts, but most are for datasets already in .rec format or containing special manifest or annotation files. The user is looking for a simple and automatic way to generate the .lst file or otherwise get the data\/class info into SageMaker without manually creating a .lst file. The user has also been informed that im2rec.py cannot be run against s3 and that the data needs to be downloaded to generate the list file.",
        "Question_gpt_summary":"user try creat imag classif pipelin have troubl gener lst file pass imag algorithm tri leverag exampl script dataset rec format contain special manifest annot file user look simpl automat wai gener lst file data class info manual creat lst file user inform imrec run data need download gener list file"
    },
    {
        "Question_title":"Sagemaker Ground truth pdf annotation tool not rendering anything",
        "Question_body":"Hello, I have followed these docs https:\/\/docs.aws.amazon.com\/comprehend\/latest\/dg\/cer-annotation-pdf.html  and have gotten to the point in which I have created the annotation task and I have uploaded several pdf's to a s3 bucket to be used for an annotation task so I can create a comprehend model. I put myself and a co-worker as annotators just so I can verify that I can set up the task properly and I only uploaded 37 pdf's. However when both of us log in and start the task, the webpage loads as the instructions tell us to however there is no pdf rendered (though I think I see it briefly flash on the screen before it goes blank) and there are also no entities to be selected as a part of the ui unlike how the documentation pictures the tool. I am trying to do named entity recognition and created this task with the full 25 entities I want to be able to label and Also another time with only 5 entities to label. However there seems to be something wrong with this native pdf annotation feature.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1649874349265,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668487286374,
        "Question_score_count":0.0,
        "Question_view_count":450.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUzYkN4V8kRsWhT3ZSNJy9mQ\/sagemaker-ground-truth-pdf-annotation-tool-not-rendering-anything",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"ground truth pdf annot tool render hello follow doc http doc aw amazon com comprehend latest cer annot pdf html gotten point creat annot task upload pdf bucket annot task creat comprehend model worker annot verifi set task properli upload pdf log start task webpag load instruct tell pdf render think briefli flash screen goe blank entiti select unlik document pictur tool try name entiti recognit creat task entiti want abl label time entiti label wrong nativ pdf annot featur",
        "Question_preprocessed_content":"ground truth pdf render doc point creat task upload pdf bucket task creat comprehend model verifi set task properli upload pdf log start task webpag load instruct pdf render entiti select unlik document pictur try name entiti recognit creat task entiti want abl label time entiti label wrong nativ pdf featur",
        "Question_gpt_summary_original":"The user is facing an issue with the Sagemaker Ground Truth PDF annotation tool, as the PDFs are not rendering and there are no entities to be selected as a part of the UI. The user has followed the documentation and created an annotation task with 37 PDFs, but the tool is not working properly. The user is trying to do named entity recognition and has created the task with 25 and 5 entities to label.",
        "Question_gpt_summary":"user face issu ground truth pdf annot tool pdf render entiti select user follow document creat annot task pdf tool work properli user try name entiti recognit creat task entiti label"
    },
    {
        "Question_title":"AWS sagemaker invokeEndpoint model internal error",
        "Question_body":"<p>I am trying to send a request on a model on sagemaker using .NET. The code I am using is: <\/p>\n\n<pre><code>var data = File.ReadAllBytes(@\"C:\\path\\file.csv\");\nvar credentials = new Amazon.Runtime.BasicAWSCredentials(\"\",\"\");\nvar awsClient = new AmazonSageMakerRuntimeClient(credentials, RegionEndpoint.EUCentral1);\nvar request = new Amazon.SageMakerRuntime.Model.InvokeEndpointRequest\n{\n    EndpointName = \"EndpointName\",\n    ContentType = \"text\/csv\",\n    Body = new MemoryStream(data),\n};\n\nvar response = awsClient.InvokeEndpoint(request);\nvar predictions = Encoding.UTF8.GetString(response.Body.ToArray());\n<\/code><\/pre>\n\n<p>the error that I am getting on <code>awsClient.InvokeEndpoint(request)<\/code><\/p>\n\n<p>is:<\/p>\n\n<blockquote>\n  <p>Amazon.SageMakerRuntime.Model.ModelErrorException: 'The service\n  returned an error with Error Code ModelError and HTTP Body:\n  {\"ErrorCode\":\"INTERNAL_FAILURE_FROM_MODEL\",\"LogStreamArn\":\"arn:aws:logs:eu-central-1:xxxxxxxx:log-group:\/aws\/sagemaker\/Endpoints\/myEndpoint\",\"Message\":\"Received\n  server error (500) from model with message \\\"\\\". See\n  \"https:\/\/ url_to_logs_on_amazon\"\n  in account xxxxxxxxxxx for more\n  information.\",\"OriginalMessage\":\"\",\"OriginalStatusCode\":500}'<\/p>\n<\/blockquote>\n\n<p>the url that the error message suggests for more information does not help at all.<\/p>\n\n<p>I believe that it is a data format issue but I was not able to find a solution.<\/p>\n\n<p>Does anyone has encountered this behavior before?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1534946906973,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":4385.0,
        "Poster_created_time":1495715386880,
        "Poster_location":null,
        "Poster_reputation_count":51.0,
        "Poster_view_count":5.0,
        "Answer_body":"<p>The problem relied on the data format as suspected. In my case all I had to do is send the data as a json serialized string array and use <code>ContentType = application\/json<\/code> because the python function running on the endpoint which is responsible for sending the data to the predictor was only accepting json strings. <\/p>\n\n<p>Another way to solve this issues is to modify the python function which is responsible for the input handling to accept all content types and modify the data in a way that the predictor will understand.<\/p>\n\n<p>example of working code for my case:<\/p>\n\n<pre><code>        var data = new string[] { \"this movie was extremely good .\", \"the plot was very boring .\" };\n        var serializedData = JsonConvert.SerializeObject(data);\n\n        var credentials = new Amazon.Runtime.BasicAWSCredentials(\"\",\"\");\n        var awsClient = new AmazonSageMakerRuntimeClient(credentials, RegionEndpoint.EUCentral1);\n        var request = new Amazon.SageMakerRuntime.Model.InvokeEndpointRequest\n        {\n            EndpointName = \"endpoint\",\n            ContentType = \"application\/json\",\n            Body = new MemoryStream(Encoding.ASCII.GetBytes(serializedData)),\n        };\n\n        var response = awsClient.InvokeEndpoint(request);\n        var predictions = Encoding.UTF8.GetString(response.Body.ToArray());\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1535104925600,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1495715386880,
        "Answerer_location":null,
        "Answerer_reputation_count":51.0,
        "Answerer_view_count":5.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51968742",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"invokeendpoint model intern error try send request model net code var data file readallbyt path file csv var credenti new amazon runtim basicawscredenti var awsclient new amazonruntimecli credenti regionendpoint eucentr var request new amazon runtim model invokeendpointrequest endpointnam endpointnam contenttyp text csv bodi new memorystream data var respons awsclient invokeendpoint request var predict encod utf getstr respons bodi toarrai error get awsclient invokeendpoint request amazon runtim model modelerrorexcept servic return error error code modelerror http bodi errorcod intern failur model logstreamarn arn aw log central xxxxxxxx log group aw endpoint myendpoint messag receiv server error model messag http url log amazon account xxxxxxxxxxx inform originalmessag originalstatuscod url error messag suggest inform help believ data format issu abl solut encount behavior",
        "Question_preprocessed_content":"model intern try send request model net code servic return code bodi url inform help believ data format abl solut encount behavior",
        "Question_gpt_summary_original":"The user is encountering an error while trying to send a request to a model on AWS Sagemaker using .NET. The error message suggests an internal failure from the model with an error code of ModelError and HTTP Body. The user suspects it to be a data format issue but is unable to find a solution.",
        "Question_gpt_summary":"user encount error try send request model net error messag suggest intern failur model error code modelerror http bodi user suspect data format issu unabl solut"
    },
    {
        "Question_title":"how can i retrain the model after a period of time",
        "Question_body":"<p>Hello everyone, i'm using lambda architecture to build a fraud detection project , i build my model using machine learning in databricks , after saving the model , i load the model in the speed layer to predict the incoming data, i want to know how can i retrain this model using new incoming data from eventhub ??  <br \/>\ndoes the retrain should be in the batch layer ?  <br \/>\nthanks for helping <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1619232734657,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/370080\/how-can-i-retrain-the-model-after-a-period-of-time",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retrain model period time hello lambda architectur build fraud detect project build model machin learn databrick save model load model speed layer predict incom data want know retrain model new incom data eventhub retrain batch layer thank help",
        "Question_preprocessed_content":"retrain model period time lambda architectur build fraud detect project build model machin learn databrick save model load model layer predict incom data want know retrain model new incom data eventhub retrain batch layer thank help",
        "Question_gpt_summary_original":"The user is building a fraud detection project using a lambda architecture and has built a model using machine learning in Databricks. They are now looking for guidance on how to retrain the model using new incoming data from Eventhub and whether the retraining should be done in the batch layer.",
        "Question_gpt_summary":"user build fraud detect project lambda architectur built model machin learn databrick look guidanc retrain model new incom data eventhub retrain batch layer"
    },
    {
        "Question_title":"Nb-replace with boolean value",
        "Question_body":"<p>I want to use guild to run a notebook as an experiment. I also want to parameterize the notebook by using guilds search and replace option with notebooks.<\/p>\n<p>One of my parameters is a boolean value. How should I define the <code>nb-replace<\/code> to work with booleans?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1646940828346,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":186.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/nb-replace-with-boolean-value\/830",
        "Tool":"Guild AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"replac boolean valu want us run notebook experi want parameter notebook search replac option notebook paramet boolean valu defin replac work boolean",
        "Question_preprocessed_content":"valu want us run experi want parameter search replac option paramet valu defin work",
        "Question_gpt_summary_original":"The user wants to use guild to run a notebook as an experiment and parameterize it using guild's search and replace option with notebooks. However, they are unsure how to define the nb-replace to work with boolean values, which is one of their parameters.",
        "Question_gpt_summary":"user want us run notebook experi parameter search replac option notebook unsur defin replac work boolean valu paramet"
    },
    {
        "Question_title":"DVC with bitbucket",
        "Question_body":"<p>I want to setup DVC on top of bitbucket instead of git. How can i do it. Can DVC integrate with bitbucket.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1564573379958,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":2236.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-with-bitbucket\/192",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"bitbucket want setup bitbucket instead git integr bitbucket",
        "Question_preprocessed_content":"bitbucket want setup bitbucket instead git integr bitbucket",
        "Question_gpt_summary_original":"The user wants to know how to set up DVC on top of Bitbucket instead of Git and if DVC can integrate with Bitbucket.",
        "Question_gpt_summary":"user want know set bitbucket instead git integr bitbucket"
    },
    {
        "Question_title":"Azure Synapse ML predict [Errno 20] Not a directory",
        "Question_body":"<p>I follow the official tutotial from microsoft: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\">https:\/\/learn.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool<\/a>    <\/p>\n<p>But when I execute:    <\/p>\n<pre><code>#Bind model within Spark session  \nmodel = pcontext.bind_model(  \n    return_types=RETURN_TYPES,   \n    runtime=RUNTIME,   \n    model_alias=&quot;Sales&quot;, #This alias will be used in PREDICT call to refer  this   model  \n    model_uri=AML_MODEL_URI, #In case of AML, it will be AML_MODEL_URI  \n    aml_workspace=ws #This is only for AML. In case of ADLS, this parameter can be removed  \n).register()  \n<\/code><\/pre>\n<p>I\u00b4ve got:    <\/p>\n<p><code>NotADirectoryError: [Errno 20] Not a directory: '\/mnt\/var\/hadoop\/tmp\/nm-local-dir\/usercache\/trusted-service-user\/appcache\/application_1648328086462_0002\/spark-3d802a7e-15b7-4eb6-88c5-f0e01f8cdb35\/userFiles-fbe23a43-67d3-4e65-a879-4a497e804b40\/68603955220f5f8646700d809b71be9949011a2476a34965a3d5c0f3d14de79b.pkl\/MLmodel'<\/code>    <br \/>\n<code>Traceback (most recent call last):<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_context.py&quot;, line 47, in bind_model<\/code>    <br \/>\n<code>udf = _create_udf(<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_udf.py&quot;, line 104, in _create_udf<\/code>    <br \/>\n<code>model_runtime = runtime_gen._create_runtime()<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py&quot;, line 103, in _create_runtime<\/code>    <br \/>\n<code>if self._check_model_runtime_compatibility(model_runtime):<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py&quot;, line 166, in _check_model_runtime_compatibility<\/code>    <br \/>\n<code>model_wrapper = self._load()<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py&quot;, line 78, in _load<\/code>    <br \/>\n<code>return SynapsePredictModelCache._get_or_load(<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_cache.py&quot;, line 172, in _get_or_load<\/code>    <br \/>\n<code>model = load_model(runtime, model_uri, functions)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py&quot;, line 257, in load_model<\/code>    <br \/>\n<code>model = loader.load(model_uri, functions)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py&quot;, line 122, in load<\/code>    <br \/>\n<code>model = self._load(model_uri)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py&quot;, line 215, in _load<\/code>    <br \/>\n<code>return self._load_mlflow(model_uri)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py&quot;, line 59, in _load_mlflow<\/code>    <br \/>\n<code>model = mlflow.pyfunc.load_model(model_uri)<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/<\/code><strong><code>init<\/code><\/strong><code>.py&quot;, line 640, in load_model<\/code>    <br \/>\n<code>model_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))<\/code>    <\/p>\n<p><code>File &quot;\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/mlflow\/models\/model.py&quot;, line 124, in load<\/code>    <br \/>\n<code>with open(path) as f:<\/code>    <\/p>\n<p><code>NotADirectoryError: [Errno 20] Not a directory: '\/mnt\/var\/hadoop\/tmp\/nm-local-dir\/usercache\/trusted-service-user\/appcache\/application_1648328086462_0002\/spark-3d802a7e-15b7-4eb6-88c5-f0e01f8cdb35\/userFiles-fbe23a43-67d3-4e65-a879-4a497e804b40\/68603955220f5f8646700d809b71be9949011a2476a34965a3d5c0f3d14de79b.pkl\/MLmodel'<\/code>    <\/p>\n<p>How can I fix that error ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1648335577807,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=6fb8f1e1-5543-4ff8-8a13-ff62f23e652f\">@Thilo Barth  <\/a>,    <\/p>\n<p>Thanks for the question and using MS Q&amp;A platform.     <\/p>\n<blockquote>\n<p>(UPDATE:29\/3\/2022): You will experiencing this error message if you model does not contains all the required files in the ML model.    <\/p>\n<\/blockquote>\n<p>As per the repro, I had created two ML models named:     <\/p>\n<blockquote>\n<p><strong>sklearn_regression_model:<\/strong> Which contains only <code>sklearn_regression_model.pkl<\/code> file.    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187737-image.png?platform=QnA\" alt=\"187737-image.png\" \/>    <\/p>\n<blockquote>\n<p>When I predict for MLFLOW packaged model named <code>sklearn_regression_model<\/code>, getting same error as shown above:    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187791-image.png?platform=QnA\" alt=\"187791-image.png\" \/>    <\/p>\n<blockquote>\n<p><strong>linear_regression<\/strong>: Which contains the below files:    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187724-image.png?platform=QnA\" alt=\"187724-image.png\" \/>    <\/p>\n<blockquote>\n<p>When I predict for MLFLOW packaged model named <code>linear_regression<\/code>, it works as excepted.    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187704-image.png?platform=QnA\" alt=\"187704-image.png\" \/>    <\/p>\n<hr \/>\n<blockquote>\n<p> It should be AML_MODEL_URI = &quot;&lt;aml model uri&gt;&quot; #In URI &quot;:x&quot;  =&gt; <code>Rossman_Sales:2<\/code>    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/187488-image.png?platform=QnA\" alt=\"187488-image.png\" \/>    <\/p>\n<blockquote>\n<p>Before running this script, update it with the URI for ADLS Gen2 data file along with model output return data type and ADLS\/AML URI for the model file.    <\/p>\n<\/blockquote>\n<pre><code>#Set model URI  \n       #Set AML URI, if trained model is registered in AML  \n          AML_MODEL_URI = &quot;&lt;aml model uri&gt;&quot; #In URI &quot;:x&quot; signifies model version in AML. You can   choose which model version you want to run. If &quot;:x&quot; is not provided then by default   latest version will be picked.  \n  \n       #Set ADLS URI, if trained model is uploaded in ADLS  \n          ADLS_MODEL_URI = &quot;abfss:\/\/&lt;filesystemname&gt;@&lt;account name&gt;.dfs.core.windows.net\/&lt;model   mlflow folder path&gt;&quot;  \n<\/code><\/pre>\n<p><strong>Model URI from AML Workspace:<\/strong>    <\/p>\n<pre><code>DATA_FILE = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv&quot;  \nAML_MODEL_URI_SKLEARN = &quot;aml:\/\/mlflow_sklearn:1&quot; #Here &quot;:1&quot; signifies model version in AML. We can choose which version we want to run. If &quot;:1&quot; is not provided then by default latest version will be picked  \nRETURN_TYPES = &quot;INT&quot;  \nRUNTIME = &quot;mlflow&quot;  \n<\/code><\/pre>\n<p><strong>Model URI uploaded to ADLS Gen2:<\/strong>    <\/p>\n<pre><code>DATA_FILE = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv&quot;  \nAML_MODEL_URI_SKLEARN = &quot;abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/linear_regression\/linear_regression&quot; #Here &quot;:1&quot; signifies model version in AML. We can choose which version we want to run. If &quot;:1&quot; is not provided then by default latest version will be picked  \nRETURN_TYPES = &quot;INT&quot;  \nRUNTIME = &quot;mlflow&quot;  \n<\/code><\/pre>\n<p>Hope this will help. Please let us know if any further queries.    <\/p>\n<p>------------------------------    <\/p>\n<ul>\n<li> Please don't forget to click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/25904\/accepted-answers.html\">how<\/a>    <\/li>\n<li> Want a reminder to come back and check responses? Here is how to subscribe to a <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/articles\/67444\/email-notifications.html\">notification<\/a>    <\/li>\n<li> If you are interested in joining the VM program and help shape the future of Q&amp;A: Here is how you can be part of <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/543261\/index.html\">Q&amp;A Volunteer Moderators<\/a>    <\/li>\n<\/ul>\n",
        "Answer_comment_count":7.0,
        "Question_closed_time":1648466772192,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/788637\/azure-synapse-ml-predict-(errno-20)-not-a-director",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"azur synaps predict errno directori follow offici tutoti microsoft http learn microsoft com azur synaps analyt machin learn tutori score model predict spark pool execut bind model spark session model pcontext bind model return type return type runtim runtim model alia sale alia predict refer model model uri aml model uri case aml aml model uri aml workspac aml case adl paramet remov regist iv got notadirectoryerror errno directori mnt var hadoop tmp local dir usercach trust servic user appcach applic spark dae fefcdb userfil fbea aeb ffdbbeaaadcfddeb pkl mlmodel traceback recent file home trust servic user cluster env env lib python site packag azur synaps predict core context line bind model udf creat udf file home trust servic user cluster env env lib python site packag azur synaps predict core udf line creat udf model runtim runtim gen creat runtim file home trust servic user cluster env env lib python site packag azur synaps predict core runtim line creat runtim self check model runtim compat model runtim file home trust servic user cluster env env lib python site packag azur synaps predict core runtim line check model runtim compat model wrapper self load file home trust servic user cluster env env lib python site packag azur synaps predict core runtim line load return synapsepredictmodelcach load file home trust servic user cluster env env lib python site packag azur synaps predict core cach line load model load model runtim model uri function file home trust servic user cluster env env lib python site packag azur synaps predict util model loader line load model model loader load model uri function file home trust servic user cluster env env lib python site packag azur synaps predict util model loader line load model self load model uri file home trust servic user cluster env env lib python site packag azur synaps predict util model loader line load return self load model uri file home trust servic user cluster env env lib python site packag azur synaps predict util model loader line load model pyfunc load model model uri file home trust servic user cluster env env lib python site packag pyfunc init line load model model meta model load path join local path mlmodel file file home trust servic user cluster env env lib python site packag model model line load open path notadirectoryerror errno directori mnt var hadoop tmp local dir usercach trust servic user appcach applic spark dae fefcdb userfil fbea aeb ffdbbeaaadcfddeb pkl mlmodel fix error",
        "Question_preprocessed_content":"azur synaps predict directori tutoti microsoft execut iv got fix",
        "Question_gpt_summary_original":"The user is following a Microsoft tutorial on Azure Synapse ML predict, but encounters a NotADirectoryError when executing a code snippet. The error message indicates that a directory is not found, and the user is seeking a solution to fix the error.",
        "Question_gpt_summary":"user follow microsoft tutori azur synaps predict encount notadirectoryerror execut code snippet error messag indic directori user seek solut fix error"
    },
    {
        "Question_title":"Tracking predictions with ml flow",
        "Question_body":"Hello all,\n\n\nTL;DR - Can you track the inference side of an ml pipeline using ml flow? if so whats the recommended way?\n\n\nI was thinking of using ml-flow-tracking to track model pipelines. ml-flow looks like a really good fit for tracking the training side, but I also want to track the prediction\/inference side. I didn't see any functionality for this built in to ml-flow.\n\n\nLet's define a \"problem\" has a single point solution that results in a model, that model will then go into production and then be used it to make batch predictions. Giving that definition, I was thinking of doing it in two ways.\nHave a single experiment per \"problem\" and a tag\/parameter that says if the run is a training or a prediction run.\nHave two experiments per problem, one for training and one for prediction. Each would get their own series of runs.\nDo either of those solutions make sense from ml flow perspective? Is one preferable?\nIs there an alternative?\nThe down side of 1) is that most of the metrics for training would be not be sent for prediction and vice versa. e.g. auc and hyper-parameters wouldn't apply to prediction, and something like mean inference score wouldn't apply to training.\nThe down side of 2) is that there is no link between training or prediction for a single problem in ml-flow. This makes it hard to compare things between the two, like comparing feature drift between training and prediction.\n\n\nLittle info that might help\n\nFor any experiment we will do multiple trainings that result in a best model.\nUsing that best model we could do one or multiple predictions.\u00a0\nWe will then repeat steps 1 and 2 every so often likely due to feature drift.\nThanks!",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1620341372000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":231.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/ru9XgXqIMCA",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"track predict flow hello track infer pipelin flow what recommend wai think flow track track model pipelin flow look like good fit track train want track predict infer function built flow let defin problem singl point solut result model model product batch predict give definit think wai singl experi problem tag paramet sai run train predict run experi problem train predict seri run solut sens flow perspect prefer altern metric train sent predict vice versa auc hyper paramet wouldn appli predict like mean infer score wouldn appli train link train predict singl problem flow make hard compar thing like compar featur drift train predict littl info help experi multipl train result best model best model multipl predict repeat step like featur drift thank",
        "Question_preprocessed_content":"track predict flow track infer pipelin flow what wai think track model pipelin like fit track train want track function built let defin problem singl point solut result model model product batch predict give definit think wai singl experi problem sai run train predict run experi problem train predict seri run solut sens flow perspect prefer altern metric train sent predict vice versa auc wouldn predict like mean infer score wouldn train link train predict singl problem make hard compar thing like compar featur drift train predict info help experi multipl train result best model best model multipl predict repeat step like featur drift thank",
        "Question_gpt_summary_original":"The user is seeking advice on how to track the inference side of an ml pipeline using ml flow. They are considering two solutions: having a single experiment per problem with a tag for training or prediction, or having two experiments per problem for training and prediction. The downside of the first solution is that metrics for training and prediction would not be sent to each other, while the downside of the second solution is that there is no link between training and prediction for a single problem in ml-flow. The user is looking for alternative solutions.",
        "Question_gpt_summary":"user seek advic track infer pipelin flow consid solut have singl experi problem tag train predict have experi problem train predict downsid solut metric train predict sent downsid second solut link train predict singl problem flow user look altern solut"
    },
    {
        "Question_title":"Confusion with resume=true",
        "Question_body":"<p>I just started using wandb,  and I wanted to train two models over the weekend on 1 GPU, but after a while one of them crashed due to lack of memory. I reduced the val batch size then added <code>resume=true<\/code> to the call to <code>wandb.init<\/code> and things started progressing. Checking in over the weekend I saw that only one run was \u201crunning\u201d, the other was \u201ccrashed\u201d. I went to look at the actual terminal session where I launched the jobs, and they were both still running.<\/p>\n<p>At this point I had 2 runs under my project, as I\u2019d deleted all the previous failed attempts. I assumed I\u2019d accidentally deleted the wrong run from the UI, but when I looked at the graphs I saw that training accuracy and loss went backwards at one epoch.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523.png\" data-download-href=\"\/uploads\/short-url\/5YiO2JPEIhGDLezHYJTY91QO9BV.png?dl=1\" title=\"Screen Shot 2022-07-18 at 5.28.13 am\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_381x500.png\" alt=\"Screen Shot 2022-07-18 at 5.28.13 am\" data-base62-sha1=\"5YiO2JPEIhGDLezHYJTY91QO9BV\" width=\"381\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_381x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_571x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_762x1000.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-07-18 at 5.28.13 am<\/span><span class=\"informations\">920\u00d71206 49.8 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>This shouldn\u2019t happen, so I went to look at the logs for the runs in MLFlow (still using it as I try out wandb) and the train accuracy for both runs was monotonically increasing. Looking closer at the actual values and the logs, I think both runs are submitting values to the same \u201crun\u201d. The graph was saying accuracy was 0.973 at epoch 6, and 0.9711 at epoch 7. Looking at my terminal logs for the most recent epoch for each run, I saw:<\/p>\n<p>point-tall-fine:  loss: 0.3797 - acc: 0.9730<br>\npoint-tall-baseline: loss: 0.3842 - acc: 0.9711<\/p>\n<p>Scrolling up to the top of each log, I see both are using <code>runs\/ajydp67n<\/code>. I\u2019m guessing  this is because I didn\u2019t specify anything other than config when calling init,  does wandb not disambiguate runs based on the value of <code>config<\/code>?<\/p>\n<p><code>wandb.init(config=wandb_args, resume=True)<\/code><\/p>",
        "Question_answer_count":6,
        "Question_comment_count":null,
        "Question_created_time":1658088070757,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":122.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/confusion-with-resume-true\/2765",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"confus resum true start want train model weekend gpu crash lack memori reduc val batch size ad resum true init thing start progress check weekend saw run run crash went look actual termin session launch job run point run project delet previou fail attempt assum accident delet wrong run look graph saw train accuraci loss went backward epoch screen shot shouldnt happen went look log run try train accuraci run monoton increas look closer actual valu log think run submit valu run graph sai accuraci epoch epoch look termin log recent epoch run saw point tall fine loss acc point tall baselin loss acc scroll log run ajydpn guess didnt specifi config call init disambigu run base valu config init config arg resum true",
        "Question_preprocessed_content":"confus resum true start want train model gpu crash lack memori reduc val batch size thing start check saw run crash went actual termin launch job point run project delet previou fail delet wrong run graph saw train went backward epoch shot shouldnt went log run train run increas closer actual valu log think run valu run graph sai epoch epoch termin log recent epoch run saw log didnt specifi config init disambigu run base valu",
        "Question_gpt_summary_original":"The user encountered confusion with the use of resume=true in wandb while training two models on one GPU. One of the models crashed due to lack of memory, and after reducing the val batch size and adding resume=true, only one run was \"running\" while the other was \"crashed\". However, checking the terminal session showed that both runs were still running. The user discovered that both runs were submitting values to the same \"run\" and had the same run ID, possibly because wandb did not disambiguate runs based on the value of config.",
        "Question_gpt_summary":"user encount confus us resum true train model gpu model crash lack memori reduc val batch size ad resum true run run crash check termin session show run run user discov run submit valu run run possibl disambigu run base valu config"
    },
    {
        "Question_title":"How to input data from S3 Bucket to Amazon Sagemaker",
        "Question_body":"<p>I would like to input data(Caltech 256 dataset) from Amazon s3 to sagemaker. I am doing this because I would like to modify the dataset if I can get this to work. Any ideas?<\/p>\n\n<p>Tried using the pandas code from 'Load S3 Data into AWS SageMaker Notebook'<\/p>\n\n<p>I hope the data from the S3 bucket will work just like downloading straight from the url. Obviously it isn't working.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1553891985250,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1613286737432,
        "Question_score_count":0.0,
        "Question_view_count":194.0,
        "Poster_created_time":1553873252896,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55425199",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"input data bucket like input data caltech dataset amazon like modifi dataset work idea tri panda code load data notebook hope data bucket work like download straight url obvious isn work",
        "Question_preprocessed_content":"input data bucket like input data amazon like modifi dataset work idea tri panda code load data hope data bucket work like download straight url obvious isn work",
        "Question_gpt_summary_original":"The user is facing challenges in inputting data from an Amazon S3 bucket to Amazon Sagemaker, specifically the Caltech 256 dataset. They have attempted to use pandas code from 'Load S3 Data into AWS SageMaker Notebook', but it is not working as expected. The user hopes that the data from the S3 bucket will work similarly to downloading it directly from the URL.",
        "Question_gpt_summary":"user face challeng input data amazon bucket specif caltech dataset attempt us panda code load data notebook work expect user hope data bucket work similarli download directli url"
    },
    {
        "Question_title":"Timing test on azure ml",
        "Question_body":"<p>I have created data sets of various sizes say 1GB, 2GB, 3GB, 4GB (&lt; 10 GB) and executing various machine learning models on Azure ML. <\/p>\n\n<p>1) Can I know what is the server specifications (RAM, CPU) that is provided in the Azure ML service.<\/p>\n\n<p>2) Also at times the reader says \"Memory exhaust\" for >4GB of data.Though azure ml should be able to handle 10GB of data as per documentation.<\/p>\n\n<p>3) If I run multiple experiments(in different tabs of browser) in parallel, its taking more time.<\/p>\n\n<p>4) Is there any way to set the RAM, CPU cores in Azure ML<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4.0,
        "Question_created_time":1456387015953,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1457425395532,
        "Question_score_count":5.0,
        "Question_view_count":155.0,
        "Poster_created_time":1456386494000,
        "Poster_location":"Dubai - United Arab Emirates",
        "Poster_reputation_count":51.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35621424",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"time test creat data set size data abl handl data document run multipl experi differ tab browser parallel take time wai set ram cpu core",
        "Question_preprocessed_content":"time test creat data set size execut machin learn model know server specif provid servic time reader sai memori exhaust abl handl data document run multipl experi take time wai set ram cpu core",
        "Question_gpt_summary_original":"The user has encountered challenges while executing various machine learning models on Azure ML. They are unsure about the server specifications provided by Azure ML and have faced \"Memory exhaust\" errors while working with data sets larger than 4GB. The user has also observed that running multiple experiments in parallel takes more time and is looking for a way to set the RAM and CPU cores in Azure ML.",
        "Question_gpt_summary":"user encount challeng execut machin learn model unsur server specif provid face memori exhaust error work data set larger user observ run multipl experi parallel take time look wai set ram cpu core"
    },
    {
        "Question_title":"Tenserflow model not detecting plants correctly",
        "Question_body":"Hi there,\n\nWe are using AutoML skd with Tenserflow model (https:\/\/tfhub.dev\/google\/lite-model\/aiy\/vision\/classifier\/plants_V1\/3) for detecting plants. The model return results, but they are not accurate. I wanted to see if there are any pre-trained TenserFlow models for detecting plant type? Similar to plant.id.\u00a0\n\nThanks",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1658900100000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":87.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Tenserflow-model-not-detecting-plants-correctly\/m-p\/447276#M449",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tenserflow model detect plant correctli automl skd tenserflow model http tfhub dev googl lite model aii vision classifi plant detect plant model return result accur want pre train tenserflow model detect plant type similar plant thank",
        "Question_preprocessed_content":"tenserflow model detect plant automl skd tenserflow model detect plant model return result want tenserflow model detect plant type similar thank",
        "Question_gpt_summary_original":"The user is facing challenges with the accuracy of the Tenserflow model used for detecting plants. They are seeking information on pre-trained TenserFlow models for detecting plant types.",
        "Question_gpt_summary":"user face challeng accuraci tenserflow model detect plant seek inform pre train tenserflow model detect plant type"
    },
    {
        "Question_title":"is sagemaker today broken - domain can not be created more then 1 hour",
        "Question_body":"at \nConfigure SageMaker Domain\n\nthere is rotating circle , and there is no access to sagemkeer coding",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1683324178726,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1683672431504,
        "Question_score_count":0.0,
        "Question_view_count":39.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUeVsa1GAHQWenTTySX6JVQg\/is-sagemaker-today-broken-domain-can-not-be-created-more-then-1-hour",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"todai broken domain creat hour configur domain rotat circl access sagemk code",
        "Question_preprocessed_content":"todai broken domain creat hour configur domain rotat circl code",
        "Question_gpt_summary_original":"The user is facing an issue with SageMaker where they are unable to create a domain for more than an hour and are unable to access SageMaker coding due to a rotating circle.",
        "Question_gpt_summary":"user face issu unabl creat domain hour unabl access code rotat circl"
    },
    {
        "Question_title":"Is there a way to pass arguments to multiple jobs in optuna?",
        "Question_body":"<p>I am trying to use optuna for searching hyper parameter spaces.<\/p>\n\n<p>In one particular scenario I train a model on a machine with a few GPUs.\nThe model and batch size allows me to run 1 training per 1 GPU.\nSo, ideally I would like to let optuna spread all trials across the available GPUs\nso that there is always 1 trial running on each GPU.<\/p>\n\n<p>In the <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/faq.html#how-can-i-use-two-gpus-for-evaluating-two-trials-simultaneously\" rel=\"nofollow noreferrer\">docs<\/a> it says, I should just start one process per GPU in a separate terminal like:<\/p>\n\n<pre><code>CUDA_VISIBLE_DEVICES=0 optuna study optimize foo.py objective --study foo --storage sqlite:\/\/\/example.db\n<\/code><\/pre>\n\n<p>I want to avoid that because the whole hyper parameter search continues in multiple rounds after that. I don't want to always manually start a process per GPU, check when all are finished, then start the next round.<\/p>\n\n<p>I saw <code>study.optimize<\/code> has a <code>n_jobs<\/code> argument.\nAt first glance this seems to be perfect.\n<em>E.g.<\/em> I could do this:<\/p>\n\n<pre><code>import optuna\n\ndef objective(trial):\n    # the actual model would be trained here\n    # the trainer here would need to know which GPU\n    # it should be using\n    best_val_loss = trainer(**trial.params)\n    return best_val_loss\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=100, n_jobs=8)\n<\/code><\/pre>\n\n<p>This starts multiple threads each starting a training.\nHowever, the trainer within <code>objective<\/code> somehow needs to know which GPU it should be using.\nIs there a trick to accomplish that?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1589323176827,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":2684.0,
        "Poster_created_time":1447522907212,
        "Poster_location":"Berlin, Germany",
        "Poster_reputation_count":758.0,
        "Poster_view_count":95.0,
        "Answer_body":"<p>After a few mental breakdowns I figured out that I can do what I want using a <code>multiprocessing.Queue<\/code>. To get it into the objective function I need to define it as a lambda function or as a class (I guess partial also works). <em>E.g.<\/em><\/p>\n\n<pre><code>from contextlib import contextmanager\nimport multiprocessing\nN_GPUS = 2\n\nclass GpuQueue:\n\n    def __init__(self):\n        self.queue = multiprocessing.Manager().Queue()\n        all_idxs = list(range(N_GPUS)) if N_GPUS &gt; 0 else [None]\n        for idx in all_idxs:\n            self.queue.put(idx)\n\n    @contextmanager\n    def one_gpu_per_process(self):\n        current_idx = self.queue.get()\n        yield current_idx\n        self.queue.put(current_idx)\n\n\nclass Objective:\n\n    def __init__(self, gpu_queue: GpuQueue):\n        self.gpu_queue = gpu_queue\n\n    def __call__(self, trial: Trial):\n        with self.gpu_queue.one_gpu_per_process() as gpu_i:\n            best_val_loss = trainer(**trial.params, gpu=gpu_i)\n            return best_val_loss\n\nif __name__ == '__main__':\n    study = optuna.create_study()\n    study.optimize(Objective(GpuQueue()), n_trials=100, n_jobs=8)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1589464897583,
        "Answer_last_edit_time":null,
        "Answer_score_count":6.0,
        "Answerer_created_time":1447522907212,
        "Answerer_location":"Berlin, Germany",
        "Answerer_reputation_count":758.0,
        "Answerer_view_count":95.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61763206",
        "Tool":"Optuna",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wai pass argument multipl job try us search hyper paramet space particular scenario train model machin gpu model batch size allow run train gpu ideal like let spread trial avail gpu trial run gpu doc sai start process gpu separ termin like cuda visibl devic studi optim foo object studi foo storag sqlite exampl want avoid hyper paramet search continu multipl round want manual start process gpu check finish start round saw studi optim job argument glanc perfect import def object trial actual model train trainer need know gpu best val loss trainer trial param return best val loss studi creat studi studi optim object trial job start multipl thread start train trainer object need know gpu trick accomplish",
        "Question_preprocessed_content":"wai argument multipl job try us search hyper paramet space particular scenario train model machin gpu model batch size run train gpu like let spread trial avail gpu trial gpu doc sai start gpu separ termin like want avoid hyper paramet search continu multipl round want start gpu check finish start round saw argument glanc perfect start multipl thread start train trainer know gpu trick",
        "Question_gpt_summary_original":"The user is trying to use optuna for hyperparameter search and wants to spread all trials across available GPUs. The documentation suggests starting one process per GPU in a separate terminal, but the user wants to avoid that. The user has tried using the `n_jobs` argument in `study.optimize` to start multiple threads, but the trainer within `objective` needs to know which GPU to use. The user is looking for a way to pass arguments to multiple jobs in optuna.",
        "Question_gpt_summary":"user try us hyperparamet search want spread trial avail gpu document suggest start process gpu separ termin user want avoid user tri job argument studi optim start multipl thread trainer object need know gpu us user look wai pass argument multipl job"
    },
    {
        "Question_title":"Is there way to fix CSV reading in Russian Language in Azure ML Studio?",
        "Question_body":"<p>I have a large csv file containing some text in Russian language. When I upload it to Azure ML Studio as dataset, it appears like \"\ufffd\ufffd\ufffd\ufffd\". What I can do to fix that problem?<\/p>\n\n<p>I tried changing encoding of my text to UTF8, KOI8-R.<\/p>\n\n<p>There is no code, but I can share part of the dataset for you to try.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1565669343940,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":141.0,
        "Poster_created_time":1565668918750,
        "Poster_location":"Nur-Sultan, Kazakhstan",
        "Poster_reputation_count":11.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57471007",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wai fix csv read russian languag studio larg csv file contain text russian languag upload studio dataset appear like fix problem tri chang encod text utf koi code share dataset try",
        "Question_preprocessed_content":"wai fix csv read languag studio larg csv file contain text languag upload studio dataset like fix problem tri chang encod text utf code share dataset try",
        "Question_gpt_summary_original":"The user is facing an issue with CSV reading in Russian language in Azure ML Studio. When the user uploads the file, the text appears as \"\ufffd\ufffd\ufffd\ufffd\". The user has tried changing the encoding to UTF8 and KOI8-R but the problem persists.",
        "Question_gpt_summary":"user face issu csv read russian languag studio user upload file text appear user tri chang encod utf koi problem persist"
    },
    {
        "Question_title":"How to using client to upload data\/artifacts to s3 bucket?",
        "Question_body":"How to use the client to upload data\/artifacts to the s3 bucket?",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1665738037000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1516",
        "Tool":"Polyaxon",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"client upload data artifact bucket us client upload data artifact bucket",
        "Question_preprocessed_content":"client upload bucket us client upload bucket",
        "Question_gpt_summary_original":"The user is seeking guidance on how to use a client to upload data or artifacts to an S3 bucket.",
        "Question_gpt_summary":"user seek guidanc us client upload data artifact bucket"
    },
    {
        "Question_title":"Timeout on AutoMLConfig is not a hard timeout",
        "Question_body":"<p>When setting the timeout on the AutoMLConfig, it is not respected. Why?     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110022-screenshot-2021-06-28-at-214112.png?platform=QnA\" alt=\"110022-screenshot-2021-06-28-at-214112.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110031-screenshot-2021-06-28-at-212944.png?platform=QnA\" alt=\"110031-screenshot-2021-06-28-at-212944.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1624927301677,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/455257\/timeout-on-automlconfig-is-not-a-hard-timeout",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"timeout automlconfig hard timeout set timeout automlconfig respect",
        "Question_preprocessed_content":"timeout automlconfig hard timeout timeout automlconfig respect",
        "Question_gpt_summary_original":"The user is facing an issue where the timeout set on the AutoMLConfig is not being respected.",
        "Question_gpt_summary":"user face issu timeout set automlconfig respect"
    },
    {
        "Question_title":"Running scripts from a datastore on Azure Machine Learning Service",
        "Question_body":"<p>I am migrating from Batch AI to the new Azure Machine Learning Service. Previously I had my python scripts on an Azure Files share and those scripts ran directly from there.<\/p>\n\n<p>In the new service when you create an Estimator you have to provide a source directory and an entry script. The documentation states the source directory is a local directory that is copied to the remote computer.<\/p>\n\n<p>However, the Estimator constructor also allows you to specify a datastore name that is supposed to specify the datastore for the project share.<\/p>\n\n<p>To me, this sounds like you can specify a datastore and then the source directory is relative to that however this does not work, it still wants to find the source directory on the local machine.<\/p>\n\n<pre><code>tf_est = TensorFlow(source_directory='.\/script',\n                source_directory_data_store=ds,\n                script_params=script_params,\n                compute_target=compute_target,\n                entry_script='helloworld.py',\n                use_gpu=False)\n<\/code><\/pre>\n\n<p>Does anybody know if its possible to run a training job using a datastore for execution?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1548806606603,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1554813331196,
        "Question_score_count":2.0,
        "Question_view_count":141.0,
        "Poster_created_time":1336005137536,
        "Poster_location":null,
        "Poster_reputation_count":752.0,
        "Poster_view_count":117.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54431484",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run script datastor servic migrat batch new servic previous python script azur file share script ran directli new servic creat estim provid sourc directori entri script document state sourc directori local directori copi remot estim constructor allow specifi datastor suppos specifi datastor project share sound like specifi datastor sourc directori rel work want sourc directori local machin est tensorflow sourc directori script sourc directori data store script param script param comput target comput target entri script helloworld us gpu fals anybodi know possibl run train job datastor execut",
        "Question_preprocessed_content":"script datastor servic migrat batch new servic previous python script azur file share script ran directli new servic creat estim provid sourc directori entri script document state sourc directori local directori copi remot estim constructor specifi datastor specifi datastor project share sound like specifi datastor sourc directori rel work want sourc directori local machin anybodi know run train job datastor execut",
        "Question_gpt_summary_original":"The user is facing challenges while migrating from Batch AI to Azure Machine Learning Service. They are unable to run python scripts from a datastore on the new service. Although the Estimator constructor allows specifying a datastore name, the source directory is still expected to be on the local machine. The user is seeking help to run a training job using a datastore for execution.",
        "Question_gpt_summary":"user face challeng migrat batch servic unabl run python script datastor new servic estim constructor allow specifi datastor sourc directori expect local machin user seek help run train job datastor execut"
    },
    {
        "Question_title":"Deploying the sagemaker endpoint created as a service",
        "Question_body":"<p>I have trained a credit-fraud data set on AWS Sagemaker and created an endpoint of the model. Suppose I want to provide it as a service to my friend. He has some credit data and wanted to know whether the transaction is fraud or not. He wishes to use my endpoint. How do I share it?<\/p>\n\n<ol>\n<li>Should I share my ARN for endpoint? I don't think its the right way. without a common account he won't be able to use it.<\/li>\n<li>Or is there another way<\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1573479066647,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":226.0,
        "Poster_created_time":1568318861627,
        "Poster_location":"Hyderabad, Telangana, India",
        "Poster_reputation_count":486.0,
        "Poster_view_count":75.0,
        "Answer_body":"<p>To share your model as an endpoint, you should use lambda and API Gateway to create your API.<\/p>\n\n<ol>\n<li>Create an API gateway that triggers a Lambda with the HTTP POST method;<\/li>\n<li>your lambda should instantiate the SageMaker endpoint, get the requested parameter in the event, call the SageMaker endpoint and return the predicted value. you can also create a DynamoDB to store commonly requested parameters with their answers;<\/li>\n<li>Send the API Gateway Endpoint to your friend.<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/qLss4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qLss4.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1573653626700,
        "Answer_last_edit_time":1573654268900,
        "Answer_score_count":6.0,
        "Answerer_created_time":1464391892936,
        "Answerer_location":"Rio de Janeiro, State of Rio de Janeiro, Brazil",
        "Answerer_reputation_count":2243.0,
        "Answerer_view_count":148.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58802366",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi endpoint creat servic train credit fraud data set creat endpoint model suppos want provid servic friend credit data want know transact fraud wish us endpoint share share arn endpoint think right wai common account won abl us wai",
        "Question_preprocessed_content":"deploi endpoint creat servic train data set creat endpoint model want provid servic friend credit data want know transact fraud wish us endpoint share share arn endpoint think right wai won abl us wai",
        "Question_gpt_summary_original":"The user has trained a credit-fraud dataset on AWS Sagemaker and created an endpoint of the model. They want to share it with a friend who has some credit data and wants to know whether the transaction is fraud or not. The user is unsure of the correct way to share the endpoint and is considering sharing their ARN, but believes it may not be the right way. They are seeking advice on alternative methods.",
        "Question_gpt_summary":"user train credit fraud dataset creat endpoint model want share friend credit data want know transact fraud user unsur correct wai share endpoint consid share arn believ right wai seek advic altern method"
    },
    {
        "Question_title":"Imbalance DataSet for Tabular AutoML",
        "Question_body":"Hi, I would like to know if in case of having a tabular database,\u00a0 with binary data (class 0 and Class 1), that has an imbalance between class 0 and class 1, as it occurs in scenarios of fraud in financial transactions.\n\nDoes AutoML solves automatically the imbalance situation? Or is it possible to add SMOTE or ADASYN to the AutoML model?\u00a0 Any comments to advice more than appreciated",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1650277560000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":341.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Imbalance-DataSet-for-Tabular-AutoML\/m-p\/414630#M278",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"imbal dataset tabular automl like know case have tabular databas binari data class class imbal class class occur scenario fraud financi transact automl solv automat imbal situat possibl add smote adasyn automl model comment advic appreci",
        "Question_preprocessed_content":"imbal dataset tabular automl like know case have tabular databas binari data imbal scenario fraud financi transact automl solv imbal situat smote adasyn automl model advic",
        "Question_gpt_summary_original":"The user is seeking advice on whether AutoML can automatically solve the issue of imbalanced data in a tabular database with binary data, specifically in scenarios of fraud in financial transactions. They also inquire about the possibility of adding SMOTE or ADASYN to the AutoML model.",
        "Question_gpt_summary":"user seek advic automl automat solv issu imbalanc data tabular databas binari data specif scenario fraud financi transact inquir possibl ad smote adasyn automl model"
    },
    {
        "Question_title":"Working with a small subset of remote data",
        "Question_body":"<p>Hi,<\/p>\n<p>I\u2019m trying to use DVC for managing data produced from simulations.  Each simulation produces a large number of small files, and a few very large files.  I have worked out how to set up a git repository with DVC and add the data (one .dvc file per simulation), and also how to push it to remote storage.  There are too many files to have one .dvc file per file. I think this is known as the \u201cdata registry\u201d use case.<\/p>\n<p>I then want to start a new project and work on, say, one of the simulations.<br>\nI think what I want to do is to \u201cdvc import\u201d the simulation data directory into the new project.  This works, and I can import just a single simulation.  However, I would like to be able to get just a small subset of the files within a simulation, without downloading the whole simulation.<\/p>\n<p>I think what I want to be able to do is to \u201cdvc import\u201d but tell it <em>not<\/em> to actually fetch the data, and then be able to tell it which files under the simulation I want to fetch.<\/p>\n<p>Is such a thing possible?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1604100899517,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1078.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/working-with-a-small-subset-of-remote-data\/541",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"work small subset remot data try us manag data produc simul simul produc larg number small file larg file work set git repositori add data file simul push remot storag file file file think known data registri us case want start new project work simul think want import simul data directori new project work import singl simul like abl small subset file simul download simul think want abl import tell actual fetch data abl tell file simul want fetch thing possibl",
        "Question_preprocessed_content":"work subset remot data try us manag data produc simul simul produc larg number file larg file work set git repositori data push remot storag file file file think known data registri us case want start new project work simul think want import simul data directori new project work import singl simul like abl subset file simul download simul think want abl import fetch data abl file simul want fetch thing",
        "Question_gpt_summary_original":"The user is trying to use DVC for managing data produced from simulations, which produces a large number of small files and a few very large files. They have set up a git repository with DVC and added the data, but there are too many files to have one .dvc file per file. The user wants to import a small subset of files within a simulation without downloading the whole simulation and is looking for a way to tell DVC not to fetch the data and then be able to specify which files to fetch.",
        "Question_gpt_summary":"user try us manag data produc simul produc larg number small file larg file set git repositori ad data file file file user want import small subset file simul download simul look wai tell fetch data abl specifi file fetch"
    },
    {
        "Question_title":"DVC run and add: store command and data",
        "Question_body":"<p>Hi,<\/p>\n<p>I would like to know whether we could store run info for reproducibility and add output data to a storage that can be than pulled.<br>\nFor example, I have a raw dataset and a cleanup script<\/p>\n<pre><code class=\"lang-auto\">$ ls \nraw cleanup.py\n<\/code><\/pre>\n<p>I can run the cleanup<\/p>\n<pre><code class=\"lang-auto\">$ dvc run -d raw -o clean python cleanup.py raw clean\n$ cat clean.dvc\ncmd: python cleanup.py\ndeps:\n- md5: xxxx\n  path: raw\nmd5: yyyyy\nouts:\n- cache: true\n  md5: zzzz\n  path: clean\n<\/code><\/pre>\n<p>and I observe how clean folder is produced. However if I add clean folder with dvc in order to share it the information on how to produce clean folder is modifed<\/p>\n<pre><code class=\"lang-auto\">$ dvc add clean\n$ cat clean.dvc\nmd5: xxxx\nouts:\n- cache: true\n   md5: xxxxx\n<\/code><\/pre>\n<p>So, can we have both features : stored command on how dataset can be produced and is stored in the cache ?<\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1534263237672,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":532.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-run-and-add-store-command-and-data\/68",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run add store command data like know store run info reproduc add output data storag pull exampl raw dataset cleanup script raw cleanup run cleanup run raw clean python cleanup raw clean cat clean cmd python cleanup dep xxxx path raw yyyyi out cach true zzzz path clean observ clean folder produc add clean folder order share inform produc clean folder modif add clean cat clean xxxx out cach true xxxxx featur store command dataset produc store cach thank",
        "Question_preprocessed_content":"run store data like know store run info reproduc output data storag exampl raw dataset cleanup script run cleanup observ clean folder produc clean folder order share inform produc clean folder modif featur store dataset produc store cach thank",
        "Question_gpt_summary_original":"The user is asking if it is possible to store run information for reproducibility and add output data to a storage that can be pulled. They have provided an example of running a cleanup script and observing how the clean folder is produced. However, when they add the clean folder with DVC in order to share it, the information on how to produce the clean folder is modified. The user is asking if it is possible to have both features: stored command on how the dataset can be produced and stored in the cache.",
        "Question_gpt_summary":"user ask possibl store run inform reproduc add output data storag pull provid exampl run cleanup script observ clean folder produc add clean folder order share inform produc clean folder modifi user ask possibl featur store command dataset produc store cach"
    },
    {
        "Question_title":"Wandb Project table value select algorithm",
        "Question_body":"<p>I have a wondering how to select value in project table.<br>\nWhat is algorithm in wandb project table to select values? In images, these values is not minimum in each models.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da.png\" data-download-href=\"\/uploads\/short-url\/bJn70ylkOmBrf45BJzAwLO3FLIe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png\" alt=\"image\" data-base62-sha1=\"bJn70ylkOmBrf45BJzAwLO3FLIe\" width=\"690\" height=\"99\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1035x148.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1380x198.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">2478\u00d7358 42.7 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1650599811340,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":510.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-project-table-value-select-algorithm\/2300",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"project tabl valu select algorithm wonder select valu project tabl algorithm project tabl select valu imag valu minimum model imag",
        "Question_preprocessed_content":"project tabl valu select algorithm wonder select valu project tabl algorithm project tabl select valu imag valu minimum model imag",
        "Question_gpt_summary_original":"The user is seeking information about the algorithm used in Wandb project table to select values, as the values shown in the images are not the minimum in each model.",
        "Question_gpt_summary":"user seek inform algorithm project tabl select valu valu shown imag minimum model"
    },
    {
        "Question_title":"Delete failed and cancelled runs automatically regularly in AzureML experiments",
        "Question_body":"<p>Hi all, AzureML experiments excellently helps us sort our runs.  <br \/>\nThere are atleast daily 100 runs or more in our workspace. Some of these runs fail. I was wondering if there is a way in AzureML to automatically delete the failed runs, because now we have to manually delete them which is not feasible everytime.  <br \/>\nI am aware of Azure LCM, but was wondering if something similar exists to manage our failed runs or any runs that does not have a 'completed' status.  <br \/>\nAny lead would be helpful.  <\/p>\n<p>Thanks :)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1641907647207,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/690810\/delete-failed-and-cancelled-runs-automatically-reg",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"delet fail cancel run automat regularli experi experi excel help sort run atleast daili run workspac run fail wonder wai automat delet fail run manual delet feasibl everytim awar azur lcm wonder similar exist manag fail run run complet statu lead help thank",
        "Question_preprocessed_content":"delet fail run regularli experi experi help sort run atleast daili run workspac run fail wonder wai delet fail run delet feasibl everytim awar azur lcm wonder similar exist manag fail run run complet statu lead help thank",
        "Question_gpt_summary_original":"The user is facing challenges in managing failed runs in AzureML experiments as there are at least 100 runs daily and manually deleting them is not feasible. They are looking for a way to automatically delete failed runs or any runs that do not have a 'completed' status. The user is seeking any leads or suggestions to manage this issue.",
        "Question_gpt_summary":"user face challeng manag fail run experi run daili manual delet feasibl look wai automat delet fail run run complet statu user seek lead suggest manag issu"
    },
    {
        "Question_title":"Unable To Run AzureML Experiment with SDK - Failed to Build Wheel for pynacl \/ Exit status:1",
        "Question_body":"<p>I am trying to run a AzureML Experiment using sdk (following a Udemy course). When I try to use the Experiment.submit function the experiment prepares and then fails with the following error messages:<\/p>\n<pre><code>ERROR: Command errored out with exit status 1 \n\nERROR: Failed building wheel for pynacl\nERROR: Could not build wheels for pynacl which use PEP 517 and cannot be installed directly\n<\/code><\/pre>\n<p>The Azure env as created within my anaconda navigator for a short period of time and then gets removed.<\/p>\n<p>Does anyone know how I can get around this? Any help would be really appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1649943158360,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1650357451940,
        "Question_score_count":0.0,
        "Question_view_count":73.0,
        "Poster_created_time":1603536549848,
        "Poster_location":null,
        "Poster_reputation_count":51.0,
        "Poster_view_count":7.0,
        "Answer_body":"<p>To resolve <code>ERROR: Could not build wheels for pynacl which use PEP 517 and cannot be installed directly<\/code> this error, try either of the following ways:<\/p>\n<ol>\n<li><p>Install missing dependencies:<\/p>\n<pre><code>sudo apt install libpython3-dev build-essential\n<\/code><\/pre>\n<\/li>\n<li><p>Upgrade pip:<\/p>\n<pre><code>pip3 install --upgrade pip\n<\/code><\/pre>\n<\/li>\n<li><p>Upgrade pip with setuptools wheel:<\/p>\n<pre><code>pip3 install --upgrade pip setuptools wheel\n<\/code><\/pre>\n<\/li>\n<li><p>Reinstall PEP517:<\/p>\n<pre><code>pip3 install p5py\npip3 install PEP517\n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>You can refer to  <a href=\"https:\/\/stackoverflow.com\/questions\/61365790\/error-could-not-build-wheels-for-scipy-which-use-pep-517-and-cannot-be-installe\">ERROR: Could not build wheels for scipy which use PEP 517 and cannot be installed directly<\/a>, <a href=\"https:\/\/stackoverflow.com\/questions\/64038673\/could-not-build-wheels-for-which-use-pep-517-and-cannot-be-installed-directly\">Could not build wheels for _ which use PEP 517 and cannot be installed directly - Easy Solution<\/a> and <a href=\"https:\/\/github.com\/martomi\/chiadog\/issues\/44\" rel=\"nofollow noreferrer\">failed building wheel for pynacl<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1650257274672,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1517548787092,
        "Answerer_location":null,
        "Answerer_reputation_count":1925.0,
        "Answerer_view_count":3530.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71872506",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl run experi sdk fail build wheel pynacl exit statu try run experi sdk follow udemi cours try us experi submit function experi prepar fail follow error messag error command error exit statu error fail build wheel pynacl error build wheel pynacl us pep instal directli azur env creat anaconda navig short period time get remov know help appreci",
        "Question_preprocessed_content":"unabl run experi sdk fail build pynacl exit statu try run experi sdk try us function experi prepar fail azur env creat anaconda navig short period time get remov know help",
        "Question_gpt_summary_original":"The user is unable to run an AzureML experiment using SDK and is encountering an error message \"Failed building wheel for pynacl\". The Azure environment created within Anaconda Navigator is getting removed after a short period of time. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":"user unabl run experi sdk encount error messag fail build wheel pynacl azur environ creat anaconda navig get remov short period time user seek help resolv issu"
    },
    {
        "Question_title":"Endpoints for getting metadata about published models?",
        "Question_body":"<p>My question centers around working with AML models that have been published as web services, as described here:    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal<\/a>    <\/p>\n<p>Are there any endpoints or ways of obtaining more detailed information about a published model? For example, the documentation states that inputs to the model are passed in via a &quot;data&quot; property, and obviously, this will vary my the model:    <\/p>\n<p>{    <br \/>\n    &quot;data&quot;:  <br \/>\n        [  <br \/>\n            &lt;model-specific-data-structure&gt;  <br \/>\n        ]  <br \/>\n}    <\/p>\n<p>Is there a way to programatically find out what the model expects as input?     <\/p>\n<p>The full 'wish-list' of metadata info we'd like is listed here:     <\/p>\n<ul>\n<li> What models are available for serving    <\/li>\n<li> What is the model prediction endpoint    <\/li>\n<li> What are the required inputs and their data types    <\/li>\n<li> What are the model outputs and data types    <\/li>\n<\/ul>\n<p>Are there any endpoints or any way at getting to this information?    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1649425228733,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=32325e98-f4ed-442a-83f3-7d1edc203dea\">@MK RP  <\/a>    <\/p>\n<p>Thanks for reaching out to us, I will answer your question below, at the meantime, if you feel like I am not getting your point well, please point it out and correct me.    <\/p>\n<p>I think you are mentioning how to monitor published model and collect data, there are several choice depends on the data you want to collect:    <\/p>\n<ol>\n<li> Collect data from models in production - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-data-collection\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-data-collection<\/a>    <\/li>\n<\/ol>\n<p>The following data can be collected:    <\/p>\n<p><strong>Model input data<\/strong> from web services deployed in an AKS cluster. Voice audio, images, and video are not collected.    <br \/>\n<strong>Model predictions<\/strong> using production input data.    <\/p>\n<p>Once collection is enabled, the data you collect helps you:    <\/p>\n<p>Monitor data drifts on the production data you collect.    <br \/>\nAnalyze collected data using Power BI or Azure Databricks    <br \/>\nMake better decisions about when to retrain or optimize your model.    <br \/>\nRetrain your model with the collected data.    <\/p>\n<p>2 . Monitor and collect data from ML web service endpoints - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-app-insights\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-app-insights<\/a>    <\/p>\n<p>You can use Azure Application Insights to collect the following data from an endpoint:    <\/p>\n<p>Output data    <br \/>\nResponses    <br \/>\nRequest rates, response times, and failure rates    <br \/>\nDependency rates, response times, and failure rates    <br \/>\nExceptions    <\/p>\n<p>3 . More details from Data Drift - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python<\/a>    <\/p>\n<p>With Azure Machine Learning dataset monitors (preview), you can:    <\/p>\n<p>Analyze drift in your data to understand how it changes over time.    <br \/>\nMonitor model data for differences between training and serving datasets. Start by collecting model data from deployed models.    <br \/>\nMonitor new data for differences between any baseline and target dataset.    <br \/>\nProfile features in data to track how statistical properties change over time.    <br \/>\nSet up alerts on data drift for early warnings to potential issues.    <br \/>\nCreate a new dataset version when you determine the data has drifted too much.    <\/p>\n<p>Hope above information helps, please let us know if you need further helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks a lot.<\/em>    <\/p>\n",
        "Answer_comment_count":6.0,
        "Question_closed_time":1649630016347,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/805976\/endpoints-for-getting-metadata-about-published-mod",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"endpoint get metadata publish model question center work aml model publish web servic describ http learn microsoft com azur machin learn consum web servic tab azur portal endpoint wai obtain detail inform publish model exampl document state input model pass data properti obvious vari model data wai programat model expect input wish list metadata info like list model avail serv model predict endpoint requir input data type model output data type endpoint wai get inform",
        "Question_preprocessed_content":"endpoint metadata publish model question center work aml model publish web servic describ endpoint wai obtain detail inform publish model exampl document state input model data properti obvious vari model data wai model expect input metadata info like list model avail serv model predict endpoint requir input data type model output data type endpoint wai inform",
        "Question_gpt_summary_original":"The user is seeking information about obtaining more detailed metadata about published AML models, including the available models for serving, the model prediction endpoint, required inputs and their data types, and model outputs and data types. They are asking if there are any endpoints or ways to programmatically find out what the model expects as input.",
        "Question_gpt_summary":"user seek inform obtain detail metadata publish aml model includ avail model serv model predict endpoint requir input data type model output data type ask endpoint wai programmat model expect input"
    },
    {
        "Question_title":"Sagemaker Studio UnkownServiceError for Session",
        "Question_body":"<p>When I run the following code in Sagemaker Studio, I get the <code>UnknownServiceError<\/code>:<\/p>\n<pre><code>import boto3\nimport sagemaker\nsagemaker_session = sagemaker.Session()\nrole = get_execution_role()\n<\/code><\/pre>\n<p>Any advice to overcome this would be greatly appreciated.<\/p>\n<p>The error message in the following:<\/p>\n<pre><code>---------------------------------------------------------------------------\nUnknownServiceError                       Traceback (most recent call last)\n&lt;ipython-input-47-2d2ae2d1e577&gt; in &lt;module&gt;\n      1 import boto3\n      2 import sagemaker\n----&gt; 3 sagemaker_session = sagemaker.Session()\n      4 role = get_execution_role()\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in __init__(self, boto_session, sagemaker_client, sagemaker_runtime_client, sagemaker_featurestore_runtime_client, default_bucket)\n    124             sagemaker_client=sagemaker_client,\n    125             sagemaker_runtime_client=sagemaker_runtime_client,\n--&gt; 126             sagemaker_featurestore_runtime_client=sagemaker_featurestore_runtime_client,\n    127         )\n    128 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in _initialize(self, boto_session, sagemaker_client, sagemaker_runtime_client, sagemaker_featurestore_runtime_client)\n    164         else:\n    165             self.sagemaker_featurestore_runtime_client = self.boto_session.client(\n--&gt; 166                 &quot;sagemaker-featurestore-runtime&quot;\n    167             )\n    168 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/boto3\/session.py in client(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\n    261             aws_access_key_id=aws_access_key_id,\n    262             aws_secret_access_key=aws_secret_access_key,\n--&gt; 263             aws_session_token=aws_session_token, config=config)\n    264 \n    265     def resource(self, service_name, region_name=None, api_version=None,\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/session.py in create_client(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\n    833             is_secure=use_ssl, endpoint_url=endpoint_url, verify=verify,\n    834             credentials=credentials, scoped_config=self.get_scoped_config(),\n--&gt; 835             client_config=config, api_version=api_version)\n    836         monitor = self._get_internal_component('monitor')\n    837         if monitor is not None:\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/client.py in create_client(self, service_name, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, api_version, client_config)\n     76             'choose-service-name', service_name=service_name)\n     77         service_name = first_non_none_response(responses, default=service_name)\n---&gt; 78         service_model = self._load_service_model(service_name, api_version)\n     79         cls = self._create_client_class(service_name, service_model)\n     80         endpoint_bridge = ClientEndpointBridge(\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/client.py in _load_service_model(self, service_name, api_version)\n    114     def _load_service_model(self, service_name, api_version=None):\n    115         json_model = self._loader.load_service_model(service_name, 'service-2',\n--&gt; 116                                                      api_version=api_version)\n    117         service_model = ServiceModel(json_model, service_name=service_name)\n    118         return service_model\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/loaders.py in _wrapper(self, *args, **kwargs)\n    130         if key in self._cache:\n    131             return self._cache[key]\n--&gt; 132         data = func(self, *args, **kwargs)\n    133         self._cache[key] = data\n    134         return data\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/loaders.py in load_service_model(self, service_name, type_name, api_version)\n    376             raise UnknownServiceError(\n    377                 service_name=service_name,\n--&gt; 378                 known_service_names=', '.join(sorted(known_services)))\n    379         if api_version is None:\n    380             api_version = self.determine_latest_version(\n\nUnknownServiceError: Unknown service: 'sagemaker-featurestore-runtime'. Valid service names are: accessanalyzer, acm, acm-pca, alexaforbusiness, amplify, apigateway, apigatewaymanagementapi, apigatewayv2, appconfig, application-autoscaling, application-insights, appmesh, appstream, appsync, athena, autoscaling, autoscaling-plans, backup, batch, braket, budgets, ce, chime, cloud9, clouddirectory, cloudformation, cloudfront, cloudhsm, cloudhsmv2, cloudsearch, cloudsearchdomain, cloudtrail, cloudwatch, codeartifact, codebuild, codecommit, codedeploy, codeguru-reviewer, codeguruprofiler, codepipeline, codestar, codestar-connections, codestar-notifications, cognito-identity, cognito-idp, cognito-sync, comprehend, comprehendmedical, compute-optimizer, config, connect, connectparticipant, cur, dataexchange, datapipeline, datasync, dax, detective, devicefarm, directconnect, discovery, dlm, dms, docdb, ds, dynamodb, dynamodbstreams, ebs, ec2, ec2-instance-connect, ecr, ecs, efs, eks, elastic-inference, elasticache, elasticbeanstalk, elastictranscoder, elb, elbv2, emr, es, events, firehose, fms, forecast, forecastquery, frauddetector, fsx, gamelift, glacier, globalaccelerator, glue, greengrass, groundstation, guardduty, health, honeycode, iam, imagebuilder, importexport, inspector, iot, iot-data, iot-jobs-data, iot1click-devices, iot1click-projects, iotanalytics, iotevents, iotevents-data, iotsecuretunneling, iotsitewise, iotthingsgraph, ivs, kafka, kendra, kinesis, kinesis-video-archived-media, kinesis-video-media, kinesis-video-signaling, kinesisanalytics, kinesisanalyticsv2, kinesisvideo, kms, lakeformation, lambda, lex-models, lex-runtime, license-manager, lightsail, logs, machinelearning, macie, macie2, managedblockchain, marketplace-catalog, marketplace-entitlement, marketplacecommerceanalytics, mediaconnect, mediaconvert, medialive, mediapackage, mediapackage-vod, mediastore, mediastore-data, mediatailor, meteringmarketplace, mgh, migrationhub-config, mobile, mq, mturk, neptune, networkmanager, opsworks, opsworkscm, organizations, outposts, personalize, personalize-events, personalize-runtime, pi, pinpoint, pinpoint-email, pinpoint-sms-voice, polly, pricing, qldb, qldb-session, quicksight, ram, rds, rds-data, redshift, rekognition, resource-groups, resourcegroupstaggingapi, robomaker, route53, route53domains, route53resolver, s3, s3control, sagemaker, sagemaker-a2i-runtime, sagemaker-runtime, savingsplans, schemas, sdb, secretsmanager, securityhub, serverlessrepo, service-quotas, servicecatalog, servicediscovery, ses, sesv2, shield, signer, sms, sms-voice, snowball, sns, sqs, ssm, sso, sso-oidc, stepfunctions, storagegateway, sts, support, swf, synthetics, textract, transcribe, transfer, translate, waf, waf-regional, wafv2, workdocs, worklink, workmail, workmailmessageflow, workspaces, xray\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1607680355900,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":6.0,
        "Question_view_count":387.0,
        "Poster_created_time":1604297242580,
        "Poster_location":null,
        "Poster_reputation_count":115.0,
        "Poster_view_count":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65249110",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio unkownserviceerror session run follow code studio unknownserviceerror import boto import session session role execut role advic overcom greatli appreci error messag follow unknownserviceerror traceback recent import boto import session session role execut role opt conda lib python site packag session init self boto session client runtim client featurestor runtim client default bucket client client runtim client runtim client featurestor runtim client featurestor runtim client opt conda lib python site packag session initi self boto session client runtim client featurestor runtim client self featurestor runtim client self boto session client featurestor runtim opt conda lib python site packag boto session client self servic region api version us ssl verifi endpoint url aw access kei aw secret access kei aw session token config aw access kei aw access kei aw secret access kei aw secret access kei aw session token aw session token config config def resourc self servic region api version opt conda lib python site packag botocor session creat client self servic region api version us ssl verifi endpoint url aw access kei aw secret access kei aw session token config secur us ssl endpoint url endpoint url verifi verifi credenti credenti scope config self scope config client config config api version api version monitor self intern compon monitor monitor opt conda lib python site packag botocor client creat client self servic region secur endpoint url verifi credenti scope config api version client config choos servic servic servic servic non respons respons default servic servic model self load servic model servic api version cl self creat client class servic servic model endpoint bridg clientendpointbridg opt conda lib python site packag botocor client load servic model self servic api version def load servic model self servic api version json model self loader load servic model servic servic api version api version servic model servicemodel json model servic servic return servic model opt conda lib python site packag botocor loader wrapper self arg kwarg kei self cach return self cach kei data func self arg kwarg self cach kei data return data opt conda lib python site packag botocor loader load servic model self servic type api version rais unknownserviceerror servic servic known servic name join sort known servic api version api version self determin latest version unknownserviceerror unknown servic featurestor runtim valid servic name accessanalyz acm acm pca alexaforbusi amplifi apigatewai apigatewaymanagementapi apigatewayv appconfig applic autosc applic insight appmesh appstream appsync athena autosc autosc plan backup batch braket budget chime cloud clouddirectori cloudform cloudfront cloudhsm cloudhsmv cloudsearch cloudsearchdomain cloudtrail cloudwatch codeartifact codebuild codecommit codedeploi codeguru review codeguruprofil codepipelin codestar codestar connect codestar notif cognito ident cognito idp cognito sync comprehend comprehendmed comput optim config connect connectparticip cur dataexchang datapipelin datasync dax detect devicefarm directconnect discoveri dlm dm docdb dynamodb dynamodbstream eb instanc connect ecr ec ef ek elast infer elasticach elasticbeanstalk elastictranscod elb elbv emr event firehos fm forecast forecastqueri frauddetector fsx gamelift glacier globalacceler glue greengrass groundstat guardduti health honeycod iam imagebuild importexport inspector iot iot data iot job data iotclick devic iotclick project iotanalyt iotev iotev data iotsecuretunnel iotsitewis iotthingsgraph iv kafka kendra kinesi kinesi video archiv media kinesi video media kinesi video signal kinesisanalyt kinesisanalyticsv kinesisvideo km lakeform lambda lex model lex runtim licens manag lightsail log machinelearn maci maci managedblockchain marketplac catalog marketplac entitl marketplacecommerceanalyt mediaconnect mediaconvert medial mediapackag mediapackag vod mediastor mediastor data mediatailor meteringmarketplac mgh migrationhub config mobil mturk networkmanag opswork opsworkscm organ outpost person person event person runtim pinpoint pinpoint email pinpoint sm voic polli price qldb qldb session quicksight ram rd rd data redshift rekognit resourc group resourcegroupstaggingapi robomak rout routedomain routeresolv scontrol runtim runtim savingsplan schema sdb secretsmanag securityhub serverlessrepo servic quota servicecatalog servicediscoveri se sesv shield signer sm sm voic snowbal sn sq ssm sso sso oidc stepfunct storagegatewai st support swf synthet textract transcrib transfer translat waf waf region wafv workdoc worklink workmail workmailmessageflow workspac xrai",
        "Question_preprocessed_content":"studio run code studio advic overcom greatli",
        "Question_gpt_summary_original":"The user is encountering an UnknownServiceError when running code in Sagemaker Studio. The error message indicates that the service 'sagemaker-featurestore-runtime' is unknown, and provides a list of valid service names. The user is seeking advice on how to overcome this error.",
        "Question_gpt_summary":"user encount unknownserviceerror run code studio error messag indic servic featurestor runtim unknown provid list valid servic name user seek advic overcom error"
    },
    {
        "Question_title":"How to use panels\/sections configured for one run for all runs",
        "Question_body":"<p>A couple of weeks ago I \u201clost\u201d the logged gradients in my wandb UI. Today I wanted to research why this might be the case (updated wandb to 0.12.11, changed <code>log-freq<\/code>, \u2026) but as it turns out (by chance) it is a visualisation issue. This is either a bug or a feature\/setting that I miss. It might also be related to a bug\/misunderstanding on my behalf that I have \u201clost\u201d sections\/panels configurations in the wandb UI.<\/p>\n<p>When I list a couple of (toy) runs with one run visible (\u201ceye open\u201d) I see a certain layout of sections\/panels. I have no gradients logged (see screenshot, section \u201cGradients\u201d. I have renamed it to uppercase and selected the option to also \u201cshow empty sections\u201d). That\u2019s what led me to believe that I have \u201clost\u201d the gradients.<\/p>\n<p>But when I select the run from above I can see both the run\u2019s gradient and the layout that I had changed.<\/p>\n<p>Can I somehow make the section\/panel configuration of this run the default for all runs? I already applied \u201cCopy to default workspace\u201d (which has a different intention I think, but it was worth a try).<\/p>\n<p>Do I miss a setting or behaviour?<\/p>\n<p>See the 2 screenshots in the PNG (had to combine them, only 1 upload allowed).<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1536b9c8180282ae0182c8834f883bea30622414.png\" data-download-href=\"\/uploads\/short-url\/31Fh7BjMnQAFkMRbuNmt9Zl6feQ.png?dl=1\" title=\"Screenshots\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_594x500.png\" alt=\"Screenshots\" data-base62-sha1=\"31Fh7BjMnQAFkMRbuNmt9Zl6feQ\" width=\"594\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_594x500.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_891x750.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_1188x1000.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1536b9c8180282ae0182c8834f883bea30622414_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshots<\/span><span class=\"informations\">1894\u00d71592 232 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Thank you in advance!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1646998887418,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":146.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-use-panels-sections-configured-for-one-run-for-all-runs\/2060",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us panel section configur run run coupl week ago lost log gradient todai want research case updat chang log freq turn chanc visualis issu bug featur set miss relat bug misunderstand behalf lost section panel configur list coupl toi run run visibl ey open certain layout section panel gradient log screenshot section gradient renam uppercas select option section that led believ lost gradient select run run gradient layout chang section panel configur run default run appli copi default workspac differ intent think worth try miss set behaviour screenshot png combin upload allow screenshot thank advanc",
        "Question_preprocessed_content":"us configur run run coupl ago lost gradient todai want research case turn visualis bug relat behalf lost configur list coupl run run visibl certain layout gradient that led believ lost gradient select run run gradient layout chang configur run default run copi default workspac behaviour png thank advanc",
        "Question_gpt_summary_original":"The user has encountered a visualization issue with their wandb UI where they are unable to see the logged gradients. However, they have discovered that it is a visualisation issue and not a loss of data. The user is seeking a way to make the section\/panel configuration of one run the default for all runs.",
        "Question_gpt_summary":"user encount visual issu unabl log gradient discov visualis issu loss data user seek wai section panel configur run default run"
    },
    {
        "Question_title":"DVC Push KeyError fileSize",
        "Question_body":"<p>I've added a large list of CSV files to my dvc repository but when I try to do DVC push it complains with<\/p>\n<pre><code>ERROR: unexpected error - KeyError('fileSize')\n<\/code><\/pre>\n<p><strong>Edit<\/strong>\nSo searching around it seem that it might help to include the verbose log with regards to the error.<\/p>\n<pre><code>T11:27:08~\/documents\/*****\/data$ dvc push -v\n2022-02-01 11:32:13,186 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/config.local' to gitignore file.\n2022-02-01 11:32:13,199 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/tmp' to gitignore file.\n2022-02-01 11:32:13,200 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/cache' to gitignore file.\n2022-02-01 11:32:14,102 DEBUG: Preparing to transfer data from '\/home\/jhylands\/Documents\/*****\/.dvc\/cache' to '*********'\n2022-02-01 11:32:14,102 DEBUG: Preparing to collect status from '********'\n2022-02-01 11:32:14,103 DEBUG: Collecting status from '*******'\n2022-02-01 11:32:14,439 DEBUG: GDrive remote auth with config '{'client_config_backend': 'settings', 'client_config_file': 'client_secrets.json', 'save_credentials': True, 'oauth_scope': ['https:\/\/www.googleapis.com\/auth\/drive', 'https:\/\/www.googleapis.com\/auth\/drive.appdata'], 'save_credentials_backend': 'file', 'save_credentials_file': '\/home\/jhylands\/Documents\/*****\/.dvc\/tmp\/gdrive-user-credentials.json', 'get_refresh_token': True, 'client_config': {'client_id': '*****.apps.googleusercontent.com', 'client_secret': '****************', 'auth_uri': 'https:\/\/accounts.google.com\/o\/oauth2\/auth', 'token_uri': 'https:\/\/oauth2.googleapis.com\/token', 'revoke_uri': 'https:\/\/oauth2.googleapis.com\/revoke', 'redirect_uri': ''}}'.\n2022-02-01 11:32:14,994 DEBUG: Estimated remote size: 256 files\n2022-02-01 11:32:14,995 DEBUG: Querying '316' hashes via traverse\n2022-02-01 11:32:15,325 ERROR: unexpected error - KeyError('fileSize')\n------------------------------------------------------------\nTraceback (most recent call last):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/files.py&quot;, line 226, in __getitem__\n    return dict.__getitem__(self, key)\nKeyError: 'fileSize'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/main.py&quot;, line 55, in main\n    ret = cmd.do_run()\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/command\/base.py&quot;, line 45, in do_run\n    return self.run()\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/command\/data_sync.py&quot;, line 57, in run\n    processed_files_count = self.repo.push(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/repo\/__init__.py&quot;, line 49, in wrapper\n    return f(repo, *args, **kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/repo\/push.py&quot;, line 56, in push\n    pushed += self.cloud.push(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/data_cloud.py&quot;, line 85, in push\n    return transfer(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/transfer.py&quot;, line 153, in transfer\n    status = compare_status(src, dest, obj_ids, check_deleted=False, **kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/status.py&quot;, line 158, in compare_status\n    dest_exists, dest_missing = status(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/status.py&quot;, line 131, in status\n    exists.update(odb.hashes_exist(hashes, name=odb.fs_path, **kwargs))\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 499, in hashes_exist\n    remote_hashes = set(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 334, in _list_hashes_traverse\n    yield from itertools.chain.from_iterable(in_remote)\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 611, in result_iterator\n    yield fs.pop().result()\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 439, in result\n    return self.__get_result()\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 388, in __get_result\n    raise self._exception\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 324, in list_with_update\n    return list(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 215, in _list_hashes\n    for path in self._list_paths(prefix, progress_callback):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 195, in _list_paths\n    for file_info in self.fs.find(fs_path, prefix=prefix):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/fs\/fsspec_wrapper.py&quot;, line 107, in find\n    yield from self.fs.find(path)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/fs\/spec.py&quot;, line 323, in find\n    &quot;size&quot;: int(item[&quot;fileSize&quot;]),\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/files.py&quot;, line 229, in __getitem__\n    raise KeyError(e)\nKeyError: KeyError('fileSize')\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":5.0,
        "Question_created_time":1643714210580,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1643715642688,
        "Question_score_count":1.0,
        "Question_view_count":54.0,
        "Poster_created_time":1333908536528,
        "Poster_location":"London, United Kingdom",
        "Poster_reputation_count":884.0,
        "Poster_view_count":59.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70939675",
        "Tool":"DVC",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"push keyerror files ad larg list csv file repositori try push complain error unexpect error keyerror files edit search help includ verbos log regard error document data push debug ad home jhyland document config local gitignor file debug ad home jhyland document tmp gitignor file debug ad home jhyland document cach gitignor file debug prepar transfer data home jhyland document cach debug prepar collect statu debug collect statu debug gdrive remot auth config client config backend set client config file client secret json save credenti true oauth scope http www googleapi com auth drive http www googleapi com auth drive appdata save credenti backend file save credenti file home jhyland document tmp gdrive user credenti json refresh token true client config client app googleusercont com client secret auth uri http account googl com oauth auth token uri http oauth googleapi com token revok uri http oauth googleapi com revok redirect uri debug estim remot size file debug queri hash travers error unexpect error keyerror files traceback recent file home jhyland local lib python site packag pydriv file line getitem return dict getitem self kei keyerror files handl except except occur traceback recent file home jhyland local lib python site packag main line main ret cmd run file home jhyland local lib python site packag command base line run return self run file home jhyland local lib python site packag command data sync line run process file count self repo push file home jhyland local lib python site packag repo init line wrapper return repo arg kwarg file home jhyland local lib python site packag repo push line push push self cloud push file home jhyland local lib python site packag data cloud line push return transfer file home jhyland local lib python site packag object transfer line transfer statu compar statu src dest obj id check delet fals kwarg file home jhyland local lib python site packag object statu line compar statu dest exist dest miss statu file home jhyland local lib python site packag object statu line statu exist updat odb hash exist hash odb path kwarg file home jhyland local lib python site packag object base line hash exist remot hash set file home jhyland local lib python site packag object base line list hash travers yield itertool chain iter remot file usr lib python concurr futur base line result iter yield pop result file usr lib python concurr futur base line result return self result file usr lib python concurr futur base line result rais self except file usr lib python concurr futur thread line run result self self arg self kwarg file home jhyland local lib python site packag object base line list updat return list file home jhyland local lib python site packag object base line list hash path self list path prefix progress callback file home jhyland local lib python site packag object base line list path file info self path prefix prefix file home jhyland local lib python site packag fsspec wrapper line yield self path file home jhyland local lib python site packag pydriv spec line size int item files file home jhyland local lib python site packag pydriv file line getitem rais keyerror keyerror keyerror files",
        "Question_preprocessed_content":"push files larg list csv file repositori try push complain edit search help includ verbos log regard",
        "Question_gpt_summary_original":"The user is encountering an error while trying to push a large list of CSV files to their DVC repository. The error message states \"KeyError('fileSize')\" and the user has tried including verbose logs to troubleshoot the issue.",
        "Question_gpt_summary":"user encount error try push larg list csv file repositori error messag state keyerror files user tri includ verbos log troubleshoot issu"
    },
    {
        "Question_title":"How to lable Table with no column in Azure Form Recognizer",
        "Question_body":"<p>I have a PDF file which will contains some data like below structure.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/183990-image.png?platform=QnA\" alt=\"183990-image.png\" \/>    <\/p>\n<p>I want to use Azure Form Recognizer to get the data.    <\/p>\n<p>How can I set the label with Table.    <\/p>\n<p>While tagging with Table, it need to specify the Column and Row.    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1647507167407,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/775939\/how-to-lable-table-with-no-column-in-azure-form-re",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"labl tabl column azur form recogn pdf file contain data like structur want us azur form recogn data set label tabl tag tabl need specifi column row",
        "Question_preprocessed_content":"labl tabl column azur form recogn pdf file contain data like structur want us azur form recogn data set label tabl tabl specifi column row",
        "Question_gpt_summary_original":"The user is trying to use Azure Form Recognizer to extract data from a PDF file that contains a table with no column labels. They are seeking guidance on how to label the table with Azure Form Recognizer, which requires specifying the column and row information.",
        "Question_gpt_summary":"user try us azur form recogn extract data pdf file contain tabl column label seek guidanc label tabl azur form recogn requir specifi column row inform"
    },
    {
        "Question_title":"Dvc remote drive",
        "Question_body":"<p>Hi DVC,<\/p>\n<p>I am following along (Mac system; MacBook Air) one of the DVC tutorials and I am using the latest DVC version.<br>\nI am using gdrive for remote storage. I have created a folder data\/remote, and I followed all the instructions from the tutorial.<br>\nwhen I do a dvc push, I get the following error:<\/p>\n<pre><code class=\"lang-auto\"> $ dvc push\n\nERROR: unexpected error - : &lt;HttpError 404 when requesting https:\/\/www.googleapis.com\/drive\/v2\/files\/1uLgZuvVlB0fnU-Fytp9kWdRyBjLmmktu?fields=driveId&amp;supportsAllDrives=true&amp;alt=json returned \"File not found: 1uLgZuvVlB0fnU-Fytp9kWdRyBjLmmktu\". Details: \"[{'message': 'File not found: 1uLgZuvVlB0fnU-Fytp9kWdRyBjLmmktu', 'domain': 'global', 'reason': 'notFound', 'location': 'file', 'locationType': 'other'}]\"&gt;\n\nHaving any troubles? Hit us up at https:\/\/dvc.org\/support, we are always happy to help!\n<\/code><\/pre>\n<p>Thanks<\/p>\n<p>Ravi<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1679392193507,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":39.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-remote-drive\/1569",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"remot drive follow mac macbook air tutori latest version gdrive remot storag creat folder data remot follow instruct tutori push follow error push error unexpect error have troubl hit http org support happi help thank ravi",
        "Question_preprocessed_content":"remot drive tutori latest version gdrive remot storag creat folder instruct tutori push thank ravi",
        "Question_gpt_summary_original":"The user is encountering an error while using DVC with gdrive for remote storage on a Mac system. The error message indicates that the file being requested is not found, resulting in an unexpected error. The user has sought help from DVC support.",
        "Question_gpt_summary":"user encount error gdrive remot storag mac error messag indic file request result unexpect error user sought help support"
    },
    {
        "Question_title":"How to set multiple environment variables in AWS Sagemaker notebook instance?",
        "Question_body":"<p>I am using the AWS Sagemaker notebook instances for some of my experiments. As I am also using the lifecycle configurations scripts that are executed during notebook startup and also want to set some environment variables.<\/p>\n\n<p>For some reason, when I set multiple env variables in the lifecycle shell script, they are not set by the instance, i.e. when I execute\n<code>echo $FOO<\/code> \nthe relevant variable is not printed. <\/p>\n\n<p>However, when I set only one env variable it is working and I can use it in my notebook session. <\/p>\n\n<p>My understanding is that I start the desired Kernel, <\/p>\n\n<p>I have also tried to set the env variables inside the notebook by running <code>export FOO=BAR<\/code> but that also did not work. \nFollowing the example script provided by AWS, I made my changes to set the variables, however when I print $FOO, it doesn't seem to be displayed.<\/p>\n\n<p>I have tried setting the envs before and after switching to ec2-user (before the commands are executed as root), still nothing helped.<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>#!\/bin\/bash\n\n\ncd \/home\/ec2-user\/anaconda3\/envs\/python3\nmkdir -p .\/etc\/conda\/activate.d\nmkdir -p .\/etc\/conda\/deactivate.d\ntouch .\/etc\/conda\/activate.d\/env_vars.sh\ntouch .\/etc\/conda\/deactivate.d\/env_vars.sh\n\necho export FOO=BAR &gt;&gt; .\/etc\/conda\/activate.d\/env_vars.sh\necho unset FOO &gt;&gt; .\/etc\/conda\/deactivate.d\/env_vars.sh\n\necho export FOO2=BAR2 &gt;&gt; .\/etc\/conda\/activate.d\/env_vars.sh\necho unset FOO2 &gt;&gt; .\/etc\/conda\/deactivate.d\/env_vars.sh\n\nsudo -u ec2-user -i &lt;&lt;'EOF'\n\ncd \/home\/ec2-user\n\n# This will affect only the Jupyter kernel called \"conda_python3\".\nsource activate python3\n\npip install --upgrade pip\n\npip install scipy xgboost sklearn\n\n# You can also perform \"conda install\" here as well.\n\n\nsource deactivate\n\nEOF\n\n\n<\/code><\/pre>\n\n<p>I want to set multiple environment variables for this Sagemaker notebook upon start, what is the best way to do this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_created_time":1565020147883,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1574242772027,
        "Question_score_count":4.0,
        "Question_view_count":5171.0,
        "Poster_created_time":1432024993980,
        "Poster_location":"Berlin, Germany",
        "Poster_reputation_count":411.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57362038",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"set multipl environ variabl notebook instanc notebook instanc experi lifecycl configur script execut notebook startup want set environ variabl reason set multipl env variabl lifecycl shell script set instanc execut echo foo relev variabl print set env variabl work us notebook session understand start desir kernel tri set env variabl insid notebook run export foo bar work follow exampl script provid aw chang set variabl print foo displai tri set env switch user command execut root help bin bash home user anaconda env python mkdir conda activ mkdir conda deactiv touch conda activ env var touch conda deactiv env var echo export foo bar conda activ env var echo unset foo conda deactiv env var echo export foo bar conda activ env var echo unset foo conda deactiv env var sudo user eof home user affect jupyt kernel call conda python sourc activ python pip instal upgrad pip pip instal scipi xgboost sklearn perform conda instal sourc deactiv eof want set multipl environ variabl notebook start best wai",
        "Question_preprocessed_content":"set multipl environ variabl instanc instanc experi lifecycl configur script execut startup want set environ variabl reason set multipl env variabl lifecycl script set instanc execut relev variabl print set env variabl work us understand start desir kernel tri set env variabl insid work exampl script provid aw chang set variabl print displai tri env switch help want set multipl environ variabl start best wai",
        "Question_gpt_summary_original":"The user is facing issues while setting multiple environment variables in AWS Sagemaker notebook instance. They have tried setting the variables in the lifecycle shell script and also inside the notebook, but none of them seem to work. However, setting a single environment variable is working fine. The user has also shared a script that they have tried to modify to set the variables, but it did not work. The user is seeking advice on the best way to set multiple environment variables for the Sagemaker notebook upon start.",
        "Question_gpt_summary":"user face issu set multipl environ variabl notebook instanc tri set variabl lifecycl shell script insid notebook work set singl environ variabl work fine user share script tri modifi set variabl work user seek advic best wai set multipl environ variabl notebook start"
    },
    {
        "Question_title":"Moving Azure Machine Learning Studio jobs to a new region",
        "Question_body":"<p>I need to move my Machine Learning Studio workspace to a new region. I am aware that the move function <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace#limitations\">doesn't allow automatically moving to a new region<\/a>, so I'll have to create a new workspace. That's not a big problem, but I still want to keep my job\/experiment history (in my new workspace). How can I do that?    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1662467585447,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=a645d9b8-7c24-4419-8686-bc144a45c4f1\">@David-3633  <\/a>     <\/p>\n<p>Sorry, I just got confimation from product team, this is currently impossible. I am sorry for the inconvenience.     <\/p>\n<p>A near future workaround which could let users at least share some experiment outputs\/inputs like environments, models, datasets cross region, but not the jobs\/metrics\/logs themselves. This feature is in private preview now and will be in public preview soon.    <\/p>\n<p>I hope this information helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Answer_comment_count":2.0,
        "Question_closed_time":1664291528087,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/995833\/moving-azure-machine-learning-studio-jobs-to-a-new",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"move studio job new region need machin learn studio workspac new region awar function allow automat move new region creat new workspac big problem want job experi histori new workspac",
        "Question_preprocessed_content":"move studio job new region machin learn studio workspac new region awar function move new region creat new workspac big problem want histori",
        "Question_gpt_summary_original":"The user needs to move their Azure Machine Learning Studio workspace to a new region, but the move function does not allow automatic moving to a new region. Therefore, the user needs to create a new workspace, but they want to keep their job\/experiment history in the new workspace. The user is seeking advice on how to achieve this.",
        "Question_gpt_summary":"user need studio workspac new region function allow automat move new region user need creat new workspac want job experi histori new workspac user seek advic achiev"
    },
    {
        "Question_title":"Sagemaker: MemoryError: Unable to allocate ___for an array with shape ___ and data type float64",
        "Question_body":"<p>I am running a notebook in sagemaker and it seems like one of the arrays produced after vectorizing text is causing issues.<\/p>\n\n<p>Reading other answers it seems like it is an issue with <a href=\"https:\/\/www.kernel.org\/doc\/Documentation\/vm\/overcommit-accounting\" rel=\"noreferrer\">overcommit<\/a>. And one of the solutions proposed is to set it to always overcommit with this:<\/p>\n\n<pre><code>$ echo 1 &gt; \/proc\/sys\/vm\/overcommit_memory\n<\/code><\/pre>\n\n<p>Is there any documentation or do you have any suggestion on how to do the same thing in sagemaker?<\/p>\n\n<p>Thank you very much.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1589441004223,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":8.0,
        "Question_view_count":2821.0,
        "Poster_created_time":1517932507092,
        "Poster_location":null,
        "Poster_reputation_count":331.0,
        "Poster_view_count":73.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61791589",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"memoryerror unabl alloc arrai shape data type float run notebook like arrai produc vector text caus issu read answer like issu overcommit solut propos set overcommit echo proc sy overcommit memori document suggest thing thank",
        "Question_preprocessed_content":"unabl shape data type float like produc vector text caus read answer like solut propos set document thing thank",
        "Question_gpt_summary_original":"The user is encountering a MemoryError while running a notebook in Sagemaker, which seems to be caused by an array produced after vectorizing text. The issue is related to overcommit and the user is seeking documentation or suggestions on how to set it to always overcommit in Sagemaker.",
        "Question_gpt_summary":"user encount memoryerror run notebook caus arrai produc vector text issu relat overcommit user seek document suggest set overcommit"
    },
    {
        "Question_title":"How to install python ta-lib library in Azure Machine Learning Juypyter Notebooks",
        "Question_body":"<p>SO I need to use this python library explained here:<\/p>\n<p><a href=\"https:\/\/medium.com\/analytics-vidhya\/recognizing-over-50-candlestick-patterns-with-python-4f02a1822cb5\" rel=\"nofollow noreferrer\">https:\/\/medium.com\/analytics-vidhya\/recognizing-over-50-candlestick-patterns-with-python-4f02a1822cb5<\/a><\/p>\n<p>However when I try to execute:<\/p>\n<p>!pip install talib\nimport talib<\/p>\n<p>I get lots of errors:<\/p>\n<pre><code>Collecting talib\n  Using cached talib-0.1.1.tar.gz (1.3 kB)\nBuilding wheels for collected packages: talib\n  Building wheel for talib (setup.py) ... error\n  ERROR: Command errored out with exit status 1:\n   command: \/anaconda\/envs\/azureml_py36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' bdist_wheel -d \/tmp\/pip-wheel-1dvr6fd9\n       cwd: \/tmp\/pip-install-lof3_wuc\/talib\/\n  Complete output (29 lines):\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build\/lib\n  creating build\/lib\/talib\n  copying talib\/__init__.py -&gt; build\/lib\/talib\n  copying talib\/cli.py -&gt; build\/lib\/talib\n  installing to build\/bdist.linux-x86_64\/wheel\n  running install\n  Traceback (most recent call last):\n    File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\n    File &quot;\/tmp\/pip-install-lof3_wuc\/talib\/setup.py&quot;, line 47, in &lt;module&gt;\n      'talib = talib.cli:cli',\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/core.py&quot;, line 148, in setup\n      dist.run_commands()\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 955, in run_commands\n      self.run_command(cmd)\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 974, in run_command\n      cmd_obj.run()\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/wheel\/bdist_wheel.py&quot;, line 326, in run\n      self.run_command('install')\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/cmd.py&quot;, line 313, in run_command\n      self.distribution.run_command(command)\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 974, in run_command\n      cmd_obj.run()\n    File &quot;\/tmp\/pip-install-lof3_wuc\/talib\/setup.py&quot;, line 20, in run\n      raise Exception(&quot;You probably meant to install and run ta-lib&quot;)\n  Exception: You probably meant to install and run ta-lib\n  ----------------------------------------\n  ERROR: Failed building wheel for talib\n  Running setup.py clean for talib\nFailed to build talib\nInstalling collected packages: talib\n    Running setup.py install for talib ... error\n    ERROR: Command errored out with exit status 1:\n     command: \/anaconda\/envs\/azureml_py36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' install --record \/tmp\/pip-record-7fqjayvz\/install-record.txt --single-version-externally-managed --compile --install-headers \/anaconda\/envs\/azureml_py36\/include\/python3.6m\/talib\n         cwd: \/tmp\/pip-install-lof3_wuc\/talib\/\n    Complete output (14 lines):\n    running install\n    Traceback (most recent call last):\n      File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\n      File &quot;\/tmp\/pip-install-lof3_wuc\/talib\/setup.py&quot;, line 47, in &lt;module&gt;\n        'talib = talib.cli:cli',\n      File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/core.py&quot;, line 148, in setup\n        dist.run_commands()\n      File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 955, in run_commands\n        self.run_command(cmd)\n      File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 974, in run_command\n        cmd_obj.run()\n      File &quot;\/tmp\/pip-install-lof3_wuc\/talib\/setup.py&quot;, line 20, in run\n        raise Exception(&quot;You probably meant to install and run ta-lib&quot;)\n    Exception: You probably meant to install and run ta-lib\n    ----------------------------------------\nERROR: Command errored out with exit status 1: \/anaconda\/envs\/azureml_py36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' install --record \/tmp\/pip-record-7fqjayvz\/install-record.txt --single-version-externally-managed --compile --install-headers \/anaconda\/envs\/azureml_py36\/include\/python3.6m\/talib Check the logs for full command output.\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-56-ef2dd36041a5&gt; in &lt;module&gt;\n      1 get_ipython().system('pip install talib')\n----&gt; 2 import talib\n\nModuleNotFoundError: No module named 'talib'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1604608935850,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":770.0,
        "Poster_created_time":1302030303092,
        "Poster_location":"Brussels, B\u00e9lgica",
        "Poster_reputation_count":30340.0,
        "Poster_view_count":2937.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64704974",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"instal python lib librari juypyt notebook need us python librari explain http medium com analyt vidhya recogn candlestick pattern python facb try execut pip instal talib import talib lot error collect talib cach talib tar build wheel collect packag talib build wheel talib setup error error command error exit statu command anaconda env bin python import sy setuptool token sy argv tmp pip instal lof wuc talib setup file tmp pip instal lof wuc talib setup getattr token open open file code read replac close exec compil code file exec bdist wheel tmp pip wheel dvrfd cwd tmp pip instal lof wuc talib complet output line run bdist wheel run build run build creat build creat build lib creat build lib talib copi talib init build lib talib copi talib cli build lib talib instal build bdist linux wheel run instal traceback recent file line file tmp pip instal lof wuc talib setup line talib talib cli cli file anaconda env lib python distutil core line setup dist run command file anaconda env lib python distutil dist line run command self run command cmd file anaconda env lib python distutil dist line run command cmd obj run file anaconda env lib python site packag wheel bdist wheel line run self run command instal file anaconda env lib python distutil cmd line run command self distribut run command command file anaconda env lib python distutil dist line run command cmd obj run file tmp pip instal lof wuc talib setup line run rais except probabl meant instal run lib except probabl meant instal run lib error fail build wheel talib run setup clean talib fail build talib instal collect packag talib run setup instal talib error error command error exit statu command anaconda env bin python import sy setuptool token sy argv tmp pip instal lof wuc talib setup file tmp pip instal lof wuc talib setup getattr token open open file code read replac close exec compil code file exec instal record tmp pip record fqjayvz instal record txt singl version extern manag compil instal header anaconda env includ python talib cwd tmp pip instal lof wuc talib complet output line run instal traceback recent file line file tmp pip instal lof wuc talib setup line talib talib cli cli file anaconda env lib python distutil core line setup dist run command file anaconda env lib python distutil dist line run command self run command cmd file anaconda env lib python distutil dist line run command cmd obj run file tmp pip instal lof wuc talib setup line run rais except probabl meant instal run lib except probabl meant instal run lib error command error exit statu anaconda env bin python import sy setuptool token sy argv tmp pip instal lof wuc talib setup file tmp pip instal lof wuc talib setup getattr token open open file code read replac close exec compil code file exec instal record tmp pip record fqjayvz instal record txt singl version extern manag compil instal header anaconda env includ python talib check log command output modulenotfounderror traceback recent ipython pip instal talib import talib modulenotfounderror modul name talib",
        "Question_preprocessed_content":"python librari juypyt us python librari explain try execut pip talib import talib lot",
        "Question_gpt_summary_original":"The user is trying to install the ta-lib library in Azure Machine Learning Jupyter Notebooks to use it for recognizing over 50 candlestick patterns with Python. However, when the user tries to execute the installation command, they encounter multiple errors and are unable to install the library.",
        "Question_gpt_summary":"user try instal lib librari jupyt notebook us recogn candlestick pattern python user tri execut instal command encount multipl error unabl instal librari"
    },
    {
        "Question_title":"Vertex AI model showing failure but 0 bytes in prediction.errors",
        "Question_body":"<p>I'm running a vertex batch job on a custom model with 676 instances in my jsonl.<\/p>\n<p>I get results for all 676 instances but the job shows &quot;Due to one or more errors, this batch prediction job was canceled on Aug 22, 2022 at 09:04PM&quot;<\/p>\n<p>The error file prediction.errors_stats-00000-of-00001 has 0 bytes and there is a directory:<\/p>\n<pre><code>beam-temp-prediction.errors_stats-e289aa8c228c11eda06642010a800fdc \n<\/code><\/pre>\n<p>with 4 files with 0 bytes\u00a0in them.<\/p>\n<pre><code>34e19e3d-e717-4c6f-860c-5c2a177f1e93.prediction.errors_stats\n7c9374c8-65f7-4a97-8a95-6068ba9cd936.prediction.errors_stats\n981a634b-d27c-4285-b871-648b25ca87b8.prediction.errors_stats\nf14dbc29-42d7-480e-8b79-95e799e132bf.prediction.errors_stats\n<\/code><\/pre>\n<p>Any ideas on why the job is showing failure but the results seem ok?<\/p>\n<p>Job params:<\/p>\n<pre><code>{&quot;displayName&quot;: &lt;MY_DISPLAY_NAME&gt;,\n &quot;model&quot;: &lt;MY_MODEL&gt;,\n &quot;inputConfig&quot;: {&quot;instancesFormat&quot;: &quot;jsonl&quot;,\n                 &quot;gcsSource&quot;: {&quot;uris&quot;: [&quot;gs:\/\/&lt;MY_BUCKET&gt;\/MY_INSTANCES.jsonl&quot;]}},\n &quot;outputConfig&quot;: {&quot;predictionsFormat&quot;: &quot;jsonl&quot;,\n                  &quot;gcsDestination&quot;: {&quot;outputUriPrefix&quot;: &quot;gs:\/\/&lt;MY_OUTPUTS&gt;\/outputs\/2022-08-23&quot;}},\n&quot;dedicatedResources&quot;: {&quot;machineSpec&quot;: {&quot;machineType&quot;: &quot;n1-standard-8&quot;, \n&quot;acceleratorType&quot;: null, &quot;acceleratorCount&quot;: null},\n&quot;startingReplicaCount&quot;: 2},\n&quot;manualBatchTuningParameters&quot;: {&quot;batch_size&quot;: 1}}\n<\/code><\/pre>\n<p>Note: I've also tried leaving out the 'startingReplicaCount and manualBatchTuningParameters.<\/p>\n<p>I'm using a curl command to initiate the batch job:<\/p>\n<pre><code>    curl -X POST \\\n-H &quot;Authorization: Bearer &quot;$(gcloud auth application-default print-access-token) \\\n-H &quot;Content-Type: application\/json; charset=utf-8&quot; \\\n-d @$INPUT_JSON \\\n&quot;https:\/\/$LOCATION-aiplatform.googleapis.com\/v1\/projects\/$PROJECT\/locations\/$LOCATION\/batchPredictionJobs&quot;\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1661278466123,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1661279037728,
        "Question_score_count":1.0,
        "Question_view_count":42.0,
        "Poster_created_time":1462581330168,
        "Poster_location":"Berkeley, CA, United States",
        "Poster_reputation_count":329.0,
        "Poster_view_count":65.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73463378",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model show failur byte predict error run vertex batch job custom model instanc jsonl result instanc job show error batch predict job cancel aug error file predict error stat byte directori beam temp predict error stat eaaccedaafdc file bytesin eed cafe predict error stat bacd predict error stat bcab predict error stat fdbc eebf predict error stat idea job show failur result job param displaynam model inputconfig instancesformat jsonl gcssourc uri instanc jsonl outputconfig predictionsformat jsonl gcsdestin outputuriprefix output dedicatedresourc machinespec machinetyp standard acceleratortyp null acceleratorcount null startingreplicacount manualbatchtuningparamet batch size note tri leav startingreplicacount manualbatchtuningparamet curl command initi batch job curl post author bearer gcloud auth applic default print access token content type applic json charset utf input json http locat aiplatform googleapi com project project locat locat batchpredictionjob",
        "Question_preprocessed_content":"model show failur byte vertex batch job custom model instanc jsonl result instanc job show batch predict job cancel aug file byte directori file bytesin idea job show failur result job param note tri leav startingreplicacount manualbatchtuningparamet curl initi batch job",
        "Question_gpt_summary_original":"The user is running a vertex batch job on a custom model with 676 instances in their jsonl. They get results for all 676 instances but the job shows \"Due to one or more errors, this batch prediction job was canceled\" and the error file prediction.errors_stats-00000-of-00001 has 0 bytes. The user is unsure why the job is showing failure but the results seem okay. They have tried leaving out the 'startingReplicaCount and manualBatchTuningParameters' and are using a curl command to initiate the batch job.",
        "Question_gpt_summary":"user run vertex batch job custom model instanc jsonl result instanc job show error batch predict job cancel error file predict error stat byte user unsur job show failur result okai tri leav startingreplicacount manualbatchtuningparamet curl command initi batch job"
    },
    {
        "Question_title":"Can you add widgets to SageMaker Notebooks similar to Azure DataBricks?",
        "Question_body":"<p>I have used Azure DataBricks in my earlier job and it comes with extended support for Notebook widgets to execute notebook manually\/ commission a notebook job by selecting some values (Ideally your run state params or variables.)<\/p>\n<p>For information here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/notebooks\/widgets\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/notebooks\/widgets<\/a><\/p>\n<p>Is there a similar service or option that I can build while working on SageMaker notebooks?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1657767572897,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":45.0,
        "Poster_created_time":1582444257040,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72974712",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"add widget notebook similar azur databrick azur databrick earlier job come extend support notebook widget execut notebook manual commiss notebook job select valu ideal run state param variabl inform http doc microsoft com azur databrick notebook widget similar servic option build work notebook",
        "Question_preprocessed_content":"widget similar azur databrick azur databrick earlier job come extend widget execut job select valu inform similar servic option build work",
        "Question_gpt_summary_original":"The user is looking for a way to add widgets to SageMaker Notebooks similar to what is available in Azure DataBricks, which allows for extended support for Notebook widgets to execute notebook manually or commission a notebook job by selecting some values. The user is seeking information on whether there is a similar service or option available in SageMaker notebooks.",
        "Question_gpt_summary":"user look wai add widget notebook similar avail azur databrick allow extend support notebook widget execut notebook manual commiss notebook job select valu user seek inform similar servic option avail notebook"
    },
    {
        "Question_title":"Using MLOPS template with custom inference code",
        "Question_body":"Hi MLOps Gurus,\n\nI'd like to seek guidance on my below situation.\n\nI am currently working on a Sagemaker project where I'm using the MLOPS template for model building, training, and deployment. I trained the model using the sklearn framework and registered it in the model registry. However, while creating the model deployment pipeline, I faced an issue with the default cloudformation template resources. Specifically, when attempting to use both the ModelPackageName and custom image as parameters for the model creation, I encountered an error. I discovered that Sagemaker expects a \"ModelDataUrl\" parameter when using a custom image. \n\nDefault Clouformation template:\n\n```\nResources:\n  Model:\n    Type: AWS::SageMaker::Model\n    Properties:\n      Containers:\n         - ModelPackageName: !Ref ModelPackageName\n      ExecutionRoleArn: !Ref ModelExecutionRoleArn\n```\n\n\nHow I modified:\n\n```\nResources:\n  Model:\n    Type: AWS::SageMaker::Model\n    Properties:\n      Containers:\n         - \n           Image: !Ref ImageURI\n           ModelDataUrl: !Ref ModelData\n           Mode: SingleModel #This defaults to single model change to \"MultiModel\" for MME\n           Environment: {\"SAGEMAKER_PROGRAM\": \"inference.py\", \n                         \"SAGEMAKER_SUBMIT_DIRECTORY\": !Ref ModelData}\n      ExecutionRoleArn: !Ref ModelExecutionRoleArn\n                       \n```\n\n\n\n\nMy question is: How can I retrieve the trained model from codebuild pipeline and add \"ModelDataUrl\" parameter  and dynamically pass it to the endpoint-config cloudformation template every time I execute the pipeline?\n\nPlease guide me the steps to progress, thank you!",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1678881226207,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1679228693272,
        "Question_score_count":0.0,
        "Question_view_count":37.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUVOG_sJsZSk-cvJvypdXY5A\/using-mlops-template-with-custom-inference-code",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"mlop templat custom infer code mlop guru like seek guidanc situat current work project mlop templat model build train deploy train model sklearn framework regist model registri creat model deploy pipelin face issu default cloudform templat resourc specif attempt us modelpackagenam custom imag paramet model creation encount error discov expect modeldataurl paramet custom imag default clouform templat resourc model type aw model properti contain modelpackagenam ref modelpackagenam executionrolearn ref modelexecutionrolearn modifi resourc model type aw model properti contain imag ref imageuri modeldataurl ref modeldata mode singlemodel default singl model chang multimodel mme environ program infer submit directori ref modeldata executionrolearn ref modelexecutionrolearn question retriev train model codebuild pipelin add modeldataurl paramet dynam pass endpoint config cloudform templat time execut pipelin guid step progress thank",
        "Question_preprocessed_content":"mlop templat custom infer code mlop guru like guidanc situat work project mlop templat model build train deploy train model sklearn framework regist model registri creat model deploy pipelin face default cloudform templat resourc us modelpackagenam custom imag paramet model creation encount discov expect modeldataurl paramet custom imag default clouform templat modifi question retriev train model codebuild pipelin modeldataurl paramet cloudform templat time execut pipelin guid step thank",
        "Question_gpt_summary_original":"The user is facing an issue with the default cloudformation template resources while creating a model deployment pipeline using the MLOPS template for a Sagemaker project. The issue arises when attempting to use both the ModelPackageName and custom image as parameters for the model creation. The user discovered that Sagemaker expects a \"ModelDataUrl\" parameter when using a custom image. The user is seeking guidance on how to retrieve the trained model from codebuild pipeline and add \"ModelDataUrl\" parameter dynamically to the endpoint-config cloudformation template every time the pipeline is executed.",
        "Question_gpt_summary":"user face issu default cloudform templat resourc creat model deploy pipelin mlop templat project issu aris attempt us modelpackagenam custom imag paramet model creation user discov expect modeldataurl paramet custom imag user seek guidanc retriev train model codebuild pipelin add modeldataurl paramet dynam endpoint config cloudform templat time pipelin execut"
    },
    {
        "Question_title":"Automate AI model training and create endpoint whenever the train data is updated using aws Sagemaker",
        "Question_body":"<p>I am searching for good references(videos or texts) to automate my AI (custom NLP model) training job whenever I update my data in s3 bucket i..e, whenever my pipeline detects change in data, it starts training automatically and create the endpoint. I am currently using aws API gateway and lambda to communicate with the endpoint. However, for each time I update my train data, I need to run the training job manually to create new endpoint. I want to automate the later part.\nIs there anyone in this group who can help me with the relevant resources to achieve this?\nThank You!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1663307946833,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":8.0,
        "Poster_created_time":1640203013416,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73740461",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"autom model train creat endpoint train data updat search good refer video text autom custom nlp model train job updat data bucket pipelin detect chang data start train automat creat endpoint current aw api gatewai lambda commun endpoint time updat train data need run train job manual creat new endpoint want autom later group help relev resourc achiev thank",
        "Question_preprocessed_content":"autom model train creat endpoint train data updat search refer autom train job updat data bucket pipelin detect chang data start train creat endpoint aw api gatewai lambda endpoint time updat train data run train job creat new endpoint want autom later group help relev resourc achiev thank",
        "Question_gpt_summary_original":"The user is looking for resources to automate the training of their custom NLP model in AWS Sagemaker whenever there is an update in their data stored in an S3 bucket. They currently use AWS API Gateway and Lambda to communicate with the endpoint, but they need to manually run the training job each time they update their data to create a new endpoint. The user is seeking help to automate this process.",
        "Question_gpt_summary":"user look resourc autom train custom nlp model updat data store bucket current us aw api gatewai lambda commun endpoint need manual run train job time updat data creat new endpoint user seek help autom process"
    },
    {
        "Question_title":"Convert jpeg image data stored in AWS s3 to TFRecords where the sub-directory is the unique label associated with these images using AWS SageMaker",
        "Question_body":"<p>I have a directory of jpeg images in AWS s3 where the sub-directory is the unique label associated with these images. I am attempting to follow this <a href=\"https:\/\/github.com\/tensorflow\/models\/blob\/f87a58cd96d45de73c9a8330a06b2ab56749a7fa\/research\/inception\/inception\/data\/build_image_data.py\" rel=\"nofollow noreferrer\">example<\/a> using AWS SageMaker and I am making a mess of input and output paths while being inexperienced with flags. Any guidance on applying the linked solution using s3 and SageMaker or another approach to achieve the output of TFRecords then saved back to s3 would be greatly appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1613676013737,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":316.0,
        "Poster_created_time":1554323448856,
        "Poster_location":null,
        "Poster_reputation_count":57.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66266759",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"convert jpeg imag data store aw tfrecord sub directori uniqu label associ imag directori jpeg imag aw sub directori uniqu label associ imag attempt follow exampl make mess input output path inexperienc flag guidanc appli link solut approach achiev output tfrecord save greatli appreci",
        "Question_preprocessed_content":"convert jpeg imag data store aw tfrecord uniqu label imag directori jpeg imag aw uniqu label imag exampl make input output path inexperienc flag guidanc link solut achiev output tfrecord save greatli",
        "Question_gpt_summary_original":"The user is trying to convert jpeg image data stored in AWS s3 to TFRecords where the sub-directory is the unique label associated with these images using AWS SageMaker. They are having difficulty with input and output paths and are seeking guidance on how to apply a linked solution or another approach to achieve the desired output of TFRecords saved back to s3.",
        "Question_gpt_summary":"user try convert jpeg imag data store aw tfrecord sub directori uniqu label associ imag have difficulti input output path seek guidanc appli link solut approach achiev desir output tfrecord save"
    },
    {
        "Question_title":"How to authenticate within Azure ML pipeline and avoid browser interactive authentication?",
        "Question_body":"<p>I have created a very simple azure ml pipeline. Basically, it accesses data through an api and prints it.\nI have tried using a ClientSecretCredential and a ServicePrincipalAuthentication but the pipeline still asks me for a web browser authentication to continue (even though the script runs when I just run the python file in the terminal)<\/p>\n<pre><code>    from azureml.core.compute import ComputeTarget, AmlCompute\n    import azureml.core\n    from azureml.core import Workspace, Datastore\n    from azure.identity import ClientSecretCredential\n    from azureml.core.authentication import ServicePrincipalAuthentication\n    \n    \n    ws = Workspace.from_config()\n    \n    keyvault = ws.get_default_keyvault()\n    \n    client_id = keyvault.get_secret(&quot;ClientID&quot;)\n    tenant_id = keyvault.get_secret(&quot;TENANTID&quot;)\n    secret_id = keyvault.get_secret(&quot;CLIENTSECRET&quot;)\n    \n    sp = ClientSecretCredential(tenant_id = tenant_id, client_id = client_id, client_secret = secret_id)\n\n#  sp = ServicePrincipalAuthentication(tenant_id, client_id, secret_id)\n<\/code><\/pre>\n<p>This is the output from the pipeline:<\/p>\n<p>2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/azureProfile.json. It will be overridden by default settings.\n2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/az.json. It will be overridden by default settings.\n2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/az.sess. It will be overridden by default settings.\n2022-07-06 06:08:21,498|azureml._vendor.azure_cli_core|DEBUG|Current cloud config:\nAzureCloud\n2022-07-06 06:08:21,501|azureml._vendor.azure_cli_core|DEBUG|Current cloud config:\nAzureCloud\n2022-07-06 06:08:21,527|azureml._vendor.azure_cli_core._profile|INFO|No web browser is available. Fall back to device code.\n<strong>2022-07-06 06:08:21,628|azureml._vendor.azure_cli_core.auth.identity|WARNING|To sign in, use a web browser to open the page <a href=\"https:\/\/microsoft.com\/devicelogin\" rel=\"nofollow noreferrer\">https:\/\/microsoft.com\/devicelogin<\/a> and enter the code XXXXXXXXXX to authenticate.<\/strong>\n2022-07-06 06:08:49,950|azureml.core.authentication|DEBUG|Time to expire 1814345.049124 seconds<\/p>\n<p>What can I do for it to pick up the credential in the code and avoid asking for interactive authentication?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1657088789413,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":67.0,
        "Poster_created_time":1516041506383,
        "Poster_location":null,
        "Poster_reputation_count":43.0,
        "Poster_view_count":21.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72878787",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"authent pipelin avoid browser interact authent creat simpl pipelin basic access data api print tri clientsecretcredenti serviceprincipalauthent pipelin ask web browser authent continu script run run python file termin core comput import computetarget amlcomput import core core import workspac datastor azur ident import clientsecretcredenti core authent import serviceprincipalauthent workspac config keyvault default keyvault client keyvault secret clientid tenant keyvault secret tenantid secret keyvault secret clientsecret clientsecretcredenti tenant tenant client client client secret secret serviceprincipalauthent tenant client secret output pipelin vendor azur cli core session info fail load pars file root auth azureprofil json overridden default set vendor azur cli core session info fail load pars file root auth json overridden default set vendor azur cli core session info fail load pars file root auth sess overridden default set vendor azur cli core debug current cloud config azurecloud vendor azur cli core debug current cloud config azurecloud vendor azur cli core profil info web browser avail fall devic code vendor azur cli core auth ident warn sign us web browser open page http microsoft com devicelogin enter code xxxxxxxxxx authent core authent debug time expir second pick credenti code avoid ask interact authent",
        "Question_preprocessed_content":"authent pipelin avoid browser interact authent creat simpl pipelin data api print tri clientsecretcredenti serviceprincipalauthent pipelin ask web browser authent continu output pipelin load pars file default load pars file default load pars file default cloud config azurecloud cloud config azurecloud web browser avail devic code sign us web browser open page enter code authent expir second pick credenti code avoid ask interact authent",
        "Question_gpt_summary_original":"The user is facing an issue with Azure ML pipeline where even after using ClientSecretCredential and ServicePrincipalAuthentication, the pipeline is asking for web browser authentication. The user is looking for a solution to authenticate within Azure ML pipeline and avoid browser interactive authentication.",
        "Question_gpt_summary":"user face issu pipelin clientsecretcredenti serviceprincipalauthent pipelin ask web browser authent user look solut authent pipelin avoid browser interact authent"
    },
    {
        "Question_title":"How does it work underhood: Predictions of multiple instances (Batch) to Vertex AI online serving",
        "Question_body":"Hello,\n\nVertex AI online serving:\n\nWhen multiple instances are passed for prediction to an endpoint, Does prepackaged container serve the inferences in the same manner as TFX Serving does with enable_batching.\u00a0 If so how do we optimize batching parameters with multiple instances sent to Vertex AI online.\n\nIf multi_instances prediction is different from TFX serving batching, how do we gain GPU resources efficient usage optimization with prepackaged serving container.\n\nOn a general note, how to handle efficient GPU usage for both prepackaged container and custom container using a custom trained model.\n\nPlease guide.\n\nThank you.",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1661981100000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":73.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-does-it-work-underhood-Predictions-of-multiple-instances\/m-p\/462022#M554",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"work underhood predict multipl instanc batch onlin serv hello onlin serv multipl instanc pass predict endpoint prepackag contain serv infer manner tfx serv enabl batch optim batch paramet multipl instanc sent onlin multi instanc predict differ tfx serv batch gain gpu resourc effici usag optim prepackag serv contain gener note handl effici gpu usag prepackag contain custom contain custom train model guid thank",
        "Question_preprocessed_content":"work predict multipl instanc onlin serv onlin serv multipl instanc predict endpoint prepackag contain serv infer tfx serv optim batch paramet multipl instanc sent onlin predict tfx serv batch gain gpu resourc usag optim prepackag serv contain gener note handl gpu usag prepackag contain custom contain custom train model guid thank",
        "Question_gpt_summary_original":"The user is seeking guidance on how to optimize GPU resource usage for multiple instances sent to Vertex AI online serving. They are specifically asking if the prepackaged container serves inferences in the same manner as TFX Serving with enable_batching and how to optimize batching parameters. Additionally, they are asking for advice on how to handle efficient GPU usage for both prepackaged and custom containers using a custom trained model.",
        "Question_gpt_summary":"user seek guidanc optim gpu resourc usag multipl instanc sent onlin serv specif ask prepackag contain serv infer manner tfx serv enabl batch optim batch paramet addition ask advic handl effici gpu usag prepackag custom contain custom train model"
    },
    {
        "Question_title":"HP Sweep: Conditional Sampling",
        "Question_body":"<p>Suppose I have a somewhat complicated hyper parameter distribution I\u2019d like to sample:<\/p>\n<p>For example, I have a hyperparameter called HP1 controlling normalization applied my dataset. If I sample HP1 \u2190 maximum-eigenvalue-norm, then maybe I have another hyperparameter I must sample; in this case that could be how to compute maximum eigenvalue which could be in the set {fancy-eigenvalue-computation, torch-built-in-symeig}.<\/p>\n<p>But suppose if normalization technique was sampled as HP1 \u2190 Frobenius-norm, then I have no other hyper parameters to sample.<\/p>\n<p>Optuna handles this nicely, and I was hoping W&amp;B\u2019s had a similar way of auto-magically handling it.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1632243031093,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":299.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/hp-sweep-conditional-sampling\/726",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sweep condit sampl suppos somewhat complic hyper paramet distribut like sampl exampl hyperparamet call control normal appli dataset sampl maximum eigenvalu norm mayb hyperparamet sampl case comput maximum eigenvalu set fanci eigenvalu comput torch built symeig suppos normal techniqu sampl frobeniu norm hyper paramet sampl handl nice hope similar wai auto magic handl",
        "Question_preprocessed_content":"condit sampl somewhat complic hyper paramet distribut like sampl exampl hyperparamet normal dataset sampl mayb hyperparamet sampl case comput maximum eigenvalu set normal techniqu sampl hyper paramet sampl handl nice hope similar wai handl",
        "Question_gpt_summary_original":"The user is looking for a way to sample a complicated hyperparameter distribution, where certain hyperparameters are conditional on others. They mention that Optuna handles this well and are hoping that W&B has a similar way of handling it.",
        "Question_gpt_summary":"user look wai sampl complic hyperparamet distribut certain hyperparamet condit mention handl hope similar wai handl"
    },
    {
        "Question_title":"normalized_boxes are bigger then one(1) - AWS SageMaker JumpStart SSD VGG16 Atrous 300",
        "Question_body":"<p>I deployed SSD VGG16 Atrous 300 model(COCO 2017, from Gluon CV) by AWS SageMaker JumpStart. Response from pretrained model contains normalized_boxes with values bigger than one(1), e.g.<\/p>\n<pre><code> \n&quot;normalized_boxes&quot;: [\n[\n0.4935379866715316,\n0.20722445845603943,\n0.7275399344308036,\n0.7329685688018799\n],\n[\n1.9931350875686813,\n0.15846982598304749,\n2.275825517256181,\n0.5962902307510376\n],\n...\n&quot;classes&quot;: [\n0,\n0,\n...\n&quot;scores&quot;: [\n0.344256728887558,\n0.4128507971763611,\n...\n&quot;labels&quot;: [\n&quot;person&quot;,\n&quot;bicycle&quot;,\n...\n&quot;mxnet_model_output&quot;: [\n[\n[\n[\n0\n],\n[\n0\n],\n...\n[\n[\n[\n0.9202409386634827\n],\n[\n0.9055193662643433\n],\n...\n[\n[\n[\n1551.213134765625,\n589.4755249023438,\n1808.19921875,\n878.4844360351562\n],\n[\n1557.686767578125,\n310.9128112792969,\n1805.559814453125,\n587.8072509765625\n],\n...\n\n<\/code><\/pre>\n<p>How to read those bounding boxes?<\/p>\n<p>I didn't manage to find the answer on gluon(<a href=\"https:\/\/cv.gluon.ai\/model_zoo\/detection.html\" rel=\"nofollow noreferrer\">https:\/\/cv.gluon.ai\/model_zoo\/detection.html<\/a>)<\/p>\n<p>The model can be fine-tuned, the rules how to prepare annotations(available in model description):\n&quot;The annotations.json file should should have information for bounding_boxes and their class labels. It should have a dictionary with keys &quot;images&quot; and &quot;annotations&quot;. Value for the &quot;images&quot; key should be a list of entries, one for each image of the form {&quot;file_name&quot;: image_name, &quot;height&quot;: height, &quot;width&quot;: width, &quot;id&quot;: image_id}. Value of the 'annotations' key should be a list of entries, one for each bounding box of the form {&quot;image_id&quot;: image_id, &quot;bbox&quot;: [xmin, ymin, xmax, ymax], &quot;category_id&quot;: bbox_label}.&quot;<\/p>\n<p>names of attributes are the same as in the COCO dataset - <a href=\"https:\/\/www.immersivelimit.com\/tutorials\/create-coco-annotations-from-scratch\/#coco-dataset-format\" rel=\"nofollow noreferrer\">https:\/\/www.immersivelimit.com\/tutorials\/create-coco-annotations-from-scratch\/#coco-dataset-format<\/a><\/p>\n<p>only this part is not consistent with COCO: &quot;[xmin, ymin, xmax, ymax]&quot; as I found, COCO has &quot;[x_min, y_min, width, height]&quot;(<a href=\"https:\/\/albumentations.ai\/docs\/getting_started\/bounding_boxes_augmentation\/\" rel=\"nofollow noreferrer\">https:\/\/albumentations.ai\/docs\/getting_started\/bounding_boxes_augmentation\/<\/a>)<\/p>\n<p>I tired also SSD VGG16 Atrous 512(pre-trained on VOC dataset) and faced the same problem, additionally, I received bbox value with a minus:<\/p>\n<pre><code>&quot;normalized_boxes&quot;: [\n        [\n            0.9567698719737294,\n            -0.14875292778015137,\n            1.0963617010430975,\n            0.5834765434265137\n        ],\n...\n<\/code><\/pre>\n<p>How to deal with values smaller than 0?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1654659657573,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":39.0,
        "Poster_created_time":1369428988750,
        "Poster_location":"Poland",
        "Poster_reputation_count":21.0,
        "Poster_view_count":8.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72539799",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"normal box bigger jumpstart ssd vgg atrou deploi ssd vgg atrou model coco gluon jumpstart respons pretrain model contain normal box valu bigger normal box class score label person bicycl mxnet model output read bound box manag answer gluon http gluon model zoo detect html model fine tune rule prepar annot avail model descript annot json file inform bound box class label dictionari kei imag annot valu imag kei list entri imag form file imag height height width width imag valu annot kei list entri bound box form imag imag bbox xmin ymin xmax ymax categori bbox label name attribut coco dataset http www immersivelimit com tutori creat coco annot scratch coco dataset format consist coco xmin ymin xmax ymax coco min min width height http albument doc get start bound box augment tire ssd vgg atrou pre train voc dataset face problem addition receiv bbox valu minu normal box deal valu smaller",
        "Question_preprocessed_content":"jumpstart atrou deploi atrou model jumpstart respons pretrain model contain valu read bound box manag answer model rule prepar json file inform label dictionari kei imag valu imag kei list entri imag form valu kei list entri bound box form name coco dataset consist coco xmin ymin xmax ymax coco width tire atrou voc dataset face problem receiv valu minu deal valu",
        "Question_gpt_summary_original":"The user has deployed an SSD VGG16 Atrous 300 model (COCO 2017) by AWS SageMaker JumpStart and is encountering issues with normalized_boxes having values bigger than one. The user is seeking guidance on how to read the bounding boxes and how to deal with values smaller than 0. The user has not found a solution on Gluon's website and is also facing the same problem with SSD VGG16 Atrous 512 (pre-trained on VOC dataset).",
        "Question_gpt_summary":"user deploi ssd vgg atrou model coco jumpstart encount issu normal box have valu bigger user seek guidanc read bound box deal valu smaller user solut gluon websit face problem ssd vgg atrou pre train voc dataset"
    },
    {
        "Question_title":"Error while deserializing the Apache MXNet object",
        "Question_body":"<p>I have trained and saved a model using Amazon SageMaker which saves the model in the format of <code>model.tar.gz<\/code> which when untarred, has a file <code>model_algo-1<\/code> which is a serialized Apache MXNet object. To load the model in memory I need to deserialize the model. I tried doing so as follows:<\/p>\n\n<p><code>import mxnet as mx\nprint(mx.ndarray.load('model_algo-1'))<\/code><\/p>\n\n<p>Reference taken from <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/cdf-training.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/cdf-training.html<\/a><\/p>\n\n<p>However, doing this yields me the following error:<\/p>\n\n<pre><code>Traceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"\/usr\/local\/lib\/python3.4\/site-packages\/mxnet\/ndarray\/utils.py\", line \n175, in load\nctypes.byref(names)))\nFile \"\/usr\/local\/lib\/python3.4\/site-packages\/mxnet\/base.py\", line 146, in \ncheck_call\nraise MXNetError(py_str(_LIB.MXGetLastError()))\nmxnet.base.MXNetError: [19:06:25] src\/ndarray\/ndarray.cc:1112: Check failed: \nheader == kMXAPINDArrayListMagic Invalid NDArray file format\n\nStack trace returned 10 entries:\n[bt] (0) \/usr\/local\/lib\/python3.4\/site-packages\/mxnet\/libmxnet.so(+0x192112) \n[0x7fe432bfa112]\n[bt] (1) \/usr\/local\/lib\/python3.4\/site-packages\/mxnet\/libmxnet.so(+0x192738) \n[0x7fe432bfa738]\n[bt] (2) \/usr\/local\/lib\/python3.4\/site-\npackages\/mxnet\/libmxnet.so(+0x24a5c44) [0x7fe434f0dc44]\n[bt] (3) \/usr\/local\/lib\/python3.4\/site-\npackages\/mxnet\/libmxnet.so(MXNDArrayLoad+0x248) [0x7fe434d19ad8]\n[bt] (4) \/usr\/lib64\/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe48c5bbcec]\n[bt] (5) \/usr\/lib64\/libffi.so.6(ffi_call+0x1f5) [0x7fe48c5bb615]\n[bt] (6) \/usr\/lib64\/python3.4\/lib-dynload\/_ctypes.cpython-\n34m.so(_ctypes_callproc+0x2fb) [0x7fe48c7ce18b]\n[bt] (7) \/usr\/lib64\/python3.4\/lib-dynload\/_ctypes.cpython-34m.so(+0xa4cf) \n[0x7fe48c7c84cf]\n[bt] (8) \/usr\/lib64\/libpython3.4m.so.1.0(PyObject_Call+0x8c) \n[0x7fe4942fcb5c]\n[bt] (9) \/usr\/lib64\/libpython3.4m.so.1.0(PyEval_EvalFrameEx+0x36c5) \n[0x7fe4943ac915]\n<\/code><\/pre>\n\n<p>Could someone suggest how this can be resolved?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3.0,
        "Question_created_time":1522869667753,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":971.0,
        "Poster_created_time":1474557627236,
        "Poster_location":null,
        "Poster_reputation_count":1039.0,
        "Poster_view_count":89.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49658834",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error deseri apach mxnet object train save model save model format model tar untar file model algo serial apach mxnet object load model memori need deseri model tri follow import mxnet print ndarrai load model algo refer taken http doc aw amazon com latest cdf train html yield follow error traceback recent file line file usr local lib python site packag mxnet ndarrai util line load ctype byref name file usr local lib python site packag mxnet base line check rais mxneterror str lib mxgetlasterror mxnet base mxneterror src ndarrai ndarrai check fail header kmxapindarraylistmag invalid ndarrai file format stack trace return entri usr local lib python site packag mxnet libmxnet xfebfa usr local lib python site packag mxnet libmxnet xfebfa usr local lib python site packag mxnet libmxnet xac xfefdc usr local lib python site packag mxnet libmxnet mxndarrayload xfedad usr lib libffi ffi unix xfecbbcec usr lib libffi ffi xfecbb usr lib python lib dynload ctype cpython ctype callproc xfb xfecceb usr lib python lib dynload ctype cpython xacf xfecccf usr lib libpython pyobject xfefcbc usr lib libpython pyeval evalframeex xfeac suggest resolv",
        "Question_preprocessed_content":"deseri apach mxnet object train save model save model format file serial apach mxnet object load model memori deseri model tri refer taken yield resolv",
        "Question_gpt_summary_original":"The user is encountering an error while trying to deserialize an Apache MXNet object that was saved in the format of 'model.tar.gz' using Amazon SageMaker. The error message indicates that the NDArray file format is invalid. The user is seeking suggestions on how to resolve this issue.",
        "Question_gpt_summary":"user encount error try deseri apach mxnet object save format model tar error messag indic ndarrai file format invalid user seek suggest resolv issu"
    },
    {
        "Question_title":"How to submit local jobs with dsl.pipeline",
        "Question_body":"<p>Trying to run and debug a pipeline locally. Pipeline is imeplemented with <code>azure.ml.component.dsl.pipeline<\/code>. When I try to set <code>default_compute_target='local'<\/code>, the compute target cannot be found:<\/p>\n<pre><code>local not found in workspace, assume this is an AmlCompute\n...\nFile &quot;\/home\/amirabdi\/miniconda3\/envs\/stm\/lib\/python3.8\/site-packages\/azure\/ml\/component\/run_settings.py&quot;, line 596, in _get_compute_type\n    raise InvalidTargetSpecifiedError(message=&quot;Cannot find compute '{}' in workspace.&quot;.format(compute_name))\nazure.ml.component._util._exceptions.InvalidTargetSpecifiedError: InvalidTargetSpecifiedError:\n        Message: Cannot find compute 'local' in workspace.\n        InnerException None\n        ErrorResponse\n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Cannot find compute 'local' in workspace.&quot;\n    }\n}\n<\/code><\/pre>\n<p>The local run, for example, can be achieved with <code>azureml.core.ScriptRunConfig<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>src = ScriptRunConfig(script=&quot;train.py&quot;, compute_target=&quot;local&quot;, environment=myenv)\nrun = exp.submit(src)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1659479334120,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":98.0,
        "Poster_created_time":1445300868316,
        "Poster_location":"Vancouver, BC, Canada",
        "Poster_reputation_count":2059.0,
        "Poster_view_count":252.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73214437",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"submit local job dsl pipelin try run debug pipelin local pipelin imepl azur compon dsl pipelin try set default comput target local comput target local workspac assum amlcomput file home amirabdi miniconda env stm lib python site packag azur compon run set line comput type rais invalidtargetspecifiederror messag comput workspac format comput azur compon util except invalidtargetspecifiederror invalidtargetspecifiederror messag comput local workspac innerexcept errorrespons error code usererror messag comput local workspac local run exampl achiev core scriptrunconfig src scriptrunconfig script train comput target local environ myenv run exp submit src",
        "Question_preprocessed_content":"submit local job try run debug pipelin pipelin imepl try set comput target local run exampl achiev",
        "Question_gpt_summary_original":"The user is encountering an issue while trying to run and debug a pipeline locally using azure.ml.component.dsl.pipeline. When attempting to set default_compute_target='local', the compute target cannot be found, resulting in an InvalidTargetSpecifiedError. The user can achieve local run using azureml.core.ScriptRunConfig.",
        "Question_gpt_summary":"user encount issu try run debug pipelin local azur compon dsl pipelin attempt set default comput target local comput target result invalidtargetspecifiederror user achiev local run core scriptrunconfig"
    },
    {
        "Question_title":"Dvc checkout takes long time",
        "Question_body":"<p>Hello,<br>\nI\u2019m testing dvc in the workspace(or dvc project) of a gpu server and NFS mounted NAS to that server.<\/p>\n<p>The dataset is about a million images (~40GB) and is located in NAS.<\/p>\n<p>I run the following command in my workspace:<\/p>\n<pre><code> dvc add \"dataset path in NAS\" -o .   (already set dvc cache dir in a path in NAS.)\n<\/code><\/pre>\n<p>This takes about 2 hours. (I wonder it\u2019s normal).<\/p>\n<p>The problem is when I run \u2018dvc checkout\u2019 in the other workspace to see it works fine, it takes about 1 hour. (I also set dvc config cache.type symlink.)<\/p>\n<p>Even though I make symlink files from the original dataset using os.symlink in python, it doesn\u2019t take this long. (I guess it\u2019s about a few minutes).<\/p>\n<p>Could I shorten this \u2018dvc checkout\u2019 time as short as possible?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/original\/1X\/977d7b25475db607c9da54f925de20434f5998cb.png\" data-download-href=\"\/uploads\/short-url\/lC8Wh3txuQbHAjckfoN7Ub1Q1lx.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/original\/1X\/977d7b25475db607c9da54f925de20434f5998cb.png\" alt=\"image\" data-base62-sha1=\"lC8Wh3txuQbHAjckfoN7Ub1Q1lx\" width=\"690\" height=\"314\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/977d7b25475db607c9da54f925de20434f5998cb_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">758\u00d7345 23.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1647850736880,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":541.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-checkout-takes-long-time\/1127",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"checkout take long time hello test workspac project gpu server nf mount na server dataset million imag locat na run follow command workspac add dataset path na set cach dir path na take hour wonder normal problem run checkout workspac work fine take hour set config cach type symlink symlink file origin dataset symlink python doesnt long guess minut shorten checkout time short possibl imag",
        "Question_preprocessed_content":"checkout take long time test workspac gpu server nf mount na server dataset imag locat na run workspac take hour problem run checkout workspac work fine take hour symlink file origin dataset python doesnt long shorten checkout time short imag",
        "Question_gpt_summary_original":"The user is facing a challenge with the 'dvc checkout' command taking a long time to execute. The user has a dataset of about a million images (~40GB) located in an NFS mounted NAS and has set the dvc cache directory in a path in NAS. The 'dvc add' command takes about 2 hours to execute, and when the user runs 'dvc checkout' in another workspace, it takes about 1 hour. The user is looking for ways to shorten the 'dvc checkout' time.",
        "Question_gpt_summary":"user face challeng checkout command take long time execut user dataset million imag locat nf mount na set cach directori path na add command take hour execut user run checkout workspac take hour user look wai shorten checkout time"
    },
    {
        "Question_title":"Documentai batch failure",
        "Question_body":"Hi,\n\nI am new to Google cloud platform, but I am testing out the Documentai API in python. I created an invoice parser and had successfully processed a few dozen invoices sequentially, before trying the batch API following the documentation. However, the code sample provided doen't work as a batch. Here is the sample code provided.\n\nhttps:\/\/cloud.google.com\/document-ai\/docs\/samples\/documentai-batch-process-documents-processor-versi...\n\nI used the alternative approach, to specify entire directory prefix. The batch started successfully, but terminated after 3 invoices we processed.\u00a0\n\nIt then threw below error.\u00a0\n\nValueError: ('Iterator has already started', <google.api_core.page_iterator.HTTPIterator object at 0x000001D0E8F089A0>)\n\n\n\nHas anyone encountered this error while using batch processing with Documentai?",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1679870640000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":86.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Documentai-batch-failure\/m-p\/537268#M1501",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"documentai batch failur new googl cloud platform test documentai api python creat invoic parser successfulli process dozen invoic sequenti try batch api follow document code sampl provid doen work batch sampl code provid http cloud googl com document doc sampl documentai batch process document processor versi altern approach specifi entir directori prefix batch start successfulli termin invoic process threw error valueerror iter start encount error batch process documentai",
        "Question_preprocessed_content":"documentai batch failur new cloud platform test documentai api python creat invoic parser dozen invoic try batch api document code sampl provid doen work batch sampl code provid altern specifi entir directori prefix batch start termin invoic threw encount batch documentai",
        "Question_gpt_summary_original":"The user is encountering a batch failure issue while using the Documentai API in Python. They were able to process a few dozen invoices sequentially but faced issues while using the batch API. The batch started successfully but terminated after processing three invoices and threw a ValueError. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":"user encount batch failur issu documentai api python abl process dozen invoic sequenti face issu batch api batch start successfulli termin process invoic threw valueerror user seek help resolv issu"
    },
    {
        "Question_title":"How to pre deploy the instances used by sagemaker for training?",
        "Question_body":"<p>Sagemaker takes ~3 mins for <code>preparing the instances for training<\/code> and around ~1 min for the actual training and artifact publishing.<\/p>\n<p>I want to pre-deploy some ec2 instances which it can use for training. However I couldn't find an option to specify pre deployed instances in the <code>ResourceConfig<\/code> part of the <code>createTrainingJob<\/code>.<\/p>\n<p>Is this possible?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1642316278607,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":30.0,
        "Poster_created_time":1551701216487,
        "Poster_location":null,
        "Poster_reputation_count":735.0,
        "Poster_view_count":106.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70727988",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pre deploi instanc train take min prepar instanc train min actual train artifact publish want pre deploi instanc us train couldn option specifi pre deploi instanc resourceconfig createtrainingjob possibl",
        "Question_preprocessed_content":"pre deploi instanc train take min min actual train artifact publish want instanc us train couldn option specifi pre deploi instanc",
        "Question_gpt_summary_original":"The user is facing a challenge with the time taken by Sagemaker to prepare instances for training. They are looking for a way to pre-deploy EC2 instances for Sagemaker to use, but are unable to find an option to specify pre-deployed instances in the ResourceConfig part of the createTrainingJob. They are seeking advice on whether this is possible.",
        "Question_gpt_summary":"user face challeng time taken prepar instanc train look wai pre deploi instanc us unabl option specifi pre deploi instanc resourceconfig createtrainingjob seek advic possibl"
    },
    {
        "Question_title":"Why do I encounter \"INVALID_PARAMETER VALUE\" error when opening \"Models\" tab in MLFlow UI?",
        "Question_body":"<p>I installed mlflow via pip and opened it in the browser through the terminal. The tab Experiments displays normally; however, when I switch to Models tab, the app crashes due to the following error:<\/p>\n<pre><code>INVALID_PARAMETER_VALUE: Model registry functionality is unavailable; \ngot unsupported URI '.\/mlruns' for model registry data storage. \nSupported URI schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. \nSee https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run \nan MLflow server against one of the supported backend storage locations.\n<\/code><\/pre>\n<p>I would like to log model data locally without connecting to external servers or databases. I thank you in advance for any help!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1659957616140,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1660218063030,
        "Question_score_count":1.0,
        "Question_view_count":39.0,
        "Poster_created_time":1652711404248,
        "Poster_location":null,
        "Poster_reputation_count":51.0,
        "Poster_view_count":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73277043",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"encount invalid paramet valu error open model tab instal pip open browser termin tab experi displai normal switch model tab app crash follow error invalid paramet valu model registri function unavail got unsupport uri mlrun model registri data storag support uri scheme postgresql mysql sqlite mssql http www org doc latest track html storag run server support backend storag locat like log model data local connect extern server databas thank advanc help",
        "Question_preprocessed_content":"encount valu open model tab pip open browser termin tab experi displai switch model tab crash like log model data extern server databas thank advanc help",
        "Question_gpt_summary_original":"The user encounters an \"INVALID_PARAMETER_VALUE\" error when trying to open the \"Models\" tab in MLFlow UI. The error message suggests that the model registry functionality is unavailable due to an unsupported URI for model registry data storage. The user wants to log model data locally without connecting to external servers or databases.",
        "Question_gpt_summary":"user encount invalid paramet valu error try open model tab error messag suggest model registri function unavail unsupport uri model registri data storag user want log model data local connect extern server databas"
    },
    {
        "Question_title":"Merge distinct sklearn models into a single one",
        "Question_body":"<p>I have a dataset where, after exploring data, I detect some patron:<\/p>\n<ul>\n<li>The entire dataset have, imagine, 9 numerical variables, 1 dichotomous variable (take 'A' or 'B' value) and 1 numerical output<\/li>\n<li>The output is a cost (in \u20ac)<\/li>\n<li>I find a sklearn regression model that, when 'A', using 4 of 9 variables I can predict output with good performance.<\/li>\n<li>I find another sklearn regression model that, when 'B', using the last 5 variables, I can predict output with good performance.<\/li>\n<li>If I try to find a model which predict output with all the variables as input, encoding the dichotomous one with One-Hot-Encoder, the model has a bad performance.<\/li>\n<\/ul>\n<p>My goal is to implement a unique model in Azure Machine Learning, using a .joblib\/.pkl, but with this approach, I have two separated models with the same output (a cost) but different inputs, depending of dichotomous variable.<\/p>\n<p>Is there any way to merge the two models into a single one? So that with the 10 inputs, estimate a single output (internally discriminate options 'A' and 'B' to select the correct model and its inputs).<\/p>\n<p>Notice that using something like Voting Ensemble it's not valid because there are different inputs on each category (or I think it so)<\/p>\n<p>I accept another approach as a solution. Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1633074956947,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":119.0,
        "Poster_created_time":1611139028547,
        "Poster_location":"Vigo, Espa\u00f1a",
        "Poster_reputation_count":39.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69402391",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"merg distinct sklearn model singl dataset explor data detect patron entir dataset imagin numer variabl dichotom variabl valu numer output output cost sklearn regress model variabl predict output good perform sklearn regress model variabl predict output good perform try model predict output variabl input encod dichotom hot encod model bad perform goal implement uniqu model joblib pkl approach separ model output cost differ input depend dichotom variabl wai merg model singl input estim singl output intern discrimin option select correct model input notic like vote ensembl valid differ input categori think accept approach solut thank",
        "Question_preprocessed_content":"merg distinct sklearn model singl dataset explor data detect patron entir dataset imagin numer variabl dichotom variabl numer output output cost sklearn model variabl predict output perform sklearn model variabl predict output perform try model predict output variabl input encod dichotom model bad perform goal implement uniqu model separ model output input depend dichotom variabl wai merg model singl input estim singl output notic like vote ensembl valid input categori solut thank",
        "Question_gpt_summary_original":"The user has two distinct sklearn regression models that predict output with good performance, but with different inputs depending on a dichotomous variable. The user wants to merge the two models into a single one that can estimate a single output using all 10 inputs, while internally discriminating between the options 'A' and 'B' to select the correct model and its inputs. The user is seeking a solution to implement a unique model in Azure Machine Learning.",
        "Question_gpt_summary":"user distinct sklearn regress model predict output good perform differ input depend dichotom variabl user want merg model singl estim singl output input intern discrimin option select correct model input user seek solut implement uniqu model"
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'ruamel' when excuting from azureml.core",
        "Question_body":"<p>I am trying to execute the Azure ml sdk from the local system using the Jupyter notebook. When I run the below code i am getting an error.<\/p>\n<pre><code>from azureml.core import Workspace, Datastore, Dataset\n\nModuleNotFoundError: No module named 'ruamel' \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1622646368700,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":332.0,
        "Poster_created_time":1599816833352,
        "Poster_location":"New Delhi, Delhi, India",
        "Poster_reputation_count":329.0,
        "Poster_view_count":58.0,
        "Answer_body":"<p>You have to add pip 20.1.1<\/p>\n<p>Conda ruamel needs higher version of pip<\/p>\n<pre><code>conda install pip=20.1.1\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1626743937907,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1536318818623,
        "Answerer_location":"\u0130zmit, Kocaeli, T\u00fcrkiye",
        "Answerer_reputation_count":1033.0,
        "Answerer_view_count":55.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67807756",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"modulenotfounderror modul name ruamel excut core try execut sdk local jupyt notebook run code get error core import workspac datastor dataset modulenotfounderror modul name ruamel",
        "Question_preprocessed_content":"modul name ruamel excut core try execut sdk local jupyt run code",
        "Question_gpt_summary_original":"The user is encountering a \"ModuleNotFoundError\" when trying to execute the Azure ml sdk from their local system using Jupyter notebook. The error message specifically states that there is no module named 'ruamel'.",
        "Question_gpt_summary":"user encount modulenotfounderror try execut sdk local jupyt notebook error messag specif state modul name ruamel"
    },
    {
        "Question_title":"Early Stopping and Callbacks with Keras when using SageMaker",
        "Question_body":"<p>I am using sagemaker to train a keras model. I need to implement early stoping approach when training the model. <\/p>\n\n<p>Is there a way to pass callbacks such as EarlyStopping, Histories..etc. <\/p>\n\n<p>In traditional way, we used to pass this as a parameter to keras's fit function:<\/p>\n\n<pre><code>results = model.fit(train_x_trim, train_y_trim, \n                    validation_data=(test_x, test_y), \n                    epochs=FLAGS.epoch,  \n                    verbose=0, \n                    callbacks=[tboard, checkpointer, early_stopping, history])\n<\/code><\/pre>\n\n<p>However, if using SageMaker, we need to call SageMaker's fit function instead which doesn't support callbacks. <\/p>\n\n<pre><code>from sagemaker.tensorflow import TensorFlow \niris_estimator = TensorFlow(entry_point='training_code.py', \n                            role=role, output_path=model_location, \n                            code_location=custom_code_upload_location, \n                            train_instance_count=1, \n                            train_instance_type='ml.c4.xlarge', \n                            training_steps=1000, \n                            evaluation_steps=100)\n<\/code><\/pre>\n\n<p>Any idea how to implement callbacks in SageMaker ? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1543252902240,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1543256081430,
        "Question_score_count":3.0,
        "Question_view_count":557.0,
        "Poster_created_time":1485886879543,
        "Poster_location":"Canada",
        "Poster_reputation_count":71.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53486118",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"earli stop callback kera train kera model need implement earli stope approach train model wai pass callback earlystop histori tradit wai pass paramet kera fit function result model fit train trim train trim valid data test test epoch flag epoch verbos callback tboard checkpoint earli stop histori need fit function instead support callback tensorflow import tensorflow iri estim tensorflow entri point train code role role output path model locat code locat custom code upload locat train instanc count train instanc type xlarg train step evalu step idea implement callback",
        "Question_preprocessed_content":"earli kera train kera model implement earli stope train model wai tradit wai paramet kera fit function fit function instead idea implement",
        "Question_gpt_summary_original":"The user is facing a challenge while using SageMaker to train a Keras model as SageMaker's fit function does not support callbacks such as EarlyStopping and Histories. The user is seeking a solution to implement callbacks in SageMaker.",
        "Question_gpt_summary":"user face challeng train kera model fit function support callback earlystop histori user seek solut implement callback"
    },
    {
        "Question_title":"Kubeflow pipeline fails on GKE cluster",
        "Question_body":"Need to create a Kubeflow pipeline for ML use-cases on GKE cluster, currently working on recommendation.\u00a0Have made the Vertex AI pipeline for the same but vertex being serverless takes time to make the containers up and then run the pipeline.\u00a0We needed a platform where the kubeflow pipelines can be executed faster - especially during development the results are needed instantly so that we can change inputs or tune the model.\n\nAfter uploading the yaml file, creating a run for the pipeline. After the first component the file read fails to write on the given bucket with below error.\n\nFileNotFoundError: [Errno 2] No such file or directory: '\/gcs\/bucket\/reco_v2\/637705bf-381e-40fa-8597-91089e700aaf\/pipeline\/reco_v2\/637705bf-381e-40fa-8597-91089e700aaf\/get-dataframe\/df_path.csv'39F0203 13:57:24.664574\u00a0 \u00a0 \u00a0 18 main.go:50] Failed to execute component: exit status 140time=\"2023-02-03T13:57:24.672Z\" level=error msg=\"cannot save artifact \/tmp\/outputs\/test_df_path\/data\" argo=true error=\"stat \/tmp\/outputs\/test_df_path\/data: no such file or directory\"41time=\"2023-02-03T13:57:24.672Z\" level=error msg=\"cannot save artifact \/tmp\/outputs\/train_df_path\/data\" argo=true error=\"stat \/tmp\/outputs\/train_df_path\/data: no such file or directory\"42Error: exit status 1\n\nTried running the sample tutorial kubeflow pipelines, they are running fine and does not throw any such file write error.\n\nWe have created a cluster and integrated Kubeflow pipelines from the GCP marketplace -> https:\/\/console.cloud.google.com\/marketplace\/details\/google-cloud-ai-platform\/kubeflow-pipelines\n\nNeed to know if there is a version issue or code is not proper or anything else. Have tried running a kfp v2 code too(from tutorials online) that worked well too.\n\nThe kubeflow pipeline should have worked and saved outputs to the bucket given.\n\nPlease help",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1675411680000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":117.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Kubeflow-pipeline-fails-on-GKE-cluster\/m-p\/517717#M1197",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"kubeflow pipelin fail gke cluster need creat kubeflow pipelin us case gke cluster current work recommend pipelin vertex serverless take time contain run pipelin need platform kubeflow pipelin execut faster especi develop result need instantli chang input tune model upload yaml file creat run pipelin compon file read fail write given bucket error filenotfounderror errno file directori gc bucket reco eaaf pipelin reco eaaf datafram path csv main fail execut compon exit statu time level error msg save artifact tmp output test path data argo true error stat tmp output test path data file directori time level error msg save artifact tmp output train path data argo true error stat tmp output train path data file directori error exit statu tri run sampl tutori kubeflow pipelin run fine throw file write error creat cluster integr kubeflow pipelin gcp marketplac http consol cloud googl com marketplac detail googl cloud platform kubeflow pipelin need know version issu code proper tri run kfp code tutori onlin work kubeflow pipelin work save output bucket given help",
        "Question_preprocessed_content":"kubeflow pipelin fail gke cluster creat kubeflow pipelin gke cluster work pipelin vertex take time contain run platform kubeflow pipelin execut faster develop result instantli chang input tune model upload yaml file creat run pipelin compon file read fail write given bucket file directori fail execut compon exit statu level msg save artifact argo true stat file level msg save artifact argo true stat file directori exit statu tri sampl tutori kubeflow pipelin fine throw file write creat cluster integr kubeflow pipelin gcp marketplac know version code proper tri kfp code work kubeflow pipelin work save output bucket given help",
        "Question_gpt_summary_original":"The user is facing issues while creating a Kubeflow pipeline for ML use-cases on GKE cluster. The pipeline fails after the first component due to a file read error. The user has tried running sample tutorial Kubeflow pipelines, which are running fine and not throwing any such file write error. The user has created a cluster and integrated Kubeflow pipelines from the GCP marketplace. The user needs help to identify if there is a version issue or code is not proper or anything else.",
        "Question_gpt_summary":"user face issu creat kubeflow pipelin us case gke cluster pipelin fail compon file read error user tri run sampl tutori kubeflow pipelin run fine throw file write error user creat cluster integr kubeflow pipelin gcp marketplac user need help identifi version issu code proper"
    },
    {
        "Question_title":"Azure Machine Learning Designer - Webservice input\/output disappear",
        "Question_body":"<p>Hi all,    <\/p>\n<p>I'm trying to create an inference pipeline with the AML designer.     <br \/>\nI clicked on the &quot;Create inference pipeline&quot; button:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/205064-image.png?platform=QnA\" alt=\"205064-image.png\" \/>    <\/p>\n<p>and now I want to do some changes in the pipeline. I added at the end two more steps and linked the Webservice output component to the last step:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/205028-image.png?platform=QnA\" alt=\"205028-image.png\" \/>    <\/p>\n<p>I clicked on save and submit it.     <br \/>\nThe result is the following:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/204999-image.png?platform=QnA\" alt=\"204999-image.png\" \/>    <\/p>\n<p>The two new steps are present and executed, but the webservice output step is disappeared! I've tried multiple time with the same result.     <br \/>\nThe webservice input step is correctly present at the beginning of the pipeline.    <\/p>\n<p>Also, after making the change and saving correctly, if I exit and reopen the pipeline the step &quot;Web Service Output&quot; is no longer there    <\/p>\n<p>Can you help me?    <\/p>\n<p>Thanks!    <\/p>\n<p>G    <\/p>",
        "Question_answer_count":8,
        "Question_comment_count":1.0,
        "Question_created_time":1653385681273,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi <a href=\"\/users\/na\/?userid=061108cd-43c2-45e6-aefa-0aaa3ab2e335\">@Antonio  <\/a>,     <\/p>\n<p>Sorry for the inconvenience caused.    <br \/>\nThis is a known bug and we've fixed. Could you please retry to see if you can still repro? I tried from my side either manually build an inference pipeline or modify the auto-gen inference pipeline, the web service input\/output components are still there.     <\/p>\n<p>If you can still repro, could you please provide following info for us to investigate?    <\/p>\n<ul>\n<li> your inference pipeline draft URL    <\/li>\n<li>  inference pipeline job URL of which the webservice input\/output components disappear    <\/li>\n<li> Is your workspace in Vnet?    <\/li>\n<\/ul>\n<p>We're also happy to set up a call to investigate, could you please send me an email so that I can send the meeting request?     <br \/>\nWe're based in Beijing (UTC+8).    <\/p>\n<p>Thanks!     <\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1654609016260,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/861882\/azure-machine-learning-designer-webservice-input-o",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"design webservic input output disappear try creat infer pipelin aml design click creat infer pipelin button want chang pipelin ad end step link webservic output compon step click save submit result follow new step present execut webservic output step disappear tri multipl time result webservic input step correctli present begin pipelin make chang save correctli exit reopen pipelin step web servic output longer help thank",
        "Question_preprocessed_content":"design webservic try creat infer pipelin aml design click creat infer pipelin want chang pipelin end step link webservic output compon step click save submit result new step present execut webservic output step tri multipl time result webservic input step present pipelin make chang save exit reopen pipelin step web servic output longer help thank",
        "Question_gpt_summary_original":"The user is facing an issue with Azure Machine Learning Designer where the Webservice output component disappears from the inference pipeline after adding two more steps and linking it to the last step. The user has tried multiple times with the same result and even after saving the changes, the step disappears when the pipeline is reopened.",
        "Question_gpt_summary":"user face issu design webservic output compon disappear infer pipelin ad step link step user tri multipl time result save chang step disappear pipelin reopen"
    },
    {
        "Question_title":"How to pass environment variables to gcloud beta ai custom-jobs create with custom container (Vertex AI)",
        "Question_body":"<p>I'm running custom training jobs in google's Vertex AI. A simple <code>gcloud<\/code> command to execute a custom job would use something like the following syntax (complete documentation for the command can be seen <a href=\"https:\/\/cloud.google.com\/sdk\/gcloud\/reference\/beta\/ai\/custom-jobs\/create#--config\" rel=\"nofollow noreferrer\">here<\/a>):<\/p>\n<pre><code>gcloud beta ai custom-jobs create --region=us-central1 \\\n--display-name=test \\\n--config=config.yaml\n<\/code><\/pre>\n<p>In the <code>config.yaml<\/code> file, it is possible to specify the machine and accelerator (GPU) types, etc., and in my case, point to a custom container living in the Google Artifact Registry that executes the training code (specified in the <code>imageUri<\/code> part of the <code>containerSpec<\/code>). An example config file may look like this:<\/p>\n<pre><code># config.yaml\nworkerPoolSpecs:\n  machineSpec:\n    machineType: n1-highmem-2\n    acceleratorType: NVIDIA_TESLA_P100\n    acceleratorCount: 2\n  replicaCount: 1\n  containerSpec:\n    imageUri: {URI_FOR_CUSTOM_CONATINER}\n    args:\n    - {ARGS TO PASS TO CONTAINER ENTRYPOINT COMMAND}\n<\/code><\/pre>\n<p>The code we're running needs some runtime environment variables (that need to be secure) passed to the container. In the <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/reference\/rest\/v1\/CustomJobSpec#containerspec\" rel=\"nofollow noreferrer\">API documentation<\/a> for the <code>containerSpec<\/code>, it says it is possible to set environment variables as follows:<\/p>\n<pre><code># config.yaml\nworkerPoolSpecs:\n  machineSpec:\n    machineType: n1-highmem-2\n    acceleratorType: NVIDIA_TESLA_P100\n    acceleratorCount: 2\n  replicaCount: 1\n  containerSpec:\n    imageUri: {URI_FOR_CUSTOM_CONATINER}\n    args:\n    - {ARGS TO PASS TO CONTAINER ENTRYPOINT COMMAND}\n    env:\n    - name: SECRET_ONE\n      value: $SECRET_ONE\n    - name: SECRET_TWO\n      value: $SECRET_TWO\n<\/code><\/pre>\n<p>When I try and add the <code>env<\/code> flag to the <code>containerSpec<\/code>, I get an error saying it's not part of the container spec:<\/p>\n<pre><code>ERROR: (gcloud.beta.ai.custom-jobs.create) INVALID_ARGUMENT: Invalid JSON payload received. Unknown name &quot;env&quot; at 'custom_job.job_spec.worker_pool_specs[0].container_spec': Cannot find field.\n- '@type': type.googleapis.com\/google.rpc.BadRequest\n  fieldViolations:\n  - description: &quot;Invalid JSON payload received. Unknown name \\&quot;env\\&quot; at 'custom_job.job_spec.worker_pool_specs[0].container_spec':\\\n      \\ Cannot find field.&quot;\n    field: custom_job.job_spec.worker_pool_specs[0].container_spec\n<\/code><\/pre>\n<p>Any idea how to securely set runtime environment variables in Vertex AI custom jobs using custom containers?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7.0,
        "Question_created_time":1632409414673,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1632410531832,
        "Question_score_count":3.0,
        "Question_view_count":1033.0,
        "Poster_created_time":1464106929608,
        "Poster_location":null,
        "Poster_reputation_count":457.0,
        "Poster_view_count":37.0,
        "Answer_body":"<p>There are two versions of the REST API - \u201c<a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/reference\/rest\/v1\/CustomJobSpec#containerspec\" rel=\"nofollow noreferrer\">v1<\/a>\u201d and \u201c<a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/reference\/rest\/v1beta1\/CustomJobSpec#containerspec\" rel=\"nofollow noreferrer\">v1beta1<\/a>\u201d where &quot;v1beta1&quot; does not have the <code>env<\/code> option in <code>ContainerSpec<\/code> but &quot;v1&quot; does. The <code>gcloud ai custom-jobs create<\/code> command without the <code>beta<\/code> parameter doesn\u2019t throw the error as it uses version \u201cv1\u201d to make the API calls.<\/p>\n<p>The environment variables from the yaml file can be passed to the custom container in the following way:<\/p>\n<p>This is the docker file of the sample custom training application I used to test the requirement. Please refer to this <a href=\"https:\/\/codelabs.developers.google.com\/vertex_custom_training_prediction\" rel=\"nofollow noreferrer\">codelab<\/a> for more information about the training application.<\/p>\n<pre class=\"lang-docker prettyprint-override\"><code>FROM gcr.io\/deeplearning-platform-release\/tf2-cpu.2-3\nWORKDIR \/root\n\nWORKDIR \/\n\n# Copies the trainer code to the docker image.\nCOPY trainer \/trainer\n\n\n# Copies the bash script to the docker image.\nCOPY commands.sh \/scripts\/commands.sh\n\n# Bash command to make the script file an executable\nRUN [&quot;chmod&quot;, &quot;+x&quot;, &quot;\/scripts\/commands.sh&quot;]\n\n\n# Command to execute the file\nENTRYPOINT [&quot;\/scripts\/commands.sh&quot;]\n\n# Sets up the entry point to invoke the trainer.\n# ENTRYPOINT &quot;python&quot; &quot;-m&quot; $SECRET_TWO \u21d2 To use the environment variable  \n# directly in the docker ENTRYPOINT. In case you are not using a bash script, \n# the trainer can be invoked directly from the docker ENTRYPOINT.\n<\/code><\/pre>\n<br \/>\n<p>Below is the <code>commands.sh<\/code> file used in the docker container to test whether the environment variables are passed to the container.<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>#!\/bin\/bash\nmkdir \/root\/.ssh\necho $SECRET_ONE\npython -m $SECRET_TWO\n<\/code><\/pre>\n<br \/>\n<p>The example <code>config.yaml<\/code> file<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code># config.yaml\nworkerPoolSpecs:\n  machineSpec:\n    machineType: n1-highmem-2\n  replicaCount: 1\n  containerSpec:\n    imageUri: gcr.io\/infosys-kabilan\/mpg:v1\n    env:\n    - name: SECRET_ONE\n      value: &quot;Passing the environment variables&quot;\n    - name: SECRET_TWO\n      value: &quot;trainer.train&quot;\n<\/code><\/pre>\n<p>As the next step, I built and pushed the container to Google Container Repository. Now, the <code>gcloud ai custom-jobs create --region=us-central1  --display-name=test --config=config.yaml<\/code> can be run to create the custom training job and the output of the <code>commands.sh<\/code> file can be seen in the job logs as shown below.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qRHV7.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qRHV7.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1632987814700,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1619163566860,
        "Answerer_location":null,
        "Answerer_reputation_count":1730.0,
        "Answerer_view_count":555.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69302528",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pass environ variabl gcloud beta custom job creat custom contain run custom train job googl simpl gcloud command execut custom job us like follow syntax complet document command seen gcloud beta custom job creat region central displai test config config yaml config yaml file possibl specifi machin acceler gpu type case point custom contain live googl artifact registri execut train code specifi imageuri containerspec exampl config file look like config yaml workerpoolspec machinespec machinetyp highmem acceleratortyp nvidia tesla acceleratorcount replicacount containerspec imageuri uri custom conatin arg arg pass contain entrypoint command code run need runtim environ variabl need secur pass contain api document containerspec sai possibl set environ variabl follow config yaml workerpoolspec machinespec machinetyp highmem acceleratortyp nvidia tesla acceleratorcount replicacount containerspec imageuri uri custom conatin arg arg pass contain entrypoint command env secret valu secret secret valu secret try add env flag containerspec error sai contain spec error gcloud beta custom job creat invalid argument invalid json payload receiv unknown env custom job job spec worker pool spec contain spec field type type googleapi com googl rpc badrequest fieldviol descript invalid json payload receiv unknown env custom job job spec worker pool spec contain spec field field custom job job spec worker pool spec contain spec idea secur set runtim environ variabl custom job custom contain",
        "Question_preprocessed_content":"environ variabl gcloud beta creat custom contain custom train job simpl execut custom job us like syntax file specifi machin type case point custom contain live artifact registri execut train code exampl config file like code runtim environ variabl contain api document sai set environ variabl try flag sai contain spec idea secur set runtim environ variabl custom job custom contain",
        "Question_gpt_summary_original":"The user is encountering an issue while trying to pass runtime environment variables to a custom container in Google's Vertex AI. The user is trying to use the \"env\" flag in the \"containerSpec\" section of the \"config.yaml\" file, but is receiving an error message stating that the \"env\" flag is not part of the container spec. The user is seeking a solution to securely set runtime environment variables in Vertex AI custom jobs using custom containers.",
        "Question_gpt_summary":"user encount issu try pass runtim environ variabl custom contain googl user try us env flag containerspec section config yaml file receiv error messag state env flag contain spec user seek solut secur set runtim environ variabl custom job custom contain"
    },
    {
        "Question_title":"Sagemaker Jumpstart 'Explain Credit Decisions' fails to deploy",
        "Question_body":"Im trying to use the Sagemaker Jumpstart 'Explain Credit Decisions' via the Studio Jumpstart menu. However, everything works as instructed until it hits the 'glue.wait_for_workflow_finished(config.GLUE_WORKFLOW, glue_run_id)' step in the datasets notebook. \n\nThis produces a \"failed to execute with exception Internal service error: Invalid Input Provided\" (error in the Glue console) and falls over on the job part of the glue job. \n\nDoes anyone have any ideas? This is as much information as is available in the console logs.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1660818001611,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1667926049704,
        "Question_score_count":0.0,
        "Question_view_count":110.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUMx_45pb_TLOfMOZINMG2JA\/sagemaker-jumpstart-explain-credit-decisions-fails-to-deploy",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"jumpstart explain credit decis fail deploi try us jumpstart explain credit decis studio jumpstart menu work instruct hit glue wait workflow finish config glue workflow glue run step dataset notebook produc fail execut except intern servic error invalid input provid error glue consol fall job glue job idea inform avail consol log",
        "Question_preprocessed_content":"jumpstart explain credit decis fail deploi try us jumpstart explain credit decis studio jumpstart menu work instruct hit step dataset produc fail execut except intern servic invalid input provid job glue job idea inform avail consol log",
        "Question_gpt_summary_original":"The user is facing an issue while using Sagemaker Jumpstart 'Explain Credit Decisions' via the Studio Jumpstart menu. The process fails at the 'glue.wait_for_workflow_finished(config.GLUE_WORKFLOW, glue_run_id)' step in the datasets notebook, producing an \"Internal service error: Invalid Input Provided\" error in the Glue console. The job part of the glue job fails, and the user is seeking help to resolve the issue.",
        "Question_gpt_summary":"user face issu jumpstart explain credit decis studio jumpstart menu process fail glue wait workflow finish config glue workflow glue run step dataset notebook produc intern servic error invalid input provid error glue consol job glue job fail user seek help resolv issu"
    },
    {
        "Question_title":"The difference between boto3.client and pymysql.connect",
        "Question_body":"<p>I am the novice in using AWS-RDS-mysql, Now I have a problem when connecting this database<\/p>\n\n<p>Here I have two ways to connect to my AWS-RDS-mysql, one is to use 'boto3' package and another is 'pymysql' package.<\/p>\n\n<p>For boto3, four paramaters are required, they are:<\/p>\n\n<pre><code>1) type='rds', \n2) region,\n3) aws_access_key_id\n4) aws_secret_access_key\n<\/code><\/pre>\n\n<p>The function I use is:<\/p>\n\n<pre><code>boto3.client(type, region, aws_access_key_id=key_id, aws_secret_access_key=access_key)\n<\/code><\/pre>\n\n<p>For pymysql, I need 5 parameters, they are:<\/p>\n\n<pre><code>1) host = \"databaseinstancename.cxxxxxxxxxx.ca-central-1.rds.amazonaws.com\"\n2) port = 3306\n3) dbname = \"xxx\"\n4) user = \"admin\"\n5) password = \"ssssss\"\n<\/code><\/pre>\n\n<p>The method I use is:<\/p>\n\n<pre><code>pymysql.connect(host, user=user, port=port, passwd=password, db=dbname)\n<\/code><\/pre>\n\n<p>All of them could connect to the database from my pycharm successfully.<\/p>\n\n<p>My question is <\/p>\n\n<p>1) what's the difference between the first method(using boto3) and the second one(using pymysql)? There are must be something difference because I provide two different kinds of information to connect.<\/p>\n\n<p>2) When I use jupyter notebook in AWS sagemaker to edit python3 code to try to connect to the database, I find only the first method(using boto3) could work, the second method(using pymysql) cannot connect successfully with a error saying that 'time out'. Why does this happen when one method could be accessible to the database but another one fails? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1585463084537,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1585463686460,
        "Question_score_count":0.0,
        "Question_view_count":936.0,
        "Poster_created_time":1585449302723,
        "Poster_location":null,
        "Poster_reputation_count":9.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60910863",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"differ boto client pymysql connect novic aw rd mysql problem connect databas wai connect aw rd mysql us boto packag pymysql packag boto paramat requir type rd region aw access kei aw secret access kei function us boto client type region aw access kei kei aw secret access kei access kei pymysql need paramet host databaseinstancenam cxxxxxxxxxx central rd amazonaw com port dbname xxx user admin password ssssss method us pymysql connect host user user port port passwd password dbname connect databas pycharm successfulli question differ method boto second pymysql differ provid differ kind inform connect us jupyt notebook edit python code try connect databas method boto work second method pymysql connect successfulli error sai time happen method access databas fail",
        "Question_preprocessed_content":" novic problem databas wai us boto packag pymysql packag boto paramat requir function us pymysql paramet method us databas pycharm question method second provid kind inform us jupyt edit python code try databas method work second method sai time method databas fail",
        "Question_gpt_summary_original":"The user is facing a problem while connecting to AWS-RDS-mysql database using two different methods - boto3 and pymysql. The user is confused about the difference between the two methods and why only boto3 is working in AWS Sagemaker while pymysql is giving a timeout error.",
        "Question_gpt_summary":"user face problem connect aw rd mysql databas differ method boto pymysql user confus differ method boto work pymysql give timeout error"
    },
    {
        "Question_title":"How to schedule repeated runs of a custom training job in Vertex AI",
        "Question_body":"<p>I have packaged my training code as a python package and then am able to run it as a custom training job on Vertex AI. Now, I wanted to be able to schedule this job to run, say every 2 weeks, and re-train the model. The Scheduling settings in the CustomJoBSpec allow only 2 fields, &quot;timeout&quot; and &quot;restartJobOnWorkerRestart&quot; so it's not possible using the scheduling settings in the CustomJobSpec. One way to achieve this I could think of was to create a Vertex AI pipeline with a single step using the &quot;CustomPythonPackageTrainingJobRunOp&quot; Google Cloud Pipeline Component and then scheduling the pipeline to run as I see fit. Are there better alternatives to achieve this?<\/p>\n<p><strong>Edit:<\/strong><\/p>\n<p>I was able to schedule the custom training job using Cloud Scheduler, but I found using the create_schedule_from_job_spec method in the AIPlatformClient very easy to use in the Vertex AI pipeline. The steps I took to schedule the custom job using Cloud Scheduler in gcp are as follows, <a href=\"https:\/\/cloud.google.com\/scheduler\/docs\/http-target-auth#setting_up_the_service_account\" rel=\"nofollow noreferrer\">link<\/a> to google docs:<\/p>\n<ol>\n<li>Set target type to HTTP<\/li>\n<li>For the url to specify the custom job, I followed <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/training\/create-custom-job#curl\" rel=\"nofollow noreferrer\">this<\/a> link to get the url<\/li>\n<li>For the authentication, under Auth header, I selected the &quot;Add OAauth token&quot;<\/li>\n<\/ol>\n<p>You also need to have a &quot;Cloud Scheduler service account&quot; with  a &quot;Cloud Scheduler Service Agent role granted to it&quot; in your project. Although the docs ay this should have been set up automatically if you enabled the Cloud Scheduler API after March 19, 2019, this was not the case for me and had to add the service account with the role manually.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6.0,
        "Question_created_time":1629043963683,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1629147961556,
        "Question_score_count":2.0,
        "Question_view_count":2669.0,
        "Poster_created_time":1471292986790,
        "Poster_location":null,
        "Poster_reputation_count":700.0,
        "Poster_view_count":90.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68793294",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"schedul repeat run custom train job packag train code python packag abl run custom train job want abl schedul job run week train model schedul set customjobspec allow field timeout restartjobonworkerrestart possibl schedul set customjobspec wai achiev think creat pipelin singl step custompythonpackagetrainingjobrunop googl cloud pipelin compon schedul pipelin run fit better altern achiev edit abl schedul custom train job cloud schedul creat schedul job spec method aiplatformcli easi us pipelin step took schedul custom job cloud schedul gcp follow link googl doc set target type http url specifi custom job follow link url authent auth header select add oaauth token need cloud schedul servic account cloud schedul servic agent role grant project doc set automat enabl cloud schedul api march case add servic account role manual",
        "Question_preprocessed_content":"schedul repeat run custom train job packag train code python packag abl run custom train job want abl schedul job run model schedul customjobspec field timeout schedul customjobspec wai achiev think creat pipelin singl step custompythonpackagetrainingjobrunop cloud pipelin compon schedul pipelin run fit altern achiev edit abl schedul custom train job cloud schedul method aiplatformcli easi us pipelin step schedul custom job cloud schedul gcp link doc set target type url specifi custom job link url authent auth header select token cloud schedul servic cloud schedul servic agent role grant project doc set enabl cloud schedul api march case servic role",
        "Question_gpt_summary_original":"The user wants to schedule a custom training job to run every two weeks on Vertex AI, but the scheduling settings in the CustomJobSpec only allow for two fields. The user suggests creating a Vertex AI pipeline with a single step using the CustomPythonPackageTrainingJobRunOp component and scheduling the pipeline to run. The user later found that they could schedule the custom job using Cloud Scheduler by following specific steps.",
        "Question_gpt_summary":"user want schedul custom train job run week schedul set customjobspec allow field user suggest creat pipelin singl step custompythonpackagetrainingjobrunop compon schedul pipelin run user later schedul custom job cloud schedul follow specif step"
    },
    {
        "Question_title":"How to get an Amazon ECR container URI for a specific model image in Sagemaker?",
        "Question_body":"<p>I want to know if it's possible to get an Amazon ECR container URI for a specific image programmatically (using AWS CLI or Python). For example, if I need the URL for the latest <code>linear-learner<\/code> (built-in model) image for the <code>eu-central-1<\/code> region.<\/p>\n<p>Expected result:<\/p>\n<pre><code>664544806723.dkr.ecr.eu-central-1.amazonaws.com\/linear-learner:latest\n<\/code><\/pre>\n<p>EDIT: I have found the solution with <code>get_image_uri<\/code>. It looks like this function will be depreceated and I don't know how to use <code>ImageURIProvider<\/code> instead.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":3.0,
        "Question_created_time":1599474994217,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1599481967088,
        "Question_score_count":4.0,
        "Question_view_count":3017.0,
        "Poster_created_time":1511210305768,
        "Poster_location":"Bad Orb, Germany",
        "Poster_reputation_count":12908.0,
        "Poster_view_count":1267.0,
        "Answer_body":"<p>The newer versions of SageMaker SDK have a more centralized API for getting the URIs:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import sagemaker \nsagemaker.image_uris.retrieve(&quot;linear-learner&quot;, &quot;eu-central-1&quot;)\n<\/code><\/pre>\n<p>which gives the expected result:<\/p>\n<pre><code>664544806723.dkr.ecr.eu-central-1.amazonaws.com\/linear-learner:1\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1617813746592,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1412713062067,
        "Answerer_location":"Munich, Germany",
        "Answerer_reputation_count":3603.0,
        "Answerer_view_count":228.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63775893",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"amazon ecr contain uri specif model imag want know possibl amazon ecr contain uri specif imag programmat aw cli python exampl need url latest linear learner built model imag central region expect result dkr ecr central amazonaw com linear learner latest edit solut imag uri look like function deprec know us imageuriprovid instead",
        "Question_preprocessed_content":"amazon ecr contain uri specif model imag want know amazon ecr contain uri specif imag exampl url latest imag region expect result edit solut like function deprec know us instead",
        "Question_gpt_summary_original":"The user is seeking a way to programmatically obtain an Amazon ECR container URI for a specific image, such as the latest linear-learner built-in model image for the eu-central-1 region, using AWS CLI or Python. The user has found a solution using get_image_uri but is unsure how to use ImageURIProvider instead, as get_image_uri is being deprecated.",
        "Question_gpt_summary":"user seek wai programmat obtain amazon ecr contain uri specif imag latest linear learner built model imag central region aw cli python user solut imag uri unsur us imageuriprovid instead imag uri deprec"
    },
    {
        "Question_title":"Is there a way to access compute quotas with the Azure CLI or Python SDK?",
        "Question_body":"<p>I want to tabulate the compute quotas for each Azure ML workspace, in each Azure location, for my organization's Azure subscription. Although it is possible to look at the quotas manually through the Azure Portal (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#workspace-level-quota\" rel=\"nofollow noreferrer\">link<\/a>), I have not found a way to do this with the Azure CLI or Python SDK for Azure. Since there are many resource groups and AML workspaces for different teams under my Azure subscription, it would be much more efficient to do this programmatically rather than manually through the portal. Is this even possible, and if so how can it be done?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1597248542537,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1597249191852,
        "Question_score_count":2.0,
        "Question_view_count":418.0,
        "Poster_created_time":1369863777596,
        "Poster_location":"Cambridge, MA",
        "Poster_reputation_count":335.0,
        "Poster_view_count":23.0,
        "Answer_body":"<p>It does look like these commands are currently in the CLI or the Python SDK. The CLI uses the Python SDK, so what's missing from one does tend to be missing from the other.<\/p>\n<p>Fortunately, you can invoke the rest endpoints directly, either in Python or by using the <code>az rest<\/code> command in the CLI.<\/p>\n<p>There are a few commands that may interest you:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/usages\/list\" rel=\"nofollow noreferrer\">Usage<\/a> and Quotas for a region:\n<code>\/subscriptions\/{subscriptionId}\/providers\/Microsoft.MachineLearningServices\/locations\/{location}\/usages?api-version=2019-05-01<\/code>\n<code>\/subscriptions\/{subscriptionId}\/providers\/Microsoft.MachineLearningServices\/locations\/{location}\/quotas?api-version=2020-04-01<\/code><\/p>\n<p>The process for updating REST specs to the offical documentation is fairly lengthy so it isn't published yet, but if you are willing to use Swagger docs to explore what is available, the 2020-06-01 version of the API is on Github, which includes endpoints for updating quotas as well as retrieving them: <a href=\"https:\/\/github.com\/Azure\/azure-rest-api-specs\/tree\/master\/specification\/machinelearningservices\/resource-manager\/Microsoft.MachineLearningServices\/stable\/2020-06-01\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-rest-api-specs\/tree\/master\/specification\/machinelearningservices\/resource-manager\/Microsoft.MachineLearningServices\/stable\/2020-06-01<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1597341970283,
        "Answer_last_edit_time":1597439016992,
        "Answer_score_count":1.0,
        "Answerer_created_time":1549041651583,
        "Answerer_location":"Atlanta, GA, USA",
        "Answerer_reputation_count":3106.0,
        "Answerer_view_count":428.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63380531",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wai access comput quota azur cli python sdk want tabul comput quota workspac azur locat organ azur subscript possibl look quota manual azur portal link wai azur cli python sdk azur resourc group aml workspac differ team azur subscript effici programmat manual portal possibl",
        "Question_preprocessed_content":"wai comput quota azur cli python sdk want tabul comput quota workspac azur locat organ azur subscript quota azur portal wai azur cli python sdk azur resourc group aml workspac team azur subscript portal",
        "Question_gpt_summary_original":"The user wants to access compute quotas for each Azure ML workspace in each Azure location for their organization's Azure subscription. They are looking for a way to do this programmatically using the Azure CLI or Python SDK, as it would be more efficient than doing it manually through the Azure Portal.",
        "Question_gpt_summary":"user want access comput quota workspac azur locat organ azur subscript look wai programmat azur cli python sdk effici manual azur portal"
    },
    {
        "Question_title":"Sagemaker Pipeline Deploy Model Step",
        "Question_body":"According to [Sagemaker's Pipeline Python SDK documenation](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/build-and-manage-steps.html), looks like there is no specific pipeline step for model deployment. \n\nCan you please confirm this and, also, if there is a plan to have such a step? \n\nWhat is the recommended way to add a pipeline step to deploy the trained model, resulting in an enpoint being created?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1669850852340,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1670198562116,
        "Question_score_count":0.0,
        "Question_view_count":312.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Hi, there is indeed no specific pipeline step for model deployment. The idea is that SageMaker Pipelines is more about \"batch mode\", but customers do ask for this feature, so it might be added. \n\nYou can implement it quite easily using Lambda Step.\n\n1st create a Lambda function to deploy\/update the model:\n```\n%%writefile deploy_model_lambda.py\n\n\n\"\"\"\nThis Lambda function deploys the model to SageMaker Endpoint. \nIf Endpoint exists, then Endpoint will be updated with new Endpoint Config.\n\"\"\"\n\nimport json\nimport boto3\nimport time\n\n\nsm_client = boto3.client(\"sagemaker\")\n\n\ndef lambda_handler(event, context):\n\n    print(f\"Received Event: {event}\")\n\n    current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n    endpoint_instance_type = event[\"endpoint_instance_type\"]\n    model_name = event[\"model_name\"]\n    endpoint_config_name = \"{}-{}\".format(event[\"endpoint_config_name\"], current_time)\n    endpoint_name = event[\"endpoint_name\"]\n\n    # Create Endpoint Configuration\n    create_endpoint_config_response = sm_client.create_endpoint_config(\n        EndpointConfigName=endpoint_config_name,\n        ProductionVariants=[\n            {\n                \"InstanceType\": endpoint_instance_type,\n                \"InitialVariantWeight\": 1,\n                \"InitialInstanceCount\": 1,\n                \"ModelName\": model_name,\n                \"VariantName\": \"AllTraffic\",\n            }\n        ],\n    )\n    print(f\"create_endpoint_config_response: {create_endpoint_config_response}\")\n\n    # Check if an endpoint exists. If no - Create new endpoint, if yes - Update existing endpoint\n    list_endpoints_response = sm_client.list_endpoints(\n        SortBy=\"CreationTime\",\n        SortOrder=\"Descending\",\n        NameContains=endpoint_name,\n    )\n    print(f\"list_endpoints_response: {list_endpoints_response}\")\n\n    if len(list_endpoints_response[\"Endpoints\"]) > 0:\n        print(\"Updating Endpoint with new Endpoint Configuration\")\n        update_endpoint_response = sm_client.update_endpoint(\n            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n        )\n        print(f\"update_endpoint_response: {update_endpoint_response}\")\n    else:\n        print(\"Creating Endpoint\")\n        create_endpoint_response = sm_client.create_endpoint(\n            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n        )\n        print(f\"create_endpoint_response: {create_endpoint_response}\")\n\n    return {\"statusCode\": 200, \"body\": json.dumps(\"Endpoint Created Successfully\")}\n```\n\nThen create the Lambda step:\n```\ndeploy_model_lambda_function_name = \"sagemaker-deploy-model-lambda-\" + current_time\n\ndeploy_model_lambda_function = Lambda(\n    function_name=deploy_model_lambda_function_name,\n    execution_role_arn=lambda_role,\n    script=\"deploy_model_lambda.py\",\n    handler=\"deploy_model_lambda.lambda_handler\",\n)\n```\n\nYou can see a full working example in [this notebook](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/sagemaker-pipelines\/tabular\/tensorflow2-california-housing-sagemaker-pipelines-deploy-endpoint\/tensorflow2-california-housing-sagemaker-pipelines-deploy-endpoint.ipynb).",
        "Answer_comment_count":0.0,
        "Question_closed_time":1669881877547,
        "Answer_last_edit_time":1669881962643,
        "Answer_score_count":2.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUiGdmBa_oQJuiiewjUhe9OA\/sagemaker-pipeline-deploy-model-step",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"pipelin deploi model step accord pipelin python sdk documen http doc aw amazon com latest build manag step html look like specif pipelin step model deploy confirm plan step recommend wai add pipelin step deploi train model result enpoint creat",
        "Question_preprocessed_content":"pipelin deploi model step like specif pipelin step model deploy confirm plan step wai pipelin step deploi train model result enpoint creat",
        "Question_gpt_summary_original":"The user is inquiring about the absence of a specific pipeline step for model deployment in Sagemaker's Pipeline Python SDK documentation and is seeking confirmation and information on any plans to introduce such a step. They are also asking for recommendations on the best way to add a pipeline step for deploying a trained model and creating an endpoint.",
        "Question_gpt_summary":"user inquir absenc specif pipelin step model deploy pipelin python sdk document seek confirm inform plan introduc step ask recommend best wai add pipelin step deploi train model creat endpoint"
    },
    {
        "Question_title":"AWS SageMaker: Create an endpoint using a trained model hosted in S3",
        "Question_body":"<p>I have following this <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/introduction_to_amazon_algorithms\/semantic_segmentation_pascalvoc\/semantic_segmentation_pascalvoc.ipynb\" rel=\"nofollow noreferrer\">tutorial<\/a>, which is mainly for jupyter notebook, and made some minimal modification for external processing. I've created a project that could prepare my dataset locally, upload it to S3, train, and finally deploy the model predictor to the same bucket. Perfect!<\/p>\n<p>So, after to train and saved it in S3 bucket:<\/p>\n<pre><code> ss_model.fit(inputs=data_channels, logs=True)\n<\/code><\/pre>\n<p>it failed while deploying as an endpoint. So, I have found tricks to host an endpoint in many ways, but not from a model already saved in S3. Because in order to host, you probably need to get the estimator, which in normal way is something like:<\/p>\n<pre><code> self.estimator = sagemaker.estimator.Estimator(self.training_image,\n                                                role,\n                                                train_instance_count=1,\n                                                train_instance_type='ml.p3.2xlarge',\n                                                train_volume_size=50,\n                                                train_max_run=360000,\n                                                output_path=output,\n                                                base_job_name='ss-training',\n                                                sagemaker_session=sess)\n<\/code><\/pre>\n<p>My question is: is there a way to load an estimator from a model saved in S3 (.tar)? Or, anyway, to create an endpoint without train it again?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1593283354330,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":1360.0,
        "Poster_created_time":1429270603900,
        "Poster_location":"S\u00e3o Jos\u00e9 dos Campos, Sao Jose dos Campos - State of S\u00e3o Paulo, Brazil",
        "Poster_reputation_count":138.0,
        "Poster_view_count":38.0,
        "Answer_body":"<p>So, after to run on many pages, just found a clue <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/introduction_to_amazon_algorithms\/blazingtext_hosting_pretrained_fasttext\/blazingtext_hosting_pretrained_fasttext.ipynb\" rel=\"nofollow noreferrer\">here<\/a>. And I finally found out how to load the model and create the endpoint:<\/p>\n<pre><code>def create_endpoint(self):\n    sess = sagemaker.Session()\n    training_image = get_image_uri(sess.boto_region_name, 'semantic-segmentation', repo_version=&quot;latest&quot;)        \n    role = &quot;YOUR_ROLE_ARN_WITH_SAGEMAKER_EXECUTION&quot;\n    model = &quot;s3:\/\/BUCKET\/PREFIX\/...\/output\/model.tar.gz&quot;\n\n    sm_model = sagemaker.Model(model_data=model, image=training_image, role=role, sagemaker_session=sess)\n    sm_model.deploy(initial_instance_count=1, instance_type='ml.p3.2xlarge')\n<\/code><\/pre>\n<p><strong>Please, do not forget to disable your endpoint after using. This is really important! Endpoints are charged by &quot;running&quot; not only by the use<\/strong><\/p>\n<p>I hope it also can help you out!<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1593463280863,
        "Answer_last_edit_time":1595855655040,
        "Answer_score_count":3.0,
        "Answerer_created_time":1429270603900,
        "Answerer_location":"S\u00e3o Jos\u00e9 dos Campos, Sao Jose dos Campos - State of S\u00e3o Paulo, Brazil",
        "Answerer_reputation_count":138.0,
        "Answerer_view_count":38.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62614143",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat endpoint train model host follow tutori mainli jupyt notebook minim modif extern process creat project prepar dataset local upload train final deploi model predictor bucket perfect train save bucket model fit input data channel log true fail deploi endpoint trick host endpoint wai model save order host probabl need estim normal wai like self estim estim estim self train imag role train instanc count train instanc type xlarg train volum size train max run output path output base job train session sess question wai load estim model save tar creat endpoint train",
        "Question_preprocessed_content":"creat endpoint train model host tutori mainli jupyt minim modif extern creat project prepar dataset upload train deploi model predictor bucket perfect train save bucket fail deploi endpoint trick host endpoint wai model save order host probabl estim normal wai like question wai load estim model save creat endpoint train",
        "Question_gpt_summary_original":"The user has followed a tutorial to create a project using AWS SageMaker that prepares a dataset locally, uploads it to S3, trains a model, and deploys the model predictor to the same bucket. However, while deploying the model as an endpoint, it failed. The user is looking for a way to load an estimator from a model saved in S3 or create an endpoint without training it again.",
        "Question_gpt_summary":"user follow tutori creat project prepar dataset local upload train model deploi model predictor bucket deploi model endpoint fail user look wai load estim model save creat endpoint train"
    },
    {
        "Question_title":"Is there any workaround for installing packages ? (deepspeed error)",
        "Question_body":"<p>i was trying to use deepspeed, but when i run the training it shows an error. I have to install mpi4py using pip. However if I try to install mpi4py i get an error.\nFrom that error i found out that to install the package, i must install &quot;libopenmpi-dev &quot; before, using apt. However we dont have the password to sudo. Any workaround to this ?\n(or the only option is to change platforms ?)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":9.0,
        "Question_created_time":1659082147263,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1659169326400,
        "Question_score_count":0.0,
        "Question_view_count":73.0,
        "Poster_created_time":1653740518870,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73163540",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"workaround instal packag deepspe error try us deepspe run train show error instal mpipi pip try instal mpipi error error instal packag instal libopenmpi dev apt dont password sudo workaround option chang platform",
        "Question_preprocessed_content":"workaround packag try us run train show mpi pip try mpi packag apt dont sudo workaround option chang platform",
        "Question_gpt_summary_original":"The user is facing an error while trying to use deepspeed for training. They need to install mpi4py using pip, but it requires installing \"libopenmpi-dev\" using apt, which requires sudo password. The user is looking for a workaround to install the package without sudo or if changing platforms is the only option.",
        "Question_gpt_summary":"user face error try us deepspe train need instal mpipi pip requir instal libopenmpi dev apt requir sudo password user look workaround instal packag sudo chang platform option"
    },
    {
        "Question_title":"error to run training job with aws Sagemaker",
        "Question_body":"<p>I am trying to use my own sickit-learn ML model with SageMaker using the github example.<\/p>\n\n<p>The python code is below : <\/p>\n\n<pre><code># Define IAM role import boto3 \nimport re \nimport os \nimport numpy as np \nimport pandas as pd \nfrom sagemaker import get_execution_role \nimport sagemaker as sage from time \nimport gmtime, strftime \nrole = get_execution_role()\n\ness =  sage.Session()\naccount = sess.boto_session.client('sts').get_caller_identity()['Account']\nregion = sess.boto_session.region_name\nimage = '{}.dkr.ecr.{}.amazonaws.com\/decision-trees-sample:latest'.format(account, region)\n\n\noutput_path=\"s3:\/\/output\"\n\nsess\n\ntree = sage.estimator.Estimator(image,\n                      role, 1, 'ml.c4.2xlarge',\n                     output_path='s3-eu-west-1.amazonaws.com\/output',\n                    sagemaker_session=sess)\n\ntree.fit(\"s3:\/\/output\/iris.csv\")\n<\/code><\/pre>\n\n<p>But I get this error : <\/p>\n\n<blockquote>\n  <p>INFO:sagemaker:Creating training-job with name:\n  decision-trees-sample-2018-04-24-13-13-38-281<\/p>\n  \n  <p>--------------------------------------------------------------------------- ClientError                               Traceback (most recent call\n  last)  in ()\n       14                     sagemaker_session=sess)\n       15 \n  ---> 16 tree.fit(\"s3:\/\/inteldatastore-cyrine\/iris.csv\")<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/estimator.py\n  in fit(self, inputs, wait, logs, job_name)\n      161             self.output_path = 's3:\/\/{}\/'.format(self.sagemaker_session.default_bucket())\n      162 \n  --> 163         self.latest_training_job = _TrainingJob.start_new(self, inputs)\n      164         if wait:\n      165             self.latest_training_job.wait(logs=logs)<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/estimator.py\n  in start_new(cls, estimator, inputs)\n      336                                           input_config=input_config, role=role,\n  job_name=estimator._current_job_name,\n      337                                           output_config=output_config, resource_config=resource_config,\n  --> 338                                           hyperparameters=hyperparameters, stop_condition=stop_condition)\n      339 \n      340         return cls(estimator.sagemaker_session, estimator._current_job_name)<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/session.py\n  in train(self, image, input_mode, input_config, role, job_name,\n  output_config, resource_config, hyperparameters, stop_condition)\n      242         LOGGER.info('Creating training-job with name: {}'.format(job_name))\n      243         LOGGER.debug('train request: {}'.format(json.dumps(train_request, indent=4)))\n  --> 244         self.sagemaker_client.create_training_job(**train_request)\n      245 \n      246     def create_model(self, name, role, primary_container):<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/botocore\/client.py\n  in _api_call(self, *args, **kwargs)\n      312                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n      313             # The \"self\" in this scope is referring to the BaseClient.\n  --> 314             return self._make_api_call(operation_name, kwargs)\n      315 \n      316         _api_call.<strong>name<\/strong> = str(py_operation_name)<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/botocore\/client.py\n  in _make_api_call(self, operation_name, api_params)\n      610             error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\n      611             error_class = self.exceptions.from_code(error_code)\n  --> 612             raise error_class(parsed_response, operation_name)\n      613         else:\n      614             return parsed_response<\/p>\n  \n  <p>ClientError: An error occurred (AccessDeniedException) when calling\n  the CreateTrainingJob operation: User:\n  arn:aws:sts::307504647302:assumed-role\/default\/SageMaker is\n  not authorized to perform: sagemaker:CreateTrainingJob on resource:\n  arn:aws:sagemaker:eu-west-1:307504647302:training-job\/decision-trees-sample-2018-04-24-13-13-38-281<\/p>\n<\/blockquote>\n\n<p>Can you help me to resolve the problem?<\/p>\n\n<p>Thank you<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1.0,
        "Question_created_time":1524576827563,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":4369.0,
        "Poster_created_time":1518617852856,
        "Poster_location":null,
        "Poster_reputation_count":495.0,
        "Poster_view_count":81.0,
        "Answer_body":"<p>Looks like you don't have access to the resource <\/p>\n\n<pre><code>arn:aws:sagemaker:eu-west-1:307504647302:training-job\/decision-trees-sample-2018-04-24-13-13-38-281\n<\/code><\/pre>\n\n<p>Can you check if the resource url is correct and the proper permissions are set in the security group. <\/p>",
        "Answer_comment_count":5.0,
        "Question_closed_time":1524587840612,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1467237684900,
        "Answerer_location":null,
        "Answerer_reputation_count":613.0,
        "Answerer_view_count":39.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50003050",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error run train job try us sickit learn model github exampl python code defin iam role import boto import import import numpi import panda import execut role import sage time import gmtime strftime role execut role ess sage session account sess boto session client st caller ident account region sess boto session region imag dkr ecr amazonaw com decis tree sampl latest format account region output path output sess tree sage estim estim imag role xlarg output path west amazonaw com output session sess tree fit output iri csv error info creat train job decis tree sampl clienterror traceback recent session sess tree fit inteldatastor cyrin iri csv anaconda env python lib python site packag estim fit self input wait log job self output path format self session default bucket self latest train job trainingjob start new self input wait self latest train job wait log log anaconda env python lib python site packag estim start new cl estim input input config input config role role job estim current job output config output config resourc config resourc config hyperparamet hyperparamet stop condit stop condit return cl estim session estim current job anaconda env python lib python site packag session train self imag input mode input config role job output config resourc config hyperparamet stop condit logger info creat train job format job logger debug train request format json dump train request indent self client creat train job train request def creat model self role primari contain anaconda env python lib python site packag botocor client api self arg kwarg accept keyword argument oper self scope refer basecli return self api oper kwarg api str oper anaconda env python lib python site packag botocor client api self oper api param error code pars respons error code error class self except code error code rais error class pars respons oper return pars respons clienterror error occur accessdeniedexcept call createtrainingjob oper user arn aw st assum role default author perform createtrainingjob resourc arn aw west train job decis tree sampl help resolv problem thank",
        "Question_preprocessed_content":"run train job try us model github exampl python code info creat traceback fit input wait estim input role role hyperparamet hyperparamet return train info debug def role arg kwarg keyword self scope basecli return kwarg rais return createtrainingjob oper user author perform createtrainingjob resourc help resolv problem thank",
        "Question_gpt_summary_original":"The user is encountering an error while trying to run a training job with AWS SageMaker. The error message indicates that the user is not authorized to perform the sagemaker:CreateTrainingJob on the resource. The user has shared the python code used for the training job and is seeking help to resolve the issue.",
        "Question_gpt_summary":"user encount error try run train job error messag indic user author perform createtrainingjob resourc user share python code train job seek help resolv issu"
    },
    {
        "Question_title":"Why Does SageMaker Data Parallel Distributed Training Only Support 3 Instances types?",
        "Question_body":"<p>I see\u00a0<a href=\"https:\/\/sagemaker-examples.readthedocs.io\/en\/latest\/training\/distributed_training\/pytorch\/data_parallel\/mnist\/pytorch_smdataparallel_mnist_demo.html\" rel=\"nofollow noreferrer\">here<\/a>\u00a0that SageMaker Data Distributed Library only supports 3 instance types: ml.p3.16xlarge, ml.p3dn.24xlarge, ml.p4d.24xlarge.<\/p>\n<p>Why is this? I would have thought there might be use cases for parallel training for other GPUs, and even potentially CPUs<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662712414643,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":13.0,
        "Poster_created_time":1662621266503,
        "Poster_location":null,
        "Poster_reputation_count":48.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73659423",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"data parallel distribut train support instanc type seeherethat data distribut librari support instanc type xlarg pdn xlarg xlarg thought us case parallel train gpu potenti cpu",
        "Question_preprocessed_content":"data distribut train instanc type data distribut librari instanc type thought us case train gpu cpu",
        "Question_gpt_summary_original":"The user is questioning why SageMaker Data Parallel Distributed Training only supports three instance types and is curious if there are use cases for parallel training on other GPUs or CPUs.",
        "Question_gpt_summary":"user question data parallel distribut train support instanc type curiou us case parallel train gpu cpu"
    },
    {
        "Question_title":"Linking multiple cloud accounts",
        "Question_body":"<p>I would like to put some of my data in different folders in aws, is there any way to link multiple projects\/ urls and then decide which one I wan to deposit it too ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1530804515195,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":484.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/linking-multiple-cloud-accounts\/51",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"link multipl cloud account like data differ folder aw wai link multipl project url decid wan deposit",
        "Question_preprocessed_content":"link multipl cloud like data folder aw wai link multipl project url decid wan deposit",
        "Question_gpt_summary_original":"The user is looking for a way to link multiple cloud accounts in order to store data in different folders in AWS and choose which project or URL to deposit it to.",
        "Question_gpt_summary":"user look wai link multipl cloud account order store data differ folder aw choos project url deposit"
    },
    {
        "Question_title":"Package \u2018AzureML\u2019 is not available In R",
        "Question_body":"<p>Dear Sir\/ Madam,    <br \/>\nI was trying to Integrate Azure ML Model(classic) with Power BI using R script and I was running following code.    <br \/>\n[    <br \/>\nwsid = &quot;&quot;    <br \/>\nauth = &quot;&quot;    <br \/>\nserviceName = &quot;Name of Exp&quot;    <\/p>\n<h1 id=\"was-trying-to-install-azureml-but-it-shows-the-error-attached-in-the-picture----\">was trying to install AzureML but it shows the error attached in the picture.    <\/h1>\n<p>library(&quot;AzureML&quot;)    <\/p>\n<p>ws &lt;- workspace(wsid, auth)    <br \/>\nds &lt;- consume(services(ws, name = serviceName),dataset)    <br \/>\nds &lt;- data.frame(ds,dataset)    <br \/>\n]    <\/p>\n<p>I tried different version of R but it is giving me the same error, Please Help.    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/63939-screenshot-38.png?platform=QnA\" alt=\"63939-screenshot-38.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1612444037050,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/258928\/package-azureml-is-not-available-in-r",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"packag avail dear sir madam try integr model classic power script run follow code wsid auth servicenam exp try instal show error attach pictur librari workspac wsid auth consum servic servicenam dataset data frame dataset tri differ version give error help",
        "Question_preprocessed_content":"packag avail dear sir madam try integr model power script code wsid auth servicenam exp try show pictur librari workspac consum dataset tri version give help",
        "Question_gpt_summary_original":"The user is encountering an error while trying to install the 'AzureML' package in R. They are attempting to integrate an Azure ML Model with Power BI using R script, but the package is not available and they have tried different versions of R without success.",
        "Question_gpt_summary":"user encount error try instal packag attempt integr model power script packag avail tri differ version success"
    },
    {
        "Question_title":"Hide Command from Overview Run Page Bug - Reopen",
        "Question_body":"<aside class=\"quote\" data-post=\"1\" data-topic=\"2231\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"><\/div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/ed8c4c\/40.png\" class=\"avatar\">\n    <a href=\"https:\/\/community.wandb.ai\/t\/hide-command-from-overview-run-page\/2231\">Hide Command from Overview Run Page<\/a> <a class=\"badge-wrapper  bullet\" href=\"\/c\/w-b-support\/36\"><span class=\"badge-category-bg\" style=\"background-color: #0088CC;\"><\/span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP.\">W&amp;B Support<\/span><\/a>\n  <\/div>\n  <blockquote>\n    On the Run Page (<a href=\"https:\/\/docs.wandb.ai\/ref\/app\/pages\/run-page\">https:\/\/docs.wandb.ai\/ref\/app\/pages\/run-page<\/a>) it shows on the left incognito that it shouldn\u2019t show your command when the public is viewing your page. \nHowever, on my page, when public and I view as not-me, it still shows the command that launched it, and that includes my Windows username, which I\u2019d rather not. I can\u2019t find anything to override or hide this. What am I missing? \nThanks.\n  <\/blockquote>\n<\/aside>\n\n<p>Reopening the above, this still isn\u2019t fixed and it\u2019s still bothering me.<\/p>\n<p>Any updates?<\/p>\n<p><a class=\"mention\" href=\"\/u\/armanharutyunyan\">@armanharutyunyan<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1658864314475,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":218.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/hide-command-from-overview-run-page-bug-reopen\/2802",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"hide command overview run page bug reopen hide command overview run page support run page http doc ref app page run page show left incognito shouldnt command public view page page public view show command launch includ window usernam overrid hide miss thank reopen isnt fix bother updat armanharutyunyan",
        "Question_preprocessed_content":"hide overview run page bug reopen hide overview run page run page show left incognito shouldnt public view page page public view show launch includ window usernam hide thank reopen isnt fix bother updat",
        "Question_gpt_summary_original":"The user is facing an issue with the \"Hide Command from Overview Run Page\" feature on the WandB platform. Despite the feature being designed to hide the command when viewed by the public, the user's Windows username is still visible. The user is seeking a solution to override or hide this information. The issue remains unresolved, and the user is requesting an update.",
        "Question_gpt_summary":"user face issu hide command overview run page featur platform despit featur design hide command view public user window usernam visibl user seek solut overrid hide inform issu remain unresolv user request updat"
    },
    {
        "Question_title":"Failure in Sidecar: Failed to read file line by line.",
        "Question_body":"<p>I was running 100 identical jobs on a compute cluster via Azure Machine Learning of which 97 failed and 3 succeeded without issues. The failed jobs failed half-way through with the following error message<\/p>\n<pre><code>AzureMLCompute job failed.\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\n    Reason: Job failed with non-zero exit Code\n    Reason: runSpecialJobTask failed with with non zero exit code\n    stderr: runSpecialJobTask: postprocessing: Failure in Sidecar:\nFailed to read file line by line.\n    Reason: Job release task failed with non-zero exit Code\n<\/code><\/pre>\n<p>There is no error message in the driver log or any other log file to indicate what went wrong. It seems like the failed jobs stopped half-way for no reason. The wording of the error message &quot;Failed to read file line by line.&quot; does not seem to be a standard python error message. Is there a way I can find out what happened in the sidecar and trace this error?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1619675273623,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/376584\/failure-in-sidecar-failed-to-read-file-line-by-lin",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"failur sidecar fail read file line line run ident job comput cluster fail succeed issu fail job fail half wai follow error messag comput job fail jobfail submit script fail non zero exit code driver log file detail reason job fail non zero exit code reason runspecialjobtask fail non zero exit code stderr runspecialjobtask postprocess failur sidecar fail read file line line reason job releas task fail non zero exit code error messag driver log log file indic went wrong like fail job stop half wai reason word error messag fail read file line line standard python error messag wai happen sidecar trace error",
        "Question_preprocessed_content":"failur sidecar fail read file line line ident job comput cluster fail fail job fail driver log log file indic went wrong like fail job reason word fail read file line standard python wai sidecar trace",
        "Question_gpt_summary_original":"The user encountered a failure in Sidecar while running 100 identical jobs on a compute cluster via Azure Machine Learning, where 97 jobs failed and 3 succeeded without issues. The failed jobs stopped half-way through with an error message \"Failed to read file line by line\" and there is no indication of what went wrong in the driver log or any other log file. The user is seeking a way to trace this error in the sidecar.",
        "Question_gpt_summary":"user encount failur sidecar run ident job comput cluster job fail succeed issu fail job stop half wai error messag fail read file line line indic went wrong driver log log file user seek wai trace error sidecar"
    },
    {
        "Question_title":"Alpha channel of standard deviation",
        "Question_body":"<p>Hello,<br>\ncan I change the alpha channel for an area of standard deviation around the line chart? Now it\u2019s not contrasting for me. I cannot recognise well the background and generated an area of stddev. Thanks a lot.<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/3\/32a3a3152fa5af0639ab0307252f741fd6e98d66.jpeg\" alt=\"image\" data-base62-sha1=\"7dYsME5bMAybvxWbkjJ2F0gbUHQ\" width=\"482\" height=\"253\"><\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1673445848149,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":145.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/alpha-channel-of-standard-deviation\/3681",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"alpha channel standard deviat hello chang alpha channel area standard deviat line chart contrast recognis background gener area stddev thank lot",
        "Question_preprocessed_content":"alpha standard deviat chang alpha area standard deviat line chart contrast recognis background gener area thank lot",
        "Question_gpt_summary_original":"The user is having difficulty recognizing the background and generated an area of standard deviation around a line chart due to the lack of contrast in the alpha channel. They are seeking a solution to change the alpha channel to improve visibility.",
        "Question_gpt_summary":"user have difficulti recogn background gener area standard deviat line chart lack contrast alpha channel seek solut chang alpha channel improv visibl"
    },
    {
        "Question_title":"Error notification not working in background job Neptune Software",
        "Question_body":"<p>For a particular server script, we are adding a background job.\nIn that ,it has an option to add error notification emails ,which is not working.  There is error in my script, which I can see in job log but not getting any notifications on email.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1639300561957,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1649766671956,
        "Question_score_count":0.0,
        "Question_view_count":36.0,
        "Poster_created_time":1583493572323,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70322291",
        "Tool":"Neptune",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error notif work background job softwar particular server script ad background job option add error notif email work error script job log get notif email",
        "Question_preprocessed_content":"notif work background job softwar particular server script background job option notif email work script job log notif email",
        "Question_gpt_summary_original":"The user is facing an issue with error notification emails not working in a background job for a server script. Although there is an error in the script, the user is not receiving any notifications on email.",
        "Question_gpt_summary":"user face issu error notif email work background job server script error script user receiv notif email"
    },
    {
        "Question_title":"PowerBI and MLflow integration (through AzureML)",
        "Question_body":"<p>I'm currently trying to integrate an ML model currently deployed as a webservice on AzureML with PowerBI.<\/p>\n<p>I see that it can be <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#invoking-the-azure-ml-model-in-power-bi\" rel=\"nofollow noreferrer\">integrated<\/a> but the model requires the addition of a schema file when it is <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#schema-discovery-for-machine-learning-models\" rel=\"nofollow noreferrer\">being deployed as a webservice<\/a>. Without this, the model can't be viewed in PowerBI.<\/p>\n<p>The problem that I have come up against is that I use MLflow to log ML model performances and subsequently to deploy a selected model onto AzureML as a webservice using MLflow's AzureML integration - mlflow.azureml.deploy(). This unfortunately doesn't have the option to define a schema file before the model is deployed, thus resulting in no model being available in PowerBI as it lacks the required schema file.<\/p>\n<p>My options seem to be:<\/p>\n<ol>\n<li>Find a workaround, possibly using the working <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-serving\" rel=\"nofollow noreferrer\">REST api of the model in a power query<\/a>.<\/li>\n<li>Rewrite the deployment code and handle the webservice deployment steps in Azure instead of MLflow.<\/li>\n<\/ol>\n<p>I thought I would ask to see if I am maybe missing something as I can't find a workaround using my current code to define a schema file in MLflow when deploying with mlflow.azureml.deploy().<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1600261190477,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1600855880503,
        "Question_score_count":0.0,
        "Question_view_count":405.0,
        "Poster_created_time":1600260166047,
        "Poster_location":null,
        "Poster_reputation_count":15.0,
        "Poster_view_count":4.0,
        "Answer_body":"<p>Point number 2 is the way we solved this issue. Instead of using MLflow to deploy to a scoring service on Azure, we wrote a custom code which load MLflow model when container is initialised.<\/p>\n<p>Scoring code is something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nfrom mlflow.pyfunc import load_model\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef init():\n    global model\n    model = load_model(os.path.join(os.environ.get(&quot;AZUREML_MODEL_DIR&quot;), &quot;awesome_model&quot;))\n\n@input_schema('data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\n\ndef run(data):\n    return model.predict(data)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1600604920243,
        "Answer_last_edit_time":1600855957376,
        "Answer_score_count":0.0,
        "Answerer_created_time":1285219808283,
        "Answerer_location":"Perth WA, Australia",
        "Answerer_reputation_count":6770.0,
        "Answerer_view_count":1127.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63920599",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"powerbi integr current try integr model current deploi webservic powerbi integr model requir addit schema file deploi webservic model view powerbi problem come us log model perform subsequ deploi select model webservic integr deploi unfortun option defin schema file model deploi result model avail powerbi lack requir schema file option workaround possibl work rest api model power queri rewrit deploy code handl webservic deploy step azur instead thought ask mayb miss workaround current code defin schema file deploi deploi",
        "Question_preprocessed_content":"powerbi integr try integr model deploi webservic powerbi integr model requir schema file deploi webservic model view powerbi problem come us log model perform subsequ deploi select model webservic integr unfortun option defin schema file model deploi result model avail powerbi lack requir schema file option workaround work rest api model power queri rewrit deploy code handl webservic deploy step azur instead thought ask mayb workaround code defin schema file deploi",
        "Question_gpt_summary_original":"The user is trying to integrate an ML model deployed as a webservice on AzureML with PowerBI, but the model requires a schema file to be viewed in PowerBI. The user uses MLflow to deploy the model onto AzureML, but MLflow's AzureML integration does not have the option to define a schema file before deployment, resulting in no model being available in PowerBI. The user is considering finding a workaround using the REST API or rewriting the deployment code to handle the webservice deployment steps in Azure instead of MLflow.",
        "Question_gpt_summary":"user try integr model deploi webservic powerbi model requir schema file view powerbi user us deploi model integr option defin schema file deploy result model avail powerbi user consid find workaround rest api rewrit deploy code handl webservic deploy step azur instead"
    },
    {
        "Question_title":"Dynamically generated parameters in pipeline",
        "Question_body":"<p>Conceptually I have a two stage pipeline. Where the first stage generates a set of flags (\u201chyper-hyper parameters\u201d). Then in the second stage I want to combine those with a set of hyper parameters to optimize. The challenge is that since they\u2019re created dynamically\u2026 I can\u2019t know ahead of time how many there are.<\/p>\n<p>I can do it manually like this<\/p>\n<p><code>guild run train x='[1,2,3] y='[1,2,3]'' @bigbatch.csv<\/code><\/p>\n<p>What I would like to do is for the train step to use a generated bigbatch.csv from the upstream pipeline<\/p>\n<p>I\u2019ve attached what I think it should look like at the guild.yml level<\/p>\n<pre><code>train:\n  description: Sample training script\n  flags-import: all\n  requires:\n    - operation: bigbatch\nbigbatch:\n  description: make file bigbatch.csv\n<\/code><\/pre>\n<p>This gives me  a symlink to the correct file called bigbatch.csv in the \u201ctrain folder\u201d after the <code>guild train<\/code> operation. However when I use the \u201c@\u201d batch notation the bigbatch.csv is taken from my cwd. Is there any way to reference batch parameters in the guild.yml?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1620135807746,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":311.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/dynamically-generated-parameters-in-pipeline\/699",
        "Tool":"Guild AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"dynam gener paramet pipelin conceptu stage pipelin stage gener set flag hyper hyper paramet second stage want combin set hyper paramet optim challeng theyr creat dynam know ahead time manual like run train bigbatch csv like train step us gener bigbatch csv upstream pipelin iv attach think look like yml level train descript sampl train script flag import requir oper bigbatch bigbatch descript file bigbatch csv give symlink correct file call bigbatch csv train folder train oper us batch notat bigbatch csv taken cwd wai refer batch paramet yml",
        "Question_preprocessed_content":"gener paramet pipelin stage pipelin stage gener set flag second stage want combin set hyper paramet optim theyr creat know ahead time like like train step us gener upstream pipelin iv think like yml level give symlink file train folder oper us batch notat taken cwd wai refer batch paramet yml",
        "Question_gpt_summary_original":"The user is facing a challenge in dynamically generating parameters in a two-stage pipeline. The first stage generates a set of flags, and in the second stage, the user wants to combine those with a set of hyper parameters to optimize. However, since the parameters are created dynamically, the user cannot know ahead of time how many there are. The user wants to use a generated bigbatch.csv from the upstream pipeline, but when using the \"@batch\" notation, the bigbatch.csv is taken from the current working directory instead of the correct file. The user is looking for a way to reference batch parameters in the guild.yml.",
        "Question_gpt_summary":"user face challeng dynam gener paramet stage pipelin stage gener set flag second stage user want combin set hyper paramet optim paramet creat dynam user know ahead time user want us gener bigbatch csv upstream pipelin batch notat bigbatch csv taken current work directori instead correct file user look wai refer batch paramet yml"
    },
    {
        "Question_title":"How to assign two or more time series identifier columns in Vertex AI Tabular Forecasting",
        "Question_body":"<p>I was wondering if it is possible to have more than one time series identifier column in the model? Let's assume I'd like to create a forecast at a product and store level (which the documentation suggests should be possible).<\/p>\n<p>If I select product as the series identifier, the only options I have left for store is either a covariate or an attribute and neither is applicable in this scenario.<\/p>\n<p>Would concatenating product and store and using the individual product and store code values for that concatenated ID as attributes be a solution? It doesn't feel right, but I can't see any other option - am I missing something?<\/p>\n<p>Note: I understand that this feature of Vertex AI is currently in preview and that because of that the options may be limited.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1632228068913,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":269.0,
        "Poster_created_time":1519630645620,
        "Poster_location":"Northampton, UK",
        "Poster_reputation_count":333.0,
        "Poster_view_count":46.0,
        "Answer_body":"<p>There isn't an alternate way to assign 2 or more <strong>Time Series Identifiers<\/strong> in the <strong>Forecasting Model<\/strong> on <strong>Vertex AI<\/strong>. The &quot;<strong>Forecasting model<\/strong>&quot; is in the &quot;<strong>Preview<\/strong>&quot; <a href=\"https:\/\/cloud.google.com\/products#product-launch-stages\" rel=\"nofollow noreferrer\">Product launch stage<\/a>, as you are aware, with all consequences of that fact the options are limited. Please refer to this <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/datasets\/bp-tabular#data_preparation_best_practices\" rel=\"nofollow noreferrer\">doc<\/a> for more information about the best practices for data preparation to train the forecasting model.<\/p>\n<p>As a workaround, the two columns can be concatenated and assigned a Time Series Identifier on that concatenated column, as you have mentioned in the question. This way, the concatenated column carries more contextual information into the training of the model.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1632376096768,
        "Answer_last_edit_time":1632482492492,
        "Answer_score_count":2.0,
        "Answerer_created_time":1619174589310,
        "Answerer_location":"Bangalore, Karnataka, India",
        "Answerer_reputation_count":1200.0,
        "Answerer_view_count":804.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69269073",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"assign time seri identifi column tabular forecast wonder possibl time seri identifi column model let assum like creat forecast product store level document suggest possibl select product seri identifi option left store covari attribut applic scenario concaten product store individu product store code valu concaten attribut solut feel right option miss note understand featur current preview option limit",
        "Question_preprocessed_content":"time seri identifi column tabular forecast wonder time seri identifi column model let like creat forecast product store level select product seri identifi option left store covari scenario concaten product store individu product store code valu concaten solut right option note understand featur preview option limit",
        "Question_gpt_summary_original":"The user is facing a challenge in assigning two or more time series identifier columns in Vertex AI Tabular Forecasting. They want to create a forecast at a product and store level, but the only options available for store are either a covariate or an attribute, which are not applicable in this scenario. The user is considering concatenating product and store and using the individual product and store code values for that concatenated ID as attributes, but they are unsure if this is the right solution. The user acknowledges that this feature is currently in preview and the options may be limited.",
        "Question_gpt_summary":"user face challeng assign time seri identifi column tabular forecast want creat forecast product store level option avail store covari attribut applic scenario user consid concaten product store individu product store code valu concaten attribut unsur right solut user acknowledg featur current preview option limit"
    },
    {
        "Question_title":"Azure ML Pipeline pyarrow dependency for installing transformers",
        "Question_body":"<p>I was trying to import transformers in AzureML designer pipeline, it says for importing transformers and datasets the version of pyarrow needs to &gt;=3.0.0, but then after upgrading pyarrow's version to 3.0.0 and importing transformers pyarrow version is reset to original version of 0.16.0. attaching few error samples. please have a look.  <\/p>\n<blockquote>\n<p>Got exception when invoking script: 'RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):To use datasets, the module pyarrow&gt;=3.0.0 is required, and the current version of pyarrow doesn't match this condition.If you are running this in a Google Colab, you should probably just restart the runtime to use the right version of pyarrow.' azureml-designer-core 0.0.68 requires pyarrow==0.16.0, but you'll have pyarrow 3.0.0 which is incompatible.  <\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1646062523127,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/753625\/azure-ml-pipeline-pyarrow-dependency-for-installin",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pipelin pyarrow depend instal transform try import transform design pipelin sai import transform dataset version pyarrow need upgrad pyarrow version import transform pyarrow version reset origin version attach error sampl look got except invok script runtimeerror fail import transform trainer follow error look traceback us dataset modul pyarrow requir current version pyarrow match condit run googl colab probabl restart runtim us right version pyarrow design core requir pyarrow pyarrow incompat",
        "Question_preprocessed_content":"pipelin depend transform try import transform design pipelin sai import transform dataset version upgrad version import transform version reset origin version sampl got except invok script fail import us dataset modul requir version match colab probabl restart runtim us right version requir incompat",
        "Question_gpt_summary_original":"The user is facing an issue while importing transformers in AzureML designer pipeline. The error message indicates that the version of pyarrow needs to be >=3.0.0 for importing transformers and datasets. However, after upgrading pyarrow's version to 3.0.0, the pyarrow version is reset to the original version of 0.16.0. The error message suggests that azureml-designer-core 0.0.68 requires pyarrow==0.16.0, which is incompatible with pyarrow 3.0.0.",
        "Question_gpt_summary":"user face issu import transform design pipelin error messag indic version pyarrow need import transform dataset upgrad pyarrow version pyarrow version reset origin version error messag suggest design core requir pyarrow incompat pyarrow"
    },
    {
        "Question_title":"Convert a datatable string from Azure ML WS to an actual Datatable C# Object?",
        "Question_body":"<p>Basically I'm receiving an output like this from my azure ws output:<\/p>\n\n<pre><code>{\n    'Results': {\n        'WSOutput': {\n            'type': 'table',\n            'value': {\n                'ColumnNames': ['ID', 'Start', 'Ask', 'Not', 'Passed', 'Suggest'],\n                'ColumnTypes': ['Int32', 'Int32', 'Int32', 'Double', 'Int64', 'Int32'],\n                'Values': [['13256025', '25000', '19000', '0.35', '1', '25000']]\n            }\n        }\n    }\n}\n<\/code><\/pre>\n\n<p>The string, as you can see, has the info to create a datatable object. Now, I can't seem to find an easy way to cast it to an actual datatable POCO. I'm able to manually code a parser with Newtonsoft.Json.Linq but there has to be an easier way. <\/p>\n\n<p>Does anybody know how? I can't seem to find anything on the net.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":7.0,
        "Question_created_time":1519929782813,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1519930038023,
        "Question_score_count":2.0,
        "Question_view_count":83.0,
        "Poster_created_time":1324654920387,
        "Poster_location":"Waterloo, ON, Canada",
        "Poster_reputation_count":5211.0,
        "Poster_view_count":449.0,
        "Answer_body":"<p>Yes, there is a open source online gernator on the net (<a href=\"http:\/\/jsonutils.com\/\" rel=\"nofollow noreferrer\">http:\/\/jsonutils.com\/<\/a>). Copy paste your result will give you that:<\/p>\n\n<pre><code> public class Value\n    {\n        public IList&lt;string&gt; ColumnNames { get; set; }\n        public IList&lt;string&gt; ColumnTypes { get; set; }\n        public IList&lt;IList&lt;string&gt;&gt; Values { get; set; }\n    }\n\n    public class WSOutput\n    {\n        public string type { get; set; }\n        public Value value { get; set; }\n    }\n\n    public class Results\n    {\n        public WSOutput WSOutput { get; set; }\n    }\n\n    public class Example\n    {\n        public Results Results { get; set; }\n    }\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1519929928907,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1327234712912,
        "Answerer_location":"Germany",
        "Answerer_reputation_count":53015.0,
        "Answerer_view_count":3262.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49056593",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"convert datat string actual datat object basic receiv output like azur output result wsoutput type tabl valu columnnam start ask pass suggest columntyp int int int doubl int int valu string info creat datat object easi wai cast actual datat poco abl manual code parser newtonsoft json linq easier wai anybodi know net",
        "Question_preprocessed_content":"convert datat string actual datat object receiv output like azur output string info creat datat object easi wai cast actual datat poco abl code parser easier wai anybodi know net",
        "Question_gpt_summary_original":"The user is having trouble converting a datatable string received from Azure ML WS into an actual Datatable C# object. The string contains the necessary information to create a datatable object, but the user is unable to find an easy way to cast it. The user has tried manually coding a parser with Newtonsoft.Json.Linq but is looking for an easier solution.",
        "Question_gpt_summary":"user have troubl convert datat string receiv actual datat object string contain necessari inform creat datat object user unabl easi wai cast user tri manual code parser newtonsoft json linq look easier solut"
    },
    {
        "Question_title":"Undo 'dvc add' operation",
        "Question_body":"<p>I <code>dvc add<\/code>-ed a file I did not mean to add. I have not yet committed.<\/p>\n\n<p>How do I undo this operation? In Git, you would do <code>git rm --cached &lt;filename&gt;<\/code>.<\/p>\n\n<p>To be clear: I want to make DVC forget about the file, and I want the file to remain untouched in my working tree. This is the opposite of what <code>dvc remove<\/code> does.<\/p>\n\n<p>One <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/1524\" rel=\"nofollow noreferrer\">issue<\/a> on the DVC issue tracker suggests that <code>dvc unprotect<\/code> is the right command. But reading the <a href=\"https:\/\/dvc.org\/doc\/commands-reference\/unprotect\" rel=\"nofollow noreferrer\">manual page<\/a> suggests otherwise.<\/p>\n\n<p>Is this possible with DVC?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1568689927047,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":1304.0,
        "Poster_created_time":1383611307000,
        "Poster_location":"New York",
        "Poster_reputation_count":10846.0,
        "Poster_view_count":984.0,
        "Answer_body":"<p>As per mroutis on the DVC Discord server:<\/p>\n\n<ol>\n<li><code>dvc unprotect<\/code> the file; this won't be necessary if you don't use <code>symlink<\/code> or <code>hardlink<\/code> caching, but it can't hurt.<\/li>\n<li>Remove the .dvc file<\/li>\n<li>If you need to delete the cache entry itself, run <code>dvc gc<\/code>, or look up the MD5 in <code>data.dvc<\/code> and manually remove it from <code>.dvc\/cache<\/code>.<\/li>\n<\/ol>\n\n<p><em>Edit<\/em> -- there is now an issue on their Github page to add this to the manual: <a href=\"https:\/\/github.com\/iterative\/dvc.org\/issues\/625\" rel=\"nofollow noreferrer\">https:\/\/github.com\/iterative\/dvc.org\/issues\/625<\/a><\/p>",
        "Answer_comment_count":6.0,
        "Question_closed_time":1568693889196,
        "Answer_last_edit_time":1568725966083,
        "Answer_score_count":7.0,
        "Answerer_created_time":1383611307000,
        "Answerer_location":"New York",
        "Answerer_reputation_count":10846.0,
        "Answerer_view_count":984.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57966851",
        "Tool":"DVC",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"undo add oper add file mean add commit undo oper git git cach clear want forget file want file remain untouch work tree opposit remov issu issu tracker suggest unprotect right command read manual page suggest possibl",
        "Question_preprocessed_content":"undo oper file mean undo oper git clear want forget file want file remain untouch work tracker right read manual page",
        "Question_gpt_summary_original":"The user accidentally added a file using the 'dvc add' command and wants to undo the operation without affecting the file in the working tree. They are seeking guidance on how to make DVC forget about the file, and are unsure if 'dvc unprotect' is the right command to use.",
        "Question_gpt_summary":"user accident ad file add command want undo oper affect file work tree seek guidanc forget file unsur unprotect right command us"
    },
    {
        "Question_title":"How do you load an existing S3 bucket in Sagemaker using R Programming?",
        "Question_body":"<p>I know how to use python to load an existing s3 bucket in sage maker using R. Something like this:<\/p>\n\n<pre><code>role = get_execution_role()\nregion = boto3.Session().region_name\nbucket='existing S3 Bucket' \ndata_key = 'Data file in the existing s3 bucket'\ndata_location = 's3:\/\/{}\/{}'.format(bucket, data_key)\n<\/code><\/pre>\n\n<p>How can one recreate this using R in Sage maker? All i see in the available documentation is how to create a new bucket but none of it mentions how to use an existing S3 bucket. Help would be appreciated.<\/p>\n\n<p>link to documentation for R in sage maker:\n<a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-r-with-amazon-sage\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-r-with-amazon-sage<\/a> maker\/<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1575069896083,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":1591.0,
        "Poster_created_time":1575069492660,
        "Poster_location":null,
        "Poster_reputation_count":31.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59111930",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"load exist bucket program know us python load exist bucket sage maker like role execut role region boto session region bucket exist bucket data kei data file exist bucket data locat format bucket data kei recreat sage maker avail document creat new bucket mention us exist bucket help appreci link document sage maker http aw amazon com blog machin learn amazon sage maker",
        "Question_preprocessed_content":"load exist bucket know us python load exist bucket sage maker like recreat sage maker avail document creat new bucket mention us exist bucket help link document sage maker maker",
        "Question_gpt_summary_original":"The user is seeking help to load an existing S3 bucket in SageMaker using R programming. They have provided a Python code snippet for reference but are unable to find any documentation on how to do the same in R. The user is requesting assistance in recreating the Python code in R.",
        "Question_gpt_summary":"user seek help load exist bucket program provid python code snippet refer unabl document user request assist recreat python code"
    },
    {
        "Question_title":"Optuna catboost pruning",
        "Question_body":"<p>is there a way to have pruning with CatBoost and Optuna (in LightGBM it's easy but in Catboost I can't find any hint).\nMy code is like this<\/p>\n<pre><code>def objective(trial):\n    param = {\n        'iterations':trial.suggest_int('iterations', 100,1500, step=100),\n        'learning_rate':trial.suggest_uniform(&quot;learning_rate&quot;, 0.001, 0.3),\n        'random_strength':trial.suggest_int(&quot;random_strength&quot;, 1,10),\n        'max_bin':trial.suggest_categorical('max_bin', [2,3,4,5,6,8,10,20,30]),\n        'grow_policy':trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),        \n        &quot;colsample_bylevel&quot;: trial.suggest_uniform(&quot;colsample_bylevel&quot;, 0.1, 1),\n        'od_type' : &quot;Iter&quot;,\n        'od_wait' : 30,\n        &quot;depth&quot;: trial.suggest_int(&quot;max_depth&quot;, 1,12),\n        &quot;l2_leaf_reg&quot;: trial.suggest_loguniform(&quot;l2_leaf_reg&quot;, 1e-8, 100),\n        'custom_metric' : ['AUC'],\n        &quot;loss_function&quot;: &quot;Logloss&quot;,\n        }\n    \n    if param['grow_policy'] == &quot;SymmetricTree&quot;: \n        param[&quot;boosting_type&quot;]= trial.suggest_categorical(&quot;boosting_type&quot;, [&quot;Ordered&quot;, &quot;Plain&quot;])\n    else:\n        param[&quot;boosting_type&quot;] = &quot;Plain&quot;\n        \n    # Added subsample manually\n    param[&quot;subsample&quot;] = trial.suggest_float(&quot;subsample&quot;, 0.1, 1)\n\n### CV ###\n\n    # How to add a callback for pruning?\n    scores = cv(train_dataset,\n            param,\n            fold_count=5, \n            early_stopping_rounds=30,         \n            plot=False, verbose=False)\n    \n    return scores['test-AUC-mean'].mean()\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1615153279437,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1238.0,
        "Poster_created_time":1487099213112,
        "Poster_location":null,
        "Poster_reputation_count":138.0,
        "Poster_view_count":21.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66521731",
        "Tool":"Optuna",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"catboost prune wai prune catboost lightgbm easi catboost hint code like def object trial param iter trial suggest int iter step learn rate trial suggest uniform learn rate random strength trial suggest int random strength max bin trial suggest categor max bin grow polici trial suggest categor grow polici symmetrictre depthwis lossguid colsampl bylevel trial suggest uniform colsampl bylevel type iter wait depth trial suggest int max depth leaf reg trial suggest loguniform leaf reg custom metric auc loss function logloss param grow polici symmetrictre param boost type trial suggest categor boost type order plain param boost type plain ad subsampl manual param subsampl trial suggest float subsampl add callback prune score train dataset param fold count earli stop round plot fals verbos fals return score test auc mean mean",
        "Question_preprocessed_content":"prune wai prune code like",
        "Question_gpt_summary_original":"The user is trying to implement pruning with CatBoost and Optuna, but is unable to find any hints on how to do so. They have provided their code and are specifically looking for guidance on how to add a callback for pruning.",
        "Question_gpt_summary":"user try implement prune catboost unabl hint provid code specif look guidanc add callback prune"
    },
    {
        "Question_title":"How to use Azure DevOps artifacts repository as source for DatabricksStep of AzureML?",
        "Question_body":"<p>If we have PyPi Packages added as Artifacts to an Azure DevOps Project Feed, how can we use these packages as a source for installing packages in <code>DatabricksStep<\/code> of Azure Machine Learning Service?<\/p>\n<p>While using <code>pip<\/code> in any environment, we use our Azure DevOps Project Artifacts feed in the following way:<\/p>\n<pre><code>pip install example-package --index-url=https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/\n<\/code><\/pre>\n<p>The DatabricksStep class of the Azure Machine Learning Service accepts the following parameters:<\/p>\n<pre><code>python_script_name = &quot;&lt;Some-Script&gt;.py&quot;\nsource_directory = &quot;&lt;Path-To-Script&gt;&quot;\n\n&lt;Some-Placeholder-Name-for-the-step&gt; = DatabricksStep(\n    name=&lt;Some-Placeholder-Name-for-the-step&gt;,\n    num_workers=1,\n    python_script_name=python_script_name,\n    source_directory=source_directory,\n    run_name= &lt;Name-of-the-run&gt;,\n    compute_target=databricks_compute,\n    pypi_libraries = [\n                      PyPiLibrary(package = 'scikit-learn'), \n                      PyPiLibrary(package = 'scipy'), \n                      PyPiLibrary(package = 'azureml-sdk'), \n                      PyPiLibrary(package = 'joblib'), \n                      PyPiLibrary(package = 'azureml-dataprep[pandas]'),\n                      PyPiLibrary(package = 'example-package', repo='https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/')\n                    ], \n\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>However, <code>PyPiLibrary(package = 'example-package', repo='https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/')<\/code> will give an error. How exactly should we consume the Artifacts Feed as an input to the <code>PyPiLibrary<\/code> property of the <code>DatabricksStep<\/code> Class in Azure Machine Learning Service?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1611234834813,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":5.0,
        "Question_view_count":341.0,
        "Poster_created_time":1601729162436,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":887.0,
        "Poster_view_count":130.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65828200",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us azur devop artifact repositori sourc databricksstep pypi packag ad artifact azur devop project feed us packag sourc instal packag databricksstep servic pip environ us azur devop project artifact feed follow wai pip instal exampl packag index url http pkg dev azur com packag pypi simpl databricksstep class servic accept follow paramet python script sourc directori databricksstep num worker python script python script sourc directori sourc directori run comput target databrick comput pypi librari pypilibrari packag scikit learn pypilibrari packag scipi pypilibrari packag sdk pypilibrari packag joblib pypilibrari packag dataprep panda pypilibrari packag exampl packag repo http pkg dev azur com packag pypi simpl allow reus true pypilibrari packag exampl packag repo http pkg dev azur com packag pypi simpl error exactli consum artifact feed input pypilibrari properti databricksstep class servic",
        "Question_preprocessed_content":"us azur devop artifact repositori sourc pypi packag artifact azur devop project us packag sourc packag servic environ us azur devop project artifact wai servic paramet exactli consum artifact input properti servic",
        "Question_gpt_summary_original":"The user is trying to use PyPi packages added as Artifacts to an Azure DevOps Project Feed as a source for installing packages in DatabricksStep of Azure Machine Learning Service. They are encountering an error while trying to consume the Artifacts Feed as an input to the PyPiLibrary property of the DatabricksStep Class in Azure Machine Learning Service.",
        "Question_gpt_summary":"user try us pypi packag ad artifact azur devop project feed sourc instal packag databricksstep servic encount error try consum artifact feed input pypilibrari properti databricksstep class servic"
    },
    {
        "Question_title":"Is it possible to mount a remote DVC data registry in a local filesystem?",
        "Question_body":"<p>Hi! This is my first post here. I\u2019ve been looking through the docs and topics to find out a best solution.<br>\nI think I almost got everything clear in terms of setup. We are currently using a DVC data registry (i.e. a DVC+GIT in charge of tracking changes in a remote storage). We can import this data registry into other DVC projects that just read data from the remote storage.<\/p>\n<p>To reduce data storage (i.e. not creating another cache for each project importing the data registry that includes tracking changes in the data registry \u2014 these changes are already taken care of by the data registry itself) we wanted to use the data registry just as a filesystem where we specify the version (so that still the dependency of the code and the version of the registry is kept \u2014 though with a somewhat manual supervision instead of automatically).<\/p>\n<p>We find the DVCFileSystem API great for this as this exactly what we need. However it only provides support for python. Furthermore, some python libraries only work with local paths. Is it possible to mount such a DVC filesystem at the OS level. Something with the same functionality as the python API but working in the same way than <code>sshfs<\/code> for example (with the addition of the revision that we want to mount)?<\/p>\n<p>Thank you!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1674142569107,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":79.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/is-it-possible-to-mount-a-remote-dvc-data-registry-in-a-local-filesystem\/1466",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl mount remot data registri local filesystem post iv look doc topic best solut think got clear term setup current data registri git charg track chang remot storag import data registri project read data remot storag reduc data storag creat cach project import data registri includ track chang data registri chang taken care data registri want us data registri filesystem specifi version depend code version registri kept somewhat manual supervis instead automat filesystem api great exactli need provid support python furthermor python librari work local path possibl mount filesystem level function python api work wai sshf exampl addit revis want mount thank",
        "Question_preprocessed_content":"mount remot data registri local filesystem post iv doc topic best solut think got clear term setup data registri import data registri project read data remot storag reduc data storag want us data registri filesystem specifi version filesystem api great exactli provid python furthermor python librari work local path mount filesystem level function python api work wai exampl thank",
        "Question_gpt_summary_original":"The user is trying to reduce data storage by using a DVC data registry as a filesystem where they can specify the version. They find the DVCFileSystem API great for this, but it only provides support for python. They are looking for a way to mount the DVC filesystem at the OS level, similar to sshfs, with the addition of the revision they want to mount.",
        "Question_gpt_summary":"user try reduc data storag data registri filesystem specifi version filesystem api great provid support python look wai mount filesystem level similar sshf addit revis want mount"
    },
    {
        "Question_title":"Sweep in DDP mode",
        "Question_body":"<p>I wonder how Sweep works in multi-GPU mode? I want to initialize the parameters that need to be optimized in just one process, and then use Sweep for hyperparametric optimization. However, if I only initialize parameters in one process, other processes will report an error because they did not query parameters when loading the model. I didn\u2019t find the answer to using Sweep in multi-GPU mode, thanks for answering!<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1641148429166,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":576.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/sweep-in-ddp-mode\/1664",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sweep ddp mode wonder sweep work multi gpu mode want initi paramet need optim process us sweep hyperparametr optim initi paramet process process report error queri paramet load model didnt answer sweep multi gpu mode thank answer",
        "Question_preprocessed_content":"mode wonder work mode want initi paramet optim us hyperparametr optim initi paramet report queri paramet load model didnt answer mode thank answer",
        "Question_gpt_summary_original":"The user is seeking information on how to use Sweep in multi-GPU mode for hyperparameter optimization. They are facing an issue where initializing parameters in one process causes errors in other processes as they did not query the parameters when loading the model. The user is looking for a solution to this problem.",
        "Question_gpt_summary":"user seek inform us sweep multi gpu mode hyperparamet optim face issu initi paramet process caus error process queri paramet load model user look solut problem"
    },
    {
        "Question_title":"Duplicate runs after 500 runs when using local controller",
        "Question_body":"<p>I deploy a wandb server in my local server, and use grid search to sweep hyperparameters with 4 parallel agents.<\/p>\n<p>In my case, the size of the search space exceeds 500, and each run takes about 2 minutes to finish.<\/p>\n<p>I always find that after 500 runs finish, the generated hyperparameter configurations of the newly started runs from the beginning again. That is, the configuration of the 501st run (or possibly the 502nd run) is the same as that of the first run, the configuration of the 502nd run (or possibly the 503rd run) is the same as that of the second run, and so on.<\/p>\n<p>I also check the log of the local controller, and the number of runs keeps to be 500 as follows:<br>\n\u2026<br>\nSweep: t3muh8oq (grid) | Runs: 470 (Running: 2, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 471 (Running: 3, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 472 (Running: 4, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 472 (Running: 3, Finished: 469)<br>\nSweep: t3muh8oq (grid) | Runs: 473 (Running: 4, Finished: 469)<br>\nSweep: t3muh8oq (grid) | Runs: 473 (Running: 3, Finished: 470)<br>\nSweep: t3muh8oq (grid) | Runs: 474 (Running: 4, Finished: 470)<br>\nSweep: t3muh8oq (grid) | Runs: 474 (Running: 3, Finished: 471)<br>\nSweep: t3muh8oq (grid) | Runs: 475 (Running: 3, Finished: 472)<br>\nSweep: t3muh8oq (grid) | Runs: 476 (Running: 4, Finished: 472)<br>\nSweep: t3muh8oq (grid) | Runs: 476 (Running: 2, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 477 (Running: 3, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 4, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 3, Finished: 475)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 2, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 479 (Running: 3, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 480 (Running: 4, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 480 (Running: 3, Finished: 477)<br>\nSweep: t3muh8oq (grid) | Runs: 481 (Running: 3, Finished: 478)<br>\nSweep: t3muh8oq (grid) | Runs: 482 (Running: 4, Finished: 478)<br>\nSweep: t3muh8oq (grid) | Runs: 482 (Running: 3, Finished: 479)<br>\nSweep: t3muh8oq (grid) | Runs: 483 (Running: 4, Finished: 479)<br>\nSweep: t3muh8oq (grid) | Runs: 483 (Running: 3, Finished: 480)<br>\nSweep: t3muh8oq (grid) | Runs: 484 (Running: 4, Finished: 480)<br>\nSweep: t3muh8oq (grid) | Runs: 484 (Running: 2, Finished: 482)<br>\nSweep: t3muh8oq (grid) | Runs: 485 (Running: 3, Finished: 482)<br>\nSweep: t3muh8oq (grid) | Runs: 486 (Running: 3, Finished: 483)<br>\nSweep: t3muh8oq (grid) | Runs: 487 (Running: 3, Finished: 484)<br>\nSweep: t3muh8oq (grid) | Runs: 488 (Running: 4, Finished: 484)<br>\nSweep: t3muh8oq (grid) | Runs: 488 (Running: 3, Finished: 485)<br>\nSweep: t3muh8oq (grid) | Runs: 489 (Running: 3, Finished: 486)<br>\nSweep: t3muh8oq (grid) | Runs: 490 (Running: 4, Finished: 486)<br>\nSweep: t3muh8oq (grid) | Runs: 490 (Running: 3, Finished: 487)<br>\nSweep: t3muh8oq (grid) | Runs: 491 (Running: 3, Finished: 488)<br>\nSweep: t3muh8oq (grid) | Runs: 492 (Running: 4, Finished: 488)<br>\nSweep: t3muh8oq (grid) | Runs: 492 (Running: 3, Finished: 489)<br>\nSweep: t3muh8oq (grid) | Runs: 493 (Running: 3, Finished: 490)<br>\nSweep: t3muh8oq (grid) | Runs: 494 (Running: 2, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 495 (Running: 3, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 496 (Running: 4, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 496 (Running: 3, Finished: 493)<br>\nSweep: t3muh8oq (grid) | Runs: 497 (Running: 3, Finished: 494)<br>\nSweep: t3muh8oq (grid) | Runs: 498 (Running: 3, Finished: 495)<br>\nSweep: t3muh8oq (grid) | Runs: 499 (Running: 3, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1679562765969,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":108.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/duplicate-runs-after-500-runs-when-using-local-controller\/4105",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"duplic run run local control deploi server local server us grid search sweep hyperparamet parallel agent case size search space exce run take minut finish run finish gener hyperparamet configur newli start run begin configur run possibl run run configur run possibl run second run check log local control number run keep follow sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish sweep tmuhoq grid run run finish",
        "Question_preprocessed_content":"duplic run run local deploi server local server us grid search hyperparamet agent case size search space run take minut finish run finish gener hyperparamet configur newli start run configur run run configur run second run check log local number run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run muh run",
        "Question_gpt_summary_original":"The user is encountering a challenge where duplicate runs are being generated after 500 runs when using a local controller for grid search with 4 parallel agents. The size of the search space exceeds 500 and each run takes about 2 minutes to finish. The configurations of the newly started runs from the beginning again after the 500th run, resulting in duplicate runs.",
        "Question_gpt_summary":"user encount challeng duplic run gener run local control grid search parallel agent size search space exce run take minut finish configur newli start run begin run result duplic run"
    },
    {
        "Question_title":"Use an Azure ML compute cluster to run Kedro + Mlflow pipeline",
        "Question_body":"<p>I want to use an Azure Machine Learning compute cluster as a compute target to run a Kedro pipeline integrated with Mlflow.<\/p>\n<p>Here's the code snippet (hooks.py) that integrates experiment tracking using Mlflow and Azure ML as backend\/artifact stores.<\/p>\n<pre><code>&quot;&quot;&quot;Project hooks.&quot;&quot;&quot;\nfrom typing import Any, Dict, Iterable, Optional\nimport git\nimport os\nimport mlflow\nimport mlflow.sklearn\nfrom kedro.config import ConfigLoader\nfrom kedro.framework.hooks import hook_impl\nfrom kedro.io import DataCatalog\nfrom kedro.pipeline.node import Node\nfrom kedro.versioning import Journal\nfrom azureml.core import Workspace\nfrom azureml.core.experiment import Experiment\n\nclass ProjectHooks:\n    @hook_impl\n    def register_config_loader(\n        self,\n        conf_paths: Iterable[str],\n        env: str,\n        extra_params: Dict[str, Any],\n    ) -&gt; ConfigLoader:\n        return ConfigLoader(conf_paths)\n\n    @hook_impl\n    def register_catalog(\n        self,\n        catalog: Optional[Dict[str, Dict[str, Any]]],\n        credentials: Dict[str, Dict[str, Any]],\n        load_versions: Dict[str, str],\n        save_version: str,\n        journal: Journal,\n    ) -&gt; DataCatalog:\n        return DataCatalog.from_config(\n            catalog, credentials, load_versions, save_version, journal\n        )\n\n\nclass ModelTrackingHooks:\n    &quot;&quot;&quot;Namespace for grouping all model-tracking hooks with MLflow together.&quot;&quot;&quot;\n\n    @hook_impl\n    def before_pipeline_run(self, run_params: Dict[str, Any]) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to start an MLflow run\n        with the same run_id as the Kedro pipeline run.\n        &quot;&quot;&quot;\n\n        # Get Azure workspace\n        ws = Workspace.get(name=workspace_name,\n                           subscription_id=subscription_id,\n                           resource_group=resource_group)\n\n        # Set tracking uri\n        mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n\n        # Create an Azure ML experiment in the workspace\n        experiment = Experiment(workspace=ws, name='kedro-mlflow-experiment')\n        mlflow.set_experiment(experiment.name)\n\n        mlflow.start_run(run_name=run_params[&quot;run_id&quot;])\n        mlflow.log_params(run_params)\n\n    @hook_impl\n    def after_node_run(\n        self, node: Node, outputs: Dict[str, Any], inputs: Dict[str, Any]\n    ) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to add model tracking after some node runs.\n        In this example, we will:\n        * Log the parameters after the data splitting node runs.\n        * Log the model after the model training node runs.\n        * Log the model's metrics after the model evaluating node runs.\n        &quot;&quot;&quot;\n        if node._func_name == &quot;function_name&quot;:\n            mlflow.log_metrics(...)\n\n    @hook_impl\n    def after_pipeline_run(self) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to end the MLflow run\n        after the Kedro pipeline finishes.\n        &quot;&quot;&quot;\n        mlflow.end_run()\n<\/code><\/pre>\n<p>This works well on a <strong>compute instance<\/strong> that I created in my Azure ML workspace, simply by doing the following :<\/p>\n<ol>\n<li><code>git clone<\/code> the source code into the Azure ML compute instance<\/li>\n<li>Do a <code>kedro run<\/code> in the compute instance Terminal<\/li>\n<\/ol>\n<p>That's ok but what I really want is to use <strong>compute clusters<\/strong> to deal with hyperparameter tuning and other heavy workloads... I Just want to mention here that I still want to git clone to the compute instance and submit the run to the compute cluster from within the compute instance (but if anyone has a better approach, please feel free to share).<\/p>\n<p>I know of two ways (listed below) to specify a compute cluster as a compute target in Azure ML but both require to pass a <code>script<\/code> parameter.<\/p>\n<ol>\n<li>Pure Azure ML <code>ScriptRunConfig()<\/code> method to submit experiments by specifying <code>script<\/code> and <code>compute_target<\/code> parameters. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Submit remote run with Azure Ml<\/a><\/li>\n<li>Mlflow integration with Azure ML : that requires to add an MLproject file to the project folder. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-mlflow-projects\" rel=\"nofollow noreferrer\">Submit an mlflow project run<\/a>.<\/li>\n<\/ol>\n<p>I tried for quite some time now to figure out how to do that within the Kedro structure but without success. So my question here, what's the best way to push experiment runs in a Kedro Pipeline to Azure ML compute clusters?<\/p>\n<p>Thank you in advance for your help !<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1639418195970,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1639471244520,
        "Question_score_count":1.0,
        "Question_view_count":271.0,
        "Poster_created_time":1586517832390,
        "Poster_location":null,
        "Poster_reputation_count":127.0,
        "Poster_view_count":20.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70338955",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us comput cluster run pipelin want us comput cluster comput target run pipelin integr code snippet hook integr experi track backend artifact store project hook type import dict iter option import git import import import sklearn config import configload framework hook import hook impl import datacatalog pipelin node import node version import journal core import workspac core experi import experi class projecthook hook impl def regist config loader self conf path iter str env str extra param dict str configload return configload conf path hook impl def regist catalog self catalog option dict str dict str credenti dict str dict str load version dict str str save version str journal journal datacatalog return datacatalog config catalog credenti load version save version journal class modeltrackinghook namespac group model track hook hook impl def pipelin run self run param dict str hook implement start run run pipelin run azur workspac workspac workspac subscript subscript resourc group resourc group set track uri set track uri track uri creat experi workspac experi experi workspac experi set experi experi start run run run param run log param run param hook impl def node run self node node output dict str input dict str hook implement add model track node run exampl log paramet data split node run log model model train node run log model metric model evalu node run node func function log metric hook impl def pipelin run self hook implement end run pipelin finish end run work comput instanc creat workspac simpli follow git clone sourc code comput instanc run comput instanc termin want us comput cluster deal hyperparamet tune heavi workload want mention want git clone comput instanc submit run comput cluster comput instanc better approach feel free share know wai list specifi comput cluster comput target requir pass script paramet pure scriptrunconfig method submit experi specifi script comput target paramet submit remot run integr requir add mlproject file project folder submit project run tri time figur structur success question best wai push experi run pipelin comput cluster thank advanc help",
        "Question_preprocessed_content":"us comput cluster run pipelin want us comput cluster comput target run pipelin integr code integr experi track store work comput instanc creat workspac simpli sourc code comput instanc comput instanc termin want us comput cluster deal hyperparamet tune heavi want mention want git clone comput instanc submit run comput cluster comput instanc know wai specifi comput cluster comput target requir paramet pure method submit experi specifi paramet submit remot run integr requir mlproject file project folder submit project run tri time figur structur question best wai push experi run pipelin comput cluster thank advanc help",
        "Question_gpt_summary_original":"The user wants to use an Azure Machine Learning compute cluster as a compute target to run a Kedro pipeline integrated with Mlflow. They have successfully integrated experiment tracking using Mlflow and Azure ML as backend\/artifact stores on a compute instance. However, they are struggling to use compute clusters for hyperparameter tuning and other heavy workloads. The user is seeking advice on the best way to push experiment runs in a Kedro Pipeline to Azure ML compute clusters.",
        "Question_gpt_summary":"user want us comput cluster comput target run pipelin integr successfulli integr experi track backend artifact store comput instanc struggl us comput cluster hyperparamet tune heavi workload user seek advic best wai push experi run pipelin comput cluster"
    },
    {
        "Question_title":"Is it possible to include the IP address of a specific Azure Machine Learning workspace in its storage account selected networks and get all functionality enabled?",
        "Question_body":"<p>We have secured the storage account of a Machine Learning workspace behind a vnet and have authorized a set of IPs to access the storage account. Since the workspace is not secured behind the vnet, a set of functions is disabled. Is there a way to get the IP of the workspace and include it in the list authorized networks for the storage account in order to have all workspace functionalities available? We know the official solution involves securing the workspace behind the vnet and enabling point-to-site, site-to-site or connecting through a VM, but these are not possible in our case. Thanks for the help.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1626459319327,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/479209\/is-it-possible-to-include-the-ip-address-of-a-spec",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl includ address specif workspac storag account select network function enabl secur storag account machin learn workspac vnet author set ip access storag account workspac secur vnet set function disabl wai workspac includ list author network storag account order workspac function avail know offici solut involv secur workspac vnet enabl point site site site connect possibl case thank help",
        "Question_preprocessed_content":"includ specif workspac storag select network function enabl secur storag machin learn workspac vnet author set ip storag workspac secur vnet set function disabl wai workspac includ list author network storag order workspac function avail know solut involv secur workspac vnet enabl case thank help",
        "Question_gpt_summary_original":"The user has secured the storage account of an Azure Machine Learning workspace behind a vnet and authorized a set of IPs to access it. However, since the workspace is not secured behind the vnet, some functions are disabled. The user is looking for a way to include the IP of the workspace in the authorized networks list for the storage account to enable all workspace functionalities, but the official solutions are not possible in their case.",
        "Question_gpt_summary":"user secur storag account workspac vnet author set ip access workspac secur vnet function disabl user look wai includ workspac author network list storag account enabl workspac function offici solut possibl case"
    },
    {
        "Question_title":"Make custom kernels available to SageMaker Studio notebooks",
        "Question_body":"<p>On starting the SageMaker Studio server, I can only see a set of predefined kernels when\nI select kernel for any notebook.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/pGJIw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/pGJIw.png\" alt=\"Predefined Kernels\" \/><\/a><\/p>\n<p>I create conda environments and persist them between sessions by pointing <code>.condarc<\/code> to a custom miniconda directory stored on EFS.<\/p>\n<p>I want all notebooks to have access to environments stored in the custom miniconda directory. I can do that on the system terminal but can't seem to find a way to make the kernels available to notebooks.<\/p>\n<p>I am aware of <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/notebook-lifecycle-config.html\" rel=\"nofollow noreferrer\">Life Cycle Configuration<\/a> but that seems to be working only with notebooks instances rather than SageMaker Studio.<\/p>\n<p><strong>Desired outcomes<\/strong><\/p>\n<p>Ideally making custom kernels persistently available to notebooks but if that isn't feasible or requires custom docker image, I am happy with running a script manually every time I run the server.<\/p>\n<p><strong>What I have tried so far:<\/strong><\/p>\n<p>I ran the following which is a tweaked version of <a href=\"https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/blob\/master\/scripts\/persistent-conda-ebs\/on-start.sh\" rel=\"nofollow noreferrer\">start.sh<\/a> meant to be for Life Cycle Configuration.<\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>#!\/bin\/bash\n\nset -e\n\nsudo -u sagemaker-user -i &lt;&lt;'EOF'\nunset SUDO_UID\nWORKING_DIR=\/home\/sagemaker-user\/.SageMaker\/custom-miniconda\/\nsource \"$WORKING_DIR\/miniconda\/bin\/activate\"\nfor env in $WORKING_DIR\/miniconda\/envs\/*; do\n    BASENAME=$(basename \"$env\")\n    source activate \"$BASENAME\"\n    python -m ipykernel install --user --name \"$BASENAME\" --display-name \"$BASENAME\"\ndone\n\nEOF<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p>That didn't work and I couldn't access the kernels from the notebooks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1631856553007,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1616.0,
        "Poster_created_time":1398880184052,
        "Poster_location":null,
        "Poster_reputation_count":2245.0,
        "Poster_view_count":213.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69218162",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"custom kernel avail studio notebook start studio server set predefin kernel select kernel notebook creat conda environ persist session point condarc custom miniconda directori store ef want notebook access environ store custom miniconda directori termin wai kernel avail notebook awar life cycl configur work notebook instanc studio desir outcom ideal make custom kernel persist avail notebook isn feasibl requir custom docker imag happi run script manual time run server tri far ran follow tweak version start meant life cycl configur bin bash set sudo user eof unset sudo uid work dir home user custom miniconda sourc work dir miniconda bin activ env work dir miniconda env basenam basenam env sourc activ basenam python ipykernel instal user basenam displai basenam eof work couldn access kernel notebook",
        "Question_preprocessed_content":"custom kernel avail studio start studio server set predefin kernel select kernel creat conda environ persist point custom miniconda directori store ef want environ store custom miniconda directori termin wai kernel avail awar life cycl configur work instanc studio desir outcom make custom kernel persist avail isn feasibl requir custom docker imag script time run server tri far ran tweak version meant life cycl configur work couldn kernel",
        "Question_gpt_summary_original":"The user is facing an issue with SageMaker Studio where they can only see predefined kernels and cannot access custom kernels stored in a custom miniconda directory. They have tried persisting the environments between sessions using .condarc but cannot find a way to make the kernels available to notebooks. The user has tried running a tweaked version of start.sh but it did not work. They are looking for a solution to make custom kernels persistently available to notebooks or are willing to run a script manually every time they run the server.",
        "Question_gpt_summary":"user face issu studio predefin kernel access custom kernel store custom miniconda directori tri persist environ session condarc wai kernel avail notebook user tri run tweak version start work look solut custom kernel persist avail notebook will run script manual time run server"
    },
    {
        "Question_title":"is it possible to trigger a sagmamker pipeline execution via event bridge?",
        "Question_body":"I have a sagemaker pipeline code , currently run through a notebook , but i would like to hook it up to a evenbridge and trigger an execution. is it possible to do that , if yes, what permissions would i need and if there any samples of the event , that would be great",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1681850824873,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1682197563478,
        "Question_score_count":0.0,
        "Question_view_count":47.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUVa1pPnIUQuK_zwh8E1wHyA\/is-it-possible-to-trigger-a-sagmamker-pipeline-execution-via-event-bridge",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl trigger sagmamk pipelin execut event bridg pipelin code current run notebook like hook evenbridg trigger execut possibl ye permiss need sampl event great",
        "Question_preprocessed_content":"sagmamk pipelin execut event bridg pipelin code run like evenbridg execut ye sampl event great",
        "Question_gpt_summary_original":"The user wants to know if it is possible to trigger a Sagemaker pipeline execution via Event Bridge. They are currently running the pipeline through a notebook and want to know what permissions they would need and if there are any samples of the event.",
        "Question_gpt_summary":"user want know possibl trigger pipelin execut event bridg current run pipelin notebook want know permiss need sampl event"
    },
    {
        "Question_title":"Deploy Azure ML Designer Web Service model",
        "Question_body":"<p>Im trying to run R code to detect outliers in datasets.\nIm trying to publish as a webservice so it can be used to pre process data.<\/p>\n\n<p>In Azure ML Designer,I have a Execute R script which contains my model.<\/p>\n\n<p>When I try to publish as a web service I get the error \"Cannot create inference because there is no model on this pipeline\".\nI see python has a Create Python module.<\/p>\n\n<p>Can I use an Execute R Script to create a webservice with my model?<\/p>\n\n<p>Im good at R and still learning Azure and would really appreciate some advice on. the above.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1583419993597,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":244.0,
        "Poster_created_time":1542820108076,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60548089",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi design web servic model try run code detect outlier dataset try publish webservic pre process data design execut script contain model try publish web servic error creat infer model pipelin python creat python modul us execut script creat webservic model good learn azur appreci advic",
        "Question_preprocessed_content":"deploi design web servic model try run code detect outlier dataset try publish webservic pre data design execut script contain model try publish web servic creat infer model pipelin python creat python modul us execut script creat webservic model learn azur advic",
        "Question_gpt_summary_original":"The user is trying to deploy an R code to detect outliers in datasets as a web service using Azure ML Designer. However, when trying to publish the web service, they receive an error message stating that there is no model on the pipeline. The user is seeking advice on whether they can use an Execute R Script to create a web service with their model.",
        "Question_gpt_summary":"user try deploi code detect outlier dataset web servic design try publish web servic receiv error messag state model pipelin user seek advic us execut script creat web servic model"
    },
    {
        "Question_title":"amazon-sagemaker-lab:: libXrender.so.1 package",
        "Question_body":"<p>I am trying to use the amazon sagemaker lab environment and the package libXrender is not installed.<\/p>\n<p>sudo privileges are removed and it's not possible to install it with:<\/p>\n<p><code>apt-get install libxrender1<\/code><\/p>\n<p>Is there an easy fix or do I have to contact their support to install the package in their docker container?<\/p>\n<p>Thanks in advance!<\/p>\n<p>Error results from this piece of code:<\/p>\n<pre><code>from rdkit.Chem.Draw import rdMolDraw2D\nfrom rdkit.Chem.Draw.rdMolDraw2D import *\n\nImportError: libXrender.so.1: cannot open shared object file: No such file or directory\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1656667948847,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":77.0,
        "Poster_created_time":1465911951740,
        "Poster_location":"Cambridge, UK",
        "Poster_reputation_count":1.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72827239",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"amazon lab libxrend packag try us lab environ packag libxrend instal sudo privileg remov possibl instal apt instal libxrend easi fix contact support instal packag docker contain thank advanc error result piec code rdkit chem draw import rdmoldrawd rdkit chem draw rdmoldrawd import importerror libxrend open share object file file directori",
        "Question_preprocessed_content":"packag try us lab environ packag libxrend sudo privileg remov easi fix contact packag docker contain thank advanc result piec code",
        "Question_gpt_summary_original":"The user is facing an issue with the Amazon SageMaker lab environment where the libXrender package is not installed. The user does not have sudo privileges to install it using \"apt-get install libxrender1\". The error is caused by a missing libXrender.so.1 file while running a code related to rdkit.Chem.Draw. The user is seeking an easy fix or support from Amazon to install the package in their docker container.",
        "Question_gpt_summary":"user face issu lab environ libxrend packag instal user sudo privileg instal apt instal libxrend error caus miss libxrend file run code relat rdkit chem draw user seek easi fix support amazon instal packag docker contain"
    },
    {
        "Question_title":"Using Wandb with HParams on TF",
        "Question_body":"<p>I think I may have got confused with this one. I had to code up a custom model using TF. It is training and running but I want to do some hyper parameter tuning so been working on getting HParms integrated.<\/p>\n<p>But I\u2019m trying to link up Wandb to keep track of things.<\/p>\n<p>Currently, since I\u2019m using hparms, when I initialize wandb with wandb.init(), it seems to initialize it for the whole process and it doesn\u2019t change when it is a new parameter set.<\/p>\n<p>I am calling the wandb.init() and logging after each parameter run, but still it doesn\u2019t create a unique job.<\/p>\n<p>This the function I call,<\/p>\n<pre><code class=\"lang-auto\">def write_to_wandb(ldl_model_params, KLi, f1_macro):\n    wandb.init(project=\"newjob1\", entity=\"demou\")\n    wandb.config = ldl_model_params\n\n    wandb_log = {\n        \"train KL\": KLi,\n        \"train F1\": f1_macro,\n        }\n\n    # logging accuracy\n    wandb.log(wandb_log)   \n<\/code><\/pre>\n<p>This is called from this train function (a high-level version of it). This <code>train_model<\/code> function is repeated again through another hyperparamter function with different hyper-parameter.<\/p>\n<pre><code class=\"lang-auto\">\ndef train_model(ldl_model_params,X,Y):\n    model = new_model(ldl_model_params)\n    model.fit(X,Y)\n    predict = model.transform(X)\n    KLi,F1 = model.evaluate(predict,Y)\n    write_to_wandb(ldl_model_params,KLi,F1)\n<\/code><\/pre>\n<p>So how do I fix this? I want each call to train_model to be recorded in a new run.<\/p>\n<p>I\u2019m new to wandb so I have a feeling that I am not using it as it should be. Thanks.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1636160879946,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":579.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Just had a chat with the support and figured out how to fix the problem with over-writing.<\/p>\n<p>Issue was with the init function and there is a flag for reinitializing (<code>reinit=True<\/code>)<\/p>\n<p><code>wandb.init(project=\"newjob1\", entity=\"demou\",reinit=True)<\/code>  this fixed this issue.<\/p>",
        "Answer_comment_count":null,
        "Question_closed_time":1636391832512,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/using-wandb-with-hparams-on-tf\/1233",
        "Tool":"Weights & Biases",
        "Question_self_closed":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"hparam think got confus code custom model train run want hyper paramet tune work get hparm integr try link track thing current hparm initi init initi process doesnt chang new paramet set call init log paramet run doesnt creat uniqu job function def write ldl model param kli macro init project newjob entiti demou config ldl model param log train kli train macro log accuraci log log call train function high level version train model function repeat hyperparamt function differ hyper paramet def train model ldl model param model new model ldl model param model fit predict model transform kli model evalu predict write ldl model param kli fix want train model record new run new feel thank",
        "Question_preprocessed_content":"hparam think got confus code custom model train want hyper paramet tune work hparm integr try link track thing hparm initi init initi doesnt chang new paramet set init paramet run doesnt creat uniqu job function train function function repeat hyperparamt function fix want record new run new thank",
        "Question_gpt_summary_original":"The user is trying to integrate HParams with Wandb to perform hyperparameter tuning for a custom model using TensorFlow. However, when initializing Wandb with wandb.init(), it seems to initialize it for the whole process and doesn't change when it is a new parameter set. The user is calling wandb.init() and logging after each parameter run, but it doesn't create a unique job. The user is seeking a solution to record each call to train_model in a new run.",
        "Question_gpt_summary":"user try integr hparam perform hyperparamet tune custom model tensorflow initi init initi process chang new paramet set user call init log paramet run creat uniqu job user seek solut record train model new run"
    },
    {
        "Question_title":"Azure ML: Upload File to Step Run's Output - Authentication Error",
        "Question_body":"<p>During a PythonScriptStep in an Azure ML Pipeline, I'm saving a model as joblib pickle dump to a directory in a Blob Container in the Azure Blob Storage which I've created during the setup of the Azure ML Workspace. Afterwards I'm trying to upload this model file to the step run's output directory using<\/p>\n<pre><code>Run.upload_file (name, path_or_stream)\n<\/code><\/pre>\n<p>(for the function's documentation, see <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#upload-file-name--path-or-stream--datastore-name-none-\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#upload-file-name--path-or-stream--datastore-name-none-<\/a>)<\/p>\n<p>Some time ago when I created the script using the azureml-sdk version 1.18.0, everything worked fine. Now, I've updated the script's functionalities and upgraded the azureml-sdk to version 1.33.0 during the process and the upload function now runs into the following error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 64, in upload_blob_from_stream\n    validate_content=True)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 93, in execute_func_with_reset\n    return ClientBase._execute_func_internal(backoff, retries, module_logger, func, reset_func, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 367, in _execute_func_internal\n    left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 399, in _handle_retry\n    raise error\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 358, in _execute_func_internal\n    response = func(*args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py&quot;, line 614, in create_blob_from_stream\n    initialization_vector=iv\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 98, in _upload_blob_chunks\n    range_ids = [f.result() for f in futures]\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 98, in &lt;listcomp&gt;\n    range_ids = [f.result() for f in futures]\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/_base.py&quot;, line 435, in result\n    return self.__get_result()\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/_base.py&quot;, line 384, in __get_result\n    raise self._exception\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 210, in process_chunk\n    return self._upload_chunk_with_progress(chunk_offset, chunk_bytes)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 224, in _upload_chunk_with_progress\n    range_id = self._upload_chunk(chunk_offset, chunk_data)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 269, in _upload_chunk\n    timeout=self.timeout,\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py&quot;, line 1013, in _put_block\n    self._perform_request(request)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 432, in _perform_request\n    raise ex\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 357, in _perform_request\n    raise ex\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 343, in _perform_request\n    HTTPError(response.status, response.message, response.headers, response.body))\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/_error.py&quot;, line 115, in _http_error_handler\n    raise ex\nazure.common.AzureHttpError: Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n\n2019-07-07\nb\n\n&lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/...\/azureml-setup\/context_manager_injector.py&quot;, line 243, in execute_with_context\n    runpy.run_path(sys.argv[0], globals(), run_name=&quot;__main__&quot;)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 263, in run_path\n    pkg_name=pkg_name, script_name=fname)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 96, in _run_module_code\n    mod_name, mod_spec, pkg_name, script_name)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 85, in _run_code\n    exec(code, run_globals)\n  File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 318, in &lt;module&gt;\n    main()\n  File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 286, in main\n    path_or_stream=model_path)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 53, in wrapped\n    return func(self, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 1989, in upload_file\n    datastore_name=datastore_name)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 114, in upload_artifact\n    return self.upload_artifact_from_path(artifact, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 107, in upload_artifact_from_path\n    return self.upload_artifact_from_stream(stream, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 99, in upload_artifact_from_stream\n    content_type=content_type, session=session)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 88, in upload_stream_to_existing_artifact\n    timeout=TIMEOUT, backoff=BACKOFF_START, retries=RETRY_LIMIT)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 71, in upload_blob_from_stream\n    raise AzureMLException._with_error(azureml_error, inner_exception=e)\nazureml._common.exceptions.AzureMLException: AzureMLException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n\n2019-07-07\nb\n\n&lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: mystorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;Auth&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;Authorization&quot;\n            }\n        }\n    }\n}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 318, in &lt;module&gt;\n    main()\n  File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 286, in main\n    path_or_stream=model_path)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 53, in wrapped\n    return func(self, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 1989, in upload_file\n    datastore_name=datastore_name)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 114, in upload_artifact\n    return self.upload_artifact_from_path(artifact, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 107, in upload_artifact_from_path\n    return self.upload_artifact_from_stream(stream, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 99, in upload_artifact_from_stream\n    content_type=content_type, session=session)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 88, in upload_stream_to_existing_artifact\n    timeout=TIMEOUT, backoff=BACKOFF_START, retries=RETRY_LIMIT)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 71, in upload_blob_from_stream\n    raise AzureMLException._with_error(azureml_error, inner_exception=e)\nUserScriptException: UserScriptException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException AzureMLException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n\n2019-07-07\nb\n\n&lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: verovisionstorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;Auth&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;Authorization&quot;\n            }\n        }\n    }\n}\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: mystorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;\n    }\n}\n<\/code><\/pre>\n<p>As far as I can tell from the code of the azureml.core.Run class and the subsequent function calls, the Run object tries to upload the file to the step run's output directory using SAS-Token-Authentication (which fails). This documentation article is linked in the code (but I don't know if this relates to the issue): <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/storageservices\/create-service-sas#service-sas-example\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/rest\/api\/storageservices\/create-service-sas#service-sas-example<\/a><\/p>\n<p>Did anybody encounter this error as well and knows what causes it or how it can be resolved?<\/p>\n<p>Best,\nJonas<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1630074825080,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":215.0,
        "Poster_created_time":1594877973727,
        "Poster_location":"Germany",
        "Poster_reputation_count":51.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68955197",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"upload file step run output authent error pythonscriptstep pipelin save model joblib pickl dump directori blob contain azur blob storag creat setup workspac try upload model file step run output directori run upload file path stream function document http doc microsoft com python api core core run class view azur upload file path stream datastor time ago creat script sdk version work fine updat script function upgrad sdk version process upload function run follow error traceback recent file opt miniconda lib python site packag file util upload line upload blob stream valid content true file opt miniconda lib python site packag restclient clientbas line execut func reset return clientbas execut func intern backoff retri modul logger func reset func arg kwarg file opt miniconda lib python site packag restclient clientbas line execut func intern left retri cl handl retri left retri total retri error logger func file opt miniconda lib python site packag restclient clientbas line handl retri rais error file opt miniconda lib python site packag restclient clientbas line execut func intern respons func arg kwarg file opt miniconda lib python site packag vendor azur storag blob blockblobservic line creat blob stream initi vector file opt miniconda lib python site packag vendor azur storag blob upload chunk line upload blob chunk rang id result futur file opt miniconda lib python site packag vendor azur storag blob upload chunk line rang id result futur file opt miniconda lib python concurr futur base line result return self result file opt miniconda lib python concurr futur base line result rais self except file opt miniconda lib python concurr futur thread line run result self self arg self kwarg file opt miniconda lib python site packag vendor azur storag blob upload chunk line process chunk return self upload chunk progress chunk offset chunk byte file opt miniconda lib python site packag vendor azur storag blob upload chunk line upload chunk progress rang self upload chunk chunk offset chunk data file opt miniconda lib python site packag vendor azur storag blob upload chunk line upload chunk timeout self timeout file opt miniconda lib python site packag vendor azur storag blob blockblobservic line block self perform request request file opt miniconda lib python site packag vendor azur storag common storagecli line perform request rais file opt miniconda lib python site packag vendor azur storag common storagecli line perform request rais file opt miniconda lib python site packag vendor azur storag common storagecli line perform request httperror respons statu respons messag respons header respons bodi file opt miniconda lib python site packag vendor azur storag common error line http error handler rais azur common azurehttperror server fail authent request sure valu author header form correctli includ signatur errorcod authenticationfail authenticationfailedserv fail authent request sure valu author header form correctli includ signatur requestid debe bfa time zsignatur match string sign rcw blob mystorag experimentrun dcid dab aac bbdeeb output model model pkl handl except except occur traceback recent file mnt batch task share root job setup context manag injector line execut context runpi run path sy argv global run main file opt miniconda lib python runpi line run path pkg pkg script fname file opt miniconda lib python runpi line run modul code mod mod spec pkg script file opt miniconda lib python runpi line run code exec code run global file aml pipelin time seri model train azur cpu line main file aml pipelin time seri model train azur cpu line main path stream model path file opt miniconda lib python site packag core run line wrap return func self arg kwarg file opt miniconda lib python site packag core run line upload file datastor datastor file opt miniconda lib python site packag restclient artifact client line upload artifact return self upload artifact path artifact arg kwarg file opt miniconda lib python site packag restclient artifact client line upload artifact path return self upload artifact stream stream arg kwarg file opt miniconda lib python site packag restclient artifact client line upload artifact stream content type content type session session file opt miniconda lib python site packag restclient artifact client line upload stream exist artifact timeout timeout backoff backoff start retri retri limit file opt miniconda lib python site packag file util upload line upload blob stream rais except error error inner except common except except except messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set storageaccount mystorag containernam statuscod innerexcept server fail authent request sure valu author header form correctli includ signatur errorcod authenticationfail authenticationfailedserv fail authent request sure valu author header form correctli includ signatur requestid debe bfa time zsignatur match string sign rcw blob mystorag experimentrun dcid dab aac bbdeeb output model model pkl errorrespons error code usererror messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set tstorageaccount mystorag tcontainernam tstatuscod inner error code auth inner error code author handl except except occur traceback recent file aml pipelin time seri model train azur cpu line main file aml pipelin time seri model train azur cpu line main path stream model path file opt miniconda lib python site packag core run line wrap return func self arg kwarg file opt miniconda lib python site packag core run line upload file datastor datastor file opt miniconda lib python site packag restclient artifact client line upload artifact return self upload artifact path artifact arg kwarg file opt miniconda lib python site packag restclient artifact client line upload artifact path return self upload artifact stream stream arg kwarg file opt miniconda lib python site packag restclient artifact client line upload artifact stream content type content type session session file opt miniconda lib python site packag restclient artifact client line upload stream exist artifact timeout timeout backoff backoff start retri retri limit file opt miniconda lib python site packag file util upload line upload blob stream rais except error error inner except userscriptexcept userscriptexcept messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set storageaccount mystorag containernam statuscod innerexcept except messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set storageaccount mystorag containernam statuscod innerexcept server fail authent request sure valu author header form correctli includ signatur errorcod authenticationfail authenticationfailedserv fail authent request sure valu author header form correctli includ signatur requestid debe bfa time zsignatur match string sign rcw blob mystorag experimentrun dcid dab aac bbdeeb output model model pkl errorrespons error code usererror messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set tstorageaccount verovisionstorag tcontainernam tstatuscod inner error code auth inner error code author errorrespons error code usererror messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set tstorageaccount mystorag tcontainernam tstatuscod far tell code core run class subsequ function call run object tri upload file step run output directori sa token authent fail document articl link code know relat issu http doc microsoft com rest api storageservic creat servic sa servic sa exampl anybodi encount error know caus resolv best jona",
        "Question_preprocessed_content":"upload file step run output authent pythonscriptstep pipelin save model joblib pickl dump directori blob contain azur blob storag creat setup workspac try upload model file step run output directori function document time ago creat script sdk version work fine updat script function upgrad sdk version upload function run far code subsequ function run object tri upload file step run output directori document articl link code anybodi encount know caus resolv best jona",
        "Question_gpt_summary_original":"the user encountered an authentication error while attempting to upload a file to the step run's output directory using run.upload_file, which was caused by a sas-token authentication failure.",
        "Question_gpt_summary":"user encount authent error attempt upload file step run output directori run upload file caus sa token authent failur"
    },
    {
        "Question_title":"Isn't Interactive login, default for Workspace.from_config()?",
        "Question_body":"<p>According to <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\">this<\/a> notebook  <\/p>\n<blockquote>\n<p>Interactive Authentication  <br \/>\nInteractive authentication is the default mode when using Azure ML SDK.  <\/p>\n<p>When you connect to your workspace using workspace.from_config, you will get an interactive login dialog.  <\/p>\n<\/blockquote>\n<p>So, i ran <code>ws=Workspace.from_config()<\/code>  <br \/>\n and got the following error  <\/p>\n<pre><code>--------------------------------------------------------------------------\nUserErrorException                        Traceback (most recent call last)\n&lt;ipython-input-13-e469111f639c&gt; in &lt;module&gt;\n----&gt; 1 ws = Workspace.from_config()\n\n~\\Documents\\Softwares\\Anaconda3\\lib\\site-packages\\azureml\\core\\workspace.py in from_config(path, auth, _logger, _file_name)\n    276\n    277             if not found_path:\n--&gt; 278                 raise UserErrorException(\n    279                     'We could not find config.json in: {} or in its parent directories. '\n    280                     'Please provide the full path to the config file or ensure that '\n\nUserErrorException: UserErrorException:\n        Message: We could not find config.json in: C:\\Users\\qwewqd or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n        InnerException None\n        ErrorResponse\n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;We could not find config.json in: C:\\\\Users\\\\qwewqd or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;\n    }\n}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1606097614390,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=2c0f2a38-b74b-451f-85f1-6cc6fb702227\">@kalyan reddy  <\/a> A configuration file(JSON) is created when you run the configuration.ipynb file or notebook which can then be used to get the configuration using     <br \/>\n    ws = Workspace.from_config()  <\/p>\n<p>You can run this <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/setup-environment\/configuration.ipynb\">notebook<\/a> and create a new workspace if not available or use the existing workspace. For example, Set the workspace details as environment varibles.    <\/p>\n<pre><code>import os  \n  \nsubscription_id = os.getenv(&quot;SUBSCRIPTION_ID&quot;, default=&quot;&lt;my-subscription-id&gt;&quot;)  \nresource_group = os.getenv(&quot;RESOURCE_GROUP&quot;, default=&quot;&lt;my-resource-group&gt;&quot;)  \nworkspace_name = os.getenv(&quot;WORKSPACE_NAME&quot;, default=&quot;&lt;my-workspace-name&gt;&quot;)  \nworkspace_region = os.getenv(&quot;WORKSPACE_REGION&quot;, default=&quot;eastus2&quot;)  \n<\/code><\/pre>\n<p>Write then to config.json file    <\/p>\n<pre><code>from azureml.core import Workspace  \n  \ntry:  \n    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)  \n    # write the details of the workspace to a configuration file to the notebook library  \n    ws.write_config()  \n    print(&quot;Workspace configuration succeeded. Skip the workspace creation steps below&quot;)  \nexcept:  \n    print(&quot;Workspace not accessible. Change your parameters or create a new workspace below&quot;)  \n<\/code><\/pre>\n<p>You can now access this config from other notebooks and need not specify the subscription or workspace details in every notebook file.    <\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1606116372007,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171577\/isnt-interactive-login-default-for-workspace-from",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"isn interact login default workspac config accord notebook interact authent interact authent default mode sdk connect workspac workspac config interact login dialog ran workspac config got follow error usererrorexcept traceback recent workspac config document softwar anaconda lib site packag core workspac config path auth logger file path rais usererrorexcept config json parent directori provid path config file ensur usererrorexcept usererrorexcept messag config json user qwewqd parent directori provid path config file ensur config json exist parent directori innerexcept errorrespons error code usererror messag config json user qwewqd parent directori provid path config file ensur config json exist parent directori",
        "Question_preprocessed_content":"isn interact login default interact authent interact authent default mode sdk workspac interact login dialog ran got",
        "Question_gpt_summary_original":"The user is encountering an error while running the code \"ws=Workspace.from_config()\" which is unable to find the config.json file in the specified directory or its parent directories. The user is questioning if interactive authentication is the default mode for Workspace.from_config().",
        "Question_gpt_summary":"user encount error run code workspac config unabl config json file specifi directori parent directori user question interact authent default mode workspac config"
    },
    {
        "Question_title":"Grouping runs decreases the granularity of the plots",
        "Question_body":"<p>See the attached image with grouped runs and range set to samples. The actual plots (faint lines) have a much higher granularity then the grouped plot. This decrease in granularity is particularly visible when x-axis is set to log-scale.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e.jpeg\" data-download-href=\"\/uploads\/short-url\/vxWxi1IA9sZR2hhpUslBXc37Mxo.jpeg?dl=1\" title=\"Screenshot 2022-12-11 at 5.03.49 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_690x235.jpeg\" alt=\"Screenshot 2022-12-11 at 5.03.49 PM\" data-base62-sha1=\"vxWxi1IA9sZR2hhpUslBXc37Mxo\" width=\"690\" height=\"235\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_690x235.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_1035x352.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_1380x470.jpeg 2x\" data-dominant-color=\"FAFAFB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2022-12-11 at 5.03.49 PM<\/span><span class=\"informations\">2801\u00d7957 152 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1670796201528,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":146.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/grouping-runs-decreases-the-granularity-of-the-plots\/3532",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"group run decreas granular plot attach imag group run rang set sampl actual plot faint line higher granular group plot decreas granular particularli visibl axi set log scale screenshot",
        "Question_preprocessed_content":"group run decreas granular plot imag group run rang set sampl actual plot higher granular group plot decreas granular particularli visibl set",
        "Question_gpt_summary_original":"The user has encountered an issue where grouping runs decreases the granularity of the plots, which is particularly visible when the x-axis is set to log-scale. The actual plots have a much higher granularity than the grouped plot.",
        "Question_gpt_summary":"user encount issu group run decreas granular plot particularli visibl axi set log scale actual plot higher granular group plot"
    },
    {
        "Question_title":"Optuna returns the last value, not the best one for one trial",
        "Question_body":"<p>I'm using Optuna. Imagine these are the value for &quot;1 trial&quot; with &quot;5 epochs or steps&quot;:<\/p>\n<p>Epoch 0: 18 - Epoch 1: 32 - Epoch 2: 14 - Epoch 3: 28 - Epoch 4: 25<\/p>\n<p>I expect Optuna to return 14 as the value for this trial but it gives me 25 (value of the last epoch). I want optuna to return the best intermediate value as the final value, not the last one. Any explanation, as well as the solution to solve the problem, will be appreciated.<\/p>\n<p>P.s: I am talking about just one trial, not a study.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1634714319767,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":321.0,
        "Poster_created_time":1634713278736,
        "Poster_location":"Germany",
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69641832",
        "Tool":"Optuna",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"return valu best trial imagin valu trial epoch step epoch epoch epoch epoch epoch expect return valu trial give valu epoch want return best intermedi valu final valu explan solut solv problem appreci talk trial studi",
        "Question_preprocessed_content":"return valu best trial imagin valu trial epoch step epoch epoch epoch epoch epoch expect return valu trial give want return best intermedi valu final valu explan solut solv problem talk trial studi",
        "Question_gpt_summary_original":"The user is facing an issue with Optuna where it returns the last value instead of the best intermediate value for one trial with 5 epochs or steps. The user expects Optuna to return the best intermediate value, which is 14, but it returns the last value, which is 25. The user is seeking an explanation and a solution to this problem.",
        "Question_gpt_summary":"user face issu return valu instead best intermedi valu trial epoch step user expect return best intermedi valu return valu user seek explan solut problem"
    },
    {
        "Question_title":"can I use mlflow python API to register a spark UDF & then use the UDF in Spark scala code?",
        "Question_body":"<p>I'm trying to use mlflow to do the machine learning work. I register the ML model as UDF using the following python code. The question is how can I use the UDF(test_predict) in my scala code? The reason is that our main code is in Scala. The problem is that UDF created below is a temporary UDF and SparkSession scoped. thanks!<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import sys\nimport mlflow\nfrom mlflow import pyfunc\nimport numpy as np\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark import SQLContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.sql.types import *\n\nsc=SparkContext()\nspark = SparkSession.builder.appName(\"Python UDF example\").getOrCreate()\npyfunc_udf=mlflow.pyfunc.spark_udf(spark=spark, model_uri=\".\/sk\",result_type=\"float\")\nspark.udf.register(\"test_predict\",pyfunc_udf)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1587824105457,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1588065231427,
        "Question_score_count":2.0,
        "Question_view_count":617.0,
        "Poster_created_time":1553506414607,
        "Poster_location":null,
        "Poster_reputation_count":129.0,
        "Poster_view_count":47.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61427012",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us python api regist spark udf us udf spark scala code try us machin learn work regist model udf follow python code question us udf test predict scala code reason main code scala problem udf creat temporari udf sparksess scope thank import sy import import pyfunc import numpi pyspark import sparkcontext sparkconf pyspark import sqlcontext pyspark sql session import sparksess pyspark sql type import sparkcontext spark sparksess builder appnam python udf exampl getorcr pyfunc udf pyfunc spark udf spark spark model uri result type float spark udf regist test predict pyfunc udf",
        "Question_preprocessed_content":"us python api regist spark udf us udf spark scala code try us machin learn work regist model udf python code question us scala code reason main code scala problem udf creat temporari udf scope thank",
        "Question_gpt_summary_original":"The user is trying to register a machine learning model as a UDF using mlflow Python API and wants to use the UDF in their Scala code. However, the UDF created is temporary and SparkSession scoped, which is causing a problem as their main code is in Scala.",
        "Question_gpt_summary":"user try regist machin learn model udf python api want us udf scala code udf creat temporari sparksess scope caus problem main code scala"
    },
    {
        "Question_title":"How can I save more metadata on an MLFlow model",
        "Question_body":"<p>I am trying to save a model to MLFlow, but as I have a custom prediction pipeline to retrieve data, I need to save extra metadata into the model.<\/p>\n<p>I tried using my custom signature class, which It does the job correctly and saves the model with the extra metadata in the MLModel file (YAML format). But when want to load the model from the MLFlow registry, the signature is not easy accesible.<\/p>\n<pre><code>mlflow.sklearn.log_model(model, &quot;model&quot;, signature = signature)\n<\/code><\/pre>\n<p>I've also tried to save an extra dictionary at the log_model function, but it saves it in the conda.yaml file:<\/p>\n<pre><code>mlflow.sklearn.log_model(model, &quot;model&quot;, {&quot;metadata1&quot;:&quot;value1&quot;, &quot;metadata2&quot;:&quot;value2&quot;})\n<\/code><\/pre>\n<p>Should I make my own flavour? Or my own Model inheritance? I've seen <a href=\"https:\/\/github1s.com\/mlflow\/mlflow\/blob\/HEAD\/mlflow\/pyfunc\/__init__.py\" rel=\"nofollow noreferrer\">here<\/a> that the PyFuncModel recieves some metadata class and an implementation to solve this, but I don't know where should I pass my own implementations to PyFuncModel on an experiment script. Here's a minimal example:<\/p>\n<pre><code>import mlflow\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\nmetadata_dic = {&quot;metadata1&quot;: &quot;value1&quot;, \n                &quot;metadata2&quot;: &quot;value2&quot;}\n\nX = np.array([[-2, -1, 0, 1, 2, 1],[-2, -1, 0, 1, 2, 1]]).T\ny = np.array([0, 0, 1, 1, 1, 0])\n\nX = pd.DataFrame(X, columns=[&quot;X1&quot;, &quot;X2&quot;])\ny = pd.DataFrame(y, columns=[&quot;y&quot;])\n\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\n\nmlflow.sklearn.log_model(model, &quot;model&quot;)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1638276045390,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":323.0,
        "Poster_created_time":1550233102176,
        "Poster_location":null,
        "Poster_reputation_count":621.0,
        "Poster_view_count":103.0,
        "Answer_body":"<p>Finally, I made a class that contains every metadata and saved it as an model argument:<\/p>\n<pre><code>model = LogisticRegression()\nmodel.fit(X, y)\nmodel.metadata = ModelMetadata(**metadata_dic)\nmlflow.sklearn.log_model(model, &quot;model&quot;)\n<\/code><\/pre>\n<p>Here I lost the customizable <code>predict<\/code> process, but after reading the <code>MLFlow<\/code> documentation is not very clear how to proceed.<\/p>\n<p>If anyone finds a good approach It would be very appreciated.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1638361888372,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1550233102176,
        "Answerer_location":null,
        "Answerer_reputation_count":621.0,
        "Answerer_view_count":103.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70169519",
        "Tool":"MLflow",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save metadata model try save model custom predict pipelin retriev data need save extra metadata model tri custom signatur class job correctli save model extra metadata mlmodel file yaml format want load model registri signatur easi acces sklearn log model model model signatur signatur tri save extra dictionari log model function save conda yaml file sklearn log model model model metadata valu metadata valu flavour model inherit seen pyfuncmodel reciev metadata class implement solv know pass implement pyfuncmodel experi script minim exampl import import numpi import panda sklearn linear model import logisticregress metadata dic metadata valu metadata valu arrai arrai datafram column datafram column model logisticregress model fit sklearn log model model model",
        "Question_preprocessed_content":"save metadata model try save model custom predict pipelin retriev data save extra metadata model tri custom signatur job save model extra metadata mlmodel file want load model registri signatur easi tri save extra dictionari function save file flavour model inherit pyfuncmodel reciev metadata implement solv know implement pyfuncmodel experi script minim exampl",
        "Question_gpt_summary_original":"The user is trying to save a model to MLFlow with extra metadata using a custom signature class or a dictionary, but is unable to access the signature when loading the model from the MLFlow registry. The user is considering creating their own flavor or model inheritance and is seeking guidance on how to pass their own implementations to PyFuncModel on an experiment script.",
        "Question_gpt_summary":"user try save model extra metadata custom signatur class dictionari unabl access signatur load model registri user consid creat flavor model inherit seek guidanc pass implement pyfuncmodel experi script"
    },
    {
        "Question_title":"The default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'",
        "Question_body":"<p>I am trying to fit XGBClassifier to my dataset after hyperparameter tuning using optuna and I keep getting this warning:<\/p>\n<blockquote>\n<p>the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'<\/p>\n<\/blockquote>\n<p>Below is my code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>#XGBC MODEL\nmodel = XGBClassifier(random_state = 69)\n\ncross_rfc_score = -1 * cross_val_score(model, train_x1, train_y,\n                           cv = 5, n_jobs = -1, scoring = 'neg_mean_squared_error')\nbase_rfc_score = cross_rfc_score.mean()\n<\/code><\/pre>\n<p>But if I use Optuna and then fit the obtained parameters it gives me the warning. Below is the code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def objective(trial):\n    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.01)\n    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n    sub_sample = trial.suggest_float('sub_sample', 0.0, 1.0)\n    max_depth = trial.suggest_int('max_depth', 1, 20)\n\n    params = {'max_depth' : max_depth,\n           'n_estimators' : n_estimators,\n           'sub_sample' : sub_sample,\n           'learning_rate' : learning_rate}\n\n    model.set_params(**params)\n\n    return np.mean(-1 * cross_val_score(model, train_x1, train_y,\n                            cv = 5, n_jobs = -1, scoring = 'neg_mean_squared_error'))\n\nxgbc_study = optuna.create_study(direction = 'minimize')\nxgbc_study.optimize(objective, n_trials = 10)\n\nxgbc_study.best_params\noptuna_rfc_mse = xgbc_study.best_value\n\nmodel.set_params(**xgbc_study.best_params)\nmodel.fit(train_x1, train_y)\nxgbc_optuna_pred = model.predict(test_x1)\nxgbc_optuna_mse1 = mean_squared_error(test_y, xgbc_optuna_pred)\n<\/code><\/pre>\n<p>The full warning is:<\/p>\n<blockquote>\n<p>Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.<\/p>\n<\/blockquote>\n<p>I want <code>MSE<\/code> as my metric of choice.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1628068876503,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1628327539816,
        "Question_score_count":7.0,
        "Question_view_count":5691.0,
        "Poster_created_time":1614760458072,
        "Poster_location":"India",
        "Poster_reputation_count":396.0,
        "Poster_view_count":70.0,
        "Answer_body":"<p>Just as described <a href=\"https:\/\/xgboost.readthedocs.io\/en\/latest\/parameter.html\" rel=\"noreferrer\">here<\/a>, try to add <code>eval_metric<\/code> to your <code>.fit<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>model.fit(train_x1, train_y, eval_metric='rmse')\n<\/code><\/pre>\n<p>as optimizing <code>rmse<\/code> and <code>mse<\/code> is leading towards the same results.<\/p>",
        "Answer_comment_count":4.0,
        "Question_closed_time":1628083548827,
        "Answer_last_edit_time":null,
        "Answer_score_count":6.0,
        "Answerer_created_time":1536872853240,
        "Answerer_location":"Copenhagen, Denmark",
        "Answerer_reputation_count":478.0,
        "Answerer_view_count":27.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68648689",
        "Tool":"Optuna",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"default evalu metric object binari logist chang error logloss try fit xgbclassifi dataset hyperparamet tune get warn default evalu metric object binari logist chang error logloss code xgbc model model xgbclassifi random state cross rfc score cross val score model train train job score neg mean squar error base rfc score cross rfc score mean us fit obtain paramet give warn code def object trial learn rate trial suggest float learn rate estim trial suggest int estim sub sampl trial suggest float sub sampl max depth trial suggest int max depth param max depth max depth estim estim sub sampl sub sampl learn rate learn rate model set param param return mean cross val score model train train job score neg mean squar error xgbc studi creat studi direct minim xgbc studi optim object trial xgbc studi best param rfc mse xgbc studi best valu model set param xgbc studi best param model fit train train xgbc pred model predict test xgbc mse mean squar error test xgbc pred warn start xgboost default evalu metric object binari logist chang error logloss explicitli set eval metric like restor old behavior want mse metric choic",
        "Question_preprocessed_content":"default evalu metric object binari logist chang try fit dataset hyperparamet tune warn default evalu metric object binari logist chang code us fit obtain paramet give warn code warn start default evalu metric object binari logist chang explicitli set like restor old behavior want metric choic",
        "Question_gpt_summary_original":"The user is encountering a warning message while fitting XGBClassifier to their dataset after hyperparameter tuning using optuna. The warning message states that the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss' in XGBoost 1.3.0. The user wants to use MSE as their metric of choice.",
        "Question_gpt_summary":"user encount warn messag fit xgbclassifi dataset hyperparamet tune warn messag state default evalu metric object binari logist chang error logloss xgboost user want us mse metric choic"
    },
    {
        "Question_title":"Can't Import Modules In Sagemaker Jupyter Notebook",
        "Question_body":"I've tried to use the pip install librosa command within a jupyter notebook, yet I get a modulenotfounderror. Is there a place where I can use pip install librosa?\n\nThanks.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1660764982506,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668609100912,
        "Question_score_count":0.0,
        "Question_view_count":334.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUBSiq8Lx5St-1D8CT3k328g\/can-t-import-modules-in-sagemaker-jupyter-notebook",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"import modul jupyt notebook tri us pip instal librosa command jupyt notebook modulenotfounderror place us pip instal librosa thank",
        "Question_preprocessed_content":"import modul jupyt tri us pip librosa jupyt place us pip librosa thank",
        "Question_gpt_summary_original":"The user is unable to import modules in Sagemaker Jupyter Notebook and is facing a ModuleNotFoundError while trying to use the pip install librosa command. They are seeking help to find a solution to this issue.",
        "Question_gpt_summary":"user unabl import modul jupyt notebook face modulenotfounderror try us pip instal librosa command seek help solut issu"
    },
    {
        "Question_title":"How can I import the latest version of pandas in my Jupyter Sagemaker notebook instance?",
        "Question_body":"<p>Whenever I run this code in a cell:<\/p>\n\n<pre><code>import pandas as pd\npd.__version__\n<\/code><\/pre>\n\n<p>I get the following:<\/p>\n\n<pre><code>'0.24.2'\n<\/code><\/pre>\n\n<p>I would like to be able to import the latest version of pandas right off the bat.  When I look at the Conda Packages under <em>Kernel<\/em> -> <em>Conda Packages<\/em>, I can see that pandas 1.0.1 is installed.  I would like to avoid having to do <code>!pip install --upgrade pandas<\/code> every time I run this notebook.  Is there a way to do that?  I'm confused by the fact that conda seems to have pandas 1.0.1 installed but it only imports version 0.24.2.<\/p>\n\n<p>I saw that you can specify the version of pandas via lifecycle configurations, but I was hoping there was a more permanent solution that automatically does it instead of me having to specify it.  <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_created_time":1582589550860,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1532.0,
        "Poster_created_time":1455042292696,
        "Poster_location":null,
        "Poster_reputation_count":43.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60385799",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"import latest version panda jupyt notebook instanc run code cell import panda version follow like abl import latest version panda right bat look conda packag kernel conda packag panda instal like avoid have pip instal upgrad panda time run notebook wai confus fact conda panda instal import version saw specifi version panda lifecycl configur hope perman solut automat instead have specifi",
        "Question_preprocessed_content":"import latest version panda jupyt instanc run code like abl import latest version panda right bat conda packag kernel conda packag panda like avoid have time run wai confus fact conda panda import version saw specifi version panda lifecycl configur hope perman solut instead have specifi",
        "Question_gpt_summary_original":"The user wants to import the latest version of pandas in their Jupyter Sagemaker notebook instance. They have pandas 1.0.1 installed in their Conda Packages, but when they run the code, it imports version 0.24.2. The user wants a permanent solution to automatically import the latest version without having to specify it every time.",
        "Question_gpt_summary":"user want import latest version panda jupyt notebook instanc panda instal conda packag run code import version user want perman solut automat import latest version have specifi time"
    },
    {
        "Question_title":"Azure ML datetime format issue in output",
        "Question_body":"<p>HI ,    <\/p>\n<p>Am trying to do some prediction for time series. When I get the output it is converting to MM\/DD\/YYYY format which is an issue.    <\/p>\n<p>When I give input in YYYY-MM-DD format why is it not returning me in the same format. Please see the screenshot of input vs output    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/41637-image.png?platform=QnA\" alt=\"41637-image.png\" \/>    <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1606058533223,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/171333\/azure-ml-datetime-format-issue-in-output",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"datetim format issu output try predict time seri output convert yyyi format issu input yyyi format return format screenshot input output",
        "Question_preprocessed_content":"datetim format output try predict time seri output convert format input format return format input output",
        "Question_gpt_summary_original":"The user is facing an issue with Azure ML datetime format in output. The output is being converted to MM\/DD\/YYYY format instead of the input format of YYYY-MM-DD. This is causing a problem for the user's time series prediction.",
        "Question_gpt_summary":"user face issu datetim format output output convert yyyi format instead input format yyyi caus problem user time seri predict"
    },
    {
        "Question_title":"How to set the environment variable WANDB_IGNORE_GLOBS correctly?",
        "Question_body":"<p>The usage in the <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/environment-variables#optional-environment-variables\">Docs<\/a> is:<\/p>\n<blockquote>\n<p>Set this to a comma separated list of file globs to ignore. These files will not be synced to the cloud<\/p>\n<\/blockquote>\n<p>So, is the below code correct?<\/p>\n<pre><code class=\"lang-python\">os.environ['WANDB_IGNORE_GLOBS'] = '[*.pth, *.npy]'\n<\/code><\/pre>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_created_time":1668582283551,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":142.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/geyao\">@geyao<\/a> thank you for writing in! Could you please check if the following would work for you?<\/p>\n<pre><code class=\"lang-auto\">os.environ['WANDB_IGNORE_GLOBS'] = '*.pth,*.npy'\n<\/code><\/pre>",
        "Answer_comment_count":null,
        "Question_closed_time":1668698260971,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-set-the-environment-variable-wandb-ignore-globs-correctly\/3423",
        "Tool":"Weights & Biases",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"set environ variabl ignor glob correctli usag doc set comma separ list file glob ignor file sync cloud code correct environ ignor glob pth npy",
        "Question_preprocessed_content":"set environ variabl usag doc set separ list file glob ignor file sync cloud code",
        "Question_gpt_summary_original":"The user is seeking guidance on how to correctly set the environment variable WANDB_IGNORE_GLOBS. They have provided a code snippet and are asking if it is correct. The variable is used to specify a list of file globs to ignore, which will not be synced to the cloud.",
        "Question_gpt_summary":"user seek guidanc correctli set environ variabl ignor glob provid code snippet ask correct variabl specifi list file glob ignor sync cloud"
    },
    {
        "Question_title":"Log (and then apply) Spark MLlib model from R to MLflow",
        "Question_body":"<p>I'm using Spark MLlib functions (through the <em>sparklyr<\/em> package) to train a model but now seem unable to save the model in <em>MLflow<\/em> for future use.<\/p>\n<pre><code>iris_tbl &lt;- sparklyr::copy_to(sc, iris, &quot;iris_spark&quot;)\nmdl_mllib &lt;- iris_tbl %&gt;% sparklyr::ml_linear_regression(formula = Sepal_Width ~ Sepal_Length)\nmlflow::mlflow_log_model(mdl_mllib, &quot;artifact_path_where_saved&quot;)\nError in UseMethod(&quot;mlflow_save_model&quot;) : \n  no applicable method for 'mlflow_save_model' applied to an object of class &quot;c('ml_model_linear_regression', 'ml_model_regression', 'ml_model_prediction', 'ml_model')&quot;\n\npackageVersion(&quot;mlflow&quot;)\n[1] \u20181.17.0\u2019\n<\/code><\/pre>\n<p>What is a simple way to save this model in <em>mlflow<\/em> for later use <strong>on a Spark DataFrame<\/strong> such as:<\/p>\n<p><code>mlflow::mlflow_load_model(model_uri = &quot;models:\/mdl_mllib_project01\/Staging&quot;)<\/code><\/p>\n<p>For context, I'm using Azure Databricks as the ecosystem.<\/p>\n<h3>Other places I've looked for answers<\/h3>\n<ul>\n<li>These links don't seem to directly solve my problem (<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#id28;\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/models.html#id28;<\/a> <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.spark.html#mlflow.spark.log_model\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.spark.html#mlflow.spark.log_model<\/a>), although maybe it's that I need to make a &quot;pipeline&quot; or that this works for Python but not yet for R?<\/li>\n<li>This question seems relevant but offers abstract answers rather than details (<a href=\"https:\/\/stackoverflow.com\/questions\/40533582\/how-to-serve-a-spark-mllib-model\">How to serve a Spark MLlib model?<\/a>).<\/li>\n<\/ul>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1627896006663,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":107.0,
        "Poster_created_time":1619023423856,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68619132",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"log appli spark mllib model spark mllib function sparklyr packag train model unabl save model futur us iri tbl sparklyr linear regress formula sepal width sepal length log model mdl mllib artifact path save error usemethod save model applic method save model appli object class model linear regress model regress model predict model packagevers simpl wai save model later us spark datafram load model model uri model mdl mllib project stage context azur databrick ecosystem place look answer link directli solv problem http www org doc latest model html http www org doc latest python api spark html spark log model mayb need pipelin work python question relev offer abstract answer detail serv spark mllib model",
        "Question_preprocessed_content":"log spark model spark function train model unabl save model futur us simpl wai save model later us spark datafram context azur databrick ecosystem place answer link directli solv problem mayb pipelin work python question relev abstract answer detail",
        "Question_gpt_summary_original":"The user is facing challenges in saving a Spark MLlib model in MLflow for future use. They are using the sparklyr package to train the model and are encountering an error when trying to log the model in MLflow. The user is seeking a simple way to save the model in MLflow for later use on a Spark DataFrame. They have looked at various resources but have not found a solution yet. The user is working in the Azure Databricks ecosystem.",
        "Question_gpt_summary":"user face challeng save spark mllib model futur us sparklyr packag train model encount error try log model user seek simpl wai save model later us spark datafram look resourc solut user work azur databrick ecosystem"
    },
    {
        "Question_title":"How to track parameter and metrics from Vertex AI pipelines",
        "Question_body":"<p>We are using both Vertex AI training jobs and Kubeflow pipelines in Google Clouds  Vertex AI.<\/p>\n<p>In training jobs we log parameters and metrics to Vertex AI Experiments through the python sdk.<\/p>\n<p>Can Vertex AI Pipelines track metrics from the Kubeflow pipeline to Experiments? Or failing that is it possible to get the pipeline run id and log manually through the sdk using this id is the run id? Any other approaches for experiment tracking in Vertex AI Pipelines?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1633589909387,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":404.0,
        "Poster_created_time":1546942930440,
        "Poster_location":null,
        "Poster_reputation_count":111.0,
        "Poster_view_count":10.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69476702",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"track paramet metric pipelin train job kubeflow pipelin googl cloud train job log paramet metric experi python sdk pipelin track metric kubeflow pipelin experi fail possibl pipelin run log manual sdk run approach experi track pipelin",
        "Question_preprocessed_content":"track paramet metric pipelin train job kubeflow pipelin cloud train job log paramet metric experi python sdk pipelin track metric kubeflow pipelin experi fail pipelin run log sdk run experi track pipelin",
        "Question_gpt_summary_original":"The user is seeking information on how to track parameters and metrics from Kubeflow pipelines in Vertex AI, specifically if it is possible to log them to Vertex AI Experiments or if there are alternative approaches for experiment tracking.",
        "Question_gpt_summary":"user seek inform track paramet metric kubeflow pipelin specif possibl log experi altern approach experi track"
    },
    {
        "Question_title":"How do I extend the waiting time of Azure speech-to-text API in Python?",
        "Question_body":"<p>When using speech-to-text to transfer audio file to text, I found that the function would stop working if human voices haven't occurred for about 5 seconds. In my case, what I want to transfer is audios of interviews, which would often contain some advertisements or music in the middle of it, and when this happens, the speech-to-text would only transfer the first half of the whole audio, and report an error that &quot;No speech could be recognized&quot;.  <br \/>\nIn this case, how can I extend the waiting time of that in order to transfer the whole file in Python codes?  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1649087644937,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=00357ba6-6a38-41a9-b332-d623f51e682e\">@Muyao Hu  <\/a>     <\/p>\n<p>I think there are two solutions you can have a try in Python SDK:     <\/p>\n<ol>\n<li> There is a 'set_property' method on the config to allow you to set parameters to your request, which can change the default silence time:: <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertycollection?view=azure-python#azure-cognitiveservices-speech-propertycollection-set-property\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertycollection?view=azure-python#azure-cognitiveservices-speech-propertycollection-set-property<\/a>    <\/li>\n<li> This way you can set the EndSilenceTimeout (PropertyIDs in Pyhton: <a href=\"https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertyid?view=azure-python#fields\">https:\/\/learn.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertyid?view=azure-python#fields<\/a>)    <\/li>\n<\/ol>\n<p>Please notice, the time is as &quot;ms&quot;. Hope above helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks!<\/em>    <\/p>\n",
        "Answer_comment_count":4.0,
        "Question_closed_time":1649205144236,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/799565\/how-do-i-extend-the-waiting-time-of-azure-speech-t",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"extend wait time azur speech text api python speech text transfer audio file text function stop work human voic haven occur second case want transfer audio interview contain advertis music middl happen speech text transfer half audio report error speech recogn case extend wait time order transfer file python code",
        "Question_preprocessed_content":"extend wait time azur api python transfer audio file text function stop work human voic haven second case want transfer audio interview contain advertis music transfer half audio report recogn case extend wait time order transfer file python code",
        "Question_gpt_summary_original":"The user is facing an issue with the Azure speech-to-text API in Python where the function stops working if there is no human voice for about 5 seconds. This is causing an error when trying to transcribe audio files that contain advertisements or music. The user is seeking a solution to extend the waiting time in order to transcribe the entire audio file.",
        "Question_gpt_summary":"user face issu azur speech text api python function stop work human voic second caus error try transcrib audio file contain advertis music user seek solut extend wait time order transcrib entir audio file"
    },
    {
        "Question_title":"How to fix ModuleNotFoundError in azureml-sdk when installed inside conda environment",
        "Question_body":"<p>I'm setting up a conda environment on Windows 10 Pro x64 using Miniconda 4.5.12 and have done a pip install of azureml-sdk inside the environment but get a ModuleNotFoundError when attempting to execute the following code:<\/p>\n\n<pre><code>import azureml.core\nazureml.core.VERSION\n<\/code><\/pre>\n\n<p>This is the output:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"azureml.py\", line 1, in &lt;module&gt;\n    import azureml.core\n  File \"D:\\Projects\\style-transfer\\azureml.py\", line 1, in &lt;module&gt;\n    import azureml.core\nModuleNotFoundError: No module named 'azureml.core'; 'azureml' is not a package\n<\/code><\/pre>\n\n<p>The code above has been run from the conda prompt, with the test environment active as well as in vscode with the same environment selected.<\/p>\n\n<p>I setup the conda environment as per the following:<\/p>\n\n<ol>\n<li>Created the conda environment <code>conda create -n test<\/code>.<\/li>\n<li>Activated the environment <code>activate test<\/code>.<\/li>\n<li>Installed pip <code>conda install pip<\/code>.<\/li>\n<li>Installed azureml-sdk <code>pip install azureml-sdk<\/code>.<\/li>\n<\/ol>\n\n<p>This results in the following packages being installed in the environment as per <code>conda list<\/code>:<\/p>\n\n<pre><code>adal                      1.2.0                     &lt;pip&gt;\nantlr4-python3-runtime    4.7.2                     &lt;pip&gt;\napplicationinsights       0.11.7                    &lt;pip&gt;\nargcomplete               1.9.4                     &lt;pip&gt;\nasn1crypto                0.24.0                    &lt;pip&gt;\nazure-cli-command-modules-nspkg 2.0.2                     &lt;pip&gt;\nazure-cli-core            2.0.54                    &lt;pip&gt;\nazure-cli-nspkg           3.0.3                     &lt;pip&gt;\nazure-cli-profile         2.1.2                     &lt;pip&gt;\nazure-cli-telemetry       1.0.0                     &lt;pip&gt;\nazure-common              1.1.16                    &lt;pip&gt;\nazure-graphrbac           0.53.0                    &lt;pip&gt;\nazure-mgmt-authorization  0.51.1                    &lt;pip&gt;\nazure-mgmt-containerregistry 2.5.0                     &lt;pip&gt;\nazure-mgmt-keyvault       1.1.0                     &lt;pip&gt;\nazure-mgmt-nspkg          3.0.2                     &lt;pip&gt;\nazure-mgmt-resource       2.0.0                     &lt;pip&gt;\nazure-mgmt-storage        3.1.0                     &lt;pip&gt;\nazure-nspkg               3.0.2                     &lt;pip&gt;\nazure-storage-blob        1.4.0                     &lt;pip&gt;\nazure-storage-common      1.4.0                     &lt;pip&gt;\nazure-storage-nspkg       3.1.0                     &lt;pip&gt;\nazureml-core              1.0.6                     &lt;pip&gt;\nazureml-pipeline          1.0.6                     &lt;pip&gt;\nazureml-pipeline-core     1.0.6                     &lt;pip&gt;\nazureml-pipeline-steps    1.0.6                     &lt;pip&gt;\nazureml-sdk               1.0.6                     &lt;pip&gt;\nazureml-telemetry         1.0.6                     &lt;pip&gt;\nazureml-train             1.0.6                     &lt;pip&gt;\nazureml-train-core        1.0.6                     &lt;pip&gt;\nazureml-train-restclients-hyperdrive 1.0.6                     &lt;pip&gt;\nbackports.tempfile        1.0                       &lt;pip&gt;\nbackports.weakref         1.0.post1                 &lt;pip&gt;\nbcrypt                    3.1.5                     &lt;pip&gt;\nca-certificates           2018.03.07                    0\ncertifi                   2018.11.29               py37_0\ncffi                      1.11.5                    &lt;pip&gt;\nchardet                   3.0.4                     &lt;pip&gt;\ncolorama                  0.4.1                     &lt;pip&gt;\ncontextlib2               0.5.5                     &lt;pip&gt;\ncryptography              2.4.2                     &lt;pip&gt;\ndocker                    3.6.0                     &lt;pip&gt;\ndocker-pycreds            0.4.0                     &lt;pip&gt;\nfutures                   3.1.1                     &lt;pip&gt;\nhumanfriendly             4.17                      &lt;pip&gt;\nidna                      2.8                       &lt;pip&gt;\nisodate                   0.6.0                     &lt;pip&gt;\njmespath                  0.9.3                     &lt;pip&gt;\njsonpickle                1.0                       &lt;pip&gt;\nknack                     0.5.1                     &lt;pip&gt;\nmsrest                    0.6.2                     &lt;pip&gt;\nmsrestazure               0.6.0                     &lt;pip&gt;\nndg-httpsclient           0.5.1                     &lt;pip&gt;\noauthlib                  2.1.0                     &lt;pip&gt;\nopenssl                   1.1.1a               he774522_0\nparamiko                  2.4.2                     &lt;pip&gt;\npathspec                  0.5.9                     &lt;pip&gt;\npip                       18.1                     py37_0\nportalocker               1.2.1                     &lt;pip&gt;\npyasn1                    0.4.4                     &lt;pip&gt;\npycparser                 2.19                      &lt;pip&gt;\nPygments                  2.3.1                     &lt;pip&gt;\nPyJWT                     1.7.1                     &lt;pip&gt;\nPyNaCl                    1.3.0                     &lt;pip&gt;\npyOpenSSL                 18.0.0                    &lt;pip&gt;\npypiwin32                 223                       &lt;pip&gt;\npyreadline                2.1                       &lt;pip&gt;\npython                    3.7.1                h8c8aaf0_6\npython-dateutil           2.7.5                     &lt;pip&gt;\npytz                      2018.7                    &lt;pip&gt;\npywin32                   224                       &lt;pip&gt;\nPyYAML                    3.13                      &lt;pip&gt;\nrequests                  2.21.0                    &lt;pip&gt;\nrequests-oauthlib         1.0.0                     &lt;pip&gt;\nruamel.yaml               0.15.51                   &lt;pip&gt;\nSecretStorage             2.3.1                     &lt;pip&gt;\nsetuptools                40.6.3                   py37_0\nsix                       1.12.0                    &lt;pip&gt;\nsqlite                    3.26.0               he774522_0\ntabulate                  0.8.2                     &lt;pip&gt;\nurllib3                   1.23                      &lt;pip&gt;\nvc                        14.1                 h0510ff6_4\nvs2015_runtime            14.15.26706          h3a45250_0\nwebsocket-client          0.54.0                    &lt;pip&gt;\nwheel                     0.32.3                   py37_0\nwheel                     0.30.0                    &lt;pip&gt;\nwincertstore              0.2                      py37_0\n<\/code><\/pre>\n\n<p>If I run <code>which pip<\/code>, I get the following output, which confirms that I used the pip inside the environment to install azureml-sdk, I think:<\/p>\n\n<pre><code>\/c\/Users\/allan\/Miniconda3\/envs\/test\/Scripts\/pip\n<\/code><\/pre>\n\n<p>I can also see that the azureml packages do in fact exist within the environment folder structure.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1545617082117,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":6343.0,
        "Poster_created_time":1460456204196,
        "Poster_location":"Australia",
        "Poster_reputation_count":140.0,
        "Poster_view_count":10.0,
        "Answer_body":"<p>It's probably because the name if your python file is the same as a module name you are trying import. In this case, rename the file to something other than <code>azureml.py<\/code>.<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1545633498167,
        "Answer_last_edit_time":null,
        "Answer_score_count":3.0,
        "Answerer_created_time":1401187183867,
        "Answerer_location":"Sweden",
        "Answerer_reputation_count":1709.0,
        "Answerer_view_count":112.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53908529",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"fix modulenotfounderror sdk instal insid conda environ set conda environ window pro miniconda pip instal sdk insid environ modulenotfounderror attempt execut follow code import core core version output traceback recent file line import core file project style transfer line import core modulenotfounderror modul name core packag code run conda prompt test environ activ vscode environ select setup conda environ follow creat conda environ conda creat test activ environ activ test instal pip conda instal pip instal sdk pip instal sdk result follow packag instal environ conda list adal antlr python runtim applicationinsight argcomplet asncrypto azur cli command modul nspkg azur cli core azur cli nspkg azur cli profil azur cli telemetri azur common azur graphrbac azur mgmt author azur mgmt containerregistri azur mgmt keyvault azur mgmt nspkg azur mgmt resourc azur mgmt storag azur nspkg azur storag blob azur storag common azur storag nspkg core pipelin pipelin core pipelin step sdk telemetri train train core train restclient hyperdr backport tempfil backport weakref post bcrypt certif certifi cffi chardet colorama contextlib cryptographi docker docker pycr futur humanfriendli idna isod jmespath jsonpickl knack msrest msrestazur ndg httpsclient oauthlib openssl paramiko pathspec pip portalock pyasn pycpars pygment pyjwt pynacl pyopenssl pypiwin pyreadlin python hcaaf python dateutil pytz pywin pyyaml request request oauthlib ruamel yaml secretstorag setuptool sqlite tabul urllib hff runtim websocket client wheel wheel wincertstor run pip follow output confirm pip insid environ instal sdk think user allan miniconda env test script pip packag fact exist environ folder structur",
        "Question_preprocessed_content":"fix sdk insid conda environ conda environ window pro miniconda pip sdk insid environ execut code output code run conda prompt test environ activ vscode environ select setup conda environ creat conda environ activ environ pip sdk result packag environ run output confirm pip insid environ sdk think packag fact exist environ folder structur",
        "Question_gpt_summary_original":"The user has installed azureml-sdk inside a conda environment on Windows 10 Pro x64 using Miniconda 4.5.12. However, when attempting to execute the code, the user gets a ModuleNotFoundError. The user has installed pip, azureml-sdk, and other packages inside the environment, and the azureml packages do exist within the environment folder structure.",
        "Question_gpt_summary":"user instal sdk insid conda environ window pro miniconda attempt execut code user get modulenotfounderror user instal pip sdk packag insid environ packag exist environ folder structur"
    },
    {
        "Question_title":"Best practice to store data artifacts",
        "Question_body":"<p>What\u2019s best practice for storing data artifacts? Currently we store them as csvs but I was wondering if pickling them makes more sense or if anyone has any experience with the pros and cons of doing that.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1666766069132,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":299.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/best-practice-to-store-data-artifacts\/3326",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"best practic store data artifact what best practic store data artifact current store csv wonder pickl make sens experi pro con",
        "Question_preprocessed_content":"best practic store data artifact what best practic store data artifact store csv wonder pickl make sens experi pro con",
        "Question_gpt_summary_original":"The user is seeking advice on the best practice for storing data artifacts and is considering whether to store them as csvs or to pickle them. They are looking for information on the pros and cons of each method.",
        "Question_gpt_summary":"user seek advic best practic store data artifact consid store csv pickl look inform pro con method"
    },
    {
        "Question_title":"Keras Custom Data Generator - Stuck on First Epoch, No Output?",
        "Question_body":"<p>I've been trying to get a multi-input data generator to work in Keras for a muti-input model. The inputs are in the form of an image and an associated number.<\/p>\n<p>I've tried two different custom data generators, but the simpler one merely uses ImageDataGenerator and flowfromdataframe with two outputs. Later on, I switch one of the outputs into an input and feed it into the model. The relevant code is as follows, where y_col is the output, number_col is the associated number and path_col is the path to the images:<\/p>\n<pre><code># data generator\ndf_gen = img_data_gen.flow_from_dataframe(\n        **all_args,\n        x_col=path_col,\n        y_col=[y_col, number_col],\n        shuffle=False,\n        class_mode='raw')\n\n  \n\n\n# sending data to model, wrapped in a larger function\nwhile True:\n    data_batch = next(df_gen)\n\n    #fake data, works in the model perfectly\n    number_labels = np.random.randint(1,219,len(data_batch[1]))\n  \n    outputdata, numberdata = data_batch[1].T\n    outputdata = np.asarray(outputdata).astype('float32')\n\n    #this code never works, the model freezes\n    numberdata = np.asarray(numberdata).astype(np.int32)\n  \n    yield [numberdata, data_batch[0]], outputdata\n\n#fitting the model\nhistory = model.fit(\n            train_generator,\n            steps_per_epoch=int(len(train_df) \/ batch_size),\n            validation_data=val_generator,\n            validation_steps=int(len(validation_df) \/ batch_size),\n            epochs=epochs,\n            callbacks=callbacks,\n            verbose = 1\n        )\n<\/code><\/pre>\n<p><strong>When I run this model, the output freezes at 'Epoch 1\/12'.<\/strong> I've checked that the data is in the right format, the right length, and matching properly to the other input.<\/p>\n<p>When I generate a random list of numbers, the model runs perfectly. I can also see that when fake data is generated, the number data is also getting generated.<\/p>\n<p>However, when I use the correct number data as an input into the model, the model <strong>freezes at the second 'next' call.<\/strong> I can also use a smaller sub-dataset with the same data structure and the model runs correctly. But when I use the entire dataset, the problem occurs again.<\/p>\n<p><strong>Do you know what could be causing this problem?<\/strong> I'm using AWS Sagemaker to run the model and can't seem to figure out where this problem is coming from. Thank you for your help!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1629139040917,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":248.0,
        "Poster_created_time":1629137397396,
        "Poster_location":null,
        "Poster_reputation_count":21.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68807732",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"kera custom data gener stuck epoch output try multi input data gener work kera muti input model input form imag associ number tri differ custom data gener simpler mere us imagedatagener flowfromdatafram output later switch output input feed model relev code follow col output number col associ number path col path imag data gener gen img data gen flow datafram arg col path col col col number col shuffl fals class mode raw send data model wrap larger function true data batch gen fake data work model perfectli number label random randint len data batch outputdata numberdata data batch outputdata asarrai outputdata astyp float code work model freez numberdata asarrai numberdata astyp int yield numberdata data batch outputdata fit model histori model fit train gener step epoch int len train batch size valid data val gener valid step int len valid batch size epoch epoch callback callback verbos run model output freez epoch check data right format right length match properli input gener random list number model run perfectli fake data gener number data get gener us correct number data input model model freez second us smaller sub dataset data structur model run correctli us entir dataset problem occur know caus problem run model figur problem come thank help",
        "Question_preprocessed_content":"kera custom data gener stuck epoch output try data gener work kera model input form imag number tri custom data gener simpler mere us imagedatagener flowfromdatafram output later switch output input model relev code output number path imag run model output epoch check data right format right length match properli input gener random list number model run perfectli fake data gener number data gener us number data input model model second us data structur model run us entir dataset problem know caus problem run model figur problem come thank help",
        "Question_gpt_summary_original":"The user is facing issues with a custom data generator in Keras for a multi-input model. The model freezes at the second 'next' call when the correct number data is used as input. The user has tried two different custom data generators, and the simpler one uses ImageDataGenerator and flowfromdataframe with two outputs. The user is seeking help to identify the cause of the problem.",
        "Question_gpt_summary":"user face issu custom data gener kera multi input model model freez second correct number data input user tri differ custom data gener simpler us imagedatagener flowfromdatafram output user seek help identifi caus problem"
    },
    {
        "Question_title":"How to increase the number of parameters logged in MLFlow (current max limit is 100)",
        "Question_body":"<p>I'm using AzureML to train some networks and the recommended MLFlow to log parameters and metrics.  <br \/>\nHowever, I have reached the maximum limit of 100 parameters (mostly configuration options I pass to the trainer but also real model parameters). And I get the following error:  <\/p>\n<blockquote>\n<p>mlflow.exceptions.RestException: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'A field of the entity is over the size limit. <strong>FieldName=Parameters, Limit=100, Size=101<\/strong>. See <a href=\"https:\/\/aka.ms\/azure-machine-learning-limits\">https:\/\/aka.ms\/azure-machine-learning-limits<\/a> for service limits documentation.', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': 'a9544317f5dd99458be006824948b38d', 'request': '0b131227514b3b4b'}, 'Environment': 'eastus', 'Location': 'eastus', 'ComponentName': 'mlflow', 'error_code': 'BAD_REQUEST'}  <\/p>\n<\/blockquote>\n<p>Is there a way to increase this limit? If not, are there any other workarounds?  <\/p>\n<p>Thank you!  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1623455284870,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/433155\/how-to-increase-the-number-of-parameters-logged-in",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"increas number paramet log current max limit train network recommend log paramet metric reach maximum limit paramet configur option pass trainer real model paramet follow error except restexcept bad request respons error code usererror sever messag field entiti size limit fieldnam paramet limit size http aka azur machin learn limit servic limit document messageformat messageparamet referencecod detailsuri target detail innererror debuginfo additionalinfo correl oper afddbebd request bbbb environ eastu locat eastu componentnam error code bad request wai increas limit workaround thank",
        "Question_preprocessed_content":"increas number paramet train network log paramet metric reach maximum limit paramet respons environ eastu locat eastu componentnam wai increas limit workaround thank",
        "Question_gpt_summary_original":"The user is facing an issue with MLFlow where they have reached the maximum limit of 100 parameters that can be logged. This is causing an error and the user is seeking a way to increase this limit or find a workaround.",
        "Question_gpt_summary":"user face issu reach maximum limit paramet log caus error user seek wai increas limit workaround"
    },
    {
        "Question_title":"MLflow 1.28.0 released!",
        "Question_body":"Hi all,\n\nWe are happy to announce the availability of\u00a0MLflow\u00a01.28.0\u00a0!\n\n\nMLflow\u00a01.28.0 includes several major features and improvements:\n\nFeatures:\n\n[Pipelines] Log the full Pipeline runtime configuration to MLflow Tracking during Pipeline execution (#6359,\u00a0@jinzhang21)\n[Pipelines] Add\u00a0pipeline.yaml\u00a0configurations to specify the Model Registry backend used for model registration (#6284,\u00a0@sunishsheth2009)\n[Pipelines] Support optionally skipping the\u00a0transform\u00a0step of the scikit-learn regression pipeline (#6362,\u00a0@sunishsheth2009)\n[Pipelines] Add UI links to Runs and Models in Pipeline Step Cards on Databricks (#6294,\u00a0@dbczumar)\n[Tracking] Introduce\u00a0mlflow.search_experiments()\u00a0API for searching experiments by name and by tags (#6333,\u00a0@WeichenXu123;\u00a0#6227,\u00a0#6172,\u00a0#6154,\u00a0@harupy)\n[Tracking] Increase the maximum parameter value length supported by File and SQL backends to 500 characters (#6358,\u00a0@johnyNJ)\n[Tracking] Introduce an\u00a0--older-than\u00a0flag to\u00a0mlflow gc\u00a0for removing runs based on deletion time (#6354,\u00a0@Jason-CKY)\n[Tracking] Add\u00a0MLFLOW_SQLALCHEMYSTORE_POOL_RECYCLE\u00a0environment variable for recycling SQLAlchemy connections (#6344,\u00a0@postrational)\n[UI] Display deeply nested runs in the Runs Table on the Experiment Page (#6065,\u00a0@tospe)\n[UI] Add box plot visualization for metrics to the Compare Runs page (#6308,\u00a0@ahlag)\n[UI] Display tags on the Compare Runs page (#6164,\u00a0@CaioCavalcanti)\n[UI] Use scientific notation for axes when viewing metric plots in log scale (#6176,\u00a0@RajezMariner)\n[UI] Add button to Metrics page for downloading metrics as CSV (#6048,\u00a0@rafaelvp-db)\n[UI] Include NaN and +\/- infinity values in plots on the Metrics page (#6422,\u00a0@hubertzub-db)\n[Tracking \/ Model Registry] Introduce environment variables to control retry behavior and timeouts for REST API requests (#5745,\u00a0@peterdhansen)\n[Tracking \/ Model Registry] Make\u00a0MlflowClient\u00a0importable as\u00a0mlflow.MlflowClient\u00a0(#6085,\u00a0@subramaniam02)\n[Model Registry] Add support for searching registered models and model versions by tags (#6413,\u00a0#6411,\u00a0#6320,\u00a0@WeichenXu123)\n[Model Registry] Add\u00a0stage\u00a0parameter to\u00a0set_model_version_tag()\u00a0(#6185,\u00a0@subramaniam02)\n[Model Registry] Add\u00a0--registry-store-uri\u00a0flag to\u00a0mlflow server\u00a0for specifying the Model Registry backend URI (#6142,\u00a0@Secbone)\n[Models] Improve performance of Spark Model logging on Databricks (#6282,\u00a0@bbarnes52)\n[Models] Include Pandas Series names in inferred model schemas (#6361,\u00a0@RynoXLI)\n[Scoring] Make\u00a0model_uri\u00a0optional in\u00a0mlflow models build-docker\u00a0to support building generic model serving images (#6302,\u00a0@harupy)\n[R] Support logging of NA and NaN parameter values (#6263,\u00a0@nathaneastwood)\n\nBug fixes and documentation updates:\n\n[Pipelines] Improve scikit-learn regression pipeline latency by limiting dataset profiling to the first 100 columns (#6297,\u00a0@sunishsheth2009)\n[Pipelines] Use\u00a0xdg-open\u00a0instead of\u00a0open\u00a0for viewing Pipeline results on Linux systems (#6326,\u00a0@strangiato)\n[Pipelines] Fix a bug that skipped Step Card rendering in Jupyter Notebooks (#6378,\u00a0@apurva-koti)\n[Tracking] Use the 401 HTTP response code in authorization failure REST API responses, instead of 500 (#6106,\u00a0@balvisio)\n[Tracking] Correctly classify artifacts as files and directories when using Azure Blob Storage (#6237,\u00a0@nerdinand)\n[Tracking] Fix a bug in the File backend that caused run metadata to be lost in the event of a failed write (#6388,\u00a0@dbczumar)\n[Tracking] Adjust\u00a0mlflow.pyspark.ml.autolog()\u00a0to only log model signatures for supported input \/ output data types (#6365,\u00a0@harupy)\n[Tracking] Adjust\u00a0mlflow.tensorflow.autolog()\u00a0to log TensorFlow early stopping callback info when\u00a0log_models=False\u00a0is specified (#6170,\u00a0@WeichenXu123)\n[Tracking] Fix signature and input example logging errors in\u00a0mlflow.sklearn.autolog()\u00a0for models containing transformers (#6230,\u00a0@dbczumar)\n[Tracking] Fix a failure in\u00a0mlflow gc\u00a0that occurred when removing a run whose artifacts had been previously deleted (#6165,\u00a0@dbczumar)\n[Tracking] Add missing\u00a0sqlparse\u00a0library to MLflow Skinny client, which is required for search support (#6174,\u00a0@dbczumar)\n[Tracking \/ Model Registry] Fix an\u00a0mlflow server\u00a0bug that rejected parameters and tags with empty string values (#6179,\u00a0@dbczumar)\n[Model Registry] Fix a failure preventing model version schemas from being downloaded with\u00a0--serve-arifacts\u00a0enabled (#6355,\u00a0@abbas123456)\n[Scoring] Patch the Java Model Server to support MLflow Models logged on recent versions of the Databricks Runtime (#6337,\u00a0@dbczumar)\n[Scoring] Verify that either the deployment name or endpoint is specified when invoking the\u00a0mlflow deployments predict\u00a0CLI (#6323,\u00a0@dbczumar)\n[Scoring] Properly encode datetime columns when performing batch inference with\u00a0mlflow.pyfunc.spark_udf()\u00a0(#6244,\u00a0@harupy)\n[Projects] Fix an issue where local directory paths were misclassified as Git URIs when running Projects (#6218,\u00a0@ElefHead)\n[R] Fix metric logging behavior for +\/- infinity values (#6271,\u00a0@nathaneastwood)\n[Docs] Move Python API docs for\u00a0MlflowClient\u00a0from\u00a0mlflow.tracking\u00a0to\u00a0mlflow.client\u00a0(#6405,\u00a0@dbczumar)\n[Docs] Document that MLflow Pipelines requires Make (#6216,\u00a0@dbczumar)\n[Docs] Improve documentation for developing and testing MLflow JS changes in\u00a0CONTRIBUTING.rst\u00a0(#6330,\u00a0@ahlag)\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1660199398000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":42.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/2BtF8qwt0Zc",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"releas happi announc avail includ major featur improv featur pipelin log pipelin runtim configur track pipelin execut jinzhang pipelin addpipelin yamlconfigur specifi model registri backend model registr sunishsheth pipelin support option skip thetransformstep scikit learn regress pipelin sunishsheth pipelin add link run model pipelin step card databrick dbczumar track introduc search experi api search experi tag weichenxu harupi track increas maximum paramet valu length support file sql backend charact johnynj track introduc older thanflag gcfor remov run base delet time jason cky track add sqlalchemystor pool recycleenviron variabl recycl sqlalchemi connect postrat displai deepli nest run run tabl experi page tosp add box plot visual metric compar run page ahlag displai tag compar run page caiocavalcanti us scientif notat ax view metric plot log scale rajezmarin add button metric page download metric csv rafaelvp includ nan infin valu plot metric page hubertzub track model registri introduc environ variabl control retri behavior timeout rest api request peterdhansen track model registri makeclientimport client subramaniam model registri add support search regist model model version tag weichenxu model registri addstageparamet toset model version tag subramaniam model registri add registri store uriflag serverfor specifi model registri backend uri secbon model improv perform spark model log databrick bbarn model includ panda seri name infer model schema rynoxli score makemodel uriopt model build dockerto support build gener model serv imag harupi support log nan paramet valu nathaneastwood bug fix document updat pipelin improv scikit learn regress pipelin latenc limit dataset profil column sunishsheth pipelin usexdg openinstead ofopenfor view pipelin result linux system strangiato pipelin fix bug skip step card render jupyt notebook apurva koti track us http respons code author failur rest api respons instead balvisio track correctli classifi artifact file directori azur blob storag nerdinand track fix bug file backend caus run metadata lost event fail write dbczumar track adjust pyspark autolog log model signatur support input output data type harupi track adjust tensorflow autolog log tensorflow earli stop callback info whenlog model falsei specifi weichenxu track fix signatur input exampl log error sklearn autolog model contain transform dbczumar track fix failur gcthat occur remov run artifact previous delet dbczumar track add missingsqlparselibrari skinni client requir search support dbczumar track model registri fix serverbug reject paramet tag string valu dbczumar model registri fix failur prevent model version schema download serv arifactsen abba score patch java model server support model log recent version databrick runtim dbczumar score verifi deploy endpoint specifi invok deploy predictcli dbczumar score properli encod datetim column perform batch infer pyfunc spark udf harupi project fix issu local directori path misclassifi git uri run project elefhead fix metric log behavior infin valu nathaneastwood doc python api doc forclientfrom trackingto client dbczumar doc document pipelin requir dbczumar doc improv document develop test chang incontribut rst ahlag comprehens list chang thereleas chang log check latest document org",
        "Question_preprocessed_content":"releas avail includ major featur improv featur pipelin log pipelin runtim configur track pipelin execut pipelin yamlconfigur specifi model registri backend model registr pipelin thetransformstep pipelin pipelin link run model pipelin step card databrick track search experi tag track increas maximum paramet valu length file sql backend charact track introduc gcfor remov run base delet time track variabl recycl sqlalchemi displai nest run run tabl experi page box plot visual metric compar run page displai tag compar run page us scientif notat ax view metric plot log scale metric page download metric csv includ nan infin valu plot metric page track model registri introduc environ variabl control retri behavior timeout rest api request track model registri makeclientimport model registri search regist model model version tag model registri model registri serverfor specifi model registri backend uri model improv perform spark model databrick model includ panda seri name model schema score model build gener model serv imag nan paramet valu bug fix document updat pipelin improv pipelin latenc limit dataset profil column pipelin ofopenfor view pipelin result linux system pipelin fix bug step card render jupyt track us respons code author failur rest api respons instead track artifact file directori azur blob storag track fix bug file backend caus run metadata lost event fail write track log model signatur input output data type track log tensorflow earli info specifi track fix signatur input exampl model contain transform track fix failur gcthat remov run artifact previous delet track client requir search track model registri fix serverbug reject paramet tag string valu model registri fix failur prevent model version schema download score patch java model server model recent version databrick runtim score verifi deploy endpoint specifi invok deploy predictcli score properli encod datetim column perform batch infer project fix local directori path git uri project fix metric behavior infin valu doc python api doc doc document pipelin requir doc improv document develop test chang comprehens list chang thereleas chang log check latest document",
        "Question_gpt_summary_original":"MLflow 1.28.0 has been released with several major features and improvements, including the ability to log the full Pipeline runtime configuration to MLflow Tracking during Pipeline execution, support for searching registered models and model versions by tags, and improvements to the UI. The release also includes bug fixes and documentation updates.",
        "Question_gpt_summary":"releas major featur improv includ abil log pipelin runtim configur track pipelin execut support search regist model model version tag improv releas includ bug fix document updat"
    },
    {
        "Question_title":"SageMaker create PyTorchModel without deploying",
        "Question_body":"<p>If I instantiate a SageMaker <code>PyTorchModel<\/code> object like this:<\/p>\n\n<pre><code>from sagemaker.pytorch import PyTorchModel\n\nmodel = PyTorchModel(name=name_from_base('model-name'),\n                     model_data=model_data,\n                     role=role,\n                     framework_version='1.0.0',\n                     entry_point='serve.py',\n                     source_dir='src',\n                     sagemaker_session=sagemaker_session,\n                     predictor_cls=ImagePredictor)\n\n#model.create_without_deploying??\n<\/code><\/pre>\n\n<p>Is there a way that I can create this model using the sagemaker python SDK so that the model shows up in the SageMaker console, but <em>without<\/em> actually deploying it to an endpoint?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1559938343560,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1559938910380,
        "Question_score_count":2.0,
        "Question_view_count":434.0,
        "Poster_created_time":1361339272692,
        "Poster_location":"NYC",
        "Poster_reputation_count":6281.0,
        "Poster_view_count":958.0,
        "Answer_body":"<p>I don't think it is possible to do so using the high-level SageMaker Pyhton SDK. However, you should be able to do it by calling the CreateModel API using the low-level boto3 <a href=\"https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_model\" rel=\"nofollow noreferrer\">https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_model<\/a>. For your reference, below is an example snippet code on how to do it.<\/p>\n\n<pre><code>%%time\nimport boto3\nimport time\n\nsage = boto3.Session().client(service_name='sagemaker')\n\nimage_uri = '520713654638.dkr.ecr.us-east-1.amazonaws.com\/sagemaker-pytorch:1.0.0-cpu-py3'\nmodel_data ='s3:\/\/&lt;bucket&gt;\/&lt;prefix&gt;\/output\/model.tar.gz'\nsource = 's3:\/\/&lt;bucket&gt;\/&lt;prefix&gt;\/sourcedir.tar.gz'\nrole = 'arn:aws:iam::xxxxxxxx:role\/service-role\/AmazonSageMaker-ExecutionRole-xxxxxx'\n\ntimestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\nmodel_name = 'my-pytorch-model' + timestamp\n\nresponse = sage.create_model(\n    ModelName=model_name,\n    PrimaryContainer={\n        'Image': image_uri,\n        'ModelDataUrl': model_data,\n        'Environment': { 'SAGEMAKER_CONTAINER_LOG_LEVEL':'20', 'SAGEMAKER_ENABLE_CLOUDWATCH_METRICS': 'False', \n                   'SAGEMAKER_PROGRAM': 'generate.py','SAGEMAKER_REGION': 'us-east-1','SAGEMAKER_SUBMIT_DIRECTORY': source}\n         },\n         ExecutionRoleArn=role\n}\nprint(response)\n<\/code><\/pre>\n\n<p>If you get no error message, then the model will shows up in the SageMaker console<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1561626837347,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1395737095150,
        "Answerer_location":null,
        "Answerer_reputation_count":81.0,
        "Answerer_view_count":18.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56500704",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat pytorchmodel deploi instanti pytorchmodel object like pytorch import pytorchmodel model pytorchmodel base model model data model data role role framework version entri point serv sourc dir src session session predictor cl imagepredictor model creat deploi wai creat model python sdk model show consol actual deploi endpoint",
        "Question_preprocessed_content":"creat pytorchmodel deploi instanti object like wai creat model python sdk model show consol deploi endpoint",
        "Question_gpt_summary_original":"The user is trying to create a SageMaker PyTorchModel object using the sagemaker python SDK, but wants to know if there is a way to create the model without deploying it to an endpoint, while still having it show up in the SageMaker console.",
        "Question_gpt_summary":"user try creat pytorchmodel object python sdk want know wai creat model deploi endpoint have consol"
    },
    {
        "Question_title":"AWS Sagemaker Kernel appears to have died and restarts",
        "Question_body":"<p>I am getting a kernel error while trying to retrieve the data from an API that includes 100 pages. The data size is huge but the code runs well when executed on Google Colab or on local machine.<\/p>\n\n<p>The error I see in a window is-<\/p>\n\n<p><strong>Kernel Restarting\nThe kernel appears to have died. It will restart automatically.<\/strong><\/p>\n\n<p>I am using an ml.m5.xlarge machine with a memory allocation of 1000GB and there are no pre-saved datasets in the instance. Also, the expected data size is around 60 GB split into multiple datasets of 4 GB each.<\/p>\n\n<p>Can anyone help?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1584774759840,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":1026.0,
        "Poster_created_time":1570163855220,
        "Poster_location":"Mumbai, Maharashtra, India",
        "Poster_reputation_count":11.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60785324",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"kernel appear di restart get kernel error try retriev data api includ page data size huge code run execut googl colab local machin error window kernel restart kernel appear di restart automat xlarg machin memori alloc pre save dataset instanc expect data size split multipl dataset help",
        "Question_preprocessed_content":"kernel di restart kernel try retriev data api includ page data size huge code run execut colab local machin window kernel restart kernel di restart machin memori dataset instanc expect data size split multipl dataset help",
        "Question_gpt_summary_original":"The user is encountering a kernel error while trying to retrieve data from an API that includes 100 pages. The error message states that the kernel appears to have died and will restart automatically. The user is using an ml.m5.xlarge machine with a memory allocation of 1000GB and there are no pre-saved datasets in the instance. The expected data size is around 60 GB split into multiple datasets of 4 GB each. The code runs well on Google Colab or on a local machine.",
        "Question_gpt_summary":"user encount kernel error try retriev data api includ page error messag state kernel appear di restart automat user xlarg machin memori alloc pre save dataset instanc expect data size split multipl dataset code run googl colab local machin"
    },
    {
        "Question_title":"Connecting to Azure SQL database from \"Execute R Script\" module in \"Azure Machine Learning Studio\"",
        "Question_body":"<p>I have already set up an <strong>Azure SQL Database<\/strong> and loaded results into it form my local machine via <strong>R (RODBC)<\/strong> successfully.  I can do queries in R Studio with no problem. <\/p>\n\n<p>However when I use the same code in <strong>Execute R script<\/strong> module in the  ML studio, I get an error that the connection is not open. <\/p>\n\n<p>What do I need to change? Have tried different strings for the driver with no avail.   <\/p>\n\n<p><em>The reason Reader or Import Data module is not working for my case is that I am creating an API that provides me with the information to query the database before doing analytics. The database is very big and I do not want to load whole table and then use project columns, etc.<\/em><\/p>\n\n<p>Any help is really appreciated<\/p>\n\n<p>Thanks all<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1463678195617,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1136.0,
        "Poster_created_time":1332513926592,
        "Poster_location":"Boston, MA, USA",
        "Poster_reputation_count":45.0,
        "Poster_view_count":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37329999",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect azur sql databas execut script modul studio set azur sql databas load result form local machin rodbc successfulli queri studio problem us code execut script modul studio error connect open need chang tri differ string driver avail reason reader import data modul work case creat api provid inform queri databas analyt databas big want load tabl us project column help appreci thank",
        "Question_preprocessed_content":"azur sql databas execut script modul studio set azur sql databas load result form local machin queri studio problem us code execut script modul studio open chang tri string driver avail reason reader import data modul work case creat api provid inform queri databas analyt databas big want load tabl us project column help thank",
        "Question_gpt_summary_original":"The user is facing challenges while trying to connect to an Azure SQL database from the \"Execute R Script\" module in \"Azure Machine Learning Studio\". The user has already successfully loaded results into the database using R (RODBC) from their local machine and can do queries in R Studio without any problem. However, when using the same code in the \"Execute R Script\" module, the user is getting an error that the connection is not open. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":"user face challeng try connect azur sql databas execut script modul studio user successfulli load result databas rodbc local machin queri studio problem code execut script modul user get error connect open user seek help resolv issu"
    },
    {
        "Question_title":"ValidationException Importing from Redshift into Data Wrangler",
        "Question_body":"<p>I'm trying to build a model workflow in AWS SageMaker using Data Wrangler for preprocessing. I'm loading data from various tables in a Redshift instance, before mutating and joining them as required to build the model input data.<\/p>\n<p>I'm a contractor working for a company who has provisioned some resource in their AWS environment for me to work, and am reading from a production database. If I do not load open the Data Wrangler flow early enough in the day (which I suspect is related to load on their system), some of the nodes which I have created will not validate, and instead show a red cross and the following error message:<\/p>\n<p><code>RedshiftQueryExecutionIdValidationError: An error occurred when trying to invoke `describe_statement`: An error occurred (ValidationException) when calling the DescribeStatement operation: Could not retrieve the query result as it has expired after 1655759552.<\/code><\/p>\n<p>The remaining un-errored nodes appear to hang in a loading\/validating state. Here's a screenshot of part of the flow in this state:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AewzK.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AewzK.png\" alt=\"An image showing some currently loading AWS Data Wrangler nodes, with some errored nodes joining in towards the end of the flow, rendering the end product errored and thus unusable\" \/><\/a><\/p>\n<p>I'm not sure if it's related, but I occasionally see error messages pop up saying something about &quot;too many inflight requests&quot;.<\/p>\n<p>My main issue, I think, is a lack of context. I have not worked in this environment before, and am finding it difficult to diagnose the issue. It might be possible to provision more resource, and I could likely trim down some of the information before reading it in, but I'd like to be able to read the error messages and understand what's <em>causing<\/em> the nodes to error, so that I can decide on the appropriate course of action.<\/p>\n<p>Can somebody please help explain what's going on here?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1655774625443,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":57.0,
        "Poster_created_time":1427947978892,
        "Poster_location":"Auckland, New Zealand",
        "Poster_reputation_count":25.0,
        "Poster_view_count":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72694415",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"validationexcept import redshift data wrangler try build model workflow data wrangler preprocess load data tabl redshift instanc mutat join requir build model input data contractor work compani provis resourc aw environ work read product databas load open data wrangler flow earli dai suspect relat load node creat valid instead red cross follow error messag redshiftqueryexecutionidvalidationerror error occur try invok statement error occur validationexcept call describestat oper retriev queri result expir remain error node appear hang load valid state screenshot flow state sure relat occasion error messag pop sai inflight request main issu think lack context work environ find difficult diagnos issu possibl provis resourc like trim inform read like abl read error messag understand caus node error decid appropri cours action somebodi help explain go",
        "Question_preprocessed_content":"validationexcept import redshift data wrangler try build model workflow data wrangler load data tabl redshift instanc mutat join requir build model input data contractor work compani provis resourc aw environ work read product databas load open data wrangler flow earli dai node creat valid instead red remain node hang state flow state sure relat pop sai inflight request main think lack context work environ find diagnos provis resourc like trim inform read like abl read understand caus node decid cours action somebodi help explain go",
        "Question_gpt_summary_original":"The user is encountering a ValidationException error while importing data from Redshift into Data Wrangler for preprocessing in AWS SageMaker. Some nodes are not validating and showing a red cross with an error message related to query result expiration. The un-errored nodes are hanging in a loading\/validating state, and the user occasionally sees error messages about too many inflight requests. The user is seeking help to understand the cause of the error messages and decide on the appropriate course of action.",
        "Question_gpt_summary":"user encount validationexcept error import data redshift data wrangler preprocess node valid show red cross error messag relat queri result expir error node hang load valid state user occasion see error messag inflight request user seek help understand caus error messag decid appropri cours action"
    },
    {
        "Question_title":"Understanding Intermediate Values and Pruning in Optuna",
        "Question_body":"<p>I am just curious for more information on what an intermediate step actually is and how to use pruning if you're using a different ml library that isn't in the tutorial section eg) XGB, Pytorch etc.<\/p>\n<p>For example:<\/p>\n<pre><code>X, y = load_iris(return_X_y=True)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y)\nclasses = np.unique(y)\nn_train_iter = 100\n\ndef objective(trial):\n    global num_pruned\n    alpha = trial.suggest_float(&quot;alpha&quot;, 0.0, 1.0)\n    clf = SGDClassifier(alpha=alpha)\n    for step in range(n_train_iter):\n        clf.partial_fit(X_train, y_train, classes=classes)\n\n        intermediate_value = clf.score(X_valid, y_valid)\n        trial.report(intermediate_value, step)\n\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n\n    return clf.score(X_valid, y_valid)\n\n\nstudy = optuna.create_study(\n    direction=&quot;maximize&quot;,\n    pruner=optuna.pruners.HyperbandPruner(\n        min_resource=1, max_resource=n_train_iter, reduction_factor=3\n    ),\n)\nstudy.optimize(objective, n_trials=30)\n<\/code><\/pre>\n<p>What is the point of the <code>for step in range()<\/code> section? Doesn't doing this just make the optimisation take more time and won't you yield the same result for every step in the loop?<\/p>\n<p>I'm really trying to figure out the need for <code>for step in range()<\/code> and is it required every time you wish to use pruning?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1637069214753,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":841.0,
        "Poster_created_time":1482279816096,
        "Poster_location":null,
        "Poster_reputation_count":138.0,
        "Poster_view_count":28.0,
        "Answer_body":"<p>The basic model creation can be done by passing a complete training datasets once. But there are models that can still be improved (an increase in accuracy) by re-training again on the same training datasets.<\/p>\n<p>To see to it that we are not wasting resources here, we would check the accuracy after every step using the validation datasets via <code>intermediate_score<\/code> if accuracy improves, if not we prune the whole trial skipping other steps. Then we go for next trial asking another value of alpha - the hyperparameter that we are trying to determine to have the greatest accuracy on the validation datasets.<\/p>\n<p>For other libraries, it is just a matter of asking ourselves what do we want with our model, accuracy for sure is a good criteria to measure the model's competency. There can be others.<\/p>\n<p>Example optuna pruning, I want the model to continue re-training but only at my specific conditions. If intermediate value cannot defeat my best_accuracy and if steps are already more than half of my max iteration then prune this trial.<\/p>\n<pre><code>best_accuracy = 0.0\n\n\ndef objective(trial):\n    global best_accuracy\n\n    alpha = trial.suggest_float(&quot;alpha&quot;, 0.0, 1.0)\n    clf = SGDClassifier(alpha=alpha)\n\n    for step in range(n_train_iter):\n        clf.partial_fit(X_train, y_train, classes=classes)\n\n        if step &gt; n_train_iter\/\/2:\n            intermediate_value = clf.score(X_valid, y_valid)\n\n            if intermediate_value &lt; best_accuracy:\n                raise optuna.TrialPruned()\n\n    best_accuracy = clf.score(X_valid, y_valid)\n\n    return best_accuracy\n<\/code><\/pre>\n<p>Optuna has specialized pruners at <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/pruners.html\" rel=\"nofollow noreferrer\">https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/pruners.html<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1637119128723,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1634692867416,
        "Answerer_location":"Philippines",
        "Answerer_reputation_count":3105.0,
        "Answerer_view_count":290.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69990009",
        "Tool":"Optuna",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"understand intermedi valu prune curiou inform intermedi step actual us prune differ librari isn tutori section xgb pytorch exampl load iri return true train valid train valid train test split class uniqu train iter def object trial global num prune alpha trial suggest float alpha clf sgdclassifi alpha alpha step rang train iter clf partial fit train train class class intermedi valu clf score valid valid trial report intermedi valu step trial prune rais trialprun return clf score valid valid studi creat studi direct maxim pruner pruner hyperbandprun min resourc max resourc train iter reduct factor studi optim object trial point step rang section optimis time won yield result step loop try figur need step rang requir time wish us prune",
        "Question_preprocessed_content":"understand intermedi valu prune curiou inform intermedi step us prune librari isn tutori section xgb pytorch exampl point section optimis time won yield result step try figur requir time wish us prune",
        "Question_gpt_summary_original":"The user is seeking clarification on intermediate values and pruning in Optuna. They are specifically curious about the purpose of the \"for step in range()\" section in the code and whether it is necessary for using pruning. They also want to know how to use pruning with ML libraries other than those in the tutorial section, such as XGB and Pytorch.",
        "Question_gpt_summary":"user seek clarif intermedi valu prune specif curiou purpos step rang section code necessari prune want know us prune librari tutori section xgb pytorch"
    },
    {
        "Question_title":"How to tune conditional objective function using optuna or hyperopt",
        "Question_body":"<p>I tried to use optuna to tune hyperparameters. But my objective function is conditional which creates issues in getting optimal parameters.<\/p>\n\n<p>i want to get cwc only if the condtion is met otherwise continue trial for next hyperparameters.\nBut i guess since the condition is not met and objective func reurns cwc it gives error<\/p>\n\n<p>UnboundLocalError: local variable 'cwc_train' referenced before assignment<\/p>\n\n<pre><code>define objective (trial):\n    k_dis = trial.suggest_uniform('k_dis', 0.0, 5.0)\n    l_dis = trial.suggest_uniform('l_dis', 0.0, 5.0)\n    k_bound = trial.suggest_uniform('k_bound', 0.0, 5.0)\n    l_bound = trial.suggest_uniform('l_bound', 0.0, 5.0) \n\n    picp = .....\n    pinrw = .....\n\n\n    if picp_train &gt;= 0.8 and pinrw_train &lt; 0.18: \n        cwc_train = fc.CWC_proposed(predict_bound_train, Y_train)\n    else:\n        print(\"error = \")\n    return  cwc_train\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=100)\n<\/code><\/pre>\n\n<p>UnboundLocalError: local variable 'cwc_train' referenced before assignment<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1564371554813,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1564379241136,
        "Question_score_count":1.0,
        "Question_view_count":814.0,
        "Poster_created_time":1564369929972,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57246939",
        "Tool":"Optuna",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tune condit object function hyperopt tri us tune hyperparamet object function condit creat issu get optim paramet want cwc condtion met continu trial hyperparamet guess condit met object func reurn cwc give error unboundlocalerror local variabl cwc train referenc assign defin object trial di trial suggest uniform di di trial suggest uniform di bound trial suggest uniform bound bound trial suggest uniform bound picp pinrw picp train pinrw train cwc train cwc propos predict bound train train print error return cwc train studi creat studi studi optim object trial unboundlocalerror local variabl cwc train referenc assign",
        "Question_preprocessed_content":"tune condit object function hyperopt tri us tune hyperparamet object function condit creat optim paramet want cwc condtion met continu trial hyperparamet condit met object func reurn cwc give local variabl referenc local variabl referenc",
        "Question_gpt_summary_original":"The user is trying to use optuna to tune hyperparameters for an objective function that is conditional. They want to get a specific value only if a certain condition is met, otherwise, they want to continue the trial for the next set of hyperparameters. However, the code is giving an error \"UnboundLocalError: local variable 'cwc_train' referenced before assignment\" because the condition is not met and the objective function returns 'cwc_train'.",
        "Question_gpt_summary":"user try us tune hyperparamet object function condit want specif valu certain condit met want continu trial set hyperparamet code give error unboundlocalerror local variabl cwc train referenc assign condit met object function return cwc train"
    },
    {
        "Question_title":"An error occured while retrieving the signin link",
        "Question_body":"<p>I am trying to login using bot framework. Everything goes well, up to the moment I click the &quot;Sign-in&quot; button on my &quot;auth&quot; card. Sign in dialog model open and it show the error  <\/p>\n<pre><code> {\n   &quot;error&quot;: {\n     &quot;code&quot;: &quot;ServiceError&quot;,\n     &quot;message&quot;: &quot;An error occured while retrieving the signin link&quot;\n    }\n }\n<\/code><\/pre>\n<p>MainDialog.ts  <\/p>\n<pre><code>  this.addDialog(new OAuthPrompt(OAUTH_PROMPT, {\n            connectionName: process.env.connectionName,\n            text: `Hi! I'm Bot - welcome to our app for Microsoft Team!&quot;,\n            I'm here to help you manage your ticket`,\n            timeout: 300000,\n            title: 'Sign In'\n        }))\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1640620798367,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/676437\/an-error-occured-while-retrieving-the-signin-link",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error occur retriev signin link try login bot framework goe moment click sign button auth card sign dialog model open error error code serviceerror messag error occur retriev signin link maindialog adddialog new oauthprompt oauth prompt connectionnam process env connectionnam text bot welcom app microsoft team help manag ticket timeout titl sign",
        "Question_preprocessed_content":"retriev signin link try login bot framework goe moment click auth card sign dialog model open",
        "Question_gpt_summary_original":"The user encountered an error while trying to retrieve the sign-in link when logging in using bot framework. The error message displayed was \"An error occurred while retrieving the sign-in link\". The issue seems to be related to the OAuthPrompt in the MainDialog.ts file.",
        "Question_gpt_summary":"user encount error try retriev sign link log bot framework error messag displai error occur retriev sign link issu relat oauthprompt maindialog file"
    },
    {
        "Question_title":"AzureML: How to delete detached Kubernetes service clusters?",
        "Question_body":"<p>On AzureMl, I have created some Kubernetes service clusters using <code>ComputeTarget.create()<\/code>.<\/p>\n<p>Unfortunately, I have detached some of them and I can no longer see them from the AzureML page (Compute &gt; Inference Clusters). I can re-attach them on the AzureMl page but the delete bottom is not available for the re-attached clusters.<\/p>\n<p>Because those idle clusters occupy the Total Regional Cores quota I can't create new clusters, I am wondering if there is a way to delete them?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1607139798633,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1610662691496,
        "Question_score_count":0.0,
        "Question_view_count":112.0,
        "Poster_created_time":1493509098560,
        "Poster_location":null,
        "Poster_reputation_count":155.0,
        "Poster_view_count":30.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65153543",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"delet detach kubernet servic cluster creat kubernet servic cluster computetarget creat unfortun detach longer page comput infer cluster attach page delet avail attach cluster idl cluster occupi total region core quota creat new cluster wonder wai delet",
        "Question_preprocessed_content":"delet detach kubernet servic cluster creat kubernet servic cluster unfortun detach longer page page delet avail cluster idl cluster total region core quota creat new cluster wonder wai delet",
        "Question_gpt_summary_original":"The user has created Kubernetes service clusters on AzureML using ComputeTarget.create(), but some of them have been detached and cannot be seen on the AzureML page. The delete button is not available for the re-attached clusters, and they are occupying the Total Regional Cores quota, preventing the user from creating new clusters. The user is looking for a way to delete these idle clusters.",
        "Question_gpt_summary":"user creat kubernet servic cluster computetarget creat detach seen page delet button avail attach cluster occupi total region core quota prevent user creat new cluster user look wai delet idl cluster"
    },
    {
        "Question_title":"entry_point file using XGBoost as a framework in sagemaker",
        "Question_body":"<p>Looking at the following source code taken from <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/xgboost.html\" rel=\"nofollow noreferrer\">here<\/a> (SDK v2):<\/p>\n<pre><code>import boto3\nimport sagemaker\nfrom sagemaker.xgboost.estimator import XGBoost\nfrom sagemaker.session import Session\nfrom sagemaker.inputs import TrainingInput\n\n# initialize hyperparameters\nhyperparameters = {\n        &quot;max_depth&quot;:&quot;5&quot;,\n        &quot;eta&quot;:&quot;0.2&quot;,\n        &quot;gamma&quot;:&quot;4&quot;,\n        &quot;min_child_weight&quot;:&quot;6&quot;,\n        &quot;subsample&quot;:&quot;0.7&quot;,\n        &quot;verbosity&quot;:&quot;1&quot;,\n        &quot;objective&quot;:&quot;reg:linear&quot;,\n        &quot;num_round&quot;:&quot;50&quot;}\n\n# set an output path where the trained model will be saved\nbucket = sagemaker.Session().default_bucket()\nprefix = 'DEMO-xgboost-as-a-framework'\noutput_path = 's3:\/\/{}\/{}\/{}\/output'.format(bucket, prefix, 'abalone-xgb-framework')\n\n# construct a SageMaker XGBoost estimator\n# specify the entry_point to your xgboost training script\nestimator = XGBoost(entry_point = &quot;your_xgboost_abalone_script.py&quot;, \n                    framework_version='1.2-2',\n                    hyperparameters=hyperparameters,\n                    role=sagemaker.get_execution_role(),\n                    instance_count=1,\n                    instance_type='ml.m5.2xlarge',\n                    output_path=output_path)\n\n# define the data type and paths to the training and validation datasets\ncontent_type = &quot;libsvm&quot;\ntrain_input = TrainingInput(&quot;s3:\/\/{}\/{}\/{}\/&quot;.format(bucket, prefix, 'train'), content_type=content_type)\nvalidation_input = TrainingInput(&quot;s3:\/\/{}\/{}\/{}\/&quot;.format(bucket, prefix, 'validation'), content_type=content_type)\n\n# execute the XGBoost training job\nestimator.fit({'train': train_input, 'validation': validation_input})\n<\/code><\/pre>\n<p>I wonder where the your_xgboost_abalone_script.py file has to be placed please? So far I used XGBoost as a built-in algorithm from my local machine with similar code (i.e. I span up a training job remotely). Thanks!<\/p>\n<p>PS:<\/p>\n<p>Looking at <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/training\/estimators.html\" rel=\"nofollow noreferrer\">this<\/a>, and source_dir, I wonder if one can upload Python files to S3. In this case, I take it is has to be tar.gz? Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1653478466700,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1653482394636,
        "Question_score_count":0.0,
        "Question_view_count":74.0,
        "Poster_created_time":1267440784443,
        "Poster_location":"Somewhere",
        "Poster_reputation_count":15705.0,
        "Poster_view_count":2150.0,
        "Answer_body":"<p><code>your_xgboost_abalone_script.py<\/code> can be created locally. The path you provide is relative to where the code is running.<\/p>\n<p>I.e. <code>your_xgboost_abalone_script.py<\/code> can be located in the same directory where you are running the SageMaker SDK (&quot;source code&quot;).<\/p>\n<p>For example if you have <code>your_xgboost_abalone_script.py<\/code> in the same directory as the source code:<\/p>\n<pre><code>.\n\u251c\u2500\u2500 source_code.py\n\u2514\u2500\u2500 your_xgboost_abalone_script.py\n<\/code><\/pre>\n<p>Then you can point to this file exactly how the documentation depicts:<\/p>\n<pre><code>estimator = XGBoost(entry_point = &quot;your_xgboost_abalone_script.py&quot;, \n.\n.\n.\n)\n<\/code><\/pre>\n<p>The SDK will take <code>your_xgboost_abalone_script.py<\/code> repackage it into a model tar ball and upload it to S3 on your behalf.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1654714910812,
        "Answer_last_edit_time":1654796658207,
        "Answer_score_count":1.0,
        "Answerer_created_time":1645475560783,
        "Answerer_location":null,
        "Answerer_reputation_count":466.0,
        "Answerer_view_count":32.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72376872",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"entri point file xgboost framework look follow sourc code taken sdk import boto import xgboost estim import xgboost session import session input import traininginput initi hyperparamet hyperparamet max depth eta gamma min child weight subsampl verbos object reg linear num round set output path train model save bucket session default bucket prefix demo xgboost framework output path output format bucket prefix abalon xgb framework construct xgboost estim specifi entri point xgboost train script estim xgboost entri point xgboost abalon script framework version hyperparamet hyperparamet role execut role instanc count instanc type xlarg output path output path defin data type path train valid dataset content type libsvm train input traininginput format bucket prefix train content type content type valid input traininginput format bucket prefix valid content type content type execut xgboost train job estim fit train train input valid valid input wonder xgboost abalon script file place far xgboost built algorithm local machin similar code span train job remot thank look sourc dir wonder upload python file case tar thank",
        "Question_preprocessed_content":"file framework sourc code taken wonder file place far algorithm local machin similar code thank wonder upload python file case thank",
        "Question_gpt_summary_original":"The user is trying to use XGBoost as a framework in Sagemaker and is unsure where to place the \"your_xgboost_abalone_script.py\" file. They are also wondering if Python files can be uploaded to S3 and if they need to be in tar.gz format.",
        "Question_gpt_summary":"user try us xgboost framework unsur place xgboost abalon script file wonder python file upload need tar format"
    },
    {
        "Question_title":"How to retrieve the model signature from the MLflow Model Registry",
        "Question_body":"<p>I have registered a scikit learn model on my MLflow Tracking server, and I am loading it with <code>sklearn.load_model(model_uri)<\/code>.<\/p>\n<p>Now, I would like to access the signature of the model so I can get a list of the model's required inputs\/features so I can retrieve them from my feature store by name. I can't seem to find any utility or method in the <code>mlflow<\/code> API or the <code>MLFlowClient<\/code> API that will let me access a signature or inputs\/outputs attribute, even though I can see a list of inputs and outputs under each version of the model in the UI.<\/p>\n<p>I know that I can find the input sample and the model configuration in the model's artifacts, but that would require me actually downloading the artifacts and loading them manually in my script. I don't need to avoid that, but I am surprised that I can't just return the signature as a dictionary the same way I can return a run's parameters or metrics.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1643655088920,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":904.0,
        "Poster_created_time":1466188731112,
        "Poster_location":"Michigan",
        "Poster_reputation_count":414.0,
        "Poster_view_count":39.0,
        "Answer_body":"<p>The way to access the model's signature without downloading the MLModel file is under the loaded model. And then you'll access the model's attributes, such as its signature or even other Pyfunc-defined methods.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\nmodel = mlflow.pyfunc.load_model(&quot;runs:\/&lt;run_id&gt;\/model&quot;)\nprint(model._model_meta._signature)\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1645469817663,
        "Answer_last_edit_time":null,
        "Answer_score_count":3.0,
        "Answerer_created_time":1508924024027,
        "Answerer_location":null,
        "Answerer_reputation_count":118.0,
        "Answerer_view_count":17.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70931309",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retriev model signatur model registri regist scikit learn model track server load sklearn load model model uri like access signatur model list model requir input featur retriev featur store util method api client api let access signatur input output attribut list input output version model know input sampl model configur model artifact requir actual download artifact load manual script need avoid surpris return signatur dictionari wai return run paramet metric",
        "Question_preprocessed_content":"retriev model signatur model registri regist scikit learn model track server load like signatur model list model requir retriev featur store util method api api let signatur list input output version model know input sampl model configur model artifact requir download artifact load script avoid surpris return signatur dictionari wai return run paramet metric",
        "Question_gpt_summary_original":"The user has registered a scikit learn model on their MLflow Tracking server and is trying to access the model signature to retrieve a list of required inputs\/features. However, they are unable to find any utility or method in the mlflow API or the MLFlowClient API that will let them access the signature or inputs\/outputs attribute. They can see a list of inputs and outputs under each version of the model in the UI, but they don't want to download the artifacts and load them manually in their script.",
        "Question_gpt_summary":"user regist scikit learn model track server try access model signatur retriev list requir input featur unabl util method api client api let access signatur input output attribut list input output version model want download artifact load manual script"
    },
    {
        "Question_title":"Connecting sagemaker using java sdk",
        "Question_body":"<p>Can anyone tell me how to connect to sagemaker using aws java sdk and invoke a endpoint which is arleady created using jupyter notebook?<\/p>\n\n<p>Link -<a href=\"https:\/\/docs.aws.amazon.com\/AWSJavaSDK\/latest\/javadoc\/com\/amazonaws\/services\/sagemaker\/AmazonSageMaker.html#createNotebookInstance-com.amazonaws.services.sagemaker.model.CreateNotebookInstanceRequest-\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/AWSJavaSDK\/latest\/javadoc\/com\/amazonaws\/services\/sagemaker\/AmazonSageMaker.html#createNotebookInstance-com.amazonaws.services.sagemaker.model.CreateNotebookInstanceRequest-<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1560072156127,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1112.0,
        "Poster_created_time":1539596007860,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":39.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56513409",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect java sdk tell connect aw java sdk invok endpoint arleadi creat jupyt notebook link http doc aw amazon com awsjavasdk latest javadoc com amazonaw servic amazon html createnotebookinst com amazonaw servic model createnotebookinstancerequest",
        "Question_preprocessed_content":"java sdk aw java sdk invok endpoint arleadi creat jupyt link",
        "Question_gpt_summary_original":"The user is seeking guidance on how to connect to Sagemaker using AWS Java SDK and invoke an endpoint that was created using Jupyter Notebook. They have provided a link to the AWS Java SDK documentation for creating a Notebook Instance.",
        "Question_gpt_summary":"user seek guidanc connect aw java sdk invok endpoint creat jupyt notebook provid link aw java sdk document creat notebook instanc"
    },
    {
        "Question_title":"How much will it cost me to learn Azure Machine Learning?",
        "Question_body":"<p>I'm trying to do the Azure Data Scientist Associate certification. I'm on the first portion of learning exercises and it has me create a Machine Learning Workspace and then its had me create a VM which according to the Azure pricing calculator will cost me $367 a month. If I forget to shut down this VM could I get a bill for this much? Is there a way to have these VM's automatically shut down? Since I'm only interacting with this VM via a web interface I'm really worried that I'm going to get stuck with some hefty bills after this training. Should I be concerned? The Azure Portal has a cost estimate section but it does not include any of my Machine Learning resources or workspaces so I'm not sure how I can get a realistic estimate for how much this will cost me to complete this training. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1589500691030,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/27214\/how-much-will-it-cost-me-to-learn-azure-machine-le",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"cost learn try azur data scientist associ certif portion learn exercis creat machin learn workspac creat accord azur price calcul cost month forget shut wai automat shut interact web interfac worri go stuck hefti bill train concern azur portal cost estim section includ machin learn resourc workspac sure realist estim cost complet train",
        "Question_preprocessed_content":"cost learn try azur data scientist certif portion learn exercis creat machin learn workspac creat azur price calcul cost month forget shut wai shut interact web interfac go stuck hefti train concern azur portal cost estim section includ machin learn resourc workspac sure realist estim cost complet train",
        "Question_gpt_summary_original":"The user is concerned about the cost of learning Azure Machine Learning as creating a VM for the training could cost $367 a month, and they are worried about forgetting to shut it down and receiving a hefty bill. They are also unsure about how to get a realistic estimate for the cost of completing the training as the Azure Portal's cost estimate section does not include any of their Machine Learning resources or workspaces.",
        "Question_gpt_summary":"user concern cost learn creat train cost month worri forget shut receiv hefti unsur realist estim cost complet train azur portal cost estim section includ machin learn resourc workspac"
    },
    {
        "Question_title":"unable to identify current timezone 'C'",
        "Question_body":"<p>all,<\/p>\n\n<p>I am using R on the Azure machine learning, and I have some problems.<\/p>\n\n<p>I want to use program R to calculate the difference between two date, for example, 2014\/11\/01 and 2014\/11\/03.<\/p>\n\n<p>I using the function \"strptime\" in R to do this thing, it can work on my own computer, but when I want to run the same code on Azure ml, it came out the error.<\/p>\n\n<p>The error is : <\/p>\n\n<pre><code>[ModuleOutput] 1: In strptime(x, format, tz = tz) :\n[ModuleOutput] \n[ModuleOutput]   unable to identify current timezone 'C':\n[ModuleOutput] \n[ModuleOutput] please set environment variable 'TZ'\n[ModuleOutput] \n[ModuleOutput] 2: In strptime(x, format, tz = tz) : unknown timezone 'localtime'\n<\/code><\/pre>\n\n<p>I think the problem is that it can't detect the timezone on Azure ml, but I'm not sure.<\/p>\n\n<p>Is there any way to solve this problem?<\/p>\n\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1415262044470,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":1456.0,
        "Poster_created_time":1413344613203,
        "Poster_location":"Taipei City, Taiwan",
        "Poster_reputation_count":579.0,
        "Poster_view_count":73.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/26774724",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl identifi current timezon problem want us program calcul differ date exampl function strptime thing work want run code came error error moduleoutput strptime format moduleoutput moduleoutput unabl identifi current timezon moduleoutput moduleoutput set environ variabl moduleoutput moduleoutput strptime format unknown timezon localtim think problem detect timezon sure wai solv problem thank advanc",
        "Question_preprocessed_content":"unabl identifi timezon problem want us program calcul date exampl function strptime thing work want run code came think problem detect timezon sure wai solv problem thank advanc",
        "Question_gpt_summary_original":"The user is facing an issue while using the \"strptime\" function in R on Azure machine learning to calculate the difference between two dates. The error message suggests that the current timezone 'C' cannot be identified, and the user needs to set the environment variable 'TZ'. The user suspects that the problem is related to the inability to detect the timezone on Azure ml.",
        "Question_gpt_summary":"user face issu strptime function calcul differ date error messag suggest current timezon identifi user need set environ variabl user suspect problem relat inabl detect timezon"
    },
    {
        "Question_title":"Azure ML Studio: How to change input value with Python before it goes through data process",
        "Question_body":"<p>I am currently attempting to change the value of input as it goes through data process in Azure ML. However, I cannot find a clue about how to access to the input data with python.<\/p>\n\n<p>For example, if you were to use python, you can access to the column of data with<\/p>\n\n<pre><code>print(dataframe1[\"Hello World\"])\n<\/code><\/pre>\n\n<p>I tried to change the name of Web Service Input and tried to do it like how I did for other dataframe (e.g. sample)<\/p>\n\n<pre><code>print(dataframe[\"sample\"])\n<\/code><\/pre>\n\n<p>But it returns an error with no luck, and from what I read from an error, it's not compatible to dataframe:<\/p>\n\n<pre><code>object of type 'NoneType' has no len()\n<\/code><\/pre>\n\n<p>I tried to look up a solution with Nonetype error, but there is no good solution.\nThe whole error message:<\/p>\n\n<pre><code>requestId = 1f0f621f1d8841baa7862d5c05154942 errorComponent=Module. taskStatusCode=400. {\"Exception\":{\"ErrorId\":\"FailedToEvaluateScript\",\"ErrorCode\":\"0085\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 0085: The following error occurred during script evaluation, please view the output log for more information:\\r\\n---------- Start of error message from Python interpreter ----------\\r\\nCaught exception while executing function: Traceback (most recent call last):\\r\\n File \\\"C:\\\\server\\\\invokepy.py\\\", line 211, in batch\\r\\n xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True)\\r\\n File \\\"C:\\\\server\\\\XDRReader\\\\xdrutils.py\\\", line 51, in DataFrameToRFile\\r\\n attributes = XDRBridge.DataFrameToRObject(dataframe)\\r\\n File \\\"C:\\\\server\\\\XDRReader\\\\xdrbridge.py\\\", line 40, in DataFrameToRObject\\r\\n if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):\\r\\nTypeError: object of type 'NoneType' has no len()\\r\\nProcess returned with non-zero exit code 1\\r\\n\\r\\n---------- End of error message from Python interpreter ----------\"}}Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:---------- Start of error message from Python interpreter ----------Caught exception while executing function: Traceback (most recent call last): File \"C:\\server\\invokepy.py\", line 211, in batch xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True) File \"C:\\server\\XDRReader\\xdrutils.py\", line 51, in DataFrameToRFile attributes = XDRBridge.DataFrameToRObject(dataframe) File \"C:\\server\\XDRReader\\xdrbridge.py\", line 40, in DataFrameToRObject if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):TypeError: object of type 'NoneType' has no len()Process returned with non-zero exit code 1---------- End of error message from Python interpreter ---------- Process exited with error code -2\n<\/code><\/pre>\n\n<p>I have also tried to <a href=\"https:\/\/i.stack.imgur.com\/DWZK6.png\" rel=\"nofollow noreferrer\">a way to pass python script in data<\/a>, but it is not able to make any change to Web Service Input value as I want it to be.<\/p>\n\n<p>I have tried to look on forums like msdn or SO, but it's been difficult to find any information about it. Please let me know if you need any more information if needed. I would greatly appreciate your help!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1533163130393,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":309.0,
        "Poster_created_time":1508281047960,
        "Poster_location":null,
        "Poster_reputation_count":25.0,
        "Poster_view_count":22.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51643168",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio chang input valu python goe data process current attempt chang valu input goe data process clue access input data python exampl us python access column data print datafram hello world tri chang web servic input tri like datafram sampl print datafram sampl return error luck read error compat datafram object type nonetyp len tri look solut nonetyp error good solut error messag requestid fffdbaadc errorcompon modul taskstatuscod except errorid failedtoevaluatescript errorcod exceptiontyp moduleexcept messag error follow error occur script evalu view output log inform start error messag python interpret ncaught except execut function traceback recent file server invokepi line batch xdrutil xdrutil dataframetorfil outlist outfil true file server xdrreader xdrutil line dataframetorfil attribut xdrbridg dataframetorobject datafram file server xdrreader xdrbridg line dataframetorobject len datafram type datafram datafram ntypeerror object type nonetyp len nprocess return non zero exit code end error messag python interpret error error follow error occur script evalu view output log inform start error messag python interpret caught except execut function traceback recent file server invokepi line batch xdrutil xdrutil dataframetorfil outlist outfil true file server xdrreader xdrutil line dataframetorfil attribut xdrbridg dataframetorobject datafram file server xdrreader xdrbridg line dataframetorobject len datafram type datafram datafram typeerror object type nonetyp len process return non zero exit code end error messag python interpret process exit error code tri wai pass python script data abl chang web servic input valu want tri look forum like msdn difficult inform let know need inform need greatli appreci help",
        "Question_preprocessed_content":"studio chang input valu python goe data chang valu input goe data clue input data python exampl us python column data tri chang web servic input tri like datafram return luck read compat datafram tri solut nonetyp solut tri wai python script data abl chang web servic input valu want tri forum like msdn inform let know inform greatli help",
        "Question_gpt_summary_original":"The user is trying to change the value of input data as it goes through data processing in Azure ML Studio using Python, but is unable to access the input data with Python. The user has tried to change the name of the Web Service Input and has encountered a 'NoneType' error. The user has also tried to pass a Python script in data, but it did not make any changes to the Web Service Input value. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":"user try chang valu input data goe data process studio python unabl access input data python user tri chang web servic input encount nonetyp error user tri pass python script data chang web servic input valu user seek help resolv issu"
    },
    {
        "Question_title":"_InactiveRpcError while querying Vertex AI Matching Engine Index",
        "Question_body":"<p>I am following the example <a href=\"https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/master\/notebooks\/community\/matching_engine\/matching_engine_for_indexing.ipynb\" rel=\"nofollow noreferrer\">notebook<\/a> as per GCP <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/matching-engine\/using-matching-engine#example_notebook\" rel=\"nofollow noreferrer\">docs<\/a> to test Vertex Matching Engine. I have deployed an index but while trying to query the index I am getting <code>_InactiveRpcError<\/code>. The VPC network is in <code>us-west2<\/code> with private service access enabled and the Index is deployed in <code>us-central1<\/code>. My VPC network contains the <a href=\"https:\/\/cloud.google.com\/vpc\/docs\/firewalls#more_rules_default_vpc\" rel=\"nofollow noreferrer\">pre-populated firewall rules<\/a>.<\/p>\n<p>Index<\/p>\n<pre><code>createTime: '2021-11-23T15:25:53.928606Z'\ndeployedIndexes:\n- deployedIndexId: brute_force_glove_deployed_v3\n  indexEndpoint: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexEndpoints\/XXXXXXXXXXXX\ndescription: testing python script for creating index\ndisplayName: glove_100_brute_force_20211123152551\netag: AMEw9yOVPWBOTpbAvJLllqxWMi2YurEV_sad2n13QvbIlqjOdMyiq_j20gG1ldhdZNTL\nmetadata:\n  config:\n    algorithmConfig:\n      bruteForceConfig: {}\n    dimensions: 100\n    distanceMeasureType: DOT_PRODUCT_DISTANCE\nmetadataSchemaUri: gs:\/\/google-cloud-aiplatform\/schema\/matchingengine\/metadata\/nearest_neighbor_search_1.0.0.yaml\nname: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexes\/XXXXXXXXXXXX\nupdateTime: '2021-11-23T16:04:17.993730Z'\n<\/code><\/pre>\n<p>Index-Endpoint<\/p>\n<pre><code>createTime: '2021-11-24T10:59:51.975949Z'\ndeployedIndexes:\n- automaticResources:\n    maxReplicaCount: 1\n    minReplicaCount: 1\n  createTime: '2021-11-30T15:16:12.323028Z'\n  deploymentGroup: default\n  displayName: brute_force_glove_deployed_v3\n  enableAccessLogging: true\n  id: brute_force_glove_deployed_v3\n  index: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexes\/XXXXXXXXXXXX\n  indexSyncTime: '2021-11-30T16:37:35.597200Z'\n  privateEndpoints:\n    matchGrpcAddress: 10.242.4.5\ndisplayName: index_endpoint_for_demo\netag: AMEw9yO6cuDfgpBhGVw7-NKnlS1vdFI5nnOtqVgW1ddMP-CMXM7NfGWVpqRpMRPsNCwc\nname: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexEndpoints\/XXXXXXXXXXXX\nnetwork: projects\/XXXXXXXXXXXX\/global\/networks\/XXXXXXXXXXXX\nupdateTime: '2021-11-24T10:59:53.271100Z'\n<\/code><\/pre>\n<p>Code<\/p>\n<pre><code>\nimport grpc\n\n# import the generated classes\nimport match_service_pb2\nimport match_service_pb2_grpc\n\nDEPLOYED_INDEX_SERVER_IP = '10.242.0.5'\nDEPLOYED_INDEX_ID = 'brute_force_glove_deployed_v3'\n\nquery = [-0.11333, 0.48402, 0.090771, -0.22439, 0.034206, -0.55831, 0.041849, -0.53573, 0.18809, -0.58722, 0.015313, -0.014555, 0.80842, -0.038519, 0.75348, 0.70502, -0.17863, 0.3222, 0.67575, 0.67198, 0.26044, 0.4187, -0.34122, 0.2286, -0.53529, 1.2582, -0.091543, 0.19716, -0.037454, -0.3336, 0.31399, 0.36488, 0.71263, 0.1307, -0.24654, -0.52445, -0.036091, 0.55068, 0.10017, 0.48095, 0.71104, -0.053462, 0.22325, 0.30917, -0.39926, 0.036634, -0.35431, -0.42795, 0.46444, 0.25586, 0.68257, -0.20821, 0.38433, 0.055773, -0.2539, -0.20804, 0.52522, -0.11399, -0.3253, -0.44104, 0.17528, 0.62255, 0.50237, -0.7607, -0.071786, 0.0080131, -0.13286, 0.50097, 0.18824, -0.54722, -0.42664, 0.4292, 0.14877, -0.0072514, -0.16484, -0.059798, 0.9895, -0.61738, 0.054169, 0.48424, -0.35084, -0.27053, 0.37829, 0.11503, -0.39613, 0.24266, 0.39147, -0.075256, 0.65093, -0.20822, -0.17456, 0.53571, -0.16537, 0.13582, -0.56016, 0.016964, 0.1277, 0.94071, -0.22608, -0.021106]\n\nchannel = grpc.insecure_channel(&quot;{}:10000&quot;.format(DEPLOYED_INDEX_SERVER_IP))\nstub = match_service_pb2_grpc.MatchServiceStub(channel)\n\nrequest = match_service_pb2.MatchRequest()\nrequest.deployed_index_id = DEPLOYED_INDEX_ID\nfor val in query:\n    request.float_val.append(val)\n\nresponse = stub.Match(request)\nresponse\n<\/code><\/pre>\n<p>Error<\/p>\n<pre><code>_InactiveRpcError                         Traceback (most recent call last)\n\/tmp\/ipykernel_3451\/467153318.py in &lt;module&gt;\n    108     request.float_val.append(val)\n    109 \n--&gt; 110 response = stub.Match(request)\n    111 response\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in __call__(self, request, timeout, metadata, credentials, wait_for_ready, compression)\n    944         state, call, = self._blocking(request, timeout, metadata, credentials,\n    945                                       wait_for_ready, compression)\n--&gt; 946         return _end_unary_response_blocking(state, call, False, None)\n    947 \n    948     def with_call(self,\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in _end_unary_response_blocking(state, call, with_call, deadline)\n    847             return state.response\n    848     else:\n--&gt; 849         raise _InactiveRpcError(state)\n    850 \n    851 \n\n_InactiveRpcError: &lt;_InactiveRpcError of RPC that terminated with:\n    status = StatusCode.UNAVAILABLE\n    details = &quot;failed to connect to all addresses&quot;\n    debug_error_string = &quot;{&quot;created&quot;:&quot;@1638277076.941429628&quot;,&quot;description&quot;:&quot;Failed to pick subchannel&quot;,&quot;file&quot;:&quot;src\/core\/ext\/filters\/client_channel\/client_channel.cc&quot;,&quot;file_line&quot;:3093,&quot;referenced_errors&quot;:[{&quot;created&quot;:&quot;@1638277076.941428202&quot;,&quot;description&quot;:&quot;failed to connect to all addresses&quot;,&quot;file&quot;:&quot;src\/core\/lib\/transport\/error_utils.cc&quot;,&quot;file_line&quot;:163,&quot;grpc_status&quot;:14}]}&quot;\n&gt;\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1638291169620,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1639486727367,
        "Question_score_count":2.0,
        "Question_view_count":350.0,
        "Poster_created_time":1463607987528,
        "Poster_location":"Lahore, Pakistan",
        "Poster_reputation_count":143.0,
        "Poster_view_count":23.0,
        "Answer_body":"<p>Currently, Matching Engine only supports Query from the same region. Can you try running the code from VM in <code>us-central1<\/code>.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1638293279416,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1638293279416,
        "Answerer_location":null,
        "Answerer_reputation_count":26.0,
        "Answerer_view_count":13.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70173096",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"inactiverpcerror queri match engin index follow exampl notebook gcp doc test vertex match engin deploi index try queri index get inactiverpcerror vpc network west privat servic access enabl index deploi central vpc network contain pre popul firewal rule index createtim deployedindex deployedindexid brute forc glove deploi indexendpoint project xxxxxxxxxxxx locat central indexendpoint xxxxxxxxxxxx descript test python script creat index displaynam glove brute forc etag amewyovpwbotpbavjlllqxwmiyurev sadnqvbilqjodmyiq jggldhdzntl metadata config algorithmconfig bruteforceconfig dimens distancemeasuretyp dot product distanc metadataschemauri googl cloud aiplatform schema matchingengin metadata nearest neighbor search yaml project xxxxxxxxxxxx locat central index xxxxxxxxxxxx updatetim index endpoint createtim deployedindex automaticresourc maxreplicacount minreplicacount createtim deploymentgroup default displaynam brute forc glove deploi enableaccesslog true brute forc glove deploi index project xxxxxxxxxxxx locat central index xxxxxxxxxxxx indexsynctim privateendpoint matchgrpcaddress displaynam index endpoint demo etag amewyocudfgpbhgvw nknlsvdfinnotqvgwddmp cmxmnfgwvpqrpmrpsncwc project xxxxxxxxxxxx locat central indexendpoint xxxxxxxxxxxx network project xxxxxxxxxxxx global network xxxxxxxxxxxx updatetim code import grpc import gener class import match servic import match servic grpc deploi index server deploi index brute forc glove deploi queri channel grpc insecur channel format deploi index server stub match servic grpc matchservicestub channel request match servic matchrequest request deploi index deploi index val queri request float val append val respons stub match request respons error inactiverpcerror traceback recent tmp ipykernel request float val append val respons stub match request respons opt conda lib python site packag grpc channel self request timeout metadata credenti wait readi compress state self block request timeout metadata credenti wait readi compress return end unari respons block state fals def self opt conda lib python site packag grpc channel end unari respons block state deadlin return state respons rais inactiverpcerror state inactiverpcerror",
        "Question_preprocessed_content":"queri match engin index exampl gcp doc test vertex match engin deploi index try queri index vpc network privat servic enabl index deploi vpc network contain rule index code",
        "Question_gpt_summary_original":"The user is encountering an _InactiveRpcError while querying a Vertex AI Matching Engine Index. The VPC network is in us-west2 with private service access enabled and the Index is deployed in us-central1. The user has pre-populated firewall rules in their VPC network. The error message indicates that the RPC terminated with a status code of UNAVAILABLE and failed to connect to all addresses.",
        "Question_gpt_summary":"user encount inactiverpcerror queri match engin index vpc network west privat servic access enabl index deploi central user pre popul firewal rule vpc network error messag indic rpc termin statu code unavail fail connect address"
    },
    {
        "Question_title":"Consume AzureML Studio Output as dataframe",
        "Question_body":"<p>Hi,    <br \/>\n    I'm performing some experiments in AzureML studio with Automl. I trained the model with no-code option and trying to evaluate the same in notebooks. However, the output comes in form of bytes. Is there a way to get it in form a dataframe ?   <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/135932-image.png?platform=QnA\" alt=\"135932-image.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1632824148170,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/569086\/consume-azureml-studio-output-as-dataframe",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"consum studio output datafram perform experi studio automl train model code option try evalu notebook output come form byte wai form datafram",
        "Question_preprocessed_content":"consum studio output datafram perform experi studio automl train model option try evalu output come form byte wai form datafram",
        "Question_gpt_summary_original":"The user trained a model using no-code option in AzureML Studio and is trying to evaluate it in notebooks. However, the output is in the form of bytes and the user is looking for a way to convert it into a dataframe.",
        "Question_gpt_summary":"user train model code option studio try evalu notebook output form byte user look wai convert datafram"
    },
    {
        "Question_title":"OCR in Sage Maker",
        "Question_body":"<p>Guys i am trying to build infrastructure on aws for getting help from others on annotation. currently we uses label-studio for text annotation. as might know you can label text by selecting through polygon and than writing what does selected area mean. ex: if polygon is made around english word than what writing out label  of it to annotate that given english word. for more see image below.<a href=\"https:\/\/i.stack.imgur.com\/8jvaj.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8jvaj.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>How can i do this in <strong>SageMaker Ground Truth<\/strong>. as far as i have gone i think it can just label pre defined words. you cant create custom label in it by selecting any given area using polygon in image am i right ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1644428834663,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":67.0,
        "Poster_created_time":1482044943532,
        "Poster_location":"Gurgaon, Haryana, India",
        "Poster_reputation_count":549.0,
        "Poster_view_count":50.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71054340",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"ocr sage maker gui try build infrastructur aw get help annot current us label studio text annot know label text select polygon write select area mean polygon english word write label annot given english word imag ground truth far gone think label pre defin word creat custom label select given area polygon imag right",
        "Question_preprocessed_content":"ocr sage maker gui try build infrastructur aw help us text know label text select polygon write select area mean polygon english word write label given english word imag ground truth far gone think label pre defin word creat custom label select given area polygon imag right",
        "Question_gpt_summary_original":"The user is trying to build infrastructure on AWS for text annotation using SageMaker Ground Truth. They are currently using Label-Studio for text annotation, which allows them to label text by selecting through a polygon and writing the label for the selected area. The user is wondering if they can do the same in SageMaker Ground Truth, but they believe it can only label pre-defined words and cannot create custom labels by selecting any given area using a polygon in an image.",
        "Question_gpt_summary":"user try build infrastructur aw text annot ground truth current label studio text annot allow label text select polygon write label select area user wonder ground truth believ label pre defin word creat custom label select given area polygon imag"
    },
    {
        "Question_title":"Compute Instance: Best practice for custom Anaconda env",
        "Question_body":"<p>I'd like to use a compute instance as my develop machine.\nAre there any best practices on how to handle custom Anaconda enviroments on these machines?<\/p>\n\n<p>So far, I do it this way:<\/p>\n\n<pre><code>conda create --name testenv python=3\nconda activate testenv\nconda install ipykernel\nipython kernel install --user --name=testenv\nsudo systemctl restart jupyter.service\n<\/code><\/pre>\n\n<p>--> Reload the JupyterHub in your browser.<\/p>\n\n<p>Do you see any drawbacks by doing it this way? I know, some special package combinations in the standard env are lost, but I'd like to know what I've installed in my system.\nOf course, one could combine it with an <code>environment.yml<\/code>.<\/p>\n\n<p>What do you think?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1591178661870,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1591865477772,
        "Question_score_count":1.0,
        "Question_view_count":116.0,
        "Poster_created_time":1589205020747,
        "Poster_location":"Germany",
        "Poster_reputation_count":163.0,
        "Poster_view_count":16.0,
        "Answer_body":"<p>Your workaround is the best option as of now. But I know that the Azure ML product group has been working on exactly this problem, but I can't make any promises as to timeline.<\/p>\n\n<p>I share your dream of an easily configurable data science cloud development environment that allows for Git repo cloning and environment creation w\/ a conda yml. We're so close especially given all the press &amp; announcements around Visual Studio Codespaces!<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1591290256907,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1405457120427,
        "Answerer_location":"Seattle, WA, USA",
        "Answerer_reputation_count":3359.0,
        "Answerer_view_count":555.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62170192",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"comput instanc best practic custom anaconda env like us comput instanc develop machin best practic handl custom anaconda enviro machin far wai conda creat testenv python conda activ testenv conda instal ipykernel ipython kernel instal user testenv sudo systemctl restart jupyt servic reload jupyterhub browser drawback wai know special packag combin standard env lost like know instal cours combin environ yml think",
        "Question_preprocessed_content":"comput instanc best practic custom anaconda env like us comput instanc develop machin best practic handl custom anaconda enviro machin far wai reload jupyterhub browser drawback wai know special packag combin standard env lost like know cours combin think",
        "Question_gpt_summary_original":"The user is seeking best practices for handling custom Anaconda environments on a compute instance used as a development machine. The user currently creates a new environment using conda, installs necessary packages, and restarts the Jupyter service. The user is concerned about losing special package combinations in the standard environment but wants to know what is installed in the system. The user is considering combining the process with an environment.yml file.",
        "Question_gpt_summary":"user seek best practic handl custom anaconda environ comput instanc develop machin user current creat new environ conda instal necessari packag restart jupyt servic user concern lose special packag combin standard environ want know instal user consid combin process environ yml file"
    },
    {
        "Question_title":"Not able to make data working in the Studio",
        "Question_body":"<p>Hi,    <br \/>\n  I am using Azure classic studio for ML.  Reading large CSV files with 20 columns. One column has a Timestamp which becomes 2.01E+16 after I cleaned the data using Excel.     <\/p>\n<p>  Each time I run it, it says:     <br \/>\n[Information]         In <code>[&lt;-.factor<\/code>(<code>*tmp*<\/code>, ri, value = c(0L, 148L, 50L, 4L, 39L, 5L,  :    <br \/>\n[Information]           invalid factor level, NA generated    <br \/>\n[Stop]     DllModuleMethod::Execute. Duration = 00:09:24.4753205    <br \/>\n[Critical]     Error: Error 0063: The following error occurred during evaluation of R script:    <\/p>\n<p>----------    <br \/>\n Start of error message from R ----------    <br \/>\nreplacement has 1 row, data has 0    <\/p>\n<p>I used colSums to print it: colSums(is.na(test). It shows this column has 3 na VALUES in data and 2 in test.    <br \/>\nI replace na with test[is.na(test$Timestamp),]$Timestamp&lt;-&quot;2.01E+16&quot;    <br \/>\nStill the same error.    <\/p>\n<p>It's so exhausting to test line by line with no way to debug it to pinpoint exactly where is the problem.    <\/p>\n<p>Plz help!    <br \/>\nNWA<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5.0,
        "Question_created_time":1657242496467,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/918864\/not-able-to-make-data-working-in-the-studio",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"abl data work studio azur classic studio read larg csv file column column timestamp clean data excel time run sai inform factor tmp valu inform invalid factor level gener stop dllmodulemethod execut durat critic error error follow error occur evalu script start error messag replac row data colsum print colsum test show column valu data test replac test test timestamp timestamp error exhaust test line line wai debug pinpoint exactli problem plz help nwa",
        "Question_preprocessed_content":"abl data work studio azur studio read larg csv file column column timestamp clean data excel time run sai inform show column valu data test replac exhaust test line line wai debug pinpoint exactli problem plz help nwa",
        "Question_gpt_summary_original":"The user is facing challenges in making data work in Azure classic studio for ML. They are reading large CSV files with 20 columns, and one column has a Timestamp which becomes 2.01E+16 after cleaning the data using Excel. The user is encountering an error message related to invalid factor level and NA generated. They have tried to replace NA with the Timestamp value but still face the same error. The user is finding it exhausting to test line by line with no way to debug the problem.",
        "Question_gpt_summary":"user face challeng make data work azur classic studio read larg csv file column column timestamp clean data excel user encount error messag relat invalid factor level gener tri replac timestamp valu face error user find exhaust test line line wai debug problem"
    },
    {
        "Question_title":"DVC Files Incomplete",
        "Question_body":"<p>I'm in a team using dvc with git to version-control data files. We are using dvc 1.3.1, with the an S3 bucket remote. I'm getting this error when executing <code>dvc fetch<\/code> or <code>dvc pull<\/code> on a colleague's branch:<\/p>\n<pre><code>ERROR: failed to fetch data from the cloud - DVC-file 'C:\\Users\\blah\\Documents\\repo\\data\\processed_data.dvc' format error: extra keys not allowed @ data['outs'][0]['size']\n<\/code><\/pre>\n<p>When I check the dvc file for a cached file with which I have no problem I see this:<\/p>\n<pre><code>md5: ded591aacbe363f0518ceb9c3bc1836b\nouts:\n- md5: efdab20e8b59903b9523cc188ff727e5\n  path: completion_header.p\n  cache: true\n  metric: false\n  persist: false\n<\/code><\/pre>\n<p>but a problematic file only has this:<\/p>\n<pre><code>outs:\n- md5: f4e15187d9a0bbb328e629eabd8d1784.dir\n  size: 112007\n  nfiles: 3\n  path: processed_data\n<\/code><\/pre>\n<p>In all cases, files are added to dvc with the command <code>dvc add %dirname%<\/code>. This is the second time I've seen this on a colleague's branch (2 different people).<\/p>\n<p>Since posting, I have realized that my colleague dvc'd a directory. I have attempted creating the directory first, then calling <code>dvc fetch<\/code>, but get the same error.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1618565400113,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1618826341416,
        "Question_score_count":2.0,
        "Question_view_count":548.0,
        "Poster_created_time":1348150034832,
        "Poster_location":"Glasgow, UK",
        "Poster_reputation_count":2400.0,
        "Poster_view_count":263.0,
        "Answer_body":"<blockquote>\n<p>In all cases, files are added to dvc with the command dvc add %filename%.<\/p>\n<\/blockquote>\n<p>It seems like there is a high chance that one of the dvc files created in newer versions of dvc and you are trying to operate with an older version. Are all of your colleagues use the same dvc version when adding new files?<\/p>",
        "Answer_comment_count":4.0,
        "Question_closed_time":1618566517710,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1614873430827,
        "Answerer_location":null,
        "Answerer_reputation_count":169.0,
        "Answerer_view_count":7.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67122683",
        "Tool":"DVC",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"file incomplet team git version control data file bucket remot get error execut fetch pull colleagu branch error fail fetch data cloud file user blah document repo data process data format error extra kei allow data out size check file cach file problem dedaacbefcebcbcb out efdabebbccff path complet header cach true metric fals persist fals problemat file out fedabbbeeabdd dir size nfile path process data case file ad command add dirnam second time seen colleagu branch differ peopl post realiz colleagu directori attempt creat directori call fetch error",
        "Question_preprocessed_content":"file incomplet team git data file bucket remot execut branch check file cach file problem problemat file case file second time branch post realiz directori creat directori",
        "Question_gpt_summary_original":"The user is encountering an error while using DVC with Git to version-control data files. The error occurs when executing \"dvc fetch\" or \"dvc pull\" on a colleague's branch, and the error message indicates a DVC-file format error. The problematic file has incomplete information in comparison to a cached file that is working fine. The files are added to DVC with the command \"dvc add %dirname%\". The user has attempted creating the directory first, but the error persists.",
        "Question_gpt_summary":"user encount error git version control data file error occur execut fetch pull colleagu branch error messag indic file format error problemat file incomplet inform comparison cach file work fine file ad command add dirnam user attempt creat directori error persist"
    },
    {
        "Question_title":"Sagemaker with windows",
        "Question_body":"<p>I am trying to use aws sagemaker with Windows using Docker :\nHere is the docker file :<\/p>\n\n<pre><code># Build an image that can do training and inference in SageMaker\n# This is a Python 2 image that uses the nginx, gunicorn, flask stack\n# for serving inferences in a stable way.\n\nFROM ubuntu:16.04\n\nMAINTAINER Amazon AI &lt;sage-learner@amazon.com&gt;\n\n\nRUN apt-get -y update &amp;&amp; apt-get install -y --no-install-recommends \\\n         wget \\\n         python3.5 \\\n         nginx \\\n         libgcc-5-dev \\\n         ca-certificates \\\n    &amp;&amp; rm -rf \/var\/lib\/apt\/lists\/*\n\n# Here we get all python packages.\n# There's substantial overlap between scipy and numpy that we eliminate by\n# linking them together. Likewise, pip leaves the install caches populated which uses\n# a significant amount of space. These optimizations save a fair amount of space in the\n# image, which reduces start up time.\nRUN wget https:\/\/bootstrap.pypa.io\/3.3\/get-pip.py &amp;&amp; python3.5 get-pip.py &amp;&amp; \\\n    pip3 install numpy==1.14.3 scipy scikit-learn==0.19.1 xgboost==0.72.1 pandas==0.22.0 flask gevent gunicorn &amp;&amp; \\\n        (cd \/usr\/local\/lib\/python3.5\/dist-packages\/scipy\/.libs; rm *; ln ..\/..\/numpy\/.libs\/* .) &amp;&amp; \\\n        rm -rf \/root\/.cache\n\n# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\n# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\n# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\n# PATH so that the train and serve programs are found when the container is invoked.\n\nENV PYTHONUNBUFFERED=TRUE\nENV PYTHONDONTWRITEBYTECODE=TRUE\nENV PATH=\"\/opt\/program:${PATH}\"\n\n# Set up the program in the image\nCOPY xgboost \/opt\/program\nWORKDIR \/opt\/program\n<\/code><\/pre>\n\n<p>My question is should I, since I work under windows 7, change these path : ?<\/p>\n\n<p>Thank you<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1534427312350,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":359.0,
        "Poster_created_time":1518617852856,
        "Poster_location":null,
        "Poster_reputation_count":495.0,
        "Poster_view_count":81.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51878668",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"window try us window docker docker file build imag train infer python imag us nginx gunicorn flask stack serv infer stabl wai ubuntu maintain amazon run apt updat apt instal instal recommend wget python nginx libgcc dev certif var lib apt list python packag substanti overlap scipi numpi elimin link likewis pip leav instal cach popul us signific space optim save fair space imag reduc start time run wget http bootstrap pypa pip python pip pip instal numpi scipi scikit learn xgboost panda flask gevent gunicorn usr local lib python dist packag scipi lib numpi lib root cach set environ variabl pythonunbuff keep python buffer standard output stream mean log deliv user quickli pythondontwritebytecod keep python write pyc file unnecessari case updat path train serv program contain invok env pythonunbuff true env pythondontwritebytecod true env path opt program path set program imag copi xgboost opt program workdir opt program question work window chang path thank",
        "Question_preprocessed_content":"window try us window docker docker file question work window chang path thank",
        "Question_gpt_summary_original":"The user is trying to use AWS Sagemaker with Windows using Docker and has provided a Docker file. The user is unsure if they need to change the paths in the file since they are working under Windows 7.",
        "Question_gpt_summary":"user try us window docker provid docker file user unsur need chang path file work window"
    },
    {
        "Question_title":"Dialogflow ES API returns payload not found in Intents",
        "Question_body":"Hello,\n\nWhen calling the DialogFlowES agent via API for a query, it returns a payload that is not found in any of the intents. Any ideas on why this is happening?\u00a0\n\nThanks!",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1684381500000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":50.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-ES-API-returns-payload-not-found-in-Intents\/m-p\/554537#M1951",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"dialogflow api return payload intent hello call dialogflow agent api queri return payload intent idea happen thank",
        "Question_preprocessed_content":"dialogflow api return payload intent dialogflow agent api queri return payload intent idea thank",
        "Question_gpt_summary_original":"The user is facing an issue where the Dialogflow ES API is returning a payload that cannot be found in any of the intents. They are seeking assistance in understanding why this is happening.",
        "Question_gpt_summary":"user face issu dialogflow api return payload intent seek assist understand happen"
    },
    {
        "Question_title":"Combining multiple sweeps with the same name",
        "Question_body":"<p>I have figured out how to do hyperparameter sweeps, and I am pleased. However, I would like to combine sweep results from multiple sweeps with the same name, and this does not appear to be possible without rerunning the simulations. If it not possible, I would like to know why not since all the information necessary to combine them is available. The runs from these multiple sweeps are all available in a single table. Thanks. Gordon.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1659536458411,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":412.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/combining-multiple-sweeps-with-the-same-name\/2846",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"combin multipl sweep figur hyperparamet sweep pleas like combin sweep result multipl sweep appear possibl rerun simul possibl like know inform necessari combin avail run multipl sweep avail singl tabl thank gordon",
        "Question_preprocessed_content":"combin multipl figur hyperparamet pleas like combin result multipl simul like know inform combin avail run multipl avail singl tabl thank gordon",
        "Question_gpt_summary_original":"The user has successfully conducted hyperparameter sweeps but is facing challenges in combining sweep results from multiple sweeps with the same name. The user is unable to do so without rerunning the simulations and is seeking information on why this is not possible since all the necessary information is available in a single table.",
        "Question_gpt_summary":"user successfulli conduct hyperparamet sweep face challeng combin sweep result multipl sweep user unabl rerun simul seek inform possibl necessari inform avail singl tabl"
    },
    {
        "Question_title":"Is it possible to parameterize the sharable url of an azure ml notebook?",
        "Question_body":"<p>I would like to share the link to a Jupyter notebook (stored in azure ml studio) with the parameters of the notebook already updated. I see I can automatically get a sharable link for the notebook. Is it possible to parameterize this link? If not, is there an equivalent alternative?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1643398754623,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/714542\/is-it-possible-to-parameterize-the-sharable-url-of",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl parameter sharabl url notebook like share link jupyt notebook store studio paramet notebook updat automat sharabl link notebook possibl parameter link equival altern",
        "Question_preprocessed_content":"parameter sharabl url like share link jupyt paramet updat sharabl link parameter link equival altern",
        "Question_gpt_summary_original":"The user wants to know if it is possible to parameterize the sharable URL of an Azure ML notebook so that the parameters of the notebook are already updated when shared. They are also looking for an alternative if this is not possible.",
        "Question_gpt_summary":"user want know possibl parameter sharabl url notebook paramet notebook updat share look altern possibl"
    },
    {
        "Question_title":"How to export a MLFlow Model from Azure Databricks as an Azure DevOps Artifacts for CD phase?",
        "Question_body":"<p>I am trying to create an MLOps Pipeline using Azure DevOps and Azure Databricks. From Azure DevOps, I am submitting a Databricks job to a cluster, which trains a Machine Learning Model and saves it into MLFlow Model Registry with a custom flavour (using PyFunc Custom Model).<\/p>\n<p>Now after the job gets over, I want to export this MLFlow Object (with all dependencies - Conda dependencies, two model files - one <code>.pkl<\/code> and one <code>.h5<\/code>, the Python Class with <code>load_context()<\/code> and <code>predict()<\/code> functions defined so that after exporting I can import it and call predict as we do with MLFlow Models).<\/p>\n<p>How do I export this entire MLFlow Model and save it as an AzureDevOps Artifact to be used in the CD phase (where I will deploy it to an AKS cluster with a custom base image)?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1629179063687,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":575.0,
        "Poster_created_time":1601729162436,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":887.0,
        "Poster_view_count":130.0,
        "Answer_body":"<p>There is no official way to export a Databricks MLflow run from one workspace to another. However, there is an &quot;unofficial&quot; tool that does most of the job with the main limitation being that notebook revisions linked to a run cannot be exported due to lack of a REST API endpoint for this.<\/p>\n<p><a href=\"https:\/\/github.com\/amesar\/mlflow-export-import\" rel=\"nofollow noreferrer\">https:\/\/github.com\/amesar\/mlflow-export-import<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1629787454223,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1595479476676,
        "Answerer_location":"Massachusetts, USA",
        "Answerer_reputation_count":246.0,
        "Answerer_view_count":21.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68812238",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"export model azur databrick azur devop artifact phase try creat mlop pipelin azur devop azur databrick azur devop submit databrick job cluster train machin learn model save model registri custom flavour pyfunc custom model job get want export object depend conda depend model file pkl python class load context predict function defin export import predict model export entir model save azuredevop artifact phase deploi ak cluster custom base imag",
        "Question_preprocessed_content":"export model azur databrick azur devop artifact phase try creat mlop pipelin azur devop azur databrick azur devop databrick job cluster train machin learn model save model registri custom flavour job get want export object export entir model save azuredevop artifact phase",
        "Question_gpt_summary_original":"The user is trying to create an MLOps Pipeline using Azure DevOps and Azure Databricks. They have trained a Machine Learning Model and saved it into MLFlow Model Registry with a custom flavour. The user wants to export this MLFlow Object with all dependencies and save it as an Azure DevOps Artifact to be used in the CD phase. They plan to deploy it to an AKS cluster with a custom base image.",
        "Question_gpt_summary":"user try creat mlop pipelin azur devop azur databrick train machin learn model save model registri custom flavour user want export object depend save azur devop artifact phase plan deploi ak cluster custom base imag"
    },
    {
        "Question_title":"Amazon SageMaker Local Mode raised boto3.exceptions.RetriesExceededError: Max Retries Exceeded",
        "Question_body":"I try to run the SageMaker local mode example without any modification at https:\/\/github.com\/aws-samples\/amazon-sagemaker-local-mode\/tree\/main\/pytorch_nlp_script_mode_local_model_inference on my local machine.\n\nHowever I encountered the **boto3.exceptions.RetriesExceededError: Max Retries Exceeded\n** exception when the example tries to deploy the inference endpoint to 'local' instance type.\n\nI checked with \n```\ndocker images -a \n```\ncommand and it does not pull the expected pre-built SageMaker deep learning container image from ECR. The code example is using a dummy role for the local SageMaker session. I need help as I am blocked at this point as the exception error message is not helpful to pinpoint the actual root cause of this issue. Thanks in advance.\n\nBelow are my configurations:\n\n* Ubuntu: **20.04.3 LTS**\n* AWS CLI version: **2.4.7**\n* Python: **3.8.12**\n* Docker: **20.10.12**\n* Docker Compose: **1.29.2**\n* boto3: **1.20.26**\n* sagemaker: **2.72.1**",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1640615850316,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668151057692,
        "Question_score_count":0.0,
        "Question_view_count":169.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUVLhj-0JzTUCLcs7yH5Kznw\/amazon-sagemaker-local-mode-raised-boto3-exceptions-retriesexceedederror-max-retries-exceeded",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"local mode rais boto except retriesexceedederror max retri exceed try run local mode exampl modif http github com aw sampl amazon local mode tree main pytorch nlp script mode local model infer local machin encount boto except retriesexceedederror max retri exceed except exampl tri deploi infer endpoint local instanc type check docker imag command pull expect pre built deep learn contain imag ecr code exampl dummi role local session need help block point except error messag help pinpoint actual root caus issu thank advanc configur ubuntu lt aw cli version python docker docker compos boto",
        "Question_preprocessed_content":"local mode rais max retri try run local mode exampl modif local machin encount max retri except exampl tri deploi infer endpoint local instanc type check expect learn contain imag ecr code exampl role local help block point except help pinpoint actual caus thank advanc configur ubuntu lt aw cli version python docker docker compos boto",
        "Question_gpt_summary_original":"The user encountered a \"boto3.exceptions.RetriesExceededError: Max Retries Exceeded\" error while trying to run the SageMaker local mode example without any modification on their local machine. The error occurred when the example tried to deploy the inference endpoint to the 'local' instance type. The user checked with the \"docker images -a\" command and found that it did not pull the expected pre-built SageMaker deep learning container image from ECR. The user is using a dummy role for the local SageMaker session and needs help to pinpoint the actual root cause of the issue.",
        "Question_gpt_summary":"user encount boto except retriesexceedederror max retri exceed error try run local mode exampl modif local machin error occur exampl tri deploi infer endpoint local instanc type user check docker imag command pull expect pre built deep learn contain imag ecr user dummi role local session need help pinpoint actual root caus issu"
    },
    {
        "Question_title":"Is there a solution for multi-user Notebook on SageMaker?",
        "Question_body":"Is there a solution for multi-user Notebook on Studio Notebook or Notebook Instances? Eg if we want several developers to interact on the same notebook at the same time",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1592989945000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668624634692,
        "Question_score_count":0.0,
        "Question_view_count":881.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Notebook instances are not connected to the user. So if two users has the same access rights they will see and will be able to access the same instance (even in the same time). \n\nThe issue is - Jupyter Notebook is not ready for that, both users will have the same privileges, no tracking who did what, ... And working on the same notebook on the same time - basically they will overwrite each other saves.\n\nI had a need for similar thing (pair programming - data scientist and software engineer) - the only viable solution we were able to find was desktop sharing (like TeamViewer, ...)",
        "Answer_comment_count":0.0,
        "Question_closed_time":1593009773000,
        "Answer_last_edit_time":1667925546486,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU4mxRvXy2QYmkYCvdqNVa2g\/is-there-a-solution-for-multi-user-notebook-on-sagemaker",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":1.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"solut multi user notebook solut multi user notebook studio notebook notebook instanc want develop interact notebook time",
        "Question_preprocessed_content":"solut solut studio instanc want develop interact time",
        "Question_gpt_summary_original":"The user is looking for a solution to enable multiple developers to work on the same notebook simultaneously on SageMaker's Studio Notebook or Notebook Instances.",
        "Question_gpt_summary":"user look solut enabl multipl develop work notebook simultan studio notebook notebook instanc"
    },
    {
        "Question_title":"mlflow How to save a sklearn pipeline with custom transformer?",
        "Question_body":"<p>I am trying to save with mlflow a sklearn machine-learning model, which is a pipeline containing a custom transformer I have defined, and load it in another project.\nMy custom transformer inherits from BaseEstimator and TransformerMixin.<\/p>\n\n<p>Let's say I have 2 projects:<\/p>\n\n<ul>\n<li>train_project: it has the custom transformers in src.ml.transformers.py<\/li>\n<li>use_project: it has other things in src, or has no src catalog at all<\/li>\n<\/ul>\n\n<p>So in my train_project I do :<\/p>\n\n<pre><code>mlflow.sklearn.log_model(preprocess_pipe, 'model\/preprocess_pipe')\n<\/code><\/pre>\n\n<p>and then when I try to load it into use_project :<\/p>\n\n<pre><code>preprocess_pipe = mlflow.sklearn.load_model(f'{ref_model_path}\/preprocess_pipe')\n<\/code><\/pre>\n\n<p>An error occurs :<\/p>\n\n<pre><code>[...]\nFile \"\/home\/quentin\/anaconda3\/envs\/api_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py\", line 210, in _load_model_from_local_file\n    return pickle.load(f)\nModuleNotFoundError: No module named 'train_project'\n<\/code><\/pre>\n\n<p>I tried to use format mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE :<\/p>\n\n<pre><code>mlflow.sklearn.log_model(preprocess_pipe, 'model\/preprocess_pipe', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n<\/code><\/pre>\n\n<p>but I get the same error during load.<\/p>\n\n<p>I saw option <strong>code_path<\/strong> into <strong>mlflow.pyfunc.log_model<\/strong> but its use and purpose is not clear to me. <\/p>\n\n<p>I thought mlflow provide a easy way to save model and serialize them so they can be used anywhere, Is that true only if you have native sklearn models (or keras, ...)?<\/p>\n\n<p>It's seem that this issue is more related to pickle functioning (mlflow use it and pickle needs to have all dependencies installed). <\/p>\n\n<p>The only solution I found so far is to make my transformer a package, import it in both project. Save version of my transformer library with <em>conda_env<\/em> argument of <em>log_model<\/em>, and check if it's same version when I load the model into my use_project.\nBut it's painfull if I have to change my transformer or debug in it...<\/p>\n\n<p>Is anybody have a better solution? \nMore elegent? Maybe there is some mlflow functionality I would have missed?<\/p>\n\n<p>other informations :<br>\nworking on linux (ubuntu)<br>\nmlflow=1.5.0<br>\npython=3.7.3   <\/p>\n\n<p>I saw in test of mlflow.sklearn api that they do a test with custom transformer, but they load it into the same file so it seems not resolve my issue but maybe it can helps other poeple :<\/p>\n\n<p><a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/tests\/sklearn\/test_sklearn_model_export.py\" rel=\"noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/tests\/sklearn\/test_sklearn_model_export.py<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1583338083850,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":8.0,
        "Question_view_count":3317.0,
        "Poster_created_time":1583251456143,
        "Poster_location":null,
        "Poster_reputation_count":81.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60530176",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save sklearn pipelin custom transform try save sklearn machin learn model pipelin contain custom transform defin load project custom transform inherit baseestim transformermixin let project train project custom transform src transform us project thing src src catalog train project sklearn log model preprocess pipe model preprocess pipe try load us project preprocess pipe sklearn load model ref model path preprocess pipe error occur file home quentin anaconda env api env lib python site packag sklearn line load model local file return pickl load modulenotfounderror modul name train project tri us format sklearn serial format cloudpickl sklearn log model preprocess pipe model preprocess pipe serial format sklearn serial format cloudpickl error load saw option code path pyfunc log model us purpos clear thought provid easi wai save model serial true nativ sklearn model kera issu relat pickl function us pickl need depend instal solut far transform packag import project save version transform librari conda env argument log model check version load model us project painful chang transform debug anybodi better solut eleg mayb function miss inform work linux ubuntu python saw test sklearn api test custom transform load file resolv issu mayb help poepl http github com blob master test sklearn test sklearn model export",
        "Question_preprocessed_content":"save sklearn pipelin custom transform try save sklearn model pipelin contain custom transform defin load project custom transform inherit transformermixin let project custom transform thing src src catalog try load tri us format load saw option us purpos clear thought provid easi wai save model serial true nativ sklearn model relat pickl function solut far transform packag import project save version transform librari argument check version load model chang transform debug anybodi solut eleg mayb function inform work linux saw test sklearn api test custom transform load file resolv mayb help poepl",
        "Question_gpt_summary_original":"The user is trying to save a machine learning model with a custom transformer using mlflow and load it into another project. However, an error occurs during loading, indicating that the module 'train_project' is not found. The user tried using the mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE option, but the error persists. The user is looking for a better solution to this issue and mentions that it may be related to the functioning of pickle. The only solution found so far is to make the transformer a package and import it in both projects.",
        "Question_gpt_summary":"user try save machin learn model custom transform load project error occur load indic modul train project user tri sklearn serial format cloudpickl option error persist user look better solut issu mention relat function pickl solut far transform packag import project"
    },
    {
        "Question_title":"Specify your own equation in ML.NET",
        "Question_body":"<p>Is there a way to specify your own equation when using ML.NET in Visual Studio?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1594911016883,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/48563\/specify-your-own-equation-in-ml-net",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"specifi equat net wai specifi equat net visual studio",
        "Question_preprocessed_content":"specifi equat wai specifi equat visual studio",
        "Question_gpt_summary_original":"The user is seeking information on whether it is possible to specify their own equation when using ML.NET in Visual Studio.",
        "Question_gpt_summary":"user seek inform possibl specifi equat net visual studio"
    },
    {
        "Question_title":"Using \"cv_splits_indices\" in AutoMLConfig (azureml)",
        "Question_body":"<p>When training an regression model with AutoMLConfig with n_cross_validations being a normal int, I'm facing no problems.<\/p>\n<p>Now I want to use TimeSeriesSplit as the cross validation method for training a model with AutoMLConfig. For this there is a &quot;cv_splits_indices&quot; argument where I put in a list of lists of indicis like the following when n_splits=5 in TimeSeriesSplit :<\/p>\n<pre><code>array([[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n        array([11, 12, 13, 14])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n        array([15, 16, 17, 18])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18]),\n        array([19, 20, 21, 22])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22]),\n        array([23, 24, 25, 26])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26]),\n        array([27, 28, 29, 30])]], dtype=object)\n<\/code><\/pre>\n<p>Unfortunately when running the following cell:<\/p>\n<pre><code>automl_settings = {\n    &quot;iteration_timeout_minutes&quot;: 15,\n    &quot;experiment_timeout_hours&quot;: 0.3,\n    &quot;max_cores_per_iteration&quot; : -1,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;primary_metric&quot;: 'normalized_root_mean_squared_error',\n    &quot;featurization&quot;: 'auto',\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;cv_splits_indices&quot;: idxs\n}\n\nautoml_config = AutoMLConfig(task='regression',\n                             debug_log=f'automated_ml_errors_.log',\n                             training_data=train,\n                             validation_data=train,\n                             label_column_name=y_var,\n                             **automl_settings)\n<\/code><\/pre>\n<p>I receive the following error:<\/p>\n<pre><code>ConfigException: ConfigException:\n Message: cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.\n InnerException: None\n ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.&quot;,\n        &quot;details_uri&quot;: &quot;https:\/\/aka.ms\/AutoMLConfig&quot;,\n        &quot;target&quot;: &quot;cv_splits_indices&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;BadArgument&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;ArgumentInvalid&quot;\n            }\n        },\n        &quot;reference_code&quot;: &quot;XXXXXXREDACTEDXXXX&quot;\n    }\n}\n<\/code><\/pre>\n<p>What is going wrong here? Does my input look correct?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1614847805423,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1614857962623,
        "Question_score_count":1.0,
        "Question_view_count":37.0,
        "Poster_created_time":1506851088052,
        "Poster_location":"Vlaardingen, Netherlands",
        "Poster_reputation_count":175.0,
        "Poster_view_count":56.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66471547",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"split indic automlconfig train regress model automlconfig cross valid normal int face problem want us timeseriessplit cross valid method train model automlconfig split indic argument list list indici like follow split timeseriessplit arrai arrai arrai arrai arrai arrai arrai arrai arrai arrai arrai dtype object unfortun run follow cell automl set iter timeout minut experi timeout hour max core iter enabl earli stop true primari metric normal root mean squar error featur auto verbos log info split indic idx automl config automlconfig task regress debug log autom error log train data train valid data train label column var automl set receiv follow error configexcept configexcept messag split indic list list numpi ndarrai list numpi ndarrai correspond fold element indic train set valid set innerexcept errorrespons error code usererror messag split indic list list numpi ndarrai list numpi ndarrai correspond fold element indic train set valid set detail uri http aka automlconfig target split indic inner error code badargu inner error code argumentinvalid refer code xxxxxxredactedxxxx go wrong input look correct",
        "Question_preprocessed_content":"automlconfig train model automlconfig normal int face problem want us valid method train model automlconfig argument list list indici like unfortun receiv go wrong input",
        "Question_gpt_summary_original":"The user is facing an issue while using the \"cv_splits_indices\" argument in AutoMLConfig for training a regression model with TimeSeriesSplit as the cross-validation method. The user is receiving a ConfigException error stating that the \"cv_splits_indices\" argument should be a List of List[numpy.ndarray] with just 2 elements for each CV fold, but the user's input does not match this format.",
        "Question_gpt_summary":"user face issu split indic argument automlconfig train regress model timeseriessplit cross valid method user receiv configexcept error state split indic argument list list numpi ndarrai element fold user input match format"
    },
    {
        "Question_title":"Customize metric visualization in MLFlow UI when using mlflow.tensorflow.autolog()",
        "Question_body":"<p>I'm trying to integrate MLFlow to my project. Because I'm using <code>tf.keras.fit_generator()<\/code> for my training so I take advantage of <code>mlflow.tensorflow.autolog()<\/code>(<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.tensorflow.html#mlflow.tensorflow.autolog\" rel=\"nofollow noreferrer\">docs<\/a> here) to enable automatic logging of metrics and parameters:<\/p>\n<pre><code>    model = Unet()\n    optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n\n    metrics = [IOUScore(threshold=0.5), FScore(threshold=0.5)]\n    model.compile(optimizer, customized_loss, metrics)\n\n    callbacks = [\n        tf.keras.callbacks.ModelCheckpoint(&quot;model.h5&quot;, save_weights_only=True, save_best_only=True, mode='min'),\n        tf.keras.callbacks.TensorBoard(log_dir='.\/logs', profile_batch=0, update_freq='batch'),\n    ]\n\n\n    train_dataset = Dataset(src_dir=SOURCE_DIR)\n\n    train_data_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n\n   \n    with mlflow.start_run():\n        mlflow.tensorflow.autolog()\n        mlflow.log_param(&quot;batch_size&quot;, BATCH_SIZE)\n\n        model.fit_generator(\n            train_data_loader,\n            steps_per_epoch=len(train_data_loader),\n            epochs=EPOCHS,\n            callbacks=callbacks   \n            )\n<\/code><\/pre>\n<p>I expected something like this (just a demonstration taken from the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#visualizing-metrics\" rel=\"nofollow noreferrer\">docs<\/a>):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eG56Z.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eG56Z.png\" alt=\"Visualization on the docs\" \/><\/a><\/p>\n<p>However, after the training finished, this is what I got:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/fS1JD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fS1JD.png\" alt=\"f1_score visualization\" \/><\/a><\/p>\n<p>How can I configure so that the metric plot will update and display its value at each epoch instead of just showing the latest value?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1593764146630,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1594008626392,
        "Question_score_count":2.0,
        "Question_view_count":1035.0,
        "Poster_created_time":1467943515392,
        "Poster_location":"Danang, H\u1ea3i Ch\u00e2u District, Da Nang, Vietnam",
        "Poster_reputation_count":173.0,
        "Poster_view_count":28.0,
        "Answer_body":"<p>After searching around, I found <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/2390\" rel=\"nofollow noreferrer\">this issue<\/a> related to my problem above. Actually, all my metrics just logged once each training (instead of each epoch as my intuitive thought). The reason is I didn't specify the <code>every_n_iter<\/code> parameter in <code>mlflow.tensorflow.autolog()<\/code>, which indicates how many 'iterations' must pass before MLflow logs metric executed (see the <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tensorflow.html#mlflow.tensorflow.autolog\" rel=\"nofollow noreferrer\">docs<\/a>). So, changing my code to:<\/p>\n<p><code>mlflow.tensorflow.autolog(every_n_iter=1)<\/code><\/p>\n<p>fixed the problem.<\/p>\n<p>P\/s: Remember that in TF 2.x, an 'iteration' is an epoch (in TF 1.x it's a batch).<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1594008525280,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1467943515392,
        "Answerer_location":"Danang, H\u1ea3i Ch\u00e2u District, Da Nang, Vietnam",
        "Answerer_reputation_count":173.0,
        "Answerer_view_count":28.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62711259",
        "Tool":"MLflow",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"custom metric visual tensorflow autolog try integr project kera fit gener train advantag tensorflow autolog doc enabl automat log metric paramet model unet optim kera optim adam learn rate metric iouscor threshold fscore threshold model compil optim custom loss metric callback kera callback modelcheckpoint model save weight true save best true mode min kera callback tensorboard log dir log profil batch updat freq batch train dataset dataset src dir sourc dir train data loader dataload train dataset batch size shuffl true start run tensorflow autolog log param batch size batch size model fit gener train data loader step epoch len train data loader epoch epoch callback callback expect like demonstr taken doc train finish got configur metric plot updat displai valu epoch instead show latest valu",
        "Question_preprocessed_content":"custom metric visual try integr project train advantag enabl automat metric paramet expect like train finish got configur metric plot updat displai valu epoch instead show latest valu",
        "Question_gpt_summary_original":"The user is trying to integrate MLFlow into their project and is using mlflow.tensorflow.autolog() to enable automatic logging of metrics and parameters. They expected a visualization of metrics to be displayed at each epoch during training, but instead, only the latest value is shown. The user is seeking guidance on how to configure the metric plot to update and display its value at each epoch.",
        "Question_gpt_summary":"user try integr project tensorflow autolog enabl automat log metric paramet expect visual metric displai epoch train instead latest valu shown user seek guidanc configur metric plot updat displai valu epoch"
    },
    {
        "Question_title":"Missing delimiter error when importing html text",
        "Question_body":"<p>Playing with Azure Machine Learning using the Designer and am getting a &quot;Delimiter not found&quot; error when importing my data.<\/p>\n<p>I originally started with a few hundred html files stored as azure blobs. Each file would be considered a single row of text, however, I had no luck importing these files for further text analytics.<\/p>\n<p>I created a Data Factory job that imported each file, stripped all the tabs, quotes, cr\/lf from the text, added a column for the file name and stored it all as a combined tab-delimited file. In notepad++ I can confirm that the format is <code>FileName tab HtmlText<\/code>. This is the file I'm trying to import into ML and getting the missing delimiter message as I'm trying to define the import module.<\/p>\n<p>Here is the error when I try and create a dataset:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>{\n  &quot;message&quot;: &quot;'Delimiter' is not specified or invalid.&quot;\n}\n<\/code><\/pre>\n<p>Question 1: Is there a better way to do text analytics on a large collection of html files?<\/p>\n<p>Question 2: Is there a format I need to use in my combined .tsv file that works?<\/p>\n<p>Question 3: Is there maybe a max length to the string column? My html can be 10's of thousands of characters long.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1598396437553,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1598498523072,
        "Question_score_count":0.0,
        "Question_view_count":209.0,
        "Poster_created_time":1221591235460,
        "Poster_location":null,
        "Poster_reputation_count":936.0,
        "Poster_view_count":105.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63588251",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"miss delimit error import html text plai design get delimit error import data origin start html file store azur blob file consid singl row text luck import file text analyt creat data factori job import file strip tab quot text ad column file store combin tab delimit file notepad confirm format filenam tab htmltext file try import get miss delimit messag try defin import modul error try creat dataset messag delimit specifi invalid question better wai text analyt larg collect html file question format need us combin tsv file work question mayb max length string column html thousand charact long",
        "Question_preprocessed_content":"delimit import html text plai design delimit import data start html file store azur blob file consid singl row text luck import file text analyt creat data factori job import file tab quot text column file store combin file notepad confirm format file try import delimit try defin import modul try creat dataset question wai text analyt larg html file question format us combin tsv file work question mayb max length string column html thousand charact long",
        "Question_gpt_summary_original":"The user is encountering a \"Delimiter not found\" error when trying to import a combined tab-delimited file containing html text into Azure Machine Learning. They had previously imported hundreds of html files stored as azure blobs, but were unable to use them for text analytics. The user is seeking advice on a better way to perform text analytics on a large collection of html files, the correct format for the combined .tsv file, and whether there is a maximum length for the string column.",
        "Question_gpt_summary":"user encount delimit error try import combin tab delimit file contain html text previous import hundr html file store azur blob unabl us text analyt user seek advic better wai perform text analyt larg collect html file correct format combin tsv file maximum length string column"
    },
    {
        "Question_title":"SageMaker Distributed Training in Local Mode (inside Notebook Instances)",
        "Question_body":"<p>I've been using SageMaker for a while and have performed several experiments already with distributed training. I am wondering if it is possible to test and run SageMaker distributed training in local mode (using SageMaker Notebook Instances)?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662649911493,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":19.0,
        "Poster_created_time":1662649653072,
        "Poster_location":null,
        "Poster_reputation_count":3.0,
        "Poster_view_count":1.0,
        "Answer_body":"<p>No, not possible yet. <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/overview.html#local-mode\" rel=\"nofollow noreferrer\">local mode<\/a> does not support the distributed training with <code>local_gpu<\/code>for Gzip compression, Pipe Mode, or manifest files for inputs<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1662652096572,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1662621266503,
        "Answerer_location":null,
        "Answerer_reputation_count":48.0,
        "Answerer_view_count":6.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73651368",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"distribut train local mode insid notebook instanc perform experi distribut train wonder possibl test run distribut train local mode notebook instanc",
        "Question_preprocessed_content":"distribut train local mode perform experi distribut train wonder test run distribut train local mode",
        "Question_gpt_summary_original":"The user is familiar with SageMaker and has performed distributed training experiments. They are now seeking to know if it is possible to test and run SageMaker distributed training in local mode using SageMaker Notebook Instances.",
        "Question_gpt_summary":"user familiar perform distribut train experi seek know possibl test run distribut train local mode notebook instanc"
    },
    {
        "Question_title":"Getting stuck on SageMaker domain creation through the standard setup wizard",
        "Question_body":"I am having difficulty in getting started on SageMaker Studio using the Standard setup wizard of SageMaker Domain creation. The wizard prevents me from moving forward at the RStudio setup step even though RStudio is indicated to be optional and which I don't need or want to pay for.  I have tried a lot of things (looked at the videos, searched the web) to no avail. Tried as a root user as well as a IAM user and have the same issue. Thanks for any help.",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1650593854106,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668428257768,
        "Question_score_count":0.0,
        "Question_view_count":456.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUaiMX9ZU3SdqFnjxiNn_XRg\/getting-stuck-on-sagemaker-domain-creation-through-the-standard-setup-wizard",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"get stuck domain creation standard setup wizard have difficulti get start studio standard setup wizard domain creation wizard prevent move forward rstudio setup step rstudio indic option need want pai tri lot thing look video search web avail tri root user iam user issu thank help",
        "Question_preprocessed_content":"stuck domain creation standard setup wizard have start studio standard setup wizard domain creation wizard prevent move forward rstudio setup step rstudio indic option want pai tri lot thing avail tri user iam user thank help",
        "Question_gpt_summary_original":"The user is facing challenges while creating a SageMaker domain through the standard setup wizard. The user is unable to proceed beyond the RStudio setup step, even though it is optional and not required. The user has tried various solutions but has not been successful.",
        "Question_gpt_summary":"user face challeng creat domain standard setup wizard user unabl proce rstudio setup step option requir user tri solut success"
    },
    {
        "Question_title":"Azure ML Studio Error CammandLine exceeds Limit",
        "Question_body":"<p>I am setting up ML experiment in Azure ML Studio Designer for K-Means Clustering and have ~750 attributes that I am attempting to cluster with ~4000 rows.    <\/p>\n<p>When i go to execute this i get the following error:    <\/p>\n<p>AzureMLCompute job failed. InvalidPropertyValue: The size of the specified property Job.Properties.CustomToolkitSettings.CommandLine exceeds the limit of 20480 characters    <\/p>\n<p>There isn't much on this error but would someone be able to assist me on how to increase the limit? I don't believe this is an K-Means error but a Azure ML Studio error.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":6.0,
        "Question_created_time":1657656469800,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/924104\/azure-ml-studio-error-cammandline-exceeds-limit",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio error cammandlin exce limit set experi studio design mean cluster attribut attempt cluster row execut follow error comput job fail invalidpropertyvalu size specifi properti job properti customtoolkitset commandlin exce limit charact isn error abl assist increas limit believ mean error studio error",
        "Question_preprocessed_content":"studio limit experi studio design cluster cluster row execut comput job fail invalidpropertyvalu size specifi properti limit charact isn abl increas limit believ studio",
        "Question_gpt_summary_original":"The user is encountering an error while setting up an ML experiment in Azure ML Studio Designer for K-Means Clustering. The error message states that the size of the specified property Job.Properties.CustomToolkitSettings.CommandLine exceeds the limit of 20480 characters. The user is seeking assistance on how to increase the limit.",
        "Question_gpt_summary":"user encount error set experi studio design mean cluster error messag state size specifi properti job properti customtoolkitset commandlin exce limit charact user seek assist increas limit"
    },
    {
        "Question_title":"Delete account?",
        "Question_body":"<p>Hi, I want my account deleted as I want to be removed from all teams I am currently in (changed jobs). I cannot delete my account since I\u2019m a billing user for some reason (I don\u2019t get charged at all by wandb so not sure why?) My username is aharakeh. Thanks!<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1668211211695,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":421.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/delete-account\/3412",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"delet account want account delet want remov team current chang job delet account bill user reason dont charg sure usernam aharakeh thank",
        "Question_preprocessed_content":"delet want delet want remov team delet user reason usernam aharakeh thank",
        "Question_gpt_summary_original":"The user wants to delete their account as they have changed jobs and want to be removed from all teams they are currently in. However, they are unable to delete their account as they are a billing user, even though they are not being charged by wandb.",
        "Question_gpt_summary":"user want delet account chang job want remov team current unabl delet account bill user charg"
    },
    {
        "Question_title":"[Vertex AI] Bug - Failed to download file",
        "Question_body":"Vertex AI recently fails to download any file greater than 30M. Any downloaded file will be trimmed at 30M. The download speed is also way slower recently (200k\/s). It was working a few days ago. (downloads files of 100+M at 5M\/s) Any ideas?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1657179300000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":352.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Bug-Failed-to-download-file\/m-p\/439222#M406",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"bug fail download file recent fail download file greater download file trim download speed wai slower recent work dai ago download file idea",
        "Question_preprocessed_content":"bug fail download file recent fail download file greater download file download wai slower recent work dai ago idea",
        "Question_gpt_summary_original":"The user is facing a bug in Vertex AI where they are unable to download files greater than 30MB and the download speed has significantly decreased to 200k\/s. This issue has occurred recently as it was working fine a few days ago, where they were able to download files of 100+MB at 5M\/s.",
        "Question_gpt_summary":"user face bug unabl download file greater download speed significantli decreas issu occur recent work fine dai ago abl download file"
    },
    {
        "Question_title":"Mlflow integration with Google's Vertex AI",
        "Question_body":"Hi,\n\n\n\u00a0 Is there any way through which we can integrate mlflow with vertex AI ?\u00a0\nAny articles or resources I can go through ?\n\nThanks\nAvinash",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1645165866000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":107.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/q9759ED2C2A",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"integr googl wai integr articl resourc thank avinash",
        "Question_preprocessed_content":"integr wai integr articl resourc thank avinash",
        "Question_gpt_summary_original":"The user is seeking information on how to integrate mlflow with Google's Vertex AI and is looking for any relevant articles or resources.",
        "Question_gpt_summary":"user seek inform integr googl look relev articl resourc"
    },
    {
        "Question_title":"how to get started about analysing time series with Azure?",
        "Question_body":"<p>We have a large amount of time series that get updated each month or week and would like to use some Azure based machine learning to QC this.  <\/p>\n<p>Having no practical experience of machine learning or azure, could you point me where\/how I could get started, please?  <\/p>\n<p>Our data itself is located on the cloud in a Snowflake database.  <\/p>\n<p>Many Thanks   <\/p>\n<p>Eric  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1611334374593,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/241953\/how-to-get-started-about-analysing-time-series-wit",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"start analys time seri azur larg time seri updat month week like us azur base machin learn have practic experi machin learn azur point start data locat cloud snowflak databas thank eric",
        "Question_preprocessed_content":"start analys time seri azur larg time seri updat month like us azur base machin learn have practic experi machin learn azur point start data locat cloud snowflak databas thank eric",
        "Question_gpt_summary_original":"The user is seeking guidance on how to use Azure-based machine learning to analyze a large amount of time series data that is updated monthly or weekly. They have no practical experience with machine learning or Azure and their data is located on the cloud in a Snowflake database.",
        "Question_gpt_summary":"user seek guidanc us azur base machin learn analyz larg time seri data updat monthli weekli practic experi machin learn azur data locat cloud snowflak databas"
    },
    {
        "Question_title":"Which algorithm is better for recommendation system design",
        "Question_body":"<p>Hello, I am new to machine learning, I want to design a recommendation system by azure machine learning studio, I am not sure which model I should apply to achieve this, can I get some help or information here?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1679952454270,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1193654\/which-algorithm-is-better-for-recommendation-syste",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"algorithm better recommend design hello new machin learn want design recommend studio sure model appli achiev help inform",
        "Question_preprocessed_content":"algorithm design new machin learn want design studio sure model achiev help inform",
        "Question_gpt_summary_original":"The user is new to machine learning and wants to design a recommendation system using Azure Machine Learning Studio but is unsure which algorithm to use and is seeking help and information.",
        "Question_gpt_summary":"user new machin learn want design recommend studio unsur algorithm us seek help inform"
    },
    {
        "Question_title":"Can not pull public ECR image using AWS SageMaker Estimator",
        "Question_body":"<p>I would like to pass a public Docker Image on ECR through the image_uri parameter to the Estimator. However, the training job fails to find this image.\nI'm running my code using AWS SageMaker Notebook instance.<\/p>\n<pre><code>from sagemaker.estimator import Estimator\n\nbyoc_image_uri = 'public.ecr.aws\/v8x6t9d9\/train-image-classifier-firefly'\n\nestimator = Estimator(image_uri=byoc_image_uri,\n                      role=role,\n                      base_job_name='tf-custom-container-test-job',\n                      instance_count=1,\n                      hyperparameters=hyperparameters,\n                      output_path=output_path,\n                      instance_type='ml.p2.xlarge')\n<\/code><\/pre>\n<p>What I have tried:<\/p>\n<ul>\n<li>I first tried to use the same image on an ECR privet repo. This works<\/li>\n<li>Then pushed the same image to a public ECR repo that I had created. The image was successfully pushed and I could pull this image successfully.<\/li>\n<li>However, when I tried to use the same image url through Estimator image_uri parameter. I get the following error message<\/li>\n<\/ul>\n<pre><code>    ClientError: An error occurred (ValidationException) when calling the CreateTrainingJob operation: TrainingImageConfig with TrainingRepositoryAccessMode set to VPC must be provided when using a training image from a private Docker registry. Please provideTrainingImageConfig and TrainingRepositoryAccessMode set to VPC when using a training image from a private Docker registry.\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1631756389253,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1632521317307,
        "Question_score_count":1.0,
        "Question_view_count":396.0,
        "Poster_created_time":1631755332636,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69201461",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pull public ecr imag estim like pass public docker imag ecr imag uri paramet estim train job fail imag run code notebook instanc estim import estim byoc imag uri public ecr aw vxtd train imag classifi firefli estim estim imag uri byoc imag uri role role base job custom contain test job instanc count hyperparamet hyperparamet output path output path instanc type xlarg tri tri us imag ecr privet repo work push imag public ecr repo creat imag successfulli push pull imag successfulli tri us imag url estim imag uri paramet follow error messag clienterror error occur validationexcept call createtrainingjob oper trainingimageconfig trainingrepositoryaccessmod set vpc provid train imag privat docker registri providetrainingimageconfig trainingrepositoryaccessmod set vpc train imag privat docker registri",
        "Question_preprocessed_content":"public ecr imag estim like public docker imag ecr paramet estim train job fail imag code instanc tri tri us imag ecr privet repo work push imag public ecr repo creat imag push imag tri us imag url estim paramet",
        "Question_gpt_summary_original":"The user is unable to pull a public Docker image from ECR using AWS SageMaker Estimator. The training job fails to find the image, and the user receives an error message stating that TrainingImageConfig with TrainingRepositoryAccessMode set to VPC must be provided when using a training image from a private Docker registry. The user has tried using the same image on a private ECR repo, which works, but encounters issues when using a public ECR repo.",
        "Question_gpt_summary":"user unabl pull public docker imag ecr estim train job fail imag user receiv error messag state trainingimageconfig trainingrepositoryaccessmod set vpc provid train imag privat docker registri user tri imag privat ecr repo work encount issu public ecr repo"
    },
    {
        "Question_title":"AzureMLCompute job failed with `FailedLoginToImageRegistry`",
        "Question_body":"<p>I've been trying to send a train job through azure ml python sdk with:<\/p>\n<pre><code>from azureml.core import Workspace, Experiment, ScriptRunConfig \n\nif __name__ == &quot;__main__&quot;:\n    ws = Workspace.from_config()\n    experiment = Experiment(workspace=ws, name='ConstructionTopicsModel')\n\n    config = ScriptRunConfig(source_directory='.\/',\n                         script='src\/azureml\/train.py',\n                         arguments=None,\n                         compute_target='ComputeTargetName',\n                         )\n\n    env = ws.environments['test-env']\n    config.run_config.environment = env\n    run = experiment.submit(config)\n    \n    run.wait_for_completion(show_output=True)\n\n    aml_url = run.get_portal_url()\n    print(aml_url)\n<\/code><\/pre>\n<p>But I was getting the <code>ServiceError<\/code> message:<\/p>\n<pre><code>AzureMLCompute job failed. FailedLoginToImageRegistry: Unable to login to docker image repo\nReason: Failed to login to the docker registry\nerror: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nserviceURL: 7ac86b04d6564d36aa80ae2ad090582c.azurecr.io\nReason: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n<\/code><\/pre>\n<p>I also tried using the azure cli without success, same error message<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1643645330913,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":202.0,
        "Poster_created_time":1589293508567,
        "Poster_location":null,
        "Poster_reputation_count":833.0,
        "Poster_view_count":55.0,
        "Answer_body":"<p>The only way I've found so far to make this work, was to run it on a terminal of the compute-target itself. That's how the docker error goes away. Trying to run the experiment from a terminal of a different compute instance raises the exception.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1643645330912,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1589293508567,
        "Answerer_location":null,
        "Answerer_reputation_count":833.0,
        "Answerer_view_count":55.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70929123",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"comput job fail failedlogintoimageregistri try send train job python sdk core import workspac experi scriptrunconfig main workspac config experi experi workspac constructiontopicsmodel config scriptrunconfig sourc directori script src train argument comput target computetargetnam env environ test env config run config environ env run experi submit config run wait complet output true aml url run portal url print aml url get serviceerror messag comput job fail failedlogintoimageregistri unabl login docker imag repo reason fail login docker registri error warn password cli insecur us password stdin error save credenti error store credenti err exit statu autolaunch bu displai serviceurl acbddaaaeadc azurecr reason warn password cli insecur us password stdin error save credenti error store credenti err exit statu autolaunch bu displai info fail setup runtim job execut job environ prepar fail err exit statu tri azur cli success error messag",
        "Question_preprocessed_content":"comput job fail try send train job python sdk tri azur cli",
        "Question_gpt_summary_original":"The user encountered an issue while trying to send a train job through Azure ML Python SDK. The job failed with a \"FailedLoginToImageRegistry\" error message, indicating that the user was unable to login to the docker image repo. The error message also suggested using \"--password-stdin\" instead of \"--password\" via the CLI. The user also tried using the Azure CLI but encountered the same error message.",
        "Question_gpt_summary":"user encount issu try send train job python sdk job fail failedlogintoimageregistri error messag indic user unabl login docker imag repo error messag suggest password stdin instead password cli user tri azur cli encount error messag"
    },
    {
        "Question_title":"Response From AWS SageMaker InvokeEndpoint Returning NULL Body (Guzzle Stream) (AWS SDK for PHP)",
        "Question_body":"<p>I am using the AWS PHP SDK to retrieve a prediction from a SageMaker Model.  The response comes back as successful, however, the body is a Null or Guzzle stream.  I know it's getting the prediction successfully since the content-length value is exactly the same as what I get when using the AWS CLI to run the prediction (which works fine).  Below is my code as well as the $result object.  I have also tested adding the &quot;accept&quot; field to the InvokeEndpoint with various MIME types with no success.  If anyone has run into similar issues please let me know!<\/p>\n<p>Any help is greatly appreciated!<\/p>\n<p><strong>Code<\/strong><\/p>\n<pre><code>use Aws\\SageMakerRuntime\\SageMakerRuntimeClient;\n\n\/\/ Build Client\n$client = new Aws\\SageMakerRuntime\\SageMakerRuntimeClient([\n                        'region' =&gt; 'us-east-1',\n                        'version' =&gt; &quot;latest&quot;,\n                        'credentials' =&gt; [\n                            'key'    =&gt; 'XXXXXXXXXXXXXX',\n                            'secret' =&gt; 'XXXXXXXXXXXXXX',\n                        ]\n]);\n\n\/\/ Invoke Endpoint\n$result = $client-&gt;invokeEndpoint([\n    'Body' =&gt; '{&quot;instances&quot;: [{&quot;in0&quot;:[13127,Sunrise Tells The Story,Midland,605,1\/16\/22,50,2197,9329,2071,53,574,39,483,122]}]}',\n    'ContentType' =&gt; 'text\/csv',\n    'EndpointName' =&gt; 'Sagemaker-Before-10-24-21'\n]);\n<\/code><\/pre>\n<p><strong>Result<\/strong><\/p>\n<pre><code>object(Aws\\Result)#124 (2) {\n  [&quot;data&quot;:&quot;Aws\\Result&quot;:private]=&gt;\n  array(5) {\n    [&quot;Body&quot;]=&gt;\n    object(GuzzleHttp\\Psr7\\Stream)#119 (7) {\n      [&quot;stream&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      resource(9) of type (stream)\n      [&quot;size&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      NULL\n      [&quot;seekable&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      bool(true)\n      [&quot;readable&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      bool(true)\n      [&quot;writable&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      bool(true)\n      [&quot;uri&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      string(10) &quot;php:\/\/temp&quot;\n      [&quot;customMetadata&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      array(0) {\n      }\n    }\n    [&quot;ContentType&quot;]=&gt;\n    string(23) &quot;text\/csv; charset=utf-8&quot;\n    [&quot;InvokedProductionVariant&quot;]=&gt;\n    string(17) &quot;AllTrafficVariant&quot;\n    [&quot;CustomAttributes&quot;]=&gt;\n    string(0) &quot;&quot;\n    [&quot;@metadata&quot;]=&gt;\n    array(4) {\n      [&quot;statusCode&quot;]=&gt;\n      int(200)\n      [&quot;effectiveUri&quot;]=&gt;\n      string(105) &quot;https:\/\/runtime.sagemaker.us-east-1.amazonaws.com\/endpoints\/Before-10-24-21\/invocations&quot;\n      [&quot;headers&quot;]=&gt;\n      array(5) {\n        [&quot;x-amzn-requestid&quot;]=&gt;\n        string(36) &quot;e523ea41-0bd9-4bcd-9a80-8b5e3f710bbf&quot;\n        [&quot;x-amzn-invoked-production-variant&quot;]=&gt;\n        string(17) &quot;AllTrafficVariant&quot;\n        [&quot;date&quot;]=&gt;\n        string(29) &quot;Mon, 24 Jan 2022 15:22:54 GMT&quot;\n        [&quot;content-type&quot;]=&gt;\n        string(23) &quot;text\/csv; charset=utf-8&quot;\n        [&quot;content-length&quot;]=&gt;\n        string(2) &quot;18&quot;\n      }\n      [&quot;transferStats&quot;]=&gt;\n      array(1) {\n        [&quot;http&quot;]=&gt;\n        array(1) {\n          [0]=&gt;\n          array(0) {\n          }\n        }\n      }\n    }\n  }\n  [&quot;monitoringEvents&quot;:&quot;Aws\\Result&quot;:private]=&gt;\n  array(0) {\n  }\n}\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1643038641057,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":173.0,
        "Poster_created_time":1538025294107,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70836427",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"respons invokeendpoint return null bodi guzzl stream aw sdk php aw php sdk retriev predict model respons come success bodi null guzzl stream know get predict successfulli content length valu exactli aw cli run predict work fine code result object test ad accept field invokeendpoint mime type success run similar issu let know help greatli appreci code us aw runtim runtimecli build client client new aw runtim runtimecli region east version latest credenti kei xxxxxxxxxxxxxx secret xxxxxxxxxxxxxx invok endpoint result client invokeendpoint bodi instanc sunris tell stori midland contenttyp text csv endpointnam result object aw result data aw result privat arrai bodi object guzzlehttp psr stream stream guzzlehttp psr stream privat resourc type stream size guzzlehttp psr stream privat null seekabl guzzlehttp psr stream privat bool true readabl guzzlehttp psr stream privat bool true writabl guzzlehttp psr stream privat bool true uri guzzlehttp psr stream privat string php temp custommetadata guzzlehttp psr stream privat arrai contenttyp string text csv charset utf invokedproductionvari string alltrafficvari customattribut string metadata arrai statuscod int effectiveuri string http runtim east amazonaw com endpoint invoc header arrai amzn requestid string eea bcd befbbf amzn invok product variant string alltrafficvari date string mon jan gmt content type string text csv charset utf content length string transferstat arrai http arrai arrai monitoringev aw result privat arrai",
        "Question_preprocessed_content":"respons return bodi aw php sdk retriev predict model respons come bodi stream know predict valu exactli aw cli run predict code result object test field mime type run similar let know help greatli code result",
        "Question_gpt_summary_original":"The user is using the AWS PHP SDK to retrieve a prediction from a SageMaker Model, but the response comes back as successful with a Null or Guzzle stream body. The content-length value is the same as what the user gets when using the AWS CLI to run the prediction. The user has tested adding the \"accept\" field to the InvokeEndpoint with various MIME types with no success.",
        "Question_gpt_summary":"user aw php sdk retriev predict model respons come success null guzzl stream bodi content length valu user get aw cli run predict user test ad accept field invokeendpoint mime type success"
    },
    {
        "Question_title":"Short polish inputs recognized but not returned by ASR.",
        "Question_body":"Hi,\n\n\u00a0\nWe're currently working with dialogflow CX and everything's running smoothly, except for the fact that whenever we answer with short polish words, e.g. \"tak\", \"nie\", the ASR system or STT recognizes it, but doesn't return it. Instead, it waits as if the client was still talking, once you repeat the phrase for some time or input a longer phrase, it returns it almost instantly.\u00a0\n\u00a0\nAny ideas of the fix? Has anybody experienced anything similar?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1663809540000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":56.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Short-polish-inputs-recognized-but-not-returned-by-ASR\/m-p\/469439#M590",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"short polish input recogn return asr current work dialogflow run smoothli fact answer short polish word tak nie asr stt recogn return instead wait client talk repeat phrase time input longer phrase return instantli idea fix anybodi experienc similar",
        "Question_preprocessed_content":"short polish input recogn return asr work dialogflow fact answer short polish word tak nie asr recogn return instead wait client talk repeat phrase time input longer phrase return instantli idea fix anybodi experienc similar",
        "Question_gpt_summary_original":"The user is facing an issue with the ASR system or STT in Dialogflow CX where short Polish words are recognized but not returned. The system waits as if the client is still talking and only returns the input after repeating the phrase for some time or inputting a longer phrase. The user is seeking a fix for this issue and asking if anyone has experienced something similar.",
        "Question_gpt_summary":"user face issu asr stt dialogflow short polish word recogn return wait client talk return input repeat phrase time input longer phrase user seek fix issu ask experienc similar"
    },
    {
        "Question_title":"How to integrate ML model with excel sheet containing 400k image links",
        "Question_body":"I created a model to identify good or bad profile images for a company, Data is in excel sheet with 400k+ links, I don't want to download all the images. I'm looking for another method in which one can run ML model on excel sheet. Is there anyone who has done this before or know the method? I created the model on Jupyter notebook, I don't know where to deploy the model to get the API key. Any reference will be apricated.",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1681192800000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":44.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-integrate-ML-model-with-excel-sheet-containing-400k-image\/m-p\/542553#M1628",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"integr model excel sheet contain imag link creat model identifi good bad profil imag compani data excel sheet link want download imag look method run model excel sheet know method creat model jupyt notebook know deploi model api kei refer apric",
        "Question_preprocessed_content":"integr model excel contain imag link creat model identifi bad profil imag compani data excel link want download imag method run model excel know method creat model jupyt know deploi model api kei refer apric",
        "Question_gpt_summary_original":"The user has created an ML model to identify good or bad profile images for a company, but the data is in an Excel sheet with 400k+ links and they do not want to download all the images. They are looking for a method to run the ML model on the Excel sheet and are seeking advice on where to deploy the model to get the API key.",
        "Question_gpt_summary":"user creat model identifi good bad profil imag compani data excel sheet link want download imag look method run model excel sheet seek advic deploi model api kei"
    },
    {
        "Question_title":"Connect Lambda function within VPC to Sagemaker Serverless Inference Endpoint",
        "Question_body":"Hello! \n\nI have a Lambda function which needs to connect to a MySQL RDS instance which is within a private VPC. The Lambda function also needs to connect to a Sagemaker Serverless Inference Endpoint, taking data from the RDS instance and passing it to a Sagemaker model for inference. \n\nI have tested a vanilla Lambda function from outside of the private VPC to connect to the Sagemaker Endpoint which was successful. However, in order for Lambda to access data from the RDS database, I have associated the Lambda function with the same private VPC and subnets as the RDS instance. As a result, the Lambda function can no longer access the Sagemaker Endpoint as it now lies within the private VPC. \n\nI need advice on **how to create a VPC Interface Endpoint** to enable the Lambda function to access the Sagemaker Endpoint, and on** how to build the associated security groups** to enable the network access. I am unsure of how to implement the VPC Interface Endpoint or how to implement the correct security groups, so I would appreciate advice on the implementation. \n\nAs an alternative architecture, I could create two lambda functions: one which is associated with the private VPC and connects to the RDS instance then stores the required data in an S3 bucket; and another lambda function which is not within the VPC which pulls the data from the S3 bucket and serves it to the Sagemaker Endpoint. **Would this be a better option? **",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1682612681713,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1682959694208,
        "Question_score_count":0.0,
        "Question_view_count":53.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU3hIvhm-IRiG4uElDlq7jBg\/connect-lambda-function-within-vpc-to-sagemaker-serverless-inference-endpoint",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect lambda function vpc serverless infer endpoint hello lambda function need connect mysql rd instanc privat vpc lambda function need connect serverless infer endpoint take data rd instanc pass model infer test vanilla lambda function outsid privat vpc connect endpoint success order lambda access data rd databas associ lambda function privat vpc subnet rd instanc result lambda function longer access endpoint li privat vpc need advic creat vpc interfac endpoint enabl lambda function access endpoint build associ secur group enabl network access unsur implement vpc interfac endpoint implement correct secur group appreci advic implement altern architectur creat lambda function associ privat vpc connect rd instanc store requir data bucket lambda function vpc pull data bucket serv endpoint better option",
        "Question_preprocessed_content":"lambda function vpc infer endpoint lambda function mysql rd instanc privat vpc lambda function infer endpoint take data rd instanc model infer test lambda function outsid privat vpc endpoint order lambda data rd databas lambda function privat vpc subnet rd instanc result lambda function longer endpoint li privat vpc advic creat vpc interfac endpoint enabl lambda function endpoint build secur group enabl network unsur implement vpc interfac endpoint implement secur group advic implement altern architectur creat lambda function privat vpc rd instanc store requir data bucket lambda function vpc data bucket serv endpoint option",
        "Question_gpt_summary_original":"The user needs advice on how to create a VPC Interface Endpoint and associated security groups to enable a Lambda function within a private VPC to access a Sagemaker Serverless Inference Endpoint, while also connecting to a MySQL RDS instance within the same VPC. They are also considering an alternative architecture involving two Lambda functions.",
        "Question_gpt_summary":"user need advic creat vpc interfac endpoint associ secur group enabl lambda function privat vpc access serverless infer endpoint connect mysql rd instanc vpc consid altern architectur involv lambda function"
    },
    {
        "Question_title":"How does one save a plot in wandb with wandb.log?",
        "Question_body":"<p>I\u2019m trying to save a plot with wandb.log. Their <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\/plots\">docs<\/a> say to do:<\/p>\n<pre><code class=\"lang-auto\">    wandb.log({\"chart\": plt})\n<\/code><\/pre>\n<p>but this fails for me.<\/p>\n<p>I get two errors, 1st error (when I do NOT do <code>plt.show()<\/code> before trying to do wand.log):<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/Applications\/PyCharm.app\/Contents\/plugins\/python\/helpers\/pydev\/_pydevd_bundle\/pydevd_exec2.py\", line 3, in Exec\n    exec(exp, global_vars, local_vars)\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 256, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 222, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1548, in log\n    self._log(data=data, step=step, commit=commit)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1339, in _log\n    self._partial_history_callback(data, step, commit)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1228, in _partial_history_callback\n    self._backend.interface.publish_partial_history(\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 541, in publish_partial_history\n    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/utils.py\", line 54, in history_dict_to_json\n    payload[key] = val_to_json(\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/utils.py\", line 82, in val_to_json\n    val = Plotly.make_plot_media(val)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/plotly.py\", line 48, in make_plot_media\n    val = util.matplotlib_to_plotly(val)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/util.py\", line 560, in matplotlib_to_plotly\n    return tools.mpl_to_plotly(obj)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/tools.py\", line 112, in mpl_to_plotly\n    matplotlylib.Exporter(renderer).run(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 53, in run\n    self.crawl_fig(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 124, in crawl_fig\n    self.crawl_ax(ax)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 146, in crawl_ax\n    self.draw_collection(ax, collection)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 289, in draw_collection\n    offset_order = offset_dict[collection.get_offset_position()]\nAttributeError: 'LineCollection' object has no attribute 'get_offset_position'\n<\/code><\/pre>\n<p>I get two errors, 2nd error (when I DO <code>plt.show()<\/code> before trying to do wand.log):<\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/Applications\/PyCharm.app\/Contents\/plugins\/python\/helpers\/pydev\/_pydevd_bundle\/pydevd_exec2.py\", line 3, in Exec\n    exec(exp, global_vars, local_vars)\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 256, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 222, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1548, in log\n    self._log(data=data, step=step, commit=commit)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1339, in _log\n    self._partial_history_callback(data, step, commit)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 1228, in _partial_history_callback\n    self._backend.interface.publish_partial_history(\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/interface\/interface.py\", line 541, in publish_partial_history\n    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/utils.py\", line 54, in history_dict_to_json\n    payload[key] = val_to_json(\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/utils.py\", line 82, in val_to_json\n    val = Plotly.make_plot_media(val)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/sdk\/data_types\/plotly.py\", line 48, in make_plot_media\n    val = util.matplotlib_to_plotly(val)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/wandb\/util.py\", line 560, in matplotlib_to_plotly\n    return tools.mpl_to_plotly(obj)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/tools.py\", line 112, in mpl_to_plotly\n    matplotlylib.Exporter(renderer).run(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 53, in run\n    self.crawl_fig(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/exporter.py\", line 122, in crawl_fig\n    with self.renderer.draw_figure(fig=fig, props=utils.get_figure_properties(fig)):\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/contextlib.py\", line 119, in __enter__\n    return next(self.gen)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mplexporter\/renderers\/base.py\", line 45, in draw_figure\n    self.open_figure(fig=fig, props=props)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/renderer.py\", line 90, in open_figure\n    self.mpl_x_bounds, self.mpl_y_bounds = mpltools.get_axes_bounds(fig)\n  File \"\/Users\/brandomiranda\/opt\/anaconda3\/envs\/meta_learning\/lib\/python3.9\/site-packages\/plotly\/matplotlylib\/mpltools.py\", line 265, in get_axes_bounds\n    x_min, y_min, x_max, y_max = min(x_min), min(y_min), max(x_max), max(y_max)\nValueError: min() arg is an empty sequence\n<\/code><\/pre>\n<p>Note that their trivial example DOES work:<\/p>\n<pre><code class=\"lang-auto\">import matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3, 4])\nplt.ylabel(\"some interesting numbers\")\nwandb.log({\"chart\": plt})\n<\/code><\/pre>\n<p>for me.<\/p>\n<hr>\n<p>cross posted: <a href=\"https:\/\/stackoverflow.com\/questions\/72134168\/how-does-one-save-a-plot-in-wandb-with-wandb-log\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - How does one save a plot in wandb with wandb.log? - Stack Overflow<\/a><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1651788927254,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":259.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-save-a-plot-in-wandb-with-wandb-log\/2373",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save plot log try save plot log doc log chart plt fail error error plt try wand log traceback recent file applic pycharm app content plugin python helper pydev pydevd bundl pydevd exec line exec exec exp global var local var file line file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line wrapper return func self arg kwarg file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line wrapper return func self arg kwarg file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line log self log data data step step commit commit file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line log self partial histori callback data step commit file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line partial histori callback self backend interfac publish partial histori file user brandomiranda opt anaconda env meta learn lib python site packag sdk interfac interfac line publish partial histori data histori dict json run data step user step ignor copi err true file user brandomiranda opt anaconda env meta learn lib python site packag sdk data type util line histori dict json payload kei val json file user brandomiranda opt anaconda env meta learn lib python site packag sdk data type util line val json val plotli plot media val file user brandomiranda opt anaconda env meta learn lib python site packag sdk data type plotli line plot media val util matplotlib plotli val file user brandomiranda opt anaconda env meta learn lib python site packag util line matplotlib plotli return tool mpl plotli obj file user brandomiranda opt anaconda env meta learn lib python site packag plotli tool line mpl plotli matplotlylib export render run fig file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib mplexport export line run self crawl fig fig file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib mplexport export line crawl fig self crawl file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib mplexport export line crawl self draw collect collect file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib mplexport export line draw collect offset order offset dict collect offset posit attributeerror linecollect object attribut offset posit error error plt try wand log traceback recent file applic pycharm app content plugin python helper pydev pydevd bundl pydevd exec line exec exec exp global var local var file line file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line wrapper return func self arg kwarg file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line wrapper return func self arg kwarg file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line log self log data data step step commit commit file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line log self partial histori callback data step commit file user brandomiranda opt anaconda env meta learn lib python site packag sdk run line partial histori callback self backend interfac publish partial histori file user brandomiranda opt anaconda env meta learn lib python site packag sdk interfac interfac line publish partial histori data histori dict json run data step user step ignor copi err true file user brandomiranda opt anaconda env meta learn lib python site packag sdk data type util line histori dict json payload kei val json file user brandomiranda opt anaconda env meta learn lib python site packag sdk data type util line val json val plotli plot media val file user brandomiranda opt anaconda env meta learn lib python site packag sdk data type plotli line plot media val util matplotlib plotli val file user brandomiranda opt anaconda env meta learn lib python site packag util line matplotlib plotli return tool mpl plotli obj file user brandomiranda opt anaconda env meta learn lib python site packag plotli tool line mpl plotli matplotlylib export render run fig file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib mplexport export line run self crawl fig fig file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib mplexport export line crawl fig self render draw figur fig fig prop util figur properti fig file user brandomiranda opt anaconda env meta learn lib python contextlib line enter return self gen file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib mplexport render base line draw figur self open figur fig fig prop prop file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib render line open figur self mpl bound self mpl bound mpltool ax bound fig file user brandomiranda opt anaconda env meta learn lib python site packag plotli matplotlylib mpltool line ax bound min min max max min min min min max max max max valueerror min arg sequenc note trivial exampl work import matplotlib pyplot plt plt plot plt ylabel interest number log chart plt cross post python save plot log stack overflow",
        "Question_preprocessed_content":"save plot log try save plot log doc fail note trivial exampl work post python save plot log stack overflow",
        "Question_gpt_summary_original":"The user is trying to save a plot with wandb.log but is encountering errors. The first error occurs when plt.show() is not executed before wand.log and the second error occurs when plt.show() is executed before wand.log. The user has followed the instructions provided in the documentation but the example provided in the documentation works for the user. The user has cross-posted the issue on Stack Overflow.",
        "Question_gpt_summary":"user try save plot log encount error error occur plt execut wand log second error occur plt execut wand log user follow instruct provid document exampl provid document work user user cross post issu stack overflow"
    },
    {
        "Question_title":"Why PyTorch is using only one GPU ?",
        "Question_body":"<p>Azure does not use the two GPUs of my node with PyTorch (and Hugging Face). The monitoring tool of Azure shows the GPU usage is stuck at 50%.    <br \/>\nIts a Standard_NC12, so it has two K80s.    <\/p>\n<p>I tried this way :    <br \/>\n<a href=\"https:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/distributed-training\/#distributeddataparallel-per-process-launch\">https:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/distributed-training\/#distributeddataparallel-per-process-launch<\/a>    <br \/>\nand it looked like this in my notebook :    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/205547-capture-decran-2022-05-25-a-81119-pm.png?platform=QnA\" alt=\"205547-capture-decran-2022-05-25-a-81119-pm.png\" \/>    <\/p>\n<p>I copied the docker file from the curated environments and added the libraries I needed successfully :    <\/p>\n<pre><code>FROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20220329.v1  \n  \nENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/pytorch-1.10  \n  \n# Create conda environment  \nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\  \n    python=3.8 \\  \n    pip=20.2.4 \\  \n    pytorch=1.10.0 \\  \n    torchvision=0.11.1 \\  \n    torchaudio=0.10.0 \\  \n    cudatoolkit=11.1.1 \\  \n    nvidia-apex=0.1.0 \\  \n    gxx_linux-64 \\  \n    -c anaconda -c pytorch -c conda-forge  \n  \n# Prepend path to AzureML conda environment  \nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH  \n  \n# Install pip dependencies  \nRUN pip install 'matplotlib&gt;=3.3,&lt;3.4' \\  \n                'psutil&gt;=5.8,&lt;5.9' \\  \n                'tqdm&gt;=4.59,&lt;4.63' \\  \n                'pandas&gt;=1.3,&lt;1.4' \\  \n                'scipy&gt;=1.5,&lt;1.8' \\  \n                'numpy&gt;=1.10,&lt;1.22' \\  \n                'ipykernel~=6.0' \\  \n                'azureml-core==1.40.0' \\  \n                'azureml-defaults==1.40.0' \\  \n                'azureml-mlflow==1.40.0' \\  \n                'azureml-telemetry==1.40.0' \\  \n                'tensorboard==2.6.0' \\  \n                'tensorflow-gpu==2.6.0' \\  \n                'onnxruntime-gpu&gt;=1.7,&lt;1.10' \\  \n                'horovod==0.23' \\  \n                'future==0.18.2' \\  \n                'wandb' \\  \n                'transformers' \\  \n                'einops' \\  \n                'torch-tb-profiler==0.3.1'  \n  \n  \n# This is needed for mpi to locate libpython  \nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH  \n  \nRUN export CUDA_VISIBLE_DEVICES=0,1  \n<\/code><\/pre>\n<p>I tried everything, I even added the CUDA_VISIBLE_DEVICES=0,1 inside the docker file.    <\/p>\n<p>My cluster is correctly configured because my colleague can use another tool (Detr with Lightning) and use 100% of the computing power.    <br \/>\nI copied his docker file and the result was the same, so our guess is that his tool is automatically managing all GPUs for him.    <\/p>\n<p>Does anyone know why the cluster is using only one GPU ?    <\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1.0,
        "Question_created_time":1653503234337,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/864175\/why-pytorch-is-using-only-one-gpu",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pytorch gpu azur us gpu node pytorch hug face monitor tool azur show gpu usag stuck standard tri wai http azur github cheatsheet doc cheatsheet python distribut train distributeddataparallel process launch look like notebook copi docker file curat environ ad librari need successfulli mcr microsoft com openmpi cuda cudnn ubuntu env conda environ path env pytorch creat conda environ run conda creat conda environ path python pip pytorch torchvis torchaudio cudatoolkit nvidia apex gxx linux anaconda pytorch conda forg prepend path conda environ env path conda environ path bin path instal pip depend run pip instal matplotlib horovod futur transform einop torch profil need mpi locat libpython env librari path conda environ path lib librari path run export cuda visibl devic tri ad cuda visibl devic insid docker file cluster correctli configur colleagu us tool detr lightn us comput power copi docker file result guess tool automat manag gpu know cluster gpu",
        "Question_preprocessed_content":"pytorch gpu azur us gpu node pytorch monitor azur show gpu usag stuck tri wai like copi docker file curat environ librari tri insid docker file cluster configur us us comput power copi docker file result manag gpu know cluster gpu",
        "Question_gpt_summary_original":"The user is facing an issue with PyTorch and Hugging Face on Azure, where only one GPU out of two is being used despite the node having two K80s. The user has tried various solutions, including modifying the docker file and adding CUDA_VISIBLE_DEVICES=0,1, but the GPU usage remains stuck at 50%. The user's colleague can use another tool (Detr with Lightning) and use 100% of the computing power, leading to the assumption that the tool is automatically managing all GPUs. The user is seeking help to understand why the cluster is using only one GPU.",
        "Question_gpt_summary":"user face issu pytorch hug face azur gpu despit node have user tri solut includ modifi docker file ad cuda visibl devic gpu usag remain stuck user colleagu us tool detr lightn us comput power lead assumpt tool automat manag gpu user seek help understand cluster gpu"
    },
    {
        "Question_title":"Kedro - how to pass nested parameters directly to node",
        "Question_body":"<p><a href=\"https:\/\/stackoverflow.com\/questions\/tagged\/kedro\"><code>kedro<\/code><\/a> recommends storing parameters in <code>conf\/base\/parameters.yml<\/code>. Let's assume it looks like this:<\/p>\n\n<pre><code>step_size: 1\nmodel_params:\n    learning_rate: 0.01\n    test_data_ratio: 0.2\n    num_train_steps: 10000\n<\/code><\/pre>\n\n<p>And now imagine I have some <code>data_engineering<\/code> pipeline whose <code>nodes.py<\/code> has a function that looks something like this:<\/p>\n\n<pre><code>def some_pipeline_step(num_train_steps):\n    \"\"\"\n    Takes the parameter `num_train_steps` as argument.\n    \"\"\"\n    pass\n<\/code><\/pre>\n\n<p>How would I go about and pass that nested parameters straight to this function in <code>data_engineering\/pipeline.py<\/code>? I unsuccessfully tried:<\/p>\n\n<pre><code>from kedro.pipeline import Pipeline, node\n\nfrom .nodes import split_data\n\n\ndef create_pipeline(**kwargs):\n    return Pipeline(\n        [\n            node(\n                some_pipeline_step,\n                [\"params:model_params.num_train_steps\"],\n                dict(\n                    train_x=\"train_x\",\n                    train_y=\"train_y\",\n                ),\n            )\n        ]\n    )\n<\/code><\/pre>\n\n<p>I know that I could just pass all parameters into the function by using <code>['parameters']<\/code> or just pass all <code>model_params<\/code> parameters with <code>['params:model_params']<\/code> but it seems unelegant and I feel like there must be a way. Would appreciate any input!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1587965065520,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1403.0,
        "Poster_created_time":1525290575943,
        "Poster_location":"Toronto, ON, Canada",
        "Poster_reputation_count":143.0,
        "Poster_view_count":17.0,
        "Answer_body":"<p>(Disclaimer: I'm part of the Kedro team)<\/p>\n\n<p>Thank you for your question. Current version of Kedro, unfortunately, does not support nested parameters. The interim solution would be to use top-level keys inside the node (as you already pointed out) or decorate your node function with some sort of a parameter filter, which is not elegant either.<\/p>\n\n<p>Probably the most viable solution would be to customise your <code>ProjectContext<\/code> (in <code>src\/&lt;package_name&gt;\/run.py<\/code>) class by overwriting <code>_get_feed_dict<\/code> method as follows:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>class ProjectContext(KedroContext):\n    # ...\n\n\n    def _get_feed_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Get parameters and return the feed dictionary.\"\"\"\n        params = self.params\n        feed_dict = {\"parameters\": params}\n\n        def _add_param_to_feed_dict(param_name, param_value):\n            \"\"\"This recursively adds parameter paths to the `feed_dict`,\n            whenever `param_value` is a dictionary itself, so that users can\n            specify specific nested parameters in their node inputs.\n\n            Example:\n\n                &gt;&gt;&gt; param_name = \"a\"\n                &gt;&gt;&gt; param_value = {\"b\": 1}\n                &gt;&gt;&gt; _add_param_to_feed_dict(param_name, param_value)\n                &gt;&gt;&gt; assert feed_dict[\"params:a\"] == {\"b\": 1}\n                &gt;&gt;&gt; assert feed_dict[\"params:a.b\"] == 1\n            \"\"\"\n            key = \"params:{}\".format(param_name)\n            feed_dict[key] = param_value\n\n            if isinstance(param_value, dict):\n                for key, val in param_value.items():\n                    _add_param_to_feed_dict(\"{}.{}\".format(param_name, key), val)\n\n        for param_name, param_value in params.items():\n            _add_param_to_feed_dict(param_name, param_value)\n\n        return feed_dict\n<\/code><\/pre>\n\n<p>Please also note that this issue has already been <a href=\"https:\/\/github.com\/quantumblacklabs\/kedro\/commit\/529606273e201a736f10338ada73ac6206081730\" rel=\"nofollow noreferrer\">addressed on develop<\/a> and will become available in the next release. The fix uses the approach from the snippet above.<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1587979890916,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1393579668636,
        "Answerer_location":"London, United Kingdom",
        "Answerer_reputation_count":1450.0,
        "Answerer_view_count":162.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61452211",
        "Tool":"Kedro",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pass nest paramet directli node recommend store paramet conf base paramet yml let assum look like step size model param learn rate test data ratio num train step imagin data engin pipelin node function look like def pipelin step num train step take paramet num train step argument pass pass nest paramet straight function data engin pipelin unsuccessfulli tri pipelin import pipelin node node import split data def creat pipelin kwarg return pipelin node pipelin step param model param num train step dict train train train train know pass paramet function paramet pass model param paramet param model param uneleg feel like wai appreci input",
        "Question_preprocessed_content":"nest paramet directli node store paramet let like imagin pipelin function like nest paramet straight function tri know paramet function paramet uneleg like wai input",
        "Question_gpt_summary_original":"The user is trying to pass nested parameters directly to a function in Kedro's data engineering pipeline, but is having trouble doing so. They have tried using the \"params:model_params.num_train_steps\" syntax, but it did not work. The user is looking for a more elegant solution to pass the nested parameters.",
        "Question_gpt_summary":"user try pass nest paramet directli function data engin pipelin have troubl tri param model param num train step syntax work user look eleg solut pass nest paramet"
    },
    {
        "Question_title":"machine learning Studio",
        "Question_body":"<p>Hi:  <\/p>\n<p>I wonder when will the classic Machine Learning Studio retire?  <\/p>\n<p>Also in order to save my data and file, any preparation or migration should be done to avoid any loss?  <\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1648415916797,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=3f0f48d2-f878-404d-bae7-0861ffefc027\">@dontbelazy  <\/a>     <\/p>\n<p>Thanks for reaching out to us, I think you are mentioning Azure Machine Learning Studio(classic). Machine Learning Studio (classic) will retire on 31 August 2024.     <\/p>\n<p>From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic). Beginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources.    <\/p>\n<p>Required action to avoid loss:     <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\">Follow these steps<\/a> to transition using Azure Machine Learning before 31 August 2024. Pricing may be subject to change, please view <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning\/#:%7E:text=Consumed%20Azure%20resources%20%28e.g.%20compute%2C%20storage%29%20%28No%20Azure,%24-%20%2B%20per%20vCPU%20hour%20Edition%3A%20Basic%20Enterprise\">pricing<\/a> here.    <\/p>\n<p>Hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p><em>-Please kindly accept the answer if you feel helpful, thanks!<\/em>    <\/p>\n",
        "Answer_comment_count":2.0,
        "Question_closed_time":1648423257900,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/789066\/machine-learning-studio",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"machin learn studio wonder classic machin learn studio retir order save data file prepar migrat avoid loss thank",
        "Question_preprocessed_content":"machin learn studio wonder machin learn studio retir order save data file prepar migrat avoid thank",
        "Question_gpt_summary_original":"The user is inquiring about the retirement date of the classic Machine Learning Studio and seeking advice on how to prepare or migrate their data and files to avoid any loss.",
        "Question_gpt_summary":"user inquir retir date classic machin learn studio seek advic prepar migrat data file avoid loss"
    },
    {
        "Question_title":"start, monitor and define script of SageMaker processing job from local machine",
        "Question_body":"<p>I am looking at <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/sagemaker_processing\/scikit_learn_data_processing_and_model_evaluation\/scikit_learn_data_processing_and_model_evaluation.ipynb\" rel=\"nofollow noreferrer\">this<\/a>, which makes all sense. Let us focus on this bit of code:<\/p>\n<pre><code>from sagemaker.processing import ProcessingInput, ProcessingOutput\n\nsklearn_processor.run(\n    code=&quot;preprocessing.py&quot;,\n    inputs=[\n        ProcessingInput(source=&quot;s3:\/\/your-bucket\/path\/to\/your\/data&quot;, destination=&quot;\/opt\/ml\/processing\/input&quot;),\n    ],\n    outputs=[\n        ProcessingOutput(output_name=&quot;train_data&quot;, source=&quot;\/opt\/ml\/processing\/train&quot;),\n        ProcessingOutput(output_name=&quot;test_data&quot;, source=&quot;\/opt\/ml\/processing\/test&quot;),\n    ],\n    arguments=[&quot;--train-test-split-ratio&quot;, &quot;0.2&quot;],\n)\n\npreprocessing_job_description = sklearn_processor.jobs[-1].describe() \n<\/code><\/pre>\n<p>Here preprocessing.py has to be obviously in the cloud. I am curious, could one also put scripts into an S3 bucket and trigger the job remotely. I can easily to this with hyper parameter optimisation, which does not require dedicated scripts though as I use an OOTB training image.<\/p>\n<p>In this case I can fire off the job like so:<\/p>\n<pre><code>tuning_job_name = &quot;amazing-hpo-job-&quot; + strftime(&quot;%d-%H-%M-%S&quot;, gmtime())\n\nsmclient = boto3.Session().client(&quot;sagemaker&quot;)\nsmclient.create_hyper_parameter_tuning_job(\n    HyperParameterTuningJobName=tuning_job_name,\n    HyperParameterTuningJobConfig=tuning_job_config,\n    TrainingJobDefinition=training_job_definition\n)\n<\/code><\/pre>\n<p>and then monitor the job's progress:<\/p>\n<pre><code>smclient = boto3.Session().client(&quot;sagemaker&quot;)\n\ntuning_job_result = smclient.describe_hyper_parameter_tuning_job(\n    HyperParameterTuningJobName=tuning_job_name\n)\n\nstatus = tuning_job_result[&quot;HyperParameterTuningJobStatus&quot;]\nif status != &quot;Completed&quot;:\n    print(&quot;Reminder: the tuning job has not been completed.&quot;)\n\njob_count = tuning_job_result[&quot;TrainingJobStatusCounters&quot;][&quot;Completed&quot;]\nprint(&quot;%d training jobs have completed&quot; % job_count)\n\nobjective = tuning_job_result[&quot;HyperParameterTuningJobConfig&quot;][&quot;HyperParameterTuningJobObjective&quot;]\nis_minimize = objective[&quot;Type&quot;] != &quot;Maximize&quot;\nobjective_name = objective[&quot;MetricName&quot;]\n\nif tuning_job_result.get(&quot;BestTrainingJob&quot;, None):\n    print(&quot;Best model found so far:&quot;)\n    pprint(tuning_job_result[&quot;BestTrainingJob&quot;])\nelse:\n    print(&quot;No training jobs have reported results yet.&quot;) \n<\/code><\/pre>\n<p>I would think starting and monitoring a SageMaker processing job from a local machine should be possible as with an HPO job but what about the script(s)? Ideally I would like to develop and test them locally and the run remotely. Hope this makes sense?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662209372887,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":38.0,
        "Poster_created_time":1267440784443,
        "Poster_location":"Somewhere",
        "Poster_reputation_count":15705.0,
        "Poster_view_count":2150.0,
        "Answer_body":"<p>Im not sure I understand the comparison to a Tuning Job.<\/p>\n<p>Based on what you have described, in this case the <code>preprocessing.py<\/code> is actually stored locally. The SageMaker SDK will upload it to S3 for the remote Processing Job to access it. I suggest launching the Job and then taking a look at the inputs in the SageMaker Console.<\/p>\n<p>If you wanted to test the Processing Job locally you can do so using <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/overview.html#local-mode\" rel=\"nofollow noreferrer\">Local Mode<\/a>. This will basically imitate the Job locally which aids in debugging the script before kicking off a remote Processing Job. Kindly note docker is required to make use of Local Mode.<\/p>\n<p>Example code for local mode:<\/p>\n<pre><code>from sagemaker.local import LocalSession\nfrom sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n\nsagemaker_session = LocalSession()\nsagemaker_session.config = {'local': {'local_code': True}}\n\n# For local training a dummy role will be sufficient\nrole = 'arn:aws:iam::111111111111:role\/service-role\/AmazonSageMaker-ExecutionRole-20200101T000001'\n\nprocessor = ScriptProcessor(command=['python3'],\n                    image_uri='sagemaker-scikit-learn-processing-local',\n                    role=role,\n                    instance_count=1,\n                    instance_type='local')\n\nprocessor.run(code='processing_script.py',\n                    inputs=[ProcessingInput(\n                        source='.\/input_data\/',\n                        destination='\/opt\/ml\/processing\/input_data\/')],\n                    outputs=[ProcessingOutput(\n                        output_name='word_count_data',\n                        source='\/opt\/ml\/processing\/processed_data\/')],\n                    arguments=['job-type', 'word-count']\n                    )\n\npreprocessing_job_description = processor.jobs[-1].describe()\noutput_config = preprocessing_job_description['ProcessingOutputConfig']\n\nprint(output_config)\n\nfor output in output_config['Outputs']:\n    if output['OutputName'] == 'word_count_data':\n        word_count_data_file = output['S3Output']['S3Uri']\n\nprint('Output file is located on: {}'.format(word_count_data_file))\n\n\n<\/code><\/pre>",
        "Answer_comment_count":4.0,
        "Question_closed_time":1662504468407,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1645475560783,
        "Answerer_location":null,
        "Answerer_reputation_count":466.0,
        "Answerer_view_count":32.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73592371",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"start monitor defin script process job local machin look make sens let focu bit code process import processinginput processingoutput sklearn processor run code preprocess input processinginput sourc bucket path data destin opt process input output processingoutput output train data sourc opt process train processingoutput output test data sourc opt process test argument train test split ratio preprocess job descript sklearn processor job preprocess obvious cloud curiou script bucket trigger job remot easili hyper paramet optimis requir dedic script us ootb train imag case job like tune job amaz hpo job strftime gmtime smclient boto session client smclient creat hyper paramet tune job hyperparametertuningjobnam tune job hyperparametertuningjobconfig tune job config trainingjobdefinit train job definit monitor job progress smclient boto session client tune job result smclient hyper paramet tune job hyperparametertuningjobnam tune job statu tune job result hyperparametertuningjobstatu statu complet print remind tune job complet job count tune job result trainingjobstatuscount complet print train job complet job count object tune job result hyperparametertuningjobconfig hyperparametertuningjobobject minim object type maxim object object metricnam tune job result besttrainingjob print best model far pprint tune job result besttrainingjob print train job report result think start monitor process job local machin possibl hpo job script ideal like develop test local run remot hope make sens",
        "Question_preprocessed_content":"start monitor defin script job local machin make sens let focu bit code obvious cloud curiou script bucket job remot easili hyper paramet optimis requir dedic script us train imag case job like monitor job think start monitor job local machin hpo job script like develop test run remot hope make sens",
        "Question_gpt_summary_original":"The user is trying to understand if it is possible to start, monitor, and define a script for a SageMaker processing job from a local machine. They have provided code examples for running a processing job and monitoring a hyperparameter tuning job remotely, but they are unsure if they can put scripts into an S3 bucket and trigger the processing job remotely. The user would like to develop and test the scripts locally and then run them remotely.",
        "Question_gpt_summary":"user try understand possibl start monitor defin script process job local machin provid code exampl run process job monitor hyperparamet tune job remot unsur script bucket trigger process job remot user like develop test script local run remot"
    },
    {
        "Question_title":"SageMaker Issue: AttributeError: 'AioClientCreator' object has no attribute '_register_lazy_block_unknown_fips_pseudo_regions'",
        "Question_body":"Hi, there\n\nWhen training model using sagemaker and calling panda.read_csv().. we are getting the above error.  It appears that this is a known issue and the workaround is to upgrade aiobotocore to the latest 2.20 release. However, the missing link is where to upgrade the aiobotocore .. since we are running model against SageMaker and its fully managed M5 instance... instead of an EC2 instance.  Any thoughts? \n\nError message in full:\n\/opt\/conda\/lib\/python3.7\/site-packages\/aiobotocore\/client.py in create_client(self, service_name, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, api_version, client_config)\n     43             service_client, endpoint_url, client_config\n     44         )\n---> 45         self._register_lazy_block_unknown_fips_pseudo_regions(service_client)\n     46         return service_client\n     47 \n\nAttributeError: 'AioClientCreator' object has no attribute '_register_lazy_block_unknown_fips_pseudo_regions'\n\nSee notes below under this link:\nhttps:\/\/github.com\/boto\/botocore\/pull\/2558\/files#",
        "Question_answer_count":3,
        "Question_comment_count":1.0,
        "Question_created_time":1649181155664,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668624296784,
        "Question_score_count":0.0,
        "Question_view_count":878.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU1RBibWGuQSymNwJfXkln6A\/sagemaker-issue-attributeerror-aioclientcreator-object-has-no-attribute-register-lazy-block-unknown-fips-pseudo-regions",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"issu attributeerror aioclientcr object attribut regist lazi block unknown fip pseudo region train model call panda read csv get error appear known issu workaround upgrad aiobotocor latest releas miss link upgrad aiobotocor run model fulli manag instanc instead instanc thought error messag opt conda lib python site packag aiobotocor client creat client self servic region secur endpoint url verifi credenti scope config api version client config servic client endpoint url client config self regist lazi block unknown fip pseudo region servic client return servic client attributeerror aioclientcr object attribut regist lazi block unknown fip pseudo region note link http github com boto botocor pull file",
        "Question_preprocessed_content":"aioclientcr object train model known workaround upgrad aiobotocor latest releas link upgrad aiobotocor model manag instead instanc thought verifi credenti return aioclientcr object note link",
        "Question_gpt_summary_original":"The user is encountering an AttributeError while training a model using SageMaker and calling panda.read_csv(). The error message suggests that upgrading aiobotocore to the latest 2.20 release can resolve the issue, but the user is unsure where to upgrade aiobotocore since they are running the model against SageMaker's fully managed M5 instance instead of an EC2 instance.",
        "Question_gpt_summary":"user encount attributeerror train model call panda read csv error messag suggest upgrad aiobotocor latest releas resolv issu user unsur upgrad aiobotocor run model fulli manag instanc instead instanc"
    },
    {
        "Question_title":"How to handle entrypoints nested in folders with amazon sagemaker pytorch estimator?",
        "Question_body":"<p>I am attempting to run a training job on amazon sagemaker using the python-sagemaker-sdk, estimator class.<\/p>\n\n<p>I have the following<\/p>\n\n<pre><code>estimator = PyTorch(entry_point='training_scripts\/train_MSCOCO.py',\n                            source_dir='.\/',\n                            role=#dummy_role,\n                            train_instance_type='ml.p3.2xlarge',\n                            train_instance_count=1,\n                            framework_version='1.0.0',\n                            output_path=#dummy_output_path,\n                            hyperparameters={'lr': 0.001,\n                                             'batch_size': 32,\n                                             'num_workers': 4,\n                                             'description': description})\n<\/code><\/pre>\n\n<p>role and output_path hidden for privacy.<\/p>\n\n<p>I get the following error, \"No module named training_scripts\\train_MSCOCO\".<\/p>\n\n<p>When I run python -m training_scripts.train_MSCOCO the script runs fine. However when I pass <code>entry_point='training_script.train_MSCOCO.py<\/code> it will not run as, \"No file named \"training_scripts.train_MSCOCO.py\" was found in directory \".\/\"\".<\/p>\n\n<p>I am confused as to how to run a nested training script from the top level of my repository within AWS sagemaker, as they seem to have conflicting path needs, one in python module dot notation, the other in standard filepath slash notation.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1563984389853,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":222.0,
        "Poster_created_time":1469720606203,
        "Poster_location":"New Jersey, United States",
        "Poster_reputation_count":65.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57187148",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"handl entrypoint nest folder pytorch estim attempt run train job python sdk estim class follow estim pytorch entri point train script train mscoco sourc dir role dummi role train instanc type xlarg train instanc count framework version output path dummi output path hyperparamet batch size num worker descript descript role output path hidden privaci follow error modul name train script train mscoco run python train script train mscoco script run fine pass entri point train script train mscoco run file name train script train mscoco directori confus run nest train script level repositori conflict path need python modul dot notat standard filepath slash notat",
        "Question_preprocessed_content":"handl entrypoint nest folder pytorch estim run train job estim role privaci modul name run python script run fine run file name directori confus run nest train script level repositori conflict path python modul dot notat standard filepath slash notat",
        "Question_gpt_summary_original":"The user is facing challenges while attempting to run a training job on Amazon SageMaker using the python-sagemaker-sdk, estimator class. The user is encountering an error \"No module named training_scripts\\train_MSCOCO\" while trying to run a nested training script from the top level of the repository within AWS SageMaker. The user is confused about how to run a nested training script from the top level of the repository within AWS SageMaker, as they seem to have conflicting path needs, one in python module dot notation, the other in standard filepath slash notation.",
        "Question_gpt_summary":"user face challeng attempt run train job python sdk estim class user encount error modul name train script train mscoco try run nest train script level repositori user confus run nest train script level repositori conflict path need python modul dot notat standard filepath slash notat"
    },
    {
        "Question_title":"Is it a good idea to store my dataset in my notebook instance in sagemaker?",
        "Question_body":"<p>I'm new to AWS and I am considering to use amazon sagemaker to train my deep learning model because I'm having memory issues due to the large dataset and neural network that I have to train. I'm confused whether to store my data in my notebook instance or in S3? If I store it in my s3 would I be able to access it to train on my notebook instance? I'm confused on the concepts. Can anyone explain the use of S3 in machine learning in AWS?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1619054238143,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":322.0,
        "Poster_created_time":1605938672327,
        "Poster_location":"Jakarta Selatan, South Jakarta City, Jakarta, Indonesia",
        "Poster_reputation_count":97.0,
        "Poster_view_count":34.0,
        "Answer_body":"<p>Yes you can use S3 as storage for your training datasets.<\/p>\n<p>Refer diagram in this link describing how everything works together: <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/how-it-works-training.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/how-it-works-training.html<\/a><\/p>\n<p>You may also want to checkout following blogs that details about File mode and Pipe mode, two mechanisms for transferring training data:<\/p>\n<ol>\n<li><a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker\/<\/a><\/li>\n<\/ol>\n<blockquote>\n<p>In File mode, the training data is downloaded first to an encrypted EBS volume attached to the training instance prior to commencing the training. However, in Pipe mode the input data is streamed directly to the training algorithm while it is running.<\/p>\n<\/blockquote>\n<ol start=\"2\">\n<li><a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-pipe-input-mode-for-amazon-sagemaker-algorithms\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-pipe-input-mode-for-amazon-sagemaker-algorithms\/<\/a><\/li>\n<\/ol>\n<blockquote>\n<p>With Pipe input mode, your data is fed on-the-fly into the algorithm container without involving any disk I\/O. This approach shortens the lengthy download process and dramatically reduces startup time. It also offers generally better read throughput than File input mode. This is because your data is fetched from Amazon S3 by a highly optimized multi-threaded background process. It also allows you to train on datasets that are much larger than the 16 TB Amazon Elastic Block Store (EBS) volume size limit.<\/p>\n<\/blockquote>\n<p>The blog also contains python code snippets using Pipe input mode for reference.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1619062178832,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1336887489390,
        "Answerer_location":null,
        "Answerer_reputation_count":758.0,
        "Answerer_view_count":44.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67205469",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"good idea store dataset notebook instanc new aw consid us train deep learn model have memori issu larg dataset neural network train confus store data notebook instanc store abl access train notebook instanc confus concept explain us machin learn aw",
        "Question_preprocessed_content":"idea store dataset instanc new aw consid us train learn model have memori larg dataset neural network train confus store data instanc store abl train instanc confus concept explain us machin learn aw",
        "Question_gpt_summary_original":"The user is new to AWS and is considering using Amazon SageMaker to train a deep learning model due to memory issues caused by a large dataset and neural network. They are unsure whether to store their data in their notebook instance or in S3 and are seeking clarification on the use of S3 in machine learning in AWS.",
        "Question_gpt_summary":"user new aw consid train deep learn model memori issu caus larg dataset neural network unsur store data notebook instanc seek clarif us machin learn aw"
    },
    {
        "Question_title":"Separating Training From Testing",
        "Question_body":"<p>Hi!<\/p>\n<p>I\u2019ve got a sort of lopsided ML workflow where most of my time is spent producing plots and metrics, and my set of trained models is rarely updated. Is there a good way to separate my training code from all of my evaluation scripts?<\/p>\n<p>I\u2019d like my experiments to have the logging information from when the model was trained, but not to have to retrain it every time.<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1630322356926,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":321.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/separating-training-from-testing\/353",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"separ train test iv got sort lopsid workflow time spent produc plot metric set train model rare updat good wai separ train code evalu script like experi log inform model train retrain time thank",
        "Question_preprocessed_content":"separ train test iv got sort lopsid workflow time spent produc plot metric set train model rare updat wai separ train code evalu script like experi inform model train retrain time thank",
        "Question_gpt_summary_original":"The user is facing a challenge in their ML workflow where they spend most of their time producing plots and metrics, and their set of trained models is rarely updated. They are looking for a way to separate their training code from evaluation scripts to avoid retraining the model every time while still having access to the logging information from the training phase.",
        "Question_gpt_summary":"user face challeng workflow spend time produc plot metric set train model rare updat look wai separ train code evalu script avoid retrain model time have access log inform train phase"
    },
    {
        "Question_title":"Can't disable a scheduled pipeline endpoint",
        "Question_body":"<p>Hello,  <br \/>\nI scheduled my pipeline to run weekly. Now I want to disable it. However, when I disable on Azure ML Studio, an error shows as below:  <\/p>\n<p>An error occurred while disabling pipeline  <br \/>\nBadRequest: Cannot deprecate a pipeline with active schedules.  <\/p>\n<p>Trace ID : cded492c-84a5-47aa-afc4-0a678e611e5b  <br \/>\nClient request ID : 4e904a8b-90f5-4572-815d-c23a0249c43b  <\/p>\n<p>Could you look into this? and instruct me how to stop that scheduled pipeline.  <br \/>\nThanks,  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1618002234640,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/351921\/cant-disable-a-scheduled-pipeline-endpoint",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"disabl schedul pipelin endpoint hello schedul pipelin run weekli want disabl disabl studio error show error occur disabl pipelin badrequest deprec pipelin activ schedul trace cdedc afc aeeb client request eab cacb look instruct stop schedul pipelin thank",
        "Question_preprocessed_content":"disabl schedul pipelin endpoint schedul pipelin run want disabl disabl studio show disabl pipelin badrequest deprec pipelin activ schedul trace client request instruct stop schedul pipelin thank",
        "Question_gpt_summary_original":"The user is unable to disable a scheduled pipeline endpoint on Azure ML Studio and receives an error message stating that a pipeline with active schedules cannot be deprecated. The user is seeking guidance on how to stop the scheduled pipeline.",
        "Question_gpt_summary":"user unabl disabl schedul pipelin endpoint studio receiv error messag state pipelin activ schedul deprec user seek guidanc stop schedul pipelin"
    },
    {
        "Question_title":"How to configure comet (comet.ml) to log Tensorflow?",
        "Question_body":"<p>Im trying to set comet (<a href=\"https:\/\/www.comet.ml\" rel=\"nofollow noreferrer\">https:\/\/www.comet.ml<\/a>) to track my Tensorflow experiment, after I create an Experiment and log the data set i dont get the accuracy in my report.<\/p>\n\n<p>my code:<\/p>\n\n<pre><code>mnist = get_data()\ntrain_step, cross_entropy, accuracy, x, y, y_ = build_model_graph(hyper_params)\n\nexperiment = Experiment(api_key=\"XXXX\", log_code=True)\nexperiment.log_multiple_params(hyper_params)\nexperiment.log_dataset_hash(mnist)\n<\/code><\/pre>\n\n<p>in the example account : <a href=\"https:\/\/www.comet.ml\/view\/Jon-Snow\" rel=\"nofollow noreferrer\">https:\/\/www.comet.ml\/view\/Jon-Snow<\/a> I see that accuracy is reported<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1506094686057,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1514341154200,
        "Question_score_count":3.0,
        "Question_view_count":338.0,
        "Poster_created_time":1506066897167,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":4.0,
        "Answer_body":"<p>you can report accuracy using this method:<\/p>\n\n<ul>\n<li><code>experiment.log_accuracy(train_accuracy)<\/code><\/li>\n<\/ul>\n\n<p>take a look at the full Tensorflow example in our guide:<\/p>\n\n<ul>\n<li><a href=\"https:\/\/github.com\/comet-ml\/comet-quickstart-guide\/tree\/master\/tensorflow\" rel=\"nofollow noreferrer\">https:\/\/github.com\/comet-ml\/comet-quickstart-guide\/tree\/master\/tensorflow<\/a><\/li>\n<\/ul>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1506100257932,
        "Answer_last_edit_time":1513514205487,
        "Answer_score_count":3.0,
        "Answerer_created_time":1359884693920,
        "Answerer_location":"Israel",
        "Answerer_reputation_count":9637.0,
        "Answerer_view_count":609.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46368389",
        "Tool":"Comet",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"configur log tensorflow try set http www track tensorflow experi creat experi log data set dont accuraci report code mnist data train step cross entropi accuraci build model graph hyper param experi experi api kei xxxx log code true experi log multipl param hyper param experi log dataset hash mnist exampl account http www view jon snow accuraci report",
        "Question_preprocessed_content":"configur log tensorflow try set track tensorflow experi creat experi log data set dont report code exampl report",
        "Question_gpt_summary_original":"The user is trying to configure comet.ml to track their Tensorflow experiment, but after creating an experiment and logging the data set, they are not getting accuracy in their report. They have shared their code and noticed that accuracy is reported in an example account on comet.ml.",
        "Question_gpt_summary":"user try configur track tensorflow experi creat experi log data set get accuraci report share code notic accuraci report exampl account"
    },
    {
        "Question_title":"ParallelRunStep doesn\u00b4t support multiple input datasets",
        "Question_body":"<p>Currently we are using the parallelrunstep in AML, Is there any workaround\/other approach to support distribute datasets in the parallel run step.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1647759270327,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/779233\/parallelrunstep-doesn-t-support-multiple-input-dat",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"parallelrunstep doesnt support multipl input dataset current parallelrunstep aml workaround approach support distribut dataset parallel run step",
        "Question_preprocessed_content":"doesnt multipl input dataset aml distribut dataset run step",
        "Question_gpt_summary_original":"The user is facing a challenge with the parallelrunstep in AML as it does not support multiple input datasets. They are seeking a workaround or alternative approach to distribute datasets in the parallel run step.",
        "Question_gpt_summary":"user face challeng parallelrunstep aml support multipl input dataset seek workaround altern approach distribut dataset parallel run step"
    },
    {
        "Question_title":"Export trained model in Azure automated ML (Interface)",
        "Question_body":"<p>Hi,    <br \/>\nWe are able to export the trained model by automl module in  Azure ML jupyter notebook. We have set enable_onnx_compatible_models=True in AutoMLConfig. As shown in image below it create  model.onnx and model.pkl  file both for each algorithm and iteration it used.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85755-with-onnx.png?platform=QnA\" alt=\"85755-with-onnx.png\" \/>    <\/p>\n<p>Now we are trying to export the model in automated ML (interface). We can see in image below it only create the model.pkl file not model.onnx file.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85745-without-onnx.png?platform=QnA\" alt=\"85745-without-onnx.png\" \/>    <\/p>\n<p>Is there any configuration change is required to export the trained model in automated ML (Interface), like enable_onnx_compatible_models in Azure ML notebook.    <\/p>\n<p>Best Regards,    <br \/>\nRatan Kumar<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1617885405287,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/349497\/export-trained-model-in-azure-automated-ml-(interf",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"export train model azur autom interfac abl export train model automl modul jupyt notebook set enabl onnx compat model true automlconfig shown imag creat model onnx model pkl file algorithm iter try export model autom interfac imag creat model pkl file model onnx file configur chang requir export train model autom interfac like enabl onnx compat model notebook best regard ratan kumar",
        "Question_preprocessed_content":"export train model azur autom abl export train model automl modul jupyt set automlconfig shown imag creat file algorithm iter try export model autom imag creat file file configur chang requir export train model autom like best regard ratan kumar",
        "Question_gpt_summary_original":"The user is able to export trained models using Azure ML Jupyter notebook with the enable_onnx_compatible_models=True configuration, which creates both model.onnx and model.pkl files. However, when trying to export the model in Azure ML interface, only the model.pkl file is created. The user is seeking guidance on whether any configuration changes are required to export the trained model in automated ML (Interface).",
        "Question_gpt_summary":"user abl export train model jupyt notebook enabl onnx compat model true configur creat model onnx model pkl file try export model interfac model pkl file creat user seek guidanc configur chang requir export train model autom interfac"
    },
    {
        "Question_title":"Azure ML - Managed Identity for Compute Instance",
        "Question_body":"<p>We need to connect Azure Data Lake Storage Gen2 to Azure Machine Learning by means of a datastore. For security reasons we do not want to provide the credential-based authentication credentials (service principal or SAS token). Instead we want to connect with identity based access.  <\/p>\n<p>The problem we face is that we are not able to assign a managed identity to a compute instance, so we can connect from notebooks to the Data Lake. In the documentation is explained how to assign a managed identity to a cluster, but we need the same for the compute instance, as it is the only way to run commands directly from the notebook.  <\/p>\n<p>Is there a way to assign managed identity to an Azure Machine Learning Compute Instance? Otherwise, we would like to know the best approach to overcome this issue, considering that we do not want to introduce the credentials in the code.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1637143820660,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=cbcc7cd1-be1d-4352-9648-87343bfaafff\">@Nimbeo  <\/a> Thanks for the question. Currently It\u2019s not supported yet  to assign managed identity to an Azure Machine Learning Compute Instance, you\u2019d need to use credential-based access. We have forwarded to the product team to support in the near future.<\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1637157273152,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/630520\/azure-ml-managed-identity-for-compute-instance",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"manag ident comput instanc need connect azur data lake storag gen mean datastor secur reason want provid credenti base authent credenti servic princip sa token instead want connect ident base access problem face abl assign manag ident comput instanc connect notebook data lake document explain assign manag ident cluster need comput instanc wai run command directli notebook wai assign manag ident comput instanc like know best approach overcom issu consid want introduc credenti code",
        "Question_preprocessed_content":"manag ident comput instanc azur data lake storag gen mean datastor secur reason want provid authent credenti instead want ident base problem face abl manag ident comput instanc data lake document explain manag ident cluster comput instanc wai run directli wai manag ident comput instanc like know best overcom consid want introduc credenti code",
        "Question_gpt_summary_original":"The user is facing a challenge in connecting Azure Data Lake Storage Gen2 to Azure Machine Learning using a datastore due to security reasons. They are unable to assign a managed identity to a compute instance, which is necessary to connect from notebooks to the Data Lake. The user is seeking a solution to assign a managed identity to an Azure Machine Learning Compute Instance or an alternative approach to overcome this issue without introducing credentials in the code.",
        "Question_gpt_summary":"user face challeng connect azur data lake storag gen datastor secur reason unabl assign manag ident comput instanc necessari connect notebook data lake user seek solut assign manag ident comput instanc altern approach overcom issu introduc credenti code"
    },
    {
        "Question_title":"Question about ML output",
        "Question_body":"<p>Dear Support,    <\/p>\n<p>I have draft a pipeline as following:    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/194175-image.png?platform=QnA\" alt=\"194175-image.png\" \/>    <\/p>\n<p>you can see it has 2 webservice output,    <\/p>\n<p>may I know where I can see the 2 output and how to use it ? thnaks. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1650351269333,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/817010\/question-about-ml-output",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"question output dear support draft pipelin follow webservic output know output us thnak",
        "Question_preprocessed_content":"question output dear draft pipelin webservic output know output us thnak",
        "Question_gpt_summary_original":"The user has created a pipeline with two webservice outputs and is seeking guidance on how to access and utilize these outputs.",
        "Question_gpt_summary":"user creat pipelin webservic output seek guidanc access util output"
    },
    {
        "Question_title":"MLFlow SparkTrials maxNumConcurrentTasks([]) does not exist",
        "Question_body":"<p>I'm very new at using mlflow and I'm currently having some issues on its SparkTrials. I'm running the following code in my Jupyter notebook using Anaconda:<\/p>\n<pre><code>import mlflow\nfrom hyperopt import hp, fmin, tpe, rand, SparkTrials, STATUS_OK, STATUS_FAIL, space_eval\n\n# replicate input_pd dataframe to workers in Spark cluster\ninputs = sc.broadcast(input_pd)\n\n# configure hyperopt settings to distribute to all executors on workers\nspark_trials = SparkTrials()\n\n# select optimization algorithm\nalgo = tpe.suggest\n\n# perform hyperparameter tuning (logging iterations to mlflow)\nargmin = fmin(\n  fn=evaluate_model,\n  space=search_space,\n  algo=algo,\n  max_evals=100,\n  trials=spark_trials\n  )\n\n# release the broadcast dataset\ninputs.unpersist()\n<\/code><\/pre>\n<p>But, I get the following error:<\/p>\n<pre><code>  Py4JError: An error occurred while calling o233.maxNumConcurrentTasks. Trace:\n    py4j.Py4JException: Method maxNumConcurrentTasks([]) does not exist\n        at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n        at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n        at py4j.Gateway.invoke(Gateway.java:274)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:238)\n        at java.lang.Thread.run(Unknown Source)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1625197883137,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":187.0,
        "Poster_created_time":1617289926807,
        "Poster_location":null,
        "Poster_reputation_count":165.0,
        "Poster_view_count":68.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68219396",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sparktrial maxnumconcurrenttask exist new current have issu sparktrial run follow code jupyt notebook anaconda import hyperopt import fmin tpe rand sparktrial statu statu fail space eval replic input datafram worker spark cluster input broadcast input configur hyperopt set distribut executor worker spark trial sparktrial select optim algorithm algo tpe suggest perform hyperparamet tune log iter argmin fmin evalu model space search space algo algo max eval trial spark trial releas broadcast dataset input unpersist follow error pyjerror error occur call maxnumconcurrenttask trace pyj pyjexcept method maxnumconcurrenttask exist pyj reflect reflectionengin getmethod reflectionengin java pyj reflect reflectionengin getmethod reflectionengin java pyj gatewai invok gatewai java pyj command abstractcommand invokemethod abstractcommand java pyj command callcommand execut callcommand java pyj gatewayconnect run gatewayconnect java java lang thread run unknown sourc",
        "Question_preprocessed_content":"sparktrial exist new have sparktrial code jupyt anaconda",
        "Question_gpt_summary_original":"The user is encountering an error while using MLFlow's SparkTrials for hyperparameter tuning. The error message indicates that the method maxNumConcurrentTasks([]) does not exist.",
        "Question_gpt_summary":"user encount error sparktrial hyperparamet tune error messag indic method maxnumconcurrenttask exist"
    },
    {
        "Question_title":"Remote s3 cache storage with minio",
        "Question_body":"<p>Hello,<br>\nFirst of all thank you for your contribution.<br>\nI would like to ask if there is a way to keep all my cache of a dataset into a remote minio bucket and not appearing into my local storage.<\/p>\n<p>I have added my dataset into a remote minio bucket<\/p>\n<pre><code class=\"lang-auto\">dvc remote add myminio -d s3:\/\/abucket\/DVC\ndvc remote modify myminio endpointurl 'http:\/\/.....\/'\ndvc remote modify myminio access_key_id 'user'\ndvc remote modify myminio secret_access_key 'pass'\n\ndvc add data\ngit add .gitignore data.dvc .dvc\/config\ngit commit -m '-Added remote storage,-Added data'\ndvc push\nrm -r .dvc\/cache\n<\/code><\/pre>\n<p>But when I try to do a dvc pull, the cache directory always return.<\/p>\n<p>Is there a way to define that my cache folder is my remote?<br>\nAlso can I use dvc pull on another PC without data.dvc?<\/p>\n<p>Thank you in advance<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_created_time":1674558901821,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":483.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/remote-s3-cache-storage-with-minio\/1472",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"remot cach storag minio hello thank contribut like ask wai cach dataset remot minio bucket appear local storag ad dataset remot minio bucket remot add myminio abucket remot modifi myminio endpointurl http remot modifi myminio access kei user remot modifi myminio secret access kei pass add data git add gitignor data config git commit ad remot storag ad data push cach try pull cach directori return wai defin cach folder remot us pull data thank advanc",
        "Question_preprocessed_content":"remot cach storag minio thank contribut like ask wai cach dataset remot minio bucket local storag dataset remot minio bucket try cach directori return wai defin cach folder remot us thank advanc",
        "Question_gpt_summary_original":"The user is seeking a way to store all cache of a dataset in a remote minio bucket instead of local storage. They have added the dataset to a remote minio bucket and used dvc push to push the data. However, when they try to do a dvc pull, the cache directory always returns. The user is looking for a way to define that their cache folder is remote and also wants to know if they can use dvc pull on another PC without data.dvc.",
        "Question_gpt_summary":"user seek wai store cach dataset remot minio bucket instead local storag ad dataset remot minio bucket push push data try pull cach directori return user look wai defin cach folder remot want know us pull data"
    },
    {
        "Question_title":"The workspace configuration file config.json, could not be found",
        "Question_body":"<p>I'm building a batch inference pipeline <strong>azureml.pipeline<\/strong>. I've placed the config.json in the directory and passed it explicitly<\/p>\n<pre><code class=\"lang-python\">ws = Workspace.from_config(path='ranking\/config.json')\n<\/code><\/pre>\n<p>I tried to let azure find it:<\/p>\n<pre><code class=\"lang-python\">ws = Workspace.from_config()\n<\/code><\/pre>\n<p>but in both cases, azure sdk doesn't seem to acknowledge the file.<\/p>\n<p><strong>The First:<\/strong><\/p>\n<p>&quot;error&quot;: {<\/p>\n<pre><code>    &quot;code&quot;: &quot;UserError&quot;,\n\n    &quot;message&quot;: &quot;The workspace configuration file config.json, could not be found in \/tmp\/44660cc1-2a72-49df-af2b-e41226727952\/azureml-bi\/114\/ranking\/config.json or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http:\/\/ml.azure.com and clicking on the name of your workspace in the right top.&quot;\n\n}\n<\/code><\/pre>\n<p><strong>The second:<\/strong><\/p>\n<p>&quot;error&quot;: {<\/p>\n<pre><code>    &quot;code&quot;: &quot;UserError&quot;,\n\n    &quot;message&quot;: &quot;The workspace configuration file config.json, could not be found in \/tmp\/44660cc1-2a72-49df-af2b-e41226727952\/azureml-bi\/114\/ or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http:\/\/ml.azure.com and clicking on the name of your workspace in the right top.&quot;\n\n}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1678117113273,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1186946\/the-workspace-configuration-file-config-json-could",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"workspac configur file config json build batch infer pipelin pipelin place config json directori pass explicitli workspac config path rank config json tri let azur workspac config case azur sdk acknowledg file error code usererror messag workspac configur file config json tmp afb rank config json parent directori check workspac configur file exist provid path configur file argument download configur file workspac http azur com click workspac right second error code usererror messag workspac configur file config json tmp afb parent directori check workspac configur file exist provid path configur file argument download configur file workspac http azur com click workspac right",
        "Question_preprocessed_content":"workspac configur file build batch infer pipelin pipelin place directori explicitli tri let azur case azur sdk acknowledg file second",
        "Question_gpt_summary_original":"The user is building a batch inference pipeline using azureml.pipeline and has placed the config.json file in the directory and passed it explicitly. However, when trying to let Azure find it, the Azure SDK does not seem to acknowledge the file, resulting in an error message stating that the workspace configuration file config.json could not be found in the specified directory or its parent directories. The user is advised to check whether the workspace configuration file exists or provide the full path to the configuration file as an argument.",
        "Question_gpt_summary":"user build batch infer pipelin pipelin place config json file directori pass explicitli try let azur azur sdk acknowledg file result error messag state workspac configur file config json specifi directori parent directori user advis check workspac configur file exist provid path configur file argument"
    },
    {
        "Question_title":"Google Cloud Translation language support for bcp-47",
        "Question_body":"Google Speech to Text supports languages using bcp 47 codes like es-MX for mexican spanish and pt-BR for Brazilian Portugese.\n\nI am using transcription and translation in a pipeline.\n\nIs there any support for bcp 47 languages in Google Cloud Translation.",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1658348100000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":130.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-Translation-language-support-for-bcp-47\/m-p\/445359#M439",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"googl cloud translat languag support bcp googl speech text support languag bcp code like mexican spanish brazilian portuges transcript translat pipelin support bcp languag googl cloud translat",
        "Question_preprocessed_content":"cloud translat languag text languag bcp code like mexican spanish brazilian portuges transcript translat pipelin bcp languag cloud translat",
        "Question_gpt_summary_original":"The user is inquiring about the support for bcp-47 languages in Google Cloud Translation for their transcription and translation pipeline.",
        "Question_gpt_summary":"user inquir support bcp languag googl cloud translat transcript translat pipelin"
    },
    {
        "Question_title":"How to create azure machine learning resource using terraform resource providers?",
        "Question_body":"<p>I wants to create azure machine learning workspace using terraform scripts.Is there any terraform provider to achieve this.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1.0,
        "Question_created_time":1581577491623,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1152.0,
        "Poster_created_time":1565633099383,
        "Poster_location":null,
        "Poster_reputation_count":110.0,
        "Poster_view_count":12.0,
        "Answer_body":"<p>In the meantime Microsoft has added a Terraform resource for ML Workspace in the Azure Provider. This should make any custom scripting obsolete.<\/p>\n<p><a href=\"https:\/\/www.terraform.io\/docs\/providers\/azurerm\/r\/machine_learning_workspace.html\" rel=\"nofollow noreferrer\">https:\/\/www.terraform.io\/docs\/providers\/azurerm\/r\/machine_learning_workspace.html<\/a><\/p>\n<pre><code>resource &quot;azurerm_machine_learning_workspace&quot; &quot;example&quot; {\n  name                    = &quot;example-workspace&quot;\n  location                = azurerm_resource_group.example.location\n  resource_group_name     = azurerm_resource_group.example.name\n  application_insights_id = azurerm_application_insights.example.id\n  key_vault_id            = azurerm_key_vault.example.id\n  storage_account_id      = azurerm_storage_account.example.id\n\n  identity {\n    type = &quot;SystemAssigned&quot;\n  }\n}\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1600285333648,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1391261341596,
        "Answerer_location":null,
        "Answerer_reputation_count":76.0,
        "Answerer_view_count":4.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60202189",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat resourc terraform resourc provid want creat workspac terraform script terraform provid achiev",
        "Question_preprocessed_content":"creat resourc resourc provid want creat workspac provid achiev",
        "Question_gpt_summary_original":"The user is looking for a way to create an Azure machine learning workspace using Terraform scripts and is seeking information on whether there is a Terraform provider available for this purpose.",
        "Question_gpt_summary":"user look wai creat workspac terraform script seek inform terraform provid avail purpos"
    },
    {
        "Question_title":"Tensorboard version conflict",
        "Question_body":"<p>Guildai tensorboard functionallity don\u0107t work for me for some time. Now I would like to make it work.<\/p>\n<p>If I execute command <code>guild tensorboard --started 'last 1 hour'<\/code>  I get:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt; guild tensorboard --started 'last 1 hour'\nPreparing runs for TensorBoard\n2020-09-24 11:32:59.909813: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\nTraceback (most recent call last):\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\programdata\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\Scripts\\guild.exe\\__main__.py\", line 7, in &lt;module&gt;\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main_bootstrap.py\", line 40, in main\n    guild.main.main()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main.py\", line 33, in main\n    _main()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\main.py\", line 40, in _main\n    main_cmd.main(standalone_mode=False)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 829, in __call__\n    return self.main(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 782, in main\n    rv = self.invoke(ctx)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\external\\click\\core.py\", line 610, in invoke\n    return callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\click_util.py\", line 201, in fn\n    return fn0(*(args + (Args(**kw),)))\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\tensorboard.py\", line 108, in tensorboard\n    tensorboard_impl.main(args)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 46, in main\n    _run_tensorboard(args)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\commands\\tensorboard_impl.py\", line 98, in _run_tensorboard\n    tensorboard.serve_forever(\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\tensorboard.py\", line 607, in serve_forever\n    app = create_app(logdir, reload_interval, tensorboard_options=tensorboard_options)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\tensorboard.py\", line 508, in create_app\n    plugins = _tensorboard_plugins(disabled_plugins)\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\tensorboard.py\", line 522, in _tensorboard_plugins\n    base_plugins = tensorboard.base_plugins()\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\guild\\plugins\\tensorboard.py\", line 232, in base_plugins\n    return list(set(default.get_plugins() + default.get_dynamic_plugins()))\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\tensorboard\\default.py\", line 122, in get_dynamic_plugins\n    return [\n  File \"c:\\programdata\\anaconda3\\lib\\site-packages\\tensorboard\\default.py\", line 123, in &lt;listcomp&gt;\n    entry_point.load()\n  File \"C:\\Users\\Mislav\\AppData\\Roaming\\Python\\Python38\\site-packages\\pkg_resources\\__init__.py\", line 2471, in load\n    self.require(*args, **kwargs)\n  File \"C:\\Users\\Mislav\\AppData\\Roaming\\Python\\Python38\\site-packages\\pkg_resources\\__init__.py\", line 2494, in require\n    items = working_set.resolve(reqs, env, installer, extras=self.extras)\n  File \"C:\\Users\\Mislav\\AppData\\Roaming\\Python\\Python38\\site-packages\\pkg_resources\\__init__.py\", line 790, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.VersionConflict: (requests 2.18.4 (c:\\users\\mislav\\appdata\\roaming\\python\\python38\\site-packages), Requirement.parse('requests&lt;3,&gt;=2.21.0'))\n<\/code><\/pre>\n<p><code>Conda list requests<\/code> gives:<\/p>\n<pre><code>(base) PS C:\\Users\\Mislav\\Documents\\GitHub\\trademl&gt; conda list requests\n# packages in environment at C:\\ProgramData\\Anaconda3:\n#\n# Name                    Version                   Build  Channel\nrequests                  2.24.0             pyh9f0ad1d_0    conda-forge\nrequests-oauthlib         1.3.0                    pypi_0    pypi\n<\/code><\/pre>\n<p>so it is greater than 2.21 and lower than 3?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1600941341725,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1087.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/tensorboard-version-conflict\/353",
        "Tool":"Guild AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tensorboard version conflict tensorboard functional dont work time like work execut command tensorboard start hour base user mislav document github trademl tensorboard start hour prepar run tensorboard tensorflow stream executor platform default dso loader successfulli open dynam librari cudart dll traceback recent file programdata anaconda lib runpi line run modul main return run code code main global file programdata anaconda lib runpi line run code exec code run global file programdata anaconda script ex main line file programdata anaconda lib site packag main bootstrap line main main main file programdata anaconda lib site packag main line main main file programdata anaconda lib site packag main line main main cmd main standalon mode fals file programdata anaconda lib site packag extern click core line return self main arg kwarg file programdata anaconda lib site packag extern click core line main self invok ctx file programdata anaconda lib site packag extern click core line invok return process result sub ctx command invok sub ctx file programdata anaconda lib site packag extern click core line invok return ctx invok self callback ctx param file programdata anaconda lib site packag extern click core line invok return callback arg kwarg file programdata anaconda lib site packag click util line return arg arg file programdata anaconda lib site packag command tensorboard line tensorboard tensorboard impl main arg file programdata anaconda lib site packag command tensorboard impl line main run tensorboard arg file programdata anaconda lib site packag command tensorboard impl line run tensorboard tensorboard serv forev file programdata anaconda lib site packag tensorboard line serv forev app creat app logdir reload interv tensorboard option tensorboard option file programdata anaconda lib site packag tensorboard line creat app plugin tensorboard plugin disabl plugin file programdata anaconda lib site packag tensorboard line tensorboard plugin base plugin tensorboard base plugin file programdata anaconda lib site packag plugin tensorboard line base plugin return list set default plugin default dynam plugin file programdata anaconda lib site packag tensorboard default line dynam plugin return file programdata anaconda lib site packag tensorboard default line entri point load file user mislav appdata roam python python site packag pkg resourc init line load self requir arg kwarg file user mislav appdata roam python python site packag pkg resourc init line requir item work set resolv req env instal extra self extra file user mislav appdata roam python python site packag pkg resourc init line resolv rais versionconflict dist req context depend req pkg resourc versionconflict request user mislav appdata roam python python site packag requir pars request conda list request give base user mislav document github trademl conda list request packag environ programdata anaconda version build channel request pyhfadd conda forg request oauthlib pypi pypi greater lower",
        "Question_preprocessed_content":"tensorboard version conflict tensorboard dont work time like work execut give greater lower",
        "Question_gpt_summary_original":"The user is facing an issue with the Tensorboard functionality of Guildai. When executing the command \"guild tensorboard --started 'last 1 hour'\", the user encounters a version conflict error related to the 'requests' package. The user has checked the version of the 'requests' package using the command \"conda list requests\" and found that it is greater than 2.21 and lower than 3.",
        "Question_gpt_summary":"user face issu tensorboard function execut command tensorboard start hour user encount version conflict error relat request packag user check version request packag command conda list request greater lower"
    },
    {
        "Question_title":"Logging Artifacts from MlFlow on GCS Bucket",
        "Question_body":"<p>I have a running MlFlow server on GCS VM instance. I have created a bucket to log the artifacts.\nThis is the command I'm running to start the server and for specifying bucket path-<\/p>\n\n<pre><code>mlflow server --default-artifact-root gs:\/\/gcs_bucket\/artifacts --host x.x.x.x\n<\/code><\/pre>\n\n<p>But facing this error:<\/p>\n\n<pre><code>TypeError: stat: path should be string, bytes, os.PathLike or integer, not ElasticNet\n<\/code><\/pre>\n\n<p>Note- The mlflow server is running fine with the specified host alone. The problem is in the way when I'm specifying the storage bucket path.\nI have given permission of storage api by using these commands:<\/p>\n\n<pre><code>gcloud auth application-default login\ngcloud auth login\n<\/code><\/pre>\n\n<p>Also, on printing the artifact URI, this is what I'm getting:<\/p>\n\n<pre><code>mlflow.get_artifact_uri()\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>gs:\/\/gcs_bucket\/artifacts\/0\/122481bf990xxxxxxxxxxxxxxxxxxxxx\/artifacts\n<\/code><\/pre>\n\n<p>So in the above path from where this is coming <code>0\/122481bf990xxxxxxxxxxxxxxxxxxxxx\/artifacts<\/code> and why it's not getting auto-created at <code>gs:\/\/gcs_bucket\/artifacts<\/code><\/p>\n\n<p>After debugging more, why it's not able to get the local path from VM:\n<a href=\"https:\/\/i.stack.imgur.com\/ubDU0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ubDU0.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And this error I'm getting on VM:<\/p>\n\n<pre><code>ARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '.\/mlruns\/mlruns\/meta.yaml' does not exist.\nTraceback (most recent call last):\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 197, in list_experiments\n   experiment = self._get_experiment(exp_id, view_type)\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 256, in _get_experiment\n   meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/utils\/file_utils.py\", line 160, in read_yaml\n   raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\nmlflow.exceptions.MissingConfigException: Yaml file '.\/mlruns\/mlruns\/meta.yaml' does not exist.\n<\/code><\/pre>\n\n<p>Can I get a solution to this and what I'm missing?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7.0,
        "Question_created_time":1583840420677,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1583922371776,
        "Question_score_count":4.0,
        "Question_view_count":2153.0,
        "Poster_created_time":1451124057623,
        "Poster_location":"India",
        "Poster_reputation_count":736.0,
        "Poster_view_count":234.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60616879",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"log artifact gc bucket run server gc instanc creat bucket log artifact command run start server specifi bucket path server default artifact root gc bucket artifact host face error typeerror stat path string byte pathlik integ elasticnet note server run fine specifi host problem wai specifi storag bucket path given permiss storag api command gcloud auth applic default login gcloud auth login print artifact uri get artifact uri output gc bucket artifact bfxxxxxxxxxxxxxxxxxxxxx artifact path come bfxxxxxxxxxxxxxxxxxxxxx artifact get auto creat gc bucket artifact debug abl local path error get arn root malform experi mlrun detail error yaml file mlrun mlrun meta yaml exist traceback recent file usr local lib python dist packag store track file store line list experi experi self experi exp view type file usr local lib python dist packag store track file store line experi meta read yaml experi dir filestor meta data file file usr local lib python dist packag util file util line read yaml rais missingconfigexcept yaml file exist file path except missingconfigexcept yaml file mlrun mlrun meta yaml exist solut miss",
        "Question_preprocessed_content":"artifact gc bucket server gc instanc creat bucket log artifact start server specifi bucket path face note server fine specifi host problem wai specifi storag bucket path given storag api print artifact uri output path come abl local path solut",
        "Question_gpt_summary_original":"The user is encountering an error while trying to log artifacts from MlFlow on a GCS bucket. The error message states that the path should be a string, bytes, os.PathLike or integer, not ElasticNet. The user has given permission of storage API and is getting an output on printing the artifact URI. However, the path is not getting auto-created at the specified location. The user is also getting an error on the VM and is looking for a solution to the problem.",
        "Question_gpt_summary":"user encount error try log artifact gc bucket error messag state path string byte pathlik integ elasticnet user given permiss storag api get output print artifact uri path get auto creat specifi locat user get error look solut problem"
    },
    {
        "Question_title":"How to get preprocess\/postprocess steps from model created using Google Vertex AI?",
        "Question_body":"<p>A client of mine wants to run their Google Vertex AI model on NVIDIA Jetson boards using TensorRT as accelerator. The problem with this is that their model uses certain operators (DecodeJpeg) that are not supported by ONNX. I've been able to isolate the feature extrator subgraph from the model, so everything supported by ONNX is being used, while the preprocess and postprocess will be written separate from the model.<\/p>\n<p>I'm asking because I need to be provided the pre\/postprocess of the model so I could implement them separately, so is there a way to get pre\/postprocess from Google Vertex AI console?<\/p>\n<p>I've tried running a loop that rescales the image to a squared tile from 0 to 512, but none of those gave the adequate result.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_created_time":1649079409933,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":107.0,
        "Poster_created_time":1616415228996,
        "Poster_location":null,
        "Poster_reputation_count":16.0,
        "Poster_view_count":8.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71738221",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"preprocess postprocess step model creat client want run model nvidia jetson board tensorrt acceler problem model us certain oper decodejpeg support onnx abl isol featur extrat subgraph model support onnx preprocess postprocess written separ model ask need provid pre postprocess model implement separ wai pre postprocess consol tri run loop rescal imag squar tile gave adequ result",
        "Question_preprocessed_content":"step model creat client want run model nvidia jetson board problem model us certain oper abl isol featur extrat subgraph model separ model ask provid model implement separ wai consol tri rescal imag squar tile gave adequ result",
        "Question_gpt_summary_original":"The user wants to run a Google Vertex AI model on NVIDIA Jetson boards using TensorRT as an accelerator. However, certain operators used in the model are not supported by ONNX. The user has isolated the feature extractor subgraph from the model, but needs the preprocess and postprocess steps separately. The user is asking if there is a way to get the pre\/postprocess from the Google Vertex AI console. The user has tried rescaling the image but has not achieved the desired result.",
        "Question_gpt_summary":"user want run model nvidia jetson board tensorrt acceler certain oper model support onnx user isol featur extractor subgraph model need preprocess postprocess step separ user ask wai pre postprocess consol user tri rescal imag achiev desir result"
    },
    {
        "Question_title":"Tensorflow error. TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn",
        "Question_body":"<p>I am trying to run this on Amazon Sagemaker but I am getting this error while when I try to run it on my local machine, it works very fine.<\/p>\n<p>this is my code:<\/p>\n<pre><code>import tensorflow as tf\n\nimport IPython.display as display\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nmpl.rcParams['figure.figsize'] = (12,12)\nmpl.rcParams['axes.grid'] = False\n\nimport numpy as np\nimport PIL.Image\nimport time\nimport functools\n    \ndef tensor_to_image(tensor):\n  tensor = tensor*255\n  tensor = np.array(tensor, dtype=np.uint8)\n  if np.ndim(tensor)&gt;3:\n    assert tensor.shape[0] == 1\n    tensor = tensor[0]\n  return PIL.Image.fromarray(tensor)\n\ncontent_path = tf.keras.utils.get_file('YellowLabradorLooking_nw4.jpg', 'https:\/\/example.com\/IMG_20200216_163015.jpg')\n\n\nstyle_path = tf.keras.utils.get_file('kandinsky3.jpg','https:\/\/example.com\/download+(2).png')\n\n\ndef load_img(path_to_img):\n    max_dim = 512\n    img = tf.io.read_file(path_to_img)\n    img = tf.image.decode_image(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n    long_dim = max(shape)\n    scale = max_dim \/ long_dim\n\n    new_shape = tf.cast(shape * scale, tf.int32)\n\n    img = tf.image.resize(img, new_shape)\n    img = img[tf.newaxis, :]\n    return img\n\n\ndef imshow(image, title=None):\n  if len(image.shape) &gt; 3:\n    image = tf.squeeze(image, axis=0)\n\n  plt.imshow(image)\n  if title:\n    plt.title(title)\n\n\ncontent_image = load_img(content_path)\nstyle_image = load_img(style_path)\n\nplt.subplot(1, 2, 1)\nimshow(content_image, 'Content Image')\n\nplt.subplot(1, 2, 2)\nimshow(style_image, 'Style Image')\n\nimport tensorflow_hub as hub\nhub_module = hub.load('https:\/\/tfhub.dev\/google\/magenta\/arbitrary-image-stylization-v1-256\/1')\nstylized_image = hub_module(tf.constant(content_image), tf.constant(style_image))[0]\ntensor_to_image(stylized_image)\n\n\nfile_name = 'stylized-image5.png'\ntensor_to_image(stylized_image).save(file_name)\n<\/code><\/pre>\n<p>This is the exact error I get:<\/p>\n<pre><code>---------------------------------------------------------------------------\n<\/code><\/pre>\n<p>TypeError                                 Traceback (most recent call last)<\/p>\n<pre><code>&lt;ipython-input-24-c47a4db4880c&gt; in &lt;module&gt;()\n     53 \n     54 \n---&gt; 55 content_image = load_img(content_path)\n     56 style_image = load_img(style_path)\n     57 \n<\/code><\/pre>\n<p> in load_img(path_to_img)<\/p>\n<pre><code>     34 \n     35     shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n---&gt; 36     long_dim = max(shape)\n     37     scale = max_dim \/ long_dim\n     38 \n<\/code><\/pre>\n<p>~\/anaconda3\/envs\/amazonei_tensorflow_p36\/lib\/python3.6\/site-packages\/tensorflow\/python\/framework\/ops.py in <strong>iter<\/strong>(self)<\/p>\n<pre><code>    475     if not context.executing_eagerly():\n    476       raise TypeError(\n--&gt; 477           &quot;Tensor objects are only iterable when eager execution is &quot;\n    478           &quot;enabled. To iterate over this tensor use tf.map_fn.&quot;)\n    479     shape = self._shape_tuple()\n<\/code><\/pre>\n<p>TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1594076057097,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1530.0,
        "Poster_created_time":1565307837780,
        "Poster_location":null,
        "Poster_reputation_count":570.0,
        "Poster_view_count":37.0,
        "Answer_body":"<p>Your error is being raised in this function <code>load_img<\/code>:<\/p>\n<pre><code>def load_img(path_to_img):\n    max_dim = 512\n    img = tf.io.read_file(path_to_img)\n    img = tf.image.decode_image(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n    long_dim = max(shape)\n    scale = max_dim \/ long_dim\n\n    new_shape = tf.cast(shape * scale, tf.int32)\n\n    img = tf.image.resize(img, new_shape)\n    img = img[tf.newaxis, :]\n    return img\n<\/code><\/pre>\n<p>Specifically, this line:<\/p>\n<pre><code>    long_dim = max(shape)\n<\/code><\/pre>\n<p>You are passing a tensor to the <a href=\"https:\/\/docs.python.org\/3\/library\/functions.html#max\" rel=\"nofollow noreferrer\">built-in Python max function<\/a> in graph execution mode. You can only iterate through tensors in eager-execution mode. You probably want to use <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/math\/reduce_max\" rel=\"nofollow noreferrer\">tf.reduce_max<\/a> instead:<\/p>\n<pre><code>    long_dim = tf.reduce_max(shape)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1594129639003,
        "Answer_last_edit_time":1594159994640,
        "Answer_score_count":1.0,
        "Answerer_created_time":1374169767267,
        "Answerer_location":"San Francisco, CA, USA",
        "Answerer_reputation_count":548.0,
        "Answerer_view_count":70.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62765658",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tensorflow error typeerror tensor object iter eager execut enabl iter tensor us map try run get error try run local machin work fine code import tensorflow import ipython displai displai import matplotlib pyplot plt import matplotlib mpl mpl rcparam figur figsiz mpl rcparam ax grid fals import numpi import pil imag import time import functool def tensor imag tensor tensor tensor tensor arrai tensor dtype uint ndim tensor assert tensor shape tensor tensor return pil imag fromarrai tensor content path kera util file yellowlabradorlook jpg http exampl com img jpg style path kera util file kandinski jpg http exampl com download png def load img path img max dim img read file path img img imag decod imag img channel img imag convert imag dtype img float shape cast shape img float long dim max shape scale max dim long dim new shape cast shape scale int img imag resiz img new shape img img newaxi return img def imshow imag titl len imag shape imag squeez imag axi plt imshow imag titl plt titl titl content imag load img content path style imag load img style path plt subplot imshow content imag content imag plt subplot imshow style imag style imag import tensorflow hub hub hub modul hub load http tfhub dev googl magenta arbitrari imag styliz styliz imag hub modul constant content imag constant style imag tensor imag styliz imag file styliz imag png tensor imag styliz imag save file exact error typeerror traceback recent content imag load img content path style imag load img style path load img path img shape cast shape img float long dim max shape scale max dim long dim anaconda env amazonei tensorflow lib python site packag tensorflow python framework op iter self context execut eagerli rais typeerror tensor object iter eager execut enabl iter tensor us map shape self shape tupl typeerror tensor object iter eager execut enabl iter tensor us map",
        "Question_preprocessed_content":"tensorflow tensor object iter eager execut enabl iter tensor us try run try run local machin work fine code exact traceback iter tensor object iter eager execut enabl iter tensor us",
        "Question_gpt_summary_original":"The user is encountering a Tensorflow error while trying to run a code on Amazon Sagemaker. The error message states that Tensor objects are only iterable when eager execution is enabled and suggests using tf.map_fn to iterate over the tensor. The code runs fine on the user's local machine.",
        "Question_gpt_summary":"user encount tensorflow error try run code error messag state tensor object iter eager execut enabl suggest map iter tensor code run fine user local machin"
    },
    {
        "Question_title":"RuntimeError: as_numpy_iterator() is not supported while tracing functions on tensorflow 2.x dataset on sagemaker",
        "Question_body":"<p>I am preparing a <a href=\"https:\/\/pypi.org\/project\/sagemaker-tensorflow\/\" rel=\"noreferrer\">sagemaker PIPE mode dataset<\/a> to train a time series model on <code>SageMaker<\/code> with <code>PIPE<\/code> mode. The <code>PipeModeDataset<\/code> is a <code>TensorFlow Dataset<\/code> for reading <code>SageMaker<\/code> Pipe Mode channels. I am using an augmented manifest file which contains image location on <code>S3<\/code> and the label each line. My model accept batches of images (512 x 512 x 1) with single label per batch as input. I thought of using the window function to bundle the images read from pipe. Please refer to following partial code for dataset generation.<\/p>\n<pre><code>def _input_fn(channel):\n    &quot;&quot;&quot;Returns a Dataset for reading from a SageMaker PipeMode channel.&quot;&quot;&quot;\n    features = {\n        'image-ref': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([3], tf.int64),\n    }\n    \n    def parse(record):\n        parsed = tf.io.parse_single_example(record, features)\n        image = tf.io.decode_png(parsed['image-ref'], channels=1, dtype=tf.uint8)\n        image = tf.reshape(image, [512, 512, 1])\n        label = parsed['label']\n        return (image, label)\n\n    ds = PipeModeDataset(channel, record_format='TFRecord', benchmark=True, benchmark_records_interval=100)\n    ds = ds.map(parse)\n    \n    print (&quot;PipeModeDataset print0 = &quot; + str(ds))\n    ds = ds.window(16, shift=1, drop_remainder=True)\n    print (&quot;PipeModeDataset print1 = &quot; + str(ds))\n    \n    def window_func(window, label):\n        window = window.batch(16, drop_remainder=True)\n        label = label.batch(16, drop_remainder=True)\n        \n        print (&quot;window batch is = &quot; + str(window))\n        print (&quot;label batch is = &quot; + str(label))\n        \n        window_np = np.stack(list(window.as_numpy_iterator()))\n        label_np = np.stack(list(label.as_numpy_iterator())) # TODO: only get the last label\n        \n        return tf.data.Dataset.from_tensor_slices((window_np, label_np))\n    \n    ds = ds.flat_map(lambda window, label: window_func(window, label))\n    ....\n    ....\n<\/code><\/pre>\n<p>Getting following error at the moment. How to fix this? Recommend better ways if there is any.<\/p>\n<pre><code>PipeModeDataset print0 = &lt;MapDataset shapes: ((512, 512, 1), (3,)), types: (tf.uint8, tf.int64)&gt;\nPipeModeDataset print1 = &lt;WindowDataset shapes: (DatasetSpec(TensorSpec(shape=(512, 512, 1), dtype=tf.uint8, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(3,), dtype=tf.int64, name=None), TensorShape([]))), types: (DatasetSpec(TensorSpec(shape=(512, 512, 1), dtype=tf.uint8, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(3,), dtype=tf.int64, name=None), TensorShape([])))&gt;\nwindow batch is = &lt;BatchDataset shapes: (16, 512, 512, 1), types: tf.uint8&gt;\nlabel batch is = &lt;BatchDataset shapes: (16, 3), types: tf.int64&gt;\n\nRuntimeError: in user code:\n\n    \/opt\/ml\/code\/train_on_pipemode.py:104 None  *\n        ds = ds.flat_map(lambda window, label: window_func(window, label))\n    \/opt\/ml\/code\/train_on_pipemode.py:96 window_func  *\n        window_np = np.stack(list(window.as_numpy_iterator()))\n    \/usr\/local\/lib\/python3.7\/site-packages\/tensorflow\/python\/data\/ops\/dataset_ops.py:518 as_numpy_iterator  **\n        raise RuntimeError(&quot;as_numpy_iterator() is not supported while tracing &quot;\n\n    RuntimeError: as_numpy_iterator() is not supported while tracing functions\n<\/code><\/pre>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/60045971\/runtimeerror-as-numpy-iterator-is-not-supported-while-tracing-functions\">This answer<\/a> says to enable eager execution, but it is enabled in my case when I printed <code>tf.executing_eagerly()<\/code>. I am training on <code>tensorflow 2.x<\/code>.<\/p>\n<pre><code>Tensorflow version: 2.3.1\nEager execution: True\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1606932510877,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":5.0,
        "Question_view_count":322.0,
        "Poster_created_time":1393576024047,
        "Poster_location":"Sri Lanka",
        "Poster_reputation_count":879.0,
        "Poster_view_count":138.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65113746",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"runtimeerror numpi iter support trace function tensorflow dataset prepar pipe mode dataset train time seri model pipe mode pipemodedataset tensorflow dataset read pipe mode channel augment manifest file contain imag locat label line model accept batch imag singl label batch input thought window function bundl imag read pipe refer follow partial code dataset gener def input channel return dataset read pipemod channel featur imag ref fixedlenfeatur string label fixedlenfeatur int def pars record pars pars singl exampl record featur imag decod png pars imag ref channel dtype uint imag reshap imag label pars label return imag label pipemodedataset channel record format tfrecord benchmark true benchmark record interv map pars print pipemodedataset print str window shift drop remaind true print pipemodedataset print str def window func window label window window batch drop remaind true label label batch drop remaind true print window batch str window print label batch str label window stack list window numpi iter label stack list label numpi iter todo label return data dataset tensor slice window label flat map lambda window label window func window label get follow error moment fix recommend better wai pipemodedataset print pipemodedataset print window batch label batch runtimeerror user code opt code train pipemod flat map lambda window label window func window label opt code train pipemod window func window stack list window numpi iter usr local lib python site packag tensorflow python data op dataset op numpi iter rais runtimeerror numpi iter support trace runtimeerror numpi iter support trace function answer sai enabl eager execut enabl case print execut eagerli train tensorflow tensorflow version eager execut true",
        "Question_preprocessed_content":"trace function tensorflow dataset prepar pipe mode dataset train time seri model mode read pipe mode augment manifest file contain imag locat label line model batch imag singl label batch input thought window function bundl imag read pipe refer partial code dataset gener moment fix wai answer sai enabl eager execut enabl case print train",
        "Question_gpt_summary_original":"The user is encountering a RuntimeError while preparing a sagemaker PIPE mode dataset to train a time series model on SageMaker with PIPE mode. The error occurs when using the window function to bundle the images read from pipe. The error message suggests that as_numpy_iterator() is not supported while tracing functions on tensorflow 2.x dataset on sagemaker. The user has already enabled eager execution and is training on tensorflow 2.3.1.",
        "Question_gpt_summary":"user encount runtimeerror prepar pipe mode dataset train time seri model pipe mode error occur window function bundl imag read pipe error messag suggest numpi iter support trace function tensorflow dataset user enabl eager execut train tensorflow"
    },
    {
        "Question_title":"Getting below error while creating dataset",
        "Question_body":"<p>{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;message&quot;: &quot;Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by StreamAccessException.\\r\\n StreamAccessException was caused by NotFoundException.\\r\\n Found no resources for the input provided: '[REDACTED]'\\r\\n| session_id=9d60cf18-54e5-457a-910d-5dcd223fa0a0&quot;  <br \/>\n}  <br \/>\n}<\/p>\n<p>Code I am using is<\/p>\n<h1 id=\"-----------------------------------------------------\">-----------------------------------------------------<\/h1>\n<h1 id=\"import-required-azureml-classes\">Import required azureml classes<\/h1>\n<h1 id=\"------------------------------------------------------1\">-----------------------------------------------------<\/h1>\n<p>from azureml.core import Workspace, Datastore, Dataset<\/p>\n<h1 id=\"------------------------------------------------------2\">-----------------------------------------------------<\/h1>\n<h1 id=\"access-the-workspace-from-the-configjson\">Access the workspace from the config.json<\/h1>\n<h1 id=\"------------------------------------------------------3\">-----------------------------------------------------<\/h1>\n<p>ws = Workspace.from_config(path=&quot;.\/config&quot;)<\/p>\n<h1 id=\"------------------------------------------------------4\">-----------------------------------------------------<\/h1>\n<h1 id=\"access-datastore-by-its-name\">Access datastore by its name<\/h1>\n<h1 id=\"------------------------------------------------------5\">-----------------------------------------------------<\/h1>\n<p>az_store = Datastore.get(ws, &quot;workspaceblobstore&quot;)<\/p>\n<h1 id=\"------------------------------------------------------6\">-----------------------------------------------------<\/h1>\n<h1 id=\"create-and-register-the-dataset\">Create and register the dataset<\/h1>\n<h1 id=\"------------------------------------------------------7\">-----------------------------------------------------<\/h1>\n<h1 id=\"create-the-path-of-the-csv-file\">Create the path of the csv file<\/h1>\n<p>csv_path = [(az_store, &quot;azureml\/EmployeeAC1.csv&quot;)]<\/p>\n<h1 id=\"create-the-dataset\">Create the dataset<\/h1>\n<h1 id=\"create-the-dataset-1\">Create the dataset<\/h1>\n<p>loan_dataset = Dataset.Tabular.from_delimited_files(path=csv_path)<\/p>\n<p>loan_dataset = loan_dataset.register(workspace=ws,  <br \/>\nname=&quot;Employee Using SDK&quot;,  <br \/>\ncreate_new_version=True)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1633749762887,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/583883\/getting-below-error-while-creating-dataset",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"get error creat dataset error code usererror messag load data specifi path sure path access contain data nscriptexecutionexcept caus streamaccessexcept streamaccessexcept caus notfoundexcept resourc input provid redact session dcf dcdfaa code import requir class core import workspac datastor dataset access workspac config json workspac config path config access datastor store datastor workspaceblobstor creat regist dataset creat path csv file csv path store employeeac csv creat dataset creat dataset loan dataset dataset tabular delimit file path csv path loan dataset loan dataset regist workspac employe sdk creat new version true",
        "Question_preprocessed_content":"creat dataset code import requir core import workspac datastor dataset workspac datastor workspaceblobstor creat regist dataset creat path csv file creat dataset creat dataset sdk",
        "Question_gpt_summary_original":"The user is encountering an error while creating a dataset using AzureML SDK. The error message indicates that no data can be loaded from the specified path and suggests that the path may not be accessible or may not contain data. The code being used involves importing required AzureML classes, accessing the workspace from the config.json, accessing the datastore by its name, creating the path of the CSV file, and creating and registering the dataset.",
        "Question_gpt_summary":"user encount error creat dataset sdk error messag indic data load specifi path suggest path access contain data code involv import requir class access workspac config json access datastor creat path csv file creat regist dataset"
    },
    {
        "Question_title":"Unsupported pytorch version 1.10.0 with SM Elastic Inference Accelerators",
        "Question_body":"Hi Team,\n\nGreetings!!\n\nWe are not able to deploy on real-time endpoint with elastic inference accelerators. Could you please have a look?\n\nSageMaker version: 2.76.0\n\nCode:\nfrom sagemaker.pytorch import PyTorchModel\nfrom sagemaker import get_execution_role\n\nendpoint_name = 'ner-bert'\n\nmodel = PyTorchModel(entry_point='deploy_ei.py',\nsource_dir='code',\nmodel_data=model_data,\nrole=get_execution_role(),\nframework_version='1.10.0',\npy_version='py38')\n\npredictor = model.deploy(initial_instance_count=1,\ninstance_type='ml.m5.xlarge',\naccelerator_type='ml.eia2.medium',\nendpoint_name=endpoint_name)\n\nError details: Unsupported pytorch version: 1.10.0. You may need to upgrade your SDK version (pip install -U sagemaker) for newer pytorch versions. Supported pytorch version(s): 1.3.1, 1.5.1, 1.3, 1.5.\n\nNote: We are able to deploy without elastic accelerator in above code and want to use Python 3.8 version because we have some dependency libraries which supports only Python 3.8 version.\n\nI looked at \"Available DL containers\" at https:\/\/github.com\/aws\/deep-learning-containers\/blob\/master\/available_images.md\nand by looking at this section \"SageMaker Framework Containers (SM support only)\", SM support PyTorch 1.10.0 with Python 3.8 version.\n\nBut we would like to deploy on Elastic Inference and by looking at this section \"Elastic Inference Containers\" in above URL, EI containers supports only PyTorch 1.5.1 with Python 3.6. Why these containers are so outdated?\n\nWhat could be the solution?\n\nCan we specify the latest version of Python in requirements.txt file and get it installed?\n\nThanks,\nVinayak",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1645246550155,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1667925603632,
        "Question_score_count":0.0,
        "Question_view_count":61.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU-LyE6PRQSbq3mXEouDuGjQ\/unsupported-pytorch-version-1-10-0-with-sm-elastic-inference-accelerators",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unsupport pytorch version elast infer acceler team greet abl deploi real time endpoint elast infer acceler look version code pytorch import pytorchmodel import execut role endpoint ner bert model pytorchmodel entri point deploi sourc dir code model data model data role execut role framework version version predictor model deploi initi instanc count instanc type xlarg acceler type eia medium endpoint endpoint error detail unsupport pytorch version need upgrad sdk version pip instal newer pytorch version support pytorch version note abl deploi elast acceler code want us python version depend librari support python version look avail contain http github com aw deep learn contain blob master avail imag look section framework contain support support pytorch python version like deploi elast infer look section elast infer contain url contain support pytorch python contain outdat solut specifi latest version python requir txt file instal thank vinayak",
        "Question_preprocessed_content":"pytorch version elast infer team abl deploi endpoint elast infer version code pytorch import pytorchmodel import model predictor detail pytorch version upgrad sdk version newer pytorch version pytorch version note abl deploi elast code want us python version depend librari python version avail contain section framework contain pytorch python version like deploi elast infer section elast infer contain url contain pytorch python contain outdat solut specifi latest version python file thank vinayak",
        "Question_gpt_summary_original":"The user is facing an issue while deploying a PyTorch model on a real-time endpoint with elastic inference accelerators. The error message suggests that the PyTorch version 1.10.0 is not supported and recommends upgrading the SDK version. However, the user wants to use Python 3.8 version due to dependency libraries. The user found that SageMaker Framework Containers support PyTorch 1.10.0 with Python 3.8, but Elastic Inference Containers only support PyTorch 1.5.1 with Python 3.6. The user is seeking a solution to deploy the model with the latest version of Python.",
        "Question_gpt_summary":"user face issu deploi pytorch model real time endpoint elast infer acceler error messag suggest pytorch version support recommend upgrad sdk version user want us python version depend librari user framework contain support pytorch python elast infer contain support pytorch python user seek solut deploi model latest version python"
    },
    {
        "Question_title":"What syntax references Pipeline parameters in the where clause of a SQL query of 'Import Data' modules in Microsoft Azure Machine Learning designer?",
        "Question_body":"<p>I have created a pipeline in Microsoft Azure Machine Learning designer. I have added a Pipeline parameter myNumber in the pipeline settings, with a valid default value, to accept the unique ID of the asset in our DB so that the pipeline can return only the asset-specific data for use as our model input. Specifically I want to reference that pipeline parameter in the where clause of the SQL query in the 'Import Data' module that connects to our Azure SQL server.  <\/p>\n<p>I cannot find a reference in the documentation on how to do this. I have tried the methods specified for accomplishing this task in Azure Data Factory, using  where RowId = @pipeline().parameters.myNumber or where RowId = @{variables('myNumber')} but the experiment fails with SqlException error code '137', variable not defined.  <\/p>\n<p>Can you please tell me the necessary syntax to reference Pipeline parameters in the where clause of a SQL query of 'Import Data' modules of Microsoft Azure Machine Learning designer?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1616787456817,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/333816\/what-syntax-references-pipeline-parameters-in-the",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"syntax refer pipelin paramet claus sql queri import data modul design creat pipelin design ad pipelin paramet mynumb pipelin set valid default valu accept uniqu asset pipelin return asset specif data us model input specif want refer pipelin paramet claus sql queri import data modul connect azur sql server refer document tri method specifi accomplish task azur data factori rowid pipelin paramet mynumb rowid variabl mynumb experi fail sqlexcept error code variabl defin tell necessari syntax refer pipelin paramet claus sql queri import data modul design",
        "Question_preprocessed_content":"syntax refer pipelin paramet claus sql queri import data modul design creat pipelin design pipelin paramet mynumb pipelin valid default valu uniqu pipelin return specif data us model input want refer pipelin paramet claus sql queri import data modul azur sql server refer document tri method specifi task azur data factori rowid rowid experi fail sqlexcept code variabl defin syntax refer pipelin paramet claus sql queri import data modul design",
        "Question_gpt_summary_original":"The user is having trouble referencing a Pipeline parameter in the where clause of a SQL query in the 'Import Data' module of Microsoft Azure Machine Learning designer. They have tried methods specified for Azure Data Factory but the experiment fails with a SqlException error code '137', variable not defined. They are seeking help to find the necessary syntax to reference Pipeline parameters in the where clause of a SQL query.",
        "Question_gpt_summary":"user have troubl referenc pipelin paramet claus sql queri import data modul design tri method specifi azur data factori experi fail sqlexcept error code variabl defin seek help necessari syntax refer pipelin paramet claus sql queri"
    },
    {
        "Question_title":"Amazon sagemaker. SKlearn estimator vs Tensorflow estimator - why requirements_file is not present in one of them?",
        "Question_body":"<p>I am looking at definitions of two estimators SKLearn and Tensorflow in Amazon Sagemaker:<\/p>\n\n<p><a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/sagemaker.sklearn.html\" rel=\"nofollow noreferrer\">SKLearn<\/a><\/p>\n\n<p><a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/sagemaker.tensorflow.html\" rel=\"nofollow noreferrer\">Tensorflow<\/a><\/p>\n\n<pre><code>class sagemaker.sklearn.estimator.SKLearn(entry_point, framework_version='0.20.0', source_dir=None, hyperparameters=None, py_version='py3', image_name=None, **kwargs)\n\nclass sagemaker.tensorflow.estimator.TensorFlow(training_steps=None, evaluation_steps=None, checkpoint_path=None, py_version='py2', framework_version=None, model_dir=None, requirements_file='', image_name=None, script_mode=False, distributions=None, **kwargs)\n<\/code><\/pre>\n\n<p>Tensorflow has requirements_file parameter, while SKLearn does not. Is there reason why? How can I add <code>requirements.txt<\/code> to SKLearn estimator?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1557166184387,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":221.0,
        "Poster_created_time":1348677250368,
        "Poster_location":null,
        "Poster_reputation_count":6498.0,
        "Poster_view_count":988.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56010337",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sklearn estim tensorflow estim requir file present look definit estim sklearn tensorflow sklearn tensorflow class sklearn estim sklearn entri point framework version sourc dir hyperparamet version imag kwarg class tensorflow estim tensorflow train step evalu step checkpoint path version framework version model dir requir file imag script mode fals distribut kwarg tensorflow requir file paramet sklearn reason add requir txt sklearn estim",
        "Question_preprocessed_content":"sklearn estim tensorflow estim present definit estim sklearn tensorflow sklearn tensorflow tensorflow paramet sklearn reason sklearn estim",
        "Question_gpt_summary_original":"The user is comparing the definitions of two Amazon Sagemaker estimators, SKLearn and Tensorflow, and has noticed that Tensorflow has a \"requirements_file\" parameter while SKLearn does not. The user is seeking to understand the reason for this difference and how to add a \"requirements.txt\" file to the SKLearn estimator.",
        "Question_gpt_summary":"user compar definit estim sklearn tensorflow notic tensorflow requir file paramet sklearn user seek understand reason differ add requir txt file sklearn estim"
    },
    {
        "Question_title":"Vertex AI Training: Auto-packaged Custom Training Job Yields Very Large Docker Image",
        "Question_body":"Hello,\n\nI am trying to run a Custom Training Job in the Vertex AI Training service.\n\nThe job is based on a tutorial for that fine-tuning a pre-trained BERT model (from HuggingFace).\n\nWhen I use the `gcloud` CLI tool to auto-package my training code into a Docker image and deploy it to the Vertex AI Training service like so:\n\n\n$BASE_GPU_IMAGE=\"us-docker.pkg.dev\/vertex-ai\/training\/pytorch-gpu.1-7:latest\"\n$BUCKET_NAME = \"my-bucket\"\n\ngcloud ai custom-jobs create `\n--region=us-central1 `\n--display-name=fine_tune_bert `\n--args=\"--job_dir=$BUCKET_NAME,--num-epochs=2,--model-name=finetuned-bert-classifier\" `\n--worker-pool-spec=\"machine-type=n1-standard-4,replica-count=1,accelerator-type=NVIDIA_TESLA_V100,executor-image-uri=$BASE_GPU_IMAGE,local-package-path=.,python-module=trainer.task\"\n\n\n\n... I end up with a Docker image that is roughly 18GB (!) and takes a very long time to upload to the GCP registry.\n\nGranted the base image is around 6.5GB but where do the additional >10GB come from? Is there a way for me to avoid incurring the added size increase?\n\nPlease note that my job loads the training data using the `datasets` Python package at run time and AFAIK does not include it in the auto-packaged docker image.\n\n\u00a0\n\nThanks,\nurig",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1645930620000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":620.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Hello Ismail,\n\n\u00a0\n\nThank you for your help.\n\nI've checked and to the best of my knowledge there are no data or log files being picked up into my custom docker image.\n\nAccording to an answer that I've received on stackoverflow.com, it's likely that the 18GB size that I'm seeing is the size of my image after extraction. Apparently the ~6.8GB size is for the image compressed.\n\n\u00a0\n\nCheers,\n\n@urig\n\nView solution in original post",
        "Answer_comment_count":null,
        "Question_closed_time":1650182580000,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Training-Auto-packaged-Custom-Training-Job-Yields-Very\/m-p\/397685#M214",
        "Tool":"Vertex AI",
        "Question_self_closed":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train auto packag custom train job yield larg docker imag hello try run custom train job train servic job base tutori fine tune pre train bert model huggingfac us gcloud cli tool auto packag train code docker imag deploi train servic like base gpu imag docker pkg dev vertex train pytorch gpu latest bucket bucket gcloud custom job creat region central displai fine tune bert arg job dir bucket num epoch model finetun bert classifi worker pool spec machin type standard replica count acceler type nvidia tesla executor imag uri base gpu imag local packag path python modul trainer task end docker imag roughli take long time upload gcp registri grant base imag addit come wai avoid incur ad size increas note job load train data dataset python packag run time afaik includ auto packag docker imag thank urig",
        "Question_preprocessed_content":"train custom train job yield larg docker imag try run custom train job train servic job base tutori bert model us cli train code docker imag deploi train servic like gcloud creat end docker imag roughli take long time upload gcp registri grant base imag come wai avoid size increas note job load train data python packag run time afaik includ docker imag thank urig",
        "Question_gpt_summary_original":"The user is facing challenges while running a Custom Training Job in the Vertex AI Training service. The Docker image created by the auto-packaging process is very large, around 18GB, which takes a long time to upload to the GCP registry. The user is unsure where the additional >10GB come from and is looking for a way to avoid incurring the added size increase.",
        "Question_gpt_summary":"user face challeng run custom train job train servic docker imag creat auto packag process larg take long time upload gcp registri user unsur addit come look wai avoid incur ad size increas"
    },
    {
        "Question_title":"Custom Compute Cluster",
        "Question_body":"<p>Hi,<\/p>\n<p>I want to create a compute cluster in Azure ML that has one vGPU and can scale its vCPU's within the specified min and max. Is this possible? And can someone explain how this can be done or point me to a tutorial?<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1680516832996,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Unfortunately, you cannot create a compute cluster with a single vGPU that can scale its vCPUs independently in Azure ML. The available VM sizes in Azure are predefined with a fixed ratio of vCPUs, memory, and GPU resources. However, you can create a compute cluster with different VM sizes that can scale within a specified range of nodes, depending on your requirements<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace#create-a-workspace\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace#create-a-workspace<\/a><\/p>\n",
        "Answer_comment_count":2.0,
        "Question_closed_time":1680518356223,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1195654\/custom-compute-cluster",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"custom comput cluster want creat comput cluster vgpu scale vcpu specifi min max possibl explain point tutori thank advanc",
        "Question_preprocessed_content":"custom comput cluster want creat comput cluster vgpu scale vcpu specifi min max explain point tutori thank advanc",
        "Question_gpt_summary_original":"The user wants to create a compute cluster in Azure ML with one vGPU and the ability to scale vCPU's within a specified range. They are seeking guidance or a tutorial on how to achieve this.",
        "Question_gpt_summary":"user want creat comput cluster vgpu abil scale vcpu specifi rang seek guidanc tutori achiev"
    },
    {
        "Question_title":"How to convert a TensorFlow Data and BatchDataset into Azure DataTable ?",
        "Question_body":"<p>I am training a model using Azure PCA-based Anomaly Detection module and streaming the data for model training and evaluation using Kafka. The train and test dataset are in Azure DataTable format. How do I convert the tf BatchDataset into an Azure DataTable? <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1681270742813,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1221752\/how-to-convert-a-tensorflow-data-and-batchdataset",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"convert tensorflow data batchdataset azur datat train model azur pca base anomali detect modul stream data model train evalu kafka train test dataset azur datat format convert batchdataset azur datat",
        "Question_preprocessed_content":"convert tensorflow data batchdataset azur datat train model azur anomali detect modul stream data model train evalu kafka train test dataset azur datat format convert batchdataset azur datat",
        "Question_gpt_summary_original":"The user is facing a challenge in converting a TensorFlow BatchDataset into an Azure DataTable format for model training and evaluation using Kafka.",
        "Question_gpt_summary":"user face challeng convert tensorflow batchdataset azur datat format model train evalu kafka"
    },
    {
        "Question_title":"Logistic regression in sagemaker",
        "Question_body":"<p>I am using the aws sagemaker for logistic regression. For validating the model on test data, the following code is used <\/p>\n\n<pre><code>runtime= boto3.client('runtime.sagemaker')\n\npayload = np2csv(test_X)\nresponse = runtime.invoke_endpoint(EndpointName=linear_endpoint,\n                                   ContentType='text\/csv',\n                                   Body=payload)\nresult = json.loads(response['Body'].read().decode())\ntest_pred = np.array([r['score'] for r in result['predictions']])\n<\/code><\/pre>\n\n<p>The result contains the prediction values and the probability scores. \nI want to know how I can run a prediction model to predict the outcome based on two specific features. Eg. I have 30 features in the model and have trained model using those features. Now for my prediction, I want to know the outcome when feature1='x' and feature2='y'. But when I filter the data to those columns and pass that in the same code, I get the following error.<\/p>\n\n<pre><code>Customer Error: The feature dimension of the input: 4 does not match the feature dimension of the model: 30. Please fix the input and try again.\n<\/code><\/pre>\n\n<p>What is the equivalent of say glm.predict('feature1','feature2')in R in AWS Sagemaker implementation?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1533920085857,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":1557.0,
        "Poster_created_time":1490822961492,
        "Poster_location":null,
        "Poster_reputation_count":960.0,
        "Poster_view_count":122.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51790953",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"logist regress logist regress valid model test data follow code runtim boto client runtim payload npcsv test respons runtim invok endpoint endpointnam linear endpoint contenttyp text csv bodi payload result json load respons bodi read decod test pred arrai score result predict result contain predict valu probabl score want know run predict model predict outcom base specif featur featur model train model featur predict want know outcom featur featur filter data column pass code follow error custom error featur dimens input match featur dimens model fix input try equival glm predict featur featur implement",
        "Question_preprocessed_content":"logist logist valid model test data code result contain predict valu probabl score want know run predict model predict outcom base specif featur featur model train model featur predict want know outcom featur featur filter data column code equival implement",
        "Question_gpt_summary_original":"The user is facing an issue while trying to predict the outcome based on two specific features using logistic regression in AWS Sagemaker. They have trained the model using 30 features and want to know the outcome when feature1='x' and feature2='y'. However, when they filter the data to those columns and pass it in the code, they get an error stating that the feature dimension of the input does not match the feature dimension of the model. The user is seeking guidance on how to predict the outcome based on specific features in AWS Sagemaker.",
        "Question_gpt_summary":"user face issu try predict outcom base specif featur logist regress train model featur want know outcom featur featur filter data column pass code error state featur dimens input match featur dimens model user seek guidanc predict outcom base specif featur"
    },
    {
        "Question_title":"How to add more photos to AWS Sagemaker Labelling job?",
        "Question_body":"<p>We wish to add more photos to the AWS Sagemaker Labelling job. We tried adding the photo's directly to the s3 path and editing the input manifest file but they don't seem to update on the Labelling task. Is there any workaround for it?<\/p>\n<p>Reference used: <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sms-input-data-input-manifest.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sms-input-data-input-manifest.html<\/a><\/p>\n<p>On a side note: Is there any reference for chaining the jobs, since the documentation on Amazon is confusing and there are no practical examples out there either.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1631557077603,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1632136492540,
        "Question_score_count":1.0,
        "Question_view_count":51.0,
        "Poster_created_time":1631533148667,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69167374",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"add photo label job wish add photo label job tri ad photo directli path edit input manifest file updat label task workaround refer http doc aw amazon com latest sm input data input manifest html note refer chain job document amazon confus practic exampl",
        "Question_preprocessed_content":"photo job wish photo job tri photo directli path edit input manifest file updat task workaround refer note refer chain job document amazon confus practic exampl",
        "Question_gpt_summary_original":"The user is facing challenges in adding more photos to their AWS Sagemaker Labelling job. They have tried adding the photos directly to the s3 path and editing the input manifest file, but the Labelling task does not update. They are looking for a workaround. Additionally, they are seeking references for chaining jobs, as the documentation on Amazon is confusing and lacks practical examples.",
        "Question_gpt_summary":"user face challeng ad photo label job tri ad photo directli path edit input manifest file label task updat look workaround addition seek refer chain job document amazon confus lack practic exampl"
    },
    {
        "Question_title":"Instant crash",
        "Question_body":"<p>Hey Guys, if i wand.init my pc instantly blue screens after inpputing my Key. I have no idea how to figure out what the issue is here and if some of you have any idea please let me know.<br>\nThanks in advance.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1653081865643,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":81.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/instant-crash\/2468",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"instant crash hei gui wand init instantli blue screen inpput kei idea figur issu idea let know thank advanc",
        "Question_preprocessed_content":"instant crash hei gui instantli blue kei idea figur idea let know thank advanc",
        "Question_gpt_summary_original":"The user's PC crashes instantly after inputting their key when they try to wand.init it, and they are seeking help to figure out the issue.",
        "Question_gpt_summary":"user crash instantli input kei try wand init seek help figur issu"
    },
    {
        "Question_title":"Training multiple model in AWS Sagemaker",
        "Question_body":"<p>Can I train multiple model in AWS Sagemaker by evaluating the models is train.py script and also how to get back multiple metrics from multiple models?<\/p>\n\n<p>Any links, docs or videos would be useful.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1584503168147,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1584511840576,
        "Question_score_count":0.0,
        "Question_view_count":695.0,
        "Poster_created_time":1502018973843,
        "Poster_location":"Noida, Uttar Pradesh, India",
        "Poster_reputation_count":311.0,
        "Poster_view_count":115.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60733257",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train multipl model train multipl model evalu model train script multipl metric multipl model link doc video us",
        "Question_preprocessed_content":"train multipl model train multipl model evalu model script multipl metric multipl model link doc video us",
        "Question_gpt_summary_original":"The user is seeking information on how to train multiple models in AWS Sagemaker and how to evaluate them in the train.py script. They are also looking for guidance on how to obtain multiple metrics from these models. They are requesting links, documentation, or videos that could be helpful.",
        "Question_gpt_summary":"user seek inform train multipl model evalu train script look guidanc obtain multipl metric model request link document video help"
    },
    {
        "Question_title":"Deploying custom model on Azure ML Studio",
        "Question_body":"<p>In Azure ML Studio, we have the option of choosing a number of inbuilt ML models like Classification, Regression, etc. , which we can drag and drop to our workflow.<\/p>\n\n<p>My question is, can I upload a custom ML model that I have built locally on my system in Python, and add it to the workflow?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1565761282107,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1565767277470,
        "Question_score_count":1.0,
        "Question_view_count":1187.0,
        "Poster_created_time":1565761178208,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":10.0,
        "Answer_body":"<ol>\n<li>Take the model.pkl file, zip it, and upload it into Azure Machine Learning Studio. Click the \u201cNew\u201d icon in the bottom left:\n<a href=\"https:\/\/i.stack.imgur.com\/Iwvhi.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Iwvhi.jpg\" alt=\"\"><\/a><\/li>\n<li>In the pane that comes up, click on dataset, and then \u201cFrom Local File\u201d:\n<a href=\"https:\/\/i.stack.imgur.com\/DvyjO.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DvyjO.jpg\" alt=\"\"><\/a><\/li>\n<li>Select the zip file where you stored your serialized model and click the tick. You expirement should look like this:\n<a href=\"https:\/\/i.stack.imgur.com\/0efka.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0efka.jpg\" alt=\"\"><\/a><\/li>\n<li>Put the following code to run your classification experiment:<\/li>\n<\/ol>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport sys\nimport pickle\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    sys.path.insert(0,\".\\Script Bundle\")\n    model = pickle.load(open(\".\\Script Bundle\\model.pkl\", 'rb'))\n    pred = model.predict(dataframe1)\n    return pd.DataFrame([pred[0]])\n<\/code><\/pre>\n\n<p><strong>Update<\/strong> \nIf you want to declare this experiment as an API you need to add web input and output to the Python script module.\n<a href=\"https:\/\/i.stack.imgur.com\/eqV8W.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eqV8W.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":7.0,
        "Question_closed_time":1566202471556,
        "Answer_last_edit_time":1566565696980,
        "Answer_score_count":0.0,
        "Answerer_created_time":1528790837107,
        "Answerer_location":"Paris, France",
        "Answerer_reputation_count":610.0,
        "Answerer_view_count":203.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57488706",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi custom model studio studio option choos number inbuilt model like classif regress drag drop workflow question upload custom model built local python add workflow",
        "Question_preprocessed_content":"deploi custom model studio studio option number inbuilt model like drag drop workflow question upload custom model built python workflow",
        "Question_gpt_summary_original":"The user wants to know if they can upload a custom ML model that they have built locally on their system in Python and add it to the workflow in Azure ML Studio, instead of using the inbuilt ML models.",
        "Question_gpt_summary":"user want know upload custom model built local python add workflow studio instead inbuilt model"
    },
    {
        "Question_title":"Custom Training Job with custom container failed with error 'Cant find specification for module...'",
        "Question_body":"Hi everyone,\n\nFor some reason, my custom training Jobs with custom container keep failing on vertex AI but the local run is working fine (I verified by running with local run as indicated in the docs here. I also built the image and run it manually and it works fine).\u00a0\u00a0\n\nError log when running custom job:\u00a0\n\n<code>\n\n{\n\"insertId\": \"2s7rqvfjzoq4v\",\n\"jsonPayload\": {\n\"attrs\": {\n\"tag\": \"workerpool0-0\"\n},\n\"message\": \"\/opt\/conda\/bin\/python: Error while finding module specification for 'trainer.train' (ModuleNotFoundError: No module named 'trainer')\\n\",\n\"levelname\": \"ERROR\"\n},\n\n<\/code>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1675288800000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":86.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Custom-Training-Job-with-custom-container-failed-with-error-Cant\/m-p\/516766#M1172",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"custom train job custom contain fail error specif modul reason custom train job custom contain fail local run work fine verifi run local run indic doc built imag run manual work fine error log run custom job insertid srqvfjzoqv jsonpayload attr tag workerpool messag opt conda bin python error find modul specif trainer train modulenotfounderror modul name trainer levelnam error",
        "Question_preprocessed_content":"custom train job custom contain fail specif reason custom train job custom contain fail local run work fine log custom job",
        "Question_gpt_summary_original":"The user is facing an issue with their custom training job with a custom container on Vertex AI. The local run is working fine, but the job fails with an error message stating that the module specification for 'trainer.train' cannot be found. The error log indicates that there is no module named 'trainer'.",
        "Question_gpt_summary":"user face issu custom train job custom contain local run work fine job fail error messag state modul specif trainer train error log indic modul name trainer"
    },
    {
        "Question_title":"How to retrive transcript of virtual agent and customer in dialogflowcx?",
        "Question_body":"I have two questions?\n\n1.\u00a0How to retrieve transcript of virtual agent and customer in dialogflowcx? After the virtual agent has triggered the \"live agent handoff\" the call reaches our internal contact centre. I want to fetch the transcript of the conversation so far to show to the real agent. Using API\/Client library\/anything.\n\n2. When live agent hand off happens, then there are certain parameters passed on. There is also an option to app a JSON in the dialogue option. Is there a way to retrieve this JSON\/Parameters using an API call?",
        "Question_answer_count":9,
        "Question_comment_count":null,
        "Question_created_time":1669865640000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":320.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-retrive-transcript-of-virtual-agent-and-customer-in\/m-p\/494977#M884",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retriv transcript virtual agent custom dialogflowcx question retriev transcript virtual agent custom dialogflowcx virtual agent trigger live agent handoff reach intern contact centr want fetch transcript convers far real agent api client librari live agent hand happen certain paramet pass option app json dialogu option wai retriev json paramet api",
        "Question_preprocessed_content":"retriv transcript virtual agent custom dialogflowcx question retriev transcript virtual agent custom dialogflowcx virtual agent live agent reach intern contact centr want fetch transcript convers far real agent live agent hand certain paramet option json dialogu option wai retriev api",
        "Question_gpt_summary_original":"The user is seeking guidance on how to retrieve the transcript of a conversation between a virtual agent and a customer in DialogflowCX, specifically after the virtual agent triggers a \"live agent handoff\" to an internal contact center. The user is also inquiring about the possibility of retrieving JSON\/parameters passed on during the handoff using an API call.",
        "Question_gpt_summary":"user seek guidanc retriev transcript convers virtual agent custom dialogflowcx specif virtual agent trigger live agent handoff intern contact center user inquir possibl retriev json paramet pass handoff api"
    },
    {
        "Question_title":"How to plot multiline in one plot with smoothing features?",
        "Question_body":"<p>I\u2019m trying to plot the figure as in [W&amp;B Smoothing Features], but it didn\u2019t provide any code:<\/p>\n<p>                    <a href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9b0793db422eac619667bd11a7c56351d9d69149.png\" target=\"_blank\" rel=\"noopener nofollow ugc\" class=\"onebox\">\n            <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/9b0793db422eac619667bd11a7c56351d9d69149.png\" width=\"690\" height=\"301\">\n          <\/a>\n\n<\/p>\n<p>Tutorials I could find by searching <code>wandb multiline in one plot<\/code> is [Custom Multi-Line Plots] which introduces <code>wandb.plot.line_series()<\/code>.  So I tried the code following<\/p>\n<pre><code class=\"lang-python\">import wandb\nimport numpy as np\n\n\nwandb.init(project=\"test\", entity=\"xxxx\")\n\nwandb.log({\"my_custom_id\":\n           wandb.plot.line_series(\n               xs=range(100),\n               ys=[range(100), np.random.randint(100, size=100)],\n               keys=[\"y1\", \"y2\"],\n               title=\"Multiline\",\n               xname=\"steps\"\n           )})\n<\/code><\/pre>\n<p>It gives me the following pic after choosing <code>Edit panel<\/code><\/p>\n<p>                    <a href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/4e32b0d8ec1fb96df36dd2a7609f129875cb9e8e.png\" target=\"_blank\" rel=\"noopener nofollow ugc\" class=\"onebox\">\n            <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/4e32b0d8ec1fb96df36dd2a7609f129875cb9e8e.png\" width=\"690\" height=\"351\">\n          <\/a>\n\n<\/p>\n<p>Unlike the first picture:<\/p>\n<ol>\n<li>It <strong>doesn\u2019t<\/strong> have <code>Data<\/code>, <code>Group<\/code> etc tabs.<\/li>\n<li>There are <strong>two types<\/strong> of legend <code>name<\/code> and <code>lineKey<\/code> rather than one type.<\/li>\n<\/ol>\n<p>My question is how to plot exactly the same as the first picture with same function supported in wandb web?<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_created_time":1639275305880,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":310.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>First I need to log the data I want<\/p>\n<pre><code class=\"lang-python\">import random\nimport wandb\n\nwandb.init(project=\"test\", entity=\"xxxx\")\nfor i in range(100):\n    wandb.log({\"y1\": random.random(), \"y2\": random.random(), \"x\": i})\n<\/code><\/pre>\n<p>Then, I need to mannually choosing y1 and y2 on Y Axis.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c.jpeg\" data-download-href=\"\/uploads\/short-url\/3mBq6eTgdFLO5BAFCPEQmOUHYoQ.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_690x262.jpeg\" alt=\"image\" data-base62-sha1=\"3mBq6eTgdFLO5BAFCPEQmOUHYoQ\" width=\"690\" height=\"262\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_690x262.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_1035x393.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_1380x524.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1807\u00d7687 214 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Answer_comment_count":null,
        "Question_closed_time":1639528370760,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-plot-multiline-in-one-plot-with-smoothing-features\/1512",
        "Tool":"Weights & Biases",
        "Question_self_closed":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"plot multilin plot smooth featur try plot figur smooth featur didnt provid code tutori search multilin plot custom multi line plot introduc plot line seri tri code follow import import numpi init project test entiti xxxx log custom plot line seri rang rang random randint size kei titl multilin xname step give follow pic choos edit panel unlik pictur doesnt data group tab type legend linekei type question plot exactli pictur function support web",
        "Question_preprocessed_content":"plot multilin plot featur try plot figur didnt provid code tutori search introduc tri code give pic unlik pictur doesnt tab type legend type question plot exactli pictur function web",
        "Question_gpt_summary_original":"The user is trying to plot a multiline graph with smoothing features using wandb.plot.line_series() function. However, the resulting graph does not match the desired output as it lacks certain features such as Data and Group tabs and has two types of legends. The user is seeking guidance on how to plot the graph with the same function supported in wandb web.",
        "Question_gpt_summary":"user try plot multilin graph smooth featur plot line seri function result graph match desir output lack certain featur data group tab type legend user seek guidanc plot graph function support web"
    },
    {
        "Question_title":"Change model file save location on AWS SageMaker Training Job",
        "Question_body":"<p>I am trying to run custom python\/sklearn sagemaker script on AWS, basically learning from these examples: <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/scikit_learn_randomforest\/Sklearn_on_SageMaker_end2end.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/scikit_learn_randomforest\/Sklearn_on_SageMaker_end2end.ipynb<\/a><\/p>\n<p>All works fine, if define the arguments, train the model and output the file:<\/p>\n<pre><code>parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\nparser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\nparser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n\n# train the model...\n\njoblib.dump(model, os.path.join(args.model_dir, &quot;model.joblib&quot;))\n<\/code><\/pre>\n<p>And call the job with:<\/p>\n<pre><code>aws_sklearn.fit({'train': 's3:\/\/path\/to\/train', 'test': 's3:\/\/path\/to\/test'}, wait=False)\n<\/code><\/pre>\n<p>In this case model gets stored on different auto-generated bucket, which I do not want. I want to get the output (.joblib file) in the same s3 bucket I took data from. So I add the parameter <code>model-dir<\/code>:<\/p>\n<pre><code>aws_sklearn.fit({'train': 's3:\/\/path\/to\/train', 'test': 's3:\/\/path\/to\/test', `model-dir`: 's3:\/\/path\/to\/model'}, wait=False)\n<\/code><\/pre>\n<p>But it results in error:\n<code>FileNotFoundError: [Errno 2] No such file or directory: 's3:\/\/path\/to\/model\/model.joblib'<\/code><\/p>\n<p>Same happens if I hardcode the output path inside the training script.<\/p>\n<p>So the main question, how can I get the output file in the bucket of my choice?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1610533493827,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1244.0,
        "Poster_created_time":1572957474856,
        "Poster_location":null,
        "Poster_reputation_count":123.0,
        "Poster_view_count":18.0,
        "Answer_body":"<p>You can use parameter <code>output_path<\/code> when you define the estimator. If you use the\n<code>model_dir<\/code> I guess you have to create that bucket beforehand, but you have the advantage that artifacts can be saved in real time during the training (if the instance has rights on S3). You can take a look at my <a href=\"https:\/\/github.com\/roccopietrini\/TFSagemakerDetection\" rel=\"nofollow noreferrer\">repo<\/a> for this specific case.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1610545645387,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1416346350292,
        "Answerer_location":"Jesi, Italy",
        "Answerer_reputation_count":2302.0,
        "Answerer_view_count":227.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65699980",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"chang model file save locat train job try run custom python sklearn script aw basic learn exampl http github com aw amazon exampl blob master python sdk scikit learn randomforest sklearn endend ipynb work fine defin argument train model output file parser add argument model dir type str default environ model dir parser add argument train type str default environ channel train parser add argument test type str default environ channel test train model joblib dump model path join arg model dir model joblib job aw sklearn fit train path train test path test wait fals case model get store differ auto gener bucket want want output joblib file bucket took data add paramet model dir aw sklearn fit train path train test path test model dir path model wait fals result error filenotfounderror errno file directori path model model joblib happen hardcod output path insid train script main question output file bucket choic",
        "Question_preprocessed_content":"chang model file save locat train job try run custom script aw learn exampl work fine defin argument train model output file job case model get store bucket want want output bucket data paramet result hardcod output path insid train script main question output file bucket choic",
        "Question_gpt_summary_original":"The user is trying to run a custom python\/sklearn sagemaker script on AWS and wants to save the output (.joblib file) in the same S3 bucket from where the data was taken. However, when the user adds the parameter \"model-dir\" to specify the output location, it results in an error \"FileNotFoundError: [Errno 2] No such file or directory\". The user is seeking a solution to save the output file in the bucket of their choice.",
        "Question_gpt_summary":"user try run custom python sklearn script aw want save output joblib file bucket data taken user add paramet model dir specifi output locat result error filenotfounderror errno file directori user seek solut save output file bucket choic"
    },
    {
        "Question_title":"\"dvc add -external S3:\/\/mybucket\/data.csv\" is failing with access error even after giving correct remote cache configurations",
        "Question_body":"<p>Hi All,<\/p>\n<p>Am connecting to remote S3 for data and also setting remote dvc cache in same S3.<br>\nFollowing is configure file,<\/p>\n<pre><code class=\"lang-ini\">[core]\n    remote = s3remote\n[cache]\n    s3 = s3cache\n['remote \"s3remote\"']\n    url = S3:\/\/dvc-example\n    endpointurl = http:\/\/localhost:9000\/\n    access_key_id = user\n    secret_access_key = password\n    use_ssl = false\n['remote \"s3cache\"']\n    url = s3:\/\/dvc-example\/cache\n\tendpointurl = http:\/\/localhost:9000\/\n    access_key_id = user\n    secret_access_key = password\n    use_ssl = false\n<\/code><\/pre>\n<p>Am able to push and pull from remote repository to local.<br>\nBut when I try to add external data by configuring cache, am getting error.<br>\nBoth s3cache, s3remote has same credentials, then why is it failing when I add external data in dvc?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/original\/1X\/844a3dfabb3e006bfe4f8e15222af4a0236fc610.png\" data-download-href=\"\/uploads\/short-url\/iSi5wqipNKK3zGD6gzqzzcaTV28.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/original\/1X\/844a3dfabb3e006bfe4f8e15222af4a0236fc610.png\" alt=\"image\" data-base62-sha1=\"iSi5wqipNKK3zGD6gzqzzcaTV28\" width=\"690\" height=\"32\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/844a3dfabb3e006bfe4f8e15222af4a0236fc610_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1553\u00d773 5.72 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Any help would be much appreciated.<\/p>\n<blockquote>\n<p>Also posted in <a href=\"https:\/\/stackoverflow.com\/questions\/67104752\" rel=\"noopener nofollow ugc\">https:\/\/stackoverflow.com\/questions\/67104752<\/a><\/p>\n<\/blockquote>",
        "Question_answer_count":9,
        "Question_comment_count":null,
        "Question_created_time":1618473589784,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":8.0,
        "Question_view_count":1589.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-add-external-s3-mybucket-data-csv-is-failing-with-access-error-even-after-giving-correct-remote-cache-configurations\/726",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"add extern mybucket data csv fail access error give correct remot cach configur connect remot data set remot cach follow configur file core remot sremot cach scach remot sremot url exampl endpointurl http localhost access kei user secret access kei password us ssl fals remot scach url exampl cach endpointurl http localhost access kei user secret access kei password us ssl fals abl push pull remot repositori local try add extern data configur cach get error scach sremot credenti fail add extern data imag help appreci post http stackoverflow com question",
        "Question_preprocessed_content":"extern fail give remot cach configur remot data remot cach configur file abl push remot repositori local try extern data configur cach cach remot credenti fail extern data imag help post",
        "Question_gpt_summary_original":"The user is facing an access error while trying to add external data to DVC using the command \"dvc add -external S3:\/\/mybucket\/data.csv\" even after configuring the remote cache correctly. The user is able to push and pull from the remote repository to local, but adding external data is failing. The user has provided the configuration file and is seeking help to resolve the issue.",
        "Question_gpt_summary":"user face access error try add extern data command add extern mybucket data csv configur remot cach correctli user abl push pull remot repositori local ad extern data fail user provid configur file seek help resolv issu"
    },
    {
        "Question_title":"Saving data with DataCatalog",
        "Question_body":"<p>I was looking at <code>iris<\/code> project example provided by kedro. Apart from logging the accuracy I also wanted to save the <code>predictions<\/code> and <code>test_y<\/code> as a csv.<\/p>\n<p>This is the example node provided by kedro.<\/p>\n<pre><code>def report_accuracy(predictions: np.ndarray, test_y: pd.DataFrame) -&gt; None:\n    &quot;&quot;&quot;Node for reporting the accuracy of the predictions performed by the\n    previous node. Notice that this function has no outputs, except logging.\n    &quot;&quot;&quot;\n    # Get true class index\n    target = np.argmax(test_y.to_numpy(), axis=1)\n    # Calculate accuracy of predictions\n    accuracy = np.sum(predictions == target) \/ target.shape[0]\n    # Log the accuracy of the model\n    log = logging.getLogger(__name__)\n    log.info(&quot;Model accuracy on test set: %0.2f%%&quot;, accuracy * 100)\n<\/code><\/pre>\n<p>I added the following to save the data.<\/p>\n<pre><code>data = pd.DataFrame({&quot;target&quot;: target , &quot;prediction&quot;: predictions})\ndata_set = CSVDataSet(filepath=&quot;data\/test.csv&quot;)\ndata_set.save(data)\n<\/code><\/pre>\n<p>This works as intended, however, my question is &quot;is it the kedro way of doing thing&quot; ? Can I provide the <code>data_set <\/code> in <code>catalog.yml<\/code> and later save <code>data<\/code> to it? If I want to do it, how do I access the <code>data_set<\/code> from <code>catalog.yml<\/code> inside a node.<\/p>\n<p>Is there a way to save data without creating a catalog inside a node like this <code>data_set = CSVDataSet(filepath=&quot;data\/test.csv&quot;)<\/code> ? I want this in <code>catalog.yml<\/code>, if possible and if it follows kedro convention!.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1629897723887,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1629897818943,
        "Question_score_count":0.0,
        "Question_view_count":333.0,
        "Poster_created_time":1519724643532,
        "Poster_location":null,
        "Poster_reputation_count":453.0,
        "Poster_view_count":79.0,
        "Answer_body":"<p>Kedro actually abstracts this part for you. You don't need to access the datasets via their Python API.<\/p>\n<p>Your <code>report_accuracy<\/code> method does need to be tweaked to return the <code>DataFrame<\/code> instead of <code>None<\/code>.<\/p>\n<p>Your node needs to be defined as such:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>node(\n  func=report_accuracy,\n  inputs='dataset_a',\n  outputs='dataset_b'\n)\n<\/code><\/pre>\n<p>Kedro then looks at your catalog and will load\/save <code>dataset_a<\/code> and <code>dataset_b<\/code> as required:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>dataset_a:\n   type: pandas.CSVDataSet\n   path: xxxx.csv\n\ndataset_b:\n   type: pandas.ParquetDataSet\n   path: yyyy.pq\n<\/code><\/pre>\n<p>As you run the node\/pipeline Kedro will handle the load\/save operations for you. You also don't need to save every dataset if it's only used mid-way in a pipeline, you can read about <code>MemoryDataSet<\/code>s <a href=\"https:\/\/kedro.readthedocs.io\/en\/stable\/11_tools_integration\/01_pyspark.html#use-memorydataset-for-intermediary-dataframe\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1629898742263,
        "Answer_last_edit_time":1643038306147,
        "Answer_score_count":7.0,
        "Answerer_created_time":1359113510580,
        "Answerer_location":null,
        "Answerer_reputation_count":1076.0,
        "Answerer_view_count":81.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68923747",
        "Tool":"Kedro",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save data datacatalog look iri project exampl provid apart log accuraci want save predict test csv exampl node provid def report accuraci predict ndarrai test datafram node report accuraci predict perform previou node notic function output log true class index target argmax test numpi axi calcul accuraci predict accuraci sum predict target target shape log accuraci model log log getlogg log info model accuraci test set accuraci ad follow save data data datafram target target predict predict data set csvdataset filepath data test csv data set save data work intend question wai thing provid data set catalog yml later save data want access data set catalog yml insid node wai save data creat catalog insid node like data set csvdataset filepath data test csv want catalog yml possibl follow convent",
        "Question_preprocessed_content":"save data datacatalog project exampl provid apart want save csv exampl node provid save data work intend question wai thing provid later save want insid node wai save data creat catalog insid node like want convent",
        "Question_gpt_summary_original":"The user is trying to save predictions and test data as a CSV file in a Kedro project. They have added code to save the data, but they are unsure if it follows the Kedro convention. They want to know if they can provide the data set in catalog.yml and access it from a node. They also want to know if there is a way to save data without creating a catalog inside a node.",
        "Question_gpt_summary":"user try save predict test data csv file project ad code save data unsur follow convent want know provid data set catalog yml access node want know wai save data creat catalog insid node"
    },
    {
        "Question_title":"Schedule the deployment of a sagemaker model",
        "Question_body":"<p>I'm trying out SageMaker and I've created a model using autopilot. The point is that SageMaker only allows you to deploy directly to an endpoint. But since I'll only be using the model a couple of times a day, what is the most direct way to  schedule deployments by events (for example when loading new csv's into an s3 directory or when I see a queue in sqs) or at least periodically?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1583361587500,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1583362462607,
        "Question_score_count":0.0,
        "Question_view_count":225.0,
        "Poster_created_time":1544205695740,
        "Poster_location":"Santiago, Chile",
        "Poster_reputation_count":410.0,
        "Poster_view_count":46.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60535760",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"schedul deploy model try creat model autopilot point allow deploi directli endpoint model coupl time dai direct wai schedul deploy event exampl load new csv directori queue sq period",
        "Question_preprocessed_content":"schedul deploy model try creat model autopilot point deploi directli endpoint model coupl time dai direct wai schedul deploy event",
        "Question_gpt_summary_original":"The user has created a model using autopilot in SageMaker but is facing challenges in scheduling deployments by events or periodically as SageMaker only allows direct deployment to an endpoint. The user wants to know the most direct way to schedule deployments.",
        "Question_gpt_summary":"user creat model autopilot face challeng schedul deploy event period allow direct deploy endpoint user want know direct wai schedul deploy"
    },
    {
        "Question_title":"MLflow run example gives me CommandNotFoundError",
        "Question_body":"<p>I was trying to run the mlflow run exercise in the anaconda prompt, and it keeps giving me the error.\nI'm using mlflow version 1.40, and the code above works fine if I execute it with --no-conda <\/p>\n\n<p><code>mlflow run https:\/\/github.com\/mlflow\/mlflow-example -P alpha=0.5<\/code> - doesn't work<\/p>\n\n<p><code>mlflow run https:\/\/github.com\/mlflow\/mlflow-example -P alpha=0.5 --no-conda<\/code> - works<\/p>\n\n<p>It gives me the error when activating the conda environment. The specific conda environment works fine if I manually activate it. It just doesn't work within the mlflow command. <\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/ehUXl.png\" alt=\"capture of prompt\"><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LjSoJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LjSoJ.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1573801005183,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1574210709447,
        "Question_score_count":1.0,
        "Question_view_count":251.0,
        "Poster_created_time":1546094080583,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58871771",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run exampl give commandnotfounderror try run run exercis anaconda prompt keep give error version code work fine execut conda run http github com exampl alpha work run http github com exampl alpha conda work give error activ conda environ specif conda environ work fine manual activ work command",
        "Question_preprocessed_content":"run exampl give try run run exercis anaconda prompt give version code work fine execut work work give activ conda environ specif conda environ work fine activ work",
        "Question_gpt_summary_original":"The user is encountering a CommandNotFoundError while trying to run the mlflow run exercise in the anaconda prompt using mlflow version 1.40. The error occurs when activating the conda environment, and the code works fine if executed with --no-conda. The specific conda environment works fine if manually activated, but it doesn't work within the mlflow command.",
        "Question_gpt_summary":"user encount commandnotfounderror try run run exercis anaconda prompt version error occur activ conda environ code work fine execut conda specif conda environ work fine manual activ work command"
    },
    {
        "Question_title":"Read-only file system error in AzureML studio - Azure ML SDK2",
        "Question_body":"<p>Hi,<\/p>\n<p>I'm having an issue while using Azure Machine Learning studio with a very simple operation:<\/p>\n<p>Write a JSON file to the Datastore (Azure Data Lake V2).<\/p>\n<p>I had a pipeline in the past using SDK1 and everything worked, we are now moving to sdk2 and we aren't able to write a json file in a Datastore we are getting the following error:<\/p>\n<pre><code>OSError: [Errno 30] Read-only file system: '\/mnt\/azureml\/cr\/j\/8bf7af1d0623404aa72957489926b032\/cap\/data-capability\/wd\/INPUT_source_data\/test.json'\n<\/code><\/pre>\n<p>I checked my access rights:<\/p>\n<ul>\n<li> AzureML workspace: Owner &amp; Contributor<\/li>\n<li> Azure Storage account: Storage Storage Contributor<\/li>\n<\/ul>\n<p>We are using a custom environment:<\/p>\n<ul>\n<li> image=&quot;mcr.microsoft.com\/azureml\/openmpi4.1.0-ubuntu22.04:latest&quot;<\/li>\n<\/ul>\n<p>with the conda file:<\/p>\n<pre><code class=\"lang-yaml\">%%writefile {dependencies_dir}\/conda.yml\nname: hespreproc-env-testcf1\nchannels:\nconda-forge\ndependencies:\npython=3.10\nnumpy=1.24.1\npandas=1.5.2\npip=22.3.1\npip:\nazure-storage-blob\nazure-identity\npyproj==3.4.1\nmlflow==1.26.1\nazureml-mlflow==1.42.0\n<\/code><\/pre>\n<p>The datalake has no access policy defined.<\/p>\n<p>I am not sure what else I can try to solve this issue.<\/p>\n<p>Kind regards,  <br \/>\nCarla Fiadeiro<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1677772230963,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1185934\/read-only-file-system-error-in-azureml-studio-azur",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"read file error studio sdk have issu studio simpl oper write json file datastor azur data lake pipelin past sdk work move sdk aren abl write json file datastor get follow error oserror errno read file mnt bfafdaab cap data capabl input sourc data test json check access right workspac owner contributor azur storag account storag storag contributor custom environ imag mcr microsoft com openmpi ubuntu latest conda file writefil depend dir conda yml hespreproc env testcf channel conda forg depend python numpi panda pip pip azur storag blob azur ident pyproj datalak access polici defin sure try solv issu kind regard carla fiadeiro",
        "Question_preprocessed_content":"file studio sdk have studio simpl oper write json file datastor pipelin past sdk work move sdk aren abl write json file datastor check right workspac owner contributor azur storag storag storag contributor custom environ conda file datalak polici defin sure try solv kind regard carla fiadeiro",
        "Question_gpt_summary_original":"The user is encountering a \"Read-only file system\" error while trying to write a JSON file to the Datastore in Azure Machine Learning studio using SDK2. The user has checked their access rights and is using a custom environment with a conda file. The datalake has no access policy defined, and the user is unsure of what else to try to solve the issue.",
        "Question_gpt_summary":"user encount read file error try write json file datastor studio sdk user check access right custom environ conda file datalak access polici defin user unsur try solv issu"
    },
    {
        "Question_title":"Fisher Linear Discriminant Analysis Azure",
        "Question_body":"<p>How is the output of Fisher Linear Discriminant Analysis experiment interpreted now that the column labels in the output are replaced with Col1, Col2, Col3.......etc? How can the model be used to predict clusters of other input data as deployed web service requires even the dependent valuable(the same same ones we wish to predict)?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1621855005240,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Are you referring to the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/latent-dirichlet-allocation#lda-transformed-dataset\">categories<\/a> generated from LDA module? If so, then that's expected. LDA is an unsupervised technique, it groups words into categories\/topics and it's up to the analyst to interpret it by observing the results and transforming the output dataset accordingly. Here's are some <a href=\"https:\/\/gallery.azure.ai\/browse?s=lda\">examples<\/a> of LDA approach in Azure AI Gallery. Hope this helps.    <\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1621895240423,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/407053\/fisher-linear-discriminant-analysis-azure",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"fisher linear discrimin analysi azur output fisher linear discrimin analysi experi interpret column label output replac col col col model predict cluster input data deploi web servic requir depend valuabl on wish predict",
        "Question_preprocessed_content":"fisher linear discrimin analysi azur output fisher linear discrimin analysi experi interpret column label output replac col col model predict cluster input data deploi web servic requir depend valuabl",
        "Question_gpt_summary_original":"The user is facing challenges in interpreting the output of Fisher Linear Discriminant Analysis experiment as the column labels are replaced with Col1, Col2, Col3, etc. They are also unsure how to use the model to predict clusters of other input data as the deployed web service requires the same dependent variables that they wish to predict.",
        "Question_gpt_summary":"user face challeng interpret output fisher linear discrimin analysi experi column label replac col col col unsur us model predict cluster input data deploi web servic requir depend variabl wish predict"
    },
    {
        "Question_title":"Upgrade mlflow",
        "Question_body":"The following error is thrown when I upgrade mlflow from 1.13.1 to 1.18.0\n\n\nalembic.util.exc.CommandError: Can't locate revision identified by 'a8c4a736bde6' mlflow\n\n\n\nWould deleting the alembic version fix the issue or is there any alternate solution?\n\n\nThank you and Warm Regards",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1624850016000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":203.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/CX4PiIGYZiE",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"upgrad follow error thrown upgrad alemb util exc commanderror locat revis identifi acabd delet alemb version fix issu altern solut thank warm regard",
        "Question_preprocessed_content":"upgrad thrown upgrad locat revis identifi bde delet alemb version fix altern solut thank warm regard",
        "Question_gpt_summary_original":"The user encountered an error when upgrading mlflow from version 1.13.1 to 1.18.0. The error message indicates a problem with locating a revision identified by 'a8c4a736bde6' in alembic. The user is seeking advice on whether deleting the alembic version would solve the issue or if there is an alternative solution.",
        "Question_gpt_summary":"user encount error upgrad version error messag indic problem locat revis identifi acabd alemb user seek advic delet alemb version solv issu altern solut"
    },
    {
        "Question_title":"MLFlow Projects throw JSONDecode error when run",
        "Question_body":"<p>I'm trying to get MLFlow Projects to run using the MLFlow CLI and its following the tutorial leads to an error.  For any project I try to run from the CLI, I get the following error<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"\/home\/rbc\/.local\/bin\/mlflow\", line 11, in &lt;module&gt;\n    sys.exit(cli())\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/cli.py\", line 139, in run\n    run_id=run_id,\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 230, in run\n    storage_dir=storage_dir, block=block, run_id=run_id)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 88, in _run\n    active_run = _create_run(uri, experiment_id, work_dir, entry_point)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 579, in _create_run\n    active_run = tracking.MlflowClient().create_run(experiment_id=experiment_id, tags=tags)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 101, in create_run\n    source_version=source_version\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 156, in create_run\n    response_proto = self._call_endpoint(CreateRun, req_body)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 66, in _call_endpoint\n    js_dict = json.loads(response.text)\n  File \"\/usr\/lib\/python3.6\/json\/__init__.py\", line 354, in loads\n    return _default_decoder.decode(s)\n  File \"\/usr\/lib\/python3.6\/json\/decoder.py\", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"\/usr\/lib\/python3.6\/json\/decoder.py\", line 357, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n<\/code><\/pre>\n\n<p>Here's an example of the type of command I'm using to start the run, which comes directly from the tutorial <\/p>\n\n<pre><code>mlflow run https:\/\/github.com\/mlflow\/mlflow#examples\/sklearn_elasticnet_wine -m databricks -c cluster-spec.json --experiment-id 72647065958042 -P alpha=2.0 -P l1_ratio=0.5\n<\/code><\/pre>\n\n<p>I've traced the error to something involving MLFLow returning empty when it tries to start a run but I can successfully run MLFlow experiments using the Databricks environment I'm connecting to so I'm not sure where the problem is, I'm running MLFlow 0.9.1 on Ubuntu 18.04<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1557754667253,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":386.0,
        "Poster_created_time":1509471438900,
        "Poster_location":"Orlando, FL, United States",
        "Poster_reputation_count":31.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56113569",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"project throw jsondecod error run try project run cli follow tutori lead error project try run cli follow error traceback recent file home rbc local bin line sy exit cli file home rbc local lib python site packag click core line return self main arg kwarg file home rbc local lib python site packag click core line main self invok ctx file home rbc local lib python site packag click core line invok return process result sub ctx command invok sub ctx file home rbc local lib python site packag click core line invok return ctx invok self callback ctx param file home rbc local lib python site packag click core line invok return callback arg kwarg file home rbc local lib python site packag cli line run run run file home rbc local lib python site packag project init line run storag dir storag dir block block run run file home rbc local lib python site packag project init line run activ run creat run uri experi work dir entri point file home rbc local lib python site packag project init line creat run activ run track client creat run experi experi tag tag file home rbc local lib python site packag track client line creat run sourc version sourc version file home rbc local lib python site packag store rest store line creat run respons proto self endpoint createrun req bodi file home rbc local lib python site packag store rest store line endpoint dict json load respons text file usr lib python json init line load return default decod decod file usr lib python json decod line decod obj end self raw decod idx end file usr lib python json decod line raw decod rais jsondecodeerror expect valu err valu json decod jsondecodeerror expect valu line column char exampl type command start run come directli tutori run http github com exampl sklearn elasticnet wine databrick cluster spec json experi alpha ratio trace error involv return tri start run successfulli run experi databrick environ connect sure problem run ubuntu",
        "Question_preprocessed_content":"project throw jsondecod run try project run cli tutori lead project try run cli exampl type start run come directli tutori trace involv return tri start run run experi databrick environ sure problem ubuntu",
        "Question_gpt_summary_original":"The user is encountering a JSONDecode error when trying to run MLFlow Projects using the MLFlow CLI. The error occurs when MLFlow returns empty while trying to start a run. The user has traced the error to MLFlow and is unsure of the problem. The user is running MLFlow 0.9.1 on Ubuntu 18.04 and can successfully run MLFlow experiments using the Databricks environment.",
        "Question_gpt_summary":"user encount jsondecod error try run project cli error occur return try start run user trace error unsur problem user run ubuntu successfulli run experi databrick environ"
    },
    {
        "Question_title":"slowness of azure ml cloud compute",
        "Question_body":"<p>I am doing a speed comparison test between my machine and azure ml cloud compute. My PC is 8 cores with 64 GB RAM. The compute instance I created on azure is &quot;Standard_D14_v2 (16 cores, 112 GB RAM, 800 GB disk)&quot;. One test I did was to run a XGBoost model and it took about 1h15m locally. On the cloud, it took 1h45m. I thought I would have a better performance with the instance created on azure. Could someone explain to me why I saw the opposite? Thank you so much!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1618714586367,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/361307\/slowness-of-azure-ml-cloud-compute",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"slow cloud comput speed comparison test machin cloud comput core ram comput instanc creat azur standard core ram disk test run xgboost model took local cloud took thought better perform instanc creat azur explain saw opposit thank",
        "Question_preprocessed_content":"cloud comput comparison test machin cloud comput core ram comput instanc creat azur test run model cloud thought perform instanc creat azur explain saw thank",
        "Question_gpt_summary_original":"The user is experiencing slowness in Azure ML cloud compute while running a speed comparison test between their local machine and the cloud instance. Despite creating an instance with better specifications, the XGBoost model took longer to run on the cloud than on their local machine. The user is seeking an explanation for this unexpected outcome.",
        "Question_gpt_summary":"user experienc slow cloud comput run speed comparison test local machin cloud instanc despit creat instanc better specif xgboost model took longer run cloud local machin user seek explan unexpect outcom"
    },
    {
        "Question_title":"Unable to use audio to text transcribe",
        "Question_body":"I am new to this Google Audio transcription and I have set up the whole Google Free Trial thing and I have tried to use the function of Google's Audio to Speech transcript and well so far my customer experience has been so hard.\u00a0 I have two files and *.mpa and a *.mp4 file and no matter what i do i keep getting an error that it cannot transcribe.\n\nCan someone\u00a0 please help me with this.\u00a0\u00a0\n\nHere are the errors I am getting.\n\nNotifications\nRunning recognize for transcription \"2022.03.20_16-30 Paradigm Shift Review Meeting David & Steve Zoom GMT20220320-050943_Recording_640x360-1dddcbcacc9d52be-9cc61\"\n6 minutes ago\nMy First Project\nUnknown error.\nRunning recognize for transcription \"2022.03.20_16-30 Paradigm Shift Review Meeting David & Steve Zoom GMT20220320-050943_Recording-c51097d6e01f1270-6f202\"\n13 minutes ago\nMy First Project\nUnknown error.\nRunning recognize for transcription \"2022.03.20_16-30 Paradigm Shift Review Meeting David & Steve Zoom GMT20220320-050943_Recording-85fc910221e53949-6752c\"\n15 minutes ago\nMy First Project\nUnknown error.\nRunning recognize for transcription \"2022.03.20_16-30 Paradigm Shift Review Meeting David & Steve Zoom GMT20220320-050943_Recording-fed8777481bb94c4-33e9f\"\n16 minutes ago\nMy First Project\nUnknown error.\n\u00a0\nAccording to Handbrake the m4a file has the following ...\n\nFormat : MPEG-4\nFormat profile : Base Media \/ Version 2\nCodec ID : mp42 (isom\/mp42)\nFile size : 26.0 MiB\nDuration : 28 min 30 s\nOverall bit rate mode : Variable\nOverall bit rate : 127 kb\/s\nEncoded date : UTC 2022-03-20 05:09:43\nTagged date : UTC 2022-03-20 05:09:43\n\nAudio\nID : 1\nFormat : AAC LC\nFormat\/Info : Advanced Audio Codec Low Complexity\nCodec ID : mp4a-40-2\nDuration : 28 min 30 s\nBit rate mode : Variable\nBit rate : 126 kb\/s\nMaximum bit rate : 166 kb\/s\nChannel(s) : 1 channel\nChannel layout : C\nSampling rate : 32.0 kHz\nFrame rate : 31.250 FPS (1024 SPF)\nCompression mode : Lossy\nStream size : 25.7 MiB (99%)\nTitle : AAC audio\n\n\u00a0\n\nAnd the mp4 file has\u00a0\n\nFormat : MPEG-4\nFormat profile : Base Media \/ Version 2\nCodec ID : mp42 (isom\/mp42)\nFile size : 30.2 MiB\nDuration : 28 min 30 s\nOverall bit rate mode : Variable\nOverall bit rate : 148 kb\/s\nEncoded date : UTC 2022-03-20 05:09:43\nTagged date : UTC 2022-03-20 05:09:43\n\nVideo\nID : 2\nFormat : AVC\nFormat\/Info : Advanced Video Codec\nFormat profile : High@L3.1\nFormat settings : CABAC \/ 11 Ref Frames\nFormat settings, CABAC : Yes\nFormat settings, Reference frames : 11 frames\nCodec ID : avc1\nCodec ID\/Info : Advanced Video Coding\nDuration : 28 min 30 s\nBit rate : 19.8 kb\/s\nWidth : 640 pixels\nHeight : 360 pixels\nDisplay aspect ratio : 16:9\nFrame rate mode : Constant\nFrame rate : 25.000 FPS\nColor space : YUV\nChroma subsampling : 4:2:0\nBit depth : 8 bits\nScan type : Progressive\nBits\/(Pixel*Frame) : 0.003\nStream size : 4.03 MiB (13%)\nTitle : H.264\/AVC video\nEncoded date : UTC 2022-03-20 05:09:43\nTagged date : UTC 2022-03-20 05:09:43\nCodec configuration box : avcC\n\n\u00a0\n\nWhat codec options do i choose and how do I use this feature.\n\nGoogle",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1647737040000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":169.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unable-to-use-audio-to-text-transcribe\/m-p\/405132#M242",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl us audio text transcrib new googl audio transcript set googl free trial thing tri us function googl audio speech transcript far custom experi hard file mpa file matter get error transcrib help error get notif run recogn transcript paradigm shift review meet david steve zoom gmt record dddcbcaccdb minut ago project unknown error run recogn transcript paradigm shift review meet david steve zoom gmt record cdef minut ago project unknown error run recogn transcript paradigm shift review meet david steve zoom gmt record fce minut ago project unknown error run recogn transcript paradigm shift review meet david steve zoom gmt record fedbbc minut ago project unknown error accord handbrak file follow format mpeg format profil base media version codec isom file size mib durat min overal bit rate mode variabl overal bit rate encod date utc tag date utc audio format aac format info advanc audio codec low complex codec mpa durat min bit rate mode variabl bit rate maximum bit rate channel channel channel layout sampl rate khz frame rate fp spf compress mode lossi stream size mib titl aac audio file format mpeg format profil base media version codec isom file size mib durat min overal bit rate mode variabl overal bit rate encod date utc tag date utc video format avc format info advanc video codec format profil high format set cabac ref frame format set cabac ye format set refer frame frame codec avc codec info advanc video code durat min bit rate width pixel height pixel displai aspect ratio frame rate mode constant frame rate fp color space yuv chroma subsampl bit depth bit scan type progress bit pixel frame stream size mib titl avc video encod date utc tag date utc codec configur box avcc codec option choos us featur googl",
        "Question_preprocessed_content":"unabl us audio text transcrib new audio transcript set trial thing tri us function audio transcript far custom experi hard file file transcrib help notif recogn transcript paradigm shift review david steve minut ago project unknown recogn transcript paradigm shift review david steve minut ago project unknown recogn transcript paradigm shift review david steve minut ago project unknown recogn transcript paradigm shift review david steve minut ago project unknown handbrak file format format profil base media version codec file size mib durat min bit rate mode variabl bit rate encod date utc date utc audio format advanc audio codec low complex codec durat min bit rate mode variabl bit rate maximum bit rate layout sampl rate khz frame rate fp mode stream size mib titl audio file format format profil base media version codec file size mib durat min bit rate mode variabl bit rate encod date utc date utc video format avc advanc video codec format profil format cabac ref frame format cabac ye format refer frame frame codec avc codec advanc video code durat min bit rate width pixel height pixel displai aspect ratio frame rate mode constant frame rate fp color space yuv chroma subsampl bit depth bit scan type stream size mib titl video encod date utc date utc codec configur box codec option us featur",
        "Question_gpt_summary_original":"The user is having difficulty using Google's Audio to Speech transcription feature. They have tried to transcribe two files, an *.mpa and an *.mp4 file, but keep receiving an error message. The user has provided information about the files' format and codec options and is seeking help on how to use the feature.",
        "Question_gpt_summary":"user have difficulti googl audio speech transcript featur tri transcrib file mpa file receiv error messag user provid inform file format codec option seek help us featur"
    },
    {
        "Question_title":"Training data in S3 in AWS Sagemaker",
        "Question_body":"<p>I've uploaded my own Jupyter notebook to Sagemaker, and am trying to create an iterator for my training \/ validation data which is in S3, as follow:<\/p>\n\n<pre><code>train = mx.io.ImageRecordIter(\n        path_imgrec         = \u2018s3:\/\/bucket-name\/train.rec\u2019 \u2026\u2026 )\n<\/code><\/pre>\n\n<p>I receive the following exception: <\/p>\n\n<pre><code>MXNetError: [04:33:32] src\/io\/s3_filesys.cc:899: Need to set enviroment variable AWS_SECRET_ACCESS_KEY to use S3\n<\/code><\/pre>\n\n<p>I've checked that the IAM role attached with this notebook instance has S3 access. Any clues on what might be needed to fix this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1522300028073,
        "Question_favorite_count":3.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":1353.0,
        "Poster_created_time":1449031669083,
        "Poster_location":null,
        "Poster_reputation_count":777.0,
        "Poster_view_count":103.0,
        "Answer_body":"<p>If your IAM roles are setup correctly, then you need to download the file to the Sagemaker instance first and then work on it. Here's how:<\/p>\n\n<pre><code># Import roles\nimport sagemaker\nrole = sagemaker.get_execution_role()\n\n# Download file locally\ns3 = boto3.resource('s3')\ns3.Bucket(bucket).download_file('your_training_s3_file.rec', 'training.rec')\n\n#Access locally\ntrain = mx.io.ImageRecordIter(path_imgrec=\u2018training.rec\u2019 \u2026\u2026 )\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1522305475727,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1411212343683,
        "Answerer_location":"Vancouver, BC, Canada",
        "Answerer_reputation_count":3592.0,
        "Answerer_view_count":268.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49548422",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train data upload jupyt notebook try creat iter train valid data follow train imagerecordit path imgrec bucket train rec receiv follow except mxneterror src filesi need set enviro variabl aw secret access kei us check iam role attach notebook instanc access clue need fix",
        "Question_preprocessed_content":"train data upload jupyt try creat iter train valid data receiv except check iam role instanc clue fix",
        "Question_gpt_summary_original":"The user is trying to create an iterator for their training\/validation data in S3 using AWS Sagemaker, but is encountering an exception that requires setting the AWS_SECRET_ACCESS_KEY environment variable to use S3. The user has checked that the IAM role attached to the notebook instance has S3 access and is seeking help to fix the issue.",
        "Question_gpt_summary":"user try creat iter train valid data encount except requir set aw secret access kei environ variabl us user check iam role attach notebook instanc access seek help fix issu"
    },
    {
        "Question_title":"Speech to text API not returning long running operation results - is service impaired?",
        "Question_body":"The Speech to text API stopped returning results today. It was working properly yesterday evening (16 hours ago.\n\nI have tried it from python and node, both of which worked fine yesterday.\n\nI am using the same code and short audio (2 minutes) that I have been using.\n\nI am using the python speech_v1p1beta1 lib and have tried speech_v1 also.\n\nconfig = {\n    'encoding': 'FLAC',\n    'language_code': 'en-US',\n    'audio_channel_count': channel_count,\n    'sample_rate_hertz': sample_rate,\n    'enable_word_time_offsets': True,\n    'enable_separate_recognition_per_channel': False,\n    'enable_automatic_punctuation': True,\n    'use_enhanced': True,\n    'model': 'video'\n}\naudio = {\n    'uri': audio_uri\n}\nrequest = {\n    'config': config,\n    'audio': audio\n}\noperation = cls.client.long_running_recognize(request)\nresponse = operation.result(timeout=10000)\ntranscript = cls.build_transcript(response)\n\nI get the operation object but the results just timeout no matter what timeout I set\n\nThanks",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1677758700000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":99.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-to-text-API-not-returning-long-running-operation-results\/m-p\/528170#M1367",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"speech text api return long run oper result servic impair speech text api stop return result todai work properli yesterdai even hour ago tri python node work fine yesterdai code short audio minut python speech vpbeta lib tri speech config encod flac languag code audio channel count channel count sampl rate hertz sampl rate enabl word time offset true enabl separ recognit channel fals enabl automat punctuat true us enhanc true model video audio uri audio uri request config config audio audio oper cl client long run recogn request respons oper result timeout transcript cl build transcript respons oper object result timeout matter timeout set thank",
        "Question_preprocessed_content":"text api return long oper result servic impair text api return result todai work properli yesterdai even python lib tri config audio request oper respons transcript oper object result timeout timeout set thank",
        "Question_gpt_summary_original":"The user is facing an issue with the Speech to text API as it has stopped returning results, even though it was working fine 16 hours ago. The user has tried using both python and node, but the results still timeout despite setting a timeout limit. The user is using the same code and a short audio file that was previously working.",
        "Question_gpt_summary":"user face issu speech text api stop return result work fine hour ago user tri python node result timeout despit set timeout limit user code short audio file previous work"
    },
    {
        "Question_title":"Add'ed files are duplicated in the cache, no links",
        "Question_body":"<p>I have started using dvc by running <code>dvc init<\/code> and then <code>dvc add<\/code> for two directories and one file.<\/p>\n<p>All worked fine, all filed have been copied to the cache but I noted that the total disk usage has doubled as the original files remained in addition to the cached copies.<\/p>\n<p>The original files do not show any signs of being reflinks.<\/p>\n<p>Is this right?<\/p>\n<p>I am using Ubuntu 16.04.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1566732869315,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":729.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/added-files-are-duplicated-in-the-cache-no-links\/209",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"add file duplic cach link start run init add directori file work fine file copi cach note total disk usag doubl origin file remain addit cach copi origin file sign reflink right ubuntu",
        "Question_preprocessed_content":"file duplic cach link start directori file work fine file copi cach note total disk usag doubl origin file remain cach copi origin file sign reflink right ubuntu",
        "Question_gpt_summary_original":"The user has encountered an issue where files added using dvc are being duplicated in the cache, resulting in double the disk usage. The original files do not show any signs of being reflinks, and the user is unsure if this is expected behavior. They are using Ubuntu 16.04.",
        "Question_gpt_summary":"user encount issu file ad duplic cach result doubl disk usag origin file sign reflink user unsur expect behavior ubuntu"
    },
    {
        "Question_title":"Load .asc file into azure machine learning",
        "Question_body":"<p>For my Azure Machine Learning experiment I want to load a .asc file into an Execute R script in my experiment. It is in fact a tab delimited file with some comments on the first couple of rows. Can anyone tell me how to do this?<\/p>\n\n<p>A csv goes well, but with this file I get an error.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1457552318890,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1457561625260,
        "Question_score_count":0.0,
        "Question_view_count":69.0,
        "Poster_created_time":1387445364536,
        "Poster_location":"Netherlands",
        "Poster_reputation_count":81.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35901044",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"load asc file experi want load asc file execut script experi fact tab delimit file comment coupl row tell csv goe file error",
        "Question_preprocessed_content":"load asc file experi want load asc file execut script experi fact tab delimit file coupl row csv goe file",
        "Question_gpt_summary_original":"The user is facing challenges in loading a .asc file into an Execute R script in their Azure Machine Learning experiment. The file is tab-delimited with comments on the first few rows, and the user is seeking guidance on how to accomplish this task. They have tried using a csv file but encountered an error.",
        "Question_gpt_summary":"user face challeng load asc file execut script experi file tab delimit comment row user seek guidanc accomplish task tri csv file encount error"
    },
    {
        "Question_title":"SageMaker Batch Transform local mode?",
        "Question_body":"Hi,\n\nA customer is experimenting with SageMaker batch transform with parquet and is interested is some form of local development to speedup iteration. Does SageMaker Batch Transform support local mode?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1571055107000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668610004528,
        "Question_score_count":0.0,
        "Question_view_count":336.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"You can do local testing by running the container in serve mode as a docker. Then using Curl\/Postman to send an HTTP request and inspecting the response.  \n\nThe request can be CSV\/JSON or binary (a parquet file in your case).  \n\nIf you're able to run the Pytorch model in serve mode locally, then this local testing provides a lot of coverage before running in Batch Transform itself.",
        "Answer_comment_count":0.0,
        "Question_closed_time":1571303926000,
        "Answer_last_edit_time":1667925565480,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUtNtH0LyFSLCXc0xCV4hYkw\/sagemaker-batch-transform-local-mode",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":1.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"batch transform local mode custom experi batch transform parquet interest form local develop speedup iter batch transform support local mode",
        "Question_preprocessed_content":"batch transform local mode custom experi batch transform parquet interest form local develop iter batch transform local mode",
        "Question_gpt_summary_original":"The user is inquiring about the possibility of using local mode for SageMaker Batch Transform to speed up iteration while experimenting with parquet.",
        "Question_gpt_summary":"user inquir possibl local mode batch transform speed iter experi parquet"
    },
    {
        "Question_title":"LightFM on AWS sagemaker | Is it possible to train model",
        "Question_body":"<p>I am using LightFM for recommender system \n<a href=\"https:\/\/github.com\/lyst\/lightfm\" rel=\"nofollow noreferrer\">https:\/\/github.com\/lyst\/lightfm<\/a><\/p>\n\n<p>Now I want to move my model to AWS Sagemaker where this is not part of build in algorithm, now I want to train my model using this algorithm and also want to leverage Sagemaker capability for huge data, I am following this link to run my custom model \n<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms.html<\/a><\/p>\n\n<p>Now, it seems I need to install docker image of this algorithm and too much other things too, is it any simple way to train my model without pre-build algorithm.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1540899526740,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":418.0,
        "Poster_created_time":1501403168107,
        "Poster_location":"Delhi, India",
        "Poster_reputation_count":1370.0,
        "Poster_view_count":125.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53063492",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"lightfm possibl train model lightfm recommend http github com lyst lightfm want model build algorithm want train model algorithm want leverag capabl huge data follow link run custom model http doc aw amazon com latest algorithm html need instal docker imag algorithm thing simpl wai train model pre build algorithm",
        "Question_preprocessed_content":"lightfm train model lightfm want model build algorithm want train model algorithm want leverag capabl huge data link run custom model docker imag algorithm thing simpl wai train model algorithm",
        "Question_gpt_summary_original":"The user is trying to use LightFM for a recommender system and wants to move the model to AWS Sagemaker. However, LightFM is not a built-in algorithm in Sagemaker, so the user is trying to train the model using a custom algorithm. The user is facing challenges in installing the required docker image and other dependencies and is looking for a simpler way to train the model without a pre-built algorithm.",
        "Question_gpt_summary":"user try us lightfm recommend want model lightfm built algorithm user try train model custom algorithm user face challeng instal requir docker imag depend look simpler wai train model pre built algorithm"
    },
    {
        "Question_title":"ML.NET Detect anomalies with gaps\/missings in data",
        "Question_body":"<p>I have done some tests with <a href=\"https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/microsoft.ml.timeseriescatalog.detectiidspike?view=ml-dotnet\" rel=\"nofollow noreferrer\">DetectSpike<\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/microsoft.ml.timeseriescatalog.detectanomalybysrcnn?view=ml-dotnet\" rel=\"nofollow noreferrer\">DetectAnomaly<\/a> but despite differences and whole pipeline building - both methods require input of 1-dimensional float[]<\/p>\n<p>Its fine to find anomalies and spikes but I was asked to find anomalies &quot;normal&quot;, and anomalies with gaps. (this can be one scenario no need to separate this by kind)<\/p>\n<p>Example 1: WebService receives about 30-100 requests\/min, then theres break\/gap and no requests for few minutes.<\/p>\n<p>Example 2: I am receiving one bill invoice with random value each month, and theres two months without invoices.\n<a href=\"https:\/\/i.stack.imgur.com\/8DJ8n.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8DJ8n.png\" alt=\"enter image description here\" \/><\/a>\nI guess, that I am not able to do this without Date\/Time dimension\/column.\nAny ideas?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1658833883307,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":38.0,
        "Poster_created_time":1353149902688,
        "Poster_location":"Cracow, Poland",
        "Poster_reputation_count":887.0,
        "Poster_view_count":111.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73122328",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"net detect anomali gap miss data test detectspik detectanomali despit differ pipelin build method requir input dimension float fine anomali spike ask anomali normal anomali gap scenario need separ kind exampl webservic receiv request min there break gap request minut exampl receiv invoic random valu month there month invoic guess abl date time dimens column idea",
        "Question_preprocessed_content":"detect anomali data test detectspik detectanomali despit pipelin build method requir input float fine anomali spike ask anomali normal anomali gap exampl webservic receiv there request minut exampl receiv invoic random valu month there month invoic abl idea",
        "Question_gpt_summary_original":"The user has tested DetectSpike and DetectAnomaly to find anomalies and spikes in data, but both methods require input of 1-dimensional float[]. The user needs to find anomalies with gaps\/missings in data, such as a scenario where there are no requests for a few minutes after receiving 30-100 requests\/min or when there are two months without invoices. The user believes that a Date\/Time dimension\/column is necessary to accomplish this task and is seeking ideas.",
        "Question_gpt_summary":"user test detectspik detectanomali anomali spike data method requir input dimension float user need anomali gap miss data scenario request minut receiv request min month invoic user believ date time dimens column necessari accomplish task seek idea"
    },
    {
        "Question_title":"Which techniques are used by SageMaker Neo for model optimizations",
        "Question_body":"<p>Does SageMaker Neo (SageMaker compilation job) use any techniques for model optimization? Are there any compression techniques used (distillation, quantization etc) to reduce the model size?<\/p>\n<p>I found some description here (<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/neo.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/neo.html<\/a>) regarding quantization but it's not clear how it could be used.<\/p>\n<p>Thanks very much for any insight.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1663683615587,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":15.0,
        "Poster_created_time":1340961229400,
        "Poster_location":null,
        "Poster_reputation_count":91.0,
        "Poster_view_count":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73788252",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"techniqu neo model optim neo compil job us techniqu model optim compress techniqu distil quantiz reduc model size descript http doc aw amazon com latest neo html quantiz clear thank insight",
        "Question_preprocessed_content":"techniqu neo model optim neo us techniqu model optim techniqu reduc model size descript quantiz clear thank insight",
        "Question_gpt_summary_original":"The user is seeking information about the techniques used by SageMaker Neo for model optimization, specifically if compression techniques such as distillation and quantization are used to reduce model size. The user found some information on quantization but is unclear on how it is used.",
        "Question_gpt_summary":"user seek inform techniqu neo model optim specif compress techniqu distil quantiz reduc model size user inform quantiz unclear"
    },
    {
        "Question_title":"AzureML Model Register",
        "Question_body":"<p>I was trying to register a model using the <code>Run<\/code> Class like this:<\/p>\n<pre><code>model = run.register_model(\n    model_name=model_name,\n    model_path=model_path)\n<\/code><\/pre>\n<p>Errors with message: <code>Could not locate the provided model_path ... in the set of files uploaded to the run...<\/code><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1643643837027,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":319.0,
        "Poster_created_time":1589293508567,
        "Poster_location":null,
        "Poster_reputation_count":833.0,
        "Poster_view_count":55.0,
        "Answer_body":"<p>The only way I found to fix the issue was to use the <code>Model<\/code> Class instead:<\/p>\n<pre><code>        model = Model.register(\n            workspace=ws,\n            model_name=model_name,\n            model_path=model_path,\n            model_framework=Model.Framework.SCIKITLEARN,\n            model_framework_version=sklearn.__version__,\n            description='Model Deescription',\n            tags={'Name' : 'ModelName', 'Type' : 'Production'},\n            model_framework=Model.Framework.SCIKITLEARN,\n            model_framework_version='1.0'\n            )\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1643643837027,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1589293508567,
        "Answerer_location":null,
        "Answerer_reputation_count":833.0,
        "Answerer_view_count":55.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70928761",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model regist try regist model run class like model run regist model model model model path model path error messag locat provid model path set file upload run",
        "Question_preprocessed_content":"model regist try regist model like",
        "Question_gpt_summary_original":"The user encountered an error while trying to register a model using the Run Class in AzureML. The error message stated that the provided model_path could not be located in the uploaded files.",
        "Question_gpt_summary":"user encount error try regist model run class error messag state provid model path locat upload file"
    },
    {
        "Question_title":"How do I take an already existing MLflow model on my local filesystem and log it to a remote tracking server?",
        "Question_body":"<p>Let's say I already have an existing MLflow model on my local system of the <code>mlflow.pyfunc<\/code> flavor.<\/p>\n<p>The directory looks like this<\/p>\n<pre><code>model\/\n  data\/\n  code\/\n  conda.yml\n  MLmodel\n<\/code><\/pre>\n<p>Where <code>MLmodel<\/code> is something like<\/p>\n<pre><code>flavors:\n  python_function:\n    code: code\n    data: data\n    env: conda.yml\n    loader_module: loader # model\/code\/loader.py has the entrypoint\n<\/code><\/pre>\n<p>I now try and log this model to a remote tracking server using (I'm in the directory above <code>model\/<\/code>, so <code>.\/model\/data<\/code> works, etc)<\/p>\n<pre><code>import mlflow\nmlflow.set_tracking_uri(&quot;http:\/\/localhost:5000&quot;)\nmlflow.pyfunc.log_model(\n  &quot;my-model-artifact&quot;,\n  registered_model_name=&quot;my-model&quot;, # same for all model versions,\n  data_path=&quot;model\/data&quot;,\n  code_path=&quot;model\/code&quot;,\n  loader_module=&quot;model\/code\/loader&quot;\n)\n<\/code><\/pre>\n<p>The tracking server ends up logging a nested MLflow model.. this is inside of the <code>.\/artifacts\/my-model-artifact<\/code> directory on the tracking server<\/p>\n<pre><code>.\/artifacts\/my-model-artifact\n  conda.yaml\n  MLmodel # *not* my MLmodel, one newly generated by MLflow\n  data\/\n  code\/\n<\/code><\/pre>\n<p>Where <code>data<\/code> now points nested to my entire <code>model\/data<\/code> directory and <code>code<\/code> points to a nested <code>model\/code<\/code> directory.<\/p>\n<p>It's like it doesn't understand that I already have this full artifact..<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1646174584637,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":336.0,
        "Poster_created_time":1425965839876,
        "Poster_location":"Santa Cruz, CA",
        "Poster_reputation_count":3256.0,
        "Poster_view_count":164.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71315446",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"exist model local filesystem log remot track server let exist model local pyfunc flavor directori look like model data code conda yml mlmodel mlmodel like flavor python function code code data data env conda yml loader modul loader model code loader entrypoint try log model remot track server directori model model data work import set track uri http localhost pyfunc log model model artifact regist model model model version data path model data code path model code loader modul model code loader track server end log nest model insid artifact model artifact directori track server artifact model artifact conda yaml mlmodel mlmodel newli gener data code data point nest entir model data directori code point nest model code directori like understand artifact",
        "Question_preprocessed_content":"exist model local filesystem log remot track server let exist model local flavor directori like like try log model remot track server track server end nest insid directori track server point nest entir directori point nest directori like understand",
        "Question_gpt_summary_original":"The user is trying to log an existing MLflow model of the pyfunc flavor to a remote tracking server using the log_model function. However, the tracking server ends up logging a nested MLflow model instead of the existing one, which is causing confusion for the user.",
        "Question_gpt_summary":"user try log exist model pyfunc flavor remot track server log model function track server end log nest model instead exist caus confus user"
    },
    {
        "Question_title":"How to specifify the class of an AWS client in Python?",
        "Question_body":"<p>In Java, for instance, we have a class that represents the SageMaker client class: <code>AmazonSageMakerClient<\/code>, but I couldn't find the equivalent for Python.<\/p>\n<p>I was hoping to be able to do something like:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from sagemaker import SageMakerClient\nclient: SageMakerClient = boto3.client(&quot;sagemaker&quot;)\n<\/code><\/pre>\n<p>I looked into the library code and docs but I couldn't find any references to such class containing the defined methods for that client. In fact, I couldn't find any classes for AWS clients like <code>s3<\/code>, <code>sqs<\/code>, etc. Are those hidden somewhere or am I missing something obvious?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1.0,
        "Question_created_time":1660582010733,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":42.0,
        "Poster_created_time":1362417569863,
        "Poster_location":"Brussels, Belgium",
        "Poster_reputation_count":506.0,
        "Poster_view_count":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73364018",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"specififi class aw client python java instanc class repres client class amazoncli couldn equival python hope abl like import client client client boto client look librari code doc couldn refer class contain defin method client fact couldn class aw client like sq hidden miss obviou",
        "Question_preprocessed_content":"specififi aw client python java instanc repres client couldn equival python hope abl like librari code doc couldn refer contain defin method client fact couldn aw client like obviou",
        "Question_gpt_summary_original":"The user is trying to specify the class of an AWS client in Python, specifically for the SageMaker client. They are unable to find the equivalent class in Python and have looked into the library code and documentation but could not find any references to such a class. They are wondering if they are missing something obvious or if the classes are hidden somewhere.",
        "Question_gpt_summary":"user try specifi class aw client python specif client unabl equival class python look librari code document refer class wonder miss obviou class hidden"
    },
    {
        "Question_title":"How to call a model's artifacts (pickeled vectorizer) when the model is on Production in databricks?",
        "Question_body":"<p>I am using databrick, machine learning view. I have successfully created and saved my model and also logged my pickled vectorizer as artifacts to it. I would like to load it in a different notebook; the model and the artifacts belong to the model which is currently in production.<\/p>\n<pre><code>   import mlflow.pyfunc\n\nmodel_name = &quot;Sentiment&quot;\nstage = 'Production'\n\nmodel = mlflow.pyfunc.load_model(\n    model_uri=f&quot;models:\/{model_name}\/{stage}&quot;\n)\n<\/code><\/pre>\n<p>So this code seems to be working but it does not load the artifacts or if it does, i do not know how to display them.<\/p>\n<p>I have found this code but not sure what to do with it to only get the artifacts from the model which is in Production.<\/p>\n<pre><code>  from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\nversion =1\nmodel_uri = MlflowClient.get_model_version_download_uri(name=model_name, version=version)\nModelsArtifactRepository(model_uri).download_artifacts(artifact_path=&quot;&quot;)\n<\/code><\/pre>\n<p>even when i run this i get an error :<\/p>\n<p>TypeError: get_model_version_download_uri() missing 1 required positional argument: 'self'<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1663332985133,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1663334102563,
        "Question_score_count":0.0,
        "Question_view_count":10.0,
        "Poster_created_time":1654503897990,
        "Poster_location":null,
        "Poster_reputation_count":47.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73745159",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model artifact pickel vector model product databrick databrick machin learn view successfulli creat save model log pickl vector artifact like load differ notebook model artifact belong model current product import pyfunc model sentiment stage product model pyfunc load model model uri model model stage code work load artifact know displai code sure artifact model product store artifact model artifact repo import modelsartifactrepositori version model uri client model version download uri model version version modelsartifactrepositori model uri download artifact artifact path run error typeerror model version download uri miss requir posit argument self",
        "Question_preprocessed_content":"model artifact model product databrick databrick machin learn view creat save model pickl vector artifact like load model artifact belong model product code work load artifact know displai code sure artifact model product run requir posit argument self",
        "Question_gpt_summary_original":"The user is trying to load a pickled vectorizer from a model that is currently in production on Databricks. They have tried using the mlflow.pyfunc.load_model() function but are unable to display the artifacts. They have also attempted to use the ModelsArtifactRepository() function but are encountering an error.",
        "Question_gpt_summary":"user try load pickl vector model current product databrick tri pyfunc load model function unabl displai artifact attempt us modelsartifactrepositori function encount error"
    },
    {
        "Question_title":"Cloud Vision API - Wrong line order",
        "Question_body":"Hi there,\n\nI'm curious how are you handling the too common case where DOCUMENT_TEXT_DETECTION returns the text lines (or specific words) at incorrect order, despite the input being a simple paragraph. For example, line n would jump to line n+2, then backtrack to line n+1.\n\nUsing \"legacy_layout\" does not usually help.\n\nthanks!",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1672883040000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":123.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-Vision-API-Wrong-line-order\/m-p\/506806#M1022",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"cloud vision api wrong line order curiou handl common case document text detect return text line specif word incorrect order despit input simpl paragraph exampl line jump line backtrack line legaci layout usual help thank",
        "Question_preprocessed_content":"cloud vision api wrong line order curiou handl case return text line order despit input simpl paragraph exampl line jump line backtrack line help thank",
        "Question_gpt_summary_original":"The user is facing an issue with the Cloud Vision API where the text lines or words are returned in the wrong order despite the input being a simple paragraph. The user has tried using \"legacy_layout\" but it has not helped.",
        "Question_gpt_summary":"user face issu cloud vision api text line word return wrong order despit input simpl paragraph user tri legaci layout help"
    },
    {
        "Question_title":"How to start? No knowledge no skill in AI or ML",
        "Question_body":"<p>Hi every one, i am a pure pure beginner in AI  and this forum can you tell me where should i go to learn basics of ML?<br>\nBecause i saw 2min Paper  telling the audience that People like me are welcomed!<br>\nThank you very much!<br>\nEro<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1660080448945,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":258.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-start-no-knowledge-no-skill-in-ai-or-ml\/2876",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"start knowledg skill pure pure beginn forum tell learn basic saw min paper tell audienc peopl like welcom thank ero",
        "Question_preprocessed_content":"start knowledg pure pure forum learn basic saw min paper audienc peopl like welcom thank ero",
        "Question_gpt_summary_original":"The user is a complete beginner in AI and is seeking guidance on where to start learning the basics of ML. They came across a video that encouraged beginners like them to learn and are seeking recommendations from the forum.",
        "Question_gpt_summary":"user complet beginn seek guidanc start learn basic came video encourag beginn like learn seek recommend forum"
    },
    {
        "Question_title":"Trained NLP model snippet",
        "Question_body":"<p>Newbie data scientist here, I am just starting my way in Azure, is there any I should start NLP? Any trained model or code sample? Thank you for any idea<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1667251332713,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=12b79ebe-b30f-4203-a714-62377c3d557b\">@jackson schmidt  <\/a>     <\/p>\n<p>Sorry I have not heard from you. I have done some researches around NLP in Azure. This can be done by two ways -    <\/p>\n<ol>\n<li> Azure Machine Learning Python SDK\/ ML CLI extension    <br \/>\nWe don't have any trained model you can use in Azure ML but you do have the SDK supporting you to train your model    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-nlp-models?tabs=cli\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-nlp-models?tabs=cli<\/a>    <\/li>\n<li> NLP Server     <br \/>\nApache Spark is a parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Azure Synapse Analytics, Azure HDInsight, and Azure Databricks offer access to Spark and take advantage of its processing power.    <\/li>\n<\/ol>\n<p>For customized NLP workloads, Spark NLP serves as an efficient framework for processing a large amount of text. This open-source NLP library provides Python, Java, and Scala libraries that offer the full functionality of traditional NLP libraries such as spaCy, NLTK, Stanford CoreNLP, and Open NLP. Spark NLP also offers functionality such as spell checking, sentiment analysis, and document classification. Spark NLP improves on previous efforts by providing state-of-the-art accuracy, speed, and scalability.    <\/p>\n<p><img src=\"https:\/\/learn.microsoft.com\/en-us\/azure\/architecture\/data-guide\/images\/natural-language-processing-functionality.png\" alt=\"natural-language-processing-functionality.png\" \/>    <\/p>\n<p>The NLP Server is available in Azure Marketplace. To explore large-scale custom NLP in Azure, see NLP Server - <a href=\"https:\/\/azuremarketplace.microsoft.com\/en-US\/marketplace\/apps\/johnsnowlabsinc1646051154808.nlp_server?ocid=gtmrewards_whatsnewblog_nlp_server_040622\">https:\/\/azuremarketplace.microsoft.com\/en-US\/marketplace\/apps\/johnsnowlabsinc1646051154808.nlp_server?ocid=gtmrewards_whatsnewblog_nlp_server_040622<\/a>    <\/p>\n<ol start=\"3\">\n<li> Azure Language Service    <br \/>\nThough we don't have trained model in Azure ML, but we do have REST APIs you can use for Text Analytics, Sentiment Analytics and so on functions for NLP, I would suggest you to check on the document, it may help you achieve your bussiness goals.    <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/<\/a>    <\/li>\n<\/ol>\n<p>I hope those information helps. Please let me know if you have any questions regarding to any of above.     <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1667776545220,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1069986\/trained-nlp-model-snippet",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train nlp model snippet newbi data scientist start wai azur start nlp train model code sampl thank idea",
        "Question_preprocessed_content":"train nlp model newbi data scientist start wai azur start nlp train model code sampl thank idea",
        "Question_gpt_summary_original":"The user is a newbie data scientist who is looking for guidance on how to start with NLP in Azure. They are seeking suggestions for trained models or code samples to help them get started.",
        "Question_gpt_summary":"user newbi data scientist look guidanc start nlp azur seek suggest train model code sampl help start"
    },
    {
        "Question_title":"Moving resources across the regions",
        "Question_body":"<p>Hi,   <br \/>\nWe have resource group(RG1) created in Germany region. Resource created are   <\/p>\n<ol>\n<li> Vnet  <\/li>\n<li> VPN gateway  <\/li>\n<li> Disks - HDD  <\/li>\n<li> VM (database installed)  <\/li>\n<\/ol>\n<p>We wanted to use  Azure machine learning service to read data from database(present in resource group RG1 in German region). We later found that azure machine learning service is not available in Germany region and in order to create end points for Azure ML service both the networks(vnets of the DB and Azure ML ) should be in the same region.   <\/p>\n<p>So we tried migrating the resource and resource group (RG1) from German region to west Europe by using wizard on the portal. But we got prompted that disk , vnet and vpn gateway cannot be moved to different region ) .   <\/p>\n<p>Is there anyway we could move them ? or any alternate solutions ? .Else, we would end up recreating every thing in westeurope which i would like to avoid.   <\/p>\n<p>Regards,   <br \/>\nSuman <\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1606983526427,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Maybe this is helpful:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/site-recovery\/azure-to-azure-tutorial-migrate\">https:\/\/learn.microsoft.com\/en-us\/azure\/site-recovery\/azure-to-azure-tutorial-migrate<\/a>    <\/p>\n<p>----------    <\/p>\n<p>(If the reply was helpful please don't forget to <strong>upvote<\/strong> and\/or <strong>accept as answer<\/strong>, thank you)    <\/p>\n<p>Regards    <br \/>\n Andreas Baumgarten    <\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1606984258243,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/184565\/moving-resources-across-the-regions",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"move resourc region resourc group creat germani region resourc creat vnet vpn gatewai disk hdd databas instal want us servic read data databas present resourc group german region later servic avail germani region order creat end point servic network vnet region tri migrat resourc resourc group german region west europ wizard portal got prompt disk vnet vpn gatewai move differ region altern solut end recreat thing westeurop like avoid regard suman",
        "Question_preprocessed_content":"move resourc region resourc group creat germani region resourc creat vnet vpn gatewai disk want us servic read data databas later servic avail germani region order creat end point servic network region tri migrat resourc resourc group german region west europ wizard portal got prompt disk vnet vpn gatewai move region altern solut end recreat thing westeurop like avoid regard suman",
        "Question_gpt_summary_original":"The user has a resource group in the Germany region with various resources including a VM with a database. They want to use Azure machine learning service to read data from the database but found out that the service is not available in Germany. They tried to migrate the resource group to the West Europe region but were unable to move the disks, Vnet, and VPN gateway. The user is seeking an alternative solution to avoid recreating everything in West Europe.",
        "Question_gpt_summary":"user resourc group germani region resourc includ databas want us servic read data databas servic avail germani tri migrat resourc group west europ region unabl disk vnet vpn gatewai user seek altern solut avoid recreat west europ"
    },
    {
        "Question_title":"how to predict more multiple values in azure ml?",
        "Question_body":"<p>I am creating Azure ML experienment to predict multiple values. but in azure ml we can not train a model to predict multiple values. my question is how to bring multiple trained models in single experienment and create webout put that gives me multiple prediction.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1517479996490,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1517995658060,
        "Question_score_count":0.0,
        "Question_view_count":666.0,
        "Poster_created_time":1517479193607,
        "Poster_location":null,
        "Poster_reputation_count":3.0,
        "Poster_view_count":7.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48560183",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"predict multipl valu creat experien predict multipl valu train model predict multipl valu question bring multipl train model singl experien creat webout give multipl predict",
        "Question_preprocessed_content":"predict multipl valu creat experien predict multipl valu train model predict multipl valu question bring multipl train model singl experien creat webout give multipl predict",
        "Question_gpt_summary_original":"The user is facing a challenge in creating an Azure ML experiment to predict multiple values as Azure ML does not allow training a model to predict multiple values. The user is seeking a solution to bring multiple trained models in a single experiment and create web output that provides multiple predictions.",
        "Question_gpt_summary":"user face challeng creat experi predict multipl valu allow train model predict multipl valu user seek solut bring multipl train model singl experi creat web output provid multipl predict"
    },
    {
        "Question_title":"Connect Azure ML notebook to azure VM",
        "Question_body":"<p>Hey All,  <\/p>\n<p>I want to connect to my VM in order to get access to files on the VM from my notebook. Is it possible?  <\/p>\n<p>can someone help me with it?  <\/p>\n<p>thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1639928946803,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/668659\/connect-azure-ml-notebook-to-azure-vm",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect notebook azur hei want connect order access file notebook possibl help thank",
        "Question_preprocessed_content":"azur hei want order file help thank",
        "Question_gpt_summary_original":"The user is seeking assistance in connecting their Azure ML notebook to their Azure VM to access files on the VM.",
        "Question_gpt_summary":"user seek assist connect notebook azur access file"
    },
    {
        "Question_title":"Vertax AI pipeline quota",
        "Question_body":"<p>I got a custom_model_training_cpus error when runing a submitted pipeline on Vertex AI. I could not find any documents. And I am using the n1-standard-4 for the deployment machine, I do not see any issue. Any commnents would be much appriciated.<\/p>\n<blockquote>\n<p>com.google.cloud.ai.platform.common.errors.AiPlatformException: code=RESOURCE_EXHAUSTED, message=The following quota metrics exceed quota limits: aiplatform.googleapis.com\/custom_model_training_cpus, cause=null; Failed to create custom job for the task.<\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TgCJD.png\" rel=\"nofollow noreferrer\">DAG flow and error message<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1660618735810,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":110.0,
        "Poster_created_time":1660618422463,
        "Poster_location":null,
        "Poster_reputation_count":31.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73368320",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"vertax pipelin quota got custom model train cpu error rune submit pipelin document standard deploy machin issu commnent apprici com googl cloud platform common error aiplatformexcept code resourc exhaust messag follow quota metric exce quota limit aiplatform googleapi com custom model train cpu caus null fail creat custom job task dag flow error messag",
        "Question_preprocessed_content":"vertax pipelin quota got rune pipelin document deploy machin quota metric quota limit caus fail creat custom job task dag flow",
        "Question_gpt_summary_original":"The user encountered a custom_model_training_cpus error while running a submitted pipeline on Vertex AI. The error message indicates that the quota metrics exceed the quota limits, and the user is unable to find any relevant documents to resolve the issue. The user is using n1-standard-4 for the deployment machine and seeks comments to address the problem.",
        "Question_gpt_summary":"user encount custom model train cpu error run submit pipelin error messag indic quota metric exce quota limit user unabl relev document resolv issu user standard deploy machin seek comment address problem"
    },
    {
        "Question_title":"forecast package versions different result",
        "Question_body":"<p>I am using R forecast package auto.arima() function, testing it against a predictable sine wave time series. When I run the R code on local machine in R studio, I get a significantly different output to running exactly the same code with the same source data as in azure ML. The only difference I can see is that azure has an older version of forecast package 5.4 whereas i have downloaded the latest version on local machine 5.9. (Interestingly the older version in azure ML correctly forecasts future values, the newer version predicts an attenuating amplitude, which is incorrect). <\/p>\n\n<p>My question then is for anyone who may know why a function's behaviour would change so significantly between package versions, which strikes me as very strange. Or am I missing something here? I am new to both R and azure ML.. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1430172286407,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1483523471852,
        "Question_score_count":0.0,
        "Question_view_count":212.0,
        "Poster_created_time":1430171674327,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29906812",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"forecast packag version differ result forecast packag auto arima function test predict sine wave time seri run code local machin studio significantli differ output run exactli code sourc data differ azur older version forecast packag download latest version local machin interestingli older version correctli forecast futur valu newer version predict attenu amplitud incorrect question know function behaviour chang significantli packag version strike strang miss new",
        "Question_preprocessed_content":"forecast packag version result forecast packag function test predict sine wave time seri run code local machin studio significantli output exactli code sourc data azur older version forecast packag download latest version local machin question know function behaviour chang significantli packag version strike strang new",
        "Question_gpt_summary_original":"The user is facing a challenge with the R forecast package auto.arima() function, as the output differs significantly when run on their local machine in R studio compared to running the same code with the same source data in Azure ML. The only difference is that Azure ML has an older version of the forecast package (5.4) while the user has the latest version (5.9). The older version in Azure ML correctly forecasts future values, while the newer version predicts an attenuating amplitude, which is incorrect. The user is seeking help to understand why a function's behavior would change so significantly between package versions.",
        "Question_gpt_summary":"user face challeng forecast packag auto arima function output differ significantli run local machin studio compar run code sourc data differ older version forecast packag user latest version older version correctli forecast futur valu newer version predict attenu amplitud incorrect user seek help understand function behavior chang significantli packag version"
    },
    {
        "Question_title":"Azure Machine Learning - Use personal container registry",
        "Question_body":"<p>I tried to run this code to create an ml workspace from the azure-ml-cli, referencing an existing azure container registry from another subscription:<\/p>\n<pre><code>az ml workspace create --workspace-name &quot;test-mlws&quot; --keyvault &quot;&lt;key-vault-service-id&gt;&quot; --container-registry &quot;&lt;container-registry-zervice-id&gt;&quot; --location westeurope\n<\/code><\/pre>\n<p>The deploy failed with this error code:<\/p>\n<pre><code>{'code': 'InternalServerError', 'message': 'Received 403 from a service request'}\n<\/code><\/pre>\n<p>I can't find any documentation about it, and I guess it's due to the container registry I used which belongs to another subscription. Anyone who knows if it's mandatory for the registry to be in the same subscription?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1617971298560,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1618194925572,
        "Question_score_count":0.0,
        "Question_view_count":773.0,
        "Poster_created_time":1519297984923,
        "Poster_location":"Cagliari, CA, Italia",
        "Poster_reputation_count":127.0,
        "Poster_view_count":21.0,
        "Answer_body":"<p>From <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#limitations\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#limitations<\/a><\/p>\n<blockquote>\n<p>If you want to use <strong>existing services from a different Azure\nsubscription<\/strong> than the workspace, you must register the Azure Machine\nLearning namespace in the subscription that contains those services.<\/p>\n<\/blockquote>\n<p>So, in order to use the ACR in that different subscription, you need to register resource provider <code>Microsoft.MachineLearningServices<\/code> in that subscription contains ACR. For information on how to see if it is registered and how to register it, see the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/resource-providers-and-types\" rel=\"nofollow noreferrer\">Azure resource providers and types<\/a> article.<\/p>\n<p>To register a resource provider, use:<\/p>\n<pre><code>Register-AzResourceProvider -ProviderNamespace Microsoft.MachineLearningServices\n<\/code><\/pre>\n<p>To see information for a particular resource provider, use:<\/p>\n<pre><code>Get-AzResourceProvider -ProviderNamespace Microsoft.MachineLearningServices\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1618194887616,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1527065173880,
        "Answerer_location":null,
        "Answerer_reputation_count":25218.0,
        "Answerer_view_count":2553.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67021176",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us person contain registri tri run code creat workspac azur cli referenc exist azur contain registri subscript workspac creat workspac test mlw keyvault contain registri locat westeurop deploi fail error code code internalservererror messag receiv servic request document guess contain registri belong subscript know mandatori registri subscript",
        "Question_preprocessed_content":"us person contain registri tri run code creat workspac referenc exist azur contain registri subscript deploi fail code document contain registri belong subscript know mandatori registri subscript",
        "Question_gpt_summary_original":"The user encountered an error while trying to create an ml workspace from the azure-ml-cli, referencing an existing azure container registry from another subscription. The error code received was 'InternalServerError' with a message stating 'Received 403 from a service request'. The user suspects that the error is due to the container registry belonging to another subscription and is unsure if it is mandatory for the registry to be in the same subscription.",
        "Question_gpt_summary":"user encount error try creat workspac azur cli referenc exist azur contain registri subscript error code receiv internalservererror messag state receiv servic request user suspect error contain registri belong subscript unsur mandatori registri subscript"
    },
    {
        "Question_title":"Error importing JSONL dataset into Vertex AI",
        "Question_body":"<p>I tried importing a JSONL dataset into Google's Vertex AI and get a weird and seemingly unrelated error:<\/p>\n<pre><code>Error: Could not parse the line, json is invalid or the format does not match the input schema: Cannot find field: classificationAnnotation in message google.cloud.aiplatform.master.schema.ImageBoundingBoxIoFormat. for: gs:\/\/[bucketname]\/set.jsonl line 10\n<\/code><\/pre>\n<p>It happens every 4 lines of code. All of my lines are identical except the image name changes.<\/p>\n<p>Line 10:<\/p>\n<pre><code>{&quot;imageGcsUri&quot;:&quot;gs:\/\/[mybucket]\/path\/to\/image.png&quot;,&quot;classificationAnnotation&quot;:{&quot;displayName&quot;:&quot;MyLabel&quot;,&quot;annotationResourceLabels&quot;:{&quot;aiplatform.googleapis.com\/annotation_set_name&quot;:&quot;MyLabel&quot;}},&quot;dataItemResourceLabels&quot;:{&quot;aiplatform.googleapis.com\/ml_use&quot;:&quot;training&quot;}}\n<\/code><\/pre>\n<p>Why am I getting this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1660139623310,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":93.0,
        "Poster_created_time":1297920350390,
        "Poster_location":"Perth, Australia",
        "Poster_reputation_count":2950.0,
        "Poster_view_count":367.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73307573",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error import jsonl dataset tri import jsonl dataset googl weird seemingli unrel error error pars line json invalid format match input schema field classificationannot messag googl cloud aiplatform master schema imageboundingboxioformat bucketnam set jsonl line happen line code line ident imag chang line imagegcsuri mybucket path imag png classificationannot displaynam mylabel annotationresourcelabel aiplatform googleapi com annot set mylabel dataitemresourcelabel aiplatform googleapi com us train get error",
        "Question_preprocessed_content":"import jsonl dataset tri import jsonl dataset weird unrel line code line ident imag chang line",
        "Question_gpt_summary_original":"The user is encountering an error while trying to import a JSONL dataset into Google's Vertex AI. The error message suggests that there is an issue with the format of the input schema and that the field \"classificationAnnotation\" cannot be found in the message. The error occurs every 4 lines of code, and all lines are identical except for the image name. The user is seeking help to understand why this error is occurring.",
        "Question_gpt_summary":"user encount error try import jsonl dataset googl error messag suggest issu format input schema field classificationannot messag error occur line code line ident imag user seek help understand error occur"
    },
    {
        "Question_title":"Azure OpenAI service capabilities",
        "Question_body":"<p>How do I get access to the Azure OpenAI service to evaluate it's capabilities?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1663989341807,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a> Thanks for the question. It is a Limited Access service so you have to apply for it <a href=\"https:\/\/aka.ms\/oai\/access\">https:\/\/aka.ms\/oai\/access<\/a><\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1664001167767,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1021561\/azure-openai-service-capabilities",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"azur openai servic capabl access azur openai servic evalu capabl",
        "Question_preprocessed_content":"azur openai servic capabl azur openai servic evalu capabl",
        "Question_gpt_summary_original":"The user is seeking information on how to access the Azure OpenAI service to evaluate its capabilities.",
        "Question_gpt_summary":"user seek inform access azur openai servic evalu capabl"
    },
    {
        "Question_title":"AWS SageMaker Canvas Model usage on Edge device in Python",
        "Question_body":"<p>This way I wanted to ask a question about AWS Sagemaker. I must confess that I'm quite a newbee to the subject and therefor I was very happy with the SageMaker Canvas app. It works really easy and gives me some nice results.<\/p>\n<p>First of all my model. I try to predict solar power production based on the time (dt), the AWS IoT Thingname (thingname), clouds percentage (clouds) and temperature (temp). I have a csv filled with data measured by IoT things<\/p>\n<p><code>clouds<\/code> + <code>temp<\/code> + <code>dt<\/code> + <code>thingname<\/code> =&gt; <code>import<\/code><\/p>\n<pre><code>dt,clouds,temp,import,thingname\n2022-08-30 07:45:00+02:00,1.0,0.1577,0.03,***\n2022-08-30 08:00:00+02:00,1.0,0.159,0.05,***\n2022-08-30 08:15:00+02:00,1.0,0.1603,0.06,***\n2022-08-30 08:30:00+02:00,1.0,0.16440000000000002,0.08,***\n2022-08-30 08:45:00+02:00,,,0.09,***\n2022-08-30 09:00:00+02:00,1.0,0.17,0.12,***\n2022-08-30 09:15:00+02:00,1.0,0.1747,0.13,***\n2022-08-30 09:30:00+02:00,1.0,0.1766,0.15,***\n2022-08-30 09:45:00+02:00,0.75,0.1809,0.18,***\n2022-08-30 10:00:00+02:00,1.0,0.1858,0.2,***\n2022-08-30 10:15:00+02:00,1.0,0.1888,0.21,***\n2022-08-30 10:30:00+02:00,0.75,0.1955,0.24,***\n<\/code><\/pre>\n<p>In AWS SageMaker canvas I upload the csv and build the model. All is very easy and when I use the predict tab I upload a CSV where the import column is missing and containing API weather data for some future moment:<\/p>\n<pre><code>dt,thingname,temp,clouds\n2022-09-21 10:15:00+02:00,***,0.1235,1.0\n2022-09-21 10:30:00+02:00,***,0.1235,1.0\n2022-09-21 10:45:00+02:00,***,0.1235,1.0\n2022-09-21 11:00:00+02:00,***,0.1235,1.0\n2022-09-21 11:15:00+02:00,***,0.12689999999999999,0.86\n2022-09-21 11:30:00+02:00,***,0.12689999999999999,0.86\n2022-09-21 11:45:00+02:00,***,0.12689999999999999,0.86\n2022-09-21 12:00:00+02:00,***,0.12689999999999999,0.86\n2022-09-21 12:15:00+02:00,***,0.1351,0.69\n2022-09-21 12:30:00+02:00,***,0.1351,0.69\n2022-09-21 12:45:00+02:00,***,0.1351,0.69\n<\/code><\/pre>\n<p>From this data SageMaker Canvas predicts some real realistic numbers, from which I assume the model is nicely build. So I want to move this model to my Greengrass Core Device to do predictions on site. I found the best model location using the sharing link to the Junyper notebook.<\/p>\n<p>From reading in the AWS docs I seem to have a few options to run the model on an edge device:<\/p>\n<ul>\n<li>Run the Greengrass SageMaker Edge component and run the model as a component and write an inference component<\/li>\n<li>Run the SageMaker Edge Agent yourself<\/li>\n<li>Just download the model yourself and do your thing with it on the device<\/li>\n<\/ul>\n<p>Now it seems that SageMaker used XGBoost to create the model and I found the <code>xgboost-model<\/code> file and downloaded it to the device.<\/p>\n<p>But here is where the trouble started:\nSageMaker Canvas never gives any info on what it does with the CSV to format it, so I have really no clue on how to make a prediction using the model.\nI get some results when I try to open the same csv file I used for the Canvas prediction, but the data is completely different and not realistic at all<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># pip install xgboost==1.6.2\nimport xgboost as xgb\n\nfilename = f'solar-prediction-data.csv'\ndpredict = xgb.DMatrix(f'{filename}?format=csv')\nmodel = xgb.Booster()\nmodel.load_model('xgboost-model')\nresult = model.predict(dpredict)\nprint('Prediction result::')\nprint(result)\n<\/code><\/pre>\n<p>I read that the column order matters, the CSV may not contain a header.  But it does not get close to the SageMaker Canvas result.<\/p>\n<p>I also tried using <code>pandas<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># pip install xgboost==1.6.2\nimport xgboost as xgb\nimport pandas as pd\n\nfilename = f'solar-prediction-data.csv'\ndf = pd.read_csv(filename, index_col=None, header=None)\n\ndpredict = xgb.DMatrix(df, enable_categorical=True)\n\nmodel = xgb.Booster()\nmodel.load_model('xgboost-model')\nresult = model.predict(dpredict, pred_interactions=True)\nprint('Prediction result::')\nprint('===============')\nprint(result)\n<\/code><\/pre>\n<p>But this last one always gives me following error:<\/p>\n<pre><code>ValueError: DataFrame.dtypes for data must be int, float, bool or category.  When\ncategorical type is supplied, DMatrix parameter `enable_categorical` must\nbe set to `True`. Invalid columns:dt, thingname\n<\/code><\/pre>\n<p>To be honest, I'm completely stuck and hope someone around here can give me some advice or clue on how I can proceed.<\/p>\n<p>Thanks!\nKind regards<\/p>\n<p>Hacor<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1663940700760,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":18.0,
        "Poster_created_time":1455091044887,
        "Poster_location":null,
        "Poster_reputation_count":43.0,
        "Poster_view_count":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73828700",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"canva model usag edg devic python wai want ask question confess newbe subject therefor happi canva app work easi give nice result model try predict solar power product base time aw iot thingnam thingnam cloud percentag cloud temperatur temp csv fill data measur iot thing cloud temp thingnam import cloud temp import thingnam canva upload csv build model easi us predict tab upload csv import column miss contain api weather data futur moment thingnam temp cloud data canva predict real realist number assum model nice build want model greengrass core devic predict site best model locat share link junyp notebook read aw doc option run model edg devic run greengrass edg compon run model compon write infer compon run edg agent download model thing devic xgboost creat model xgboost model file download devic troubl start canva give info csv format clue predict model result try open csv file canva predict data complet differ realist pip instal xgboost import xgboost xgb filenam solar predict data csv dpredict xgb dmatrix filenam format csv model xgb booster model load model xgboost model result model predict dpredict print predict result print result read column order matter csv contain header close canva result tri panda pip instal xgboost import xgboost xgb import panda filenam solar predict data csv read csv filenam index col header dpredict xgb dmatrix enabl categor true model xgb booster model load model xgboost model result model predict dpredict pred interact true print predict result print print result give follow error valueerror datafram dtype data int float bool categori categor type suppli dmatrix paramet enabl categor set true invalid column thingnam honest complet stuck hope advic clue proce thank kind regard hacor",
        "Question_preprocessed_content":"canva model usag edg devic python wai want ask question subject therefor canva work easi give nice result model try predict solar power product base time aw iot thingnam cloud percentag temperatur csv data measur iot thing canva upload csv build model easi us predict tab upload csv import column contain api weather data futur moment data canva predict real realist number model nice build want model core devic predict site best model locat share link junyp read aw doc option run model edg devic run edg compon run model compon write infer compon run edg agent download model thing devic creat model file download devic troubl start canva give info csv format clue predict model result try open csv file canva predict data complet realist read column order csv contain header close canva result tri give honest complet stuck hope advic clue thank kind regard hacor",
        "Question_gpt_summary_original":"The user is trying to use an AWS SageMaker Canvas app to predict solar power production based on data from an IoT device. They have successfully built a model in SageMaker Canvas and are now trying to move the model to their Greengrass Core Device to do predictions on site. However, they are having trouble making predictions using the model on the device, as they do not know how to format the CSV data correctly. They have tried using xgboost and pandas libraries but have not been successful. They are seeking advice on how to proceed.",
        "Question_gpt_summary":"user try us canva app predict solar power product base data iot devic successfulli built model canva try model greengrass core devic predict site have troubl make predict model devic know format csv data correctli tri xgboost panda librari success seek advic proce"
    },
    {
        "Question_title":"VertexAI Batch Inference Failing for Custom Container Model",
        "Question_body":"<p>I'm having trouble executing VertexAI's batch inference, despite endpoint deployment and inference working perfectly. My TensorFlow model has been trained in a custom Docker container with the following arguments:<\/p>\n<pre><code>aiplatform.CustomContainerTrainingJob(\n        display_name=display_name,\n        command=[&quot;python3&quot;, &quot;train.py&quot;],\n        container_uri=container_uri,\n        model_serving_container_image_uri=container_uri,\n        model_serving_container_environment_variables=env_vars,\n        model_serving_container_predict_route='\/predict',\n        model_serving_container_health_route='\/health',\n        model_serving_container_command=[\n            &quot;gunicorn&quot;,\n            &quot;src.inference:app&quot;,\n            &quot;--bind&quot;,\n            &quot;0.0.0.0:5000&quot;,\n            &quot;-k&quot;,\n            &quot;uvicorn.workers.UvicornWorker&quot;,\n            &quot;-t&quot;,\n            &quot;6000&quot;,\n        ],\n        model_serving_container_ports=[5000],\n)\n<\/code><\/pre>\n<p>I have a Flask endpoint defined for predict and health essentially defined below:<\/p>\n<pre><code>@app.get(f&quot;\/health&quot;)\ndef health_check_batch():\n    return 200\n\n@app.post(f&quot;\/predict&quot;)\ndef predict_batch(request_body: dict):\n    pred_df = pd.DataFrame(request_body['instances'],\n                           columns = request_body['parameters']['columns'])\n    # do some model inference things\n    return {&quot;predictions&quot;: predictions.tolist()}\n<\/code><\/pre>\n<p>As described, when training a model and deploying to an endpoint, I can successfully hit the API with JSON schema like:<\/p>\n<pre><code>{&quot;instances&quot;:[[1,2], [1,3]], &quot;parameters&quot;:{&quot;columns&quot;:[&quot;first&quot;, &quot;second&quot;]}}\n<\/code><\/pre>\n<p>This also works when using the endpoint Python SDK and feeding in instances\/parameters as functional arguments.<\/p>\n<p>However, I've tried performing batch inference with a CSV file and a JSONL file, and every time it fails with an Error Code 3. I can't find logs on why it failed in Logs Explorer either. I've read through all the documentation I could find and have seen other's successfully invoke batch inference, but haven't been able to find a guide. Does anyone have recommendations on batch file structure or the structure of my APIs? Thank you!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1650785345693,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":111.0,
        "Poster_created_time":1467136510360,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":7.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71986344",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"vertexai batch infer fail custom contain model have troubl execut vertexai batch infer despit endpoint deploy infer work perfectli tensorflow model train custom docker contain follow argument aiplatform customcontainertrainingjob displai displai command python train contain uri contain uri model serv contain imag uri contain uri model serv contain environ variabl env var model serv contain predict rout predict model serv contain health rout health model serv contain command gunicorn src infer app bind uvicorn worker uvicornwork model serv contain port flask endpoint defin predict health essenti defin app health def health check batch return app post predict def predict batch request bodi dict pred datafram request bodi instanc column request bodi paramet column model infer thing return predict predict tolist describ train model deploi endpoint successfulli hit api json schema like instanc paramet column second work endpoint python sdk feed instanc paramet function argument tri perform batch infer csv file jsonl file time fail error code log fail log explor read document seen successfulli invok batch infer haven abl guid recommend batch file structur structur api thank",
        "Question_preprocessed_content":"vertexai batch infer fail custom contain model have troubl execut vertexai batch infer despit endpoint deploy infer work perfectli tensorflow model train custom docker contain argument flask endpoint defin predict health defin describ train model deploi endpoint hit api json schema like work endpoint python sdk function argument tri perform batch infer csv file jsonl file time fail code log fail log explor read document invok batch infer haven abl guid batch file structur structur api thank",
        "Question_gpt_summary_original":"The user is facing issues while performing batch inference using VertexAI despite successful endpoint deployment and inference. The TensorFlow model has been trained in a custom Docker container, and the Flask endpoint is defined for predict and health. The user has tried performing batch inference with a CSV file and a JSONL file, but it fails every time with an Error Code 3, and the logs do not provide any information on why it failed. The user is seeking recommendations on batch file structure or API structure to resolve the issue.",
        "Question_gpt_summary":"user face issu perform batch infer vertexai despit success endpoint deploy infer tensorflow model train custom docker contain flask endpoint defin predict health user tri perform batch infer csv file jsonl file fail time error code log provid inform fail user seek recommend batch file structur api structur resolv issu"
    },
    {
        "Question_title":"Newly released based image for Azure Machine Learning contains medium- and high-level security vulnerabillities",
        "Question_body":"<p>Hi,     <\/p>\n<p>We are currently using the latest (as of 4 Aug 2022) container based image released by Microsoft for our AML workloads: mcr.microsoft.com\/azureml\/openmpi4.1.0-ubuntu20.04:20220729.v1 (<a href=\"https:\/\/github.com\/Azure\/AzureML-Containers\/blob\/master\/base\/cpu\/openmpi4.1.0-ubuntu20.04\/release-notes.md\">https:\/\/github.com\/Azure\/AzureML-Containers\/blob\/master\/base\/cpu\/openmpi4.1.0-ubuntu20.04\/release-notes.md<\/a>).    <\/p>\n<p>However, this image contains the following security vulnerabilities:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/227904-screenshot-1.jpg?platform=QnA\" alt=\"227904-screenshot-1.jpg\" \/>    <\/p>\n<p>We would like to know if it's possible to resolve them (we are not sure how to implement the remedy provided).    <br \/>\nIn our company, vulnerable container registry images would be deleted automatically - hence it's important for us to know how to make the image secure.    <\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1659575906903,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/954345\/newly-released-based-image-for-azure-machine-learn",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"newli releas base imag contain medium high level secur vulnerabil current latest aug contain base imag releas microsoft aml workload mcr microsoft com openmpi ubuntu http github com azur contain blob master base cpu openmpi ubuntu releas note imag contain follow secur vulner like know possibl resolv sure implement remedi provid compani vulner contain registri imag delet automat import know imag secur thank",
        "Question_preprocessed_content":"newli releas base imag contain medium secur latest contain base imag releas microsoft aml workload imag contain secur vulner like know resolv compani vulner contain registri imag delet import know imag secur thank",
        "Question_gpt_summary_original":"The user is facing security vulnerabilities in the latest container-based image released by Microsoft for their Azure Machine Learning workloads. The vulnerabilities are of medium and high levels, and the user is unsure how to implement the remedy provided. They are concerned about the security of the image and want to know how to make it secure.",
        "Question_gpt_summary":"user face secur vulner latest contain base imag releas microsoft workload vulner medium high level user unsur implement remedi provid concern secur imag want know secur"
    },
    {
        "Question_title":"Package usage in AzureML: ggplot2 and ggrepel",
        "Question_body":"<p>I have a code in Azure ML which uses the function <code>ggrepel<\/code>. That function requires the version 2.0.0 of the package <code>ggplot2<\/code>. When I try to use it I obtain the error:<\/p>\n\n<pre><code>Error 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\npackage 'ggplot2' 1.0.0 was found, but &gt;= 2.0.0 is required by 'ggrepel'\n<\/code><\/pre>\n\n<p>So, what I did was: <\/p>\n\n<ol>\n<li>updated the R package <code>ggplot2<\/code> of my local version (is there a command to use to check the version of a package?);<\/li>\n<li>taken the folder related to <code>ggplot2<\/code>, and put it in the zip file I pass to Azure. So the x.zip wil contain generic functions, then ggrepel.zip and ggplot2.zip.<\/li>\n<\/ol>\n\n<p>At the end I have written:<\/p>\n\n<pre><code>install.packages(\"src\/ggplot2.zip\",lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggrepel.zip\",lib = \".\", repos = NULL, verbose = TRUE)\nlibrary(ggrepel, lib.loc=\".\", verbose=TRUE)\nlibrary(ggplot2, lib.loc=\".\", verbose=TRUE)\n<\/code><\/pre>\n\n<p>It seems working for ggrepel, but not for ggplot, because I obtain the same issue shown at the beginning. It's like the system does not see the updated package, but the default ggplot2 of Azure ML.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1465908944767,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":142.0,
        "Poster_created_time":1436432728608,
        "Poster_location":"Colleferro, Italy",
        "Poster_reputation_count":809.0,
        "Poster_view_count":361.0,
        "Answer_body":"<p>At the end I have solved adding an additional package. The problem is in the fact that you have to check the log of the error and not only the error output (that does not insert all you need). At the end I have solved in this way:<\/p>\n\n<pre><code>install.packages(\"src\/scales_0.4.0.zip\" ,lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggplot2_2.1.0.zip\",lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggrepel.zip\"      ,lib = \".\", repos = NULL, verbose = TRUE)\n\nlibrary(scales,  lib.loc=\".\", verbose=TRUE)\nlibrary(ggplot2, lib.loc=\".\", verbose=TRUE)\nlibrary(ggrepel, lib.loc=\".\", verbose=TRUE)\n...\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1466607112096,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1436432728608,
        "Answerer_location":"Colleferro, Italy",
        "Answerer_reputation_count":809.0,
        "Answerer_view_count":361.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37812686",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"packag usag ggplot ggrepel code us function ggrepel function requir version packag ggplot try us obtain error error follow error occur evalu script start error messag packag ggplot requir ggrepel updat packag ggplot local version command us check version packag taken folder relat ggplot zip file pass azur zip wil contain gener function ggrepel zip ggplot zip end written instal packag src ggplot zip lib repo null verbos true instal packag src ggrepel zip lib repo null verbos true librari ggrepel lib loc verbos true librari ggplot lib loc verbos true work ggrepel ggplot obtain issu shown begin like updat packag default ggplot",
        "Question_preprocessed_content":"packag usag code us function function requir version packag try us obtain updat packag local version taken folder relat zip file azur wil contain gener function zip end work obtain shown like updat packag default",
        "Question_gpt_summary_original":"The user is facing an issue while using the function 'ggrepel' in Azure ML, which requires version 2.0.0 of the package 'ggplot2'. The user tried updating the package and including it in the zip file passed to Azure, but the system still uses the default version of ggplot2 and shows the same error.",
        "Question_gpt_summary":"user face issu function ggrepel requir version packag ggplot user tri updat packag includ zip file pass azur us default version ggplot show error"
    },
    {
        "Question_title":"XGBoost Reports Not Generated",
        "Question_body":"Hi!\n\nI have been trying to create a model using XGBoost, and was able to successfully run\/train the model. However, I have not been able to generate the training reports. I have included the rules parameter as follows: \"rules=[Rule.sagemaker(rule_configs.create_xgboost_report())]\".\n\nI am following this tutorial, but I am using objective: \"multi:softmax\" instead of the \"binary:logistic\" used in the example.\n\nWhen I run the model everything is fine but only the Profiler Report gets generated and I do not see the XGBoostReport under the rule-output folder. According to the tutorial it should be under the same file path.\n\nHere is my code for the model if it helps any:\n\n```\ns3_output_location='s3:\/\/{}\/{}\/{}'.format(bucket, prefix, 'xgboost_model')\ncontainer = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")\n\ntrain_input = TrainingInput(\n    \"s3:\/\/{}\/{}\/{}\".format(bucket, prefix, \"data\/train.csv\"), content_type=\"csv\"\n)\nvalidation_input = TrainingInput(\n    \"s3:\/\/{}\/{}\/{}\".format(bucket, prefix, \"data\/validation.csv\"), content_type=\"csv\"\n)\n\nrules=[\n    Rule.sagemaker(rule_configs.create_xgboost_report())\n]\n\nxgb = sagemaker.estimator.Estimator(\n    image_uri=container,\n    role=sagemaker.get_execution_role(),\n    instance_count=1,\n    instance_type=\"ml.c5.2xlarge\",\n    volume_size=5,\n    output_path=s3_output_location,\n    sagemaker_session=sagemaker.Session(),\n    rules=rules\n)\n\nxgb.set_hyperparameters(\n    max_depth=6,\n    objective='multi:softmax',\n    num_class=num_classes,\n    gamma=800,\n    num_round=250\n)\n```\n\nAny help is appreciated! Thanks!",
        "Question_answer_count":3,
        "Question_comment_count":3.0,
        "Question_created_time":1638475570231,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668531229208,
        "Question_score_count":0.0,
        "Question_view_count":305.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUx_M71_2nQJSDp-I1mgbjDg\/xgboost-reports-not-generated",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"xgboost report gener try creat model xgboost abl successfulli run train model abl gener train report includ rule paramet follow rule rule rule config creat xgboost report follow tutori object multi softmax instead binari logist exampl run model fine profil report get gener xgboostreport rule output folder accord tutori file path code model help output locat format bucket prefix xgboost model contain imag uri retriev xgboost boto session region latest train input traininginput format bucket prefix data train csv content type csv valid input traininginput format bucket prefix data valid csv content type csv rule rule rule config creat xgboost report xgb estim estim imag uri contain role execut role instanc count instanc type xlarg volum size output path output locat session session rule rule xgb set hyperparamet max depth object multi softmax num class num class gamma num round help appreci thank",
        "Question_preprocessed_content":"report gener try creat model abl model abl gener train report includ rule paramet tutori object multi softmax instead binari logist exampl run model fine profil report get gener folder tutori file path code model help help thank",
        "Question_gpt_summary_original":"The user has successfully trained a model using XGBoost but is unable to generate the training reports. The Profiler Report gets generated but the XGBoostReport does not appear under the rule-output folder. The user has included the rules parameter and is following a tutorial but is using \"multi:softmax\" instead of \"binary:logistic\" used in the example. The user has shared the code for the model and is seeking help to resolve the issue.",
        "Question_gpt_summary":"user successfulli train model xgboost unabl gener train report profil report get gener xgboostreport appear rule output folder user includ rule paramet follow tutori multi softmax instead binari logist exampl user share code model seek help resolv issu"
    },
    {
        "Question_title":"ModuleNotFoundError when starting a training job on Sagemaker",
        "Question_body":"I want to submit a training job on sagemaker. I tried it on notebook and it works. When I try the following I get `ModuleNotFoundError: No module named 'nltk'`\n\nMy code is\n\n    import sagemaker  \n    from sagemaker.pytorch import PyTorch\n\n    JOB_PREFIX   = 'pyt-ic'\n    FRAMEWORK_VERSION = '1.3.1'\n\n    estimator = PyTorch(entry_point='finetune-T5.py',\n                       source_dir='..\/src',\n                       train_instance_type='ml.p2.xlarge' ,\n                       train_instance_count=1,\n                       role=sagemaker.get_execution_role(),\n                       framework_version=FRAMEWORK_VERSION, \n                       debugger_hook_config=False,  \n                       py_version='py3',\n                       base_job_name=JOB_PREFIX)\n\n    estimator.fit()\n\n\n\n\n`finetune-T5.py` have many other libraries that are not installed. How can I install the missing library? Or is there a better way to run the training job?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1598912648000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668620734992,
        "Question_score_count":0.0,
        "Question_view_count":833.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Check out this [link][1] (Using third-party libraries section) on how to install third-party libraries for training jobs.  You need to create requirement.txt file in the same directory as your training script to install other dependencies at runtime.\n\n\n  [1]: https:\/\/sagemaker.readthedocs.io\/en\/stable\/frameworks\/pytorch\/using_pytorch.html#using-third-party-libraries",
        "Answer_comment_count":0.0,
        "Question_closed_time":1598914035000,
        "Answer_last_edit_time":1667925593038,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUJMd_4s52RpWXDXITXFsQdw\/modulenotfounderror-when-starting-a-training-job-on-sagemaker",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"modulenotfounderror start train job want submit train job tri notebook work try follow modulenotfounderror modul name nltk code import pytorch import pytorch job prefix pyt framework version estim pytorch entri point finetun sourc dir src train instanc type xlarg train instanc count role execut role framework version framework version debugg hook config fals version base job job prefix estim fit finetun librari instal instal miss librari better wai run train job",
        "Question_preprocessed_content":"start train job want submit train job tri work try code import pytorch import pytorch estim librari librari wai run train job",
        "Question_gpt_summary_original":"The user is encountering a `ModuleNotFoundError` when trying to submit a training job on Sagemaker. The error is caused by a missing library (`nltk`) in the `finetune-T5.py` file. The user is seeking advice on how to install the missing library or if there is a better way to run the training job.",
        "Question_gpt_summary":"user encount modulenotfounderror try submit train job error caus miss librari nltk finetun file user seek advic instal miss librari better wai run train job"
    },
    {
        "Question_title":"How to strip HTML from a text column in Azure ML Execute Python Script step",
        "Question_body":"<p>If I have a column of data of type string in an incoming Azure ML dataset that contains HTML tags screwing up my results, how can I remove those tags?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1484610622880,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":325.0,
        "Poster_created_time":1265234764768,
        "Poster_location":"Denver, CO",
        "Poster_reputation_count":30577.0,
        "Poster_view_count":6460.0,
        "Answer_body":"<p>Like this:<\/p>\n\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n  dataframe1[1] = dataframe1['text'].str.replace('&lt;[^&lt;]+?&gt;', ' ', case=False)\n  return dataframe1,\n<\/code><\/pre>\n\n<p>Remember to precede the <code>Execute Python Script<\/code> step with <code>Clean Missing Data<\/code> step and change the action to remove the entire row (if appropriate). This is important because the <code>Execute Python Script<\/code> step cannot return an empty <code>dataframe<\/code>. Only you know your data, in this case.<\/p>\n\n<p>Let me also point out that the <code>Preprocessing Text<\/code> step allows you to apply a Regular Expression. That is another alternative that might be right for your situation.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1484610622880,
        "Answer_last_edit_time":1484679092912,
        "Answer_score_count":1.0,
        "Answerer_created_time":1265234764768,
        "Answerer_location":"Denver, CO",
        "Answerer_reputation_count":30577.0,
        "Answerer_view_count":6460.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41686871",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"strip html text column execut python script step column data type string incom dataset contain html tag screw result remov tag",
        "Question_preprocessed_content":"strip html text column execut python script step column data type string incom dataset contain html tag screw result remov tag",
        "Question_gpt_summary_original":"The user is facing a challenge in removing HTML tags from a string column in an incoming Azure ML dataset to avoid interference with the results.",
        "Question_gpt_summary":"user face challeng remov html tag string column incom dataset avoid interfer result"
    },
    {
        "Question_title":"Docker container fails to run due to invalid --GPU switch",
        "Question_body":"<p>I have been testing Azure ML experiments running locally on my machine with docker. So far I have run into the same issue using several curated environments as well as using a conda dependencies file.  <\/p>\n<ul>\n<li> The run job is submitted successfully  <\/li>\n<li> Docker container builds successfully   <\/li>\n<li> The docker run command fails due to the --gpu all switch  <\/li>\n<\/ul>\n<p>This switch gets added to every docker container I try to launch locally (doesn't matter the container type).   <\/p>\n<p>I have tested this a few different ways   <\/p>\n<ul>\n<li> Using VScode and VScode insiders  <\/li>\n<li> Running the experiment from code  <\/li>\n<li> Running Experiment the Azure ML Extension in VScode  <\/li>\n<\/ul>\n<p>All attempts end with the docker container failing to run.   <\/p>\n<p>Any thought on how to fix this would be appreciated.  <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":7.0,
        "Question_created_time":1610298719520,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/225027\/docker-container-fails-to-run-due-to-invalid-gpu-s",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"docker contain fail run invalid gpu switch test experi run local machin docker far run issu curat environ conda depend file run job submit successfulli docker contain build successfulli docker run command fail gpu switch switch get ad docker contain try launch local matter contain type test differ wai vscode vscode insid run experi code run experi extens vscode attempt end docker contain fail run thought fix appreci",
        "Question_preprocessed_content":"docker contain fail run invalid switch test experi machin docker far run curat environ conda depend file run job docker contain build docker run fail switch switch get docker contain try launch test wai vscode vscode insid experi code experi extens vscode end docker contain fail run thought fix",
        "Question_gpt_summary_original":"The user is facing an issue where the Docker container fails to run due to an invalid --GPU switch. The run job is submitted successfully and the Docker container builds successfully, but the docker run command fails due to the --gpu all switch. The user has tried different methods such as using VScode and VScode insiders, running the experiment from code, and running Experiment the Azure ML Extension in VScode, but all attempts end with the docker container failing to run. The user is seeking help to fix this issue.",
        "Question_gpt_summary":"user face issu docker contain fail run invalid gpu switch run job submit successfulli docker contain build successfulli docker run command fail gpu switch user tri differ method vscode vscode insid run experi code run experi extens vscode attempt end docker contain fail run user seek help fix issu"
    },
    {
        "Question_title":"How to create a sagemaker serverless endpoint via cloudformation?",
        "Question_body":"based on the documentation, i am creating a model and trying to create an sagemaker endpoint configuration for a serverless endpoint (sample below) , I added a ServerlessConfig attribute in my endpoint configuration resource below,  but i'm get an error = \"Property validation failure: [Encountered unsupported properties in {\/} [ServerlessConfig]]. any ideas? \n```\nSageMakerModel:\n    Type: AWS::SageMaker::Model\n    Properties: \n      Containers: \n        -\n          Image: !Ref ImageURI\n          ModelDataUrl: !Ref ModelData\n          ExecutionRoleArn: !Ref RoleArn\n\nSageMakerEndpointConfig:\n    Type: \"AWS::SageMaker::EndpointConfig\"\n    Properties:\n      ServerlessConfig: \n        -\n          MaxConcurrency: 5\n```",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1664305906330,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1668438999972,
        "Question_score_count":1.0,
        "Question_view_count":146.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU1p5lKUqcTl6s6e-Oh7mKYg\/how-to-create-a-sagemaker-serverless-endpoint-via-cloudformation",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat serverless endpoint cloudform base document creat model try creat endpoint configur serverless endpoint sampl ad serverlessconfig attribut endpoint configur resourc error properti valid failur encount unsupport properti serverlessconfig idea model type aw model properti contain imag ref imageuri modeldataurl ref modeldata executionrolearn ref rolearn endpointconfig type aw endpointconfig properti serverlessconfig maxconcurr",
        "Question_preprocessed_content":"creat endpoint cloudform base document creat model try creat endpoint configur endpoint endpoint configur resourc properti valid failur idea",
        "Question_gpt_summary_original":"The user is trying to create a serverless endpoint configuration for a SageMaker model using CloudFormation, but is encountering an error related to the ServerlessConfig attribute. The error message indicates that the property is not supported.",
        "Question_gpt_summary":"user try creat serverless endpoint configur model cloudform encount error relat serverlessconfig attribut error messag indic properti support"
    },
    {
        "Question_title":"How to optimize for multiple metrics in Optuna",
        "Question_body":"<p>How do I optimize for multiple metrics simultaneously inside the <code>objective<\/code> function of Optuna. For example, I am training an LGBM classifier and want to find the best hyperparameter set for all common classification metrics like F1, precision, recall, accuracy, AUC, etc.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def objective(trial):\n    # Train\n    gbm = lgb.train(param, dtrain)\n\n    preds = gbm.predict(X_test)\n    pred_labels = np.rint(preds)\n    # Calculate metrics\n    accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels)\n    recall = metrics.recall_score(pred_labels, y_test)\n    precision = metrics.precision_score(pred_labels, y_test)\n    f1 = metrics.f1_score(pred_labels, y_test, pos_label=1)\n\n    ...\n<\/code><\/pre>\n<p>How do I do it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1630917852487,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1630917952870,
        "Question_score_count":2.0,
        "Question_view_count":1887.0,
        "Poster_created_time":1565697423932,
        "Poster_location":"Uzbekistan",
        "Poster_reputation_count":602.0,
        "Poster_view_count":117.0,
        "Answer_body":"<p>After defining the grid and fitting the model with these params and generate predictions, calculate all metrics you want to optimize for:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def objective(trial):\n    param_grid = {&quot;n_estimators&quot;: trial.suggest_int(&quot;n_estimators&quot;, 2000, 10000, step=200)}\n    clf = lgbm.LGBMClassifier(objective='binary', **param_grid)\n    clf.fit(X_train, y_train)\n    preds = clf.predict(X_valid)\n    probs = clf.predict_proba(X_valid)\n \n    # Metrics\n    f1 = sklearn.metrics.f1_score(y_valid, press)\n    accuracy = ...\n    precision = ...\n    recall = ...\n    logloss = ...\n<\/code><\/pre>\n<p>and return them in the order you want:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def objective(trial):\n    ...\n\n    return f1, logloss, accuracy, precision, recall\n<\/code><\/pre>\n<p>Then, in the study object, specify whether you want to minimize or maximize each metric to <code>directions<\/code> like so:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>study = optuna.create_study(directions=['maximize', 'minimize', 'maximize', 'maximize', 'maximize'])\n\nstudy.optimize(objective, n_trials=100)\n<\/code><\/pre>\n<p>For more details, see <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/tutorial\/20_recipes\/002_multi_objective.html#sphx-glr-tutorial-20-recipes-002-multi-objective-py\" rel=\"nofollow noreferrer\">Multi-objective Optimization with Optuna<\/a> in the documentation.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1630917852487,
        "Answer_last_edit_time":1659853446112,
        "Answer_score_count":6.0,
        "Answerer_created_time":1565697423932,
        "Answerer_location":"Uzbekistan",
        "Answerer_reputation_count":602.0,
        "Answerer_view_count":117.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69071684",
        "Tool":"Optuna",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"optim multipl metric optim multipl metric simultan insid object function exampl train lgbm classifi want best hyperparamet set common classif metric like precis recal accuraci auc def object trial train gbm lgb train param dtrain pred gbm predict test pred label rint pred calcul metric accuraci sklearn metric accuraci score test pred label recal metric recal score pred label test precis metric precis score pred label test metric score pred label test po label",
        "Question_preprocessed_content":"optim multipl metric optim multipl metric simultan insid function exampl train lgbm want best hyperparamet set metric like precis auc",
        "Question_gpt_summary_original":"The user is seeking guidance on how to optimize for multiple metrics simultaneously inside the objective function of Optuna, specifically for a scenario where they are training an LGBM classifier and want to find the best hyperparameter set for all common classification metrics like F1, precision, recall, accuracy, AUC, etc.",
        "Question_gpt_summary":"user seek guidanc optim multipl metric simultan insid object function specif scenario train lgbm classifi want best hyperparamet set common classif metric like precis recal accuraci auc"
    },
    {
        "Question_title":"Azure Machine Learning Studio - Predict multiple values",
        "Question_body":"<p>I am trying to build a model using the designer in Azure Machine Learning Studio that will need to predict multiple values simultaneously.<\/p>\n<p>The scenario I am working with is there are a set of codes assigned to an order. When the order is audited, the codes may be adjusted (either added, removed, changed or a combination of all). What this results in is a before and after set of codes assigned to an order.<\/p>\n<p>What I want to do is feed the before and after codes plus other characteristics of the order into a model so going forward it is possible to provide suggestions to the auditor on potential changes to 'before' codes to create the 'after' codes.<\/p>\n<p>I want to understand if this can be done using the designer or if it would need to be done using code. If it can be done with the designer, how would it be done?<\/p>\n<p>With the experimentation I have done so far, I can only find ways for it to predict a single value, not a collection or values.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1643870170150,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1643895912543,
        "Question_score_count":0.0,
        "Question_view_count":48.0,
        "Poster_created_time":1559879904440,
        "Poster_location":"Melbourne VIC, Australia",
        "Poster_reputation_count":1.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70966856",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio predict multipl valu try build model design studio need predict multipl valu simultan scenario work set code assign order order audit code adjust ad remov chang combin result set code assign order want feed code plu characterist order model go forward possibl provid suggest auditor potenti chang code creat code want understand design need code design experiment far wai predict singl valu collect valu",
        "Question_preprocessed_content":"studio predict multipl valu try build model design studio predict multipl valu simultan scenario work set code order order audit code adjust result set code order want code plu characterist order model go forward provid auditor potenti chang code creat code want understand design code design experiment far wai predict singl valu valu",
        "Question_gpt_summary_original":"The user is trying to build a model in Azure Machine Learning Studio that can predict multiple values simultaneously. The model needs to suggest potential changes to 'before' codes to create the 'after' codes based on a set of codes assigned to an order. The user is unsure if this can be done using the designer or if it would need to be done using code. The user has only been able to find ways for the model to predict a single value, not a collection of values.",
        "Question_gpt_summary":"user try build model studio predict multipl valu simultan model need suggest potenti chang code creat code base set code assign order user unsur design need code user abl wai model predict singl valu collect valu"
    },
    {
        "Question_title":"Speech-to-text fails to work with MP3 input in Machine Learning studio - error 'SPXERR_GSTREAMER_NOT_FOUND_ERROR'",
        "Question_body":"<p>Hi, <\/p>\n<p>I try to use the speech-to-text API from within Azure Machine Learning Studio on an MP3 file.<\/p>\n<p>I installed GStreamer using the instructions for Ubuntu\/Debian on <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-use-codec-compressed-audio-input-streams?tabs=linux%2Cdebian%2Cjava-android%2Cterminal&amp;pivots=programming-language-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-use-codec-compressed-audio-input-streams?tabs=linux%2Cdebian%2Cjava-android%2Cterminal&amp;pivots=programming-language-python<\/a><\/p>\n<p>However, when I then try to run my code, he gives an error. I put my error log and my code block below.<\/p>\n<p>On stackoverflow I found a solution for Windows that had something to do with the Gstreamer version installed. Are the Ubuntu instructions on your site also referring to a wrong version or is this error related to something else I'm missing ?<\/p>\n<p>Could it eg. have something to do that I should also build an authentication token still too as explained on: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-configure-azure-ad-auth?tabs=portal&amp;pivots=programming-language-python\">https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-configure-azure-ad-auth?tabs=portal&amp;pivots=programming-language-python<\/a>:<\/p>\n<blockquote>\n<p>resourceId = &quot;Your Resource ID&quot; \nregion = &quot;Your Region&quot; <\/p>\n<h1 id=\"you-need-to-include-the-aad-prefix-and-the--hash-separator-between-resource-id-and-aad-access-token-authorizationtoken--aad--resourceid----aadtokentoken-\">You need to include the &quot;aad#&quot; prefix and the &quot;#&quot; (hash) separator between resource ID and AAD access token. authorizationToken = &quot;aad#&quot; + resourceId + &quot;#&quot; + aadToken.token <\/h1>\n<p>speechConfig = speechsdk.SpeechConfig(auth_token=authorizationToken, region=region)<\/p>\n<\/blockquote>\n<p>before running:<\/p>\n<blockquote>\n<p>speech_config = speechsdk.SpeechConfig(subscription=key, region=regio)<\/p>\n<\/blockquote>\n<p><strong>Error log:<\/strong><\/p>\n<p>Input In [4], in pull_audio_input_stream_compressed_mp3(mp3_file_path, taal, key, regio)<\/p>\n<pre><code>  1 def pull_audio_input_stream_compressed_mp3(mp3_file_path: str, taal, key, regio):\n\n  2     # Create a compressed format\n\n  3     compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n<\/code><\/pre>\n<p>----&gt; 4     result=compressed_stream_helper(compressed_format, mp3_file_path, taal, key, regio)<\/p>\n<pre><code>  6     return result\n<\/code><\/pre>\n<p>Input In [3], in compressed_stream_helper(compressed_format, mp3_file_path, taal, key, regio)<\/p>\n<pre><code>  6 speech_config.speech_recognition_language=taal\n\n  7 audio_config = speechsdk.audio.AudioConfig(stream=stream)\n<\/code><\/pre>\n<p>----&gt; 9 speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)<\/p>\n<pre><code> 11 done = False\n\n 13 def stop_cb(evt):\n<\/code><\/pre>\n<p>File \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/speech.py:1004, in SpeechRecognizer.<strong>init<\/strong>(self, speech_config, audio_config, language, source_language_config, auto_detect_source_language_config)<\/p>\n<p>   1002 audio_config_handle = audio_config._handle if audio_config is not None else None<\/p>\n<p>   1003 if language is None and source_language_config is None and auto_detect_source_language_config is None:<\/p>\n<p>-&gt; 1004     _call_hr_fn(<\/p>\n<p>   1005         fn=_sdk_lib.recognizer_create_speech_recognizer_from_config,<\/p>\n<p>   1006         *[ctypes.byref(handle), speech_config._handle, audio_config_handle])<\/p>\n<p>   1007 elif language is not None:<\/p>\n<p>   1008     source_language_config = languageconfig.SourceLanguageConfig(language)<\/p>\n<p>File \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/interop.py:62, in _call_hr_fn(fn, *args)<\/p>\n<pre><code> 60 fn.restype = _spx_hr\n\n 61 hr = fn(*args) if len(args) &gt; 0 else fn()\n<\/code><\/pre>\n<p>---&gt; 62 _raise_if_failed(hr)<\/p>\n<p>File \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/interop.py:55, in _raise_if_failed(hr)<\/p>\n<pre><code> 53 def _raise_if_failed(hr: _spx_hr):\n\n 54     if hr != 0:\n<\/code><\/pre>\n<p>---&gt; 55         __try_get_error(_spx_handle(hr))<\/p>\n<pre><code> 56         raise RuntimeError(hr)\n<\/code><\/pre>\n<p>File \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/interop.py:50, in __try_get_error(error_handle)<\/p>\n<pre><code> 45 message = &quot;Exception with error code: %s%s&quot; % (\n\n 46     callstack if callstack is not None else &quot;&quot;,\n\n 47     what if what is not None else code\n\n 48 )\n\n 49 _sdk_lib.error_release(error_handle)\n<\/code><\/pre>\n<p>---&gt; 50 raise RuntimeError(message)<\/p>\n<p>RuntimeError: Exception with error code: <\/p>\n<p>[CALL STACK BEGIN]<\/p>\n<p>\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/azure\/cognitiveservices\/speech\/libMicrosoft.CognitiveServices.Speech.core.so(+0x1638a5) [.....]<\/p>\n<p>...<\/p>\n<p>[CALL STACK END]<\/p>\n<p>Exception with an error code: 0x29 (SPXERR_GSTREAMER_NOT_FOUND_ERROR)<\/p>\n<p><strong>Code:<\/strong><\/p>\n<pre><code class=\"lang-python\">class BinaryFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n   &lt;defined as on your page: \n\ndef compressed_stream_helper(compressed_format, mp3_file_path, taal, key, regio):\n    \n    callback = BinaryFileReaderCallback(mp3_file_path)\n    stream = speechsdk.audio.PullAudioInputStream(stream_format=compressed_format, pull_stream_callback=callback)\n    \n    #speech authentication needed too still?\n    #https:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-configure-azure-ad-auth?tabs=portal&amp;pivots=programming-language-python\n\n    speech_config = speechsdk.SpeechConfig(subscription=key, region=regio)\n    speech_config.speech_recognition_language=taal\n    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n\n    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n\n    done = False\n\n    def stop_cb(evt):\n        &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot;\n        print('CLOSING on {}'.format(evt))\n        nonlocal done\n        done = True\n\n    # Connect callbacks to the events fired by the speech recognizer\n    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n    # stop continuous recognition on either session stopped or canceled events\n    speech_recognizer.session_stopped.connect(stop_cb)\n    speech_recognizer.canceled.connect(stop_cb)\n\n    # Start continuous speech recognition\n    speech_recognizer.start_continuous_recognition()\n    while not done:\n        time.sleep(.5)\n\n    speech_recognizer.stop_continuous_recognition()\n\n\ndef pull_audio_input_stream_compressed_mp3(mp3_file_path: str, taal, key, regio):\n    # Create a compressed format\n    compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n    result=compressed_stream_helper(compressed_format, mp3_file_path, taal, key, regio)\n    \n    return result\n\ntekst=pull_audio_input_stream_compressed_mp3(&quot;file1.mp3&quot;, &quot;fr-BE&quot;, &quot;&lt;my speech services key&gt;&quot;, &quot;&lt;my speech services region&gt;&quot;)\n\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1676567428973,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1181474\/speech-to-text-fails-to-work-with-mp3-input-in-mac",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"speech text fail work input machin learn studio error spxerr gstreamer error try us speech text api studio file instal gstreamer instruct ubuntu debian http learn microsoft com azur cognit servic speech servic us codec compress audio input stream tab linux cdebian cjava android ctermin pivot program languag python try run code give error error log code block stackoverflow solut window gstreamer version instal ubuntu instruct site refer wrong version error relat miss build authent token explain http learn microsoft com azur cognit servic speech servic configur azur auth tab portal pivot program languag python resourceid resourc region region need includ aad prefix hash separ resourc aad access token authorizationtoken aad resourceid aadtoken token speechconfig speechsdk speechconfig auth token authorizationtoken region region run speech config speechsdk speechconfig subscript kei region regio error log input pull audio input stream compress file path taal kei regio def pull audio input stream compress file path str taal kei regio creat compress format compress format speechsdk audio audiostreamformat compress stream format speechsdk audiostreamcontainerformat result compress stream helper compress format file path taal kei regio return result input compress stream helper compress format file path taal kei regio speech config speech recognit languag taal audio config speechsdk audio audioconfig stream stream speech recogn speechsdk speechrecogn speech config speech config audio config audio config fals def stop evt file anaconda env sdkv lib python site packag azur cognitiveservic speech speech speechrecogn init self speech config audio config languag sourc languag config auto detect sourc languag config audio config handl audio config handl audio config languag sourc languag config auto detect sourc languag config sdk lib recogn creat speech recogn config ctype byref handl speech config handl audio config handl elif languag sourc languag config languageconfig sourcelanguageconfig languag file anaconda env sdkv lib python site packag azur cognitiveservic speech interop arg restyp spx arg len arg rais fail file anaconda env sdkv lib python site packag azur cognitiveservic speech interop rais fail def rais fail spx try error spx handl rais runtimeerror file anaconda env sdkv lib python site packag azur cognitiveservic speech interop try error error handl messag except error code callstack callstack code sdk lib error releas error handl rais runtimeerror messag runtimeerror except error code stack begin anaconda env sdkv lib python site packag azur cognitiveservic speech libmicrosoft cognitiveservic speech core stack end except error code spxerr gstreamer error code class binaryfilereadercallback speechsdk audio pullaudioinputstreamcallback",
        "Question_preprocessed_content":"fail work input machin learn studio try us api studio file gstreamer instruct try run code give log code block stackoverflow solut window gstreamer version ubuntu instruct site wrong version relat build authent token explain resourceid resourc region region includ prefix separ resourc token authorizationtoken resourceid token region region log input kei regio kei regio input kei regio file init languag elif languag file arg file file rais except code stack begin stack end except code code",
        "Question_gpt_summary_original":"The user is encountering an error while trying to use the speech-to-text API from within Azure Machine Learning Studio on an MP3 file. The error is related to the GStreamer version installed and the error log shows 'SPXERR_GSTREAMER_NOT_FOUND_ERROR'. The user has installed GStreamer using the instructions for Ubuntu\/Debian and is unsure if the instructions are referring to the wrong version or if the error is related to something else missing. The user is also unsure if building an authentication token is necessary.",
        "Question_gpt_summary":"user encount error try us speech text api studio file error relat gstreamer version instal error log show spxerr gstreamer error user instal gstreamer instruct ubuntu debian unsur instruct refer wrong version error relat miss user unsur build authent token necessari"
    },
    {
        "Question_title":"Add model description when registering model after hyperdrive successful run",
        "Question_body":"<p>I have successfully trained a model on Azure Machine Learning Service using Hyperdrive that has now yielded a hyperdrive run instance<\/p>\n\n<pre><code>hyperdrive_run = exp.submit(config=hypertune_config)\nhyperdrive_run\nbest_run = hyperdrive_run.get_best_run_by_primary_metric()\n<\/code><\/pre>\n\n<p>As a next step, I would like to register a model while adding a description to the model.:<\/p>\n\n<pre><code>pumps_rf = best_run.register_model(model_name='pumps_rf', model_path='outputs\/rf.pkl')\n<\/code><\/pre>\n\n<p>There is a <code>description<\/code> column in the Models section of my AML Workspace on Azure portal but the <code>register_model<\/code> method does not seem to have a <code>description<\/code> flag. So how do I go about adding a description to the model so I see it in Azure Portal?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1550539380057,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":453.0,
        "Poster_created_time":1408574571227,
        "Poster_location":"Toronto, Canada",
        "Poster_reputation_count":2754.0,
        "Poster_view_count":124.0,
        "Answer_body":"<p>Good question :).<\/p>\n\n<p>Looking at the current version of the API, it doesn't look like you can add the description using <code>Run.register_model<\/code>, as confirmed <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run?view=azure-ml-py#register-model-model-name--model-path-none--tags-none--properties-none----kwargs-\" rel=\"nofollow noreferrer\">by the docs<\/a>. <\/p>\n\n<p>You can go around this however by registering the model using the <code>Model.register<\/code> method which, fortunately, includes an argument for <code>description<\/code> as detailed <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none-\" rel=\"nofollow noreferrer\">here<\/a>. In your case, you also need to <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#download-file-name--output-file-path-none-\" rel=\"nofollow noreferrer\">download the files<\/a> first.<\/p>\n\n<p>In short, use something like:<\/p>\n\n<pre class=\"lang-python prettyprint-override\"><code>best_run.download_file('outputs\/rf.pkl', output_file_path='.\/rf.pkl')\n\nModel.register(workspace=ws, model_path='.\/rf.pkl', model_name=\"pumps_rf\", description=\"There are many models like it, but this one is mine.\")\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1550668517447,
        "Answer_last_edit_time":1550686459150,
        "Answer_score_count":1.0,
        "Answerer_created_time":1250158552416,
        "Answerer_location":"Romania",
        "Answerer_reputation_count":7916.0,
        "Answerer_view_count":801.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54757598",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"add model descript regist model hyperdr success run successfulli train model servic hyperdr yield hyperdr run instanc hyperdr run exp submit config hypertun config hyperdr run best run hyperdr run best run primari metric step like regist model ad descript model pump best run regist model model pump model path output pkl descript column model section aml workspac azur portal regist model method descript flag ad descript model azur portal",
        "Question_preprocessed_content":"model descript regist model hyperdr run train model servic hyperdr yield hyperdr run instanc step like regist model descript column model section aml workspac azur portal method flag descript model azur portal",
        "Question_gpt_summary_original":"The user has successfully trained a model on Azure Machine Learning Service using Hyperdrive and wants to register the model while adding a description to it. However, the register_model method does not seem to have a description flag, and the user is unsure how to add a description to the model so that it appears in the Azure Portal.",
        "Question_gpt_summary":"user successfulli train model servic hyperdr want regist model ad descript regist model method descript flag user unsur add descript model appear azur portal"
    },
    {
        "Question_title":"Authentication errors running vaictl in container",
        "Question_body":"I'm trying to run\u00a0vaictl on OSX inside a docker container based on these Vertex AI Vision instructions, but hitting the following auth error:\n\n\u00a0\n\nroot@dc89ced3ac47:\/# vaictl -p backyard-camera -l us-central1 -c application-cluster-0 -v list streams\nE1107 23:01:37.006251735     858 google_default_credentials.cc:434] Could not create google default credentials: {\"created\":\"@1667862097.001779783\",\"description\":\"Failed to load file\",\"file\":\"external\/com_github_grpc_grpc\/src\/core\/lib\/iomgr\/load_file.cc\",\"file_line\":72,\"filename\":\"\/root\/.config\/gcloud\/application_default_credentials.json\",\"referenced_errors\":[{\"created\":\"@1667862097.001778260\",\"description\":\"No such file or directory\",\"errno\":2,\"file\":\"external\/com_github_grpc_grpc\/src\/core\/lib\/iomgr\/load_file.cc\",\"file_line\":45,\"os_error\":\"No such file or directory\",\"syscall\":\"fopen\"}]}\nE20221107 23:01:37.007882   858 resource_manager_app.cc:312] INVALID_ARGUMENT: Invalid credentials.; while listing streams; while listing streams\n\n\u00a0\n\nI've run gcloud auth login\u00a0in the container and saved the authorization code.\n\nAre there any extra steps needed to make this work?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1667833740000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":88.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Authentication-errors-running-vaictl-in-container\/m-p\/486888#M744",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"authent error run vaictl contain try runvaictl osx insid docker contain base vision instruct hit follow auth error root dccedac vaictl backyard camera central applic cluster list stream googl default credenti creat googl default credenti creat descript fail load file file extern com github grpc grpc src core lib iomgr load file file line filenam root config gcloud applic default credenti json referenc error creat descript file directori errno file extern com github grpc grpc src core lib iomgr load file file line error file directori syscal fopen resourc manag app invalid argument invalid credenti list stream list stream run gcloud auth loginin contain save author code extra step need work",
        "Question_preprocessed_content":"authent vaictl contain try runvaictl osx insid docker contain base vision instruct auth vaictl list stream creat default credenti invalid list stream list stream run gcloud auth loginin contain save author code extra step work",
        "Question_gpt_summary_original":"The user is encountering an authentication error while running vaictl in a docker container on OSX. The error message suggests that the default Google credentials could not be created, and the user has already tried running gcloud auth login in the container. The user is seeking advice on any additional steps required to resolve the issue.",
        "Question_gpt_summary":"user encount authent error run vaictl docker contain osx error messag suggest default googl credenti creat user tri run gcloud auth login contain user seek advic addit step requir resolv issu"
    },
    {
        "Question_title":"Dataset selection for hyperparameter optimization and training",
        "Question_body":"<p>Hi,<br>\ni want to make a multiclass classifier using a bert model. For this i would like to compare the performance of (at least) two domain specific bert models. But  before i compare the model performance i would like to find the best hyperparameters using wandb sweeps und the simpletransformers api (the simpletransformers api, has an easy integration with wandb).<\/p>\n<p>Currently i\u2019m a bit confused how to select a good dataset for<\/p>\n<ol>\n<li>the hyperparameter optimization<\/li>\n<li>the training with the best hyperparams.<\/li>\n<\/ol>\n<p>So for the hyperparams, should i create n cross-validation sets and then run a training cycle with the current selected hyperparams for every m in n dataset?<br>\nE.g. i created 2 train\/test sets and i only want to find the best n of episodes out of [1,2]:<br>\nFor both train\/test sets, the training is done for 1 episode and in the nex cycle for 2 episodes?<\/p>\n<p>And if i found the best hyperparameters, should i train the final model afterwards using my full dataset?<\/p>\n<p>Hope my questions are kind of clear<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1669276235658,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":103.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/dataset-selection-for-hyperparameter-optimization-and-training\/3455",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"dataset select hyperparamet optim train want multiclass classifi bert model like compar perform domain specif bert model compar model perform like best hyperparamet sweep und simpletransform api simpletransform api easi integr current bit confus select good dataset hyperparamet optim train best hyperparam hyperparam creat cross valid set run train cycl current select hyperparam dataset creat train test set want best episod train test set train episod nex cycl episod best hyperparamet train final model dataset hope question kind clear",
        "Question_preprocessed_content":"dataset select hyperparamet optim train want bert model like compar perform domain specif bert model compar model perform like best hyperparamet und simpletransform api bit confus select dataset hyperparamet optim train best hyperparam hyperparam creat valid set run train cycl select hyperparam dataset creat set want best episod set train episod nex cycl episod best hyperparamet train final model dataset hope question kind clear",
        "Question_gpt_summary_original":"The user wants to create a multiclass classifier using a BERT model and compare the performance of at least two domain-specific BERT models. They are confused about how to select a good dataset for hyperparameter optimization and training with the best hyperparameters. They are considering creating n cross-validation sets and running a training cycle with the current selected hyperparameters for every m in n datasets. They are also unsure if they should train the final model using the full dataset after finding the best hyperparameters.",
        "Question_gpt_summary":"user want creat multiclass classifi bert model compar perform domain specif bert model confus select good dataset hyperparamet optim train best hyperparamet consid creat cross valid set run train cycl current select hyperparamet dataset unsur train final model dataset find best hyperparamet"
    },
    {
        "Question_title":"Machine Learning Workspace Load Balancer",
        "Question_body":"<p>Hi there,    <\/p>\n<p>Is it possible to delete the Load Balancer that's installed as part of the Machine Learning workspace? Or to adjust the configuration so that it doesn't cost so much?     <\/p>\n<p>I'm just using this ML workspace to study\/practice concepts for the DP-100 exam so I don't think I need a load balancer, but at no point did I see an option to turn it off, it doesn't even appear as a resource item.    <\/p>\n<p>What role\/purpose is the load balancer playing as part of the Workspace deployment?    <\/p>\n<p>Thanks kindly for any insight.    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/95742-pluralsight-rg-microsoft-azure.png?platform=QnA\" alt=\"95742-pluralsight-rg-microsoft-azure.png\" \/>    <\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1.0,
        "Question_created_time":1620773916823,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/391564\/machine-learning-workspace-load-balancer",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"machin learn workspac load balanc possibl delet load balanc instal machin learn workspac adjust configur cost workspac studi practic concept exam think need load balanc point option turn appear resourc item role purpos load balanc plai workspac deploy thank kindli insight",
        "Question_preprocessed_content":"machin learn workspac load balanc delet load balanc machin learn workspac adjust configur cost workspac concept exam think load balanc point option turn resourc item load balanc plai workspac deploy thank kindli insight",
        "Question_gpt_summary_original":"The user is seeking information on how to delete or adjust the configuration of the Load Balancer that comes with the Machine Learning workspace, as it is causing high costs. They are using the workspace for studying and do not believe they need the load balancer, but are unsure of its purpose in the deployment.",
        "Question_gpt_summary":"user seek inform delet adjust configur load balanc come machin learn workspac caus high cost workspac studi believ need load balanc unsur purpos deploy"
    },
    {
        "Question_title":"How send to image payload to the Deep learning model using lambda and send get the Image respone",
        "Question_body":"<p>I am working on Deploying background removal using AWS lambda, I didn't understand how to create a proper image payload to model and get the response back as an image.\nplease help me with this, I am struggling with this for one week.\nhere I tried:<\/p>\n<pre><code> model_dir='model\/u2net.pth'\n    model=load_models(model_dir)\n    \n    def lambda_handler(event, context):\n        \n        url = event['url']\n        img = io.imread(url)\n        # classify image\n        img = u2net_api_call(img, model)\n        output_image = img.numpy()\n        output_image = np.uint8(output_image.transpose(1, 2, 0) * 255)\n        output_image = Image.fromarray(output_image)\n    \n      # convert the PIL image to base64\n        result = {\n          &quot;output&quot;: img_to_base64_str(output_image)\n      }\n    \n      # send the result back to the client inside the body field\n        return {\n          &quot;statusCode&quot;: 200,\n          &quot;body&quot;: json.dumps(result),\n          &quot;headers&quot;: {\n              'Content-Type': 'application\/json',\n              'Access-Control-Allow-Origin': '*'\n          }\n      }\n<\/code><\/pre>\n<p>I have deployed these with lambda and docker images, I have created the docker image and push ECR and I am adding with lambda.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1646168848977,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":32.0,
        "Poster_created_time":1583415050007,
        "Poster_location":"Bangalore, Karnataka, India",
        "Poster_reputation_count":1.0,
        "Poster_view_count":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71314659",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"send imag payload deep learn model lambda send imag respon work deploi background remov aw lambda understand creat proper imag payload model respons imag help struggl week tri model dir model unet pth model load model model dir def lambda handler event context url event url img imread url classifi imag img unet api img model output imag img numpi output imag uint output imag transpos output imag imag fromarrai output imag convert pil imag base result output img base str output imag send result client insid bodi field return statuscod bodi json dump result header content type applic json access control allow origin deploi lambda docker imag creat docker imag push ecr ad lambda",
        "Question_preprocessed_content":"send imag payload learn model lambda send imag respon work deploi background remov aw lambda understand creat proper imag payload model respons imag help tri deploi lambda docker imag creat docker imag push ecr lambda",
        "Question_gpt_summary_original":"The user is struggling to create a proper image payload to send to a deep learning model using AWS Lambda and receive the response back as an image. They have tried deploying the model with Lambda and Docker images, but are still facing difficulties.",
        "Question_gpt_summary":"user struggl creat proper imag payload send deep learn model aw lambda receiv respons imag tri deploi model lambda docker imag face difficulti"
    },
    {
        "Question_title":"Failing to read data from s3 to a spark dataframe in Sagemaker",
        "Question_body":"<p>I'm trying to read a csv file on an s3 bucket (for which the sagemaker notebook has full access to) into a spark dataframe however I am hitting the following issue where <code>sagemaker-spark_2.11-spark_2.2.0-1.1.1.jar<\/code> can't be found. Any tips on how to resolve this is appreciate!<\/p>\n\n<pre><code>bucket = \"mybucket\"\nprefix = \"folder\/file.csv\"\ndf = spark.read.csv(\"s3:\/\/{}\/{}\/\".format(bucket,prefix))\n\nPy4JJavaError: An error occurred while calling o388.csv.\n: java.util.ServiceConfigurationError: org.apache.spark.sql.sources.DataSourceRegister: Error reading configuration file\nat java.util.ServiceLoader.fail(ServiceLoader.java:232)\nat java.util.ServiceLoader.parse(ServiceLoader.java:309)\nat java.util.ServiceLoader.access$200(ServiceLoader.java:185)\nat java.util.ServiceLoader$LazyIterator.hasNextService(ServiceLoader.java:357)\nat java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)\nat java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)\nat scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42)\nat scala.collection.Iterator$class.foreach(Iterator.scala:893)\nat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\nat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\nat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\nat scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)\nat scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)\nat scala.collection.AbstractTraversable.filter(Traversable.scala:104)\nat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:614)\nat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:190)\nat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:596)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:498)\nat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\nat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\nat py4j.Gateway.invoke(Gateway.java:282)\nat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\nat py4j.commands.CallCommand.execute(CallCommand.java:79)\nat py4j.GatewayConnection.run(GatewayConnection.java:238)\nat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.FileNotFoundException: \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker_pyspark\/jars\/sagemaker-spark_2.11-spark_2.2.0-1.1.1.jar (No such file or directory)\n    at java.util.zip.ZipFile.open(Native Method)\n    at java.util.zip.ZipFile.&lt;init&gt;(ZipFile.java:219)\n    at java.util.zip.ZipFile.&lt;init&gt;(ZipFile.java:149)\n    at java.util.jar.JarFile.&lt;init&gt;(JarFile.java:166)\n    at java.util.jar.JarFile.&lt;init&gt;(JarFile.java:103)\n    at sun.net.www.protocol.jar.URLJarFile.&lt;init&gt;(URLJarFile.java:93)\n    at sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:69)\n    at sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:84)\n    at sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:122)\n    at sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:150)\n    at java.net.URL.openStream(URL.java:1045)\n    at java.util.ServiceLoader.parse(ServiceLoader.java:304)\n    ... 26 more\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1532387294417,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1532387921180,
        "Question_score_count":0.0,
        "Question_view_count":2283.0,
        "Poster_created_time":1444524456120,
        "Poster_location":"Los Angeles, CA, USA",
        "Poster_reputation_count":973.0,
        "Poster_view_count":82.0,
        "Answer_body":"<p>(Making comment to the original question as answer)<\/p>\n\n<p>It looks like a jupyter kernel issue. I had a similar issue and I used <code>Sparkmagic (pyspark)<\/code> kernel instead of <code>Sparkmagic (pyspark3)<\/code> and it is working fine. Follow instructions on this <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/build-amazon-sagemaker-notebooks-backed-by-spark-in-amazon-emr\/\" rel=\"nofollow noreferrer\">blog<\/a> and see if it helps.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1532493818792,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1458100127643,
        "Answerer_location":null,
        "Answerer_reputation_count":1083.0,
        "Answerer_view_count":86.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51488308",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"fail read data spark datafram try read csv file bucket notebook access spark datafram hit follow issu spark spark jar tip resolv appreci bucket mybucket prefix folder file csv spark read csv format bucket prefix pyjjavaerror error occur call csv java util serviceconfigurationerror org apach spark sql sourc datasourceregist error read configur file java util serviceload fail serviceload java java util serviceload pars serviceload java java util serviceload access serviceload java java util serviceload lazyiter hasnextservic serviceload java java util serviceload lazyiter hasnext serviceload java java util serviceload hasnext serviceload java scala collect convert wrapper jiteratorwrapp hasnext wrapper scala scala collect iter class foreach iter scala scala collect abstractiter foreach iter scala scala collect iterablelik class foreach iterablelik scala scala collect abstractiter foreach iter scala scala collect traversablelik class filterimpl traversablelik scala scala collect traversablelik class filter traversablelik scala scala collect abstracttravers filter travers scala org apach spark sql execut datasourc datasourc lookupdatasourc datasourc scala org apach spark sql dataframeread load dataframeread scala org apach spark sql dataframeread csv dataframeread scala sun reflect nativemethodaccessorimpl invok nativ method sun reflect nativemethodaccessorimpl invok nativemethodaccessorimpl java sun reflect delegatingmethodaccessorimpl invok delegatingmethodaccessorimpl java java lang reflect method invok method java pyj reflect methodinvok invok methodinvok java pyj reflect reflectionengin invok reflectionengin java pyj gatewai invok gatewai java pyj command abstractcommand invokemethod abstractcommand java pyj command callcommand execut callcommand java pyj gatewayconnect run gatewayconnect java java lang thread run thread java caus java filenotfoundexcept home user anaconda env python lib python site packag pyspark jar spark spark jar file directori java util zip zipfil open nativ method java util zip zipfil zipfil java java util zip zipfil zipfil java java util jar jarfil jarfil java java util jar jarfil jarfil java sun net www protocol jar urljarfil urljarfil java sun net www protocol jar urljarfil getjarfil urljarfil java sun net www protocol jar jarfilefactori jarfilefactori java sun net www protocol jar jarurlconnect connect jarurlconnect java sun net www protocol jar jarurlconnect getinputstream jarurlconnect java java net url openstream url java java util serviceload pars serviceload java",
        "Question_preprocessed_content":"fail read data spark datafram try read csv file bucket spark datafram tip resolv",
        "Question_gpt_summary_original":"The user is facing an issue while trying to read a CSV file from an S3 bucket into a Spark dataframe in Sagemaker. The error message indicates that the sagemaker-spark_2.11-spark_2.2.0-1.1.1.jar file cannot be found, resulting in a java.util.ServiceConfigurationError. The user is seeking tips on how to resolve this issue.",
        "Question_gpt_summary":"user face issu try read csv file bucket spark datafram error messag indic spark spark jar file result java util serviceconfigurationerror user seek tip resolv issu"
    },
    {
        "Question_title":"Waiting for SageMaker CreateTrainingJob to Finish",
        "Question_body":"I'm invoking the following task in my step function workflow:  \n  \nhttps:\/\/docs.aws.amazon.com\/cdk\/api\/latest\/docs\/@aws-cdk_aws-stepfunctions-tasks.SageMakerCreateTrainingJob.html  \n  \nSageMakerCreateTrainingJob starts the task in an asynchronous manner, i.e. the task returns immediately after I request it to start, even if the training job may take hours to finish.  \n  \nI want to have another task execute after the training job truly and completely finishes.  What is an easy way to accomplish this without having to use the two techniques below?  \n  \nI know there are two clunky ways to do this:  \n- Using a combination of a Lambda function that calls the SageMaker API to poll for the status of a training job - i.e. to detect when it is finished - and a wait state to force a poll every X number of minutes or so.  \n- Another possibility is using step function activities, but that would probably preclude me from using Lambdas as a Lambda activity worker would need to keep waiting (doing a thread wait) and constantly polling.  I would also need to worry about the 15 minute Lambda time limit.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1618441857000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668620571120,
        "Question_score_count":0.0,
        "Question_view_count":350.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUKgs9xRKGRYaibqIaX7sdzg\/waiting-for-sagemaker-createtrainingjob-to-finish",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wait createtrainingjob finish invok follow task step function workflow http doc aw amazon com cdk api latest doc aw cdk aw stepfunct task createtrainingjob html createtrainingjob start task asynchron manner task return immedi request start train job hour finish want task execut train job truli complet finish easi wai accomplish have us techniqu know clunki wai combin lambda function call api poll statu train job detect finish wait state forc poll number minut possibl step function activ probabl preclud lambda lambda activ worker need wait thread wait constantli poll need worri minut lambda time limit",
        "Question_preprocessed_content":"wait createtrainingjob finish invok task step function workflow createtrainingjob start task asynchron task return request start train job hour finish want task execut train job truli complet finish easi wai have us techniqu know clunki wai combin lambda function api statu train job detect finish wait state forc number minut step function activ probabl preclud lambda lambda activ worker wait constantli minut lambda time limit",
        "Question_gpt_summary_original":"The user is facing a challenge in executing a task using SageMakerCreateTrainingJob in an asynchronous manner. They want to execute another task only after the training job is completely finished, without using the clunky techniques of polling or using step function activities.",
        "Question_gpt_summary":"user face challeng execut task createtrainingjob asynchron manner want execut task train job complet finish clunki techniqu poll step function activ"
    },
    {
        "Question_title":"English to Chinese glossary is ignored",
        "Question_body":"I am trying to translate domain-specific English (en-US) text to Chinese simplified (zh). I have created a glossary, however, it looks like CloudTranslate gives precedence to other translations over the glossary.\n\nFor example, the word \"fabric\" has many translations to Chinese, so the glossary has an entry \"the fabric,\u4ea4\u6362\u7f51\", but the API returns \"\u9762\u6599\", which is the same translation as I get from Google Translate website.\n\nQuestion 1: Since I didn't get any error, is it true to assume that the glossary was found and used?\n\nQuestion 2: I expected that the glossary will get strict precedence over other translations. Is there a way to force it?",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1676864760000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":57.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/English-to-Chinese-glossary-is-ignored\/m-p\/524065#M1299",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"english chines glossari ignor try translat domain specif english text chines simplifi creat glossari look like cloudtransl give preced translat glossari exampl word fabric translat chines glossari entri fabric api return translat googl translat websit question error true assum glossari question expect glossari strict preced translat wai forc",
        "Question_preprocessed_content":"english chines ignor try translat english text chines simplifi creat like cloudtransl give preced translat exampl word fabric translat chines entri fabric api return translat translat websit question true question expect strict preced translat wai forc",
        "Question_gpt_summary_original":"The user is facing an issue where their glossary for translating English to Chinese is being ignored by CloudTranslate. Despite creating a glossary, the API is giving precedence to other translations over the glossary. The user is unsure if the glossary was found and used and is looking for a way to force the glossary to be given strict precedence over other translations.",
        "Question_gpt_summary":"user face issu glossari translat english chines ignor cloudtransl despit creat glossari api give preced translat glossari user unsur glossari look wai forc glossari given strict preced translat"
    },
    {
        "Question_title":"Retrain the classification model automatically based on updated data set",
        "Question_body":"<p>We have created an experiment in Azure ML Studio to predict some scheduling activities based on the system data and user data. System data consists of the CPU time, Heap Usage and other system parameters while user data has active sessions of the user and some user-specific data.\nOur experiment is working fine and returning the results quite similar to what we are expecting, but we are struggling with the following:-<\/p>\n\n<p>1) Our experiment is not considering the updated data for training its models.<\/p>\n\n<p>2) Every time we are required to upload the data and retrain the models manually.<\/p>\n\n<p>I wonder if it is really possible to feed in live data to the azure experiments using some web-services or by using Azure DB. We are trying to update the data in CSV file that we have created in Azure storage. That probably would solve our 1st query.<\/p>\n\n<p>Now, this updated data should be considered to train the model periodically automatically.<\/p>\n\n<p>It would be great if someone could help us out with it?<\/p>\n\n<p>Note: We are using our model using the web services created with the help of Azure studio.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1550724960020,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1550942353507,
        "Question_score_count":0.0,
        "Question_view_count":772.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Step 1 : Create 2 web services with Azure ML Studio ( One for the training model and one for the predictive model)<\/p>\n\n<p>Step 2: Create endpoint through the web service with the link Manage Endpoint on Azure ML Studio for each web service<\/p>\n\n<p>Step 3: Create 2 new connections on Azure Data Factory \/ Find Azure ML (on compute tab) and copy the Endpoint key and API Key that you will find under the Consume tab in the endpoint configuration (the one that you created on step 2) Endpoint Key = Batch Requests Key and API Key = Primary Key <\/p>\n\n<p>Set Disable Update Resource for the training model endpoint\nSet Enable Update Resource for the predictive model endpoint ( Update Resource End Point = Patch key )<\/p>\n\n<p>Step 4 : Create a pipeline with 2 activities ( ML Batch Execution and ML Update Resource)\nSet the AML Linked service for the ML batch Execution with the connection that has  disable Update Resource<\/p>\n\n<p>Set the AML Linked service for the ML Update Resource with the connection that has  Enable Update Resource<\/p>\n\n<p>Step 5 : Set the Web Service Inputs and Outputs<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1551972299452,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1521189557296,
        "Answerer_location":null,
        "Answerer_reputation_count":160.0,
        "Answerer_view_count":27.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54799512",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retrain classif model automat base updat data set creat experi studio predict schedul activ base data user data data consist cpu time heap usag paramet user data activ session user user specif data experi work fine return result similar expect struggl follow experi consid updat data train model time requir upload data retrain model manual wonder possibl feed live data azur experi web servic azur try updat data csv file creat azur storag probabl solv queri updat data consid train model period automat great help note model web servic creat help azur studio",
        "Question_preprocessed_content":"retrain model base updat data set creat experi studio predict schedul activ base data user data data consist cpu time heap usag paramet user data activ user data experi work fine return result similar expect experi consid updat data train model time requir upload data retrain model wonder live data azur experi azur try updat data csv file creat azur storag probabl solv queri updat data consid train model great help note model web servic creat help azur studio",
        "Question_gpt_summary_original":"The user has created an experiment in Azure ML Studio to predict scheduling activities based on system and user data. However, the experiment is not considering updated data for training its models and requires manual retraining every time. The user is seeking a solution to feed live data to the experiment and train the model periodically automatically. They are using the model through web services created with Azure Studio.",
        "Question_gpt_summary":"user creat experi studio predict schedul activ base user data experi consid updat data train model requir manual retrain time user seek solut feed live data experi train model period automat model web servic creat azur studio"
    },
    {
        "Question_title":"How to use AzureMLDataset",
        "Question_body":"<p>Hi,  <\/p>\n<p>I have used the data labeling system within Azure Machine Learning studio to label a dataset of images.  <br \/>\nThen the output of the labeling system is a new dataset that can be found in the &quot;Dataset&quot; section of the designer in ML studio.  <\/p>\n<p>The problem is that this new dataset module, that can be dragged and dropped in the pipeline, has datatype &quot;AzureMLDataset&quot; (or datasoruce type &quot;amldataset&quot;), which then I cannot connect to any other module in the pipeline because there is no module which accepts as input something with datatype &quot;AzureMLDataset&quot; (or with datasource type &quot;amldataset&quot;).  <\/p>\n<p>I have seen that it is possible to consume the dataset using python, but I would like to use Azure ML studio because it is more convenient to the system I am working in.  <\/p>\n<p>How can I use the AzureMLDataset output module inside ML studio?  <\/p>\n<p>Thank you in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1607676200880,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/194940\/how-to-use-azuremldataset",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us dataset data label studio label dataset imag output label new dataset dataset section design studio problem new dataset modul drag drop pipelin datatyp dataset datasoruc type amldataset connect modul pipelin modul accept input datatyp dataset datasourc type amldataset seen possibl consum dataset python like us studio conveni work us dataset output modul insid studio thank advanc",
        "Question_preprocessed_content":"us dataset data label studio label dataset imag output label new dataset dataset section design studio problem new dataset modul pipelin datatyp dataset modul pipelin modul input datatyp dataset consum dataset python like us studio conveni work us dataset output modul insid studio thank advanc",
        "Question_gpt_summary_original":"The user has labeled a dataset of images using the data labeling system in Azure Machine Learning studio, which has resulted in a new dataset module with datatype \"AzureMLDataset\". However, the user is unable to connect this module to any other module in the pipeline because there is no module that accepts input with datatype \"AzureMLDataset\". The user is seeking a solution to use the AzureMLDataset output module inside ML studio.",
        "Question_gpt_summary":"user label dataset imag data label studio result new dataset modul datatyp dataset user unabl connect modul modul pipelin modul accept input datatyp dataset user seek solut us dataset output modul insid studio"
    },
    {
        "Question_title":"AutoML Translation: again one of 22 requests finishes with timeout",
        "Question_body":"Again we meet some problems with AutoML Translation API \u00a0\n\nTrained 22 custom models for translation from EN to target language. Try to translate with Google Cloud API and every minute minimum one of\u00a022 custoim models can't execute translation with 504 deadline error.\n\nWe can not manage or configure our models on your infrustructure. How can we fix\u00a0504 deadline error while translating with custom model with API call? Can we increase any quotes? Or pay additional for something? Please, help!",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1680754800000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":94.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-Translation-again-one-of-22-requests-finishes-with\/m-p\/541243#M1599",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"automl translat request finish timeout meet problem automl translat api train custom model translat target languag try translat googl cloud api minut minimum custoim model execut translat deadlin error manag configur model infrustructur fix deadlin error translat custom model api increas quot pai addit help",
        "Question_preprocessed_content":"automl translat request finish timeout problem automl translat api train custom model translat target languag try translat cloud api minut minimum custoim model execut translat deadlin manag configur model infrustructur fix deadlin translat custom model api increas quot pai help",
        "Question_gpt_summary_original":"The user is facing issues with the AutoML Translation API as one out of their 22 custom models fails to execute translation with a 504 deadline error. They are unable to manage or configure their models on the infrastructure and are seeking help to fix the issue, including increasing quotes or paying additional fees.",
        "Question_gpt_summary":"user face issu automl translat api custom model fail execut translat deadlin error unabl manag configur model infrastructur seek help fix issu includ increas quot pai addit fee"
    },
    {
        "Question_title":"How to deploy an automl model from gcp as a web app using streamlit on GCP",
        "Question_body":"<p>I plan to build an application which asks user input in the form of news and predicts it as fake or true.\ni have trained the model using automl google cloud platform (GCP) on vertex AI platform. I have created the endpoint.<\/p>\n<p>How to proceed further? How to build an app without downloading anything on local system? (all of this should be built on GCP)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1647671495320,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":112.0,
        "Poster_created_time":1611850729940,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71535888",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi automl model gcp web app streamlit gcp plan build applic ask user input form new predict fake true train model automl googl cloud platform gcp platform creat endpoint proce build app download local built gcp",
        "Question_preprocessed_content":"deploi automl model gcp web streamlit gcp plan build ask user input form new predict fake true train model automl cloud platform platform creat endpoint build download local",
        "Question_gpt_summary_original":"The user has trained an automl model on GCP's Vertex AI platform to predict whether a news article is fake or true. They are now seeking guidance on how to deploy the model as a web app using Streamlit on GCP without downloading anything on their local system.",
        "Question_gpt_summary":"user train automl model gcp platform predict new articl fake true seek guidanc deploi model web app streamlit gcp download local"
    },
    {
        "Question_title":"Can we connect to the instance (via ssh or other means) where a Triton Sagemaker endpoint is deployed?",
        "Question_body":"I am deploying a Triton server endpoint on Sagemaker and I want to ssh into the instance where the endpoint is running for debugging purposes. I can't find a way to identify the instance (e.g. find the instance id) and connect to it. I saw this repo, https:\/\/github.com\/aws-samples\/sagemaker-ssh-helper#inference, but it seems it only works with estimator objects on Sagemaker. I was wondering if there is a way to do the same thing with Sagemaker client objects: botocore.client.SageMaker. I am using the Sagemaker client to create the endpoint with the Triton image on aws ECR.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1678225961811,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1678573626735,
        "Question_score_count":0.0,
        "Question_view_count":92.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU8-U_XgPVRSuLTSXf8eW8fA\/can-we-connect-to-the-instance-via-ssh-or-other-means-where-a-triton-sagemaker-endpoint-is-deployed",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect instanc ssh mean triton endpoint deploi deploi triton server endpoint want ssh instanc endpoint run debug purpos wai identifi instanc instanc connect saw repo http github com aw sampl ssh helper infer work estim object wonder wai thing client object botocor client client creat endpoint triton imag aw ecr",
        "Question_preprocessed_content":"instanc triton endpoint deploi deploi triton server endpoint want instanc endpoint purpos wai identifi instanc saw repo work estim object wonder wai thing client object client creat endpoint triton imag aw ecr",
        "Question_gpt_summary_original":"The user is trying to debug a Triton server endpoint deployed on Sagemaker and wants to connect to the instance where the endpoint is running via ssh or other means. However, they are unable to identify the instance and connect to it. They have tried using a repo that only works with estimator objects on Sagemaker and are wondering if there is a way to do the same thing with Sagemaker client objects.",
        "Question_gpt_summary":"user try debug triton server endpoint deploi want connect instanc endpoint run ssh mean unabl identifi instanc connect tri repo work estim object wonder wai thing client object"
    },
    {
        "Question_title":"Get stuck at uploading at the end",
        "Question_body":"<p>My program finished before a few hours, but wandb get stuck at uploading files until now. I asked my friend and he said he had the same problem. So there are any problem for wandb server in the past  few hours and how to fix it?<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf.jpeg\" data-download-href=\"\/uploads\/short-url\/kwlk7giIWlj5N5PsCmnxPYQd8d1.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_690x83.jpeg\" alt=\"image\" data-base62-sha1=\"kwlk7giIWlj5N5PsCmnxPYQd8d1\" width=\"690\" height=\"83\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_690x83.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_1035x124.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/8\/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_1380x166.jpeg 2x\" data-dominant-color=\"181717\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">2122\u00d7256 120 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1669253840661,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":822.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/get-stuck-at-uploading-at-the-end\/3453",
        "Tool":"Weights & Biases",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"stuck upload end program finish hour stuck upload file ask friend said problem problem server past hour fix imag",
        "Question_preprocessed_content":"stuck upload end program finish hour stuck upload file ask friend said problem problem server past hour fix imag",
        "Question_gpt_summary_original":"The user's program finished a few hours ago, but they are unable to upload files to wandb as it is stuck. The user's friend also faced the same issue. The user is seeking information on whether there were any problems with the wandb server in the past few hours and how to fix it.",
        "Question_gpt_summary":"user program finish hour ago unabl upload file stuck user friend face issu user seek inform problem server past hour fix"
    },
    {
        "Question_title":"ML Pipeline on AWS SageMaker: How to create long-running query\/preprocessing tasks",
        "Question_body":"<p>I'm a software engineer transitioning toward machine learning engineering, but need some assistance.<\/p>\n<p>I'm currently using AWS Lambda and Step Functions to run query and preprocessing jobs for my ML pipeline, but am restrained by Lambda's 15m runtime limitation.<\/p>\n<p>We're a strictly AWS shop, so I'm kind of stuck with SageMaker and other AWS tools for the time being. Later on we'll consider experimenting with something like Kubeflow if it looks advantageous enough.<\/p>\n<p><strong>My current process<\/strong><\/p>\n<ul>\n<li>I have my data scientists write python scripts (in a git repo) for the query and preprocessing steps of a model, and deploy them (via Terraform) as Lambda functions, then use Step Functions to sequence the ML Pipeline steps as a DAG (query -&gt; preprocess -&gt; train -&gt; deploy)<\/li>\n<li>The Query lambda pulls data from our data warehouse (Redshift), and writes the unprocessed dataset to S3<\/li>\n<li>The Preprocessing lambda loads the unprocessed dataset from S3, manipulates it as needed, and writes it as training &amp; validation datasets to a different S3 location<\/li>\n<li>The Train and Deploy tasks use the SageMaker python api to train and deploy the models as SageMaker Endpoints<\/li>\n<\/ul>\n<p>Do I need to be using Glue and SageMaker Processing jobs? From what I can tell, Glue seems more targeted towards ETLs than for writing to S3, and SageMaker Processing jobs seem a bit more complex to deploy to than Lambda.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1604367008457,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":468.0,
        "Poster_created_time":1268298510172,
        "Poster_location":"Austin, TX",
        "Poster_reputation_count":1209.0,
        "Poster_view_count":55.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64655582",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pipelin creat long run queri preprocess task softwar engin transit machin learn engin need assist current aw lambda step function run queri preprocess job pipelin restrain lambda runtim limit strictli aw shop kind stuck aw tool time later consid experi like kubeflow look advantag current process data scientist write python script git repo queri preprocess step model deploi terraform lambda function us step function sequenc pipelin step dag queri preprocess train deploi queri lambda pull data data warehous redshift write unprocess dataset preprocess lambda load unprocess dataset manipul need write train valid dataset differ locat train deploi task us python api train deploi model endpoint need glue process job tell glue target etl write process job bit complex deploi lambda",
        "Question_preprocessed_content":"pipelin creat task softwar transit machin learn aw lambda step function run queri job pipelin restrain lambda runtim limit strictli aw shop kind stuck aw time later consid experi like kubeflow advantag data scientist write python script queri step model deploi lambda function us step function sequenc pipelin step dag queri lambda data data warehous write dataset lambda load dataset manipul write train valid dataset locat train deploi task us python api train deploi model endpoint glue job glue target etl write job bit complex deploi lambda",
        "Question_gpt_summary_original":"The user is facing a challenge in running query and preprocessing jobs for their ML pipeline on AWS Lambda due to its 15-minute runtime limitation. They are currently using AWS Lambda and Step Functions to sequence the ML Pipeline steps as a DAG. The user is unsure if they need to use Glue and SageMaker Processing jobs instead of Lambda. They are a strictly AWS shop and plan to experiment with Kubeflow in the future.",
        "Question_gpt_summary":"user face challeng run queri preprocess job pipelin aw lambda minut runtim limit current aw lambda step function sequenc pipelin step dag user unsur need us glue process job instead lambda strictli aw shop plan experi kubeflow futur"
    },
    {
        "Question_title":"How to connect Azure ML to Eventhub",
        "Question_body":"<p>Hi I'm new to Azure ML so I have little knowledge of it..  <br \/>\nI've created a basic regression ML model using auto ml package inJjupyeter notebook  <br \/>\nand now I have to deploy the model and send the output to the eventhub..  <\/p>\n<p>I'm wondering if anyone could help me with deploying the model and connecting it to the eventhub  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1639361629193,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/660845\/how-to-connect-azure-ml-to-eventhub",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect eventhub new littl knowledg creat basic regress model auto packag injjupyet notebook deploi model send output eventhub wonder help deploi model connect eventhub",
        "Question_preprocessed_content":"eventhub new knowledg creat basic model auto packag deploi model send output wonder help deploi model eventhub",
        "Question_gpt_summary_original":"The user is new to Azure ML and has created a basic regression ML model using auto ml package in Jupyter notebook. They are seeking help to deploy the model and connect it to the eventhub.",
        "Question_gpt_summary":"user new creat basic regress model auto packag jupyt notebook seek help deploi model connect eventhub"
    },
    {
        "Question_title":"Use custom modules in Sagemaker MXNet",
        "Question_body":"<p>I\u2019ve been trying to use Sagemaker to run my custom MXNet training job. In all the examples I\u2019ve seen, the code sample looks like this<\/p>\n\n<pre><code>estimator = MXNet(\u2018train.py\u2019, role=role, other_params)\nestimator.fit(inputs)\n<\/code><\/pre>\n\n<p>\u2028\u2028What if my <code>train.py<\/code> relies on a custom module? Given a directory structure like so<\/p>\n\n<pre><code>.\n\u251c\u2500\u2500 awesome\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lib.py\n\u2514\u2500\u2500 train.py \n<\/code><\/pre>\n\n<p>With my <code>train.py<\/code> file importing from <code>awesome\/lib.py<\/code>, what\u2019s the best way for me to deploy this job on Sagemaker without going through the hassle of creating a Docker container. <\/p>\n\n<p>Note: all the code in the custom module is just regular mxnet code, organized across various files and helper methods<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1590078681800,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":139.0,
        "Poster_created_time":1590078591488,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61939275",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us custom modul mxnet iv try us run custom mxnet train job exampl iv seen code sampl look like estim mxnet train role role param estim fit input train reli custom modul given directori structur like awesom init lib train train file import awesom lib what best wai deploi job go hassl creat docker contain note code custom modul regular mxnet code organ file helper method",
        "Question_preprocessed_content":"us custom modul mxnet iv try us run custom mxnet train job exampl iv code sampl like reli custom modul given directori structur like file import what best wai deploi job go creat docker contain note code custom modul regular mxnet code organ file helper method",
        "Question_gpt_summary_original":"The user is facing a challenge while using Sagemaker to run a custom MXNet training job that relies on a custom module. The user is unsure about the best way to deploy the job on Sagemaker without creating a Docker container. The custom module contains regular MXNet code organized across various files and helper methods.",
        "Question_gpt_summary":"user face challeng run custom mxnet train job reli custom modul user unsur best wai deploi job creat docker contain custom modul contain regular mxnet code organ file helper method"
    },
    {
        "Question_title":"Not able to read variable in custom RStudio open-source application , Azure ML",
        "Question_body":"<p>In Azure ML we have created compute instance by using setup shell script and we also installed custom RStudio open-source application using below MS docs  <br \/>\n<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio<\/a><\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/247908-image.png?platform=QnA\" alt=\"compute instance\" \/><\/p>\n<p>In setup shell script we define environment variable<\/p>\n<h1 id=\"create-renviron-file\">Create .Renviron file<\/h1>\n<p>r_env_file=&quot;\/home\/${aml_user}\/.Renviron&quot;<\/p>\n<p>echo &quot;Creating R environment variables&quot;  <br \/>\nsudo tee &quot;${r_env_file}&quot; &gt; \/dev\/null &lt;&lt;EOF  <br \/>\nAZURE_TENANT_ID=${AZURE_TENANT_ID}  <br \/>\nAZURE_CLIENT_ID=${AZURE_CLIENT_ID}  <br \/>\nAZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}  <br \/>\nDEFAULT_ADLS_ACCOUNT=${DEFAULT_ADLS_ACCOUNT}  <br \/>\nDEFAULT_ADLS_CONTAINER=${DEFAULT_ADLS_CONTAINER}  <br \/>\nEOF<\/p>\n<p>sudo chown &quot;${aml_user}&quot; &quot;${r_env_file}&quot;  <br \/>\nsudo chmod 600 &quot;${r_env_file}&quot;<\/p>\n<p>In terminal we are able to read above variable  <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/247949-image.png?platform=QnA\" alt=\"treminal\" \/><\/p>\n<p>However, we are not able to read above variable in custom RStudio open-source application.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1665035652217,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1037115\/not-able-to-read-variable-in-custom-rstudio-open-s",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"abl read variabl custom rstudio open sourc applic creat comput instanc setup shell script instal custom rstudio open sourc applic doc http learn microsoft com azur machin learn creat manag comput instanc tab azur studio setup shell script defin environ variabl creat renviron file env file home aml user renviron echo creat environ variabl sudo tee env file dev null eof azur tenant azur tenant azur client azur client azur client secret azur client secret default adl account default adl account default adl contain default adl contain eof sudo chown aml user env file sudo chmod env file termin abl read variabl abl read variabl custom rstudio open sourc applic",
        "Question_preprocessed_content":"abl read variabl custom rstudio creat comput instanc setup script custom rstudio doc setup script defin environ variabl creat renviron file echo creat environ variabl sudo eof eof sudo chown sudo chmod termin abl read variabl abl read variabl custom rstudio",
        "Question_gpt_summary_original":"The user is unable to read environment variables defined in a setup shell script in a custom RStudio open-source application installed on an Azure ML compute instance, even though they are able to read the variables in the terminal.",
        "Question_gpt_summary":"user unabl read environ variabl defin setup shell script custom rstudio open sourc applic instal comput instanc abl read variabl termin"
    },
    {
        "Question_title":"Accessing Data from azure container from a notebook",
        "Question_body":"<p>Hey there,  <\/p>\n<p>i have a question concerning the navigation in the file system of the azure cloud.  <\/p>\n<p>How can i access data (like images) from my container through a azure notebook?  <br \/>\nCan i navigate in the cloud like in the file system of my local machine?  <\/p>\n<p>Best regards and thank you in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1617804754800,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/348022\/accessing-data-from-azure-container-from-a-noteboo",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"access data azur contain notebook hei question concern navig file azur cloud access data like imag contain azur notebook navig cloud like file local machin best regard thank advanc",
        "Question_preprocessed_content":"data azur contain hei question concern navig file azur cloud data contain azur navig cloud like file local machin best regard thank advanc",
        "Question_gpt_summary_original":"The user is facing challenges in accessing data, specifically images, from their Azure container through an Azure notebook. They are unsure of how to navigate the cloud file system and are seeking guidance on whether it is possible to navigate it like a local machine's file system.",
        "Question_gpt_summary":"user face challeng access data specif imag azur contain azur notebook unsur navig cloud file seek guidanc possibl navig like local machin file"
    },
    {
        "Question_title":"What is a 'XGBoostLabelEncoder' object?",
        "Question_body":"<p>I'm trying to load a model from an mlflow run. When I do that I get an 'XGBoostLabelEncoder' object, an object with no attributes like predict or predict_proba. I don't really know what you can do with it.<\/p>\n<p>I've googled around but can't find any information about what an 'XGBoostLabelEncoder' object is.<\/p>\n<p>Anybody who knows?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1663571938730,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1663573301816,
        "Question_score_count":0.0,
        "Question_view_count":25.0,
        "Poster_created_time":1503559541763,
        "Poster_location":"Malm\u00f6, Sverige",
        "Poster_reputation_count":796.0,
        "Poster_view_count":136.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73769728",
        "Tool":"MLflow",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"xgboostlabelencod object try load model run xgboostlabelencod object object attribut like predict predict proba know googl inform xgboostlabelencod object anybodi know",
        "Question_preprocessed_content":"object try load model run object object like predict know inform object anybodi know",
        "Question_gpt_summary_original":"The user is encountering an issue while trying to load a model from an mlflow run. They are getting an 'XGBoostLabelEncoder' object which has no attributes like predict or predict_proba. The user is unsure about what can be done with this object and is seeking help to understand it.",
        "Question_gpt_summary":"user encount issu try load model run get xgboostlabelencod object attribut like predict predict proba user unsur object seek help understand"
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml' in ML Studio",
        "Question_body":"<p>I am learning Azure ML from Microsoft tutorials, <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data\">here<\/a>. The third tutorial is giving me the following error.    <\/p>\n<pre><code>[stderr]Traceback (most recent call last):  \n[stderr]  File &quot;train.py&quot;, line 8, in &lt;module&gt;  \n[stderr]    from azureml.core import Run  \n[stderr]ModuleNotFoundError: No module named 'azureml'  \n[stderr]  \n<\/code><\/pre>\n<p>Working with Azure ML Studio and submitting the code to the environment, I am unable to find how to resolve this error.    <\/p>\n<p>I have checked that the package is installed (running on Azure ML studio so this is a basic assumption, but I have tested as well). Following is the code 'run-pytorch.py' which calls the script 'train.py'    <\/p>\n<pre><code># run-pytorch.py  \nfrom azureml.core import Workspace  \nfrom azureml.core import Experiment  \nfrom azureml.core import Environment  \nfrom azureml.core import ScriptRunConfig  \n  \nif __name__ == &quot;__main__&quot;:  \n    ws = Workspace.from_config()  \n    experiment = Experiment(workspace=ws, name='day1-experiment-train')  \n    config = ScriptRunConfig(source_directory='.\/src',  \n                             script='train.py',  \n                             compute_target='cpu-cluster')  \n  \n    # set up pytorch environment  \n    env = Environment.from_conda_specification(  \n        name='pytorch-env',  \n        file_path='pytorch-env.yml'  \n    )  \n    config.run_config.environment = env  \n  \n    run = experiment.submit(config)  \n  \n    aml_url = run.get_portal_url()  \n    print(aml_url)  \n    print('Success...!!!')  \n<\/code><\/pre>\n<p>The code snippet for train.py is as follows    <\/p>\n<pre><code># train.py  \nimport os  \nimport argparse  \nimport torch  \nimport torch.optim as optim  \nimport torchvision  \nimport torchvision.transforms as transforms  \nfrom model import Net  \nfrom azureml.core import Run  \n...  \n...  \n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1643140351313,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/709861\/modulenotfounderror-no-module-named-azureml-in-ml",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"modulenotfounderror modul name studio learn microsoft tutori tutori give follow error stderr traceback recent stderr file train line stderr core import run stderr modulenotfounderror modul name stderr work studio submit code environ unabl resolv error check packag instal run studio basic assumpt test follow code run pytorch call script train run pytorch core import workspac core import experi core import environ core import scriptrunconfig main workspac config experi experi workspac dai experi train config scriptrunconfig sourc directori src script train comput target cpu cluster set pytorch environ env environ conda specif pytorch env file path pytorch env yml config run config environ env run experi submit config aml url run portal url print aml url print success code snippet train follow train import import argpars import torch import torch optim optim import torchvis import torchvis transform transform model import net core import run",
        "Question_preprocessed_content":"modul name studio learn microsoft tutori tutori give work studio code environ unabl resolv check packag code script code",
        "Question_gpt_summary_original":"The user is encountering a \"ModuleNotFoundError\" while learning Azure ML from Microsoft tutorials. The error occurs while running the third tutorial and the user is unable to resolve it. The user has checked that the package is installed and shared the code snippets for \"run-pytorch.py\" and \"train.py\".",
        "Question_gpt_summary":"user encount modulenotfounderror learn microsoft tutori error occur run tutori user unabl resolv user check packag instal share code snippet run pytorch train"
    },
    {
        "Question_title":"Azure ML 'Designer': how to view logistic regression model coefficients \/ intercept",
        "Question_body":"<p>Using Azure ML Designer it is easy to create a model using the Two-Class Logistic Regression &amp; Train Model components. However it does not seem to be possible to view the regression coefficients \/ intercept (ie. the weights applied to the feature values within the model). How can we go about viewing the model coefficients? Are they stored in one of the Train Model output files (eg. data.ilearner) in a way that can be viewed \/ exported to a human readable format?  <\/p>\n<p>Note: this question relates to the Azure Machine Learning Studio (not the older 'classic' version where I believe it was possible to 'right-click' and visualise the model coefficients).<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1607433503623,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/190478\/azure-ml-designer-how-to-view-logistic-regression",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"design view logist regress model coeffici intercept design easi creat model class logist regress train model compon possibl view regress coeffici intercept weight appli featur valu model view model coeffici store train model output file data ilearn wai view export human readabl format note question relat studio older classic version believ possibl right click visualis model coeffici",
        "Question_preprocessed_content":"design view logist model intercept design easi creat model logist train model compon view intercept view model store train model output file wai view export human readabl format note question relat studio",
        "Question_gpt_summary_original":"The user is having difficulty viewing the regression coefficients and intercept of a logistic regression model created using the Two-Class Logistic Regression and Train Model components in Azure ML Designer. They are seeking advice on how to view or export these coefficients in a human-readable format.",
        "Question_gpt_summary":"user have difficulti view regress coeffici intercept logist regress model creat class logist regress train model compon design seek advic view export coeffici human readabl format"
    },
    {
        "Question_title":"Google translate API gave a mixed language translation result?",
        "Question_body":"I am using Google Translate API for translating a Japanese sentence to Portuguese.\n\nOn July 6 to 8, the translation result was a sentence of mixed English and Portuguese words, but on July 9 the result seems to be a correct Portuguese sentence.\n\nWas there any event on July 6 to 8 such that Google Translate API gave a mixed language translation result?\n\nThank you for your time.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1657498980000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":277.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"The issue was generated due our service update and multiple service languages including Portuguese were affected. Our Translate API engineer team detected the root cause of the issue, and it was mitigated by a roll back recently performed.\n\nOur engineers confirmed that the issue is officially mitigated and you should not be experiencing any service misbehavior at this point.\n\nWe apologize for any inconvenience this may have caused on your operation.\n\nView solution in original post",
        "Answer_comment_count":null,
        "Question_closed_time":1657726380000,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-translate-API-gave-a-mixed-language-translation-result\/m-p\/440841#M412",
        "Tool":"Vertex AI",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"googl translat api gave mix languag translat result googl translat api translat japanes sentenc portugues juli translat result sentenc mix english portugues word juli result correct portugues sentenc event juli googl translat api gave mix languag translat result thank time",
        "Question_preprocessed_content":"translat api gave mix languag translat result translat api translat japanes sentenc portugues juli translat result sentenc mix english portugues word juli result portugues sentenc event juli translat api gave mix languag translat result thank time",
        "Question_gpt_summary_original":"The user encountered a problem with the Google Translate API where the translation result was a mix of English and Portuguese words instead of a correct Portuguese sentence. The issue occurred from July 6 to 8 and was resolved on July 9. The user is seeking information on whether there was an event that caused this problem.",
        "Question_gpt_summary":"user encount problem googl translat api translat result mix english portugues word instead correct portugues sentenc issu occur juli resolv juli user seek inform event caus problem"
    },
    {
        "Question_title":"Azure container instances deployment failed",
        "Question_body":"<p>I am deploying a machine learning image to Azure Container Instances from Azure Machine Learning services according to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml\" rel=\"nofollow noreferrer\">this article<\/a>, but am always stuck with the error message:<\/p>\n\n<blockquote>\n  <p>Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.<br>\n  Please check the logs for your container instance xxxxxxx'.<\/p>\n<\/blockquote>\n\n<p>I tried:<\/p>\n\n<ol>\n<li>increasing memory_gb=4 in aci_config.<\/li>\n<li>I did\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-troubleshoot-deployment#debug-the-docker-image-locally\" rel=\"nofollow noreferrer\">troubleshooting<\/a> locally, but I could not have found any.<\/li>\n<\/ol>\n\n<p>Below is my score.py<\/p>\n\n<pre><code>def init():\n    global model\n    model_path = Model.get_model_path('pofc_fc_model')\n    model = joblib.load(model_path)\n\ndef run(raw_data):\n    data = np.array(json.loads(raw_data)['data'])\n    y_hat = model.predict(data)\n    return y_hat.tolist()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1553593173310,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1562618473092,
        "Question_score_count":2.0,
        "Question_view_count":3020.0,
        "Poster_created_time":1510960409296,
        "Poster_location":"Bangkok Thailand",
        "Poster_reputation_count":306.0,
        "Poster_view_count":32.0,
        "Answer_body":"<p>Have you registered the model <code>'pofc_fc_model'<\/code> in your workspace using the <code>register()<\/code> function on the model object? If not, there will be no model path and that can cause failure.<\/p>\n\n<p>See this section on model registration: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#registermodel\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#registermodel<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1553715289510,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1468951834403,
        "Answerer_location":"Seattle, WA, United States",
        "Answerer_reputation_count":645.0,
        "Answerer_view_count":101.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55353889",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"azur contain instanc deploy fail deploi machin learn imag azur contain instanc servic accord articl stuck error messag aci deploy fail except contain applic crash caus error score file init function check log contain instanc xxxxxxx tri increas memori aci config troubleshoot local score def init global model model path model model path pofc model model joblib load model path def run raw data data arrai json load raw data data hat model predict data return hat tolist",
        "Question_preprocessed_content":"azur contain instanc deploy fail deploi machin learn imag azur contain instanc servic articl stuck aci deploy fail except contain crash caus score file init function check log contain instanc tri increas",
        "Question_gpt_summary_original":"The user is facing issues while deploying a machine learning image to Azure Container Instances from Azure Machine Learning services. The deployment is failing with an error message indicating that the container application crashed, which may be caused by errors in the scoring file's init() function. The user has tried increasing memory_gb and troubleshooting locally but could not find any issues. The score.py file is also provided.",
        "Question_gpt_summary":"user face issu deploi machin learn imag azur contain instanc servic deploy fail error messag indic contain applic crash caus error score file init function user tri increas memori troubleshoot local issu score file provid"
    },
    {
        "Question_title":"best practice to apply logic regression in azure ml",
        "Question_body":"<p> I am developing my logic regression model and I want to use azure ml to do so. What is the best proactive way to do it? How to start<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1669838650910,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=d871097d-7248-431e-be81-1cf586fe17a0\">@kevin  <\/a>     <\/p>\n<p>Thanks for reaching out to us, I would suggest you start from below sample for regression project - <a href=\"https:\/\/github.com\/Azure\/MachineLearningDesigner\/blob\/master\/articles\/samples\/text-classification-wiki.md\">https:\/\/github.com\/Azure\/MachineLearningDesigner\/blob\/master\/articles\/samples\/text-classification-wiki.md<\/a>    <\/p>\n<p>This sample demonstrates how to use text analytics modules to build a text classification pipeline in Azure Machine Learning designer.    <\/p>\n<p>The goal of text classification is to assign some piece of text to one or more predefined classes or categories. The piece of text could be a document, news article, search query, email, tweet, support tickets, customer feedback, user product review etc. Applications of text classification include categorizing newspaper articles and news wire contents into topics, organizing web pages into hierarchical categories, filtering spam email, sentiment analysis, predicting user intent from search queries, routing support tickets, and analyzing customer feedback.    <\/p>\n<p>This pipeline trains a multiclass logistic regression classifier to predict the company category with Wikipedia SP 500 dataset derived from Wikipedia.    <\/p>\n<p><img src=\"https:\/\/github.com\/Azure\/MachineLearningDesigner\/blob\/master\/articles\/samples\/media\/text-classification-wiki\/nlp-modules-overall.png?raw=true\" alt=\"nlp-modules-overall.png\" \/>    <\/p>\n<p>This is a good example if you want to design your project, I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1669854799128,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1111053\/best-practice-to-apply-logic-regression-in-azure-m",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"best practic appli logic regress develop logic regress model want us best proactiv wai start",
        "Question_preprocessed_content":"best practic logic develop logic model want us best proactiv wai start",
        "Question_gpt_summary_original":"The user is seeking advice on the best way to apply logic regression in Azure ML and is looking for guidance on how to get started.",
        "Question_gpt_summary":"user seek advic best wai appli logic regress look guidanc start"
    },
    {
        "Question_title":"Unable to spin up Azure DBX cluster despite numerous quota increase request",
        "Question_body":"<p>Hi Team,   <\/p>\n<p>We are unable to spin up even a basic Azure DBX cluster since yesterday because of the following error. We have made numerous requests for quota increase, but to no avail.   <\/p>\n<p>Cluster terminated.Reason: Azure Operation Not Allowed Exception  <\/p>\n<p>Error code: OperationNotAllowed, error message: Operation could not be completed as it results in exceeding approved standardDSv2Family Cores quota. Additional details - Deployment Model: Resource Manager, Location: westus, Current Limit: 10, Current Usage: 8, Additional Required: 8, (Minimum) New Limit Required: 16.   <\/p>\n<p><strong>Request Summary \/ New Limit:  DSv2 Series, (US) West US \/ 120<\/strong>  <br \/>\n My request for DSv2 Series, West US for 120 CPU was approved this morning, and yet I am unable to spin up the cluster. Any help is greatly appreciated! <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1637257327543,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/632708\/unable-to-spin-up-azure-dbx-cluster-despite-numero",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl spin azur dbx cluster despit numer quota increas request team unabl spin basic azur dbx cluster yesterdai follow error numer request quota increas avail cluster termin reason azur oper allow except error code operationnotallow error messag oper complet result exceed approv standarddsvfamili core quota addit detail deploy model resourc manag locat westu current limit current usag addit requir minimum new limit requir request summari new limit dsv seri west request dsv seri west cpu approv morn unabl spin cluster help greatli appreci",
        "Question_preprocessed_content":"unabl spin azur dbx cluster despit numer quota increas request team unabl spin basic azur dbx cluster yesterdai numer request quota increas avail cluster azur oper except code oper complet result famili core quota detail deploy model resourc manag locat westu limit usag requir new limit requir request new limit dsv seri west request dsv seri west cpu morn unabl spin cluster help greatli",
        "Question_gpt_summary_original":"The user is unable to create an Azure DBX cluster due to exceeding the approved quota for standardDSv2Family Cores. Despite making numerous requests for quota increase, the user is still unable to create the cluster even after their latest request for 120 CPU was approved.",
        "Question_gpt_summary":"user unabl creat azur dbx cluster exceed approv quota standarddsvfamili core despit make numer request quota increas user unabl creat cluster latest request cpu approv"
    },
    {
        "Question_title":"what is the difference between using amazon sagemaker python SDK vs AWS SDK for python (Boto3)",
        "Question_body":"<p>I am new to AWS, and just started to learn sagemaker, and I found there are two ways to train a model: \n<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ex1-train-model.html\" rel=\"noreferrer\">train a model using sagemaker<\/a><\/p>\n\n<ol>\n<li>Create and Run a Training Job (Amazon SageMaker Python SDK)<\/li>\n<li>Create and Run a Training Job (AWS SDK for Python (Boto 3))<\/li>\n<\/ol>\n\n<p>Is there anyone can explain what is the difference between this two ways and is there advantage and disadvantage of both ways?<\/p>\n\n<p>Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1563782678607,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":null,
        "Question_score_count":6.0,
        "Question_view_count":2041.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57141552",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"differ python sdk aw sdk python boto new aw start learn wai train model train model creat run train job python sdk creat run train job aw sdk python boto explain differ wai advantag disadvantag wai thank",
        "Question_preprocessed_content":"python sdk aw sdk python new aw start learn wai train model train model creat run train job creat run train job explain wai advantag disadvantag wai thank",
        "Question_gpt_summary_original":"The user is new to AWS and is learning about SageMaker. They have found two ways to train a model: using the SageMaker Python SDK or the AWS SDK for Python (Boto3). The user is seeking an explanation of the differences between the two methods and any advantages or disadvantages of each.",
        "Question_gpt_summary":"user new aw learn wai train model python sdk aw sdk python boto user seek explan differ method advantag disadvantag"
    },
    {
        "Question_title":"Is it possible to update automated machine learning model timeseries \"live\" as new events come in.",
        "Question_body":"<p>I have trained a simple time series ML model and deployed it.  <br \/>\nGetting predictions works well enough, but I would like to keep the model up to date as new events come along each hour.  <\/p>\n<p>For example I want to predict an event that happens in 10 minutes.   <br \/>\nAfter 10 minutes has gone by, and I learn the real value, i'd like to push that value at the end of the ML model data array without having to re-train\/deploy everything.  <br \/>\nIs that possible in Automated ML ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1628032373347,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/500499\/is-it-possible-to-update-automated-machine-learnin",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl updat autom machin learn model timeseri live new event come train simpl time seri model deploi get predict work like model date new event come hour exampl want predict event happen minut minut gone learn real valu like push valu end model data arrai have train deploi possibl autom",
        "Question_preprocessed_content":"updat autom machin learn model timeseri live new event come train simpl time seri model deploi predict work like model date new event come hour exampl want predict event minut minut gone learn real valu like push valu end model data have autom",
        "Question_gpt_summary_original":"The user has trained a time series ML model and wants to update it as new events come in without having to re-train\/deploy everything. They are seeking to know if it is possible to update the automated machine learning model timeseries \"live\" as new events come in.",
        "Question_gpt_summary":"user train time seri model want updat new event come have train deploi seek know possibl updat autom machin learn model timeseri live new event come"
    },
    {
        "Question_title":"Segmentation fault (core dumped) with optuna",
        "Question_body":"<p>I'm running a python script in the command line with <code>python3 CTGAN_noscale.py --database_name CTGAN_noshift<\/code> and receive the following error (with faulthandler):<\/p>\n<pre><code>Fatal Python error: Segmentation fault\n\nCurrent thread 0x00007f57e97fe700 (most recent call first):\n&lt;no Python frame&gt;\n\nThread 0x00007f593db07740 (most recent call first):\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/torch\/autograd\/__init__.py&quot;, line 145 in backward\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/torch\/tensor.py&quot;, line 245 in backward\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/ctgan\/synthesizers\/ctgan.py&quot;, line 374 in fit\n  File &quot;CTGAN_noscale.py&quot;, line 140 in objective\n  File &quot;CTGAN_noscale.py&quot;, line 162 in &lt;lambda&gt;\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/optuna\/_optimize.py&quot;, line 216 in _run_trial\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/optuna\/_optimize.py&quot;, line 162 in _optimize_sequential\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/optuna\/_optimize.py&quot;, line 65 in _optimize\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/optuna\/study.py&quot;, line 401 in optimize\n  File &quot;CTGAN_noscale.py&quot;, line 162 in run_CTGAN\n  File &quot;CTGAN_noscale.py&quot;, line 210 in &lt;module&gt;\nSegmentation fault (core dumped)\n<\/code><\/pre>\n<p>It seems that the problem is somehow with optuna.\nThe weird part is that everything worked fine on another server, after changing the server it crashed like this.<\/p>\n<p><strong>Update<\/strong><\/p>\n<p>I found out that the the problem doesn't occur when I don't use a docker container OR use a docker container without GPU.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1630053103290,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1659952934500,
        "Question_score_count":0.0,
        "Question_view_count":255.0,
        "Poster_created_time":1604138895270,
        "Poster_location":"Straubing, Deutschland",
        "Poster_reputation_count":11.0,
        "Poster_view_count":6.0,
        "Answer_body":"<p>I solved the problem by rebuilding a new image and derived a container from this image. In this container somehow the error didn't appear anymore.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1630389747607,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1604138895270,
        "Answerer_location":"Straubing, Deutschland",
        "Answerer_reputation_count":11.0,
        "Answerer_view_count":6.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68950349",
        "Tool":"Optuna",
        "Question_self_closed":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"segment fault core dump run python script command line python ctgan noscal databas ctgan noshift receiv follow error faulthandl fatal python error segment fault current thread xfefe recent thread xfdb recent file usr local lib python dist packag torch autograd init line backward file usr local lib python dist packag torch tensor line backward file usr local lib python dist packag ctgan synthes ctgan line fit file ctgan noscal line object file ctgan noscal line file usr local lib python dist packag optim line run trial file usr local lib python dist packag optim line optim sequenti file usr local lib python dist packag optim line optim file usr local lib python dist packag studi line optim file ctgan noscal line run ctgan file ctgan noscal line segment fault core dump problem weird work fine server chang server crash like updat problem occur us docker contain us docker contain gpu",
        "Question_preprocessed_content":"segment fault python script line receiv problem weird work fine server chang server crash like updat problem us docker contain us docker contain gpu",
        "Question_gpt_summary_original":"The user is encountering a \"Segmentation fault (core dumped)\" error while running a Python script with optuna. The error seems to be related to the use of a docker container with GPU, as the problem doesn't occur when not using a container or using a container without GPU. The issue worked fine on another server, but after changing the server, it crashed.",
        "Question_gpt_summary":"user encount segment fault core dump error run python script error relat us docker contain gpu problem occur contain contain gpu issu work fine server chang server crash"
    },
    {
        "Question_title":"Program on VM automatically crash after long idle",
        "Question_body":"<p>Hi,   <\/p>\n<p>I am training machine learning model on Azure VM with NC6 promo GPU. Everything was fine at the beginning, but after a while I went back to check and realized my training program was stopped. Also, I got this message &quot;client_loop: send disconnect: Broken pipe&quot;. Is there any solution for this problem since it cost me a lot of time and money.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1615873089030,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/315909\/program-on-vm-automatically-crash-after-long-idle",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"program automat crash long idl train machin learn model azur promo gpu fine begin went check realiz train program stop got messag client loop send disconnect broken pipe solut problem cost lot time monei",
        "Question_preprocessed_content":"program crash long idl train machin learn model azur promo gpu fine went check realiz train program got send broken pipe solut problem cost lot time monei",
        "Question_gpt_summary_original":"The user is facing an issue where their machine learning training program on Azure VM with NC6 promo GPU automatically stops after a long idle period, accompanied by the error message \"client_loop: send disconnect: Broken pipe\". The user is seeking a solution to this problem as it is causing them to waste time and money.",
        "Question_gpt_summary":"user face issu machin learn train program azur promo gpu automat stop long idl period accompani error messag client loop send disconnect broken pipe user seek solut problem caus wast time monei"
    },
    {
        "Question_title":"Cant install imbalanced-learn on an Azure ML Environment",
        "Question_body":"<p>I have an Azure ML Workspace which comes by default with some pre-installed packages.<\/p>\n<p>I tried to install<\/p>\n<pre><code>!pip install -U imbalanced-learn\n<\/code><\/pre>\n<p>But I got this error<\/p>\n<pre><code>Requirement already up-to-date: scikit-learn in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (0.24.2)\nRequirement already satisfied, skipping upgrade: scipy&gt;=0.19.1 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (1.4.1)\nRequirement already satisfied, skipping upgrade: joblib&gt;=0.11 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (0.14.1)\nRequirement already satisfied, skipping upgrade: numpy&gt;=1.13.3 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (1.18.5)\nRequirement already satisfied, skipping upgrade: threadpoolctl&gt;=2.0.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (2.1.0)\nCollecting imbalanced-learn\n  Using cached imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\nRequirement already satisfied, skipping upgrade: threadpoolctl&gt;=2.0.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (2.1.0)\nRequirement already satisfied, skipping upgrade: joblib&gt;=0.11 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (0.14.1)\nRequirement already satisfied, skipping upgrade: scipy&gt;=1.1.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (1.4.1)\nERROR: Could not find a version that satisfies the requirement scikit-learn&gt;=1.0.1 (from imbalanced-learn) (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0b1, 0.15.0b2, 0.15.0, 0.15.1, 0.15.2, 0.16b1, 0.16.0, 0.16.1, 0.17b1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19b2, 0.19.0, 0.19.1, 0.19.2, 0.20rc1, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21rc2, 0.21.0, 0.21.1, 0.21.2, 0.21.3, 0.22rc2.post1, 0.22rc3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0rc1, 0.23.0, 0.23.1, 0.23.2, 0.24.dev0, 0.24.0rc1, 0.24.0, 0.24.1, 0.24.2)\nERROR: No matching distribution found for scikit-learn&gt;=1.0.1 (from imbalanced-\n<\/code><\/pre>\n<p>learn)<\/p>\n<p>Not sure how to solve this, I have read in other posts to use conda, but that didnt work either.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1644933997077,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1644960360047,
        "Question_score_count":1.0,
        "Question_view_count":219.0,
        "Poster_created_time":1302030303092,
        "Poster_location":"Brussels, B\u00e9lgica",
        "Poster_reputation_count":30340.0,
        "Poster_view_count":2937.0,
        "Answer_body":"<p><a href=\"https:\/\/pypi.org\/project\/scikit-learn\/1.0.1\/\" rel=\"nofollow noreferrer\"><code>scikit-learn<\/code> 1.0.1<\/a> and up require Python &gt;= 3.7; you use Python 3.6. You need to upgrade Python or downgrade <code>imbalanced-learn<\/code>. <a href=\"https:\/\/pypi.org\/project\/imbalanced-learn\/0.8.1\/\" rel=\"nofollow noreferrer\"><code>imbalanced-learn<\/code> 0.8.1<\/a> allows Python 3.6 so<\/p>\n<pre><code>!pip install -U &quot;imbalanced-learn &lt; 0.9&quot;\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1644935036627,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1494171603136,
        "Answerer_location":null,
        "Answerer_reputation_count":73187.0,
        "Answerer_view_count":8473.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71127858",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"instal imbalanc learn environ workspac come default pre instal packag tri instal pip instal imbalanc learn got error requir date scikit learn anaconda env lib python site packag requir satisfi skip upgrad scipi anaconda env lib python site packag scikit learn requir satisfi skip upgrad joblib anaconda env lib python site packag scikit learn requir satisfi skip upgrad numpi anaconda env lib python site packag scikit learn requir satisfi skip upgrad threadpoolctl anaconda env lib python site packag scikit learn collect imbalanc learn cach imbalanc learn whl requir satisfi skip upgrad threadpoolctl anaconda env lib python site packag imbalanc learn requir satisfi skip upgrad joblib anaconda env lib python site packag imbalanc learn requir satisfi skip upgrad scipi anaconda env lib python site packag imbalanc learn error version satisfi requir scikit learn imbalanc learn version post post dev error match distribut scikit learn imbalanc learn sure solv read post us conda didnt work",
        "Question_preprocessed_content":"environ workspac come default packag tri got learn sure solv read post us conda didnt work",
        "Question_gpt_summary_original":"The user is trying to install imbalanced-learn on an Azure ML Workspace, but is encountering an error stating that it cannot find a matching distribution for scikit-learn>=1.0.1. The user has tried using conda but it did not work.",
        "Question_gpt_summary":"user try instal imbalanc learn workspac encount error state match distribut scikit learn user tri conda work"
    },
    {
        "Question_title":"Cannot connect PlainText (JSON) to Dataset at Azure Machine Learning",
        "Question_body":"<p>I uploaded a PlainText file in a JSON format to the new Azure Machine Learning Studio (studio.azureml.net), but I cannot connect the PlainText object with any module. I get all the time the error message \"Cannot connect PlainText to Dataset...\". <\/p>\n\n<p>At the documentation (<a href=\"http:\/\/help.azureml.net\/Content\/html\/e8219c57-e8dd-4989-9559-bbd73ba5bcea.htm\" rel=\"nofollow\">here<\/a>) is written that \"Plain text can be read and then split up into columns with the help of downstream preprocessing modules.\", but I can't find any downstream preprocessing modules.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1418490465200,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1446192454607,
        "Question_score_count":5.0,
        "Question_view_count":2157.0,
        "Poster_created_time":1408374893790,
        "Poster_location":null,
        "Poster_reputation_count":53.0,
        "Poster_view_count":11.0,
        "Answer_body":"<p>Actually Azure ML can't process JSON data. It will probably be added in a future update, but the easiest way (in my opinion) to consume that data is to convert it into CSV format. This can be done quickly with Power Query. Then you upload the CSV file as a new dataset.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1418919495800,
        "Answer_last_edit_time":null,
        "Answer_score_count":6.0,
        "Answerer_created_time":1345114008840,
        "Answerer_location":"Lyon, France",
        "Answerer_reputation_count":4233.0,
        "Answerer_view_count":151.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/27461432",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect plaintext json dataset upload plaintext file json format new studio studio net connect plaintext object modul time error messag connect plaintext dataset document written plain text read split column help downstream preprocess modul downstream preprocess modul",
        "Question_preprocessed_content":"plaintext dataset upload plaintext file json format new studio plaintext object modul time plaintext document plain text read split column help downstream downstream modul",
        "Question_gpt_summary_original":"The user is unable to connect a PlainText file in JSON format to any module in Azure Machine Learning Studio and is receiving an error message stating \"Cannot connect PlainText to Dataset\". The user is also unable to find any downstream preprocessing modules as mentioned in the documentation.",
        "Question_gpt_summary":"user unabl connect plaintext file json format modul studio receiv error messag state connect plaintext dataset user unabl downstream preprocess modul mention document"
    },
    {
        "Question_title":"Google Cloud AutoML Vision annotation stopped working",
        "Question_body":"Has anyone encountered the issue where the AutoML Vision annotations for datasets stopped working. This includes not being able to change labels anymore, not being able delete created labels or not save create labels. The annotations were working as expected last week, but for some reason they stopped working this week.",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1668777360000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":101.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-AutoML-Vision-annotation-stopped-working\/m-p\/490920#M816",
        "Tool":"Vertex AI",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"googl cloud automl vision annot stop work encount issu automl vision annot dataset stop work includ abl chang label anymor abl delet creat label save creat label annot work expect week reason stop work week",
        "Question_preprocessed_content":"cloud automl vision work encount automl vision dataset work includ abl chang label anymor abl delet creat label save creat label work expect reason work",
        "Question_gpt_summary_original":"The user is facing an issue with Google Cloud AutoML Vision annotations for datasets. They are unable to change or delete labels and save created labels. The annotations were working fine last week but stopped working this week.",
        "Question_gpt_summary":"user face issu googl cloud automl vision annot dataset unabl chang delet label save creat label annot work fine week stop work week"
    },
    {
        "Question_title":"AWS web service to upload and analyse users video",
        "Question_body":"<p>I'm developing a prototype of a video analysis service on AWS.<\/p>\n<p>The question is: am thinking in the right direction or I will fail to implement this architecture?<\/p>\n<p>Architecture:<\/p>\n<ol>\n<li>Flask on EC2.<\/li>\n<li>User(authenticated) upload file via web view, I'm saving it to S3.<\/li>\n<li>Lambda triggers SageMaker.<\/li>\n<li>SageMaker taking a file from S3, making preparation and analysis then: 1) Saving the results to PostgreSQL DB. 2) Triggers lambda that sends a notification to Flask that analysis is Done<\/li>\n<li>User receives a notification from Flask that the analysis is done.<\/li>\n<li>Flask web page visualizes data from the analysis for the user.<\/li>\n<\/ol>\n<p>It has only a prototyping purpose, I'm trying to keep it as simple as possible.<\/p>\n<p>will appreciate any comments and recommendations.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1631895559793,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":39.0,
        "Poster_created_time":1441637659808,
        "Poster_location":null,
        "Poster_reputation_count":119.0,
        "Poster_view_count":27.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69226644",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"aw web servic upload analys user video develop prototyp video analysi servic aw question think right direct fail implement architectur architectur flask user authent upload file web view save lambda trigger take file make prepar analysi save result postgresql trigger lambda send notif flask analysi user receiv notif flask analysi flask web page visual data analysi user prototyp purpos try simpl possibl appreci comment recommend",
        "Question_preprocessed_content":"aw web servic upload analys user video develop prototyp video analysi servic aw question think right direct fail implement architectur architectur flask user upload file web view save lambda take file make prepar analysi save result postgresql lambda send notif flask analysi user receiv notif flask analysi flask web page visual data analysi user prototyp purpos try simpl",
        "Question_gpt_summary_original":"The user is developing a prototype of a video analysis service on AWS and is seeking feedback on their proposed architecture. The architecture involves Flask on EC2, user-authenticated file uploads to S3, Lambda triggers SageMaker for analysis, and results saved to PostgreSQL DB. The user receives a notification from Flask when the analysis is done, and Flask web page visualizes data from the analysis for the user. The user is seeking comments and recommendations to keep the prototype as simple as possible.",
        "Question_gpt_summary":"user develop prototyp video analysi servic aw seek feedback propos architectur architectur involv flask user authent file upload lambda trigger analysi result save postgresql user receiv notif flask analysi flask web page visual data analysi user user seek comment recommend prototyp simpl possibl"
    },
    {
        "Question_title":"Symlink semantics in tracked directories",
        "Question_body":"<p>What are the semantics of symlinks inside a directory tree i track all at once with <code>dvc add &lt;some directory&gt;<\/code>?<\/p>\n<p>I have some COCO image datasets of this form:<\/p>\n<pre><code class=\"lang-auto\">rootdir\/\n\u251c\u2500\u2500 clientdata\n\u2502   \u251c\u2500\u2500 images\n|   |-- dataset-val.json\n\u2502   \u2514\u2500\u2500 dataset-train.json\n\u251c\u2500\u2500 clientdata-merged\n\u2502   \u251c\u2500\u2500 images\n|   |-- dataset-merged-val.json\n\u2502   \u2514\u2500\u2500 dataset-merged-train.json\n\u2514\u2500\u2500 clientdata-supplemental\n|     |-- dataset-supplemental-val.json\n\u2502     \u2514\u2500\u2500 dataset-supplemental-train.json\n|     \u2514\u2500\u2500 images\n<\/code><\/pre>\n<p>And what i would like to have is this situation:<\/p>\n<ul>\n<li>all the images in <code>clientdata\/images<\/code> are dvc-tracked image files<\/li>\n<li>all the images in <code>clientdata-supplemental\/images<\/code> are dvc-tracked image files<\/li>\n<li>all the images in <code>clientdata-merged\/images<\/code> are dvc-tracked symlinks to the other two image subdirectories<\/li>\n<\/ul>\n<p>and this way no data is duplicated.<\/p>\n<p>I <em>think<\/em> that what is happening now is that running <code>dvc add rootdir<\/code> doesn\u2019t respect the symlinks, and when i <code>dvc pull<\/code> on another host, i get three subdirectories of images.   I\u2019m confident that that is what happens for windows; i am pretty sure it\u2019s true for linux as well.<\/p>\n<p>Am i thinking about things the right way here? Are there other strategies here that i should be considering?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1683060015210,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":50.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/symlink-semantics-in-tracked-directories\/1645",
        "Tool":"DVC",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"symlink semant track directori semant symlink insid directori tree track add coco imag dataset form rootdir clientdata imag dataset val json dataset train json clientdata merg imag dataset merg val json dataset merg train json clientdata supplement dataset supplement val json dataset supplement train json imag like situat imag clientdata imag track imag file imag clientdata supplement imag track imag file imag clientdata merg imag track symlink imag subdirectori wai data duplic think happen run add rootdir doesnt respect symlink pull host subdirectori imag confid happen window pretti sure true linux think thing right wai strategi consid",
        "Question_preprocessed_content":"symlink semant track directori semant symlink insid directori track coco imag dataset form like situat imag track imag file imag track imag file imag track symlink imag subdirectori wai data duplic think doesnt respect symlink host subdirectori imag confid window sure true linux think thing right wai strategi consid",
        "Question_gpt_summary_original":"The user is trying to track multiple directories with DVC and wants to use symlinks to avoid duplicating data. They want to know if running \"dvc add\" on the root directory will respect the symlinks and if there are any other strategies they should consider. The user suspects that running \"dvc pull\" on another host will result in three subdirectories of images instead of the desired setup.",
        "Question_gpt_summary":"user try track multipl directori want us symlink avoid duplic data want know run add root directori respect symlink strategi consid user suspect run pull host result subdirectori imag instead desir setup"
    },
    {
        "Question_title":"Parquet file registered in a Tabular format is loaded with worng values",
        "Question_body":"<p>I'm facing an issue that pandas DataFrames loaded from the following two datasets are not identical although the same parquet file is used to register.  <\/p>\n<ul>\n<li> DataFrame loaded with &quot;to_pandas_dataframe()&quot; from a dataset registered in a <strong>Tabular<\/strong> format  <\/li>\n<li> DataFrame loaded with &quot;pandas.read_parquet()&quot; from a dataset registered in a <strong>File<\/strong> format  <\/li>\n<\/ul>\n<p>Specifically, DataFrame from the Tabular format has wrong values in some fields. Let's say, a DataFrame has 5 rows, and a field &quot;col1&quot; should has values [&quot;A&quot;, <strong>&quot;A&quot;<\/strong>, &quot;B&quot;, &quot;C&quot;, &quot;C&quot;] from the top, but it has [&quot;A&quot;, <strong>&quot;B&quot;<\/strong>, &quot;B&quot;, &quot;C&quot;, &quot;C&quot;]. The second element should have &quot;A&quot;, but somehow it has &quot;B&quot;. Wrong values are not completely unknown or broken values, but other values used in the same field seem to be set.  <\/p>\n<p>I'd like to know there is a known issue to see how the situation (fix plan, etc.) is going. I cannot give reproducible environment here because this issue happened with internal dataset, and I tried but couldn't reproduce it with toy dataset that I can share in public.  <\/p>\n<p>Environment that I created the parquet file  <\/p>\n<ul>\n<li> OS: Windows 10  <\/li>\n<li> Python: 3.7.4  <\/li>\n<li> pandas: 0.25.1  <br \/>\nThe parquet file was created with &quot;df.to_parquet(output_path, index=False)&quot; without any other args.  <\/li>\n<\/ul>\n<p>Environment that I loaded dataset registered on AzureML  <\/p>\n<ul>\n<li> Notebook in AzureML workspace with default environment.  <\/li>\n<\/ul>\n<p>Pseudo script used to load dataset  <br \/>\nFor Tabular dataset   <\/p>\n<pre><code>from azureml.core import Dataset, Workspace\n\nws = Workspace.from_config()\ndf = Dataset.get_by_name(workspace=ws, name='dataset_name1').to_pandas_dataframe()\n<\/code><\/pre>\n<p>For File dataset   <\/p>\n<pre><code>from pathlib import Path\n\nfrom azureml.core import Dataset, Workspace\nimport pandas as pd\n\nws = Workspace.from_config()\nds = Dataset.get_by_name(workspace=ws, name='dataset_name2')\nwith ds.mount() as m:\n    path = str(Path(m.mount_point) \/ 'filename.parquet')\n    df = pd.read_parquet(path)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1602081582550,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/119459\/parquet-file-registered-in-a-tabular-format-is-loa",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"parquet file regist tabular format load worng valu face issu panda datafram load follow dataset ident parquet file regist datafram load panda datafram dataset regist tabular format datafram load panda read parquet dataset regist file format specif datafram tabular format wrong valu field let datafram row field col valu second element wrong valu complet unknown broken valu valu field set like know known issu situat fix plan go reproduc environ issu happen intern dataset tri couldn reproduc toi dataset share public environ creat parquet file window python panda parquet file creat parquet output path index fals arg environ load dataset regist notebook workspac default environ pseudo script load dataset tabular dataset core import dataset workspac workspac config dataset workspac dataset panda datafram file dataset pathlib import path core import dataset workspac import panda workspac config dataset workspac dataset mount path str path mount point filenam parquet read parquet path",
        "Question_preprocessed_content":"parquet file regist tabular format load worng valu face panda datafram load dataset ident parquet file regist datafram load dataset regist tabular format datafram load dataset regist file format datafram tabular format wrong valu field let datafram row field col valu second element wrong valu complet unknown broken valu valu field set like know known situat go reproduc environ intern dataset tri couldn reproduc toi dataset share public environ creat parquet file window python panda parquet file creat index fals arg environ load dataset regist workspac default environ pseudo script load dataset tabular dataset file dataset",
        "Question_gpt_summary_original":"The user is facing an issue where pandas DataFrames loaded from the same parquet file registered in a Tabular format and a File format are not identical. The DataFrame from the Tabular format has wrong values in some fields, and the user is unsure if there is a known issue and how to fix it. The parquet file was created on Windows 10 with Python 3.7.4 and pandas 0.25.1, and the dataset was loaded on AzureML workspace with default environment. The user has provided pseudo scripts used to load the dataset.",
        "Question_gpt_summary":"user face issu panda datafram load parquet file regist tabular format file format ident datafram tabular format wrong valu field user unsur known issu fix parquet file creat window python panda dataset load workspac default environ user provid pseudo script load dataset"
    },
    {
        "Question_title":"Does mlflow have Slack channel?",
        "Question_body":"I think communication in Slack will be much efficient.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1561615635000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":39.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/aG4Mm0nuIE4",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"slack channel think commun slack effici",
        "Question_preprocessed_content":"slack think slack",
        "Question_gpt_summary_original":"The user is inquiring if mlflow has a Slack channel as they believe communication would be more efficient through that platform.",
        "Question_gpt_summary":"user inquir slack channel believ commun effici platform"
    },
    {
        "Question_title":"Lambda read DynamoDB and send to ML Endpoint",
        "Question_body":"<p><strong>Background:<\/strong><\/p>\n\n<blockquote>\n  <p>I have a DynamoDB table with column's \"TimeStamp | Data1 | Data2\". I\n  also have a ML endpoint in SageMaker which needs Data1 and Data2 to\n  generate one output value(score).<\/p>\n<\/blockquote>\n\n<p><strong>Question:<\/strong><\/p>\n\n<blockquote>\n  <p>My ambition is to script a Lambda function (Java or Python) to read\n  the latest row in the DynamoDB table, and send this through the\n  Endpoint and receive the score.<\/p>\n<\/blockquote>\n\n<p><strong>What I have tried:<\/strong><\/p>\n\n<blockquote>\n  <p>I have only found guides where you do this by exporting the whole\n  DynamoDB table to s3 and in Data Pipeline send it to the Endpoint.\n  This is not how I want it to work!<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1540988846833,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":782.0,
        "Poster_created_time":1426492930156,
        "Poster_location":null,
        "Poster_reputation_count":398.0,
        "Poster_view_count":84.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53083329",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"lambda read dynamodb send endpoint background dynamodb tabl column timestamp data data endpoint need data data gener output valu score question ambit script lambda function java python read latest row dynamodb tabl send endpoint receiv score tri guid export dynamodb tabl data pipelin send endpoint want work",
        "Question_preprocessed_content":"lambda read dynamodb send endpoint background dynamodb tabl column timestamp data data endpoint data data gener output valu question ambit script lambda function read latest row dynamodb tabl send endpoint receiv score tri guid export dynamodb tabl data pipelin send endpoint want work",
        "Question_gpt_summary_original":"The user wants to create a Lambda function in Java or Python to read the latest row in a DynamoDB table with columns \"TimeStamp | Data1 | Data2\" and send it to an ML endpoint in SageMaker to generate a score. The user has tried exporting the whole DynamoDB table to s3 and sending it to the endpoint using Data Pipeline, but wants a different solution.",
        "Question_gpt_summary":"user want creat lambda function java python read latest row dynamodb tabl column timestamp data data send endpoint gener score user tri export dynamodb tabl send endpoint data pipelin want differ solut"
    },
    {
        "Question_title":"Organizations using MLflow - Reinsight",
        "Question_body":"Hi,\n\nReinsight is a Stockholm based consulting company specialized in Data & AI, provide our solutions to banks, insurance, retails and clients in other areas. MLflow is the core part of our MLOps solution that we built and operationalizing for many clients, and it has been running really well.\n\n\nIt would be great if our company logo can appear on the MLflow.org. Please find our logo in attachment. Thanks!\n\n\n\n\nRegards,\n\nCo\u200bng Peng\n\n+46 70\u00a0429 4382\n\ncong...@reinsight.se\n\nSveav\u00e4gen 59,\u00a0 \u00a0113 59 Stockholm\n\nwww.reinsight.se",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1674749406000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":20.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/_C9EtDwHCHc",
        "Tool":"MLflow",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"organ reinsight reinsight stockholm base consult compani special data provid solut bank insur retail client area core mlop solut built operation client run great compani logo appear org logo attach thank regard cong peng cong reinsight sveavgen stockholm www reinsight",
        "Question_preprocessed_content":"organ reinsight reinsight stockholm base consult compani special data provid solut bank insur retail client area core mlop solut built operation client great compani logo org logo thank regard cong peng sveavgen stockholm",
        "Question_gpt_summary_original":"The user, a consulting company called Reinsight, specializes in Data & AI and uses MLflow as the core part of their MLOps solution for clients in various industries. They are requesting to have their company logo appear on MLflow.org.",
        "Question_gpt_summary":"user consult compani call reinsight special data us core mlop solut client industri request compani logo appear org"
    },
    {
        "Question_title":"ERROR: Cannot uninstall 'ruamel-yaml' while creating docker image for azure ML ACI deployment",
        "Question_body":"<p><strong>I am trying to deploy machine learning model in azure ACI but i am getting following error while creating a docker image<\/strong><\/p>\n<pre><code>Pip subprocess error:\nERROR: Cannot uninstall 'ruamel-yaml'. It is a distutils installed project and thus we cannot \naccurately determine which files belong to it which would lead to only a partial uninstall.\n<\/code><\/pre>\n<p>Below is my yml file for pip dependencies<\/p>\n<pre><code>name: project_environment\ndependencies:\n# The python interpreter version.\n\n# Currently Azure ML only supports 3.5.2 and later.\n\n\n- pip:\n  # Required packages for AzureML execution, history, and data preparation.\n  - pandas\n  - azureml-defaults\n  - azureml-sdk\n  - azureml-widgets\n  - numpy\n  - tensorflow-gpu\n  - keras\n  - azureml-defaults\n  - torch==1.4.0\n  - scikit-learn==0.22.2.post1\n<\/code><\/pre>\n<p>and if i use conda instead of pip then i am getting following error<\/p>\n<pre><code>Step 11\/13 : RUN CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; if [ -n \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; ]; then conda env update -p \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; -f '\/var\/azureml-app\/binary_2.yml'; else \nconda env update -n base -f '\/var\/azureml-app\/binary_2.yml'; fi &amp;&amp; conda \nclean -aqy &amp;&amp; rm -rf \/root\/.cache\/pip &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; \nfind &quot;$CONDA_ROOT_DIR&quot; -type d -name __pycache__ -exec rm -rf {} +\n---&gt; Running in 9e6eb7278bfc  \n[91mUnable to install package for Conda.\n\nPlease double check and ensure you dependencies file has\nthe correct spelling.  You might also try installing the\nconda-env-Conda package to see if provides the required\ninstaller. \n[0mThe command '\/bin\/sh -c CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; if [ -n \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; ]; then conda env update -p \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; -f '\/var\/azureml-app\/binary_2.yml'; else \n conda env update -n base -f '\/var\/azureml-app\/binary_2.yml'; fi &amp;&amp; conda \nclean \n-aqy &amp;&amp; rm -rf \/root\/.cache\/pip &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find \n&quot;$CONDA_ROOT_DIR&quot; -type d -name __pycache__ -exec rm -rf {} +' returned a \nnon- \n zero code: 255\n 2020\/08\/12 19:36:09 Container failed during run: acb_step_0. No retries \n remaining.\n failed to run step ID: acb_step_0: exit status 255\n<\/code><\/pre>\n<p>**Can anyone please help me **<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":6.0,
        "Question_created_time":1597259959573,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1597261729536,
        "Question_score_count":9.0,
        "Question_view_count":9743.0,
        "Poster_created_time":1426308318630,
        "Poster_location":null,
        "Poster_reputation_count":179.0,
        "Poster_view_count":44.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63383400",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error uninstal ruamel yaml creat docker imag aci deploy try deploi machin learn model azur aci get follow error creat docker imag pip subprocess error error uninstal ruamel yaml distutil instal project accur determin file belong lead partial uninstal yml file pip depend project environ depend python interpret version current support later pip requir packag execut histori data prepar panda default sdk widget numpi tensorflow gpu kera default torch scikit learn post us conda instead pip get follow error step run conda root dir conda info root conda environ path conda env updat conda environ path var app binari yml conda env updat base var app binari yml conda clean aqi root cach pip conda root dir pkg conda root dir type pycach exec run eebbfc munabl instal packag conda doubl check ensur depend file correct spell try instal conda env conda packag provid requir instal mthe command bin conda root dir conda info root conda environ path conda env updat conda environ path var app binari yml conda env updat base var app binari yml conda clean aqi root cach pip conda root dir pkg conda root dir type pycach exec return non zero code contain fail run acb step retri remain fail run step acb step exit statu help",
        "Question_preprocessed_content":"creat docker imag aci deploy try deploi machin learn model azur aci creat docker imag yml file pip depend us conda instead pip help",
        "Question_gpt_summary_original":"The user is encountering an error while creating a docker image for Azure ML ACI deployment. The error message states that 'ruamel-yaml' cannot be uninstalled as it is a distutils installed project. The user has provided a yml file for pip dependencies, but using conda instead of pip results in another error. The user is seeking help to resolve the issue.",
        "Question_gpt_summary":"user encount error creat docker imag aci deploy error messag state ruamel yaml uninstal distutil instal project user provid yml file pip depend conda instead pip result error user seek help resolv issu"
    },
    {
        "Question_title":"Can't change virtual environment within Azure ML notebook",
        "Question_body":"<p>For some reason the jupyter notebooks on my VM are in the wrong environment (ie stuck in <code>(base)<\/code>). Furthermore, I can change the environment in the terminal but not in the notebook. Here is what happens when I attempt <code>!conda activate desired_env<\/code> in the notebook:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\nTo initialize your shell, run\n\n    $ conda init &lt;SHELL_NAME&gt;\n\nCurrently supported shells are:\n  - bash\n  - fish\n  - tcsh\n  - xonsh\n  - zsh\n  - powershell\n\nSee 'conda init --help' for more information and options.\n\nIMPORTANT: You may need to close and restart your shell after running 'conda init'.\n\n\n# conda environments:\n#\nbase                  *  \/anaconda\nazureml_py36             \/anaconda\/envs\/azureml_py36\nazureml_py38             \/anaconda\/envs\/azureml_py38\nazureml_py38_pytorch     \/anaconda\/envs\/azureml_py38_pytorch\nazureml_py38_tensorflow     \/anaconda\/envs\/azureml_py38_tensorflow\n<\/code><\/pre>\n<p>I tried the answers <a href=\"https:\/\/stackoverflow.com\/questions\/61915607\/commandnotfounderror-your-shell-has-not-been-properly-configured-to-use-conda\">here<\/a> (e.g., first running <code>!source \/anaconda\/etc\/profile.d\/conda.sh<\/code>).<\/p>\n<p>I also tried activating the environment using <code>source<\/code> rather than 'conda activate': <code>!source \/anaconda\/envs\/desired_env\/bin\/activate<\/code>. This runs but doesn't actually do anything when I see the current environment in <code>conda env list<\/code><\/p>\n<p>Edit: also adding that if I install a package in the <code>(base)<\/code> environment in the terminal, I still don't have access to it in jupyter notebook.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1636646694700,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1636647028003,
        "Question_score_count":1.0,
        "Question_view_count":672.0,
        "Poster_created_time":1586979502910,
        "Poster_location":null,
        "Poster_reputation_count":361.0,
        "Poster_view_count":47.0,
        "Answer_body":"<p>I'm the PM that released AzureML Notebooks, you can't activate a Conda env from a cell, you have to create a new kernel will the Conda Env. Here are the instructions: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#add-new-kernels\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#add-new-kernels<\/a><\/p>",
        "Answer_comment_count":8.0,
        "Question_closed_time":1636652640790,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1614882423070,
        "Answerer_location":"Seattle, WA, USA",
        "Answerer_reputation_count":111.0,
        "Answerer_view_count":13.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69931411",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"chang virtual environ notebook reason jupyt notebook wrong environ stuck base furthermor chang environ termin notebook happen attempt conda activ desir env notebook commandnotfounderror shell properli configur us conda activ initi shell run conda init current support shell bash fish tcsh xonsh zsh powershel conda init help inform option import need close restart shell run conda init conda environ base anaconda anaconda env anaconda env pytorch anaconda env pytorch tensorflow anaconda env tensorflow tri answer run sourc anaconda profil conda tri activ environ sourc conda activ sourc anaconda env desir env bin activ run actual current environ conda env list edit ad instal packag base environ termin access jupyt notebook",
        "Question_preprocessed_content":"chang virtual environ reason jupyt wrong environ furthermor chang environ termin tri answer tri activ environ conda activ run environ edit packag environ termin jupyt",
        "Question_gpt_summary_original":"The user is unable to change the virtual environment within Azure ML notebook and is stuck in the wrong environment. The user tried changing the environment in the terminal but encountered an error message. The user also tried activating the environment using 'source' but it did not work. Additionally, the user is unable to access packages installed in the (base) environment in the notebook.",
        "Question_gpt_summary":"user unabl chang virtual environ notebook stuck wrong environ user tri chang environ termin encount error messag user tri activ environ sourc work addition user unabl access packag instal base environ notebook"
    },
    {
        "Question_title":"How can I deploy AWS SageMaker Linear Learner Model in a Local Environment",
        "Question_body":"<p>I have trained a AWS SageMaker Model using the in-built Linear Learner algorithm. I can download the trained model artifacts (model.tar.gz) from S3.<\/p>\n\n<p>How can I deploy the model in an local environment which is independent of AWS, so I can make predictions inferences calls without internet access?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1533869148300,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":518.0,
        "Poster_created_time":1533787759288,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51778200",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi linear learner model local environ train model built linear learner algorithm download train model artifact model tar deploi model local environ independ aw predict infer call internet access",
        "Question_preprocessed_content":"deploi linear learner model local environ train model linear learner algorithm download train model artifact deploi model local environ independ aw predict infer internet",
        "Question_gpt_summary_original":"The user has trained an AWS SageMaker Model using the Linear Learner algorithm and downloaded the trained model artifacts from S3. They are now looking for a way to deploy the model in a local environment that is independent of AWS, so they can make prediction inference calls without internet access.",
        "Question_gpt_summary":"user train model linear learner algorithm download train model artifact look wai deploi model local environ independ aw predict infer call internet access"
    },
    {
        "Question_title":"Read bytes file from AWS S3 into AWS SageMaker conda_python3",
        "Question_body":"<p>Good morning,\nYesterday I saved a file from SageMaker conda_python3 to S3 like this:<\/p>\n\n<pre><code>s3 = boto3.client(\n            's3',\n            aws_access_key_id='XXXX',\n            aws_secret_access_key='XXXX'\n        )\ny = pandas.DataFrame(df.tag_factor,index = df.index)\ns3.put_object(Body = y.values.tobytes(), Bucket='xxx', Key='xxx')\n<\/code><\/pre>\n\n<p>Today I am trying to open it with conda_python3 as a pandas.Series or as a numpy.array object, with this code:<\/p>\n\n<pre><code>s3 = boto3.client(\n            's3',\n            aws_access_key_id='XXX',\n            aws_secret_access_key='XXX'\n        )\ny_bytes = s3.get_object(Bucket='xxx', Key='xxx')\ny = numpy.load(io.BytesIO(y_bytes['Body'].read()))\n<\/code><\/pre>\n\n<p>but I am getting this error: OSError: Failed to interpret file &lt;_io.BytesIO >object at 0x7fcb0b403258> as a pickle<\/p>\n\n<p>I tried this:<\/p>\n\n<pre><code>y = numpy.fromfile(io.BytesIO(y_bytes['Body'].read()))\n<\/code><\/pre>\n\n<p>and I get this error:<\/p>\n\n<blockquote>\n  <p>UnsupportedOperation: fileno<\/p>\n<\/blockquote>\n\n<p>I tried this:<\/p>\n\n<pre><code>y = pd.read_csv(io.BytesIO(y_bytes['Body'].read()), sep=\" \", header=None)\n<\/code><\/pre>\n\n<p>and I get this error:<\/p>\n\n<blockquote>\n  <p>EmptyDataError: No columns to parse from file<\/p>\n<\/blockquote>\n\n<p>How can I read this file?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1544802647203,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1605707872200,
        "Question_score_count":1.0,
        "Question_view_count":1398.0,
        "Poster_created_time":1458416707412,
        "Poster_location":"Ecuador, Quito",
        "Poster_reputation_count":617.0,
        "Poster_view_count":117.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53782956",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"read byte file aw conda python good morn yesterdai save file conda python like boto client aw access kei xxxx aw secret access kei xxxx panda datafram tag factor index index object bodi valu tobyt bucket xxx kei xxx todai try open conda python panda seri numpi arrai object code boto client aw access kei xxx aw secret access kei xxx byte object bucket xxx kei xxx numpi load bytesio byte bodi read get error oserror fail interpret file object xfcbb pickl tri numpi fromfil bytesio byte bodi read error unsupportedoper fileno tri read csv bytesio byte bodi read sep header error emptydataerror column pars file read file",
        "Question_preprocessed_content":"read byte file aw morn yesterdai save file like todai try open object code fail interpret file object fcb pickl tri fileno tri column pars file read file",
        "Question_gpt_summary_original":"The user is facing challenges in reading a file from AWS S3 into AWS SageMaker conda_python3 as a pandas.Series or as a numpy.array object. The user has tried different methods such as numpy.fromfile and pd.read_csv but is encountering errors such as OSError, UnsupportedOperation, and EmptyDataError. The user is seeking guidance on how to read the file.",
        "Question_gpt_summary":"user face challeng read file aw conda python panda seri numpi arrai object user tri differ method numpi fromfil read csv encount error oserror unsupportedoper emptydataerror user seek guidanc read file"
    },
    {
        "Question_title":"Interactive Login coming for child run during hyperparameter tuning (hyperdrive) in Azure ML Notebook",
        "Question_body":"<p>I have created a train.py script in Azure and it has the data cleaning, wrangling and classification part using XGBoost. Then I have created a ipynb file to do hyperparameter tuning by calling train.py script.<\/p>\n<p>The child runs keep asking me to perform manual interactive login for every run. Please see the image.\nI did the interactive login for many runs but still it will ask me everytime.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eKutW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eKutW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Here is the code in ipynb file:<\/p>\n<pre><code>subscription_id = 'XXXXXXXXXXXXXXXXXX'\nresource_group = 'XXXXXXXXXXXXXXX'\nworkspace_name = 'XXXXXXXXXXXXXXX'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\nmyenv = Environment(workspace=workspace, name=&quot;myenv&quot;)\n\nfrom azureml.core.conda_dependencies import CondaDependencies\nconda_dep = CondaDependencies()\n\nconda_dep.add_pip_package(&quot;numpy&quot;)\nconda_dep.add_pip_package(&quot;pandas&quot;)\nconda_dep.add_pip_package(&quot;nltk&quot;)\nconda_dep.add_pip_package(&quot;sklearn&quot;)\nconda_dep.add_pip_package(&quot;xgboost&quot;)\n\nmyenv.python.conda_dependencies = conda_dep\n\nexperiment_name = 'experiments_xgboost_hyperparams'\nexperiment = Experiment(workspace, experiment_name)\n\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\n\ncompute_cluster_name = 'shan'\n\ntry:\n    compute_target = ComputeTarget(workspace=workspace, name = compute_cluster_name)\n    print('Found the compute cluster')\n\nexcept ComputeTargetException:\n    compute_config = AmlCompute.provisioning_configuration(vm_size=&quot;STANDARD_DS3_V2&quot;, max_nodes=4)\n    compute_target = ComputeTarget.create(workspace, compute_cluster_name, compute_config)\n    compute_target.wait_for_completion(show_output=True)\n\nearly_termination_policy = BanditPolicy(slack_factor=0.01)\n\nfrom azureml.train.hyperdrive import RandomParameterSampling\nfrom azureml.train.hyperdrive import uniform, choice\nps = RandomParameterSampling( {\n        'learning_rate': uniform(0.1, 0.9),\n        'max_depth': choice(range(3,8)),\n        'n_estimators': choice(300, 400, 500, 600)\n    }\n)\n\nprimary_metric_name=&quot;accuracy&quot;,\nprimary_metric_goal=PrimaryMetricGoal.MAXIMIZE\n\n\n\n from azureml.core import ScriptRunConfig\n    script_run_config = ScriptRunConfig(source_directory='.', script='train.py', compute_target=compute_target, environment=myenv)\n    # script_run_config.run_config.target = compute_target\n    \n    # Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n    hyperdrive_config = HyperDriveConfig(run_config=script_run_config,\n                                        hyperparameter_sampling=ps,\n                                        policy=early_termination_policy,\n                                        primary_metric_name=&quot;accuracy&quot;,\n                                        primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                                        max_total_runs=10,\n                                        max_concurrent_runs=4)\n\nhyperdrive = experiment.submit(config=hyperdrive_config)\n\nRunDetails(hyperdrive).show()\nhyperdrive.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>This just keeps asking me interactive login for every child run.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1613646219407,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1613646463208,
        "Question_score_count":0.0,
        "Question_view_count":157.0,
        "Poster_created_time":1598018883048,
        "Poster_location":null,
        "Poster_reputation_count":77.0,
        "Poster_view_count":35.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66258663",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"interact login come child run hyperparamet tune hyperdr notebook creat train script azur data clean wrangl classif xgboost creat ipynb file hyperparamet tune call train script child run ask perform manual interact login run imag interact login run ask everytim code ipynb file subscript xxxxxxxxxxxxxxxxxx resourc group xxxxxxxxxxxxxxx workspac xxxxxxxxxxxxxxx workspac workspac subscript resourc group workspac myenv environ workspac workspac myenv core conda depend import condadepend conda dep condadepend conda dep add pip packag numpi conda dep add pip packag panda conda dep add pip packag nltk conda dep add pip packag sklearn conda dep add pip packag xgboost myenv python conda depend conda dep experi experi xgboost hyperparam experi experi workspac experi core comput import computetarget amlcomput core comput target import computetargetexcept comput cluster shan try comput target computetarget workspac workspac comput cluster print comput cluster computetargetexcept comput config amlcomput provis configur size standard max node comput target computetarget creat workspac comput cluster comput config comput target wait complet output true earli termin polici banditpolici slack factor train hyperdr import randomparametersampl train hyperdr import uniform choic randomparametersampl learn rate uniform max depth choic rang estim choic primari metric accuraci primari metric goal primarymetricgo maxim core import scriptrunconfig script run config scriptrunconfig sourc directori script train comput target comput target environ myenv script run config run config target comput target creat hyperdriveconfig estim hyperparamet sampler polici hyperdr config hyperdriveconfig run config script run config hyperparamet sampl polici earli termin polici primari metric accuraci primari metric goal primarymetricgo maxim max total run max concurr run hyperdr experi submit config hyperdr config rundetail hyperdr hyperdr wait complet output true keep ask interact login child run",
        "Question_preprocessed_content":"interact login come child run hyperparamet tune creat script azur data clean wrangl creat ipynb file hyperparamet tune script child run ask perform manual interact login run imag interact login run ask everytim code ipynb file ask interact login child run",
        "Question_gpt_summary_original":"The user has created a train.py script in Azure and an ipynb file to do hyperparameter tuning by calling the train.py script. However, the child runs keep asking for manual interactive login for every run, even after performing the interactive login for many runs. The user has shared the code in the ipynb file and is seeking a solution to this issue.",
        "Question_gpt_summary":"user creat train script azur ipynb file hyperparamet tune call train script child run ask manual interact login run perform interact login run user share code ipynb file seek solut issu"
    },
    {
        "Question_title":"SageMaker NodeJS's SDK is not locking the API Version",
        "Question_body":"<p>I am running some code in AWS Lambda that dynamically creates SageMaker models.\nI am locking Sagemaker's API version like so:<\/p>\n\n<p><code>const sagemaker = new AWS.SageMaker({apiVersion: '2017-07-24'});<\/code><\/p>\n\n<p>And here's the code to create the model:<\/p>\n\n<pre><code>await sagemaker.createModel({\n        ExecutionRoleArn: 'xxxxxx',\n        ModelName: sageMakerConfigId,\n        Containers: [{\n            Image: ecrUrl\n        }]\n    }).promise()\n<\/code><\/pre>\n\n<p>This code runs just fine locally with <code>aws-sdk<\/code> on <code>2.418.0<\/code>. <\/p>\n\n<p>However, when this code is deployed to Lambda, it doesn't work due to some validation errors upon creating the model:<\/p>\n\n<blockquote>\n  <ul>\n  <li>MissingRequiredParameter: Missing required key 'PrimaryContainer' in params<\/li>\n  <li>UnexpectedParameter: Unexpected key 'Containers' found in params<\/li>\n  <\/ul>\n<\/blockquote>\n\n<p>Is anyone aware of existing bugs in the <code>aws-sdk<\/code> for NodeJS using the SDK provided by AWS in the Lambda context? I believe the SDK available inside AWS Lambda is more up-to-date than <code>2.418.0<\/code> but apparently there are compatibility issues.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1553074522987,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1553082788147,
        "Question_score_count":1.0,
        "Question_view_count":277.0,
        "Poster_created_time":1548169897263,
        "Poster_location":null,
        "Poster_reputation_count":6496.0,
        "Poster_view_count":759.0,
        "Answer_body":"<p>As you've noticed the 'embedded' lambda version of the aws-sdk lags behind. It's actually on <code>2.290.0<\/code> (you can see the full details on the environment here: <a href=\"https:\/\/docs.aws.amazon.com\/lambda\/latest\/dg\/current-supported-versions.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/lambda\/latest\/dg\/current-supported-versions.html<\/a>)<\/p>\n\n<p>You can see here: <a href=\"https:\/\/github.com\/aws\/aws-sdk-js\/blame\/master\/clients\/sagemaker.d.ts\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/aws-sdk-js\/blame\/master\/clients\/sagemaker.d.ts<\/a> that it is not until <code>2.366.0<\/code> that the params for this method included <code>Containers<\/code> and did not require <code>PrimaryContainer<\/code>.<\/p>\n\n<p>As you've noted, the <em>workaround<\/em> is to deploy your lambda with the <code>aws-sdk<\/code> version that you're using. This is sometimes noted as a best practice, as it pins the <code>aws-sdk<\/code> on the functionality you've built and tested against.<\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1553117574836,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1372408547912,
        "Answerer_location":"Farnborough, United Kingdom",
        "Answerer_reputation_count":7360.0,
        "Answerer_view_count":372.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55257580",
        "Tool":"Amazon SageMaker",
        "Question_self_closed":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"nodej sdk lock api version run code aw lambda dynam creat model lock api version like const new aw apivers code creat model await createmodel executionrolearn xxxxxx modelnam configid contain imag ecrurl promis code run fine local aw sdk code deploi lambda work valid error creat model missingrequiredparamet miss requir kei primarycontain param unexpectedparamet unexpect kei contain param awar exist bug aw sdk nodej sdk provid aw lambda context believ sdk avail insid aw lambda date appar compat issu",
        "Question_preprocessed_content":"nodej sdk lock api version code aw lambda creat model lock api version like code creat model code run fine code deploi lambda work valid creat model requir kei primarycontain param unexpectedparamet unexpect kei contain param awar exist bug nodej sdk provid aw lambda context believ sdk avail insid aw lambda compat",
        "Question_gpt_summary_original":"The user is facing compatibility issues while using SageMaker NodeJS's SDK in AWS Lambda. The code runs fine locally but fails to create a model in Lambda due to validation errors. The user suspects that the SDK provided by AWS in the Lambda context is more up-to-date than the version used locally, causing compatibility issues.",
        "Question_gpt_summary":"user face compat issu nodej sdk aw lambda code run fine local fail creat model lambda valid error user suspect sdk provid aw lambda context date version local caus compat issu"
    },
    {
        "Question_title":"Azure ML doesn't let me use notebooks",
        "Question_body":"<p>I am going into my notebooks portal on one of my expiriments, and it says,&quot;The current subscription state does not allow this operation.&quot; It worked yesterday, but why not today?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1610372674263,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/226106\/azure-ml-doesnt-let-me-use-notebooks",
        "Tool":"Azure Machine Learning",
        "Question_self_closed":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"let us notebook go notebook portal expiri sai current subscript state allow oper work yesterdai todai",
        "Question_preprocessed_content":"let us go portal expiri sai subscript state work yesterdai todai",
        "Question_gpt_summary_original":"The user is unable to use notebooks on Azure ML due to a subscription state error message that says \"The current subscription state does not allow this operation.\" The user is wondering why this error occurred as it was working fine the previous day.",
        "Question_gpt_summary":"user unabl us notebook subscript state error messag sai current subscript state allow oper user wonder error occur work fine previou dai"
    }
]