[
    {
        "Question_title":"Optuna - what is a suitable metric for TFKerasPruningCallback?",
        "Question_body":"<p>I've been using optuna to perform a hyperparameter search for a Keras neural network model (using scikit-learn's wrapper, KerasRegressor). I have been trying to implement the TFKerasPruningCallback function to prune unpromising trials, but keep getting the following error: <code>UserWarning: The metric 'val_accuracy' is not in the evaluation logs for pruning. Please make sure you set the correct metric name.<\/code><\/p>\n<p>A recommended metric provided in the <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.integration.TFKerasPruningCallback.html\" rel=\"nofollow noreferrer\">docs<\/a> is 'val_acc', or 'val_accuracy' for tensorflow version &gt; 2 as shown in <a href=\"https:\/\/github.com\/optuna\/optuna-examples\/blob\/main\/tfkeras\/tfkeras_integration.py#L90\" rel=\"nofollow noreferrer\">this example<\/a>. I'm using v2.9.1.<\/p>\n<p>Here's a simplified version of my code:<\/p>\n<pre><code>    def nn(n_layers, neurons):\n    \n        model = Sequential()\n        model.add(Dense(neurons, input_dim=3, activation='relu'))\n        model.add(Dense(1, activation='linear'))\n        model.compile(loss='mean_absolute_error', optimizer='Adam')\n    \n        return model\n    \n    \n    def objective(trial, X_train, y_train):\n    \n        # callbacks\n        cb =  [TFKerasPruningCallback(trial,'val_accuracy')]\n            \n        params =  {'neurons': trial.suggest_int('neurons', 1, 10, 1),\n                   'batch_size': trial.suggest_int('batch_size', 10, 200, 10),\n                   'epochs': trial.suggest_int('epochs', 100, 500, 20),\n                   'callbacks': cb}\n    \n        # create model and perform cross-validation\n        model = KerasRegressor(model=nn, **params)\n        score = np.mean(cross_val_score(model, X_train, y_train, cv=5,\n                                        scoring='neg_root_mean_squared_error'))\n    \n        return score\n\n    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(n_startup_trials=5))\n    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=100)\n<\/code><\/pre>\n<p>Everything works fine if I don't bother to implement the callback. I haven't found any reports of this issue so it might be something really silly that I've overlooked, but I'm stuck. Any advice?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1655383902150,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":61.0,
        "Poster_created_time":1655375540670,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72646172",
        "Tool":"Optuna",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"suitabl metric tfkeraspruningcallback perform hyperparamet search kera neural network model scikit learn wrapper kerasregressor try implement tfkeraspruningcallback function prune unpromis trial get follow error userwarn metric val accuraci evalu log prune sure set correct metric recommend metric provid doc val acc val accuraci tensorflow version shown exampl simplifi version code def layer neuron model sequenti model add dens neuron input dim activ relu model add dens activ linear model compil loss mean absolut error optim adam return model def object trial train train callback tfkeraspruningcallback trial val accuraci param neuron trial suggest int neuron batch size trial suggest int batch size epoch trial suggest int epoch callback creat model perform cross valid model kerasregressor model param score mean cross val score model train train score neg root mean squar error return score studi creat studi direct maxim pruner pruner medianprun startup trial studi optim lambda trial object trial train train trial work fine bother implement callback haven report issu silli overlook stuck advic",
        "Question_preprocessed_content":"suitabl metric perform hyperparamet search kera neural network model try implement function prune unpromis trial metric provid doc tensorflow version shown exampl simplifi version code work fine bother implement haven report stuck advic",
        "Question_gpt_summary_original":"The user is using Optuna for hyperparameter search in a Keras neural network model and is trying to implement the TFKerasPruningCallback function to prune unpromising trials. However, they are getting an error message stating that the metric 'val_accuracy' is not in the evaluation logs for pruning. The recommended metric provided in the Optuna documentation is 'val_acc' or 'val_accuracy' for TensorFlow version > 2. The user has provided a simplified version of their code and is seeking advice on how to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Does MLFLOW supports CNNs ike yolo and unet running on NVIDIA tao platform",
        "Question_body":"Hi, we are a company working in the field of computer vision and would like to make sure that the MLFLOW experiment management platform fits our needs and workflow.\n\nWe work with image processing\u00a0 CNNs like Yolo, UNET, and RetinaNet based on an NVIDIA TAO framework.\u00a0\n\nWhat we actually need is a tool that concentrates on one place (in a nice and representative way comfortable for comparison) at least the three following things for each experiment:\n\n\na- chosen by user typical meta parameters that were used to train a network (such as batches, subdivisions, max batches, etc)\n\nb- a link to the dataset the network was trained on, located on our cloud storage (such as one-drive, google drive or google cloud) or a list of filenames or a link to a file storage cloud or online drive suggested by your service if there is such a thing.\n\nc- a result of running the trained network - the number of detected objects\n\nThank you very much",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1663470424000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":38.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/BjkpwrXLXPM",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"support cnn ik yolo unet run nvidia tao platform compani work field vision like sure experi manag platform fit need workflow work imag process cnn like yolo unet retinanet base nvidia tao framework actual need tool concentr place nice repres wai comfort comparison follow thing experi chosen user typic meta paramet train network batch subdivis max batch link dataset network train locat cloud storag drive googl drive googl cloud list filenam link file storag cloud onlin drive suggest servic thing result run train network number detect object thank",
        "Question_preprocessed_content":"ik yolo unet nvidia tao platform compani work field vision like sure experi manag platform fit workflow work imag like yolo unet retinanet base nvidia tao framework concentr place thing experi chosen user typic meta paramet train network link dataset network train locat cloud storag list filenam link file storag cloud onlin drive servic thing result train network number detect object thank",
        "Question_gpt_summary_original":"The user is a company working in computer vision and wants to know if MLFLOW experiment management platform supports CNNs like Yolo and UNET running on NVIDIA TAO platform. They need a tool that can provide meta parameters used to train a network, a link to the dataset used for training, and the number of detected objects for each experiment.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Defining routes in MLflow serving",
        "Question_body":"<p>When we serve mlflow model we define different ports for each serving and to access these models we use IP:port\/invocations<\/p>\n<p>ex:<\/p>\n<p>app 1 : IP:2020\/invocations<\/p>\n<p>app 2 : IP:2021\/invocations<\/p>\n<p>But I want to serve 2 mlflow models at same port with different routes.<\/p>\n<p>ex:<\/p>\n<p>app 1 : IP:2020\/app1<\/p>\n<p>app 2 : IP:2020\/app2<\/p>\n<p>How can I achieve it using MLflow.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1640763158347,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1640842613347,
        "Question_score_count":0.0,
        "Question_view_count":56.0,
        "Poster_created_time":1504498312456,
        "Poster_location":null,
        "Poster_reputation_count":334.0,
        "Poster_view_count":24.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70516388",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"defin rout serv serv model defin differ port serv access model us port invoc app invoc app invoc want serv model port differ rout app app app app achiev",
        "Question_preprocessed_content":"defin rout serv serv model defin port serv model us want serv model port rout achiev",
        "Question_gpt_summary_original":"The user is trying to serve two MLflow models on the same port with different routes, but is unsure how to achieve this using MLflow.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Unable to access data from S3 bucket to jupyter notebook of aws sagemaker",
        "Question_body":"<p>I need to train a model on aws sagemaker. I'm unable to access data in Jupiter notebook of sagemaker from S3 bucket. My bucket name is &quot;riceleaf&quot; there are four folders in the bucket named as s1,s2,s3,s4 and each folder contains 330 images named as 1.jpg and so on. It is created in Us-east zone. Bucket is private.<\/p>\n<p>One way i did was to access the object and when i displayed the key it shows me 1.jpg and so on. But when i try to open that image it didn't work. So i think I'm unable to get exact data path.<\/p>\n<p>In my code I need exact data path since I'm doing some random data generation in the code so need to access different folders. Therefore, I need a path till bucket so i can change next folder name and image name randomly in my code.<\/p>\n<p>Please help me to so that I can access the images in the Jupiter notebook of sagemaker.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1647841162080,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1647863096848,
        "Question_score_count":0.0,
        "Question_view_count":733.0,
        "Poster_created_time":1647840996452,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71553217",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl access data bucket jupyt notebook need train model unabl access data jupit notebook bucket bucket riceleaf folder bucket name folder contain imag name jpg creat east zone bucket privat wai access object displai kei show jpg try open imag work think unabl exact data path code need exact data path random data gener code need access differ folder need path till bucket chang folder imag randomli code help access imag jupit notebook",
        "Question_preprocessed_content":"unabl data bucket jupyt train model unabl data jupit bucket bucket riceleaf folder bucket name folder contain imag name creat zone bucket privat wai object displai kei show try open imag work think unabl exact data path code exact data path random data gener code folder path bucket chang folder imag randomli code help imag jupit",
        "Question_gpt_summary_original":"The user is facing challenges in accessing data from an S3 bucket to a Jupyter notebook of AWS Sagemaker. The bucket contains four folders with 330 images each, and the user needs to access different folders for random data generation in their code. The user has tried accessing the object, but it did not work, and they need help in getting the exact data path to access the images in the Jupyter notebook.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Test data after deploying model",
        "Question_body":"<p>Hello,<\/p>\n<p>We are deploying our model built locally to Azure Machine Learning resource. The model was successfully registered and deployed.<\/p>\n<p>We are now trying to test the model but keeping getting different errors such as:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;MLMain.py&quot;, line 248, in &lt;module&gt;\n    test = bytes(test, encoding='utf8')\n<\/code><\/pre>\n<p>and<\/p>\n<pre><code>TypeError: encoding without a string argument\nInference result = float() argument must be a string or a number, not 'dict'\n<\/code><\/pre>\n<p>Our MLMain.py looks like:<\/p>\n<pre><code>........\n\nprint('************ REGISTER MODEL ******\\n')\n    model = run.register_model(model_name='TempModel',\n                       tags={'Temp': 'SelfTrainingClassifier'},\n                       model_path='outputs\/TempModel.pkl')\n    print(model.name, model.id, model.version, sep='\\t')\n\n    print('************ DEPLOY MODEL ******\\n')\n    service_name = 'test123'\n    #aks_target = AksCompute(workspace,&quot;testCompute&quot;)\n    deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                                           memory_gb = 1)\n\n    #env.python.conda_dependencies.add_pip_package(&quot;inference-schema[numpy-support]&quot;)\n    #env.python.conda_dependencies.save_to_file(&quot;.&quot;, &quot;myenv.yml&quot;)\n    inference_config = InferenceConfig(entry_script=&quot;.\/TempModel\/score.py&quot;,\n                                   environment=env)\n\n    service = Model.deploy(workspace, service_name, [model], inference_config, deployment_config)\n    service.wait_for_deployment(show_output = True)\n    print(service.state)\n    print(service.scoring_uri)\n\n\n    print('*********** TEST MODEL *****\\n')\n    test = {\n    &quot;data&quot;:   [[177,44]]\n    }\n\n    test = bytes(test, encoding='utf8')\n    y_hat = service.run(input_data=test)\n<\/code><\/pre>\n<p>The score.py looks like:<\/p>\n<pre><code>def run(data):\n    try:\n        data = np.array(json.loads(data))\n        result = model.predict(data)\n        # You can return any data type, as long as it is JSON serializable.\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<p>When we run the model locally we are able to predict on:<\/p>\n<pre><code>loaded_model = pickle.load(open('self_training_model5.pkl', 'rb'))\n\nresult = loaded_model.predict([[177,89]])\n<\/code><\/pre>\n<p>Any ideas would be great.  <br \/>\nThanks so much!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1619200443810,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/369813\/test-data-after-deploying-model",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"test data deploi model hello deploi model built local resourc model successfulli regist deploi try test model keep get differ error traceback recent file mlmain line test byte test encod utf typeerror encod string argument infer result float argument string number dict mlmain look like print regist model model run regist model model tempmodel tag temp selftrainingclassifi model path output tempmodel pkl print model model model version sep print deploi model servic test ak target akscomput workspac testcomput deploy config aciwebservic deploi configur cpu core memori env python conda depend add pip packag infer schema numpi support env python conda depend save file myenv yml infer config inferenceconfig entri script tempmodel score environ env servic model deploi workspac servic model infer config deploy config servic wait deploy output true print servic state print servic score uri print test model test data test byte test encod utf hat servic run input data test score look like def run data try data arrai json load data result model predict data return data type long json serializ return result tolist except error str return error run model local abl predict load model pickl load open self train model pkl result load model predict idea great thank",
        "Question_preprocessed_content":"test data deploi model deploi model built resourc model regist deploi try test model like like run model abl predict idea great thank",
        "Question_gpt_summary_original":"The user has successfully registered and deployed their model to Azure Machine Learning resource, but is facing errors while testing the model. The errors include \"encoding without a string argument\" and \"Inference result = float() argument must be a string or a number, not 'dict'\". The user has shared their MLMain.py and score.py files and is seeking help to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Hyperparameter search with HyperDriveConfig for ReinforcementLearningEstimator",
        "Question_body":"<p>Hello,   <\/p>\n<p>I would like to automatize Hyperparameter search for my Reinforcement Learning training jobs.  <br \/>\nIn my understanding the workflow can be written as  <\/p>\n<pre><code>training_estimator = rl.ReinforcementLearningEstimator(\n        source_directory='.\/src',\n        entry_script=entry_script,\n        script_params=script_params,\n        compute_target=compute_target,\n        rl_framework=rl.Ray(),\n        environment=env_settings)\n\n    grid_sampling = hyperdrive.GridParameterSampling(parameter_space={'lr': hyperdrive.choice([0.007, 0.005])})\n\n    hd_config = hyperdrive.HyperDriveConfig(estimator=training_estimator,\n                                            hyperparameter_sampling=grid_sampling,\n                                            policy=early_termination_policy,\n                                            primary_metric_name=&quot;episode_reward_mean&quot;,\n                                            primary_metric_goal=hyperdrive.PrimaryMetricGoal.MAXIMIZE,\n                                            max_total_runs=100,\n                                            max_concurrent_runs=4)\n\n    run = exp.submit(hd_config)\n<\/code><\/pre>\n<p>However, this gets rejected because <code>ReinforcementLearningEstimator<\/code> does not implement <code>MMLBaseEstimator<\/code>.  <\/p>\n<p>Is there any trick that I'm missing or this use case isn't supported by Azure?  <\/p>\n<p><strong>EDIT:<\/strong>  <\/p>\n<p>This code fails with the following error message  <\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;hyperdriverun.py&quot;, line 188, in &lt;module&gt;\n    run = exp.submit(hd_config)\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/core\/experiment.py&quot;, line 220, in submit\n    run = submit_func(config, self.workspace, self.name, **kwargs)\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/_search.py&quot;, line 145, in search\n    telemetry_values, activity_logger, **kwargs)\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/_search.py&quot;, line 38, in _create_experiment_dto\n    platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 672, in _get_platform_config\n    platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n  File &quot;\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py&quot;, line 684, in _get_platform_config_data_from_run_config\n    run_config = get_run_config_from_script_run(self.estimator._get_script_run_config())\nAttributeError: 'ReinforcementLearningEstimator' object has no attribute '_get_script_run_config'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1624459443980,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/448819\/hyperparameter-search-with-hyperdriveconfig-for-re",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"hyperparamet search hyperdriveconfig reinforcementlearningestim hello like automat hyperparamet search reinforc learn train job understand workflow written train estim reinforcementlearningestim sourc directori src entri script entri script script param script param comput target comput target framework rai environ env set grid sampl hyperdr gridparametersampl paramet space hyperdr choic config hyperdr hyperdriveconfig estim train estim hyperparamet sampl grid sampl polici earli termin polici primari metric episod reward mean primari metric goal hyperdr primarymetricgo maxim max total run max concurr run run exp submit config get reject reinforcementlearningestim implement mmlbaseestim trick miss us case isn support azur edit code fail follow error messag traceback recent file hyperdriverun line run exp submit config file home python site packag core experi line submit run submit func config self workspac self kwarg file home python site packag train hyperdr search line search telemetri valu activ logger kwarg file home python site packag train hyperdr search line creat experi dto platform config hyperdr config platform config workspac experi kwarg file home python site packag train hyperdr runconfig line platform config platform config updat self platform config data run config workspac file home python site packag train hyperdr runconfig line platform config data run config run config run config script run self estim script run config attributeerror reinforcementlearningestim object attribut script run config",
        "Question_preprocessed_content":"hyperparamet search hyperdriveconfig reinforcementlearningestim like automat hyperparamet search reinforc learn train job understand workflow get reject implement trick us case isn azur edit code fail",
        "Question_gpt_summary_original":"The user is attempting to automate hyperparameter search for their Reinforcement Learning training jobs using HyperDriveConfig, but their code is being rejected because ReinforcementLearningEstimator does not implement MMLBaseEstimator. The user is asking if there is a trick they are missing or if this use case is not supported by Azure. Additionally, the user has provided an error message that they are encountering.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"DocAI - Form Processor table issue",
        "Question_body":"Hello,\nI used Document AI form processor to convert pdf file table data into table object.\nSome table data are not converted properly.\n\nIn the sample file, the 3rd table is not detected columns properly.\nCould you please throw some light on this ?\n\nSource PDF file\n\nAfter conversion using form processor. The third one is having issue on column detection.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1669240800000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":138.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/DocAI-Form-Processor-table-issue\/m-p\/492493#M856",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"docai form processor tabl issu hello document form processor convert pdf file tabl data tabl object tabl data convert properli sampl file tabl detect column properli throw light sourc pdf file convers form processor have issu column detect",
        "Question_preprocessed_content":"docai form tabl document form convert pdf file tabl data tabl object tabl data convert properli sampl file tabl detect column properli throw light sourc pdf file convers form have column detect",
        "Question_gpt_summary_original":"The user encountered an issue with the DocAI Form Processor where some table data was not converted properly, specifically the third table in the provided PDF file was not detected with proper column detection. The user is seeking assistance to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to get image classification prediction from GCP AIPlatform in ruby?",
        "Question_body":"<p>I'm new with ruby and I want to use GCP AIPlatform but I'm struggeling with the payload.<\/p>\n<p>So far, I have :<\/p>\n<pre class=\"lang-rb prettyprint-override\"><code>client = ::Google::Cloud::AIPlatform::V1::PredictionService::Client.new do |config|\n  config.endpoint = &quot;#{location}-aiplatform.googleapis.com&quot;\nend\n\nimg = File.open(imgPath, 'rb') do |img|\n  'data:image\/png;base64,' + Base64.strict_encode64(img.read)\nend\n\ninstance = Instance.new(:content =&gt; img)\n\nrequest = Google::Cloud::AIPlatform::V1::PredictRequest.new(\n  endpoint: &quot;projects\/#{project}\/locations\/#{location}\/endpoints\/#{endpoint}&quot;,\n  instances: [instance]\n)\n\nresult = client.predict request\np result\n<\/code><\/pre>\n<p>Here is my proto<\/p>\n<pre><code>message Instance {\n  required bytes content = 1;\n};\n<\/code><\/pre>\n<p>But I have the following error : <code>Invalid type Instance to assign to submessage field 'instances'<\/code><\/p>\n<p>I read the documentation but for ruby SDK it's a bit light.\nThe parameters are OK, the JS example here : <a href=\"https:\/\/github.com\/googleapis\/nodejs-ai-platform\/blob\/main\/samples\/predict-image-object-detection.js\" rel=\"nofollow noreferrer\">https:\/\/github.com\/googleapis\/nodejs-ai-platform\/blob\/main\/samples\/predict-image-object-detection.js<\/a> is working with those parameters<\/p>\n<p>What am I doing wrong ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1656671602857,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":54.0,
        "Poster_created_time":1656670919183,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":"<p>I managed it<\/p>\n<pre class=\"lang-rb prettyprint-override\"><code>client = Google::Cloud::AIPlatform::V1::PredictionService::Client.new do |config|\n  config.endpoint = &quot;#{location}-aiplatform.googleapis.com&quot;\nend\n\nimg = File.open(imgPath, 'rb') do |img|\n  Base64.strict_encode64(img.read)\nend\n\ninstance = Google::Protobuf::Value.new(:struct_value =&gt; {:fields =&gt; {\n  :content =&gt; {:string_value =&gt; img}\n}})\nendpoint = &quot;projects\/#{project}\/locations\/#{location}\/endpoints\/#{endpoint}&quot;\n\n\nrequest = Google::Cloud::AIPlatform::V1::PredictRequest.new(\n  endpoint: endpoint,\n  instances: [instance]\n)\n\nresult = client.predict request\np result\n<\/code><\/pre>\n<p>The use of the Google::Protobuf::Value looks ugly to me but it works<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1656947266916,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1656670919183,
        "Answerer_location":null,
        "Answerer_reputation_count":1.0,
        "Answerer_view_count":2.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72827960",
        "Tool":"Vertex AI",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"imag classif predict gcp aiplatform rubi new rubi want us gcp aiplatform struggel payload far client googl cloud aiplatform predictionservic client new config config endpoint locat aiplatform googleapi com end img file open imgpath img data imag png base base strict encod img read end instanc instanc new content img request googl cloud aiplatform predictrequest new endpoint project project locat locat endpoint endpoint instanc instanc result client predict request result proto messag instanc requir byte content follow error invalid type instanc assign submessag field instanc read document rubi sdk bit light paramet exampl http github com googleapi nodej platform blob main sampl predict imag object detect work paramet wrong",
        "Question_preprocessed_content":"imag predict gcp aiplatform rubi new rubi want us gcp aiplatform payload far proto read document rubi sdk bit light paramet exampl work paramet wrong",
        "Question_gpt_summary_original":"The user is new to Ruby and is trying to use GCP AIPlatform for image classification prediction. They are struggling with the payload and are encountering an error message \"Invalid type Instance to assign to submessage field 'instances'\". The user has provided their code and proto and is seeking help to identify the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Why are shh keys lost on reboot of AWS ec2 instance (sage maker)?",
        "Question_body":"<p>I have an AWS SageMaker notebook running some ML stuff for work, and I have a private github repo with some of my commonly used functions which is formatted in such a way to be pip install-able, so I set up an SSH key by doing this:<\/p>\n<pre><code>ssh-keygen \n\n-t rsa -b 4096 -C &quot;danielwarfield1@gmail.com&quot;\n<\/code><\/pre>\n<p>enter, enter, enter (default save location no password)<\/p>\n<pre><code>eval $(ssh-agent -s)\nssh-add ~\/.ssh\/id_rs\n<\/code><\/pre>\n<p>then I copy the public key into github, then I run this to install my library<\/p>\n<pre><code>$PWD\/pip install git+ssh:\/\/git@github.com\/...\n<\/code><\/pre>\n<p>where <code>$PWD<\/code> is the directory containing pip for the conda env I'm using (tensorflow2_p36 specifically, the one that AWS provides)<\/p>\n<p>this works fine, until I restart the EC2, then it appears my shh key (along with all my other installs) are lost, and I have to repeat the process. I expect the modules to be lost, I know SageMaker manages the environments, but me loosing my ssh key seems peculiar, is there a place I can save my ssh key wher it wont get lost, but I can still find it when I pip install?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1596230563253,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":278.0,
        "Poster_created_time":1545360696800,
        "Poster_location":"Earth",
        "Poster_reputation_count":1011.0,
        "Poster_view_count":93.0,
        "Answer_body":"<p>The <code>\/home\/ec2-user\/SageMaker<\/code> location is persisted even when you switch down the notebook instance, you can try saving things here to get them persisted. Things saved elsewhere will be lost when you switch off the instance<\/p>\n<p>Regarding private git integration, you can use the <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/nbi-git-repo.html\" rel=\"nofollow noreferrer\">SageMaker git Notebook integration<\/a>, which uses Secrets Manager to safely handle your credentials<\/p>\n<p>You can perform steps automatically when the notebook starts with a <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/notebook-lifecycle-config.html\" rel=\"nofollow noreferrer\">lifecycle configuration<\/a>. This is useful for example to standardise and automatise copying of data and environment customization<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1596232881236,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1442180190107,
        "Answerer_location":null,
        "Answerer_reputation_count":3203.0,
        "Answerer_view_count":400.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63199239",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"shh kei lost reboot aw instanc sage maker notebook run stuff work privat github repo commonli function format wai pip instal abl set ssh kei ssh keygen rsa danielwarfield gmail com enter enter enter default save locat password eval ssh agent ssh add ssh copi public kei github run instal librari pwd pip instal git ssh git github com pwd directori contain pip conda env tensorflow specif aw provid work fine restart appear shh kei instal lost repeat process expect modul lost know manag environ loos ssh kei peculiar place save ssh kei wher wont lost pip instal",
        "Question_preprocessed_content":"kei lost aw instanc work privat github repo function wai pip abl set kei enter enter enter copi public kei github run librari directori contain pip conda env work fine restart kei lost repeat expect modul lost know manag environ kei peculiar place save kei wher wont lost pip",
        "Question_gpt_summary_original":"The user is facing an issue with losing their SSH key on reboot of their AWS SageMaker notebook instance, which is affecting their ability to install commonly used functions from a private GitHub repo. They have tried setting up the SSH key and copying the public key into GitHub, but the key is lost on reboot, along with all other installs. The user is seeking a solution to save their SSH key in a place where it won't get lost but can still be found when pip installing.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How do I get the experimentID inside a running pipeline script?",
        "Question_body":"<p>Hello, I'm writing a ML pipeline.  <\/p>\n<p>At the end of a script I have to write the output to a SQL database, and I would need the ExperimentID as a field of the output dataframe.  <\/p>\n<p>Is there a way for me to find within the running script in which experiment it's being run?  <br \/>\nOr is there a way for me to input the ExperimentID as a parameter to the pipeline at launch? From what I understand parameters are defined before the experiment is created so that's a bit confusing.  <\/p>\n<p>In case this is too complicated, is there a way I can somehow chain the pipeline output inside a script to the experiment it's being run?   <\/p>\n<p>Thank you very much,<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1638292741140,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/646416\/how-do-i-get-the-experimentid-inside-a-running-pip",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"experimentid insid run pipelin script hello write pipelin end script write output sql databas need experimentid field output datafram wai run script experi run wai input experimentid paramet pipelin launch understand paramet defin experi creat bit confus case complic wai chain pipelin output insid script experi run thank",
        "Question_preprocessed_content":"experimentid insid pipelin script write pipelin end script write output sql databas experimentid field output datafram wai script experi run wai input experimentid paramet pipelin launch understand paramet defin experi creat bit confus case complic wai chain pipelin output insid script experi run thank",
        "Question_gpt_summary_original":"The user is writing an ML pipeline and needs to write the output to a SQL database with the ExperimentID as a field of the output dataframe. They are looking for a way to find the ExperimentID within the running script or input it as a parameter at launch. They are also asking if there is a way to chain the pipeline output inside a script to the experiment it's being run.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"InvalidContentLength The input image is too large. Refer to documentation for the maximum file size. JPEG 5MB",
        "Question_body":"<p>Hi,   <br \/>\nI have been having this issue with JPEG files since Studio launched. On 2.1-preview it is working fine, but with newer API I am getting image too large error.  <br \/>\nI have tried changing between JPEG\/JPG\/Bitmap and such files. Also cropping the image to less than 5MB, but the issue seems to persist. From documentation max file size is 50MB, this is 1 page, 5MB 3000x4000 pixel image.  <br \/>\nTried analyzing with studio and through REST API, still same error.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":5.0,
        "Question_created_time":1647524366683,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/776406\/invalidcontentlength-the-input-image-is-too-large",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"invalidcontentlength input imag larg refer document maximum file size jpeg have issu jpeg file studio launch preview work fine newer api get imag larg error tri chang jpeg jpg bitmap file crop imag issu persist document max file size page pixel imag tri analyz studio rest api error",
        "Question_preprocessed_content":"invalidcontentlength input imag larg refer document maximum file size jpeg have jpeg file studio launch work fine newer api imag larg tri chang file imag persist document max file size page pixel imag tri analyz studio rest api",
        "Question_gpt_summary_original":"The user is encountering an \"InvalidContentLength\" error while trying to upload a JPEG image that is less than 5MB in size. The issue persists even after trying different file formats and cropping the image. The maximum file size mentioned in the documentation is 50MB.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"What value should I set for directory_path for the Amazon SageMaker SDK with FSx as data source?",
        "Question_body":"What value should I set for the **directory_path** parameter in **FileSystemInput** for the Amazon SageMaker SDK?\n\nHere is some information about my Amazon FSx for Lustre file system:\n - My FSx ID is `fs-0684xxxxxxxxxxx`.\n - My FSx has the mount name `lhskdbmv`.\n - The FSx maps to an Amazon S3 bucket with files (without extra prefixes in their keys)\n\nMy attempts to describe the job and the results are the following:\n\n**Attempt 1:**\n\n    fs = FileSystemInput(\n        file_system_id='fs-0684xxxxxxxxxxx',\n        file_system_type='FSxLustre',\n        directory_path='lhskdbmv',\n        file_system_access_mode='ro')\n\n**Result:**\n\n`estimator.fit(fs)` returns `ClientError: An error occurred (ValidationException) when calling the CreateTrainingJob operation: FileSystem DirectoryPath 'lhskdbmv' for channel 'training' is not absolute or normalized. Please ensure you don't have a trailing \"\/\", and\/or \"..\", \".\", \"\/\/\" in the path.`\n\n**Attempt 2:**\n\n    fs = FileSystemInput(\n        file_system_id='fs-0684xxxxxxxxxxx',\n        file_system_type='FSxLustre',\n        directory_path='\/',\n        file_system_access_mode='ro')\n\n**Result:**\n\n`ClientError: An error occurred (ValidationException) when calling the CreateTrainingJob operation: The directory path for FSx Lustre file system fs-068406952bf758bac is invalid. The directory path must begin with mount name of the file system.`\n\n**Attempt 3:**\n\n    fs = FileSystemInput(\n        file_system_id='fs-0684xxxxxxxxxxx',\n        file_system_type='FSxLustre',\n        directory_path='fsx',\n        file_system_access_mode='ro')\n\n**Result:**\n\nClientError: An error occurred (ValidationException) when calling the CreateTrainingJob operation: FileSystem DirectoryPath 'fsx' for channel 'training' is not absolute or normalized. Please ensure you don't have a trailing \"\/\", and\/or \"..\", \".\", \"\/\/\" in the path.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1605283057000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668165980160,
        "Question_score_count":1.0,
        "Question_view_count":272.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"The **directory_path** parameter must point to \/**mountname**\/path\/to\/specific\/folder\/in-file-system. The value of mountname is returned in the CreateFileSystem API operation response. It is also returned in the response of the describe-file-systems AWS Command Line Interface (AWS CLI) command and the DescribeFileSystems API operation. \n\nFor your use case,  the response might look similar to the following:\n```mountName = lhskdbmv```",
        "Answer_comment_count":0.0,
        "Question_closed_time":1605296508000,
        "Answer_last_edit_time":1667925582735,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUHaScKqcfRu-aZ1Cwza63NQ\/what-value-should-i-set-for-directory-path-for-the-amazon-sagemaker-sdk-with-fsx-as-data-source",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":1.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"valu set directori path sdk fsx data sourc valu set directori path paramet filesysteminput sdk inform amazon fsx lustr file fsx xxxxxxxxxxx fsx mount lhskdbmv fsx map amazon bucket file extra prefix kei attempt job result follow attempt filesysteminput file xxxxxxxxxxx file type fsxlustr directori path lhskdbmv file access mode result estim fit return clienterror error occur validationexcept call createtrainingjob oper filesystem directorypath lhskdbmv channel train absolut normal ensur trail path attempt filesysteminput file xxxxxxxxxxx file type fsxlustr directori path file access mode result clienterror error occur validationexcept call createtrainingjob oper directori path fsx lustr file bfbac invalid directori path begin mount file attempt filesysteminput file xxxxxxxxxxx file type fsxlustr directori path fsx file access mode result clienterror error occur validationexcept call createtrainingjob oper filesystem directorypath fsx channel train absolut normal ensur trail path",
        "Question_preprocessed_content":"valu set sdk fsx data sourc valu set paramet filesysteminput sdk inform amazon fsx lustr file fsx fsx mount fsx map amazon bucket file job result filesysteminput result return filesysteminput result filesysteminput result createtrainingjob oper filesystem directorypath fsx train absolut normal ensur trail path",
        "Question_gpt_summary_original":"The user is trying to set the directory_path parameter in FileSystemInput for the Amazon SageMaker SDK with FSx as the data source. However, the user is encountering errors while attempting to set the value for directory_path. The attempts made by the user and the corresponding errors encountered have been described in the post.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to alter shared memory for SageMaker Docker containers?",
        "Question_body":"<p>I have a Docker image in Elastic Container Registry (ECR). It was created via a simple Dockerfile which I have control over.<\/p>\n<p>The image itself is fine, but I have a problem where the shared memory is insufficient when working inside a container in SageMaker Studio. Therefore I need to raise the shared memory of these containers.<\/p>\n<p>To raise the shared memory of a container, I believe the usual method is to pass the <code>--shm-size<\/code> argument to the <code>docker run<\/code> command when starting the container. However, I do not have control over this command, as SageMaker is doing that bit for me. The <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms-training-algo-dockerfile.html\" rel=\"nofollow noreferrer\">docs<\/a> say that SageMaker is running <code>docker run &lt;image&gt; train<\/code> when starting a container.<\/p>\n<p>Is it possible to work around this problem? Either via somehow providing additional arguments to the command, or specifying something when creating the Docker image (such as in the Dockerfile, deployment script to ECR).<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1648550512340,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":456.0,
        "Poster_created_time":1352838205400,
        "Poster_location":null,
        "Poster_reputation_count":718.0,
        "Poster_view_count":43.0,
        "Answer_body":"<p>As pointed out by @rok (thank you!) it is not possible in this situation to pass arguments to <code>docker run<\/code>, although it would be if switching to ECS.<\/p>\n<p>It is however possible to pass the <code>--shm-size<\/code> argument to <code>docker build<\/code> when building the image to push to ECR. This seems to have fixed the problem, albeit it does require a new Docker image to be built and pushed whenever wanting to change this parameter.<\/p>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1648732366736,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1352838205400,
        "Answerer_location":null,
        "Answerer_reputation_count":718.0,
        "Answerer_view_count":43.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71660619",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"alter share memori docker contain docker imag elast contain registri ecr creat simpl dockerfil control imag fine problem share memori insuffici work insid contain studio need rais share memori contain rais share memori contain believ usual method pass shm size argument docker run command start contain control command bit doc run docker run train start contain possibl work problem provid addit argument command specifi creat docker imag dockerfil deploy script ecr",
        "Question_preprocessed_content":"alter share memori docker contain docker imag elast contain registri creat simpl dockerfil control imag fine problem share memori work insid contain studio rais share memori contain rais share memori contain believ usual method argument start contain control bit doc start contain work problem provid argument specifi creat docker imag",
        "Question_gpt_summary_original":"The user has a Docker image in Elastic Container Registry (ECR) and needs to increase the shared memory of the containers in SageMaker Studio. However, they do not have control over the <code>docker run<\/code> command as it is done by SageMaker. The user is looking for a workaround to provide additional arguments to the command or specify something in the Docker image or deployment script to ECR.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Send request as Json on UWP",
        "Question_body":"<p>I have deployed an AzureML published experiment with deployed web service. I tried to use the <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-consume-web-services\/\" rel=\"nofollow\">sample code provided in the configuration page<\/a>, but universal apps do not implement Http.Formatting yet, thus I couldn't use <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/hh944521(v=vs.118).aspx\" rel=\"nofollow\">postasjsonasync<\/a>.<\/p>\n\n<p>I tried to follow the sample code as much as possible, but I'm getting statuscode of 415 \"Unsupported Media Type\", What's the mistake I'm doing?<\/p>\n\n<pre><code>var client = new HttpClient();\nclient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", apiKey);\n\/\/ client.BaseAddress = uri;\n\nvar scoreRequest = new\n{\n            Inputs = new Dictionary&lt;string, StringTable&gt;() {\n                    {\n                        \"dataInput\",\n                        new StringTable()\n                        {\n                            ColumnNames = new [] {\"Direction\", \"meanX\", \"meanY\", \"meanZ\"},\n                            Values = new [,] {  { \"\", x.ToString(), y.ToString(), z.ToString() },  }\n                        }\n                    },\n                },\n            GlobalParameters = new Dictionary&lt;string, string&gt;() { }\n };\n var stringContent = new StringContent(scoreRequest.ToString());\n HttpResponseMessage response = await client.PostAsync(uri, stringContent);\n<\/code><\/pre>\n\n<p>Many Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1452005613750,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":3194.0,
        "Poster_created_time":1352139399460,
        "Poster_location":"Cyprus",
        "Poster_reputation_count":820.0,
        "Poster_view_count":256.0,
        "Answer_body":"<p>You'll need to serialize the object to a JSON string (I recommend using NewtonSoft.Json to make it easier) and set the content type accordingly. Here's an implementation I'm using in my UWP apps (note that <code>_client<\/code> is an <code>HttpClient<\/code>):<\/p>\n\n<pre><code>    public async Task&lt;HttpResponseMessage&gt; PostAsJsonAsync&lt;T&gt;(Uri uri, T item)\n    {\n        var itemAsJson = JsonConvert.SerializeObject(item);\n        var content = new StringContent(itemAsJson);\n        content.Headers.ContentType = new MediaTypeHeaderValue(\"application\/json\");\n\n        return await _client.PostAsync(uri, content);\n    }\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1452007973623,
        "Answer_last_edit_time":null,
        "Answer_score_count":3.0,
        "Answerer_created_time":1395422283667,
        "Answerer_location":null,
        "Answerer_reputation_count":1411.0,
        "Answerer_view_count":45.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34614582",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"send request json uwp deploi publish experi deploi web servic tri us sampl code provid configur page univers app implement http format couldn us postasjsonasync tri follow sampl code possibl get statuscod unsupport media type mistak var client new httpclient client defaultrequesthead author new authenticationheadervalu bearer apikei client baseaddress uri var scorerequest new input new dictionari datainput new stringtabl columnnam new direct meanx meani meanz valu new tostr tostr tostr globalparamet new dictionari var stringcont new stringcont scorerequest tostr httpresponsemessag respons await client postasync uri stringcont thank",
        "Question_preprocessed_content":"send request json uwp deploi publish experi deploi web servic tri us sampl code provid configur page univers implement couldn us postasjsonasync tri sampl code statuscod media type mistak thank",
        "Question_gpt_summary_original":"The user is facing challenges while trying to send a request as JSON on UWP for an AzureML published experiment with a deployed web service. The sample code provided in the configuration page is not working as universal apps do not implement Http.Formatting yet, resulting in a status code of 415 \"Unsupported Media Type\". The user is seeking help to identify the mistake in the code.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Artifacts (local) caching - how does it really work?",
        "Question_body":"<p>Hi all,<\/p>\n<p>I\u2019m trying to figure out how does the caching  of artifacts work. Let\u2019s say I want to download a model artifact to run some evaluation on. I don\u2019t need the file on disk to persist rather I just want to load it into memory. What I do right now in my evaluation script is:<\/p>\n<pre><code class=\"lang-auto\">import tempfile\nimport wandb\n\nartifact = wandb.use_artifact(model_weights_uri)\nwith tempfile.TemporaryDirectory() as tmpdirname:\n    artifact.download(tmpdirname)\n    model_weights = load_pickle(os.path.join(tmpdirname, \"model_weights.pickle\"))\n<\/code><\/pre>\n<p>And from that point on I use the <code>model_weights<\/code> as it was loaded into memory.<\/p>\n<p>My first question is: if I run the code twice (on the same machine), <strong>will the model-weights be downloaded again<\/strong> or are they cached somewhere? assuming the logged artifact wasn\u2019t changed of course. And if they are cached, where are they cached?<br>\nI\u2019m also not clear about the <code>artifact<\/code> directory (which is used if I run <code>artifact.download()<\/code> without any argument). Does that directory serve as cache? if so, what does the <code>.cache<\/code> directory used for?<\/p>\n<p>I would appreciate answers to my questions and perhaps a  general explanation of the artifact caching mechanism &amp; best practices.<\/p>\n<p>Thanks!<br>\nRan<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1650203452610,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":861.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/ranshadmi-nexite\">@ranshadmi-nexite<\/a>,<\/p>\n<p>Thank you for your question. You are right, all Artifacts are cached on your system under <code>~\/.cache\/wandb\/artifacts<\/code> and organized by their checksum. So if you try to download a file with checksum <code>x<\/code> and that file has been logged in an Artifact from your machine or downloaded to your machine as part of an artifact before, we just pull it from the cache by checking if there is a cached Artifact file with checksum <code>x<\/code>.<\/p>\n<p>So, if you run the same code twice, assuming the version of the artifact you are trying to download has not changed, the artifact can simply be pickked up from your cache directory.<\/p>\n<p>Also, when calling <code>artifact.download()<\/code> without any arguments, the artifact is saved in the directory in which the code is running. This, however,  is not the directory that serves as a cache, that still remains <code>.cache<\/code> which acts as a central location to look for artifacts before fetching it.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Answer_comment_count":null,
        "Question_closed_time":1650312955392,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/artifacts-local-caching-how-does-it-really-work\/2255",
        "Tool":"Weights & Biases",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"artifact local cach work try figur cach artifact work let want download model artifact run evalu dont need file disk persist want load memori right evalu script import tempfil import artifact us artifact model weight uri tempfil temporarydirectori tmpdirnam artifact download tmpdirnam model weight load pickl path join tmpdirnam model weight pickl point us model weight load memori question run code twice machin model weight download cach assum log artifact wasnt chang cours cach cach clear artifact directori run artifact download argument directori serv cach cach directori appreci answer question gener explan artifact cach mechan best practic thank ran",
        "Question_preprocessed_content":"artifact cach work try figur cach artifact work let want download model artifact run evalu dont file disk persist want load memori right evalu script point us load memori question run code twice download cach artifact wasnt chang cours cach cach clear directori directori serv cach directori answer question gener explan artifact cach mechan best practic thank ran",
        "Question_gpt_summary_original":"The user is trying to understand how the caching of artifacts works in their evaluation script. They want to know if the model-weights will be downloaded again if they run the code twice on the same machine and where the cached files are stored. They also have questions about the artifact directory and the .cache directory. The user is seeking answers and best practices for artifact caching.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Can I mount EFS in SageMaker processing job?",
        "Question_body":"<p>We are running some predictions using processing jobs in SageMaker. Before, we added some models into Docker image that was used by SageMaker processing job. Now, as we have more models (&gt;= 6Gb), it is quite a bad design to add them to Docker image.<\/p>\n<p>At first, we thought to download huge models from S3, but then realised, that it will cost a fortune. Then, an idea came to my mind. What if we use EFS with all heavy models and connect it to the running processing job so that python code can reference and use them?<\/p>\n<p>I did a search and couldn't find any working solution for this. UI in AWS doesn't allow to connect EFS, and I couldn't find any working solution how to connect to EFS from the docker container. All suggest to use Docker volumes, but there is no way to configure this when create a processing job.<\/p>\n<p>Question is is there any way to mount EFS to processing job in SageMaker? If no, what are the alternatives to host and use heavy models in the processing jobs? Maybe there are some other alternatives?<\/p>\n<p>Thank you for any input.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662945203473,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":36.0,
        "Poster_created_time":1307457791456,
        "Poster_location":"Sydney, Australia",
        "Poster_reputation_count":537.0,
        "Poster_view_count":49.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73683651",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"mount ef process job run predict process job ad model docker imag process job model bad design add docker imag thought download huge model realis cost fortun idea came mind us ef heavi model connect run process job python code refer us search couldn work solut aw allow connect ef couldn work solut connect ef docker contain suggest us docker volum wai configur creat process job question wai mount ef process job altern host us heavi model process job mayb altern thank input",
        "Question_preprocessed_content":"mount ef job predict job model docker imag job model bad design docker imag thought download huge model realis cost fortun idea came mind us ef heavi model job python code refer us search couldn work solut aw ef couldn work solut ef docker contain us docker volum wai configur creat job question wai mount ef job altern host us heavi model job mayb altern thank input",
        "Question_gpt_summary_original":"The user is facing challenges in hosting heavy models for predictions using processing jobs in SageMaker. They are looking for alternatives to adding the models to the Docker image, as the models are now over 6GB. The user considered using EFS to connect to the running processing job, but couldn't find a working solution to connect EFS to the Docker container. They are seeking input on whether it is possible to mount EFS to processing jobs in SageMaker or if there are any alternative solutions.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Saving an Matlabplot as an MLFlow artifact",
        "Question_body":"<p>I am using DataBricks and Spark 7.4ML,<\/p>\n<p>The following code successfully logs the params and metrics, and I can see the ROCcurve.png in the MLFLOW gui (just the item in the tree below the model). But the actually plot is blank. Why?<\/p>\n<pre><code>with mlflow.start_run(run_name=&quot;logistic-regression&quot;) as run:\n  pipeModel = pipe.fit(trainDF)\n  mlflow.spark.log_model(pipeModel, &quot;model&quot;)\n  predTest = pipeModel.transform(testDF)\n  predTrain = pipeModel.transform(trainDF)\n  evaluator=BinaryClassificationEvaluator(labelCol=&quot;arrivedLate&quot;)\n  trainROC = evaluator.evaluate(predTrain)\n  testROC = evaluator.evaluate(predTest)\n  print(f&quot;Train ROC: {trainROC}&quot;)\n  print(f&quot;Test ROC: {testROC}&quot;)\n  mlflow.log_param(&quot;Dataset Name&quot;, &quot;Flights &quot; + datasetName)\n  mlflow.log_metric(key=&quot;Train ROC&quot;, value=trainROC)\n  mlflow.log_metric(key=&quot;Test ROC&quot;, value=testROC)\n\n  lrModel = pipeModel.stages[3]\n  trainingSummary = lrModel.summary\n  roc = trainingSummary.roc.toPandas()\n  plt.plot(roc['FPR'],roc['TPR'])\n  plt.ylabel('False Positive Rate')\n  plt.xlabel('True Positive Rate')\n  plt.title('ROC Curve')\n  plt.show()\n  plt.savefig(&quot;ROCcurve.png&quot;)\n  mlflow.log_artifact(&quot;ROCcurve.png&quot;)\n  plt.close()\n  \n  display(predTest.select(stringCols + [&quot;arrivedLate&quot;, &quot;prediction&quot;]))\n<\/code><\/pre>\n<p>What the notebook shows:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/sCIN9.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sCIN9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What the MLFlow shows:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oXk8Y.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oXk8Y.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1607094596640,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1607191847983,
        "Question_score_count":8.0,
        "Question_view_count":5219.0,
        "Poster_created_time":1316705139196,
        "Poster_location":"Boston, MA",
        "Poster_reputation_count":6711.0,
        "Poster_view_count":819.0,
        "Answer_body":"<p>Put <code>plt.show()<\/code> after <code>plt.savefig()<\/code> - <code>plt.show()<\/code> will remove your plot because it is shown already.<\/p>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1607094854147,
        "Answer_last_edit_time":null,
        "Answer_score_count":7.0,
        "Answerer_created_time":1598380609848,
        "Answerer_location":"Oxford, UK",
        "Answerer_reputation_count":38531.0,
        "Answerer_view_count":4137.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65145994",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save matlabplot artifact databrick spark follow code successfulli log param metric roccurv png gui item tree model actual plot blank start run run logist regress run pipemodel pipe fit traindf spark log model pipemodel model predtest pipemodel transform testdf predtrain pipemodel transform traindf evalu binaryclassificationevalu labelcol arrivedl trainroc evalu evalu predtrain testroc evalu evalu predtest print train roc trainroc print test roc testroc log param dataset flight datasetnam log metric kei train roc valu trainroc log metric kei test roc valu testroc lrmodel pipemodel stage trainingsummari lrmodel summari roc trainingsummari roc topanda plt plot roc fpr roc tpr plt ylabel fals posit rate plt xlabel true posit rate plt titl roc curv plt plt savefig roccurv png log artifact roccurv png plt close displai predtest select stringcol arrivedl predict notebook show show",
        "Question_preprocessed_content":"save matlabplot artifact databrick spark code log param metric png gui plot blank show show",
        "Question_gpt_summary_original":"The user is trying to save a Matplotlib plot as an MLFlow artifact in DataBricks and Spark 7.4ML. The code successfully logs the params and metrics, and the ROCcurve.png is visible in the MLFLOW gui, but the plot is blank. The user is seeking help to understand why this is happening.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Keras sequential model results not reproducible with wildly inconsistent results on same dataset and parameters optimized using Optuna",
        "Question_body":"<p>I am running a Keras sequential model as a regressor with tensorflow backend. I am using Optuna to optimize it's hyper-paramters and reducing the rmse in the Optuna optimizer.\nHowever, when I re-create the Keras model with the best parameters from Optuna and use the same dataset for re-fitting and predicting as the one used in the Optuna objective function, I get wildly inconsistent results.<\/p>\n<p>I'm aware that neural nets are stochastic in nature with an element of randomness. In order to make it deterministic I tried setting the seeds for both numpy and tensorflow in the following manner at beginning of my script, but it doesn't work,<\/p>\n<pre><code>from numpy.random import seed\nseed(1)\nimport tensorflow\ntensorflow.random.set_seed(2)\n<\/code><\/pre>\n<p>Following is my code and the output-<\/p>\n<pre><code>def create_model(trial):   \n    n_layers = trial.suggest_int(&quot;layers_number&quot;, 4,  8)#4\n    model = keras.Sequential()\n    for i in range(n_layers):\n        num_hidden = trial.suggest_int(&quot;n_units_l_{}&quot;.format(i), 10, 16)\n        activation = trial.suggest_categorical('activation_l_{}'.format(i), ['linear'])#, 'relu', 'sigmoid', 'tanh', 'elu'\n        model.add(layers.Dense(num_hidden, activation=activation, kernel_initializer = 'uniform'))\n        dropout = trial.suggest_uniform(&quot;dropout_l_{}&quot;.format(i), 0.1, 0.4)\n        model.add(layers.Dropout(dropout))\n    model.add(layers.Dense(1, activation='linear'))\n\n    lr = trial.suggest_loguniform(&quot;lr&quot;, 1e-5, 1e-1)\n\n    model.compile(\n        loss='mean_squared_error',\n        optimizer=keras.optimizers.Adam(lr=lr),\n        metrics=['mse']\n    )\n\n    return model\n<\/code><\/pre>\n<pre><code>def objective(trial):\n    keras.backend.clear_session()\n    model = create_model(trial)\n    \n    epochs = trial.suggest_int(&quot;epochs&quot;, 3, 4)#50\n    batch = trial.suggest_int(&quot;batch&quot;, 1, 2)\n    \n    model.fit(\n        X_train.values,\n        y_train.values, \n        batch_size=batch, \n        epochs=epochs, \n        verbose=0,\n        shuffle=False\n    )\n    y_pred_test = model.predict(X_test)\n    test_copy['pred_scaled'] = y_pred_test\n    rmse = inverse_transform(test_copy, y_pred_test, df_copy) #inverse transforms the transformed target and calculates rmse\n\n    return rmse\n<\/code><\/pre>\n<pre><code>study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=2)\n<\/code><\/pre>\n<p>Output- best trial screenshot\n<a href=\"https:\/\/i.stack.imgur.com\/2JAwJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2JAwJ.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>RMSE of best trial is 110.90926282554379<\/p>\n<p>Refitting and predicting using best params.<\/p>\n<pre><code>def KerasRegressor(parameters):\n    print(parameters)\n    model = keras.Sequential()\n    layers_number = int(parameters['layers_number'])\n\n    for i in range(layers_number):\n        model.add(layers.Dense(int(parameters['n_units_l_' + str(i)]), activation=parameters['activation_l_' + str(i)], kernel_initializer = 'uniform'))\n        model.add(layers.Dropout(int(parameters['dropout_l_' + str(i)])))\n    model.add(layers.Dense(1, activation='linear'))\n    model.compile(\n        loss='mean_squared_error',\n        optimizer=keras.optimizers.Adam(lr=float(parameters['lr'])),\n        metrics=['mse'])\n        \n    return model\n<\/code><\/pre>\n<pre><code>params = study.best_trial.params\nepochs = params['epochs']\nbatch = params['batch']\ndel params['epochs']\ndel params['batch']\n\nseed(1)\ntensorflow.random.set_seed(2)\nmodel = KerasRegressor(params)\nmodel.fit(X_train.values, y_train.values, epochs=epochs, batch_size=batch, shuffle=False)\n\ny_pred_test = model.predict(X_test)\ntest_copy['pred_scaled'] = y_pred_test\nrmse = inverse_transform(test_copy, y_pred_test, df_copy)#inverse transforms the transformed target and calculates rmse\nprint(rmse)\n<\/code><\/pre>\n<p>New rmse on same dataset as used in Optuna objective function with best hyperparameters-\n<a href=\"https:\/\/i.stack.imgur.com\/PXv6F.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PXv6F.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>New rmse - 227892.23560327655<\/p>\n<p>Small differences in rmse are acceptable but not this large a difference.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1647324297490,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1647879472192,
        "Question_score_count":0.0,
        "Question_view_count":94.0,
        "Poster_created_time":1475693346256,
        "Poster_location":"Hyderabad, Telangana, India",
        "Poster_reputation_count":35.0,
        "Poster_view_count":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71477693",
        "Tool":"Optuna",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"kera sequenti model result reproduc wildli inconsist result dataset paramet optim run kera sequenti model regressor tensorflow backend optim hyper paramt reduc rmse optim creat kera model best paramet us dataset fit predict object function wildli inconsist result awar neural net stochast natur element random order determinist tri set seed numpi tensorflow follow manner begin script work numpi random import seed seed import tensorflow tensorflow random set seed follow code output def creat model trial layer trial suggest int layer number model kera sequenti rang layer num hidden trial suggest int unit format activ trial suggest categor activ format linear relu sigmoid tanh elu model add layer dens num hidden activ activ kernel initi uniform dropout trial suggest uniform dropout format model add layer dropout dropout model add layer dens activ linear trial suggest loguniform model compil loss mean squar error optim kera optim adam metric mse return model def object trial kera backend clear session model creat model trial epoch trial suggest int epoch batch trial suggest int batch model fit train valu train valu batch size batch epoch epoch verbos shuffl fals pred test model predict test test copi pred scale pred test rmse invers transform test copi pred test copi invers transform transform target calcul rmse return rmse studi creat studi direct minim studi optim object trial output best trial screenshot rmse best trial refit predict best param def kerasregressor paramet print paramet model kera sequenti layer number int paramet layer number rang layer number model add layer dens int paramet unit str activ paramet activ str kernel initi uniform model add layer dropout int paramet dropout str model add layer dens activ linear model compil loss mean squar error optim kera optim adam float paramet metric mse return model param studi best trial param epoch param epoch batch param batch del param epoch del param batch seed tensorflow random set seed model kerasregressor param model fit train valu train valu epoch epoch batch size batch shuffl fals pred test model predict test test copi pred scale pred test rmse invers transform test copi pred test copi invers transform transform target calcul rmse print rmse new rmse dataset object function best hyperparamet new rmse small differ rmse accept larg differ",
        "Question_preprocessed_content":"kera sequenti model result reproduc wildli inconsist result dataset paramet optim kera sequenti model tensorflow backend optim reduc rmse optim kera model best paramet us dataset predict object function wildli inconsist result awar neural net stochast natur element order determinist tri numpi tensorflow script work code output output best trial rmse best trial predict best param new rmse dataset object function best hyperparamet new rmse rmse larg",
        "Question_gpt_summary_original":"The user is encountering inconsistent results while using Keras sequential model as a regressor with tensorflow backend. The user is using Optuna to optimize hyper-parameters and reduce the rmse, but when the user re-creates the Keras model with the best parameters from Optuna and uses the same dataset for re-fitting and predicting as the one used in the Optuna objective function, the user gets wildly inconsistent results. The user has tried to make the neural nets deterministic by setting the seeds for both numpy and tensorflow, but it doesn't work. The user has provided the code and output for reference.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How can I utilize multiple cores on Azure ML Studio VM's?",
        "Question_body":"<p>Hi. I have a python script which can be run either sequentially or in parallel (using concurrent.futures). On my local machine using the parallel option results in a considerably faster execution (nearly linear speed up). Running the same script inside an Experiment on Azure ML Studio I was not able to observe any speedup from the parallel version. At first I thought adding the following line conda_env.docker.arguments = [&quot;--cpuset-cpus=4&quot;] would help, but still the same. Therfore my question is, how can I enable the docker container to leverage multiple cores of the vm-instance? Kind Regard Kai <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_created_time":1603703811737,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/139002\/how-can-i-utilize-multiple-cores-on-azure-ml-studi",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"util multipl core studio python script run sequenti parallel concurr futur local machin parallel option result consider faster execut nearli linear speed run script insid experi studio abl observ speedup parallel version thought ad follow line conda env docker argument cpuset cpu help therfor question enabl docker contain leverag multipl core instanc kind regard kai",
        "Question_preprocessed_content":"util multipl core studio python script run local machin option result consider faster execut script insid experi studio abl observ version thought line help therfor question enabl docker contain leverag multipl core kind regard kai",
        "Question_gpt_summary_original":"The user is facing challenges in utilizing multiple cores on Azure ML Studio VM's while running a python script in parallel. The user has tried adding a line of code to enable the docker container to leverage multiple cores, but it did not help. The user is seeking guidance on how to enable the docker container to utilize multiple cores of the VM-instance.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Problem with wandb.plot.pr_curve",
        "Question_body":"<p>Hello. My code for each training epoch:<\/p>\n<pre><code class=\"lang-auto\">wandb.log({\n    \"PR_curve\":  wandb.plot.pr_curve(y_true, [(x, 1 - x) for x in y_predict])\n})\n<\/code><\/pre>\n<p>But I had plots like that(the left part):<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5.jpeg\" data-download-href=\"\/uploads\/short-url\/9PhavrmCKrRlTKNxaRThfK8TGZv.jpeg?dl=1\" title=\"imgonline-com-ua-2to1-fyiDuqxQ397nx579\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_690x210.jpeg\" alt=\"imgonline-com-ua-2to1-fyiDuqxQ397nx579\" data-base62-sha1=\"9PhavrmCKrRlTKNxaRThfK8TGZv\" width=\"690\" height=\"210\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_690x210.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_1035x315.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_1380x420.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">imgonline-com-ua-2to1-fyiDuqxQ397nx579<\/span><span class=\"informations\">1565\u00d7477 91.1 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\nWhen I used pyplot I got the right part for some epoche:<br>\nAs I understand curve for class \u201c1\u201d must be equal to one of curves from second picture.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1643736812021,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":112.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/problem-with-wandb-plot-pr-curve\/1857",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"problem plot curv hello code train epoch log curv plot curv true predict plot like left imgonlin com fyiduqxqnx pyplot got right epoch understand curv class equal curv second pictur",
        "Question_preprocessed_content":"problem code train epoch plot like pyplot got right epoch understand curv equal curv second pictur",
        "Question_gpt_summary_original":"The user is facing an issue with the wandb.plot.pr_curve function, as the generated plots are not as expected. The user has shared the code used for each training epoch and the generated plots, which show a discrepancy between the expected and actual curves. The user has also tried using pyplot and has obtained the expected curves for some epochs.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"I got an error that the kernel could not be found in Azure ml.",
        "Question_body":"<p>When I was using a compute instance with azure ml, I got the following message:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/168157-kernelerror.png?platform=QnA\" alt=\"168157-kernelerror.png\" \/>    <br \/>\nThe kernel for python 3.8 azure ml was not available.    <br \/>\nPlease tell me the cause and solution.    <br \/>\nThe instance I was using is:    <br \/>\nVirtual machine size    <br \/>\nStandard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk)    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1643096138537,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/708659\/i-got-an-error-that-the-kernel-could-not-be-found",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"got error kernel comput instanc got follow messag kernel python avail tell caus solut instanc virtual machin size standard core ram disk",
        "Question_preprocessed_content":"got kernel comput instanc got kernel python avail caus solut instanc virtual machin size",
        "Question_gpt_summary_original":"The user encountered an error in Azure ml where the kernel for python 3.8 was not available on their compute instance. They are seeking the cause and solution for this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Waiting for wandb.init",
        "Question_body":"<p>Hi, the code ran 3 days agoand it worked, but after I changed some variables and it failed with: \u201cwandb: W&amp;B API key is configured. Use <code>wandb login --relogin<\/code> to force relogin wandb: - Waiting for wandb.init()\u2026wandb: \\ Waiting for wandb.init()\u2026wandb: | Waiting for wandb.init()\u2026wandb: \/ Waiting for wandb.init()\u2026wandb: - Waiting for wandb.init()\u2026Traceback (most recent call last):\u201d. Now after I changed it back the error persists.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1673289804453,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":682.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/waiting-for-wandb-init\/3658",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wait init code ran dai agoand work chang variabl fail api kei configur us login relogin forc relogin wait init wait init wait init wait init wait init traceback recent chang error persist",
        "Question_preprocessed_content":"wait init code ran dai agoand work chang variabl fail api kei configur us forc relogin wait init wait init wait init wait init wait init traceback chang persist",
        "Question_gpt_summary_original":"The user is encountering an error while running their code with wandb. The error message suggests that the API key is configured and the code is waiting for wandb.init(). The user had made some changes to the variables which caused the code to fail and even after changing it back, the error persists.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Unable to create labelling project",
        "Question_body":"<p>I've been trying to create a Labeling project in AzureML. I have succesfully registered the datastore (without credentials, so AzureML should use the users's AD Credential), I have succesfully created a dataset from the datastore (approx 15k images in the dataset) and can explore the dataset from the portal.  <\/p>\n<p>When I then create a labelling project, I finish the creation wizard and get back to the label project overview with. For a few seconds the project shows it's initializing but then shows the project as Failed. The only information I get is:  <\/p>\n<blockquote>\n<p>The dataset refresh has failed. Verify the project's datastore credentials are correct and the dataset contains datapoints.  <\/p>\n<\/blockquote>\n<p>However, as far as I can tell the credentials are correct and the dataset does contain datapoints as evidenced by me being able to 'explore' the dataset from the portal.  <\/p>\n<p>What other issues can cause this error and\/or how can I get a more detailed explanation for what went wrong?  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1654602922600,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/879956\/unable-to-create-labelling-project",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl creat label project try creat label project succesfulli regist datastor credenti us user credenti succesfulli creat dataset datastor approx imag dataset explor dataset portal creat label project finish creation wizard label project overview second project show initi show project fail inform dataset refresh fail verifi project datastor credenti correct dataset contain datapoint far tell credenti correct dataset contain datapoint evidenc abl explor dataset portal issu caus error detail explan went wrong",
        "Question_preprocessed_content":"unabl creat project try creat label project regist datastor creat dataset datastor explor dataset portal creat project finish creation wizard label project overview second project show initi show project fail inform dataset refresh fail verifi project datastor credenti dataset contain datapoint far credenti dataset contain datapoint evidenc abl explor dataset portal caus detail explan went wrong",
        "Question_gpt_summary_original":"The user is unable to create a labelling project in AzureML despite successfully registering the datastore and creating a dataset with 15k images. The project shows as failed with the error message \"The dataset refresh has failed. Verify the project's datastore credentials are correct and the dataset contains datapoints.\" The user is unsure of what other issues could be causing this error and how to get a more detailed explanation.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Where do augmentations in ClearML run?",
        "Question_body":"<p>In ClearML Dataviews, it is possible to add <a href=\"https:\/\/clear.ml\/docs\/latest\/docs\/hyperdatasets\/dataviews\/#data-augmentation\" rel=\"nofollow noreferrer\">augmentations<\/a>.<\/p>\n<p>Where do these augmentations run?<\/p>\n<p>Options<\/p>\n<ol>\n<li>Original data gets downloaded to local, then runs (on which device? How is multiprocessing handled?)<\/li>\n<li>Only augmented data gets downloaded to local cache, augmentations run remotely (who pays for compute? How fast? Should pipelines be changed accordingly?)<\/li>\n<\/ol>\n<p>I couldn't find this in the docs.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1658746321690,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":22.0,
        "Poster_created_time":1314313109232,
        "Poster_location":"Technion, Israel",
        "Poster_reputation_count":18777.0,
        "Poster_view_count":2000.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73108016",
        "Tool":"ClearML",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"augment run dataview possibl add augment augment run option origin data get download local run devic multiprocess handl augment data get download local cach augment run remot pai comput fast pipelin chang accordingli couldn doc",
        "Question_preprocessed_content":"augment run dataview augment augment run option origin data get download local run augment data get download local cach augment run remot couldn doc",
        "Question_gpt_summary_original":"The user is seeking clarification on where augmentations in ClearML Dataviews run, and presents two possible options: whether the original data is downloaded locally and run on a device (with questions about multiprocessing), or if only augmented data is downloaded to a remote location (with questions about cost, speed, and pipeline changes). The user notes that they were unable to find this information in the documentation.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Wandb login issue",
        "Question_body":"<p>Hi, everytime I run my experiment in kubernetes, wandb is asking for options wandb:<br>\n(1) Create a W&amp;B account<br>\nwandb: (2) Use an existing W&amp;B account<br>\nwandb: (3) Don\u2019t visualize my results<\/p>",
        "Question_answer_count":6,
        "Question_comment_count":null,
        "Question_created_time":1661773970926,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1317.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-login-issue\/3023",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"login issu everytim run experi kubernet ask option creat account us exist account dont visual result",
        "Question_preprocessed_content":"login everytim run experi kubernet ask option creat us exist dont visual result",
        "Question_gpt_summary_original":"The user is facing an issue with Wandb while running experiments in Kubernetes as it keeps asking for options to either create a new account, use an existing one, or not visualize the results.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Unable to load .ipynb file in Azure Machine Learning Workspace",
        "Question_body":"<p>Hey all,    <\/p>\n<p>I experienced the issue below. To summarize, I cannot open .ipynb file in my azure machine learning workspace.    <\/p>\n<p>I have tried and ensure that the notebooks are under ~\/cloudfiles\/code\/Users\/ folder so it is visible to Jupyter environment.     <\/p>\n<p>Can anyone give suggestions\/guidance on how to resolve the issue?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/165932-image.png?platform=QnA\" alt=\"165932-image.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1642489248987,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/699144\/unable-to-load-ipynb-file-in-azure-machine-learnin",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl load ipynb file workspac hei experienc issu summar open ipynb file workspac tri ensur notebook cloudfil code user folder visibl jupyt environ suggest guidanc resolv issu",
        "Question_preprocessed_content":"unabl load ipynb file workspac hei experienc open ipynb file workspac tri ensur folder visibl jupyt environ guidanc resolv",
        "Question_gpt_summary_original":"The user is unable to open .ipynb files in their Azure Machine Learning Workspace despite ensuring that the files are in the correct folder. They are seeking suggestions or guidance on how to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Amazon SageMaker - Training Job \/ Data Wrangler",
        "Question_body":"I have a customer who is interested in testing Amazon Sagemaker and would like to consult the following questions: \n\nQ1. While submitting training job in Amazon Sagemaker, if there is insufficient capacity occurred, would there be any auto-retry mechanism? How to set up?\nQ2. Is the underlying SQL \/ MySQL infrastructure in Data Wrangler from AWS serverless DB backend?\nQ3. What is the backend database to support Sagemaker \/ Sagemkaer Data Wrangler ? \n\nUse case: Vision ML - Object detection (self-built algorithm)\nFramework: Tensorflow 2.4.4",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1665982852548,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668618190215,
        "Question_score_count":0.0,
        "Question_view_count":124.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUg1kenySVSc2Eq9mW7Mwy1A\/amazon-sagemaker-training-job-data-wrangler",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train job data wrangler custom interest test like consult follow question submit train job insuffici capac occur auto retri mechan set underli sql mysql infrastructur data wrangler aw serverless backend backend databas support sagemka data wrangler us case vision object detect self built algorithm framework tensorflow",
        "Question_preprocessed_content":"train job data wrangler custom interest test like consult question train job capac mechan set underli sql mysql infrastructur data wrangler aw backend backend databas sagemka data wrangler us case vision object detect framework tensorflow",
        "Question_gpt_summary_original":"The user is seeking answers to questions related to Amazon SageMaker and Data Wrangler, including whether there is an auto-retry mechanism for insufficient capacity during training job submission, the underlying SQL\/MySQL infrastructure in Data Wrangler, and the backend database supporting SageMaker and Data Wrangler. The use case is for Vision ML - Object detection using a self-built algorithm and the framework is Tensorflow 2.4.4.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Adding Image() to a Report programatically",
        "Question_body":"<p>Hello,<br>\nI am experimenting with programmatic report generation using Python.<br>\nI understand that reports are a beta feature.<br>\nI would like to add an Image object to a report.  The image was generated in MatPlotLib and rendered using PIL.  I\u2019ve read the documentation but there is little if any mention of how to handle <code>Image<\/code> objects, other than a brief mention that they are supported.<\/p>\n<p>I am getting the following error:<\/p>\n<pre><code class=\"lang-auto\">TypeError: url object must be of type (&lt;class 'str'&gt;,) (got &lt;class 'PIL.PngImagePlugin.PngImageFile'&gt;)\n<\/code><\/pre>\n<p>The generating code for the report looks like:<\/p>\n<pre><code class=\"lang-auto\">blocks  = []\nblocks += [wr.MarkdownBlock(text=\"Markdown cell with *italics* and **bold** and $e=mc^2$\")]\nfor result in results:\n    if result:\n        blocks += wr.PanelGrid(panels=[wr.Image(result['image'], caption=f\"Subject={result['subject']}\")])\nreport.blocks = blocks\nreport.save()<\/code><\/pre>",
        "Question_answer_count":14,
        "Question_comment_count":null,
        "Question_created_time":1665986600457,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":356.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/adding-image-to-a-report-programatically\/3266",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"ad imag report programat hello experi programmat report gener python understand report beta featur like add imag object report imag gener matplotlib render pil iv read document littl mention handl imag object brief mention support get follow error typeerror url object type got gener code report look like block block markdownblock text markdown cell ital bold result result result block panelgrid panel imag result imag caption subject result subject report block block report save",
        "Question_preprocessed_content":"imag report experi report gener python understand report beta featur like imag object report imag gener matplotlib render pil iv read document mention handl object brief mention gener code report like",
        "Question_gpt_summary_original":"The user is experimenting with programmatic report generation using Python and wants to add an Image object to a report that was generated in MatPlotLib and rendered using PIL. However, the user is encountering a TypeError that says the url object must be of type 'str' but got 'PIL.PngImagePlugin.PngImageFile'. The user has shared the generating code for the report.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is it possible to check that the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file?",
        "Question_body":"<p>My team has a set up wherein we track datasets and models in DVC, and have a GitLab repository for tracking our code and DVC metadata files. We have a job in our dev GitLab pipeline (run on each push to a merge request) that has the goal of checking to be sure that the developer remembered to run <code>dvc push<\/code> to keep DVC remote storage up-to-date. Right now, the way we do this is by running <code>dvc pull<\/code> on the GitLab runner, which will fail with errors telling you which files (new files or latest versions of existing files) were not found.<\/p>\n<p>The downside to this approach is that we are loading the entirety of our data stored in DVC onto a GitLab runner, and we've run into out-of-memory issues, not to mention lengthy run time to download all that data. Since the path and md5 hash of the objects are stored in the DVC metadata files, I would think that's all the information that DVC would need to be able to answer the question &quot;is the remote storage system up-to-date&quot;.<\/p>\n<p>It seems like <code>dvc status<\/code> is similar to what I'm asking for, but compares the cache or workspace and remote storage. In other words, it requires the files to actually be present on whatever filesystem is making the call.<\/p>\n<p>Is there some way to achieve the goal I laid out above (&quot;inform the developer that they need to run <code>dvc push<\/code>&quot;) without pulling everything from DVC?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1622232629793,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1622257491983,
        "Question_score_count":5.0,
        "Question_view_count":488.0,
        "Poster_created_time":1618255062696,
        "Poster_location":null,
        "Poster_reputation_count":75.0,
        "Poster_view_count":2.0,
        "Answer_body":"<blockquote>\n<p>It seems like dvc status is similar to what I'm asking for<\/p>\n<\/blockquote>\n<p><code>dvc status --cloud<\/code> will give you a list of &quot;new&quot; files if they that haven't been pushed to the (default) remote. It won't error out though, so your CI script should fail depending on the stdout message.<\/p>\n<p>More info: <a href=\"https:\/\/dvc.org\/doc\/command-reference\/status#options\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/status#options<\/a><\/p>\n<p>I'd also ask everyone to run <code>dvc install<\/code>, which will setup some Git hooks, including automatic <code>dvc push<\/code> with <code>git push<\/code>.<\/p>\n<p>See <a href=\"https:\/\/dvc.org\/doc\/command-reference\/install\" rel=\"nofollow noreferrer\">https:\/\/dvc.org\/doc\/command-reference\/install<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1622257759208,
        "Answer_last_edit_time":1622503453296,
        "Answer_score_count":3.0,
        "Answerer_created_time":1305851487736,
        "Answerer_location":null,
        "Answerer_reputation_count":5993.0,
        "Answerer_view_count":457.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67744934",
        "Tool":"DVC",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl check version file track metadata file exist remot storag pull file team set track dataset model gitlab repositori track code metadata file job dev gitlab pipelin run push merg request goal check sure develop rememb run push remot storag date right wai run pull gitlab runner fail error tell file new file latest version exist file downsid approach load entireti data store gitlab runner run memori issu mention lengthi run time download data path hash object store metadata file think inform need abl answer question remot storag date like statu similar ask compar cach workspac remot storag word requir file actual present filesystem make wai achiev goal laid inform develop need run push pull",
        "Question_preprocessed_content":"check version file track metadata file exist remot storag file team set track dataset model gitlab repositori track code metadata file job dev gitlab pipelin goal check sure develop rememb run remot storag right wai gitlab fail file downsid load entireti data store gitlab run mention lengthi run time download data path hash object store metadata file think inform abl answer question remot storag like similar ask compar cach workspac remot storag word requir file present filesystem make wai achiev goal laid",
        "Question_gpt_summary_original":"The user's team tracks datasets and models in DVC and has a GitLab repository for tracking code and DVC metadata files. They have a job in their dev GitLab pipeline that checks if the developer has run \"dvc push\" to keep DVC remote storage up-to-date. Currently, they run \"dvc pull\" on the GitLab runner, which loads the entirety of their data stored in DVC onto the runner, causing out-of-memory issues and lengthy run time. The user is looking for a way to check if the version of a file tracked by a DVC metadata file exists in remote storage without pulling the file.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to solve \"Encountered unresolved custom op: edgetpu-custom-op\" exception",
        "Question_body":"<p>Im trying to implement my custom ML model in a kotlin app.<\/p>\n<p>I first make and train my model in GCP Vertex AI.\nAfter my model was ready i've export it as tensor flow model to the edge and then upload to my Firebase Machine Learning proyect.<\/p>\n<p>After that i follow the <a href=\"https:\/\/firebase.google.com\/docs\/ml\/android\/use-custom-models?hl=es&amp;authuser=0\" rel=\"nofollow noreferrer\">guide to implement a custom model of tensor flow lite on android.<\/a><\/p>\n<p>Then when i execute my app it crash on this part of the code:<\/p>\n<pre><code>val conditions = CustomModelDownloadConditions.Builder()\n        .requireWifi()  \/\/ Also possible: .requireCharging() and .requireDeviceIdle()\n        .build()\nFirebaseModelDownloader.getInstance()\n        .getModel(&quot;your_model&quot;, DownloadType.LOCAL_MODEL_UPDATE_IN_BACKGROUND,\n            conditions)\n        .addOnSuccessListener { model: CustomModel? -&gt;\n            \/\/ Download complete. Depending on your app, you could enable the ML\n            \/\/ feature, or switch from the local model to the remote model, etc.\n\n            \/\/ The CustomModel object contains the local path of the model file,\n            \/\/ which you can use to instantiate a TensorFlow Lite interpreter.\n            val modelFile = model?.file\n            if (modelFile != null) {\n                interpreter = Interpreter(modelFile) \/\/ this line crash\n            }\n        }\n<\/code><\/pre>\n<p>More specific at the line &quot;interpreter = Interpreter(modelFile)&quot;.\nI get the following exception:<\/p>\n<blockquote>\n<p>java.lang.IllegalStateException: Internal error: Unexpected failure\nwhen preparing tensor allocations: Encountered unresolved custom op:\nedgetpu-custom-op. See instructions:\n<a href=\"https:\/\/www.tensorflow.org\/lite\/guide\/ops_custom\" rel=\"nofollow noreferrer\">https:\/\/www.tensorflow.org\/lite\/guide\/ops_custom<\/a>  Node number 0\n(edgetpu-custom-op) failed to prepare.<\/p>\n<\/blockquote>\n<p>What is the meaning of this error?  How can i solve it?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1663959349290,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":21.0,
        "Poster_created_time":1345651822772,
        "Poster_location":null,
        "Poster_reputation_count":109.0,
        "Poster_view_count":21.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73831871",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"solv encount unresolv custom edgetpu custom except try implement custom model kotlin app train model gcp model readi export tensor flow model edg upload firebas machin learn proyect follow guid implement custom model tensor flow lite android execut app crash code val condit custommodeldownloadcondit builder requirewifi possibl requirecharg requiredeviceidl build firebasemodeldownload getinst getmodel model downloadtyp local model updat background condit addonsuccesslisten model custommodel download complet depend app enabl featur switch local model remot model custommodel object contain local path model file us instanti tensorflow lite interpret val modelfil model file modelfil null interpret interpret modelfil line crash specif line interpret interpret modelfil follow except java lang illegalstateexcept intern error unexpect failur prepar tensor alloc encount unresolv custom edgetpu custom instruct http www tensorflow org lite guid op custom node number edgetpu custom fail prepar mean error solv",
        "Question_preprocessed_content":"solv encount unresolv custom except try implement custom model kotlin train model gcp model readi export tensor flow model edg upload firebas machin learn proyect guid implement custom model tensor flow lite android execut crash code specif line interpret interpret except intern unexpect failur prepar tensor encount unresolv custom instruct node number fail prepar mean solv",
        "Question_gpt_summary_original":"The user is trying to implement a custom ML model in a Kotlin app by following the guide to implement a custom model of TensorFlow Lite on Android. However, the app crashes at the line \"interpreter = Interpreter(modelFile)\" with the exception \"Encountered unresolved custom op: edgetpu-custom-op.\" The user is seeking help to understand the meaning of this error and how to solve it.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How is one suppose to do custom logging in wandb especially with the x-axis?",
        "Question_body":"<p>I feel I\u2019ve discussed this with someone somewhere (perhaps a gitissue\u2026can\u2019t find it!) but I can\u2019t find it and now I came back and can\u2019t figure out why my wandb command looks the way it does:<\/p>\n<pre><code class=\"lang-auto\">        # - log to wandb\n        if log_to_wandb:\n            if it == 0:\n                wandb.define_metric(\"train loss\", step_metric=it_or_epoch)\n                wandb.define_metric(\"train acc\", step_metric=it_or_epoch)\n                wandb.define_metric(\"val loss\", step_metric=it_or_epoch)\n                wandb.define_metric(\"val val\", step_metric=it_or_epoch)\n                # if mdl_watch_log_freq == -1:\n                #     wandb.watch(args.base_model, args.criterion, log=\"all\", log_freq=mdl_watch_log_freq)\n            # - log to wandb\n            wandb.log(data={it_or_epoch: it,  # custom step,\n                            'train loss': train_loss,\n                            'train acc': train_acc,\n                            'val loss': val_loss,\n                            'val acc': val_acc},\n                            commit=True)\n            # if it == total_its:  # not needed here, only needed for normal SL training\n            #     wandb.finish()\n<\/code><\/pre>\n<p>can someone help me decipher what this was supposed to mean? Especially the commit option?<\/p>\n<hr>\n<p>related:<\/p>\n<ul>\n<li><a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log\">https:\/\/docs.wandb.ai\/guides\/track\/log<\/a><\/li>\n<li><a href=\"https:\/\/docs.wandb.ai\/guides\/track\/log#customize-axes-and-summaries-with-define_metric\">https:\/\/docs.wandb.ai\/guides\/track\/log#customize-axes-and-summaries-with-define_metric<\/a><\/li>\n<li><a href=\"https:\/\/colab.research.google.com\/drive\/1uegSY1HRGlKfK-07Uuw-ZxPJsNA9BN_9#scrollTo=0BIYhmSROGmq\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/wandb\/examples\/issues\/89\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Why isn't wandb logging at the last iteration? (when I want to log figs, ckpts etc) \u00b7 Issue #89 \u00b7 wandb\/examples \u00b7 GitHub<\/a><\/li>\n<\/ul>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1637974690752,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":252.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-is-one-suppose-to-do-custom-logging-in-wandb-especially-with-the-x-axis\/1400",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"suppos custom log especi axi feel iv discuss gitissuec came figur command look wai log log defin metric train loss step metric epoch defin metric train acc step metric epoch defin metric val loss step metric epoch defin metric val val step metric epoch mdl watch log freq watch arg base model arg criterion log log freq mdl watch log freq log log data epoch custom step train loss train loss train acc train acc val loss val loss val acc val acc commit true total need need normal train finish help deciph suppos mean especi commit option relat http doc guid track log http doc guid track log custom ax summari defin metric googl colab isn log iter want log fig ckpt issu exampl github",
        "Question_preprocessed_content":"custom iv came figur wai help deciph mean option relat colab isn iter exampl github",
        "Question_gpt_summary_original":"The user is seeking help in understanding how to do custom logging in wandb, particularly with the x-axis. They have provided a code snippet and are confused about the \"commit\" option. They have also included some related links for reference.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS SageMaker + Tensorflow + GPU",
        "Question_body":"<p>I'm trying to extract ELMo embeddings and running the code on AWS SageMaker and TensorFlow. The code runs fine on cpu instance in SageMaker <strong>but I want to run it on GPU<\/strong>. Below are the steps I performed and error listed:<\/p>\n\n<ol>\n<li>Started AWS SageMaker instance: ml.p3.8xlarge - it has 8 GPUs <\/li>\n<li>Started JuperterLab and selected conda_tensorflow_p36 for the notebook<\/li>\n<li>Ran the following code:<\/li>\n<\/ol>\n\n<p>!pip3 install <strong>tensorflow-gpu==1.15<\/strong>.<br>\n!pip3 install \"tensorflow-hub&lt;0.5.0\"<\/p>\n\n<pre><code>url = \"https:\/\/tfhub.dev\/google\/elmo\/2\"\nembed = hub.Module(url)\n\ndef defineEmbeddings(start, end, extractions):    \n    embeddings = embed(extractions[start:end],signature=\"default\",as_dict=True)[\"default\"]\n    return embeddings\ndef scoreExtractions (embeddings):\n\n    config = tf.compat.v1.ConfigProto(log_device_placement=True)\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.9\n    with tf.compat.v1.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        sess.run(tf.tables_initializer())\n        x = sess.run(embeddings)\n    return x\n<\/code><\/pre>\n\n<p>I get the following error with sess.run(embeddings)<\/p>\n\n<p>UnknownError: 2 root error(s) found.\n  (0) Unknown: <strong>Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.<\/strong>\n     [[{{node module_apply_default_1\/bilm\/CNN_1\/Conv2D}}]]\n     [[module_apply_default_1\/truediv\/_155]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n     [[{{node module_apply_default_1\/bilm\/CNN_1\/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored.<\/p>\n\n<p>But following works with the above setup:<\/p>\n\n<pre><code>with tf.device('\/device:GPU:3'):\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n    c = tf.matmul(a, b)\nwith tf.Session() as sess:\n    print(sess.run(c))\n<\/code><\/pre>\n\n<p>Based on my reading up on this issue on StackOverflow, I also tried to use <strong>tensorflow-gpu = 1.8.0<\/strong> also and with that, I'm getting the error in import tensorflow as tf :<\/p>\n\n<p><strong>ImportError<\/strong>: libcublas.so.9.0: cannot open shared object file: No such file or directory<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1588094390093,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":454.0,
        "Poster_created_time":1568045612272,
        "Poster_location":null,
        "Poster_reputation_count":97.0,
        "Poster_view_count":17.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61486115",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tensorflow gpu try extract elmo embed run code tensorflow code run fine cpu instanc want run gpu step perform error list start instanc xlarg gpu start juperterlab select conda tensorflow notebook ran follow code pip instal tensorflow gpu pip instal tensorflow hub url http tfhub dev googl elmo emb hub modul url def defineembed start end extract embed emb extract start end signatur default dict true default return embed def scoreextract embed config compat configproto log devic placement true config gpu option allow growth true config gpu option process gpu memori fraction compat session config config sess sess run global variabl initi sess run tabl initi sess run embed return follow error sess run embed unknownerror root error unknown fail convolut algorithm probabl cudnn fail initi try look warn log messag print node modul appli default bilm cnn convd modul appli default truediv unknown fail convolut algorithm probabl cudnn fail initi try look warn log messag print node modul appli default bilm cnn convd success oper deriv error ignor follow work setup devic devic gpu constant shape constant shape matmul session sess print sess run base read issu stackoverflow tri us tensorflow gpu get error import tensorflow importerror libcubla open share object file file directori",
        "Question_preprocessed_content":"tensorflow gpu try extract elmo code tensorflow code run fine cpu instanc want run gpu step perform list start instanc gpu start juperterlab select ran code pip pip run unknown fail convolut algorithm probabl fail initi try warn log print unknown fail convolut algorithm probabl fail initi try warn log print oper deriv ignor work setup base read stackoverflow tri us import tensorflow open share object file file directori",
        "Question_gpt_summary_original":"The user is trying to extract ELMo embeddings using TensorFlow and AWS SageMaker on a GPU instance. The code runs fine on a CPU instance, but when running on a GPU instance, the user encounters an error related to cuDNN initialization. The user has tried using different versions of TensorFlow-gpu and also encountered an error related to libcublas.so.9.0.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Not able to log artifacts from Windows client to mlflow server running on GCP VM instance",
        "Question_body":"<p>I installed mlflow on GCP VM and started the server by running this command on VM <code>mlflow server --host x.x.x.x<\/code>, here x.x.x.x is the internal IP of the VM<\/p>\n\n<p>Set the tracking URI using <code>mlflow.set_tracking_uri(\"http:\/\/x.x.x.x:5000\/\")<\/code>, here x.x.x.x is the external ip of the VM<\/p>\n\n<p>I'm running this code now to log parameters and artifacts on GCP VM where my mlflow server is running:<\/p>\n\n<pre><code>def eval_metrics(actual, pred):\n        rmse = np.sqrt(mean_squared_error(actual, pred))\n        mae = mean_absolute_error(actual, pred)\n        r2 = r2_score(actual, pred)\n        return rmse, mae, r2\n<\/code><\/pre>\n\n<pre><code>with mlflow.start_run():\n        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n        lr.fit(train_x, train_y)\n        predicted_qualities = lr.predict(test_x)\n        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n        print(\"  RMSE: %s\" % rmse)\n        print(\"  MAE: %s\" % mae)\n        print(\"  R2: %s\" % r2)\n        mlflow.log_param(\"alpha\", alpha)\n        mlflow.log_param(\"l1_ratio\", l1_ratio)\n        mlflow.log_metric(\"rmse\", rmse)\n        mlflow.log_metric(\"r2\", r2)\n        mlflow.log_metric(\"mae\", mae)\n        mlflow.log_artifacts(lr)\n<\/code><\/pre>\n\n<p>Parameters and Metrics I'm able to get on <a href=\"https:\/\/x.x.x.x:5000\" rel=\"nofollow noreferrer\">https:\/\/x.x.x.x:5000<\/a>, where x.x.x.x is external IP of the VM, but at the last line of the code i.e., <code>mlflow.log_artifacts(lr)<\/code> facing the error given below:<\/p>\n\n<p><img src=\"https:\/\/user-images.githubusercontent.com\/10863620\/76417135-517a5b80-63c2-11ea-8235-2f6c7c2d5324.png\" alt=\"image\"><\/p>\n\n<p>When executed <code>mlflow.get_artifact_uri()<\/code>, the path returned is <code>.\/mlruns\/0\/6073b44bbac842e5axxxxxxxxxxxxxxxxxx\/artifacts<\/code><\/p>\n\n<p>Is there something wrong with the artifact path and any idea how can I resolve this to log artifacts on VM from code running on local jupyter notebook?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1583994838227,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1583995374870,
        "Question_score_count":2.0,
        "Question_view_count":154.0,
        "Poster_created_time":1451124057623,
        "Poster_location":"India",
        "Poster_reputation_count":736.0,
        "Poster_view_count":234.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60648742",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"abl log artifact window client server run gcp instanc instal gcp start server run command server host intern set track uri set track uri http extern run code log paramet artifact gcp server run def eval metric actual pred rmse sqrt mean squar error actual pred mae mean absolut error actual pred score actual pred return rmse mae start run elasticnet alpha alpha ratio ratio random state fit train train predict qualiti predict test rmse mae eval metric test predict qualiti print elasticnet model alpha ratio alpha ratio print rmse rmse print mae mae print log param alpha alpha log param ratio ratio log metric rmse rmse log metric log metric mae mae log artifact paramet metric abl http extern line code log artifact face error given execut artifact uri path return mlrun bbbaceaxxxxxxxxxxxxxxxxxx artifact wrong artifact path idea resolv log artifact code run local jupyt notebook",
        "Question_preprocessed_content":"abl log artifact window client server gcp instanc gcp start server intern set track uri extern code log paramet artifact gcp server paramet metric abl extern line code face given execut path return wrong artifact path idea resolv log artifact code local jupyt",
        "Question_gpt_summary_original":"The user is facing an issue while trying to log artifacts from a Windows client to an mlflow server running on a GCP VM instance. The user is able to log parameters and metrics on the server but is encountering an error while trying to log artifacts. The error message suggests that the path to the artifact is incorrect. The user is seeking help to resolve the issue and log artifacts on the VM from code running on a local Jupyter notebook.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AttributeError: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGBoosterUnserializeFromBuffer",
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/93350-capture2.png?platform=QnA\" alt=\"93350-capture2.png\" \/>    <\/p>\n<p>I am following automated ML guideline.:    <\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/regression\/auto-ml-regression.ipynb\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/regression\/auto-ml-regression.ipynb<\/a>    <\/p>\n<p>I created development environment according to the documentation. As recommended, I am using version 1.27.0 of the Azure ML SDK.    <\/p>\n<p>After remote_run completed, I got the error for the following command &quot;best_run, fitted_model = remote_run.get_output()&quot;    <\/p>\n<p>I would appreciate if you could help me.    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1620076989343,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/381203\/attributeerror-anaconda-envs-azureml-py36-lib-libx",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"attributeerror anaconda env lib libxgboost undefin symbol xgboosterunserializefrombuff follow autom guidelin http github com azur machinelearningnotebook blob master us autom machin learn regress auto regress ipynb creat develop environ accord document recommend version sdk remot run complet got error follow command best run fit model remot run output appreci help",
        "Question_preprocessed_content":"undefin symbol autom creat develop environ document version sdk complet got help",
        "Question_gpt_summary_original":"The user encountered an AttributeError while following the automated ML guideline on Azure ML SDK version 1.27.0. The error occurred after the remote_run completed and while executing the command \"best_run, fitted_model = remote_run.get_output()\". The user is seeking assistance to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Executing existing Python Code in Azure ML",
        "Question_body":"<p>I have a code written Python and I need to deploy it on Azure ML. The python code consists of many function and returns the output in Jason format.<\/p>\n\n<p>However when implemented on Azure ML, there are no errors. But, there is no result as such generated. It is displaying the input dataset for both Result Dataset and Python device dataset.<\/p>\n\n<p>Can I know, how to go about it. I'm new to Azure ML, and have no clue how to go about it<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1483524253643,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1483525625560,
        "Question_score_count":1.0,
        "Question_view_count":111.0,
        "Poster_created_time":1479194627132,
        "Poster_location":null,
        "Poster_reputation_count":2713.0,
        "Poster_view_count":358.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41461066",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"execut exist python code code written python need deploi python code consist function return output jason format implement error result gener displai input dataset result dataset python devic dataset know new clue",
        "Question_preprocessed_content":"execut exist python code code python deploi python code consist function return output jason format implement result gener displai input dataset result dataset python devic dataset know new clue",
        "Question_gpt_summary_original":"The user is facing challenges in deploying existing Python code on Azure ML. Although there are no errors, the output is not generated and only the input dataset is displayed for both Result Dataset and Python device dataset. The user is seeking guidance on how to proceed as they are new to Azure ML.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to change metrics computation and recompute",
        "Question_body":"<p>Hi all,<br>\nI trained several models and computed a simple metrics summary for each of them. Now, those models (and their corresponding metrics.json files) are versioned by dvc and git and there is a git tag associated with each model.<br>\nHaving the models trained and stored, I would like to enrich the metrics summary and go back and recompute it for each model \u2013 and store it in git as with the simple summary. This means the last part of the pipeline, say compute_metrics.py, will be changed and I would like to run dvc repro again. Is there a simple way of recomputing the metrics for all models (that is for all tags)?<\/p>\n<p>Thank you,<br>\nMichal<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1575979302220,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":452.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/how-to-change-metrics-computation-and-recompute\/278",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"chang metric comput recomput train model comput simpl metric summari model correspond metric json file version git git tag associ model have model train store like enrich metric summari recomput model store git simpl summari mean pipelin comput metric chang like run repro simpl wai recomput metric model tag thank michal",
        "Question_preprocessed_content":"chang metric comput recomput train model comput simpl metric model version git git tag model have model train store like enrich metric recomput model store git simpl mean pipelin chang like run repro simpl wai recomput metric model thank michal",
        "Question_gpt_summary_original":"The user has trained several models and computed a simple metrics summary for each of them. Now, they want to enrich the metrics summary and recompute it for each model, and store it in git as with the simple summary. The user is looking for a simple way to recomputed the metrics for all models (that is for all tags).",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Error while deploying hugging pytorch model (ROBERTA) to Vertex AI",
        "Question_body":"Hello\n\nI am new to the vertex AI. I have created a binary classfication model using hugging face Pytorch model (ROBERTA).\u00a0 Now I am following the google vertex AI documentation to deploy but I am facing somer errors while deploying.\n\nERROR 2023-05-22T08:08:18.241378784Z usage: torchserve [-h] [-v | --start | --stop] [--ts-config TS_CONFIG]\nERROR 2023-05-22T08:08:18.241437196Z [--model-store MODEL_STORE]\nERROR 2023-05-22T08:08:18.241444587Z [--workflow-store WORKFLOW_STORE]\nERROR 2023-05-22T08:08:18.241451025Z [--models MODEL_PATH1 MODEL_NAME=MODEL_PATH2... [MODEL_PATH1 MODEL_NAME=MODEL_PATH2... ...]]\nERROR 2023-05-22T08:08:18.241456985Z [--log-config LOG_CONFIG] [--foreground]\nERROR 2023-05-22T08:08:18.241462945Z [--no-config-snapshots] [--plugins-path PLUGINS_PATH]\nERROR 2023-05-22T08:08:18.241468906Z torchserve: error: unrecognized arguments: --handler \/home\/jupyter\/Container\/hugging_face_handler.py\nERROR 2023-05-22T08:08:22.568594694Z usage: torchserve [-h] [-v | --start | --stop] [--ts-config TS_CONFIG]\nERROR 2023-05-22T08:08:22.568649768Z [--model-store MODEL_STORE]\nERROR 2023-05-22T08:08:22.568657159Z [--workflow-store WORKFLOW_STORE]\nERROR 2023-05-22T08:08:22.568664073Z [--models MODEL_PATH1 MODEL_NAME=MODEL_PATH2... [MODEL_PATH1 MODEL_NAME=MODEL_PATH2... ...]]\nERROR 2023-05-22T08:08:22.568670034Z [--log-config LOG_CONFIG] [--foreground]\nERROR 2023-05-22T08:08:22.568676233Z [--no-config-snapshots] [--plugins-path PLUGINS_PATH]\nERROR 2023-05-22T08:08:22.568681955Z torchserve: error: unrecognized arguments: --handler \/home\/jupyter\/Container\/hugging_face_handler.py\n\n\u00a0\n\nDocker Image code\n\nFROM pytorch\/torchserve:latest\n\n# Install additional dependencies if required\n# RUN pip install transformers\n\n# Copy the requirements file to the container\nCOPY requirements.txt \/home\/jupyter\/Container\/requirements.txt\n\n# Install the requirements\nRUN pip install -r \/home\/jupyter\/Container\/requirements.txt\n# Copy your model and inference code to the container\nCOPY cls \/home\/jupyter\/Container\/cls\nCOPY hugging_face_handler.py \/home\/jupyter\/Container\/hugging_face_handler.py\n\n# Set the working directory\nWORKDIR \/home\/jupyter\/Container\/\n\n# Expose the port used by TorchServe (default: 8080)\nEXPOSE 8080\n\n# Start TorchServe with your custom model and handler\nCMD [\"torchserve\", \"--start\", \"--model-store\", \".\", \"--models\", \"my_model=\/home\/jupyter\/Container\/cls\/pytorch_model.bin\", \"--handler\", \"\/home\/jupyter\/Container\/hugging_face_handler.py\"]\n\n\u00a0\n\n\u00a0\n\nHandler file code:\n\nfrom transformers import RobertaForSequenceClassification, RobertaTokenizer\nimport torch\nfrom sklearn import preprocessing\nimport numpy as np\n\nclass TransformersClassifierHandler(BaseHandler):\n\"\"\"\nThe handler takes an input string and returns the classification text\nbased on the serialized transformers checkpoint.\n\"\"\"\ndef __init__(self):\nsuper(TransformersClassifierHandler, self).__init__()\nself.initialized = False\nself.model = None\nself.tokenizer = None\nself.device = None\n\ndef initialize(self, ctx):\n# self.manifest = ctx.manifest\n# properties = ctx.system_properties\nmodel_dir = \"\/home\/jupyter\/Container\/cls\" # Set the model directory path\nself.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load model\nself.model = RobertaForSequenceClassification.from_pretrained(model_dir)\nself.model.to(self.device)\nself.model.eval()\nlogger.debug('Transformer model from path {0} loaded successfully'.format(model_dir))\n\n# Ensure to use the same tokenizer used during training\nself.tokenizer = RobertaTokenizer.from_pretrained(model_dir)\n\nself.initialized = True\n\ndef preprocess(self, data):\ntext = data.get(\"data\", [\"\"])[0]\nsentences = text.decode('utf-8')\nlogger.info(\"Received text: '%s'\", sentences)\n\n# Tokenize the texts\ntokenizer_args = ((sentences,))\ninputs = self.tokenizer(*tokenizer_args,\npadding='max_length',\nmax_length=512,\ntruncation=True,\nreturn_tensors=\"pt\")\nreturn inputs\n\ndef inference(self, inputs):\nwith torch.no_grad():\noutputs = self.model(**inputs)\nlogits = outputs.logits\nprobabilities = torch.softmax(logits, dim=1)\npredicted_labels = torch.argmax(probabilities, dim=1).item()\nreturn ['Y' if predicted_labels == 1 else 'N']\n\n\ndef postprocess(self, inference_output):\nreturn inference_output\n\n\u00a0\n\n\u00a0\n\nI am not sure where I am going wrong over here and getting the above mentioned error. So any help in this topic would be of great help\n\nThanks\n\nJagdish\n\n(PII Removed by Staff)\n\n(PII Removed by Staff)",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1684722720000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":54.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-while-deploying-hugging-pytorch-model-ROBERTA-to-Vertex-AI\/m-p\/595498#M1989",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error deploi hug pytorch model roberta hello new creat binari classfic model hug face pytorch model roberta follow document deploi face somer error deploi error usag torchserv start stop config config error model store model store error workflow store workflow store error model model path model model path model path model model path error log config log config foreground error config snapshot plugin path plugin path error torchserv error unrecogn argument handler home jupyt contain hug face handler error usag torchserv start stop config config error model store model store error workflow store workflow store error model model path model model path model path model model path error log config log config foreground error config snapshot plugin path plugin path error torchserv error unrecogn argument handler home jupyt contain hug face handler docker imag code pytorch torchserv latest instal addit depend requir run pip instal transform copi requir file contain copi requir txt home jupyt contain requir txt instal requir run pip instal home jupyt contain requir txt copi model infer code contain copi cl home jupyt contain cl copi hug face handler home jupyt contain hug face handler set work directori workdir home jupyt contain expos port torchserv default expos start torchserv custom model handler cmd torchserv start model store model model home jupyt contain cl pytorch model bin handler home jupyt contain hug face handler handler file code transform import robertaforsequenceclassif robertatoken import torch sklearn import preprocess import numpi class transformersclassifierhandl basehandl handler take input string return classif text base serial transform checkpoint def init self super transformersclassifierhandl self init self initi fals self model self token self devic def initi self ctx self manifest ctx manifest properti ctx properti model dir home jupyt contain cl set model directori path self devic torch devic cuda torch cuda avail cpu load model self model robertaforsequenceclassif pretrain model dir self model self devic self model eval logger debug transform model path load successfulli format model dir ensur us token train self token robertatoken pretrain model dir self initi true def preprocess self data text data data sentenc text decod utf logger info receiv text sentenc token text token arg sentenc input self token token arg pad max length max length truncat true return tensor return input def infer self input torch grad output self model input logit output logit probabl torch softmax logit dim predict label torch argmax probabl dim item return predict label def postprocess self infer output return infer output sure go wrong get mention error help topic great help thank jagdish pii remov staff pii remov staff",
        "Question_preprocessed_content":"deploi pytorch model new creat binari model face pytorch model document deploi face somer deploi usag torchserv torchserv unrecogn argument usag torchserv torchserv unrecogn argument docker imag code depend requir run pip transform copi requir file contain copi requir run pip copi model infer code contain copi cl copi set work directori workdir expos port torchserv expos start torchserv custom model handler cmd handler file code transform import robertatoken import torch sklearn import import numpi handler take input string return text base serial transform checkpoint def super fals def initi properti set model directori path cpu load model debug ensur us token train true def text sentenc info token text input truncat true return input def infer output logit probabl dim return def return sure go wrong mention help topic great help thank jagdish remov remov",
        "Question_gpt_summary_original":"The user is encountering errors while trying to deploy a binary classification model created using hugging face Pytorch model (ROBERTA) to Vertex AI. The error message suggests that there are unrecognized arguments in the torchserve command, specifically related to the handler file. The user has provided the Docker image code and handler file code for reference. The user is seeking help to identify the issue and resolve the error.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to perform Real Time Object Detection with trained AWS model",
        "Question_body":"<p>After successfully training object detection model with AWS SageMaker, how do I use this model to perform real time object detection on RTSP video?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1613826543790,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":162.0,
        "Poster_created_time":1597047251990,
        "Poster_location":null,
        "Poster_reputation_count":139.0,
        "Poster_view_count":46.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66291913",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"perform real time object detect train aw model successfulli train object detect model us model perform real time object detect rtsp video",
        "Question_preprocessed_content":"perform real time object detect train aw model train object detect model us model perform real time object detect rtsp video",
        "Question_gpt_summary_original":"The user has trained an object detection model with AWS SageMaker and is now seeking guidance on how to use the model for real-time object detection on RTSP video.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Wandb.Html() not displaying",
        "Question_body":"<p>I\u2019m trying to display a block of text (a confusion matrix actually, since they do not display in WB) using HTML.<br>\nThe code runs but it will not show up on run panel.  How can i see it?  It seems only images will display.<\/p>\n<pre><code class=\"lang-auto\">wandb.log({f\"ConfMatrix\" : wandb.Html(\"&lt;tt&gt;\"+my_confusion_matrix.ai2_confusion_matrix(y_true, y_pred...).replace(\"\\n\", \"&lt;P&gt;\").replace(\" \", \"&amp;nbsp;\"))})\n<\/code><\/pre>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1666068919749,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":309.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-html-not-displaying\/3271",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"html displai try displai block text confus matrix actual displai html code run run panel imag displai log confmatrix html confus matrix confus matrix true pred replac replac nbsp",
        "Question_preprocessed_content":"html displai try displai block text html code run run panel imag displai",
        "Question_gpt_summary_original":"The user is trying to display a confusion matrix using HTML in Wandb, but it is not showing up on the run panel. The user is seeking a solution to display the text block as only images seem to be displaying.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"I cannot see the progress of my modules run on Azure ML. Its stuck at the first module",
        "Question_body":"<p> When I run my ML on Azure ML Designer. I am unable to see the progress of the modules. The program runs at the back end however the designer interface seems to be stuck at the first module of Designer. If an error happens in any module, i dont get to know as I still see it stuck at the first module. I am using ML compute in US East  <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1629204002400,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/517242\/i-cannot-see-the-progress-of-my-modules-run-on-azu",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"progress modul run stuck modul run design unabl progress modul program run end design interfac stuck modul design error happen modul dont know stuck modul comput east",
        "Question_preprocessed_content":"modul run stuck modul run design unabl modul program run end design interfac stuck modul design modul dont know stuck modul comput east",
        "Question_gpt_summary_original":"The user is unable to see the progress of their modules run on Azure ML Designer and the interface seems to be stuck at the first module. They are using ML compute in US East and are unable to detect any errors that may occur in the subsequent modules.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How can dvc pipeline recognize when to use encoding pipeline while new data added for the modeling?",
        "Question_body":"<p>I have created separate pipelines for feature encoding and feature scaling in DVC.\nNow, when I will input new data from my flask API, how these DVC pipelines will automatically run and encode and scale data for modelling?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1654017845533,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":25.0,
        "Poster_created_time":1654016718443,
        "Poster_location":null,
        "Poster_reputation_count":9.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72451922",
        "Tool":"DVC",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pipelin recogn us encod pipelin new data ad model creat separ pipelin featur encod featur scale input new data flask api pipelin automat run encod scale data model",
        "Question_preprocessed_content":"pipelin recogn us encod pipelin new data model creat separ pipelin featur encod featur scale input new data flask api pipelin run encod scale data",
        "Question_gpt_summary_original":"The user has created separate pipelines for feature encoding and scaling in DVC and is wondering how these pipelines will automatically run and encode and scale new data for modeling when inputted from their Flask API.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Can I make Amazon SageMaker deliver a recommendation based on historic data instead of a probability score?",
        "Question_body":"<p>We have a huge set of data in CSV format, containing a few numeric elements, like this:<\/p>\n\n<pre><code>Year,BinaryDigit,NumberToPredict,JustANumber, ...other stuff\n1954,1,762,16, ...other stuff\n1965,0,142,16, ...other stuff\n1977,1,172,16, ...other stuff\n<\/code><\/pre>\n\n<p>The thing here is that there is a strong correlation between the third column and the columns before that. So I have pre-processed the data and it's now available in a format I think is perfect:<\/p>\n\n<pre><code>1954,1,762\n1965,0,142\n1977,1,172\n<\/code><\/pre>\n\n<p>What I want is a predicition on the value in the third column, using the first two as input. So in the case above, I want the input 1965,0 to return 142. In real life this file is thousands of rows, but since there's a pattern, I'd like to retrieve the most possible value.<\/p>\n\n<p>So far I've setup a train job on the CSV file using the L<em>inear Learner<\/em> algorithm, with the following settings:<\/p>\n\n<pre><code>label_size = 1\nfeature_dim = 2\npredictor_type = regression\n<\/code><\/pre>\n\n<p>I've also created a model from it, and setup an endpoint. When I invoke it, I get a score in return.<\/p>\n\n<pre><code>    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n                                   ContentType='text\/csv',\n                                   Body=payload)\n<\/code><\/pre>\n\n<p>My goal here is to get the third column prediction instead. How can I achieve that? I have read a lot of the documentation regarding this, but since I'm not very familiar with AWS, I might as well have used the wrong algorithms for what I am trying to do.<\/p>\n\n<p>(Please feel free to edit this question to better suit AWS terminology)<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1552553455710,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1552895653107,
        "Question_score_count":1.0,
        "Question_view_count":271.0,
        "Poster_created_time":1411464641600,
        "Poster_location":"\u00d6rebro, Sverige",
        "Poster_reputation_count":205.0,
        "Poster_view_count":38.0,
        "Answer_body":"<p>For csv input, the label should be in the first column, as mentioned <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/cdf-training.html\" rel=\"nofollow noreferrer\">here<\/a>:  So you should preprocess your data to put the label (the column you want to predict) on the left.<\/p>\n\n<p>Next, you need to decide whether this is a regression problem or a classification problem. <\/p>\n\n<p>If you want to predict a number that's as close as possible to the true number, that's regression. For example, the truth might be 4, and the model might predict 4.15. If you need an integer prediction, you could round the model's output.<\/p>\n\n<p>If you want the prediction to be one of a few categories, then you have a classification problem. For example, we might encode 'North America' = 0, 'Europe' = 1, 'Africa' = 2, and so on. In this case, a fractional prediction wouldn't make sense. <\/p>\n\n<p>For regression, use <code>'predictor_type' = 'regressor'<\/code> and for classification with more than 2 classes, use <code>'predictor_type' = 'multiclass_classifier'<\/code> as documented <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ll_hyperparameters.html\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>The output of regression will contain only a <code>'score'<\/code> field, which is the model's prediction. The output of multiclass classification will contain a <code>'predicted_label'<\/code> field, which is the model's prediction, as well as a <code>'score'<\/code> field, which is a vector of probabilities representing the model's confidence. The index with the highest probability will be the one that's predicted as the <code>'predicted_label'<\/code>. The output formats are documented <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/LL-in-formats.html\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1553880598532,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1373375969332,
        "Answerer_location":"New York, NY, USA",
        "Answerer_reputation_count":126.0,
        "Answerer_view_count":16.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55158307",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deliv recommend base histor data instead probabl score huge set data csv format contain numer element like year binarydigit numbertopredict justanumb stuff stuff stuff stuff thing strong correl column column pre process data avail format think perfect want predicit valu column input case want input return real life file thousand row pattern like retriev possibl valu far setup train job csv file linear learner algorithm follow set label size featur dim predictor type regress creat model setup endpoint invok score return respons runtim invok endpoint endpointnam endpoint contenttyp text csv bodi payload goal column predict instead achiev read lot document familiar aw wrong algorithm try feel free edit question better suit aw terminolog",
        "Question_preprocessed_content":"deliv base histor data instead probabl score huge set data csv format contain numer element like thing strong column column data avail format think perfect want predicit valu column input case want input return real life file thousand row like retriev valu far setup train job csv file linear learner algorithm creat model setup endpoint invok score return goal column predict instead achiev read lot document familiar aw wrong algorithm try edit question suit aw terminolog",
        "Question_gpt_summary_original":"The user has a large dataset in CSV format with a strong correlation between the third column and the columns before it. They have pre-processed the data and want to use the first two columns as input to predict the value in the third column. The user has set up a train job using the Linear Learner algorithm with regression settings and created a model and endpoint. However, when invoking the endpoint, they receive a score instead of the predicted value. The user is seeking guidance on how to achieve their goal of getting the predicted value instead of a score.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"I am not able to create a feature store in vertexAI using labels",
        "Question_body":"<p>I am passing the values of lables as below to create a featurestore with labels. But after creation of the featurestore, I do not see the featurestore created with labels. Is it still not supported in VertexAI<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>    fs = aiplatform.Featurestore.create(\n        featurestore_id=featurestore_id,\n        labels=dict(project='retail', env='prod'),\n        online_store_fixed_node_count=online_store_fixed_node_count,\n        sync=sync\n    )\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/viOSu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/viOSu.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1651616413553,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1651623411107,
        "Question_score_count":0.0,
        "Question_view_count":83.0,
        "Poster_created_time":1530457174832,
        "Poster_location":null,
        "Poster_reputation_count":1043.0,
        "Poster_view_count":212.0,
        "Answer_body":"<p>As mentioned in this <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/featurestore\/managing-featurestores\" rel=\"nofollow noreferrer\">featurestore documentation<\/a>:<\/p>\n<blockquote>\n<p>A <strong>featurestore<\/strong> is a top-level container for entity types, features,\nand feature values.<\/p>\n<\/blockquote>\n<p>With this, the GCP console UI &quot;labels&quot; are the &quot;labels&quot; at the <strong>Feature<\/strong> level.<\/p>\n<p>Once a <strong>featurestore<\/strong> is created, you will need to create an <strong>entity<\/strong> and then create a <strong>Feature<\/strong> that has the <em>labels<\/em> parameter as shown on the below sample python code.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from google.cloud import aiplatform\n\ntest_label = {'key1' : 'value1'}\n\ndef create_feature_sample(\n    project: str,\n    location: str,\n    feature_id: str,\n    value_type: str,\n    entity_type_id: str,\n    featurestore_id: str,\n):\n\n    aiplatform.init(project=project, location=location)\n\n    my_feature = aiplatform.Feature.create(\n        feature_id=feature_id,\n        value_type=value_type,\n        entity_type_name=entity_type_id,\n        featurestore_id=featurestore_id,\n        labels=test_label,\n    )\n\n    my_feature.wait()\n\n    return my_feature\n\ncreate_feature_sample('your-project','us-central1','test_feature3','STRING','test_entity3','test_fs3')\n<\/code><\/pre>\n<p>Below is the screenshot of the GCP console which shows that <em>labels<\/em> for <strong>test_feature3<\/strong> feature has the values defined in the above sample python code.\n<a href=\"https:\/\/i.stack.imgur.com\/7S2oa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7S2oa.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>You may refer to this <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/featurestore\/managing-features#create-feature\" rel=\"nofollow noreferrer\">creation of feature documentation<\/a> using python for more details.<\/p>\n<p>On the other hand, you may still view the <em>labels<\/em> you defined for your featurestore using the REST API as shown on the below sample.<\/p>\n<pre><code>curl -X GET \\\n-H &quot;Authorization: Bearer &quot;$(gcloud auth application-default print-access-token) \\\n&quot;https:\/\/&lt;your-location&gt;-aiplatform.googleapis.com\/v1\/projects\/&lt;your-project&gt;\/locations\/&lt;your-location&gt;\/featurestores&quot;\n<\/code><\/pre>\n<p>Below is the result of the REST API which also shows the value of the <em>labels<\/em> I defined for my &quot;test_fs3&quot; featurestore.\n<a href=\"https:\/\/i.stack.imgur.com\/gW45X.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gW45X.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1651709813300,
        "Answer_last_edit_time":1651710305260,
        "Answer_score_count":0.0,
        "Answerer_created_time":1639972620503,
        "Answerer_location":null,
        "Answerer_reputation_count":1653.0,
        "Answerer_view_count":1212.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72106030",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"abl creat featur store vertexai label pass valu labl creat featurestor label creation featurestor featurestor creat label support vertexai aiplatform featurestor creat featurestor featurestor label dict project retail env prod onlin store fix node count onlin store fix node count sync sync",
        "Question_preprocessed_content":"abl creat featur store vertexai label valu labl creat featurestor label creation featurestor featurestor creat label vertexai",
        "Question_gpt_summary_original":"The user is unable to create a feature store in VertexAI using labels. They have passed the values of labels to create a feature store, but after creation, they are unable to see the feature store created with labels. The user is unsure if this feature is supported in VertexAI.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Mono repo Kedro project",
        "Question_body":"<p>I started a Kedro project a while ago and started to build different parts of the pipeline which only tangentially interact with each other. In some cases not much at all.<\/p>\n<p>As a consequence, as the project grew, I am starting to get issues with the dependencies given that the installation process uses requirement.txt<\/p>\n<p>Thus I wanted to ask if Kedro was meant to be designed as a mono repo or not.\nIf so, is there an example of how this could be done, please?\nThanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1650877645533,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":68.0,
        "Poster_created_time":1384332648270,
        "Poster_location":null,
        "Poster_reputation_count":158.0,
        "Poster_view_count":22.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71997005",
        "Tool":"Kedro",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"mono repo project start project ago start build differ part pipelin tangenti interact case consequ project grew start issu depend given instal process us requir txt want ask meant design mono repo exampl thank advanc",
        "Question_preprocessed_content":"mono repo project start project ago start build part pipelin interact case consequ project grew start depend given us want ask meant design mono repo exampl thank advanc",
        "Question_gpt_summary_original":"The user started a Kedro project with different parts of the pipeline that have minimal interaction with each other. As the project grew, the user encountered dependency issues during installation using requirement.txt. The user is now asking if Kedro is designed to be a mono repo and if there are examples of how to do it.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Basic DVC workflow",
        "Question_body":"<p>I\u2019m a new DVC user and I have a question about the basic model management workflow.<\/p>\n<p>I\u2019ve configured a repo for DVC, I ran a test experiment by creating a feature branch. I ran a sweep and selected the <code>best<\/code> model, i.e.<\/p>\n<pre><code class=\"lang-auto\">dvc exp run -S 'train.batch_size=16,32,64,128' --queue\ndvc queue start\ndvc exp apply ex1\ngit add .\ngit commit -m 'My Experiment'\n<\/code><\/pre>\n<p>I have a question about how to merge this back to main correctly, the process I\u2019ve been following is:<\/p>\n<ul>\n<li>switch to <code>main<\/code>\n<\/li>\n<li>merge the feature branch to <code>main<\/code>\n<\/li>\n<li><code>dvc pull<\/code><\/li>\n<\/ul>\n<p>The last step seems to be important - if I don\u2019t do the the vscode source control sidebar shows uncommitted DVC tracked model files. Is this the correct workflow (I\u2019m about to learn GTO but I wanted to ensure that I can correctly manage the state of my <code>main<\/code> branch first).<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1674171670865,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":80.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/basic-dvc-workflow\/1467",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"basic workflow new user question basic model manag workflow iv configur repo ran test experi creat featur branch ran sweep select best model exp run train batch size queue queue start exp appli git add git commit experi question merg main correctli process iv follow switch main merg featur branch main pull step import dont vscode sourc control sidebar show uncommit track model file correct workflow learn gto want ensur correctli manag state main branch",
        "Question_preprocessed_content":"basic workflow new user question basic model manag workflow iv configur repo ran test experi creat featur branch ran select model question merg main iv switch merg featur branch step import dont vscode sourc control sidebar show track model file workflow",
        "Question_gpt_summary_original":"The user is a new DVC user who has configured a repo for DVC and ran a test experiment by creating a feature branch. They have a question about how to merge this back to main correctly and are following a process of switching to main, merging the feature branch to main, and doing a \"dvc pull\" which seems to be important to avoid uncommitted DVC tracked model files. They want to know if this is the correct workflow.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML: Creating a Siamese network, I have the reference data stored in one blob storage and the user input stored in another blob storage. How can I connect the two blob storage to my batch endpoint. If not, is there a workaround?",
        "Question_body":"<p>Azure ML: Creating a Siamese network, I have the reference data stored in one blob storage and the user input stored in another blob storage. How can I connect the two blob storage to my batch endpoint. If not, is there a workaround? The setup looks like this. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/239776-screenshot-2022-09-11-at-105820.png?platform=QnA\" alt=\"239776-screenshot-2022-09-11-at-105820.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662886746297,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1002087\/azure-ml-creating-a-siamese-network-i-have-the-ref",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat siames network refer data store blob storag user input store blob storag connect blob storag batch endpoint workaround creat siames network refer data store blob storag user input store blob storag connect blob storag batch endpoint workaround setup look like",
        "Question_preprocessed_content":"creat siames network refer data store blob storag user input store blob storag blob storag batch endpoint workaround creat siames network refer data store blob storag user input store blob storag blob storag batch endpoint workaround setup like",
        "Question_gpt_summary_original":"The user is facing a challenge in connecting two blob storages, one containing reference data and the other containing user input, to their batch endpoint while creating a Siamese network in Azure ML. They are seeking a workaround if direct connection is not possible.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Trying to invoke an AWS sagemaker endpoint for a locally trained Object detection model (with .pb file). Facing this issue while invoking",
        "Question_body":"<p>I have created a multi model endpoint and facing issue while invoking the object detection model alone. The OD model has only .pb file and no variables folder in the saved model dir. While trying to invoke the endpoint with a sample image, I am getting this error:\n<a href=\"https:\/\/i.stack.imgur.com\/H4I3v.png\" rel=\"nofollow noreferrer\">Error in Cloudwatch:<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1631791432093,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":32.0,
        "Poster_created_time":1605887877220,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69207550",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"try invok endpoint local train object detect model file face issu invok creat multi model endpoint face issu invok object detect model model file variabl folder save model dir try invok endpoint sampl imag get error error cloudwatch",
        "Question_preprocessed_content":"try invok endpoint train object detect model face invok creat multi model endpoint face invok object detect model model file variabl folder save model dir try invok endpoint sampl imag cloudwatch",
        "Question_gpt_summary_original":"The user is facing an issue while trying to invoke an AWS Sagemaker endpoint for a locally trained object detection model with only a .pb file and no variables folder in the saved model directory. The user is receiving an error while trying to invoke the endpoint with a sample image.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Source custom shell script when running in remote virtual environment",
        "Question_body":"<p>I am using a <code>ssh<\/code> remote with the following setup:<\/p>\n<pre><code>remotes:\n  azure-deeplearning:\n    type: ssh\n    host: deeplearning.guild.ai\n    venv-path: mypath\/.training_venv\n    user: myuser\n    use-prerelease: yes\n<\/code><\/pre>\n<p>The <code>venv<\/code> gets correctly activated. The issue is that I need to source a setup file after the <code>venv<\/code> gets activated. If I were to do it manually on the remote I would do:<\/p>\n<pre><code>source mypath\/.training-venv\/bin\/activate\nsource my_custom_bash.sh\n<\/code><\/pre>\n<p>How would this fit into the guild remote workflow?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1602179862963,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":521.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/source-custom-shell-script-when-running-in-remote-virtual-environment\/368",
        "Tool":"Guild AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sourc custom shell script run remot virtual environ ssh remot follow setup remot azur deeplearn type ssh host deeplearn venv path mypath train venv user myuser us prereleas ye venv get correctli activ issu need sourc setup file venv get activ manual remot sourc mypath train venv bin activ sourc custom bash fit remot workflow",
        "Question_preprocessed_content":"sourc custom script remot virtual environ remot setup get activ sourc setup file get activ remot fit remot workflow",
        "Question_gpt_summary_original":"The user is facing an issue while using a remote virtual environment via ssh. The virtual environment gets activated correctly, but the user needs to source a custom shell script after activation, which is not happening automatically. The user is seeking guidance on how to incorporate the custom shell script into the remote workflow.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to disable logs in Kedro",
        "Question_body":"<p>I have been unsuccessful in disabling kedro logs.  I have tried adding <code>disable_existing_loggers: True<\/code> to the logging.yml file as well as <code>disable:True<\/code> to all of the existing logs and it still appears to be saving log files.  Any suggestions?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1573137628147,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":410.0,
        "Poster_created_time":1479159384132,
        "Poster_location":"Illinois, United States",
        "Poster_reputation_count":513.0,
        "Poster_view_count":113.0,
        "Answer_body":"<p>If you want <code>kedro<\/code> to stop logging you can override the <code>_setup_logging<\/code> in <code>ProjectContext<\/code> in <code>src\/&lt;package-name&gt;\/run.py<\/code> as per the <a href=\"https:\/\/kedro.readthedocs.io\/en\/latest\/04_user_guide\/07_logging.html#configure-logging\" rel=\"nofollow noreferrer\">documentation<\/a>. For example:<\/p>\n\n<pre><code>class ProjectContext(KedroContext):\n    \"\"\"Users can override the remaining methods from the parent class here, or create new ones\n    (e.g. as required by plugins)\n\n    \"\"\"\n\n    project_name = \"&lt;PACKGE-NAME&gt;\"\n    project_version = \"0.15.4\"\n\n    def _get_pipelines(self) -&gt; Dict[str, Pipeline]:\n        return create_pipelines()\n\n    def _setup_logging(self) -&gt; None:\n        import logging\n        logging.disable()\n<\/code><\/pre>\n\n<p>If you want it to still log to the console, but not save to <code>logs\/info.log<\/code> then you can do <code>def _setup_logging(self) -&gt; None: pass<\/code>.<\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1573141908796,
        "Answer_last_edit_time":1573142581883,
        "Answer_score_count":3.0,
        "Answerer_created_time":1530092504712,
        "Answerer_location":"London, United Kingdom",
        "Answerer_reputation_count":915.0,
        "Answerer_view_count":288.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58751122",
        "Tool":"Kedro",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"disabl log unsuccess disabl log tri ad disabl exist logger true log yml file disabl true exist log appear save log file suggest",
        "Question_preprocessed_content":"disabl log disabl log tri yml file exist log save log file",
        "Question_gpt_summary_original":"The user is having trouble disabling logs in Kedro despite trying to add \"disable_existing_loggers: True\" to the logging.yml file and \"disable:True\" to existing logs. They are seeking suggestions to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"is it possible to trigger a sagmamker pipeline execution via event bridge?",
        "Question_body":"I have a sagemaker pipeline code , currently run through a notebook , but i would like to hook it up to a evenbridge and trigger an execution. is it possible to do that , if yes, what permissions would i need and if there any samples of the event , that would be great",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1681850824873,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1682197563478,
        "Question_score_count":0.0,
        "Question_view_count":47.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUVa1pPnIUQuK_zwh8E1wHyA\/is-it-possible-to-trigger-a-sagmamker-pipeline-execution-via-event-bridge",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl trigger sagmamk pipelin execut event bridg pipelin code current run notebook like hook evenbridg trigger execut possibl ye permiss need sampl event great",
        "Question_preprocessed_content":"sagmamk pipelin execut event bridg pipelin code run like evenbridg execut ye sampl event great",
        "Question_gpt_summary_original":"The user wants to know if it is possible to trigger a Sagemaker pipeline execution via Event Bridge. They are currently running the pipeline through a notebook and want to know what permissions they would need and if there are any samples of the event.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Can't find the run button",
        "Question_body":"<p>****Do I need to add the .ipynb extension manually to my notebook file ?**  <br \/>\n**I can't find the run button.****<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/85574-capture2.png?platform=QnA\" alt=\"85574-capture2.png\" \/><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1617852662423,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=441c29e9-5f3d-4595-9f6c-dec6fcde5e85\">@paul gureghian  <\/a> You can re-name your file with .ipynb extension which should help to display the cells and the available options like run button for cell. Usually while creating new files in your workspace the UI prompts to select the extension of the file. If you can create a new file with .ipynb extension and copy these cells individually that should also work. Thanks.<\/p>\n",
        "Answer_comment_count":2.0,
        "Question_closed_time":1617872811416,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/348777\/cant-find-the-run-button",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run button need add ipynb extens manual notebook file run button",
        "Question_preprocessed_content":"run ipynb extens file run",
        "Question_gpt_summary_original":"The user is unable to find the run button in their notebook file and is unsure if they need to manually add the .ipynb extension to the file.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Being told to contact Vertex AI support but we don't have a support contract?!",
        "Question_body":"Getting an internal error when training a model on Vertex AI.\n\nI have gotten repeated emails from Google telling me to contact Vertex AI support about this.\n\nWe don't pay for a support contract.\n\nIt seems odd that there is no way to report issues like this to Vertex AI without a support contract.",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1646739240000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":81.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Being-told-to-contact-Vertex-AI-support-but-we-don-t-have-a\/m-p\/401449#M227",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"told contact support support contract get intern error train model gotten repeat email googl tell contact support pai support contract odd wai report issu like support contract",
        "Question_preprocessed_content":"told contact contract intern train model repeat email contact pai contract wai report like contract",
        "Question_gpt_summary_original":"The user is encountering an internal error while training a model on Vertex AI and has been receiving emails from Google to contact Vertex AI support. However, the user does not have a support contract and is unable to report the issue to Vertex AI without one.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to return a Dataframe in Azure ML from a python script",
        "Question_body":"<p>I have the below Python script. And I'm trying to return the new Dataframe created. Unfortunately, I'm getting \"NotImplementedError:\"<\/p>\n\n<p>Please let me know, how to return a Dataframe in Azure ML from a python script<\/p>\n\n<p>Code:<\/p>\n\n<pre><code>def azureml_main(df) :\n\n    therm_patterns,therm_missed_patterns = thermostat_phase(df)\n    th_pat = json.loads(therm_patterns)\n    missed_th_pat = json.loads(therm_missed_patterns)\n\n    light_patterns, light_missed_patterns = light_phase(df)\n    lt_pat = json.loads(light_patterns)\n    missed_lt_pat = json.loads(light_missed_patterns)\n\n    for j in range (0,len(lt_pat)):\n        for i in range (0,len(lt_pat[0]['John'])):\n            th_pat[0]['John'].append(lt_pat[0]['John'][i])\n    for j in range (0,len(lt_pat)):\n        for i in range (0,len(lt_pat[0]['Jane'])):\n            th_pat[0]['Jane'].append(lt_pat[0]['Jane'][i])\n    for j in range (0,len(lt_pat)):\n        for i in range (0,len(lt_pat[0]['Jen'])):\n            th_pat[0]['Jen'].append(lt_pat[0]['Jen'][i])\n\n    for j in range (0,len(missed_lt_pat)):\n        for i in range (0,len(missed_lt_pat[0]['John'])):\n            missed_th_pat[0]['John'].append(missed_lt_pat[0]['John'][i])\n    for j in range (0,len(missed_lt_pat)):\n        for i in range (0,len(missed_lt_pat[0]['Jane'])):\n            missed_th_pat[0]['Jane'].append(missed_lt_pat[0]['Jane'][i])\n    for j in range (0,len(missed_lt_pat)):\n        for i in range (0,len(missed_lt_pat[0]['Jen'])):\n            missed_th_pat[0]['Jen'].append(missed_lt_pat[0]['Jen'][i])\n\n    output = json.dumps(th_pat)\n\n    df = pd.DataFrame.from_dict({k: v[0] for k, v in json.loads(output) \n    [0].items()}, 'index' ).rename_axis('User').reset_index()\n\n\n    return df         \n<\/code><\/pre>\n\n<p>Error:<\/p>\n\n<pre><code>  Error 0085: The following error occurred during script evaluation, please  \n  view the output log for more information:\n\n   ---------- Start of error message from Python interpreter ----------\n   Caught exception while executing function: Traceback (most recent call  \n   last):\n\n       File \"C:\\server\\invokepy.py\", line 211, in batch\n       xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True)\n\n       File \"C:\\server\\XDRReader\\xdrutils.py\", line 54, in DataFrameToRFile\n       xdrwriter.write_attribute_list(attributes)\n\n       File \"C:\\server\\XDRReader\\xdrwriter2.py\", line 155, in   \n       write_attribute_list\n       self.write_object(value)\n\n       File \"C:\\server\\XDRReader\\xdrwriter2.py\", line 215, in write_object\n       write_func(flags, converted, missingIndices)\n\n       File \"C:\\server\\XDRReader\\xdrwriter2.py\", line 185, in write_objects\n       self.write_object(value)\n\n       File \"C:\\server\\XDRReader\\xdrwriter2.py\", line 200, in write_object\n       raise NotImplementedError('Python Bridge conversion table not    \n       implemented for type [{0}]'.format(value.getType()))\n\n       NotImplementedError: Python Bridge conversion table not implemented  \n       for type [&lt;type 'list'&gt;]\n\n       Process returned with non-zero exit code 1\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1484124401607,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1484584933627,
        "Question_score_count":3.0,
        "Question_view_count":1101.0,
        "Poster_created_time":1479194627132,
        "Poster_location":null,
        "Poster_reputation_count":2713.0,
        "Poster_view_count":358.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41586275",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"return datafram python script python script try return new datafram creat unfortun get notimplementederror let know return datafram python script code def main therm pattern therm miss pattern thermostat phase pat json load therm pattern miss pat json load therm miss pattern light pattern light miss pattern light phase pat json load light pattern miss pat json load light miss pattern rang len pat rang len pat john pat john append pat john rang len pat rang len pat jane pat jane append pat jane rang len pat rang len pat jen pat jen append pat jen rang len miss pat rang len miss pat john miss pat john append miss pat john rang len miss pat rang len miss pat jane miss pat jane append miss pat jane rang len miss pat rang len miss pat jen miss pat jen append miss pat jen output json dump pat datafram dict json load output item index renam axi user reset index return error error follow error occur script evalu view output log inform start error messag python interpret caught except execut function traceback recent file server invokepi line batch xdrutil xdrutil dataframetorfil outlist outfil true file server xdrreader xdrutil line dataframetorfil xdrwriter write attribut list attribut file server xdrreader xdrwriter line write attribut list self write object valu file server xdrreader xdrwriter line write object write func flag convert missingindic file server xdrreader xdrwriter line write object self write object valu file server xdrreader xdrwriter line write object rais notimplementederror python bridg convers tabl implement type format valu gettyp notimplementederror python bridg convers tabl implement type process return non zero exit code",
        "Question_preprocessed_content":"return datafram python script python script try return new datafram creat unfortun let know return datafram python script code",
        "Question_gpt_summary_original":"The user is trying to return a new Dataframe created in a Python script in Azure ML, but is encountering a \"NotImplementedError\" and is unable to do so. The error message suggests that the Python Bridge conversion table is not implemented for the type \"list\".",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Run a Vertex AI model locally",
        "Question_body":"<p>Using the Vertex AI product at GCP training was very easy, I uploaded a data set and it returned a model which is saved in a gcp bucket, I downloaded the files and the tree has these files<\/p>\n<pre><code>\u251c\u2500\u2500 environment.json\n\u251c\u2500\u2500 feature_attributions.yaml\n\u251c\u2500\u2500 final_model_structure.pb\n\u251c\u2500\u2500 instance.yaml\n\u251c\u2500\u2500 predict\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 001\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 assets\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 PVC_vocab\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 assets.extra\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 tf_serving_warmup_requests\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 saved_model.pb\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 variables\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 variables.data-00000-of-00001\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 variables.index\n\u251c\u2500\u2500 prediction_schema.yaml\n\u251c\u2500\u2500 tables_server_metadata.pb\n\u2514\u2500\u2500 transformations.pb\n<\/code><\/pre>\n<p>I would like to serve this model locally from a dockerized python application, but I don't know enough TF to do this and I am very confused about which <code>.pb<\/code> file is the actual one that has the neural network I need.<\/p>\n<p>Thanks for any tips.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_created_time":1649554815260,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":261.0,
        "Poster_created_time":1483057875592,
        "Poster_location":"St. Louis, MO, USA",
        "Poster_reputation_count":710.0,
        "Poster_view_count":175.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71813169",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run model local product gcp train easi upload data set return model save gcp bucket download file tree file environ json featur attribut yaml final model structur instanc yaml predict asset pvc vocab asset extra serv warmup request save model variabl variabl data variabl index predict schema yaml tabl server metadata transform like serv model local docker python applic know confus file actual neural network need thank tip",
        "Question_preprocessed_content":"run model product gcp train easi upload data set return model save gcp bucket download file file like serv model docker python know confus file actual neural network thank tip",
        "Question_gpt_summary_original":"The user has successfully trained a model using Vertex AI product at GCP and downloaded the model files from a GCP bucket. However, the user is facing challenges in serving the model locally from a dockerized python application due to lack of knowledge in TensorFlow and confusion about which .pb file contains the required neural network. The user is seeking tips to overcome this challenge.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to retrieve all the artifacts lineage for a set of runs, based on both the name of the run, and the name of the artifact?",
        "Question_body":"From slack\n\nI have several runs with the named RUN_NAME each run is logging an artifact named ARTIFACT_NAME. I would like to query all these artifacts from all this subset of runs.\n\nWhat I\u2019m using to try to achieve this is calling RunClient.client.runs_v1.get_runs_artifacts_lineage, but in this function I get all artifacts from all runs ever independently from the run name.\nAlso, when listing the artifacts from these runs, for some reason the path is always None, even though if I use the function you suggested last time, get_artifacts_lineage , for a specific run, I do get values on the path field.\nSo my two main issues are:\n\nHow do I get all artifacts from a set of runs with the same run_name?\nWhy the path is empty in case this is the correct function to use?",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1649410426000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"To filter all artifacts lineage directly by run name and artifact name:\n\nfrom polyaxon.client import RunClient\n\nRunClient.client.runs_v1.get_runs_artifacts_lineage(project=\"PROJECT_NAME\", query=\"run.name: RUN_NAME, kind: ARTIFACT_KIND, name: ARTIFACT_NAME\")",
        "Answer_comment_count":0.0,
        "Question_closed_time":1649410506000,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1486",
        "Tool":"Polyaxon",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retriev artifact lineag set run base run artifact slack run name run run log artifact name artifact like queri artifact subset run try achiev call runclient client run run artifact lineag function artifact run independ run list artifact run reason path us function suggest time artifact lineag specif run valu path field main issu artifact set run run path case correct function us",
        "Question_preprocessed_content":"retriev artifact lineag set run base run artifact slack run name run artifact name like queri artifact subset run try achiev function artifact run independ run list artifact run reason path us function time specif run valu path field main artifact set run path case function us",
        "Question_gpt_summary_original":"The user is trying to retrieve all artifacts lineage for a set of runs based on both the name of the run and the name of the artifact. They are using the RunClient.client.runs_v1.get_runs_artifacts_lineage function but are getting all artifacts from all runs ever, regardless of the run name. Additionally, when listing the artifacts from these runs, the path is always None, even though the function get_artifacts_lineage for a specific run returns values on the path field. The user is facing two main issues: how to get all artifacts from a set of runs with the same run_name and why the path is empty in case this is the correct function to use.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Disable Azure Datastore download message",
        "Question_body":"<p>Is there any way to disable the warning presented whenever a file is loaded for the first time in Azure ML using datastores?<\/p>\n<pre><code>Downloaded path: \/tmp\/tmp5dto5vq4\/path\/to\/file.txt is different from target path: \/tmp\/tmp5dto5vq4\/path\/to\/file.txt\n<\/code><\/pre>\n<p>I connect to the Datastore following the azure tutorial:<\/p>\n<pre><code>ws = Workspace.from_config()\nmounted_path = tempfile.mkdtemp()\ndataset = Dataset.get_by_name(workspace = ws, name = 'name')\nmount_context = dataset.mount(mounted_path)\n\nmount_context.start()\n\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1644884590780,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":106.0,
        "Poster_created_time":1490704811283,
        "Poster_location":"K\u00f8benhavn, Danmark",
        "Poster_reputation_count":94.0,
        "Poster_view_count":22.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71119807",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"disabl azur datastor download messag wai disabl warn present file load time datastor download path tmp tmpdtovq path file txt differ target path tmp tmpdtovq path file txt connect datastor follow azur tutori workspac config mount path tempfil mkdtemp dataset dataset workspac mount context dataset mount mount path mount context start",
        "Question_preprocessed_content":"disabl azur datastor download wai disabl warn present file load time datastor datastor azur tutori",
        "Question_gpt_summary_original":"The user is encountering a warning message when loading a file for the first time in Azure ML using datastores. They are looking for a way to disable this warning message. The user is following the Azure tutorial to connect to the Datastore.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"trains with grid search",
        "Question_body":"<p>I would like to test <a href=\"https:\/\/github.com\/allegroai\/trains\" rel=\"nofollow noreferrer\">trains<\/a> usage during grid search and it not clear how to do so.<\/p>\n\n<pre><code>from trains import Task \nTask.init(project_name=\"project name\", task_name='name')\n<\/code><\/pre>\n\n<p>creates an experiment in the demo server and logs all but you can't call init twice no matter the 'task_name' and <\/p>\n\n<pre><code>from trains import Task \nTask.create(project_name=\"project name\", task_name='name')\n<\/code><\/pre>\n\n<p>can be called with different 'task_name' but thus not log any data into the server and creates only 'Draft'.<\/p>\n\n<p>here is a sample code:<\/p>\n\n<pre><code> epochs=[160,300]\n for epoch in epochs:\n    model = define_model_run(epoch)\n    model.fit(x_train,y_train)\n    score = model.score(...)\n<\/code><\/pre>\n\n<p>my final try was:<\/p>\n\n<pre><code> epochs=[160,300]\n task=Task.init(project_name=\"demo\", task_name='search')\n for epoch in epochs:\n    task.create(project_name=\"demo\", task_name=f'search_{epoch}')\n    model = define_model_run(epoch)\n    model.fit(x_train,y_train)\n    score = model.score(...)\n<\/code><\/pre>\n\n<p>which logs all information under the experiments tab and none under the 'Draft'.\nI tried the last two hour the read the few documentations provided and reading the source code, but no luck.<\/p>\n\n<p>any help? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1566218806593,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1609778640296,
        "Question_score_count":1.0,
        "Question_view_count":121.0,
        "Poster_created_time":1416942229380,
        "Poster_location":null,
        "Poster_reputation_count":161.0,
        "Poster_view_count":58.0,
        "Answer_body":"<p>Declaimer: I'm a member of TRAINS team<\/p>\n\n<p>Yes, that's exactly the answer.\nThe idea is that you always have one main Task, in order to create a new one you need to close the running Task, and re-initialize with a new name.\nKudos on solving it so quickly :)<\/p>\n\n<p>BTW: You can see examples <a href=\"https:\/\/stackoverflow.com\/q\/56744397\/11682840\">here<\/a>\/<a href=\"https:\/\/github.com\/allegroai\/trains\/blob\/master\/docs\/faq.md#can-i-create-a-graph-comparing-hyper-parameters-vs-model-accuracy-\" rel=\"nofollow noreferrer\">and here<\/a>, showing how to send accuracy logs so it is easier to compare the experiments, especially when running hyper-parameter search.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1566240704540,
        "Answer_last_edit_time":1566242122212,
        "Answer_score_count":0.0,
        "Answerer_created_time":1561143508792,
        "Answerer_location":"TRAINS Station",
        "Answerer_reputation_count":489.0,
        "Answerer_view_count":60.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57557070",
        "Tool":"ClearML",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train grid search like test train usag grid search clear train import task task init project project task creat experi demo server log init twice matter task train import task task creat project project task call differ task log data server creat draft sampl code epoch epoch epoch model defin model run epoch model fit train train score model score final try epoch task task init project demo task search epoch epoch task creat project demo task search epoch model defin model run epoch model fit train train score model score log inform experi tab draft tri hour read document provid read sourc code luck help",
        "Question_preprocessed_content":"train grid search like test train usag grid search clear creat experi demo server log init twice log data server creat draft sampl code final try log inform experi tab draft tri hour read document provid read sourc code luck help",
        "Question_gpt_summary_original":"The user is trying to use the Trains library for grid search but is having trouble logging data into the server. They have tried different methods, including calling the 'init' and 'create' functions with different task names, but have not been successful. They are seeking help to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Experiments disappear when adding --backend-store-uri",
        "Question_body":"<p>I have an EC2 instance running a mlflow server using the following command:<\/p>\n<pre><code>mlflow server -h 0.0.0.0 --default-artifact-root s3:\/\/xxxx\n<\/code><\/pre>\n<p>After running multiple experiments, I was trying to register the best one. However, when trying to register or accessing the tab &quot;Models&quot;, I get the following error:<\/p>\n<blockquote>\n<p>INVALID_PARAMETER_VALUE: Model registry functionality is unavailable; got unsupported URI '.\/mlruns' for model registry data storage. Supported URI schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. See <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage<\/a> for how to run an MLflow server against one of the supported backend storage locations.<\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/63255631\/mlflow-invalid-parameter-value-unsupported-uri-mlruns-for-model-registry-s\">This SO answer<\/a> suggested adding a <code>backend-store-uri<\/code>:<\/p>\n<pre><code>mlflow server -h 0.0.0.0 --default-artifact-root --backend-store-uri sqlite:\/\/\/mlflow.db\n<\/code><\/pre>\n<p>That solved the above issue, however, now all experiments are gone. The Experiments tab is blank. Is there a way to add a <code>backend-store-uri<\/code> after running multiple experiments while keeping all of them?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1651906154493,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":208.0,
        "Poster_created_time":1394900987340,
        "Poster_location":"Curitiba, State of Paran\u00e1, Brazil",
        "Poster_reputation_count":1490.0,
        "Poster_view_count":346.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72150148",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"experi disappear ad backend store uri instanc run server follow command server default artifact root xxxx run multipl experi try regist best try regist access tab model follow error invalid paramet valu model registri function unavail got unsupport uri mlrun model registri data storag support uri scheme postgresql mysql sqlite mssql http www org doc latest track html storag run server support backend storag locat answer suggest ad backend store uri server default artifact root backend store uri sqlite solv issu experi gone experi tab blank wai add backend store uri run multipl experi keep",
        "Question_preprocessed_content":"experi instanc server multipl experi try regist best try regist tab model model registri function unavail got uri model registri data storag uri scheme run server backend storag locat answer solv experi gone experi tab blank wai multipl experi",
        "Question_gpt_summary_original":"The user encountered an issue with MLflow server where the Model registry functionality was unavailable due to an unsupported URI. They followed a suggestion to add a backend-store-uri which solved the issue but caused all experiments to disappear. The user is seeking a solution to add a backend-store-uri without losing their experiments.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"consolidatedAnnotation attribute is null error from AWS SageMaker Ground Truth",
        "Question_body":"<p>I have used AWS SageMaker Ground Truth to annotate an image using Mechanical Turk.<\/p>\n\n<p>The labelling job failed with the following error in the output manifest:<\/p>\n\n<pre><code>{\"source-ref\":\"&lt;MYIMAGE&gt;\",\"Test1-ref-metadata\":{\"retry-count\":1,\"failure-reason\":\"Error in Annotation Consolidation Response :  consolidatedAnnotation attribute is null\",\"human-annotated\":\"true\"}}\n<\/code><\/pre>\n\n<p>Does anyone have an idea if this is a bug or if I made a mistake?<\/p>\n\n<p>Thanks\nChris<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1543547061310,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":328.0,
        "Poster_created_time":1270006662236,
        "Poster_location":"Perth, Australia",
        "Poster_reputation_count":1094.0,
        "Poster_view_count":91.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53550636",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"consolidatedannot attribut null error ground truth ground truth annot imag mechan turk label job fail follow error output manifest sourc ref test ref metadata retri count failur reason error annot consolid respons consolidatedannot attribut null human annot true idea bug mistak thank chri",
        "Question_preprocessed_content":"ground truth ground truth imag mechan turk job fail output manifest idea bug mistak thank chri",
        "Question_gpt_summary_original":"The user encountered an error while using AWS SageMaker Ground Truth to annotate an image using Mechanical Turk. The error message in the output manifest stated that the \"consolidatedAnnotation\" attribute was null, causing the labeling job to fail. The user is seeking help to determine if this is a bug or a mistake on their part.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"'Remote end closed connection without response' in log_batch()",
        "Question_body":"The following exception is raised through a call to log_batch(). Anyone experienced something similar?\n\n\n\n\nraise ConnectionError(err, request=request)\n\nrequests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1576600519000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":2.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/9R3dx94gWns",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"remot end close connect respons log batch follow except rais log batch experienc similar rais connectionerror err request request request except connectionerror connect abort remotedisconnect remot end close connect respons",
        "Question_preprocessed_content":"remot end close respons except rais experienc similar rais",
        "Question_gpt_summary_original":"The user encountered a 'Remote end closed connection without response' error while using log_batch() function, resulting in a ConnectionError exception. They are seeking advice from others who may have experienced a similar issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Python support for Azure ML -- speed issue",
        "Question_body":"<p>We are trying to create an Azure ML web-service that will receive a (.csv) data file, do some processing, and return two similar files. The Python support recently added to the azure ML platform was very helpful and we were able to successfully port our code, run it in experiment mode and publish the web-service.<\/p>\n\n<p>Using the \"batch processing\" API, we are now able to direct a file from blob-storage to the service and get the desired output. However, run-time for small files (a few KB) is significantly slower than on a local machine, and more importantly, the process seems to never return for slightly larger input data files (40MB). Processing time on my local machine for the same file is under 1 minute. <\/p>\n\n<p>My question is if you can see anything we are doing wrong, or if there is a way to get this to speed up. Here is the DAG representation of the experiment:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/MalhQ.png\" alt=\"The DAG representation of the experiment\"><\/p>\n\n<p>Is this the way the experiment should be set up? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1425837068693,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1425890468080,
        "Question_score_count":0.0,
        "Question_view_count":491.0,
        "Poster_created_time":1419868247680,
        "Poster_location":null,
        "Poster_reputation_count":877.0,
        "Poster_view_count":55.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/28929813",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"python support speed issu try creat web servic receiv csv data file process return similar file python support recent ad platform help abl successfulli port code run experi mode publish web servic batch process api abl direct file blob storag servic desir output run time small file significantli slower local machin importantli process return slightli larger input data file process time local machin file minut question wrong wai speed dag represent experi wai experi set",
        "Question_preprocessed_content":"python try creat receiv data file return similar file python recent platform help abl port code run experi mode publish batch api abl direct file servic desir output file significantli slower local machin importantli return slightli larger input data file time local machin file minut question wrong wai dag represent experi wai experi set",
        "Question_gpt_summary_original":"The user is facing speed issues while using Python support for Azure ML to create a web-service that processes CSV files and returns two similar files. While the Python support was helpful in porting the code and running it in experiment mode, the run-time for small files is slower than on a local machine, and the process never returns for slightly larger input data files. The user is seeking advice on whether they are doing anything wrong or if there is a way to speed up the process. The user has also shared the DAG representation of the experiment and is asking if it is set up correctly.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Deploying ml model using azureml and mlflow",
        "Question_body":"<p>I'm new to databricks and deploying models using mlflow and azureml, I'm trying to deploy my model but haven't found a lot of documentation or examples.<\/p>\n\n<p>I have my model which I save using:<\/p>\n\n<pre><code>mlflow.sklearn.save_model(model, model_path, \n                          conda_env=conda_env_file_name)\n<\/code><\/pre>\n\n<p>I created the workspace and the aci webservice, the next step is to create the image and the webservice:<\/p>\n\n<pre><code># image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n                                                    runtime = \"python\", \n                                                    conda_file = conda_env_file_name)\n\n# Webservice creation\nmyservice = AciWebservice.deploy_from_model(\n  workspace=ws, \n  name=\"service\",\n  deployment_config = aciconfig,\n  models = [model_path],\n  image_config = myimage_config)\n\nmyservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n\n<p>However when I try to create the webservice I receive an error and looking at the log:<\/p>\n\n<pre><code>mlflow.exceptions.MlflowException: Could not find an \"MLmodel\" configuration file at \"mode_path\"\n<\/code><\/pre>\n\n<p>My score file init function is like this:<\/p>\n\n<pre><code>def init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('model_path')\n    model = joblib.load(model_path)\n<\/code><\/pre>\n\n<p>It seems like it cannot find the path to the model. I'm not sure in the moment the image is saved, the model is not saved in it and thus it cannot be found by sklearn.load_model. I'm quite confused cause I've seen that a model can be deployed using mlflow or azureml. I think the problems is that mlflow.save_model does not register the model and then there's no path. Have someone been able to solve this? What is the best way to deploy a model?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1559175361693,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1559831718176,
        "Question_score_count":3.0,
        "Question_view_count":933.0,
        "Poster_created_time":1461539594160,
        "Poster_location":null,
        "Poster_reputation_count":737.0,
        "Poster_view_count":116.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56370096",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi model new databrick deploi model try deploi model haven lot document exampl model save sklearn save model model model path conda env conda env file creat workspac aci webservic step creat imag webservic imag creation core imag import containerimag myimag config containerimag imag configur execut script driver file runtim python conda file conda env file webservic creation myservic aciwebservic deploi model workspac servic deploy config aciconfig model model path imag config myimag config myservic wait deploy output true try creat webservic receiv error look log except except mlmodel configur file mode path score file init function like def init global model retreiv path model file model model path model model path model path model joblib load model path like path model sure moment imag save model save sklearn load model confus caus seen model deploi think problem save model regist model path abl solv best wai deploi model",
        "Question_preprocessed_content":"deploi model new databrick deploi model try deploi model haven lot document exampl model save creat workspac aci webservic step creat imag webservic try creat webservic receiv log score file init function like like path model sure moment imag save model save confus caus model deploi think problem regist model path abl solv best wai deploi model",
        "Question_gpt_summary_original":"The user is new to deploying models using mlflow and azureml and is encountering an error while creating a webservice. The error message suggests that the \"MLmodel\" configuration file cannot be found at the specified model path. The user suspects that the model is not saved in the image and thus cannot be found by sklearn.load_model. The user is seeking advice on the best way to deploy a model and if anyone has been able to solve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Endpoint \"predict-auto-price\" deployment failed",
        "Question_body":"<p>I'm following the &quot;Exercise - Explore regression with Azure Machine Learning designer&quot;    <\/p>\n<p>I've redone this exercise twice following all the instructions perfectly!    <\/p>\n<p>On the &quot;Deploy a service&quot; section in the exercise, I've tried it over 7 times:    <\/p>\n<p><em>4. In the configuration screen, select Deploy a new real-time endpoint, using the following settings:<\/em>    <\/p>\n<p><em>Name: predict-auto-price    <br \/>\nDescription: Auto price regression    <br \/>\nCompute type: Azure Container Instance<\/em>    <\/p>\n<p><strong>It always fails with &quot;Endpoint &quot;predict-auto-price&quot; deployment failed&quot;<\/strong>    <\/p>\n<p>And nothing comes up in the Deployment Logs.    <br \/>\n<strong>Please help! I'm out of idea's<\/strong>    <\/p>\n<p>&quot;<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234916-untitled1.png?platform=QnA\" alt=\"234916-untitled1.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/234799-untitled2.png?platform=QnA\" alt=\"234799-untitled2.png\" \/>&quot;    <\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1661430065143,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=7d0191ce-e12e-41a0-9e2c-30b454b8736b\">@Mervyn King  <\/a> Do you see any new jobs added on the jobs tab when your deployment fails? Usually, there is a drop down that loads on the Deployment logs tab to select the Deployment. But, I dont see that on your page. It looks like the page might not have loaded completely. You can also report the issue using the smiley icon on the top right corner with a screen shot of this page.    <\/p>\n<p>If an answer is helpful, please click on <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130616-image.png?platform=QnA\" alt=\"130616-image.png\" \/> or upvote <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/130671-image.png?platform=QnA\" alt=\"130671-image.png\" \/> which might help other community members reading this thread.    <\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1661512226996,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/981735\/endpoint-predict-auto-price-deployment-failed",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"endpoint predict auto price deploy fail follow exercis explor regress design redon exercis twice follow instruct perfectli deploi servic section exercis tri time configur screen select deploi new real time endpoint follow set predict auto price descript auto price regress comput type azur contain instanc fail endpoint predict auto price deploy fail come deploy log help idea",
        "Question_preprocessed_content":"endpoint deploy fail exercis explor design redon exercis twice instruct perfectli deploi servic section exercis tri time configur select deploi new endpoint descript auto price comput type azur contain instanc fail endpoint deploy fail come deploy log help idea",
        "Question_gpt_summary_original":"The user is encountering an issue with the deployment of the \"predict-auto-price\" endpoint in the Azure Machine Learning designer exercise. Despite following the instructions perfectly and attempting to deploy the endpoint over 7 times, it always fails with no information provided in the Deployment Logs. The user is seeking help to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Switching from Keras to tf.keras spams my screen with #010",
        "Question_body":"<p>I've built a simple Keras model for experimentation within Amazon SageMaker. I'm using Python 3.5 TensorFlow 1.12.0. Recently I switched my model to use TensorFlow.keras, but doing so has resulted in the printing of <code>#010<\/code> repeatedly followed by <code>#015<\/code>,  while downloading image net weights and displaying batch accuracy during the fit call.<\/p>\n\n<p>For example, with verbose=1 in <code>model.fit<\/code>:<\/p>\n\n<blockquote>\n  <p>Epoch 1\/1<\/p>\n  \n  <h1>015   1\/1563 [..............................] - ETA: 5:50:36 - loss: 2.2798 - acc: 0.1875#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015<\/h1>\n  \n  <p>3\/1563 [..............................] - ETA: 1:57:18 - loss: 2.3002\n  - acc: 0.1146#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015\n  5\/1563 [..............................] - ETA: 1:10:36 - loss: 2.3088\n  - acc: 0.1062#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010<\/p>\n<\/blockquote>\n\n<p>Does anyone know why this might be happening or how I can prevent this? Reproducing with a minimal example may require running through SageMaker, but the code I switched from Keras to tf.keras is from <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/tree\/master\/hyperparameter_tuning\/keras_bring_your_own\" rel=\"nofollow noreferrer\">this example<\/a>, and specifically the <code>trainer\/start.py<\/code> file:<\/p>\n\n<pre><code># Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http:\/\/aws.amazon.com\/apache2.0\/\n#\n# or in the \"license\" file accompanying this file. This file is\n# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nimport os\nimport numpy as np\n\nfrom trainer.environment import create_trainer_environment\n\nNUM_CLASSES = 10\nEPOCHS = 10\nNUM_PREDICTIONS = 20\nMODEL_NAME = 'keras_cifar10_trained_model.h5'\n\n# the trainer environment contains useful information about\nenv = create_trainer_environment()\nprint('creating SageMaker trainer environment:\\n%s' % str(env))\n\n# getting the hyperparameters\nbatch_size = env.hyperparameters.get('batch_size', object_type=int)\ndata_augmentation = env.hyperparameters.get('data_augmentation', default=True, object_type=bool)\nlearning_rate = env.hyperparameters.get('learning_rate', default=.0001, object_type=float)\nwidth_shift_range = env.hyperparameters.get('width_shift_range', object_type=float)\nheight_shift_range = env.hyperparameters.get('height_shift_range', object_type=float)\nEPOCHS = env.hyperparameters.get('epochs', default=10, object_type=int)\n\n# reading data from train and test channels\ntrain_data = np.load(os.path.join(env.channel_dirs['train'], 'cifar-10-npz-compressed.npz'))\n(x_train, y_train) = train_data['x'], train_data['y']\n\ntest_data = np.load(os.path.join(env.channel_dirs['test'], 'cifar-10-npz-compressed.npz'))\n(x_test, y_test) = test_data['x'], test_data['y']\n\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(NUM_CLASSES))\nmodel.add(Activation('softmax'))\n\n# initiate RMSprop optimizer\nopt = keras.optimizers.rmsprop(lr=learning_rate, decay=1e-6)\n\n# Let's train the model using RMSprop\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255\nx_test \/= 255\n\nif not data_augmentation:\n    print('Not using data augmentation.')\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=EPOCHS, validation_data=(x_test, y_test), shuffle=True)\nelse:\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and real time data augmentation:\n    data_generator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=width_shift_range,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=height_shift_range,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    data_generator.fit(x_train)\n\n    # Fit the model on the batches generated by data_generator.flow().\n    data_generator_flow = data_generator.flow(x_train, y_train, batch_size=batch_size)\n    model.fit_generator(data_generator_flow, epochs=EPOCHS, validation_data=(x_test, y_test), workers=4)\n\n# Save model and weights\nmodel_path = os.path.join(env.model_dir, MODEL_NAME)\nmodel.save(model_path)\nprint('Saved trained model at %s ' % model_path)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1544642065947,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":305.0,
        "Poster_created_time":1361339272692,
        "Poster_location":"NYC",
        "Poster_reputation_count":6281.0,
        "Poster_view_count":958.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53749877",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"switch kera kera spam screen built simpl kera model experiment python tensorflow recent switch model us tensorflow kera result print repeatedli follow download imag net weight displai batch accuraci fit exampl verbos model fit epoch eta loss acc eta loss acc eta loss acc know happen prevent reproduc minim exampl requir run code switch kera kera exampl specif trainer start file copyright amazon com affili right reserv licens apach licens version licens us file complianc licens copi licens locat http aw amazon com apach licens file accompani file file distribut basi warranti condit kind express impli licens specif languag govern permiss limit licens futur import absolut import futur import print function import kera kera preprocess imag import imagedatagener kera model import sequenti kera layer import dens dropout activ flatten kera layer import convd maxpoolingd import import numpi trainer environ import creat trainer environ num class epoch num predict model kera cifar train model trainer environ contain us inform env creat trainer environ print creat trainer environ str env get hyperparamet batch size env hyperparamet batch size object type int data augment env hyperparamet data augment default true object type bool learn rate env hyperparamet learn rate default object type float width shift rang env hyperparamet width shift rang object type float height shift rang env hyperparamet height shift rang object type float epoch env hyperparamet epoch default object type int read data train test channel train data load path join env channel dir train cifar npz compress npz train train train data train data test data load path join env channel dir test cifar npz compress npz test test test data test data model sequenti model add convd pad input shape train shape model add activ relu model add convd model add activ relu model add maxpoolingd pool size model add dropout model add convd pad model add activ relu model add convd model add activ relu model add maxpoolingd pool size model add dropout model add flatten model add dens model add activ relu model add dropout model add dens num class model add activ softmax initi rmsprop optim opt kera optim rmsprop learn rate decai let train model rmsprop model compil loss categor crossentropi optim opt metric accuraci train train astyp float test test astyp float train test data augment print data augment model fit train train batch size batch size epoch epoch valid data test test shuffl true print real time data augment preprocess real time data augment data gener imagedatagener featurewis center fals set input mean dataset samplewis center fals set sampl mean featurewis std normal fals divid input std dataset samplewis std normal fals divid input std zca whiten fals appli zca whiten rotat rang randomli rotat imag rang degre width shift rang width shift rang randomli shift imag horizont fraction total width height shift rang height shift rang randomli shift imag vertic fraction total height horizont flip true randomli flip imag vertic flip fals randomli flip imag comput quantiti requir featur wise normal std mean princip compon zca whiten appli data gener fit train fit model batch gener data gener flow data gener flow data gener flow train train batch size batch size model fit gener data gener flow epoch epoch valid data test test worker save model weight model path path join env model dir model model save model path print save train model model path score train model score model evalu test test verbos print test loss score print test accuraci score",
        "Question_preprocessed_content":"switch kera spam built simpl kera model experiment python tensorflow recent switch model us result print repeatedli download imag net weight displai batch fit exampl verbos epoch eta eta eta know prevent reproduc minim exampl requir code switch kera exampl file",
        "Question_gpt_summary_original":"The user has switched from Keras to TensorFlow.keras and is encountering an issue where the screen is being spammed with #010 and #015 while downloading image net weights and displaying batch accuracy during the fit call. The user is seeking help to understand why this is happening and how to prevent it.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Properly return a label in post-annotation lambda for AWS SageMaker Ground Truth custom labeling job",
        "Question_body":"<p>I'm working on a SageMaker labeling job with custom datatypes. For some reason though, I'm not getting the correct label in the AWS web console. It should have the selected label which is &quot;Native&quot;, but instead, I'm getting the <a href=\"https:\/\/github.com\/aws-samples\/aws-sagemaker-ground-truth-recipe\/blob\/master\/aws_sagemaker_ground_truth_sample_lambda\/annotation_consolidation_lambda.py#L65\" rel=\"nofollow noreferrer\"><code>&lt;labelattributename&gt;<\/code><\/a> which is &quot;new-test-14&quot;.<\/p>\n<p>After Ground Truth runs the post-annotation lambda, it seems to modify the metadata before returning a data object. The data object it returns doesn't contain a class-name key inside the metadata attribute, even when I hard-code the lambda to return an object that contains it.<\/p>\n<p>My manifest file looks like this:<\/p>\n<pre><code>{&quot;source-ref&quot; : &quot;s3:\/\/&lt;file-name&gt;&quot;, &quot;text&quot; : &quot;Hello world&quot;}\n{&quot;source-ref&quot; : &quot;s3:\/\/&quot;&lt;file-name&gt;&quot;, &quot;text&quot; : &quot;Hello world&quot;}\n<\/code><\/pre>\n<p>And the worker response looks like this:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{&quot;answers&quot;:[{&quot;acceptanceTime&quot;:&quot;2021-05-18T16:08:29.473Z&quot;,&quot;answerContent&quot;:{&quot;new-test-14&quot;:{&quot;label&quot;:&quot;Native&quot;}},&quot;submissionTime&quot;:&quot;2021-05-18T16:09:15.960Z&quot;,&quot;timeSpentInSeconds&quot;:46.487,&quot;workerId&quot;:&quot;private.us-east-1.ea05a03fcd679cbb&quot;,&quot;workerMetadata&quot;:{&quot;identityData&quot;:{&quot;identityProviderType&quot;:&quot;Cognito&quot;,&quot;issuer&quot;:&quot;https:\/\/cognito-idp.us-east-1.amazonaws.com\/us-east-1_XPxQ9txEq&quot;,&quot;sub&quot;:&quot;edc59ce1-e09d-4551-9e0d-a240465ea14a&quot;}}}]}\n<\/code><\/pre>\n<p>That worker response gets processed by my post-annotation lambda which is modeled after <a href=\"https:\/\/github.com\/aws-samples\/aws-sagemaker-ground-truth-recipe\/blob\/master\/aws_sagemaker_ground_truth_sample_lambda\/annotation_consolidation_lambda.py\" rel=\"nofollow noreferrer\">this aws sample ground truth recipe<\/a>. Here's my code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import json\nimport sys\nimport boto3\nfrom datetime import datetime\n\n\n\ndef lambda_handler(event, context):\n\n\n    # Event received\n    print(&quot;Received event: &quot; + json.dumps(event, indent=2))\n\n    labeling_job_arn = event[&quot;labelingJobArn&quot;]\n    label_attribute_name = event[&quot;labelAttributeName&quot;]\n\n    label_categories = None\n    if &quot;label_categories&quot; in event:\n        label_categories = event[&quot;labelCategories&quot;]\n        print(&quot; Label Categories are : &quot; + label_categories)\n\n    payload = event[&quot;payload&quot;]\n    role_arn = event[&quot;roleArn&quot;]\n\n    output_config = None # Output s3 location. You can choose to write your annotation to this location\n    if &quot;outputConfig&quot; in event:\n        output_config = event[&quot;outputConfig&quot;]\n\n    # If you specified a KMS key in your labeling job, you can use the key to write\n    # consolidated_output to s3 location specified in outputConfig.\n    # kms_key_id = None\n    # if &quot;kmsKeyId&quot; in event:\n    #     kms_key_id = event[&quot;kmsKeyId&quot;]\n\n    # # Create s3 client object\n    # s3_client = S3Client(role_arn, kms_key_id)\n    s3_client = boto3.client('s3')\n\n    # Perform consolidation\n    return do_consolidation(labeling_job_arn, payload, label_attribute_name, s3_client)\n\n\ndef do_consolidation(labeling_job_arn, payload, label_attribute_name, s3_client):\n    &quot;&quot;&quot;\n        Core Logic for consolidation\n\n    :param labeling_job_arn: labeling job ARN\n    :param payload:  payload data for consolidation\n    :param label_attribute_name: identifier for labels in output JSON\n    :param s3_client: S3 helper class\n    :return: output JSON string\n    &quot;&quot;&quot;\n\n    # Extract payload data\n    if &quot;s3Uri&quot; in payload:\n        s3_ref = payload[&quot;s3Uri&quot;]\n        payload_bucket, payload_key = s3_ref.split('\/',2)[-1].split('\/',1)\n        payload = json.loads(s3_client.get_object(Bucket=payload_bucket, Key=payload_key)['Body'].read())\n#         print(payload)\n\n    # Payload data contains a list of data objects.\n    # Iterate over it to consolidate annotations for individual data object.\n    consolidated_output = []\n    success_count = 0  # Number of data objects that were successfully consolidated\n    failure_count = 0  # Number of data objects that failed in consolidation\n\n    for p in range(len(payload)):\n        response = None\n\n        dataset_object_id = payload[p]['datasetObjectId']\n        log_prefix = &quot;[{}] data object id [{}] :&quot;.format(labeling_job_arn, dataset_object_id)\n        print(&quot;{} Consolidating annotations BEGIN &quot;.format(log_prefix))\n\n        annotations = payload[p]['annotations']\n#             print(&quot;{} Received Annotations from all workers {}&quot;.format(log_prefix, annotations))\n\n        # Iterate over annotations. Log all annotation to your CloudWatch logs\n        annotationsFromAllWorkers = []\n        for i in range(len(annotations)):\n            worker_id = annotations[i][&quot;workerId&quot;]\n            anotation_data = annotations[i][&quot;annotationData&quot;]\n            annotation_content = anotation_data[&quot;content&quot;]\n            annotation_content_json = json.loads(annotation_content)\n            annotation_job = annotation_content_json[&quot;new_test&quot;]\n            annotation_label = annotation_job[&quot;label&quot;]\n            consolidated_annotation= {\n                &quot;workerId&quot;: worker_id,\n                &quot;annotationData&quot;: {\n                    &quot;content&quot;: {\n                        &quot;annotatedResult&quot;: {\n                            &quot;instances&quot;: [{&quot;label&quot;:annotation_label }]    \n                        }\n                    }\n                }\n            }\n            annotationsFromAllWorkers.append(consolidated_annotation)\n\n        consolidated_annotation = {&quot;annotationsFromAllWorkers&quot;: annotationsFromAllWorkers} # TODO : Add your consolidation logic\n\n        # Build consolidation response object for an individual data object\n        response = {\n            &quot;datasetObjectId&quot;: dataset_object_id,\n            &quot;consolidatedAnnotation&quot;: {\n                &quot;content&quot;: {\n                    label_attribute_name: consolidated_annotation,\n                    label_attribute_name+ &quot;-metadata&quot;: {\n                        &quot;class-name&quot;: &quot;Native&quot;,\n                        &quot;confidence&quot;: 0.00,\n                        &quot;human-annotated&quot;: &quot;yes&quot;,\n                        &quot;creation-date&quot;: datetime.strftime(datetime.now(), &quot;%Y-%m-%dT%H:%M:%S&quot;),\n                        &quot;type&quot;: &quot;groundtruth\/custom&quot;\n                    }\n \n                }\n            }\n        }\n\n        success_count += 1\n#             print(&quot;{} Consolidating annotations END &quot;.format(log_prefix))\n\n        # Append individual data object response to the list of responses.\n        if response is not None:\n            consolidated_output.append(response)\n\n\n        failure_count += 1\n        print(&quot; Consolidation failed for dataobject {}&quot;.format(p))\n        print(&quot; Unexpected error: Consolidation failed.&quot; + str(sys.exc_info()[0]))\n\n    print(&quot;Consolidation Complete. Success Count {}  Failure Count {}&quot;.format(success_count, failure_count))\n\n    print(&quot; -- Consolidated Output -- &quot;)\n    print(consolidated_output)\n    print(&quot; ------------------------- &quot;)\n    return consolidated_output\n<\/code><\/pre>\n<p>As you can see above, the <code>do_consolidation<\/code> method returns an object hard-coded to include a class-name of &quot;Native&quot;, and the <code>lambda_handler<\/code> method returns that same object. Here's the post-annotation function response:<\/p>\n<pre><code>[{\n    &quot;datasetObjectId&quot;: &quot;4&quot;,\n    &quot;consolidatedAnnotation&quot;: {\n        &quot;content&quot;: {\n            &quot;new-test-14&quot;: {\n                &quot;annotationsFromAllWorkers&quot;: [{\n                    &quot;workerId&quot;: &quot;private.us-east-1.ea05a03fcd679cbb&quot;,\n                    &quot;annotationData&quot;: {\n                        &quot;content&quot;: {\n                            &quot;annotatedResult&quot;: {\n                                &quot;instances&quot;: [{\n                                    &quot;label&quot;: &quot;Native&quot;\n                                }]\n                            }\n                        }\n                    }\n                }]\n            },\n            &quot;new-test-14-metadata&quot;: {\n                &quot;class-name&quot;: &quot;Native&quot;,\n                &quot;confidence&quot;: 0,\n                &quot;human-annotated&quot;: &quot;yes&quot;,\n                &quot;creation-date&quot;: &quot;2021-05-19T07:06:06&quot;,\n                &quot;type&quot;: &quot;groundtruth\/custom&quot;\n            }\n        }\n    }\n}]\n<\/code><\/pre>\n<p>As you can see, the post-annotation function return value has the class-name of &quot;Native&quot; in the metadata so I would expect the class-name to be present in the data object metadata, but it's not. And here's a screenshot of the data object summary:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wHpEl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wHpEl.png\" alt=\"Labeled object summary\" \/><\/a><\/p>\n<p>It seems like Ground Truth overwrote the metadata, and now the object doesn't contain the correct label. I think perhaps that's why my label is coming through as the label attribute name &quot;new-test-14&quot; instead of as the correct label &quot;Native&quot;. Here's a screenshot of the labeling job in the AWS web console:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/yOdfP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yOdfP.png\" alt=\"labeling job\" \/><\/a><\/p>\n<p>The web console is supposed to show the label <strong>&quot;Native&quot;<\/strong> inside the &quot;Label&quot; column but instead I'm getting the <a href=\"https:\/\/github.com\/aws-samples\/aws-sagemaker-ground-truth-recipe\/blob\/master\/aws_sagemaker_ground_truth_sample_lambda\/annotation_consolidation_lambda.py#L65\" rel=\"nofollow noreferrer\"><code>&lt;labelattributename&gt;<\/code><\/a> <strong>&quot;new-test-14&quot;<\/strong> in the label column.<\/p>\n<p>Here is the output.manifest file generated by Ground Truth at the end:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n    &quot;source-ref&quot;: &quot;s3:\/\/&lt;file-name&gt;&quot;,\n    &quot;text&quot;: &quot;Hello world&quot;,\n    &quot;new-test-14&quot;: {\n        &quot;annotationsFromAllWorkers&quot;: [{\n            &quot;workerId&quot;: &quot;private.us-east-1.ea05a03fcd679ert&quot;,\n            &quot;annotationData&quot;: {\n                &quot;content&quot;: {\n                    &quot;annotatedResult&quot;: {\n                        &quot;label&quot;: &quot;Native&quot;\n                    }\n                }\n            }\n        }]\n    },\n    &quot;new-test-14-metadata&quot;: {\n        &quot;type&quot;: &quot;groundtruth\/custom&quot;,\n        &quot;job-name&quot;: &quot;new-test-14&quot;,\n        &quot;human-annotated&quot;: &quot;yes&quot;,\n        &quot;creation-date&quot;: &quot;2021-05-18T12:34:17.400000&quot;\n    }\n}\n<\/code><\/pre>\n<p>What should I return from the Post-Annotation function? Am I missing something in my response? How do I get the proper label to appear in the AWS web console?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1621410650207,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1622189648607,
        "Question_score_count":3.0,
        "Question_view_count":430.0,
        "Poster_created_time":1621405531012,
        "Poster_location":null,
        "Poster_reputation_count":31.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67599026",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"properli return label post annot lambda ground truth custom label job work label job custom datatyp reason get correct label aw web consol select label nativ instead get new test ground truth run post annot lambda modifi metadata return data object data object return contain class kei insid metadata attribut hard code lambda return object contain manifest file look like sourc ref text hello world sourc ref text hello world worker respons look like answer acceptancetim answercont new test label nativ submissiontim timespentinsecond workerid privat east eaafcdcbb workermetadata identitydata identityprovidertyp cognito issuer http cognito idp east amazonaw com east xpxqtxeq sub edcc aeaa worker respons get process post annot lambda model aw sampl ground truth recip code import json import sy import boto datetim import datetim def lambda handler event context event receiv print receiv event json dump event indent label job arn event labelingjobarn label attribut event labelattributenam label categori label categori event label categori event labelcategori print label categori label categori payload event payload role arn event rolearn output config output locat choos write annot locat outputconfig event output config event outputconfig specifi km kei label job us kei write consolid output locat specifi outputconfig km kei kmskeyid event km kei event kmskeyid creat client object client sclient role arn km kei client boto client perform consolid return consolid label job arn payload label attribut client def consolid label job arn payload label attribut client core logic consolid param label job arn label job arn param payload payload data consolid param label attribut identifi label output json param client helper class return output json string extract payload data suri payload ref payload suri payload bucket payload kei ref split split payload json load client object bucket payload bucket kei payload kei bodi read print payload payload data contain list data object iter consolid annot individu data object consolid output success count number data object successfulli consolid failur count number data object fail consolid rang len payload respons dataset object payload datasetobjectid log prefix data object format label job arn dataset object print consolid annot begin format log prefix annot payload annot print receiv annot worker format log prefix annot iter annot log annot cloudwatch log annotationsfromallwork rang len annot worker annot workerid anot data annot annotationdata annot content anot data content annot content json json load annot content annot job annot content json new test annot label annot job label consolid annot workerid worker annotationdata content annotatedresult instanc label annot label annotationsfromallwork append consolid annot consolid annot annotationsfromallwork annotationsfromallwork todo add consolid logic build consolid respons object individu data object respons datasetobjectid dataset object consolidatedannot content label attribut consolid annot label attribut metadata class nativ confid human annot ye creation date datetim strftime datetim type groundtruth custom success count print consolid annot end format log prefix append individu data object respons list respons respons consolid output append respons failur count print consolid fail dataobject format print unexpect error consolid fail str sy exc info print consolid complet success count failur count format success count failur count print consolid output print consolid output print return consolid output consolid method return object hard code includ class nativ lambda handler method return object post annot function respons datasetobjectid consolidatedannot content new test annotationsfromallwork workerid privat east eaafcdcbb annotationdata content annotatedresult instanc label nativ new test metadata class nativ confid human annot ye creation date type groundtruth custom post annot function return valu class nativ metadata expect class present data object metadata screenshot data object summari like ground truth overwrot metadata object contain correct label think label come label attribut new test instead correct label nativ screenshot label job aw web consol web consol suppos label nativ insid label column instead get new test label column output manifest file gener ground truth end sourc ref text hello world new test annotationsfromallwork workerid privat east eaafcdert annotationdata content annotatedresult label nativ new test metadata type groundtruth custom job new test human annot ye creation date return post annot function miss respons proper label appear aw web consol",
        "Question_preprocessed_content":"properli return label lambda ground truth custom label job work label job custom datatyp reason label aw web consol select label nativ instead ground truth run lambda modifi metadata return data object data object return contain kei insid metadata lambda return object contain manifest file like worker respons like worker respons get lambda model aw sampl ground truth recip code method return object includ nativ method return object function respons function return valu nativ metadata expect present data object metadata data object like ground truth overwrot metadata object contain label think label come label instead label nativ label job aw web consol web consol label nativ insid label column instead label column file gener ground truth end return function respons proper label aw web consol",
        "Question_gpt_summary_original":"The user is encountering an issue with a SageMaker labeling job with custom datatypes. The post-annotation lambda is not returning the correct label in the AWS web console, instead returning the label attribute name. The metadata is being modified by Ground Truth, and the data object does not contain the correct label. The user is unsure of what to return from the Post-Annotation function and how to get the proper label to appear in the AWS web console.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML Dataset Versioning: What is Different if it Points to the Same Data?",
        "Question_body":"<p><strong>Context<\/strong><\/p>\n<p>In AzureML, we are facing an error when running a pipeline. It fails on <code>to_pandas_dataframe<\/code> because a particular dataset &quot;could not be read beyond end of stream&quot;. On its own, this seems to be an issue with the parquet file that is being registered, maybe special characters being misinterpreted.<\/p>\n<p>However, when we explicitly load a previous &quot;version&quot; of this Dataset--which points to the exact same location of data--it works as expected. In the documentation (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-version-track-datasets#versioning-best-practice\" rel=\"nofollow noreferrer\">here<\/a>), Azure says that &quot;when you load data from a dataset, the current data content referenced by the dataset is always loaded.&quot; This makes me think that a new version of the dataset with the same schema will be, well, the same.<\/p>\n<p><strong>Questions<\/strong><\/p>\n<ol>\n<li><p>What makes a Dataset version <em>different<\/em> from another version when both point to the same location? Is it only the schema definition?<\/p>\n<\/li>\n<li><p>Based on these differences, is there a way to figure out why one version would be succeeding and another failing?<\/p>\n<\/li>\n<\/ol>\n<p><strong>Attempts<\/strong><\/p>\n<ul>\n<li>The schemas of the two versions are identical. We can profile both in AzureML, and all the fields have the same profile information.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1639665519797,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":245.0,
        "Poster_created_time":1591385782727,
        "Poster_location":"Chicago, IL, USA",
        "Poster_reputation_count":594.0,
        "Poster_view_count":53.0,
        "Answer_body":"<p>As rightly suggested by @Anand Sowmithiran in comment section, This looks more like a bug with the SDK.<\/p>\n<p>You can raise <a href=\"https:\/\/azure.microsoft.com\/en-us\/support\/create-ticket\/\" rel=\"nofollow noreferrer\">Azure support ticket<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1641212437096,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1550902509267,
        "Answerer_location":null,
        "Answerer_reputation_count":2669.0,
        "Answerer_view_count":3292.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70380861",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"dataset version differ point data context face error run pipelin fail panda datafram particular dataset read end stream issu parquet file regist mayb special charact misinterpret explicitli load previou version dataset point exact locat data work expect document azur sai load data dataset current data content referenc dataset load make think new version dataset schema question make dataset version differ version point locat schema definit base differ wai figur version succeed fail attempt schema version ident profil field profil inform",
        "Question_preprocessed_content":"dataset version point data context face pipelin fail particular dataset read end stream parquet file regist mayb special charact misinterpret explicitli load previou version point exact locat work expect document azur sai load data dataset data content referenc dataset make think new version dataset schema question make dataset version version point locat schema definit base wai figur version fail schema version ident profil field profil inform",
        "Question_gpt_summary_original":"The user is facing an error in AzureML while running a pipeline, which fails on to_pandas_dataframe. However, when they load a previous version of the dataset that points to the same location of data, it works as expected. The user is questioning what makes a dataset version different from another version when both point to the same location and if there is a way to figure out why one version would be succeeding and another failing. The user has attempted to compare the schemas of the two versions, and they are identical.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Deployment timeout while deploying the ML model in the Azure Container Instance with the azure pipeline",
        "Question_body":"<p>Our code was working fine till yesterday while deploying the ML model on Azure ACI, but facing the deployment timeout or sometimes 400 (Bad response) today.<\/p>\n<p>Is there any issue with microsoft datcenters or there is something else ?<\/p>\n<p>The errors are given below<\/p>\n<blockquote>\n<p>&quot;message&quot;: &quot;Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Thu, 06 Aug 2020 21:05:31 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '8aa4dcafb0ec40ef822b55fc4c7a196f', 'x-ms-client-session-id': 'bf2decff-8879-4a9c-bb5f-2fae7034946c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-request-time': '0.044', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{&quot;code&quot;:&quot;BadRequest&quot;,&quot;statusCode&quot;:400,&quot;message&quot;:&quot;The request is invalid.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;InvalidOverwriteRequest&quot;,&quot;message&quot;:&quot;Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;8aa4dcafb0ec40ef822b55fc4c7a196f&quot;}}'&quot;<\/p>\n<\/blockquote>\n<blockquote>\n<p>&quot;message&quot;: &quot;Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nOperation ID: 1b6746b3-cdb6-4e0c-a43d-b31b34ac99b2\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n &quot;code&quot;: &quot;DeploymentTimedOut&quot;,\\n &quot;statusCode&quot;: 504,\\n &quot;message&quot;: &quot;The deployment operation polling has TimedOut. The service creation is taking longer than our normal time. We are still trying to achieve the desired state for the web service. Please check the webservice state for the current webservice health. You can run print(service.state) from the python SDK to retrieve the current state of the webservice.&quot;\\n}&quot;<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1596785856050,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1596790304580,
        "Question_score_count":0.0,
        "Question_view_count":606.0,
        "Poster_created_time":1593185044876,
        "Poster_location":"Lahore, Pakistan",
        "Poster_reputation_count":11.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63297308",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploy timeout deploi model azur contain instanc azur pipelin code work fine till yesterdai deploi model azur aci face deploy timeout bad respons todai issu microsoft datcent error given messag receiv bad respons model manag servic nrespons code nheader date thu aug gmt content type applic json transfer encod chunk connect aliv request context appid cid dee eea client request aadcafbecefbfccaf client session bfdecff bbf faec api support version preview request time strict transport secur max ag includesubdomain preload ncontent code badrequest statuscod messag request invalid detail code invalidoverwriterequest messag invalid overwrit request updat contain resourc requir dn label deploy type delet redeploi servic correl requestid aadcafbecefbfccaf messag servic deploy poll reach non success termin state current servic state unhealthi noper cdb bbacb nmore inform log nerror code deploymenttimedout statuscod messag deploy oper poll timedout servic creation take longer normal time try achiev desir state web servic check webservic state current webservic health run print servic state python sdk retriev current state webservic",
        "Question_preprocessed_content":"deploy timeout deploi model azur contain instanc azur pipelin code work fine yesterdai deploi model azur aci face deploy timeout todai microsoft datcent given receiv bad respons model manag code requestid dcafb servic deploy reach termin state servic state inform code statuscod deploy oper timedout servic creation take longer normal time try achiev desir state web servic check webservic state webservic health run python sdk retriev state",
        "Question_gpt_summary_original":"The user is facing deployment timeout or 400 (Bad response) errors while deploying an ML model on Azure ACI. The error messages indicate that the deployment operation polling has timed out and the service creation is taking longer than normal. The user is unsure if there is an issue with Microsoft data centers or if there is something else causing the problem.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure Machine Learning Endpoint attempting to cast string parameter as an int",
        "Question_body":"<p>Hi,     <\/p>\n<p>I have created a an ML model in Azure ML using auto ML. This has been deployed as an endpoint using the UI.     <br \/>\nThis is a sample of the original dataset:     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111244-image.png?platform=QnA\" alt=\"111244-image.png\" \/>    <\/p>\n<p>Its deployed as a container instance and the deployment state is healthy.     <\/p>\n<p>When I test the endpoint, it pre-populates the test form with some example values, for the various paratmeters which are strings and ints.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110980-image.png?platform=QnA\" alt=\"110980-image.png\" \/>    <\/p>\n<p>However, if I populate the blank fields with ints and leave the strings, .     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111051-image.png?platform=QnA\" alt=\"111051-image.png\" \/>    <\/p>\n<p>then test the service, I get an error that suggests it is trying to convert attribute13 to an int    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/110994-image.png?platform=QnA\" alt=\"110994-image.png\" \/>    <\/p>\n<p>as you can see, it is fine with the productName parameter being a string, but tries to convert Attribute13 to an int.     <br \/>\nThe same happens with the other attributesXX.     <br \/>\nIf I set all the attributes to numerical values, the test completes and the endpoint returns a value from the model as expected.     <\/p>\n<p>IF i check the swagger file, it shows that the api is expecting a string:     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111018-image.png?platform=QnA\" alt=\"111018-image.png\" \/>    <\/p>\n<p>So that all suggests the issue exists somewhere in the python code created automatically.     <br \/>\nThis is kinda where I get stuck - I see <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment-local\">resources on debugging<\/a> the python code, I can see in my score.py file the example sample passes specifies these as 'object' dtypes:     <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/111025-image.png?platform=QnA\" alt=\"111025-image.png\" \/>    <\/p>\n<p>And after that I dont know where to go from here - feels like it should just work 'out of the box' as I got to this point purely through the UI.     <\/p>\n<p>Any help greatly appreciated.     <\/p>\n<p>Steve    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1625151488777,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>TL;DR: Don't have column names that are numerical.     <\/p>\n<p>I have discovered that if I send the attributes in the order the appear in they dataset - ignoring the order that they are named on the api, then they are all parsed to the correct type. Effectively the 3 columns named 341, 513, 514 belong at the end, but for some reason have been lined up with the wrong parameter names.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/112439-image.png?platform=QnA\" alt=\"112439-image.png\" \/>    <br \/>\n(this returns expected values)    <\/p>\n<p>So i renamed the columns in my training data pandas dataframe so they are not numerical (e.g. System341, System513, System514) and re-ran the AutoML, and deployed the new model.     <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/112552-image.png?platform=QnA\" alt=\"112552-image.png\" \/>    <\/p>\n<p>now the order of columns matches that of the dataset- and IT WORKS!     <\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1625655157923,
        "Answer_last_edit_time":null,
        "Answer_score_count":3.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/459799\/azure-machine-learning-endpoint-attempting-to-cast",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"endpoint attempt cast string paramet int creat model auto deploi endpoint sampl origin dataset deploi contain instanc deploy state healthi test endpoint pre popul test form exampl valu paratmet string int popul blank field int leav string test servic error suggest try convert attribut int fine productnam paramet string tri convert attribut int happen attributesxx set attribut numer valu test complet endpoint return valu model expect check swagger file show api expect string suggest issu exist python code creat automat kinda stuck resourc debug python code score file exampl sampl pass specifi object dtype dont know feel like work box got point pure help greatli appreci steve",
        "Question_preprocessed_content":"endpoint cast string paramet int creat model auto deploi endpoint sampl origin dataset deploi contain instanc deploy state healthi test endpoint test form exampl valu paratmet string int popul blank field int leav string test servic try convert int fine productnam paramet string tri convert int set numer valu test complet endpoint return valu model expect check file show api expect string exist python code creat kinda stuck resourc python code file exampl sampl specifi object dtype dont know like work box got point pure help greatli steve",
        "Question_gpt_summary_original":"The user has created an ML model in Azure ML using auto ML and deployed it as an endpoint. The endpoint is pre-populated with example values for various parameters that are strings and ints. However, when the user populates the blank fields with ints and leaves the strings, an error occurs suggesting that it is trying to convert a string parameter to an int. The issue seems to exist in the python code created automatically, and the user is unsure how to proceed with debugging it.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is it possible to load a Scala\/Spark PipelineModel by mlflow?",
        "Question_body":"<p>I try to use <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/_modules\/mlflow\/spark.html#load_model\" rel=\"nofollow noreferrer\">mlflow<\/a> to load a serialized Scala\/Spark <a href=\"https:\/\/spark.apache.org\/docs\/latest\/api\/java\/org\/apache\/spark\/ml\/PipelineModel.html\" rel=\"nofollow noreferrer\">PipelineModel<\/a>.<\/p>\n<p>From <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.spark.html#mlflow.spark.load_model\" rel=\"nofollow noreferrer\">mlflow document<\/a> it seems it only supports <strong>Py<\/strong>Spark. Is this the case?<\/p>\n<p>Is it possible to load a serialized Scala\/Spark PipelineModel in mlflow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1600724655090,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1600988955576,
        "Question_score_count":0.0,
        "Question_view_count":175.0,
        "Poster_created_time":1510578501763,
        "Poster_location":null,
        "Poster_reputation_count":1529.0,
        "Poster_view_count":150.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64000348",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl load scala spark pipelinemodel try us load serial scala spark pipelinemodel document support pyspark case possibl load serial scala spark pipelinemodel",
        "Question_preprocessed_content":"load pipelinemodel try us load serial pipelinemodel document pyspark case load serial pipelinemodel",
        "Question_gpt_summary_original":"The user is trying to load a serialized Scala\/Spark PipelineModel using mlflow, but is unsure if mlflow only supports PySpark and is seeking clarification on whether it is possible to load a serialized Scala\/Spark PipelineModel in mlflow.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Where to find updated manifest file after labeling a dataset using a premade manifest for a Rekognition Custom Labels project without training a model?",
        "Question_body":"Hi!\n\nI have a training set of images for which I manually created a manifest file respecting the format required to train a Rekognition Custom Labels model for object detection. Both the images and that manifest are stored in an S3 bucket. When creating a project to train the model I noticed that the manifest contained some errors which I corrected manually (\"Start labeling\" then \"Draw bounding boxes\") but the updated manifest is nowhere to be found.\n\nI made sure to save the changes and when I browse through the dataset as it appears during the creation of a project I noticed that my changes were taken into account. I want the manifest so that I can store it locally on my computer but I can't seem to find it. Any help is very much appreciated.\n\nThank you!",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1682636174386,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1682983647104,
        "Question_score_count":0.0,
        "Question_view_count":61.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUGJnnynrdT3SdFt_XAnDwzw\/where-to-find-updated-manifest-file-after-labeling-a-dataset-using-a-premade-manifest-for-a-rekognition-custom-labels-project-without-training-a-model",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"updat manifest file label dataset premad manifest rekognit custom label project train model train set imag manual creat manifest file respect format requir train rekognit custom label model object detect imag manifest store bucket creat project train model notic manifest contain error correct manual start label draw bound box updat manifest sure save chang brows dataset appear creation project notic chang taken account want manifest store local help appreci thank",
        "Question_preprocessed_content":"updat manifest file label dataset premad manifest rekognit custom label project train model train set imag creat manifest file respect format requir train rekognit custom label model object detect imag manifest store bucket creat project train model notic manifest contain updat manifest sure save chang brows dataset creation project notic chang taken want manifest store help thank",
        "Question_gpt_summary_original":"The user manually corrected errors in a manifest file for a Rekognition Custom Labels project for object detection, but cannot find the updated manifest file after making changes through the \"Start labeling\" and \"Draw bounding boxes\" options. The user wants to store the updated manifest file locally on their computer.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Git bash command prompt hanging when running dvc push to DAGsHub",
        "Question_body":"<p>I'm having problems pushing files with DVC to DAGsHub.<\/p>\n<p>Workflow:<\/p>\n<ul>\n<li>I used my email to signup to DAGsHub.<\/li>\n<li>I created a repo and clone it to my computer.<\/li>\n<li>I added files to the repo and track them using DVC and Git to track the pointer files.<\/li>\n<li>Running DVC push -r origin, it asks me for my password. When I enter the password and hit enter - nothing happens.<\/li>\n<\/ul>\n<p>It sits and waits, barring me from even canceling the operation with Ctrl+C.\nI'm forced to manually close the terminal, open a new one, ending the &quot;Python&quot; process in task manager and delete the lock file in .dvc\/tmp\/lock.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1620537862843,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1620625906412,
        "Question_score_count":5.0,
        "Question_view_count":254.0,
        "Poster_created_time":1620537484800,
        "Poster_location":null,
        "Poster_reputation_count":53.0,
        "Poster_view_count":2.0,
        "Answer_body":"<p><strong>Short answer<\/strong><\/p>\n<p>Do not use <code>ask_password<\/code>.\nInstead, save your token in the local config by running once:<\/p>\n<pre><code>dvc remote modify origin --local --unset ask_password\ndvc remote modify origin --local password &lt;--access token--&gt;\n<\/code><\/pre>\n<p><code>dvc push -r origin<\/code> should work then.<\/p>\n<p><strong>Long answer<\/strong><\/p>\n<p><a href=\"https:\/\/www.atlassian.com\/git\/tutorials\/git-bash#:%7E:text=What%20is%20Git%20Bash%3F,operating%20system%20through%20written%20commands.\" rel=\"nofollow noreferrer\">Git Bash<\/a> is not running the regular Windows command prompt but an emulated Unix-style bash prompt. From the information in your question, I cannot know for sure, but this is probably causing the <code>msvcrt<\/code> package used by DVC to prompt the password on windows machines to fail\/hang.<\/p>\n<p>There are potentially 3 ways to deal with the issue:<\/p>\n<ol>\n<li>Run <code>dvc pull<\/code> from the regular Windows cmd prompt.<\/li>\n<li>Find a way to make Git Bash wrap Python calls with <code>winpty<\/code> - I am not 100% positive about how to do this, but not using <code>winpty<\/code> seems to be the reason <code>msvcrt<\/code> fails at prompting for your password.<\/li>\n<li>The simplest solution - Do not use <code>ask_password<\/code>.\nInstead, save your token in the local config by running once:\n<pre><code>dvc remote modify origin --local --unset ask_password\ndvc remote modify origin --local password &lt;--access token--&gt;\n<\/code><\/pre>\nYou can get your access token by clicking on the question mark beside the DVC\nremote of your DAGsHub repository, then click on &quot;Reveal my token&quot;.<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1620591578072,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1427953176670,
        "Answerer_location":null,
        "Answerer_reputation_count":145.0,
        "Answerer_view_count":13.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67454531",
        "Tool":"DVC",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"git bash command prompt hang run push dagshub have problem push file dagshub workflow email signup dagshub creat repo clone ad file repo track git track pointer file run push origin ask password enter password hit enter happen sit wait bar cancel oper ctrl forc manual close termin open new end python process task manag delet lock file tmp lock",
        "Question_preprocessed_content":"git bash prompt hang push dagshub have problem push file dagshub workflow email signup dagshub creat repo clone file repo track git track pointer file push origin ask enter hit enter sit wait cancel oper ctrl forc close termin open new end python task manag delet lock file",
        "Question_gpt_summary_original":"The user is facing issues while pushing files with DVC to DAGsHub. The Git bash command prompt hangs when the user runs DVC push -r origin, and it asks for a password. However, when the user enters the password and hits enter, nothing happens, and the operation cannot be canceled with Ctrl+C. The user is forced to manually close the terminal, end the \"Python\" process in task manager, and delete the lock file in .dvc\/tmp\/lock.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is there a way to list out my datastores if I've deployed to a VNET?",
        "Question_body":"<p>I followed the instructions in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-enable-virtual-network\" rel=\"nofollow noreferrer\">MSFT Docs<\/a>, but now I can't list our my Datastores either via the SDK nor the Azure Machine Learning studio. <\/p>\n\n<p>Instead, in the studio I see this:\n<a href=\"https:\/\/i.stack.imgur.com\/im2oe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/im2oe.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Is there a way to make this work? Did I miss a step?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1573145127473,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":164.0,
        "Poster_created_time":1529439461716,
        "Poster_location":null,
        "Poster_reputation_count":392.0,
        "Poster_view_count":39.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58753430",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wai list datastor deploi vnet follow instruct msft doc list datastor sdk studio instead studio wai work miss step",
        "Question_preprocessed_content":"wai list datastor deploi vnet instruct msft doc list datastor sdk studio instead studio wai work step",
        "Question_gpt_summary_original":"The user followed the instructions in the MSFT Docs to deploy to a VNET, but is now unable to list out their Datastores using the SDK or Azure Machine Learning studio. They are seeking assistance to make this work and wondering if they missed a step.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Convert `String Feature` DataFrame into Float in Azure ML Using Python Script",
        "Question_body":"<p>I am trying to understand how to convert azure ml <code>String Feature<\/code> data type into float using python script. my data set is contain \"HH:MM\" data time format. It recognized as <code>String Feature<\/code> like the following img:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/gy4A7.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gy4A7.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/aB4P6.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/aB4P6.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I want to convert it into float type which will divide the timestamp by  84600 ( 24 hour) so <code>17:30<\/code> will be converted into <code>0,729166666666667<\/code>, so I write python script to convert that. This is my script:<\/p>\n\n<pre><code>import pandas as pd\nimport numpy as np \n\ndef timeToFloat(x):\n    frt = [3600,60]\n    data = str(x)\n    result = float(sum([a*b for a,b in zip(frt, map(int,data.split(':')))]))\/86400\n    return result if isNotZero(x) else 0.0\n\ndef isNotZero(x):\n    return (x is \"0\")\n\ndef azureml_main(dataframe1 = None):\n\n    df = pd.DataFrame(dataframe1)\n    df[\"Departure Time\"] = pd.to_numeric(df[\"Departure Time\"]).apply(timeToFloat)\n\n    print(df[\"Departure Time\"])\n\n    return df,\n<\/code><\/pre>\n\n<p>When I run the script it was failed. Then I try to check whether it is <code>str<\/code> or not, but it returns <code>None<\/code>.<\/p>\n\n<p>can we treat <code>String Feature<\/code> as <code>String<\/code>? or how should I covert this data correctly?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1529548568263,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":299.0,
        "Poster_created_time":1446250907867,
        "Poster_location":"Depok, Depok City, West Java, Indonesia",
        "Poster_reputation_count":123.0,
        "Poster_view_count":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50959561",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"convert string featur datafram float python script try understand convert string featur data type float python script data set contain data time format recogn string featur like follow img want convert float type divid timestamp hour convert write python script convert script import panda import numpi def timetofloat frt data str result float sum zip frt map int data split return result isnotzero def isnotzero return def main datafram datafram datafram departur time numer departur time appli timetofloat print departur time return run script fail try check str return treat string featur string covert data correctli",
        "Question_preprocessed_content":"convert datafram float python script try understand convert data type float python script data set contain data time format recogn like img want convert float type divid timestamp convert write python script convert script run script fail try check return treat covert data",
        "Question_gpt_summary_original":"The user is trying to convert a `String Feature` data type into float using a Python script in Azure ML. The data set contains time data in \"HH:MM\" format, which is recognized as a `String Feature`. The user wants to convert it into a float type by dividing the timestamp by 84600 (24 hours). However, the Python script failed to run, and the user is unsure how to correctly convert the data.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How can I effectively use Google Cloud for machine learning and AI?",
        "Question_body":"Using Google Cloud's suite of tools and services for machine learning and artificial intelligence. The person asking the question is looking for steps they can follow to make the most of Google Cloud's capabilities in this area, including how to determine their requirements, preprocess and clean data, train and evaluate models, deploy models, and monitor and maintain them. The goal is to build high-quality, reliable models that deliver real-world impact.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1674978660000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":49.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-effectively-use-Google-Cloud-for-machine-learning-and\/m-p\/515192#M1149",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"effect us googl cloud machin learn googl cloud suit tool servic machin learn artifici intellig person ask question look step follow googl cloud capabl area includ determin requir preprocess clean data train evalu model deploi model monitor maintain goal build high qualiti reliabl model deliv real world impact",
        "Question_preprocessed_content":"us cloud machin learn cloud suit servic machin learn artifici person ask question step cloud capabl area includ determin requir clean data train evalu model deploi model monitor maintain goal build reliabl model deliv impact",
        "Question_gpt_summary_original":"The user is seeking guidance on how to effectively utilize Google Cloud's tools and services for machine learning and AI. They are looking for steps to determine their requirements, preprocess and clean data, train and evaluate models, deploy models, and monitor and maintain them to build high-quality, reliable models that deliver real-world impact.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Connect 2 separate experiments via webservice - Azure MLS Classic",
        "Question_body":"<p>I have 2 experiments A and B in Azure MLS classic. I need the web service output of experiment A as one of the web service inputs for experiment B.  Please let me know if it is possible and if yes, how I can do it.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1592407262483,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>I used export module in experiment A and import module in experiment B to transfer the output of A as input of B.<\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1592433417623,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/37128\/connect-2-separate-experiments-via-webservice-azur",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect separ experi webservic classic experi classic need web servic output experi web servic input experi let know possibl ye",
        "Question_preprocessed_content":"separ experi webservic experi web servic output experi web servic input experi let know ye",
        "Question_gpt_summary_original":"The user has two experiments in Azure MLS classic and needs to use the web service output of experiment A as one of the web service inputs for experiment B. They are seeking guidance on whether this is possible and how to do it.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to view runs on all remotes?",
        "Question_body":"<p>Hi, I have concurrent runs on multiple remotes (say 4 runs on 4 different remote). Is there a way to view the status of all runs from a single interface? I would imagine that <code>guild runs<\/code> should show them, but for some reason the remote runs appear as \u201cterminated\u201d (while in fact running) and switch to \u201ccompleted\u201d when they are finished.<br>\nI am working with a cluster that has shared drives if that could be taken advantage of.<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1614500077203,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":416.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/how-to-view-runs-on-all-remotes\/554",
        "Tool":"Guild AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"view run remot concurr run multipl remot run differ remot wai view statu run singl interfac imagin run reason remot run appear termin fact run switch complet finish work cluster share drive taken advantag thank",
        "Question_preprocessed_content":"view run remot run multipl remot wai view statu run singl interfac imagin reason remot run termin switch complet finish work cluster share drive taken advantag thank",
        "Question_gpt_summary_original":"The user is facing challenges in viewing the status of concurrent runs on multiple remotes from a single interface. The remote runs appear as \"terminated\" even when they are running and switch to \"completed\" only when they are finished. The user is working with a cluster that has shared drives.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"VSCode cannot see packages on a GCP VM",
        "Question_body":"<p>I have an issue where vscode when connected to a VM on GCP cannot see packages installed in <code>\/opt\/conda\/lib\/python3.7\/site-packages.<\/code> I have created the VM using Vertex AI. When I open the jupyter notebook through the UI in a the browser I can see all the packages via <code>pip3 list<\/code>. But when I am connected to the VM through SSH in vscode I cannot see the packages installed such as nltk, spacy etc. and when I try to load it gives me <code>ModuleNotFoundError<\/code>. This error does not show up when I use the jupyter notebook from the Vertex AI UI. The site-packages folder is in my system path and the python that I am using is <code>\/opt\/conda\/bin\/python3<\/code>.<\/p>\n<p>Any help is appreciated. Please do let me know if my question is clear.<\/p>\n<p>EDIT: I figured out that my packages are running on a container in the VM. Is there a way for me to access those packages via jupyter notebook in vscode?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1638473538253,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1638550660460,
        "Question_score_count":0.0,
        "Question_view_count":230.0,
        "Poster_created_time":1580840045043,
        "Poster_location":null,
        "Poster_reputation_count":85.0,
        "Poster_view_count":16.0,
        "Answer_body":"<p>Posting the answer as community wiki. As confirmed by @Abhishek, he was able to make it work by installing a docker extension on the VM then attach VS code to the container.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1638843453688,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1606724007903,
        "Answerer_location":null,
        "Answerer_reputation_count":5969.0,
        "Answerer_view_count":2590.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70205432",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"vscode packag gcp issu vscode connect gcp packag instal opt conda lib python site packag creat open jupyt notebook browser packag pip list connect ssh vscode packag instal nltk spaci try load give modulenotfounderror error us jupyt notebook site packag folder path python opt conda bin python help appreci let know question clear edit figur packag run contain wai access packag jupyt notebook vscode",
        "Question_preprocessed_content":"vscode packag gcp vscode gcp packag creat open jupyt browser packag vscode packag nltk spaci try load give us jupyt folder path python help let know question clear edit figur packag contain wai packag jupyt vscode",
        "Question_gpt_summary_original":"The user is facing an issue where VSCode, when connected to a VM on GCP, cannot see packages installed in \/opt\/conda\/lib\/python3.7\/site-packages. The packages are running on a container in the VM, and the user is looking for a way to access those packages via Jupyter Notebook in VSCode. The error message received is ModuleNotFoundError.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Saving partitioned parquet on AzureML",
        "Question_body":"<p>I'm working at a company that only allows us to use AzureMl.<\/p>\n<p>The output for one of our models is data enrichment: we read a table with customer information, segment it and then return a pandas DataFrame with <code>customer_id<\/code>, <code>segment_name<\/code>, <code>segment_type<\/code>, <code>reference_dt<\/code> and <code>processed_dt<\/code>.<\/p>\n<p>I wanted to save this information as parquet files, at the Azure blob storage, with <code>reference_dt<\/code> as partition.<\/p>\n<p>I can't find in the Docs how to do this. What I did find was the <code>Dataset.Tabular.register_pandas_dataframe<\/code> that stores the data in a non-customizable path, with an un-human-readable UIUD as the folder name.<\/p>\n<p>Whenever we update that segmentation, that method creates another version of the dataset, whose file path is under a different UIUD.<\/p>\n<p>Is there a way for me to have control on where the data will be stored so that I can later safely automate this procedure?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1635184123353,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":319.0,
        "Poster_created_time":1372453042100,
        "Poster_location":"Lisbon, Portugal",
        "Poster_reputation_count":394.0,
        "Poster_view_count":183.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69712598",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save partit parquet work compani allow us output model data enrich read tabl custom inform segment return panda datafram custom segment segment type refer process want save inform parquet file azur blob storag refer partit doc dataset tabular regist panda datafram store data non customiz path human readabl uiud folder updat segment method creat version dataset file path differ uiud wai control data store later safe autom procedur",
        "Question_preprocessed_content":"save partit parquet work compani us output model data enrich read tabl custom inform segment return panda datafram want save inform parquet file azur blob storag partit doc store data path uiud folder updat segment method creat version dataset file path uiud wai control data store later safe autom procedur",
        "Question_gpt_summary_original":"The user is working on a project using AzureML and needs to save data as parquet files on Azure blob storage with a specific partition. However, they are unable to find documentation on how to do this and the method they found creates non-customizable paths with unreadable folder names. The user is looking for a way to have control over where the data is stored to automate the procedure safely.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS Sagemaker Spark S3 access issue",
        "Question_body":"<p>I am new in AWS sagemaker. I created a notebook in a VPC with private subnet, kms default encrypted key, root access, no direct internet access. I have attached policy which have full access to Sagemaker and S3 in IAM as per documentations.  Now while one of data scientist trying to run his code in jupyter, getting below error. I can see jar files (\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker_pyspark\/jars\/), I have even given access key and secret key in code, is there anything we are doing wrong here<\/p>\n\n<pre><code>import os\nimport boto3\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nimport sagemaker\nfrom sagemaker import get_execution_role\nimport sagemaker_pyspark\nimport pyspark\n\nrole = get_execution_role()\nspark = SparkSession.builder \\\n            .appName(\"app_name2\") \\\n            .getOrCreate()\n\nsc=pyspark.SparkContext.getOrCreate()\nsc.setSystemProperty(\"com.amazonaws.services.s3.enableV4\", \"true\")\n\nhadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", 'access_key')\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", 'secret_key')\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-2.amazonaws.com\")\nspark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3a.enableV4\", \"true\")\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\");\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\ndf= spark.read.csv(\"s3a:\/\/mybucket\/ConsolidatedData\/my.csv\",header=\"true\")\n\n\nPy4JJavaError: An error occurred while calling o579.csv.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n    at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n    at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n    at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n    at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n    at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:709)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1583781550823,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1583817907990,
        "Question_score_count":0.0,
        "Question_view_count":933.0,
        "Poster_created_time":1513883236660,
        "Poster_location":"Noida, Uttar Pradesh, India",
        "Poster_reputation_count":465.0,
        "Poster_view_count":46.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60607041",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"spark access issu new creat notebook vpc privat subnet km default encrypt kei root access direct internet access attach polici access iam document data scientist try run code jupyt get error jar file home user anaconda env python lib python site packag pyspark jar given access kei secret kei code wrong import import boto pyspark import sparkcontext sparkconf pyspark sql import sparksess import import execut role import pyspark import pyspark role execut role spark sparksess builder appnam app getorcr pyspark sparkcontext getorcr setsystemproperti com amazonaw servic enablev true hadoop conf spark sparkcontext jsc hadoopconfigur spark jsc hadoopconfigur set access kei access kei spark jsc hadoopconfigur set secret kei secret kei spark jsc hadoopconfigur set endpoint east amazonaw com spark jsc hadoopconfigur set com amazonaw servic enablev true spark jsc hadoopconfigur set connect ssl enabl fals spark jsc hadoopconfigur set impl org apach hadoop safilesystem spark read csv mybucket consolidateddata csv header true pyjjavaerror error occur call csv java lang runtimeexcept java lang classnotfoundexcept class org apach hadoop safilesystem org apach hadoop conf configur getclass configur java org apach hadoop filesystem getfilesystemclass filesystem java org apach hadoop filesystem createfilesystem filesystem java org apach hadoop filesystem access filesystem java org apach hadoop filesystem cach getintern filesystem java org apach hadoop filesystem cach filesystem java org apach hadoop filesystem filesystem java org apach hadoop path getfilesystem path java org apach spark sql execut datasourc datasourc org apach spark sql execut datasourc datasourc checkandglobpathifnecessari datasourc scala",
        "Question_preprocessed_content":"spark new creat vpc privat subnet km default encrypt kei direct internet polici iam document data scientist try run code jupyt jar file given kei secret kei code wrong",
        "Question_gpt_summary_original":"The user is encountering an issue while trying to access S3 from AWS Sagemaker Spark. The user has attached a policy with full access to Sagemaker and S3 in IAM, and has given access key and secret key in the code. However, while running the code in Jupyter, the user is getting a \"ClassNotFoundException\" error for \"org.apache.hadoop.fs.s3a.S3AFileSystem\".",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"What is the role of feature type in AzureML?",
        "Question_body":"<p>I want to know what is the difference between <code>feature numeric<\/code> and <code>numeric<\/code> columns in Azure Machine Learning Studio.<\/p>\n\n<p>The <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/edit-metadata\" rel=\"nofollow noreferrer\">documentation site<\/a> states: <\/p>\n\n<blockquote>\n  <p>Because all columns are initially treated as features, for modules\n  that perform mathematical operations, you might need to use this\n  option to prevent numeric columns from being treated as variables.<\/p>\n<\/blockquote>\n\n<p>But nothing more. Not what a feature is, in which modules you need features. Nothing. <\/p>\n\n<p>I specifically would like to understand if the <code>clear feature<\/code> dropdown option in the <code>fields<\/code> in the <code>edit metadata<\/code>-module has any effect. Can somebody give me a szenario where this <code>clear feature<\/code>-operation changes the ML outcome? Thank you<\/p>\n\n<p>According to the documentation in ought to have an effect:<\/p>\n\n<blockquote>\n  <p>Use the Fields option if you want to change the way that Azure Machine\n  Learning uses the data in a model.<\/p>\n<\/blockquote>\n\n<p>But what can this effect be? Any example might help<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1538054010173,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1538054394440,
        "Question_score_count":1.0,
        "Question_view_count":70.0,
        "Poster_created_time":1368739128832,
        "Poster_location":"Riga, Latvia",
        "Poster_reputation_count":1763.0,
        "Poster_view_count":380.0,
        "Answer_body":"<p>As you suspect, setting a column as <code>feature<\/code> does have an effect, and it's actually quite important - when training a model, the algorithms will only take into account columns with the <code>feature<\/code> flag, effectively ignoring the others. <\/p>\n\n<p>For example, if you have a dataset with columns <code>Feature1<\/code>, <code>Feature2<\/code>, and <code>Label<\/code> and you want to try out just <code>Feature1<\/code>, you would apply <code>clear feature<\/code> to the <code>Feature2<\/code> column (while making sure that <code>Feature1<\/code> has the <code>feature<\/code> label set, of course).<\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1538116098500,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1250158552416,
        "Answerer_location":"Romania",
        "Answerer_reputation_count":7916.0,
        "Answerer_view_count":801.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52537861",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"role featur type want know differ featur numer numer column studio document site state column initi treat featur modul perform mathemat oper need us option prevent numer column treat variabl featur modul need featur specif like understand clear featur dropdown option field edit metadata modul effect somebodi szenario clear featur oper chang outcom thank accord document ought effect us field option want chang wai azur machin learn us data model effect exampl help",
        "Question_preprocessed_content":"role featur type want know column studio document site state column treat featur modul perform mathemat oper us option prevent numer column treat variabl featur modul featur like understand dropdown option modul somebodi szenario oper chang outcom thank document ought us field option want chang wai azur machin learn us data model exampl help",
        "Question_gpt_summary_original":"The user is seeking clarification on the difference between \"feature numeric\" and \"numeric\" columns in Azure Machine Learning Studio. They are also unsure about the purpose of the \"clear feature\" dropdown option in the \"edit metadata\" module and how it affects the ML outcome. The documentation provides limited information on these topics, and the user is looking for specific scenarios or examples.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Sagemaker Studio Pyspark example fails",
        "Question_body":"<p>When I try to run the Sagemaker provided examples with PySpark in Sagemaker Studio<\/p>\n<pre><code>import os\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nimport sagemaker\nfrom sagemaker import get_execution_role\nimport sagemaker_pyspark\n\nrole = get_execution_role()\n\n# Configure Spark to use the SageMaker Spark dependency jars\njars = sagemaker_pyspark.classpath_jars()\n\nclasspath = &quot;:&quot;.join(sagemaker_pyspark.classpath_jars())\n\n# See the SageMaker Spark Github repo under sagemaker-pyspark-sdk\n# to learn how to connect to a remote EMR cluster running Spark from a Notebook Instance.\nspark = SparkSession.builder.config(&quot;spark.driver.extraClassPath&quot;, classpath)\\\n    .master(&quot;local[*]&quot;).getOrCreate()\n<\/code><\/pre>\n<p>I get the following exception:<\/p>\n<pre><code>    ---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\n&lt;ipython-input-6-c8f6fff0daaf&gt; in &lt;module&gt;\n     19 # to learn how to connect to a remote EMR cluster running Spark from a Notebook Instance.\n     20 spark = SparkSession.builder.config(&quot;spark.driver.extraClassPath&quot;, classpath)\\\n---&gt; 21     .master(&quot;local[*]&quot;).getOrCreate()\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/sql\/session.py in getOrCreate(self)\n    171                     for key, value in self._options.items():\n    172                         sparkConf.set(key, value)\n--&gt; 173                     sc = SparkContext.getOrCreate(sparkConf)\n    174                     # This SparkContext may be an existing one.\n    175                     for key, value in self._options.items():\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/context.py in getOrCreate(cls, conf)\n    361         with SparkContext._lock:\n    362             if SparkContext._active_spark_context is None:\n--&gt; 363                 SparkContext(conf=conf or SparkConf())\n    364             return SparkContext._active_spark_context\n    365 \n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/context.py in __init__(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\n    127                     &quot; note this option will be removed in Spark 3.0&quot;)\n    128 \n--&gt; 129         SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n    130         try:\n    131             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/context.py in _ensure_initialized(cls, instance, gateway, conf)\n    310         with SparkContext._lock:\n    311             if not SparkContext._gateway:\n--&gt; 312                 SparkContext._gateway = gateway or launch_gateway(conf)\n    313                 SparkContext._jvm = SparkContext._gateway.jvm\n    314 \n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/java_gateway.py in launch_gateway(conf)\n     44     :return: a JVM gateway\n     45     &quot;&quot;&quot;\n---&gt; 46     return _launch_gateway(conf)\n     47 \n     48 \n\n\/opt\/conda\/lib\/python3.6\/site-packages\/pyspark\/java_gateway.py in _launch_gateway(conf, insecure)\n    106 \n    107             if not os.path.isfile(conn_info_file):\n--&gt; 108                 raise Exception(&quot;Java gateway process exited before sending its port number&quot;)\n    109 \n    110             with open(conn_info_file, &quot;rb&quot;) as info:\n\nException: Java gateway process exited before sending its port number\n<\/code><\/pre>\n<p>Before running the example I installed pyspark and sagemaker_pyspark with pip from the notebook. I am also using SparkMagic kernel from the kernels library of SageMaker.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_created_time":1610957989217,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1827.0,
        "Poster_created_time":1452190055592,
        "Poster_location":"Germany",
        "Poster_reputation_count":247.0,
        "Poster_view_count":49.0,
        "Answer_body":"<p>Maybe, you are having this issue because this notebook was designed to run when you have an EMR cluster. I suggest you start a notebook with conda_python3 kernel on Sagemaker instead of the SparkMagic kernel. You will need to install <code>pyspark<\/code> and <code>sagemaker_pyspark<\/code> using pip, but it should work with the code you posted.<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1611005573523,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1489170718523,
        "Answerer_location":"Toronto, ON, Canada",
        "Answerer_reputation_count":81.0,
        "Answerer_view_count":5.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65770913",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio pyspark exampl fail try run provid exampl pyspark studio import pyspark import sparkcontext sparkconf pyspark sql import sparksess import import execut role import pyspark role execut role configur spark us spark depend jar jar pyspark classpath jar classpath join pyspark classpath jar spark github repo pyspark sdk learn connect remot emr cluster run spark notebook instanc spark sparksess builder config spark driver extraclasspath classpath master local getorcr follow except except traceback recent learn connect remot emr cluster run spark notebook instanc spark sparksess builder config spark driver extraclasspath classpath master local getorcr opt conda lib python site packag pyspark sql session getorcr self kei valu self option item sparkconf set kei valu sparkcontext getorcr sparkconf sparkcontext exist kei valu self option item opt conda lib python site packag pyspark context getorcr cl conf sparkcontext lock sparkcontext activ spark context sparkcontext conf conf sparkconf return sparkcontext activ spark context opt conda lib python site packag pyspark context init self master appnam sparkhom pyfil environ batchsiz serial conf gatewai jsc profil cl note option remov spark sparkcontext ensur initi self gatewai gatewai conf conf try self init master appnam sparkhom pyfil environ batchsiz serial opt conda lib python site packag pyspark context ensur initi cl instanc gatewai conf sparkcontext lock sparkcontext gatewai sparkcontext gatewai gatewai launch gatewai conf sparkcontext jvm sparkcontext gatewai jvm opt conda lib python site packag pyspark java gatewai launch gatewai conf return jvm gatewai return launch gatewai conf opt conda lib python site packag pyspark java gatewai launch gatewai conf insecur path isfil conn info file rais except java gatewai process exit send port number open conn info file info except java gatewai process exit send port number run exampl instal pyspark pyspark pip notebook sparkmag kernel kernel librari",
        "Question_preprocessed_content":"studio pyspark exampl fail try run provid exampl pyspark studio except exampl pyspark pip sparkmag kernel kernel librari",
        "Question_gpt_summary_original":"The user is encountering an exception while trying to run Sagemaker provided examples with PySpark in Sagemaker Studio. The exception is related to the Java gateway process which exited before sending its port number. The user has installed pyspark and sagemaker_pyspark with pip and is using SparkMagic kernel from the kernels library of SageMaker.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"SageMaker metrics persistence",
        "Question_body":"Quick questions on ML metrics persistence from sagemaker training tasks. The SageMaker regexp-over-CloudWatch is an attractive option, yet the metric retention in Cloudwatch seems to be restricted to 15 days. \n\n 1. How to persist those metrics longer? Is it common to extract them out of Cloudwatch regularly to persist them somewhere else, eg S3 or an RDS? what is the best practice for long-term persistence of those\n    metrics?\n 2. Would SageMaker Experiments allow a collection of similar data (customer-defined training metrics) over a longer retention?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1578643279000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668414520527,
        "Question_score_count":0.0,
        "Question_view_count":227.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"1. You can now persist algorithm metrics from SageMaker Training Jobs (the ones you can collect with regexes or the ones available from built-in algorithms by default) by setting [EnableSageMakerTimeSeriesMetrics](https:\/\/alpha-docs-aws.amazon.com\/sagemaker\/latest\/dg\/API_AlgorithmSpecification.html#SageMaker-Type-AlgorithmSpecification-EnableSageMakerMetricsTimeSeries) through the AWS SDK or `enable_sagemaker_metrics=true` in the SageMaker Python SDK. These metrics are persisted long term, and available through Amazon SageMaker Studio. (Go to \"Metrics\" -> \"Add Chart\" from the detail page of a training job). These are available at no additional cost. \n\n2. Yes, SageMaker Experiments allow collection of similar data\n\nNote that system metrics (CPU\/GPU\/Memory\/Disk) are still available only through CloudWatch. ",
        "Answer_comment_count":0.0,
        "Question_closed_time":1578681130000,
        "Answer_last_edit_time":1667925565860,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU197giXXuRn-4Hz56HZZpSw\/sagemaker-metrics-persistence",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":1.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"metric persist quick question metric persist train task regexp cloudwatch attract option metric retent cloudwatch restrict dai persist metric longer common extract cloudwatch regularli persist rd best practic long term persist metric experi allow collect similar data custom defin train metric longer retent",
        "Question_preprocessed_content":"metric persist quick question metric persist train task option metric retent cloudwatch restrict dai persist metric longer extract cloudwatch regularli persist rd best practic persist metric experi similar data longer retent",
        "Question_gpt_summary_original":"The user is facing challenges with persisting ML metrics from SageMaker training tasks beyond the restricted 15-day retention period in Cloudwatch. They are seeking advice on the best practices for long-term persistence of these metrics, including whether to extract them regularly to persist elsewhere such as S3 or RDS. Additionally, they are inquiring about whether SageMaker Experiments would allow for longer retention of customer-defined training metrics.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Filter just one plot",
        "Question_body":"<p>I am doing a big sweep over my hyperparameters. I can plot the same statistic (accuracy) in multiple plots, grouping each plot by a different hyperparameter. Then, by looking at the plots I can see which hyperparameters perform best.<br>\nAt this point, I need to plot the accuracy in one plot filtering according to the best hyperparameters. I can use the filter button above the runs, but that filters ALL plots. I want to filter only one plot.<br>\nHow can I do that?<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1683929162225,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":45.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/filter-just-one-plot\/4390",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"filter plot big sweep hyperparamet plot statist accuraci multipl plot group plot differ hyperparamet look plot hyperparamet perform best point need plot accuraci plot filter accord best hyperparamet us filter button run filter plot want filter plot thank",
        "Question_preprocessed_content":"filter plot big hyperparamet plot statist multipl plot group plot hyperparamet plot hyperparamet perform best point plot plot filter best hyperparamet us filter run filter plot want filter plot thank",
        "Question_gpt_summary_original":"The user is trying to plot the accuracy of different hyperparameters in multiple plots to determine the best performing hyperparameters. However, they are facing difficulty in filtering just one plot based on the best hyperparameters, as the filter button filters all plots. They are seeking a solution to filter only one plot.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Use images in s3 with SageMaker without .lst files",
        "Question_body":"<p>I am trying to create (what I thought was) a simple image classification pipeline between s3 and SageMaker.<\/p>\n\n<p>Images are stored in an s3 bucket with their class labels in their file names currently, e.g.<\/p>\n\n<p><strong>My-s3-bucket-dir<\/strong><\/p>\n\n<pre><code>cat-1.jpg\ndog-1.jpg\ncat-2.jpg\n..\n<\/code><\/pre>\n\n<p>I've been trying to leverage several related example .py scripts, but most seem to be download data sets already in .rec format or containing special manifest or annotation files I don't have.<\/p>\n\n<p>All I want is to pass the images from s3 to the SageMaker image classification algorithm that's located in the same region, IAM account, etc. I suppose this means I need a <code>.lst<\/code> file<\/p>\n\n<p>When I try to manually create the <code>.lst<\/code> it doesn't seem to like it and it also takes too long doing manual work to be a good practice.<\/p>\n\n<p>How can I automatically generate the <code>.lst<\/code> file (or otherwise send the images\/classes for training)? <\/p>\n\n<p>Things I read made it sound like <code>im2rec.py<\/code> was a solution, but I don't see how. The example I'm working with now is <\/p>\n\n<p><code>Image-classification-fulltraining-highlevel.ipynb<\/code><\/p>\n\n<p>but it seems to download the data as <code>.rec<\/code>, <\/p>\n\n<pre><code>download('http:\/\/data.mxnet.io\/data\/caltech-256\/caltech-256-60-train.rec')\ndownload('http:\/\/data.mxnet.io\/data\/caltech-256\/caltech-256-60-val.rec')\n<\/code><\/pre>\n\n<p>which just skips working with the .jpeg files. I found another that converts them to <code>.rec<\/code> but again it has essentially the <code>.lst<\/code> already as <code>.json<\/code> and just converts it.<\/p>\n\n<p>I have mostly been working in a Python Jupyter notebook within the AWS console (in my browser) but I have also tried using their GUI. <\/p>\n\n<p>How can I simply and automatically generate the <code>.lst<\/code> or otherwise get the data\/class info into SageMaker without manually creating a <code>.lst<\/code> file?<\/p>\n\n<p><strong><em>Update<\/em><\/strong><\/p>\n\n<p>It looks like im2py can't be run against s3. You'd have to completely download everything from all s3 buckets into the notebook's storage...<\/p>\n\n<blockquote>\n  <p>Please note that [...] im2rec.py is running locally,\n  therefore cannot take input from the S3 bucket. To generate the list\n  file, you need to download the data and then use the im2rec tool. - AWS SageMaker Team<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1559921851153,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1560181849816,
        "Question_score_count":2.0,
        "Question_view_count":937.0,
        "Poster_created_time":1399301338467,
        "Poster_location":"Columbia, MD, USA",
        "Poster_reputation_count":21413.0,
        "Poster_view_count":6465.0,
        "Answer_body":"<p>There are 3 options to provide annotated data to the Image Classification algo: (1) packing labels in recordIO files, (2) storing labels in a JSON manifest file (\"augmented manifest\" option), (3) storing labels in a list file. All options are documented here: <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/image-classification.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/image-classification.html<\/a>.<\/p>\n\n<p>Augmented Manifest and .lst files option are quick to do since they just require you to create an annotation file with a usually quick <code>for<\/code> loop for example. RecordIO requires you to use <code>im2rec.py<\/code> tool, which is a little more work.<\/p>\n\n<p>Using .lst files is <strong>another option<\/strong> that is reasonably easy: you just need to create annotation them with a quick for loop, like this:<\/p>\n\n<pre><code># assuming train_index, train_class, train_pics store the pic index, class and path\n\nwith open('train.lst', 'a') as file:\n    for index, cl, pic in zip(train_index, train_class, train_pics):\n        file.write(str(index) + '\\t' + str(cl) + '\\t' + pic + '\\n')\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1559948298332,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1442180190107,
        "Answerer_location":null,
        "Answerer_reputation_count":3203.0,
        "Answerer_view_count":400.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56497428",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us imag lst file try creat thought simpl imag classif pipelin imag store bucket class label file name current bucket dir cat jpg dog jpg cat jpg try leverag relat exampl script download data set rec format contain special manifest annot file want pass imag imag classif algorithm locat region iam account suppos mean need lst file try manual creat lst like take long manual work good practic automat gener lst file send imag class train thing read sound like imrec solut exampl work imag classif fulltrain highlevel ipynb download data rec download http data mxnet data caltech caltech train rec download http data mxnet data caltech caltech val rec skip work jpeg file convert rec essenti lst json convert work python jupyt notebook aw consol browser tri gui simpli automat gener lst data class info manual creat lst file updat look like impi run complet download bucket notebook storag note imrec run local input bucket gener list file need download data us imrec tool team",
        "Question_preprocessed_content":"us imag lst file try creat simpl imag pipelin imag store bucket label file name try leverag relat exampl script download data set rec format contain special manifest file want imag imag algorithm locat region iam mean file try creat like take long manual work practic gener file thing read sound like solut exampl work download data skip work jpeg file convert convert work python jupyt aw consol tri gui simpli gener info creat file updat like run complet download bucket note input bucket gener list file download data us rec team",
        "Question_gpt_summary_original":"The user is trying to create an image classification pipeline between s3 and SageMaker, but is having trouble generating a .lst file to pass the images to the algorithm. They have tried leveraging example .py scripts, but most are for datasets already in .rec format or containing special manifest or annotation files. The user is looking for a simple and automatic way to generate the .lst file or otherwise get the data\/class info into SageMaker without manually creating a .lst file. The user has also been informed that im2rec.py cannot be run against s3 and that the data needs to be downloaded to generate the list file.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"azure ml update service erro AttributeError: AttributeError: 'str' object has no attribute 'id'",
        "Question_body":"<p>I am tying to update existing webservice using new Azure ML package   <br \/>\nIts failing with error - AttributeError: 'str' object has no attribute 'id'  <\/p>\n<p>Here is the script I am using -  <\/p>\n<pre><code>ws = Workspace.get(\n        name=workspace_name,\n        subscription_id=subscription_id,\n        resource_group=resource_group,\n        auth=cli_auth)\n\nmodel = Model.register(model_path = model_path,\n                   model_name = model_name,\n                   #tags = {&quot;key&quot;: &quot;1&quot;},\n                   description = model_description,\n                   workspace = ws)\n\nimage_config = ContainerImage.image_configuration(execution_script=&quot;score.py&quot;, \n                                              runtime=&quot;python&quot;, \n                                              conda_file=&quot;packagesenv.yml&quot;)\nimage = 'testazureml'\nservice_name = 'testazureml'\n\n# Retrieve existing service\nservice = Webservice(name = service_name, workspace = ws)\n\nprint(service)\n\nservice.update(image,'image.id')\n<\/code><\/pre>\n<p>please help  <br \/>\nI have been trying with different methods   <br \/>\nas - 'id', 'image_id'   <br \/>\nits still failing <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1626917581717,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/485052\/azure-ml-update-service-erro-attributeerror-attrib",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"updat servic erro attributeerror attributeerror str object attribut ty updat exist webservic new packag fail error attributeerror str object attribut script workspac workspac subscript subscript resourc group resourc group auth cli auth model model regist model path model path model model tag kei descript model descript workspac imag config containerimag imag configur execut script score runtim python conda file packagesenv yml imag test servic test retriev exist servic servic webservic servic workspac print servic servic updat imag imag help try differ method imag fail",
        "Question_preprocessed_content":"updat servic str object ty updat exist webservic new packag fail str object script help try method fail",
        "Question_gpt_summary_original":"The user is encountering an error while trying to update an existing webservice using the new Azure ML package. The error message states that 'str' object has no attribute 'id'. The user has shared the script used for the update and has tried different methods such as 'id' and 'image_id' but the issue persists.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS sagemaker invokeEndpoint model internal error",
        "Question_body":"<p>I am trying to send a request on a model on sagemaker using .NET. The code I am using is: <\/p>\n\n<pre><code>var data = File.ReadAllBytes(@\"C:\\path\\file.csv\");\nvar credentials = new Amazon.Runtime.BasicAWSCredentials(\"\",\"\");\nvar awsClient = new AmazonSageMakerRuntimeClient(credentials, RegionEndpoint.EUCentral1);\nvar request = new Amazon.SageMakerRuntime.Model.InvokeEndpointRequest\n{\n    EndpointName = \"EndpointName\",\n    ContentType = \"text\/csv\",\n    Body = new MemoryStream(data),\n};\n\nvar response = awsClient.InvokeEndpoint(request);\nvar predictions = Encoding.UTF8.GetString(response.Body.ToArray());\n<\/code><\/pre>\n\n<p>the error that I am getting on <code>awsClient.InvokeEndpoint(request)<\/code><\/p>\n\n<p>is:<\/p>\n\n<blockquote>\n  <p>Amazon.SageMakerRuntime.Model.ModelErrorException: 'The service\n  returned an error with Error Code ModelError and HTTP Body:\n  {\"ErrorCode\":\"INTERNAL_FAILURE_FROM_MODEL\",\"LogStreamArn\":\"arn:aws:logs:eu-central-1:xxxxxxxx:log-group:\/aws\/sagemaker\/Endpoints\/myEndpoint\",\"Message\":\"Received\n  server error (500) from model with message \\\"\\\". See\n  \"https:\/\/ url_to_logs_on_amazon\"\n  in account xxxxxxxxxxx for more\n  information.\",\"OriginalMessage\":\"\",\"OriginalStatusCode\":500}'<\/p>\n<\/blockquote>\n\n<p>the url that the error message suggests for more information does not help at all.<\/p>\n\n<p>I believe that it is a data format issue but I was not able to find a solution.<\/p>\n\n<p>Does anyone has encountered this behavior before?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1534946906973,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":4385.0,
        "Poster_created_time":1495715386880,
        "Poster_location":null,
        "Poster_reputation_count":51.0,
        "Poster_view_count":5.0,
        "Answer_body":"<p>The problem relied on the data format as suspected. In my case all I had to do is send the data as a json serialized string array and use <code>ContentType = application\/json<\/code> because the python function running on the endpoint which is responsible for sending the data to the predictor was only accepting json strings. <\/p>\n\n<p>Another way to solve this issues is to modify the python function which is responsible for the input handling to accept all content types and modify the data in a way that the predictor will understand.<\/p>\n\n<p>example of working code for my case:<\/p>\n\n<pre><code>        var data = new string[] { \"this movie was extremely good .\", \"the plot was very boring .\" };\n        var serializedData = JsonConvert.SerializeObject(data);\n\n        var credentials = new Amazon.Runtime.BasicAWSCredentials(\"\",\"\");\n        var awsClient = new AmazonSageMakerRuntimeClient(credentials, RegionEndpoint.EUCentral1);\n        var request = new Amazon.SageMakerRuntime.Model.InvokeEndpointRequest\n        {\n            EndpointName = \"endpoint\",\n            ContentType = \"application\/json\",\n            Body = new MemoryStream(Encoding.ASCII.GetBytes(serializedData)),\n        };\n\n        var response = awsClient.InvokeEndpoint(request);\n        var predictions = Encoding.UTF8.GetString(response.Body.ToArray());\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1535104925600,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1495715386880,
        "Answerer_location":null,
        "Answerer_reputation_count":51.0,
        "Answerer_view_count":5.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51968742",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"invokeendpoint model intern error try send request model net code var data file readallbyt path file csv var credenti new amazon runtim basicawscredenti var awsclient new amazonruntimecli credenti regionendpoint eucentr var request new amazon runtim model invokeendpointrequest endpointnam endpointnam contenttyp text csv bodi new memorystream data var respons awsclient invokeendpoint request var predict encod utf getstr respons bodi toarrai error get awsclient invokeendpoint request amazon runtim model modelerrorexcept servic return error error code modelerror http bodi errorcod intern failur model logstreamarn arn aw log central xxxxxxxx log group aw endpoint myendpoint messag receiv server error model messag http url log amazon account xxxxxxxxxxx inform originalmessag originalstatuscod url error messag suggest inform help believ data format issu abl solut encount behavior",
        "Question_preprocessed_content":"model intern try send request model net code servic return code bodi url inform help believ data format abl solut encount behavior",
        "Question_gpt_summary_original":"The user is encountering an error while trying to send a request to a model on AWS Sagemaker using .NET. The error message suggests an internal failure from the model with an error code of ModelError and HTTP Body. The user suspects it to be a data format issue but is unable to find a solution.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"What are the files under \"artifact\/\" for each run?",
        "Question_body":"<p>In an effort to comply with the 100GB storage limits, I have been looking closely at the \u201cusage\u201d page (<code>https:\/\/wandb.ai\/usage\/your-username-here<\/code>), and indexing, then deleting files using the <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/\">export API<\/a>. There is sometimes a significant discrepancy between the runs size reported by <code>https:\/\/wandb.ai\/usage\/your-username-here\/your-project-here\/runs<\/code> VS <code>https:\/\/wandb.ai\/usage\/your-username-here\/your-project-here\/runs\/your-run-here<\/code>.<\/p>\n<p>There is a set of files that are returned when using <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/run#files\">Run.files()<\/a> call, but they are invisible when looking at the run on the web dashboard (I suspect they are the cause of that size report discrepancy). In the extreme case of some of my runs, they are json files, with paths starting with <code>artifact\/<\/code>, and they number in the <strong>tens of thousands<\/strong>: e.g.:<\/p>\n<pre><code class=\"lang-auto\">artifact\/142190504\/wandb_manifest.json\nartifact\/142190516\/wandb_manifest.json\nartifact\/142190533\/wandb_manifest.json\nartifact\/142190533\/wandb_manifest.json.deadlist\nartifact\/142190544\/wandb_manifest.json\nartifact\/142190544\/wandb_manifest.json.deadlist\n<\/code><\/pre>\n<p>These files obviously relate to artifacts, but the artifacts themselves are queried through <a href=\"https:\/\/docs.wandb.ai\/ref\/python\/public-api\/run#logged_artifacts\">Run. logged_artifacts()<\/a>. I have been deleting artifacts in my past runs, keeping only less than 400 per run (these are very small artifacts), and I have been expecting the count of these \u201cmanifest\u201d files to go down, But it instead seemed to have created additional <code>.deadlist<\/code> files\u2026<\/p>\n<p>My questions are:<\/p>\n<ol>\n<li>What are these files?<\/li>\n<li>Are they important?<\/li>\n<li>What can I expect to happen if I manually delete them through the export API?<\/li>\n<li>Are they counted towards the 100GB limit?<\/li>\n<\/ol>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1684737262272,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":61.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-are-the-files-under-artifact-for-each-run\/4438",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"file artifact run effort compli storag limit look close usag page http usag usernam index delet file export api signific discrep run size report http usag usernam project run http usag usernam project run run set file return run file invis look run web dashboard suspect caus size report discrep extrem case run json file path start artifact number ten thousand artifact manifest json artifact manifest json artifact manifest json artifact manifest json deadlist artifact manifest json artifact manifest json deadlist file obvious relat artifact artifact queri run log artifact delet artifact past run keep run small artifact expect count manifest file instead creat addit deadlist file question file import expect happen manual delet export api count limit",
        "Question_preprocessed_content":"file run compli storag limit close usag page index delet file export api signific discrep run size report set file return invis run web dashboard extrem case run json file path start number ten thousand file obvious relat artifact artifact queri run delet artifact past run run expect count manifest file instead creat file question file import expect delet export api count limit",
        "Question_gpt_summary_original":"The user is trying to comply with the 100GB storage limit by indexing and deleting files using the export API. However, there is a discrepancy between the reported size of runs on the web dashboard and the Run.files() call. The user has found a set of files starting with \"artifact\/\" that are not visible on the web dashboard and suspects they are causing the discrepancy. The user has questions about these files, including what they are, if they are important, if they count towards the 100GB limit, and what will happen if they are manually deleted through the export API.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Error while hyperparameter search",
        "Question_body":"<p>When I try wandb.sweep, it gives following error:  wandb.errors.CommError: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.<\/p>\n<p>Following this, is my sweep config<br>\n{\u2018method\u2019: \u2018random\u2019,<br>\n\u2018metric\u2019: {\u2018goal\u2019: \u2018minimize\u2019, \u2018name\u2019: \u2018loss\u2019},<br>\n\u2018parameters\u2019: {\u2018batch_size\u2019: {\u2018distribution\u2019: \u2018q_log_uniform_values\u2019,<br>\n\u2018max\u2019: 256,<br>\n\u2018min\u2019: 32,<br>\n\u2018q\u2019: 8},<br>\n\u2018epochs\u2019: {\u2018value\u2019: 10},<br>\n\u2018fc_layer_size\u2019: {\u2018values\u2019: [16, 32, 64]},<br>\n\u2018learning_rate\u2019: {\u2018distribution\u2019: \u2018uniform\u2019,<br>\n\u2018max\u2019: 0.1,<br>\n\u2018min\u2019: 0},<br>\n\u2018optimizer\u2019: {\u2018values\u2019: [\u2018adam\u2019, \u2018sgd\u2019]},<br>\n\u2018training_snr\u2019: {\u2018values\u2019: [0.3981071705534972,<br>\n0.44668359215096315,<br>\n0.5011872336272722,<br>\n0.5623413251903491,<br>\n0.6309573444801932,<br>\n0.7079457843841379,<br>\n0.7943282347242815,<br>\n0.8912509381337456,<br>\n1.0,<br>\n1.1220184543019633,<br>\n1.2589254117941673,<br>\n1.4125375446227544,<br>\n1.5848931924611136,<br>\n1.7782794100389228,<br>\n1.9952623149688795,<br>\n2.2387211385683394,<br>\n2.51188643150958,<br>\n2.8183829312644537,<br>\n3.1622776601683795,<br>\n3.548133892335755,<br>\n3.9810717055349722,<br>\n4.466835921509632,<br>\n5.011872336272722,<br>\n5.623413251903491,<br>\n6.309573444801933,<br>\n7.079457843841379,<br>\n7.943282347242816,<br>\n8.912509381337454,<br>\n10.0]}}}<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_created_time":1657819842704,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":306.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-while-hyperparameter-search\/2751",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error hyperparamet search try sweep give follow error error commerror bad request browser proxi sent request server understand follow sweep config method random metric goal minim loss paramet batch size distribut log uniform valu max min epoch valu layer size valu learn rate distribut uniform max min optim valu adam sgd train snr valu",
        "Question_preprocessed_content":"hyperparamet search try give bad request browser sent request server understand config method random metric paramet epoch optim",
        "Question_gpt_summary_original":"The user is encountering an error while using wandb.sweep for hyperparameter search. The error message is \"wandb.errors.CommError: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\" The user has also provided their sweep config, which includes various parameters such as batch size, epochs, learning rate, optimizer, and training signal-to-noise ratio.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Convert web service output to a dataset Azure MLS classic",
        "Question_body":"<p>Is it possible to convert a web service output as a dataset or a csv file ? I want to consume this in another experiment.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1592408319737,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>You can delete or export in-product data stored by Azure Machine Learning Studio (classic) by using the Azure portal, the Studio (classic) interface, PowerShell, and authenticated REST APIs. This article tells you how.    <\/p>\n<p>Telemetry data can be accessed through the Azure Privacy portal.    <\/p>\n<p>More details please refer to: <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/export-delete-personal-data-dsr\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio\/export-delete-personal-data-dsr<\/a>    <\/p>\n<p>And also you can use one of the Azure Machine Learning Studio Module - &quot;Export Data&quot; to do it : <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-data?redirectedfrom=MSDN\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-data?redirectedfrom=MSDN<\/a>    <\/p>\n<p>Let me know if you have more questions.    <\/p>\n<p>Regards,    <br \/>\nYutong<\/p>\n",
        "Answer_comment_count":2.0,
        "Question_closed_time":1592416585020,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/37214\/convert-web-service-output-to-a-dataset-azure-mls",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"convert web servic output dataset classic possibl convert web servic output dataset csv file want consum experi",
        "Question_preprocessed_content":"convert web servic output dataset convert web servic output dataset csv file want consum experi",
        "Question_gpt_summary_original":"The user wants to know if it is possible to convert a web service output into a dataset or CSV file so that it can be used in another experiment.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Google Retail Facet Search: How to get all facets where result count is not empty in search response",
        "Question_body":"Dear Developers,\n\nI am currently working on implementing Google Retail Search in my application. The challenge I am facing is that I have over 200 custom product attributes, making it impractical to add all of them in the FacetSpecs during searching requests. However, I need to retrieve facets value and their count to build a user-friendly filter.\n\nI attempted to use dynamic Facets, but unfortunately, I could not find any specific documentation on how to retrieve dynamic facet data when using Search API. Hence, I am requesting suggestions from experienced developers within the community. Any help provided will be greatly appreciated.\n\nThank you.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1680550980000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":120.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Retail-Facet-Search-How-to-get-all-facets-where-result\/m-p\/540416#M1576",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"googl retail facet search facet result count search respons dear develop current work implement googl retail search applic challeng face custom product attribut make impract add facetspec search request need retriev facet valu count build user friendli filter attempt us dynam facet unfortun specif document retriev dynam facet data search api request suggest experienc develop commun help provid greatli appreci thank",
        "Question_preprocessed_content":"retail facet search facet result count search respons dear develop work implement retail search face custom product make impract facetspec search request retriev facet valu count build filter us dynam facet unfortun specif document retriev dynam facet data search api request experienc develop help provid greatli thank",
        "Question_gpt_summary_original":"The user is facing a challenge while implementing Google Retail Search in their application due to having over 200 custom product attributes, making it impractical to add all of them in the FacetSpecs during searching requests. They need to retrieve facets value and their count to build a user-friendly filter but are unable to find specific documentation on how to retrieve dynamic facet data when using Search API. They are seeking suggestions from experienced developers within the community.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How do I get the version of an artifact?",
        "Question_body":"<p>Hey,<br>\nI\u2019m trying to get the version of an artifact directly after logging my model (encoder) as an artifact to WandB.<\/p>\n<p><strong>Code:<\/strong><\/p>\n<pre><code class=\"lang-auto\">artifact = wandb.Artifact('my_artifact_name', type='model')\nartifact.add_file('\/home\/dezzardhd\/encoder.pth')\nwandb.log_artifact(artifact)\nversion = artifact.version\n<\/code><\/pre>\n<p>Logging works so far, but\u2026<br>\nwhen trying to access the version of the artifact I get an error.<br>\n<strong>Error:<\/strong><\/p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/main.py\", line 48, in &lt;module&gt;\n    train_setups.start_training_sessions(project=project)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/train_setups.py\", line 18, in start_training_sessions\n    model_pipeline(config, project=project)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/learning.py\", line 84, in model_pipeline\n    save_model(model_ae=model, model_encoder=model_encoder, model_decoder=model_decoder)\n  File \"\/home\/moritz\/PycharmProjects\/bachelorarbeit\/learning.py\", line 124, in save_model\n    version = artifact_enc.version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_artifacts.py\", line 191, in version\n    return self._logged_artifact.version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 2899, in version\n    return self._assert_instance().version\n  File \"\/home\/moritz\/anaconda3\/envs\/bachelorarbeit\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_run.py\", line 2871, in _assert_instance\n    raise ValueError(\nValueError: Must call wait() before accessing logged artifact properties\n<\/code><\/pre>\n<p>What should I do now?<\/p>\n<p>For context:<br>\nI want to print out the version number with some other parameters so that I can easier start my evaluation process for certain runs.<\/p>\n<p>Best regards<br>\nDezzardHD<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1646690111212,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":411.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dezzardhd\">@dezzardhd<\/a>,<\/p>\n<p>Could you try running your code as the following?<\/p>\n<pre><code class=\"lang-python\">artifact = wandb.Artifact('my_artifact_name', type='model')\nartifact.add_file('\/home\/dezzardhd\/encoder.pth')\nwandb.log_artifact(artifact).wait()\nversion = artifact.version\n<\/code><\/pre>\n<p>Calling <code>wait()<\/code> after <code>log_artifact()<\/code> should resolve this for you.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
        "Answer_comment_count":null,
        "Question_closed_time":1646696888232,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-get-the-version-of-an-artifact\/2035",
        "Tool":"Weights & Biases",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"version artifact hei try version artifact directli log model encod artifact code artifact artifact artifact type model artifact add file home dezzardhd encod pth log artifact artifact version artifact version log work far try access version artifact error error traceback recent file home moritz pycharmproject bachelorarbeit main line train setup start train session project project file home moritz pycharmproject bachelorarbeit train setup line start train session model pipelin config project project file home moritz pycharmproject bachelorarbeit learn line model pipelin save model model model model encod model encod model decod model decod file home moritz pycharmproject bachelorarbeit learn line save model version artifact enc version file home moritz anaconda env bachelorarbeit lib python site packag sdk artifact line version return self log artifact version file home moritz anaconda env bachelorarbeit lib python site packag sdk run line version return self assert instanc version file home moritz anaconda env bachelorarbeit lib python site packag sdk run line assert instanc rais valueerror valueerror wait access log artifact properti context want print version number paramet easier start evalu process certain run best regard dezzardhd",
        "Question_preprocessed_content":"version artifact hei try version artifact directli model artifact code work far try version artifact context want print version number paramet easier start evalu certain run best regard",
        "Question_gpt_summary_original":"The user is trying to get the version of an artifact after logging their model as an artifact to WandB. Although logging works, the user encounters an error when trying to access the version of the artifact. The error message suggests that the user must call wait() before accessing logged artifact properties. The user is seeking advice on what to do next as they want to print out the version number with some other parameters to start their evaluation process for certain runs.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Compose model",
        "Question_body":"<p>As the document     <br \/>\nA composed model is created by taking a collection of custom models and assigning them to a single model ID. You can assign up to 100 trained custom models to a single composed model ID. When a document is submitted to a composed model, the service performs a classification step to decide which custom model accurately represents the form presented for analysis.     <\/p>\n<p>What\u2019s the price for the classification step? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1669041105107,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=08dc8e09-5319-4bd7-9cf8-cce17f133981\">@KenSmith  <\/a>     <\/p>\n<p>Thanks for reaching out to us and sorry for the confusion of the document.     <\/p>\n<p>There is <strong>no extra fee<\/strong> for the classification you mentioned in the document. You only pay for the custom model you finally run for your document.    <\/p>\n<p>I will raise a ticket to fix the document, thanks a lot for pointing out it.    <\/p>\n<p>I hope this helps!    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks! <\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1669044705523,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1098169\/compose-model",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"compos model document compos model creat take collect custom model assign singl model assign train custom model singl compos model document submit compos model servic perform classif step decid custom model accur repres form present analysi what price classif step",
        "Question_preprocessed_content":"compos model document compos model creat take custom model singl model train custom model singl compos model document compos model servic perform step decid custom model repres form present analysi what price step",
        "Question_gpt_summary_original":"The user is inquiring about the cost of the classification step when using a composed model, which is created by assigning multiple custom models to a single model ID for document analysis.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to input data from S3 Bucket to Amazon Sagemaker",
        "Question_body":"<p>I would like to input data(Caltech 256 dataset) from Amazon s3 to sagemaker. I am doing this because I would like to modify the dataset if I can get this to work. Any ideas?<\/p>\n\n<p>Tried using the pandas code from 'Load S3 Data into AWS SageMaker Notebook'<\/p>\n\n<p>I hope the data from the S3 bucket will work just like downloading straight from the url. Obviously it isn't working.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1553891985250,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1613286737432,
        "Question_score_count":0.0,
        "Question_view_count":194.0,
        "Poster_created_time":1553873252896,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55425199",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"input data bucket like input data caltech dataset amazon like modifi dataset work idea tri panda code load data notebook hope data bucket work like download straight url obvious isn work",
        "Question_preprocessed_content":"input data bucket like input data amazon like modifi dataset work idea tri panda code load data hope data bucket work like download straight url obvious isn work",
        "Question_gpt_summary_original":"The user is facing challenges in inputting data from an Amazon S3 bucket to Amazon Sagemaker, specifically the Caltech 256 dataset. They have attempted to use pandas code from 'Load S3 Data into AWS SageMaker Notebook', but it is not working as expected. The user hopes that the data from the S3 bucket will work similarly to downloading it directly from the URL.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Timing test on azure ml",
        "Question_body":"<p>I have created data sets of various sizes say 1GB, 2GB, 3GB, 4GB (&lt; 10 GB) and executing various machine learning models on Azure ML. <\/p>\n\n<p>1) Can I know what is the server specifications (RAM, CPU) that is provided in the Azure ML service.<\/p>\n\n<p>2) Also at times the reader says \"Memory exhaust\" for >4GB of data.Though azure ml should be able to handle 10GB of data as per documentation.<\/p>\n\n<p>3) If I run multiple experiments(in different tabs of browser) in parallel, its taking more time.<\/p>\n\n<p>4) Is there any way to set the RAM, CPU cores in Azure ML<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4.0,
        "Question_created_time":1456387015953,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1457425395532,
        "Question_score_count":5.0,
        "Question_view_count":155.0,
        "Poster_created_time":1456386494000,
        "Poster_location":"Dubai - United Arab Emirates",
        "Poster_reputation_count":51.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35621424",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"time test creat data set size data abl handl data document run multipl experi differ tab browser parallel take time wai set ram cpu core",
        "Question_preprocessed_content":"time test creat data set size execut machin learn model know server specif provid servic time reader sai memori exhaust abl handl data document run multipl experi take time wai set ram cpu core",
        "Question_gpt_summary_original":"The user has encountered challenges while executing various machine learning models on Azure ML. They are unsure about the server specifications provided by Azure ML and have faced \"Memory exhaust\" errors while working with data sets larger than 4GB. The user has also observed that running multiple experiments in parallel takes more time and is looking for a way to set the RAM and CPU cores in Azure ML.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"how to log error\/messages in while running a sagemaker batch transform job?",
        "Question_body":"i'm using a hugging face model and a container to create a batch transform job in sagemaker. i have a custom inference code and in the output_fn function i'm returning json_dumps(prediction). I'm using print(prediction) to see, if i can see it in the cloudwatch logs to find out type and what prediction is. how can  log these messages . Also, the inference output i get is in the form below., i'm not sure why is it not a json object in each line instead it has square brackets. I want to use the filter to match the input and output in the batch job. I'm not sure how the output should look like , because i'm trying to associate input with output by using dataprocessing config as below. but i get an error. the documenation has example of csv not json. what should the output look like so that i can associate the input with output when they both are in json format. \n\n```\n  \"DataProcessing\": {\n        \"JoinSource\": \"Input\"\n    },\n```\n```\n[ output text 1 ]\n[output text 2 ]\n```\n\n```\n# Serialize the prediction result into the desired response content type\ndef output_fn(prediction, accept=JSON_CONTENT_TYPE):\n    logger.info(\"Serializing the generated output.\")\n    if accept == JSON_CONTENT_TYPE:\n        output = json.dumps(prediction)\n        return output, accept\n    raise Exception(\"Requested unsupported ContentType in Accept: {}\".format(accept))\n```",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1653699481978,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1667926062256,
        "Question_score_count":0.0,
        "Question_view_count":83.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUNirOT1cMSfig9ANtgmZMpg\/how-to-log-error-messages-in-while-running-a-sagemaker-batch-transform-job",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"log error messag run batch transform job hug face model contain creat batch transform job custom infer code output function return json dump predict print predict cloudwatch log type predict log messag infer output form sure json object line instead squar bracket want us filter match input output batch job sure output look like try associ input output dataprocess config error documen exampl csv json output look like associ input output json format dataprocess joinsourc input output text output text serial predict result desir respons content type def output predict accept json content type logger info serial gener output accept json content type output json dump predict return output accept rais except request unsupport contenttyp accept format accept",
        "Question_preprocessed_content":"log batch transform job face model contain creat batch transform job custom infer code function return print cloudwatch log type predict log infer output form sure json object line instead squar bracket want us filter match input output batch job sure output like try input output config documen exampl csv json output like input output json format",
        "Question_gpt_summary_original":"The user is facing challenges in logging error\/messages while running a SageMaker batch transform job using a Hugging Face model and a container with custom inference code. They are using print statements to view the output in CloudWatch logs and want to log these messages. The user is also unsure about the output format and how to associate input with output when both are in JSON format. They are trying to use the DataProcessing config to match input and output but are getting an error.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure Machine  learning AutoML Fail",
        "Question_body":"<p>Hi ,    <\/p>\n<p>I use the fakenews data to try azure machine learning automl , but always train model fail and I tried reducing the feature field  , but still fail    <\/p>\n<p>Error message :    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/188507-image.png?platform=QnA\" alt=\"188507-image.png\" \/>    <\/p>\n<p>Run timed out. No model completed training in the specified time. Possible solutions:     <\/p>\n<ol>\n<li> Please check if there are enough compute resources to run the experiment.     <\/li>\n<li> Increase experiment timeout when creating a run.     <\/li>\n<li> Subsample your dataset to decrease featurization\/training time out    <\/li>\n<\/ol>\n<p>compute machine : STANDARD_DS12_V2    <\/p>\n<p>data source  : <a href=\"https:\/\/www.kaggle.com\/c\/fake-news\/data\">https:\/\/www.kaggle.com\/c\/fake-news\/data<\/a>    <\/p>\n<p>Is any good idea or suggestions ?    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1648706020587,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/794697\/azure-machine-learning-automl-fail",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"azur machin learn automl fail us fakenew data try automl train model fail tri reduc featur field fail error messag run time model complet train specifi time possibl solut check comput resourc run experi increas experi timeout creat run subsampl dataset decreas featur train time comput machin standard data sourc http www kaggl com fake new data good idea suggest",
        "Question_preprocessed_content":"azur machin learn automl fail us fakenew data try automl train model fail tri reduc featur field fail run time model complet train specifi time solut check comput resourc run experi increas experi timeout creat run subsampl dataset decreas time comput machin data sourc idea",
        "Question_gpt_summary_original":"The user is facing issues with Azure Machine Learning AutoML while trying to train a model using the fakenews dataset. The model training always fails, even after reducing the feature field. The error message suggests that the run timed out and provides possible solutions such as checking for enough compute resources, increasing experiment timeout, and subsampling the dataset. The user is using a STANDARD_DS12_V2 compute machine and the data source is from Kaggle. The user is seeking suggestions to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is there a way to pass arguments to multiple jobs in optuna?",
        "Question_body":"<p>I am trying to use optuna for searching hyper parameter spaces.<\/p>\n\n<p>In one particular scenario I train a model on a machine with a few GPUs.\nThe model and batch size allows me to run 1 training per 1 GPU.\nSo, ideally I would like to let optuna spread all trials across the available GPUs\nso that there is always 1 trial running on each GPU.<\/p>\n\n<p>In the <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/faq.html#how-can-i-use-two-gpus-for-evaluating-two-trials-simultaneously\" rel=\"nofollow noreferrer\">docs<\/a> it says, I should just start one process per GPU in a separate terminal like:<\/p>\n\n<pre><code>CUDA_VISIBLE_DEVICES=0 optuna study optimize foo.py objective --study foo --storage sqlite:\/\/\/example.db\n<\/code><\/pre>\n\n<p>I want to avoid that because the whole hyper parameter search continues in multiple rounds after that. I don't want to always manually start a process per GPU, check when all are finished, then start the next round.<\/p>\n\n<p>I saw <code>study.optimize<\/code> has a <code>n_jobs<\/code> argument.\nAt first glance this seems to be perfect.\n<em>E.g.<\/em> I could do this:<\/p>\n\n<pre><code>import optuna\n\ndef objective(trial):\n    # the actual model would be trained here\n    # the trainer here would need to know which GPU\n    # it should be using\n    best_val_loss = trainer(**trial.params)\n    return best_val_loss\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=100, n_jobs=8)\n<\/code><\/pre>\n\n<p>This starts multiple threads each starting a training.\nHowever, the trainer within <code>objective<\/code> somehow needs to know which GPU it should be using.\nIs there a trick to accomplish that?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1589323176827,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":2684.0,
        "Poster_created_time":1447522907212,
        "Poster_location":"Berlin, Germany",
        "Poster_reputation_count":758.0,
        "Poster_view_count":95.0,
        "Answer_body":"<p>After a few mental breakdowns I figured out that I can do what I want using a <code>multiprocessing.Queue<\/code>. To get it into the objective function I need to define it as a lambda function or as a class (I guess partial also works). <em>E.g.<\/em><\/p>\n\n<pre><code>from contextlib import contextmanager\nimport multiprocessing\nN_GPUS = 2\n\nclass GpuQueue:\n\n    def __init__(self):\n        self.queue = multiprocessing.Manager().Queue()\n        all_idxs = list(range(N_GPUS)) if N_GPUS &gt; 0 else [None]\n        for idx in all_idxs:\n            self.queue.put(idx)\n\n    @contextmanager\n    def one_gpu_per_process(self):\n        current_idx = self.queue.get()\n        yield current_idx\n        self.queue.put(current_idx)\n\n\nclass Objective:\n\n    def __init__(self, gpu_queue: GpuQueue):\n        self.gpu_queue = gpu_queue\n\n    def __call__(self, trial: Trial):\n        with self.gpu_queue.one_gpu_per_process() as gpu_i:\n            best_val_loss = trainer(**trial.params, gpu=gpu_i)\n            return best_val_loss\n\nif __name__ == '__main__':\n    study = optuna.create_study()\n    study.optimize(Objective(GpuQueue()), n_trials=100, n_jobs=8)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1589464897583,
        "Answer_last_edit_time":null,
        "Answer_score_count":6.0,
        "Answerer_created_time":1447522907212,
        "Answerer_location":"Berlin, Germany",
        "Answerer_reputation_count":758.0,
        "Answerer_view_count":95.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61763206",
        "Tool":"Optuna",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wai pass argument multipl job try us search hyper paramet space particular scenario train model machin gpu model batch size allow run train gpu ideal like let spread trial avail gpu trial run gpu doc sai start process gpu separ termin like cuda visibl devic studi optim foo object studi foo storag sqlite exampl want avoid hyper paramet search continu multipl round want manual start process gpu check finish start round saw studi optim job argument glanc perfect import def object trial actual model train trainer need know gpu best val loss trainer trial param return best val loss studi creat studi studi optim object trial job start multipl thread start train trainer object need know gpu trick accomplish",
        "Question_preprocessed_content":"wai argument multipl job try us search hyper paramet space particular scenario train model machin gpu model batch size run train gpu like let spread trial avail gpu trial gpu doc sai start gpu separ termin like want avoid hyper paramet search continu multipl round want start gpu check finish start round saw argument glanc perfect start multipl thread start train trainer know gpu trick",
        "Question_gpt_summary_original":"The user is trying to use optuna for hyperparameter search and wants to spread all trials across available GPUs. The documentation suggests starting one process per GPU in a separate terminal, but the user wants to avoid that. The user has tried using the `n_jobs` argument in `study.optimize` to start multiple threads, but the trainer within `objective` needs to know which GPU to use. The user is looking for a way to pass arguments to multiple jobs in optuna.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is there way to fix CSV reading in Russian Language in Azure ML Studio?",
        "Question_body":"<p>I have a large csv file containing some text in Russian language. When I upload it to Azure ML Studio as dataset, it appears like \"\ufffd\ufffd\ufffd\ufffd\". What I can do to fix that problem?<\/p>\n\n<p>I tried changing encoding of my text to UTF8, KOI8-R.<\/p>\n\n<p>There is no code, but I can share part of the dataset for you to try.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1565669343940,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":141.0,
        "Poster_created_time":1565668918750,
        "Poster_location":"Nur-Sultan, Kazakhstan",
        "Poster_reputation_count":11.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57471007",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wai fix csv read russian languag studio larg csv file contain text russian languag upload studio dataset appear like fix problem tri chang encod text utf koi code share dataset try",
        "Question_preprocessed_content":"wai fix csv read languag studio larg csv file contain text languag upload studio dataset like fix problem tri chang encod text utf code share dataset try",
        "Question_gpt_summary_original":"The user is facing an issue with CSV reading in Russian language in Azure ML Studio. When the user uploads the file, the text appears as \"\ufffd\ufffd\ufffd\ufffd\". The user has tried changing the encoding to UTF8 and KOI8-R but the problem persists.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Use GroundTruth bbox labels in a TensorFlow fine tuning job",
        "Question_body":"I can use the manifest file created by Ground Truth [ref](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sms-data-output.html#sms-output-box) as input to a training job for object detection ([ref](https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/396c4d204c966df8a1d5f702a6fb16789d96a9b3\/ground_truth_labeling_jobs\/object_detection_augmented_manifest_training\/object_detection_augmented_manifest_training.ipynb)). \nCan also use it for Tensorflow jobs, like the one [here](https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/object-detection-tensorflow.html)? In all the tutorials I find, the data in `annotations.json` has a different format than the one in the GroundTruth output.\n\nMy goal is to use more ad-hoc models rather than just resnet and vgg, and get information from Tensorboard and such.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1685146292984,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1685319981020,
        "Question_score_count":0.0,
        "Question_view_count":16.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUqOffgCNnTj2FSE873aQeLQ\/use-groundtruth-bbox-labels-in-a-tensorflow-fine-tuning-job",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us groundtruth bbox label tensorflow fine tune job us manifest file creat ground truth ref http doc aw amazon com latest sm data output html sm output box input train job object detect ref http github com aw amazon exampl blob cdcdfadfafbdab ground truth label job object detect augment manifest train object detect augment manifest train ipynb us tensorflow job like http doc aw amazon com latest object detect tensorflow html tutori data annot json differ format groundtruth output goal us hoc model resnet vgg inform tensorboard",
        "Question_preprocessed_content":"us groundtruth label tensorflow fine tune job us manifest file creat ground truth input train job object detect us tensorflow job like tutori data format groundtruth output goal us model resnet inform tensorboard",
        "Question_gpt_summary_original":"The user wants to use the manifest file created by Ground Truth as input to a TensorFlow fine tuning job for object detection. However, the user is facing challenges as the data format in the `annotations.json` file used in tutorials is different from the one in the GroundTruth output. The user's goal is to use more ad-hoc models and get information from Tensorboard.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Error 403 in Vertex Ai Workbench",
        "Question_body":"I am facing an issue where if I click on the \"OPEN JUPITER LAB\" link on my instance it directs me to a Error 403 page with the text: \"403.\u00a0That\u2019s an error.\u00a0That\u2019s all we know.\"\n\nWhat access am I missing?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1678243800000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":182.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-403-in-Vertex-Ai-Workbench\/m-p\/530061#M1390",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error workbench face issu click open jupit lab link instanc direct error page text that error that know access miss",
        "Question_preprocessed_content":"workbench face click open jupit lab link instanc direct page text that",
        "Question_gpt_summary_original":"The user is encountering an Error 403 page when trying to access the \"OPEN JUPITER LAB\" link on their Vertex AI Workbench instance, indicating that they are missing the necessary access to view the page.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Running scripts from a datastore on Azure Machine Learning Service",
        "Question_body":"<p>I am migrating from Batch AI to the new Azure Machine Learning Service. Previously I had my python scripts on an Azure Files share and those scripts ran directly from there.<\/p>\n\n<p>In the new service when you create an Estimator you have to provide a source directory and an entry script. The documentation states the source directory is a local directory that is copied to the remote computer.<\/p>\n\n<p>However, the Estimator constructor also allows you to specify a datastore name that is supposed to specify the datastore for the project share.<\/p>\n\n<p>To me, this sounds like you can specify a datastore and then the source directory is relative to that however this does not work, it still wants to find the source directory on the local machine.<\/p>\n\n<pre><code>tf_est = TensorFlow(source_directory='.\/script',\n                source_directory_data_store=ds,\n                script_params=script_params,\n                compute_target=compute_target,\n                entry_script='helloworld.py',\n                use_gpu=False)\n<\/code><\/pre>\n\n<p>Does anybody know if its possible to run a training job using a datastore for execution?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1548806606603,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1554813331196,
        "Question_score_count":2.0,
        "Question_view_count":141.0,
        "Poster_created_time":1336005137536,
        "Poster_location":null,
        "Poster_reputation_count":752.0,
        "Poster_view_count":117.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54431484",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run script datastor servic migrat batch new servic previous python script azur file share script ran directli new servic creat estim provid sourc directori entri script document state sourc directori local directori copi remot estim constructor allow specifi datastor suppos specifi datastor project share sound like specifi datastor sourc directori rel work want sourc directori local machin est tensorflow sourc directori script sourc directori data store script param script param comput target comput target entri script helloworld us gpu fals anybodi know possibl run train job datastor execut",
        "Question_preprocessed_content":"script datastor servic migrat batch new servic previous python script azur file share script ran directli new servic creat estim provid sourc directori entri script document state sourc directori local directori copi remot estim constructor specifi datastor specifi datastor project share sound like specifi datastor sourc directori rel work want sourc directori local machin anybodi know run train job datastor execut",
        "Question_gpt_summary_original":"The user is facing challenges while migrating from Batch AI to Azure Machine Learning Service. They are unable to run python scripts from a datastore on the new service. Although the Estimator constructor allows specifying a datastore name, the source directory is still expected to be on the local machine. The user is seeking help to run a training job using a datastore for execution.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Deploying the sagemaker endpoint created as a service",
        "Question_body":"<p>I have trained a credit-fraud data set on AWS Sagemaker and created an endpoint of the model. Suppose I want to provide it as a service to my friend. He has some credit data and wanted to know whether the transaction is fraud or not. He wishes to use my endpoint. How do I share it?<\/p>\n\n<ol>\n<li>Should I share my ARN for endpoint? I don't think its the right way. without a common account he won't be able to use it.<\/li>\n<li>Or is there another way<\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1573479066647,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":226.0,
        "Poster_created_time":1568318861627,
        "Poster_location":"Hyderabad, Telangana, India",
        "Poster_reputation_count":486.0,
        "Poster_view_count":75.0,
        "Answer_body":"<p>To share your model as an endpoint, you should use lambda and API Gateway to create your API.<\/p>\n\n<ol>\n<li>Create an API gateway that triggers a Lambda with the HTTP POST method;<\/li>\n<li>your lambda should instantiate the SageMaker endpoint, get the requested parameter in the event, call the SageMaker endpoint and return the predicted value. you can also create a DynamoDB to store commonly requested parameters with their answers;<\/li>\n<li>Send the API Gateway Endpoint to your friend.<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/qLss4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qLss4.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1573653626700,
        "Answer_last_edit_time":1573654268900,
        "Answer_score_count":6.0,
        "Answerer_created_time":1464391892936,
        "Answerer_location":"Rio de Janeiro, State of Rio de Janeiro, Brazil",
        "Answerer_reputation_count":2243.0,
        "Answerer_view_count":148.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58802366",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi endpoint creat servic train credit fraud data set creat endpoint model suppos want provid servic friend credit data want know transact fraud wish us endpoint share share arn endpoint think right wai common account won abl us wai",
        "Question_preprocessed_content":"deploi endpoint creat servic train data set creat endpoint model want provid servic friend credit data want know transact fraud wish us endpoint share share arn endpoint think right wai won abl us wai",
        "Question_gpt_summary_original":"The user has trained a credit-fraud dataset on AWS Sagemaker and created an endpoint of the model. They want to share it with a friend who has some credit data and wants to know whether the transaction is fraud or not. The user is unsure of the correct way to share the endpoint and is considering sharing their ARN, but believes it may not be the right way. They are seeking advice on alternative methods.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How does sagmaker batch inference processes individual files?",
        "Question_body":"based on the documentation provided here , https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/batch-transform.html, large dataset can be structured as shown below in a csv file. is it possible to have multiple files in this format for batch inference, is there any configuration that can be set , for it to process multiple files. Also, what other formats , beside csv can the batch inference handle? \n\n\n```\nRecord1-Attribute1, Record1-Attribute2, Record1-Attribute3, ..., Record1-AttributeM\nRecord2-Attribute1, Record2-Attribute2, Record2-Attribute3, ..., Record2-AttributeM\n...\n...\nRecordN-Attribute1, RecordN-Attribute2, RecordN-Attribute3, ..., RecordN-AttributeM  \n```",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1648600758921,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668548598475,
        "Question_score_count":0.0,
        "Question_view_count":169.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUKlZAPl2oRtGHPnpQrPcPXA\/how-does-sagmaker-batch-inference-processes-individual-files",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sagmak batch infer process individu file base document provid http doc aw amazon com latest batch transform html larg dataset structur shown csv file possibl multipl file format batch infer configur set process multipl file format csv batch infer handl record attribut record attribut record attribut record attributem record attribut record attribut record attribut record attributem recordn attribut recordn attribut recordn attribut recordn attributem",
        "Question_preprocessed_content":"sagmak batch infer individu file base document provid larg dataset structur shown csv file multipl file format batch infer configur set multipl file format csv batch infer handl",
        "Question_gpt_summary_original":"The user is seeking information on whether SageMaker batch inference can process multiple files in CSV format and if there are any configurations that need to be set for it. They are also curious about other formats that can be handled by batch inference.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How do we create learning virtual machine AI assistants with smart home control and self-driving vehicle funtionality?",
        "Question_body":"<p>I am developing Conscious Quantum Coding Living AI Virtual Assistants to help with everything.   <\/p>\n<p>Jodi, The AI Motor Home  <br \/>\nJodi will be an integrative, quantum coded, learning\/self-improving, online\/cloud, virtual machine, life conscious Living AI assistant who fully controls, and self drives, an RV\/Motor home  <\/p>\n<p>How would you create a Living AI assistant for a motor home?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1591266810177,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/31993\/how-do-we-create-learning-virtual-machine-ai-assis",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat learn virtual machin assist smart home control self drive vehicl funtion develop consciou quantum code live virtual assist help jodi motor home jodi integr quantum code learn self improv onlin cloud virtual machin life consciou live assist fulli control self drive motor home creat live assist motor home",
        "Question_preprocessed_content":"creat learn virtual machin smart home control vehicl funtion develop consciou quantum code live virtual help jodi motor home jodi integr quantum code virtual machin life consciou live control self drive home creat live motor home",
        "Question_gpt_summary_original":"The user is developing a Conscious Quantum Coding Living AI Virtual Assistant named Jodi, which will be a self-driving RV\/Motor home. The user is seeking advice on how to create a Living AI assistant for a motor home.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"DVC on HPC with CML and large(r) number of experiments",
        "Question_body":"<p>Hi, we are currently testing and configuring a new HPC setup and I will be working on setting up a best practice guide and template projects for running ML\/Data science project using DVC, CML and possibly other tools.<\/p>\n<p>Based on the examples I read, I am wondering if the CML workflow also supports large numbers of parameter grid searches?<\/p>\n<p>Thank you!<\/p>",
        "Question_answer_count":9,
        "Question_comment_count":null,
        "Question_created_time":1662118461346,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":273.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-on-hpc-with-cml-and-large-r-number-of-experiments\/1319",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"hpc cml larg number experi current test configur new hpc setup work set best practic guid templat project run data scienc project cml possibl tool base exampl read wonder cml workflow support larg number paramet grid search thank",
        "Question_preprocessed_content":"hpc cml larg number experi test configur new hpc setup work best practic guid templat project scienc project cml base exampl read wonder cml workflow larg number paramet grid search thank",
        "Question_gpt_summary_original":"The user is testing and configuring a new HPC setup and is planning to set up a best practice guide and template projects for running ML\/Data science project using DVC, CML, and other tools. The user is wondering if the CML workflow supports large numbers of parameter grid searches.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"SDK v1 or V2",
        "Question_body":"<p>We are planing for next gen of product. Will V2 provide way more changes than V1? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1661977244390,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=7f2ff54e-2fc4-4d74-b946-fc6ec46d4863\">@nam  <\/a>    <\/p>\n<p>Thanks for using Microsoft Q&amp;A. I will recommend you keeping in V1 at this moment.     <\/p>\n<p>SDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews.    <\/p>\n<p><a href=\"https:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/\">https:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/<\/a>    <\/p>\n<p>I hope this helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.<\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1661981560816,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/989368\/sdk-v1-or-v2",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sdk plane gen product provid wai chang",
        "Question_preprocessed_content":"sdk plane gen product provid wai chang",
        "Question_gpt_summary_original":"The user is planning for the next generation of their product and is wondering if there will be significant changes between SDK v1 and v2.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Issues with importing aiplatform",
        "Question_body":"Hi, I am following this tutorial on model deployment (https:\/\/codelabs.developers.google.com\/vertex-image-deploy#6), but I ran into a issue when importing the aiplatform library.\n\nWhen running \"from google.cloud import aiplatform\", I get the following error message:\n\nImportError                               Traceback (most recent call last)\n\/tmp\/ipykernel_22080\/3236611779.py in <module>\n      4 #!python #3.7.12\n      5 \n----> 6 from google.cloud import aiplatform\n      7 \n      8 import tensorflow as tf\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/cloud\/aiplatform\/__init__.py in <module>\n     22 \n     23 \n---> 24 from google.cloud.aiplatform import initializer\n     25 \n     26 from google.cloud.aiplatform.datasets import (\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/cloud\/aiplatform\/initializer.py in <module>\n     24 \n     25 from google.api_core import client_options\n---> 26 from google.api_core import gapic_v1\n     27 import google.auth\n     28 from google.auth import credentials as auth_credentials\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/gapic_v1\/__init__.py in <module>\n     17 from google.api_core.gapic_v1 import config_async\n     18 from google.api_core.gapic_v1 import method\n---> 19 from google.api_core.gapic_v1 import method_async\n     20 from google.api_core.gapic_v1 import routing_header\n     21 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/gapic_v1\/method_async.py in <module>\n     20 import functools\n     21 \n---> 22 from google.api_core import grpc_helpers_async\n     23 from google.api_core.gapic_v1 import client_info\n     24 from google.api_core.gapic_v1.method import _GapicCallable\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/grpc_helpers_async.py in <module>\n     23 \n     24 import grpc\n---> 25 from grpc import aio\n     26 \n     27 from google.api_core import exceptions, grpc_helpers\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/aio\/__init__.py in <module>\n     21 \n     22 import grpc\n---> 23 from grpc._cython.cygrpc import (init_grpc_aio, shutdown_grpc_aio, EOF,     24                                  AbortError, BaseError, InternalError,\n     25                                  UsageError)\n\nImportError: cannot import name 'shutdown_grpc_aio' from 'grpc._cython.cygrpc' (\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_cython\/cygrpc.cpython-37m-x86_64-linux-gnu.so)\n\nThe versions of the concerned libraries are shown below.\n\ngoogle-api-core                       2.10.1\ngoogle-api-python-client              2.55.0\ngoogle-cloud-aiplatform               1.17.0\n\ngrpcio                                1.33.1\ngrpcio-gcp                            0.2.2\ngrpcio-status                         1.47.0\n\nI have tried grpcio versions 1.26, 1.27.2, and even the latest 1.50, but all of them had import errors (concerning importing of aio module for 1.26 and 127.2 and AbortError module for 1.50). Are there any additional steps or libraries that I need to take to avoid these import errors?\n\nThank you!",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_created_time":1668388200000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":0.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Hi, thank you for your reply. I am running the code on Vertex AI.\n\nI realised I had to restart the kernel to refresh the package after updating grpcio, and I could then import aiplatform without any issues as shown below:\n\nfrom google.cloud import aiplatform\nprint(\"aiplatform version: \", aiplatform.__version__)\n\naiplatform version:  1.17.0\n\nThanks again for your help!\n\nView solution in original post",
        "Answer_comment_count":null,
        "Question_closed_time":"11-14-2022 05:15 PM",
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Issues-with-importing-aiplatform\/m-p\/489087#M771",
        "Tool":"Vertex AI",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"issu import aiplatform follow tutori model deploy http codelab develop googl com vertex imag deploi ran issu import aiplatform librari run googl cloud import aiplatform follow error messag importerror traceback recent tmp ipykernel python googl cloud import aiplatform import tensorflow opt conda lib python site packag googl cloud aiplatform init googl cloud aiplatform import initi googl cloud aiplatform dataset import opt conda lib python site packag googl cloud aiplatform initi googl api core import client option googl api core import gapic import googl auth googl auth import credenti auth credenti opt conda lib python site packag googl api core gapic init googl api core gapic import config async googl api core gapic import method googl api core gapic import method async googl api core gapic import rout header opt conda lib python site packag googl api core gapic method async import functool googl api core import grpc helper async googl api core gapic import client info googl api core gapic method import gapiccal opt conda lib python site packag googl api core grpc helper async import grpc grpc import aio googl api core import except grpc helper opt conda lib python site packag grpc aio init import grpc grpc cython cygrpc import init grpc aio shutdown grpc aio eof aborterror baseerror internalerror usageerror importerror import shutdown grpc aio grpc cython cygrpc opt conda lib python site packag grpc cython cygrpc cpython linux gnu version concern librari shown googl api core googl api python client googl cloud aiplatform grpcio grpcio gcp grpcio statu tri grpcio version latest import error concern import aio modul aborterror modul addit step librari need avoid import error thank",
        "Question_preprocessed_content":"import aiplatform tutori model deploy ran import aiplatform librari cloud import aiplatform traceback python cloud import aiplatform import tensorflow import initi import import version concern librari shown grpcio tri grpcio version latest import step librari avoid import thank",
        "Question_gpt_summary_original":"The user is facing an issue while importing the aiplatform library while following a tutorial on model deployment. The error message shows an ImportError and the concerned libraries' versions are also mentioned. The user has tried different versions of grpcio but still faces import errors. The user is seeking additional steps or libraries to avoid these errors.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Unable To Run AzureML Experiment with SDK - Failed to Build Wheel for pynacl \/ Exit status:1",
        "Question_body":"<p>I am trying to run a AzureML Experiment using sdk (following a Udemy course). When I try to use the Experiment.submit function the experiment prepares and then fails with the following error messages:<\/p>\n<pre><code>ERROR: Command errored out with exit status 1 \n\nERROR: Failed building wheel for pynacl\nERROR: Could not build wheels for pynacl which use PEP 517 and cannot be installed directly\n<\/code><\/pre>\n<p>The Azure env as created within my anaconda navigator for a short period of time and then gets removed.<\/p>\n<p>Does anyone know how I can get around this? Any help would be really appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1649943158360,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1650357451940,
        "Question_score_count":0.0,
        "Question_view_count":73.0,
        "Poster_created_time":1603536549848,
        "Poster_location":null,
        "Poster_reputation_count":51.0,
        "Poster_view_count":7.0,
        "Answer_body":"<p>To resolve <code>ERROR: Could not build wheels for pynacl which use PEP 517 and cannot be installed directly<\/code> this error, try either of the following ways:<\/p>\n<ol>\n<li><p>Install missing dependencies:<\/p>\n<pre><code>sudo apt install libpython3-dev build-essential\n<\/code><\/pre>\n<\/li>\n<li><p>Upgrade pip:<\/p>\n<pre><code>pip3 install --upgrade pip\n<\/code><\/pre>\n<\/li>\n<li><p>Upgrade pip with setuptools wheel:<\/p>\n<pre><code>pip3 install --upgrade pip setuptools wheel\n<\/code><\/pre>\n<\/li>\n<li><p>Reinstall PEP517:<\/p>\n<pre><code>pip3 install p5py\npip3 install PEP517\n<\/code><\/pre>\n<\/li>\n<\/ol>\n<p>You can refer to  <a href=\"https:\/\/stackoverflow.com\/questions\/61365790\/error-could-not-build-wheels-for-scipy-which-use-pep-517-and-cannot-be-installe\">ERROR: Could not build wheels for scipy which use PEP 517 and cannot be installed directly<\/a>, <a href=\"https:\/\/stackoverflow.com\/questions\/64038673\/could-not-build-wheels-for-which-use-pep-517-and-cannot-be-installed-directly\">Could not build wheels for _ which use PEP 517 and cannot be installed directly - Easy Solution<\/a> and <a href=\"https:\/\/github.com\/martomi\/chiadog\/issues\/44\" rel=\"nofollow noreferrer\">failed building wheel for pynacl<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1650257274672,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1517548787092,
        "Answerer_location":null,
        "Answerer_reputation_count":1925.0,
        "Answerer_view_count":3530.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71872506",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl run experi sdk fail build wheel pynacl exit statu try run experi sdk follow udemi cours try us experi submit function experi prepar fail follow error messag error command error exit statu error fail build wheel pynacl error build wheel pynacl us pep instal directli azur env creat anaconda navig short period time get remov know help appreci",
        "Question_preprocessed_content":"unabl run experi sdk fail build pynacl exit statu try run experi sdk try us function experi prepar fail azur env creat anaconda navig short period time get remov know help",
        "Question_gpt_summary_original":"The user is unable to run an AzureML experiment using SDK and is encountering an error message \"Failed building wheel for pynacl\". The Azure environment created within Anaconda Navigator is getting removed after a short period of time. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Welcome to Discussions!",
        "Question_body":"Hey everyone,\n\nWe're opening up Discussions as a place for our community users to interact with each other and Polyaxon' contributors.\n\nWe've historically used Slack as the place to ask questions, and we would like to try a new experiment with discussion as the new default place to ask repeatable questions about how to use a specific feature.\n\nQ&A, Ideation, and feature requests\n\nThis is a great place to:\n\nAsk questions about Polyaxon\nRequest features from our team\nShare ideas and projects you are working on\nBug Reports\n\nIf you've found a bug, it is best to file an issue.\n\nJoin us on Slack\n\nYou are welcome to join our Slack community by signing up here\n\nWe will still be using Slack as a place to provide private help and make announcements about events and releases. We encourage all of our users to still join our community. If you have a question that contains sensitive information that needs to be asked in private, it is best to do it on Slack.\n\nCode of Conduct\n\nIn addition to the Code of Conduct guide line, we have a couple of rules we would like you to follow:\n\nBe nice, always!\nBe respectful; we assume positive intent from you and we ask the same in return\nAvoid posting sensitive information\nDon\u2019t abuse tagging other users\nDon\u2019t advertise material unrelated to Polyaxon\nExplicit is better than implicit: be as precise as you can.\nIt\u2019s OK to disagree but disagree politely and constructively.\nAvoid absolutes: absolute statements do not provide room for a conversation to grow\nNever attack: being defensive about your own ideas, or running offense on another person\u2019s ideas will always result in shutting down collaboration\nStay humble: disagreements are learning opportunities\nBefore creating a new topic, search if someone posted a similar issue before to avoid duplication.\nEach topic should be well-scoped (focused on one thing), non-duplicated and specific to problematic we are solving in one of our repos or with our solution.\nOrganizing FAQs and discussions\nTitle: try to specify the problem rather than the feature or solution you tried.\nIf you have multiple issues, please break them down to multiple discussions.\nUse labels to categorize the new discussion.\nProvide as much information as you can to help us identify the root cause of the issue:\nWhat environment are you using, e.g. Python version when for CLI\/Library issues?\nWhat infrastructure are you using, e.g. an on-premise deployment, a specific cloud provider (AWS, GCP, Azure).\nWhat version are you using?\nDid you check the docs and search bar?\nDid you check the discussions and github search?\nDid you try upgrading before asking?\nIf the issue is related to operations on k8s, can you please use the inpsection button and copy\/paste the YAML results as an attachement (you can replace sensitive info with xxx).\nCan you share logs or code snippets that can make it easier to reproduce your issue?\nAs a discussion creator, you will have a button that allows you to accept an answer. If some user responds to your question with a great answer, mark it as the accepted solution. Doing that helps others quickly navigate to the answer that helped you solve the problem.\nCategories\nAnnouncements: a category for general-purpose category for announcing new releases and blog posts.\nFAQ: a category for frequently asked questions not strictly falling into any other mentioned category.\nQ&A: a category to ask for help.\nGeneral: a category for discussing anything related to Polyaxon.\nShow and tell: a category for links to various resources that can help you get started and learn about Polyaxon as we as a place for sharing blog posts, walkthroughs, or simply sharing how to solve a specific problem.\nIdeas: a category to share ideas for new features.",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1619177543000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1290",
        "Tool":"Polyaxon",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"welcom discuss hei open discuss place commun user interact contributor histor slack place ask question like try new experi discuss new default place ask repeat question us specif featur ideat featur request great place ask question request featur team share idea project work bug report bug best file issu join slack welcom join slack commun sign slack place provid privat help announc event releas encourag user join commun question contain sensit inform need ask privat best slack code conduct addit code conduct guid line coupl rule like follow nice respect assum posit intent ask return avoid post sensit inform dont abus tag user dont advertis materi unrel explicit better implicit precis disagre disagre polit construct avoid absolut absolut statement provid room convers grow attack defens idea run offens person idea result shut collabor stai humbl disagr learn opportun creat new topic search post similar issu avoid duplic topic scope focus thing non duplic specif problemat solv repo solut organ faq discuss titl try specifi problem featur solut tri multipl issu break multipl discuss us label categor new discuss provid inform help identifi root caus issu environ python version cli librari issu infrastructur premis deploy specif cloud provid aw gcp azur version check doc search bar check discuss github search try upgrad ask issu relat oper us inpsect button copi past yaml result attach replac sensit info xxx share log code snippet easier reproduc issu discuss creator button allow accept answer user respond question great answer mark accept solut help quickli navig answer help solv problem categori announc categori gener purpos categori announc new releas blog post faq categori frequent ask question strictli fall mention categori categori ask help gener categori discuss relat tell categori link resourc help start learn place share blog post walkthrough simpli share solv specif problem idea categori share idea new featur",
        "Question_preprocessed_content":"welcom hei open place user interact contributor slack place ask question like try new experi new default place ask repeat question us specif featur ideat featur request great place ask question request featur team share idea project work bug report bug best file join slack welcom join slack sign slack place provid privat help event releas encourag user join question contain sensit inform ask privat best slack code conduct code conduct guid line coupl rule like nice respect posit intent ask return avoid post sensit inform dont abus user dont advertis materi unrel explicit implicit precis polit construct avoid absolut absolut statement provid convers grow defens idea person idea result stai humbl learn creat new topic search post similar avoid duplic topic scope specif problemat solv repo solut organ faq titl try specifi problem featur solut tri multipl break multipl us label categor new provid inform help identifi caus environ python version infrastructur deploy specif cloud provid version check doc search bar check github search try upgrad ask relat oper us inpsect yaml result share log code easier reproduc creator answer user respond question great answer mark solut help quickli navig answer help solv problem categori categori categori new releas blog post faq categori frequent ask question strictli mention categori categori ask help gener categori relat categori link resourc help start learn place share blog post walkthrough simpli share solv specif problem idea categori share idea new featur",
        "Question_gpt_summary_original":"Polyaxon has opened up Discussions as a new platform for community users to interact with each other and the contributors. It is a place to ask repeatable questions about how to use a specific feature, request features, share ideas and projects, and report bugs. Slack will still be used for private help and announcements. The Code of Conduct guidelines must be followed, and users should provide as much information as possible while creating a new topic. Discussions are categorized into Announcements, FAQ, Q&A, General, Show and tell, and Ideas.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Sagemaker Studio UnkownServiceError for Session",
        "Question_body":"<p>When I run the following code in Sagemaker Studio, I get the <code>UnknownServiceError<\/code>:<\/p>\n<pre><code>import boto3\nimport sagemaker\nsagemaker_session = sagemaker.Session()\nrole = get_execution_role()\n<\/code><\/pre>\n<p>Any advice to overcome this would be greatly appreciated.<\/p>\n<p>The error message in the following:<\/p>\n<pre><code>---------------------------------------------------------------------------\nUnknownServiceError                       Traceback (most recent call last)\n&lt;ipython-input-47-2d2ae2d1e577&gt; in &lt;module&gt;\n      1 import boto3\n      2 import sagemaker\n----&gt; 3 sagemaker_session = sagemaker.Session()\n      4 role = get_execution_role()\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in __init__(self, boto_session, sagemaker_client, sagemaker_runtime_client, sagemaker_featurestore_runtime_client, default_bucket)\n    124             sagemaker_client=sagemaker_client,\n    125             sagemaker_runtime_client=sagemaker_runtime_client,\n--&gt; 126             sagemaker_featurestore_runtime_client=sagemaker_featurestore_runtime_client,\n    127         )\n    128 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in _initialize(self, boto_session, sagemaker_client, sagemaker_runtime_client, sagemaker_featurestore_runtime_client)\n    164         else:\n    165             self.sagemaker_featurestore_runtime_client = self.boto_session.client(\n--&gt; 166                 &quot;sagemaker-featurestore-runtime&quot;\n    167             )\n    168 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/boto3\/session.py in client(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\n    261             aws_access_key_id=aws_access_key_id,\n    262             aws_secret_access_key=aws_secret_access_key,\n--&gt; 263             aws_session_token=aws_session_token, config=config)\n    264 \n    265     def resource(self, service_name, region_name=None, api_version=None,\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/session.py in create_client(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\n    833             is_secure=use_ssl, endpoint_url=endpoint_url, verify=verify,\n    834             credentials=credentials, scoped_config=self.get_scoped_config(),\n--&gt; 835             client_config=config, api_version=api_version)\n    836         monitor = self._get_internal_component('monitor')\n    837         if monitor is not None:\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/client.py in create_client(self, service_name, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, api_version, client_config)\n     76             'choose-service-name', service_name=service_name)\n     77         service_name = first_non_none_response(responses, default=service_name)\n---&gt; 78         service_model = self._load_service_model(service_name, api_version)\n     79         cls = self._create_client_class(service_name, service_model)\n     80         endpoint_bridge = ClientEndpointBridge(\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/client.py in _load_service_model(self, service_name, api_version)\n    114     def _load_service_model(self, service_name, api_version=None):\n    115         json_model = self._loader.load_service_model(service_name, 'service-2',\n--&gt; 116                                                      api_version=api_version)\n    117         service_model = ServiceModel(json_model, service_name=service_name)\n    118         return service_model\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/loaders.py in _wrapper(self, *args, **kwargs)\n    130         if key in self._cache:\n    131             return self._cache[key]\n--&gt; 132         data = func(self, *args, **kwargs)\n    133         self._cache[key] = data\n    134         return data\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/botocore\/loaders.py in load_service_model(self, service_name, type_name, api_version)\n    376             raise UnknownServiceError(\n    377                 service_name=service_name,\n--&gt; 378                 known_service_names=', '.join(sorted(known_services)))\n    379         if api_version is None:\n    380             api_version = self.determine_latest_version(\n\nUnknownServiceError: Unknown service: 'sagemaker-featurestore-runtime'. Valid service names are: accessanalyzer, acm, acm-pca, alexaforbusiness, amplify, apigateway, apigatewaymanagementapi, apigatewayv2, appconfig, application-autoscaling, application-insights, appmesh, appstream, appsync, athena, autoscaling, autoscaling-plans, backup, batch, braket, budgets, ce, chime, cloud9, clouddirectory, cloudformation, cloudfront, cloudhsm, cloudhsmv2, cloudsearch, cloudsearchdomain, cloudtrail, cloudwatch, codeartifact, codebuild, codecommit, codedeploy, codeguru-reviewer, codeguruprofiler, codepipeline, codestar, codestar-connections, codestar-notifications, cognito-identity, cognito-idp, cognito-sync, comprehend, comprehendmedical, compute-optimizer, config, connect, connectparticipant, cur, dataexchange, datapipeline, datasync, dax, detective, devicefarm, directconnect, discovery, dlm, dms, docdb, ds, dynamodb, dynamodbstreams, ebs, ec2, ec2-instance-connect, ecr, ecs, efs, eks, elastic-inference, elasticache, elasticbeanstalk, elastictranscoder, elb, elbv2, emr, es, events, firehose, fms, forecast, forecastquery, frauddetector, fsx, gamelift, glacier, globalaccelerator, glue, greengrass, groundstation, guardduty, health, honeycode, iam, imagebuilder, importexport, inspector, iot, iot-data, iot-jobs-data, iot1click-devices, iot1click-projects, iotanalytics, iotevents, iotevents-data, iotsecuretunneling, iotsitewise, iotthingsgraph, ivs, kafka, kendra, kinesis, kinesis-video-archived-media, kinesis-video-media, kinesis-video-signaling, kinesisanalytics, kinesisanalyticsv2, kinesisvideo, kms, lakeformation, lambda, lex-models, lex-runtime, license-manager, lightsail, logs, machinelearning, macie, macie2, managedblockchain, marketplace-catalog, marketplace-entitlement, marketplacecommerceanalytics, mediaconnect, mediaconvert, medialive, mediapackage, mediapackage-vod, mediastore, mediastore-data, mediatailor, meteringmarketplace, mgh, migrationhub-config, mobile, mq, mturk, neptune, networkmanager, opsworks, opsworkscm, organizations, outposts, personalize, personalize-events, personalize-runtime, pi, pinpoint, pinpoint-email, pinpoint-sms-voice, polly, pricing, qldb, qldb-session, quicksight, ram, rds, rds-data, redshift, rekognition, resource-groups, resourcegroupstaggingapi, robomaker, route53, route53domains, route53resolver, s3, s3control, sagemaker, sagemaker-a2i-runtime, sagemaker-runtime, savingsplans, schemas, sdb, secretsmanager, securityhub, serverlessrepo, service-quotas, servicecatalog, servicediscovery, ses, sesv2, shield, signer, sms, sms-voice, snowball, sns, sqs, ssm, sso, sso-oidc, stepfunctions, storagegateway, sts, support, swf, synthetics, textract, transcribe, transfer, translate, waf, waf-regional, wafv2, workdocs, worklink, workmail, workmailmessageflow, workspaces, xray\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1607680355900,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":6.0,
        "Question_view_count":387.0,
        "Poster_created_time":1604297242580,
        "Poster_location":null,
        "Poster_reputation_count":115.0,
        "Poster_view_count":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65249110",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio unkownserviceerror session run follow code studio unknownserviceerror import boto import session session role execut role advic overcom greatli appreci error messag follow unknownserviceerror traceback recent import boto import session session role execut role opt conda lib python site packag session init self boto session client runtim client featurestor runtim client default bucket client client runtim client runtim client featurestor runtim client featurestor runtim client opt conda lib python site packag session initi self boto session client runtim client featurestor runtim client self featurestor runtim client self boto session client featurestor runtim opt conda lib python site packag boto session client self servic region api version us ssl verifi endpoint url aw access kei aw secret access kei aw session token config aw access kei aw access kei aw secret access kei aw secret access kei aw session token aw session token config config def resourc self servic region api version opt conda lib python site packag botocor session creat client self servic region api version us ssl verifi endpoint url aw access kei aw secret access kei aw session token config secur us ssl endpoint url endpoint url verifi verifi credenti credenti scope config self scope config client config config api version api version monitor self intern compon monitor monitor opt conda lib python site packag botocor client creat client self servic region secur endpoint url verifi credenti scope config api version client config choos servic servic servic servic non respons respons default servic servic model self load servic model servic api version cl self creat client class servic servic model endpoint bridg clientendpointbridg opt conda lib python site packag botocor client load servic model self servic api version def load servic model self servic api version json model self loader load servic model servic servic api version api version servic model servicemodel json model servic servic return servic model opt conda lib python site packag botocor loader wrapper self arg kwarg kei self cach return self cach kei data func self arg kwarg self cach kei data return data opt conda lib python site packag botocor loader load servic model self servic type api version rais unknownserviceerror servic servic known servic name join sort known servic api version api version self determin latest version unknownserviceerror unknown servic featurestor runtim valid servic name accessanalyz acm acm pca alexaforbusi amplifi apigatewai apigatewaymanagementapi apigatewayv appconfig applic autosc applic insight appmesh appstream appsync athena autosc autosc plan backup batch braket budget chime cloud clouddirectori cloudform cloudfront cloudhsm cloudhsmv cloudsearch cloudsearchdomain cloudtrail cloudwatch codeartifact codebuild codecommit codedeploi codeguru review codeguruprofil codepipelin codestar codestar connect codestar notif cognito ident cognito idp cognito sync comprehend comprehendmed comput optim config connect connectparticip cur dataexchang datapipelin datasync dax detect devicefarm directconnect discoveri dlm dm docdb dynamodb dynamodbstream eb instanc connect ecr ec ef ek elast infer elasticach elasticbeanstalk elastictranscod elb elbv emr event firehos fm forecast forecastqueri frauddetector fsx gamelift glacier globalacceler glue greengrass groundstat guardduti health honeycod iam imagebuild importexport inspector iot iot data iot job data iotclick devic iotclick project iotanalyt iotev iotev data iotsecuretunnel iotsitewis iotthingsgraph iv kafka kendra kinesi kinesi video archiv media kinesi video media kinesi video signal kinesisanalyt kinesisanalyticsv kinesisvideo km lakeform lambda lex model lex runtim licens manag lightsail log machinelearn maci maci managedblockchain marketplac catalog marketplac entitl marketplacecommerceanalyt mediaconnect mediaconvert medial mediapackag mediapackag vod mediastor mediastor data mediatailor meteringmarketplac mgh migrationhub config mobil mturk networkmanag opswork opsworkscm organ outpost person person event person runtim pinpoint pinpoint email pinpoint sm voic polli price qldb qldb session quicksight ram rd rd data redshift rekognit resourc group resourcegroupstaggingapi robomak rout routedomain routeresolv scontrol runtim runtim savingsplan schema sdb secretsmanag securityhub serverlessrepo servic quota servicecatalog servicediscoveri se sesv shield signer sm sm voic snowbal sn sq ssm sso sso oidc stepfunct storagegatewai st support swf synthet textract transcrib transfer translat waf waf region wafv workdoc worklink workmail workmailmessageflow workspac xrai",
        "Question_preprocessed_content":"studio run code studio advic overcom greatli",
        "Question_gpt_summary_original":"The user is encountering an UnknownServiceError when running code in Sagemaker Studio. The error message indicates that the service 'sagemaker-featurestore-runtime' is unknown, and provides a list of valid service names. The user is seeking advice on how to overcome this error.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"updating\/upgrading of Azure ML VM Operating System?",
        "Question_body":"<p>Currently in my Azure ML portal the OS version is    <\/p>\n<p>NAME=&quot;Ubuntu&quot;    <br \/>\nVERSION=&quot;20.04.4 LTS (Focal Fossa)&quot;    <\/p>\n<p>I need to update os version to Ubuntu 22.04 LTS    <\/p>\n<p>In azure, user can updating os version manually? or it is by default upgrading from Microsoft Azure?    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662553688820,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/997469\/updating-upgrading-of-azure-ml-vm-operating-system",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"updat upgrad oper current portal version ubuntu version lt focal fossa need updat version ubuntu lt azur user updat version manual default upgrad microsoft azur",
        "Question_preprocessed_content":"oper portal version ubuntu lt updat version ubuntu lt azur user updat version default upgrad microsoft azur",
        "Question_gpt_summary_original":"The user wants to update the operating system of their Azure ML VM from Ubuntu 20.04.4 LTS to Ubuntu 22.04 LTS. They are unsure if the update can be done manually or if it is automatically upgraded by Microsoft Azure.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"DVC Push KeyError fileSize",
        "Question_body":"<p>I've added a large list of CSV files to my dvc repository but when I try to do DVC push it complains with<\/p>\n<pre><code>ERROR: unexpected error - KeyError('fileSize')\n<\/code><\/pre>\n<p><strong>Edit<\/strong>\nSo searching around it seem that it might help to include the verbose log with regards to the error.<\/p>\n<pre><code>T11:27:08~\/documents\/*****\/data$ dvc push -v\n2022-02-01 11:32:13,186 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/config.local' to gitignore file.\n2022-02-01 11:32:13,199 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/tmp' to gitignore file.\n2022-02-01 11:32:13,200 DEBUG: Adding '\/home\/jhylands\/Documents\/*****\/.dvc\/cache' to gitignore file.\n2022-02-01 11:32:14,102 DEBUG: Preparing to transfer data from '\/home\/jhylands\/Documents\/*****\/.dvc\/cache' to '*********'\n2022-02-01 11:32:14,102 DEBUG: Preparing to collect status from '********'\n2022-02-01 11:32:14,103 DEBUG: Collecting status from '*******'\n2022-02-01 11:32:14,439 DEBUG: GDrive remote auth with config '{'client_config_backend': 'settings', 'client_config_file': 'client_secrets.json', 'save_credentials': True, 'oauth_scope': ['https:\/\/www.googleapis.com\/auth\/drive', 'https:\/\/www.googleapis.com\/auth\/drive.appdata'], 'save_credentials_backend': 'file', 'save_credentials_file': '\/home\/jhylands\/Documents\/*****\/.dvc\/tmp\/gdrive-user-credentials.json', 'get_refresh_token': True, 'client_config': {'client_id': '*****.apps.googleusercontent.com', 'client_secret': '****************', 'auth_uri': 'https:\/\/accounts.google.com\/o\/oauth2\/auth', 'token_uri': 'https:\/\/oauth2.googleapis.com\/token', 'revoke_uri': 'https:\/\/oauth2.googleapis.com\/revoke', 'redirect_uri': ''}}'.\n2022-02-01 11:32:14,994 DEBUG: Estimated remote size: 256 files\n2022-02-01 11:32:14,995 DEBUG: Querying '316' hashes via traverse\n2022-02-01 11:32:15,325 ERROR: unexpected error - KeyError('fileSize')\n------------------------------------------------------------\nTraceback (most recent call last):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/files.py&quot;, line 226, in __getitem__\n    return dict.__getitem__(self, key)\nKeyError: 'fileSize'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/main.py&quot;, line 55, in main\n    ret = cmd.do_run()\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/command\/base.py&quot;, line 45, in do_run\n    return self.run()\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/command\/data_sync.py&quot;, line 57, in run\n    processed_files_count = self.repo.push(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/repo\/__init__.py&quot;, line 49, in wrapper\n    return f(repo, *args, **kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/repo\/push.py&quot;, line 56, in push\n    pushed += self.cloud.push(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/data_cloud.py&quot;, line 85, in push\n    return transfer(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/transfer.py&quot;, line 153, in transfer\n    status = compare_status(src, dest, obj_ids, check_deleted=False, **kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/status.py&quot;, line 158, in compare_status\n    dest_exists, dest_missing = status(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/status.py&quot;, line 131, in status\n    exists.update(odb.hashes_exist(hashes, name=odb.fs_path, **kwargs))\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 499, in hashes_exist\n    remote_hashes = set(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 334, in _list_hashes_traverse\n    yield from itertools.chain.from_iterable(in_remote)\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 611, in result_iterator\n    yield fs.pop().result()\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 439, in result\n    return self.__get_result()\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/_base.py&quot;, line 388, in __get_result\n    raise self._exception\n  File &quot;\/usr\/lib\/python3.8\/concurrent\/futures\/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 324, in list_with_update\n    return list(\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 215, in _list_hashes\n    for path in self._list_paths(prefix, progress_callback):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/objects\/db\/base.py&quot;, line 195, in _list_paths\n    for file_info in self.fs.find(fs_path, prefix=prefix):\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/dvc\/fs\/fsspec_wrapper.py&quot;, line 107, in find\n    yield from self.fs.find(path)\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/fs\/spec.py&quot;, line 323, in find\n    &quot;size&quot;: int(item[&quot;fileSize&quot;]),\n  File &quot;\/home\/jhylands\/.local\/lib\/python3.8\/site-packages\/pydrive2\/files.py&quot;, line 229, in __getitem__\n    raise KeyError(e)\nKeyError: KeyError('fileSize')\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":5.0,
        "Question_created_time":1643714210580,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1643715642688,
        "Question_score_count":1.0,
        "Question_view_count":54.0,
        "Poster_created_time":1333908536528,
        "Poster_location":"London, United Kingdom",
        "Poster_reputation_count":884.0,
        "Poster_view_count":59.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70939675",
        "Tool":"DVC",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"push keyerror files ad larg list csv file repositori try push complain error unexpect error keyerror files edit search help includ verbos log regard error document data push debug ad home jhyland document config local gitignor file debug ad home jhyland document tmp gitignor file debug ad home jhyland document cach gitignor file debug prepar transfer data home jhyland document cach debug prepar collect statu debug collect statu debug gdrive remot auth config client config backend set client config file client secret json save credenti true oauth scope http www googleapi com auth drive http www googleapi com auth drive appdata save credenti backend file save credenti file home jhyland document tmp gdrive user credenti json refresh token true client config client app googleusercont com client secret auth uri http account googl com oauth auth token uri http oauth googleapi com token revok uri http oauth googleapi com revok redirect uri debug estim remot size file debug queri hash travers error unexpect error keyerror files traceback recent file home jhyland local lib python site packag pydriv file line getitem return dict getitem self kei keyerror files handl except except occur traceback recent file home jhyland local lib python site packag main line main ret cmd run file home jhyland local lib python site packag command base line run return self run file home jhyland local lib python site packag command data sync line run process file count self repo push file home jhyland local lib python site packag repo init line wrapper return repo arg kwarg file home jhyland local lib python site packag repo push line push push self cloud push file home jhyland local lib python site packag data cloud line push return transfer file home jhyland local lib python site packag object transfer line transfer statu compar statu src dest obj id check delet fals kwarg file home jhyland local lib python site packag object statu line compar statu dest exist dest miss statu file home jhyland local lib python site packag object statu line statu exist updat odb hash exist hash odb path kwarg file home jhyland local lib python site packag object base line hash exist remot hash set file home jhyland local lib python site packag object base line list hash travers yield itertool chain iter remot file usr lib python concurr futur base line result iter yield pop result file usr lib python concurr futur base line result return self result file usr lib python concurr futur base line result rais self except file usr lib python concurr futur thread line run result self self arg self kwarg file home jhyland local lib python site packag object base line list updat return list file home jhyland local lib python site packag object base line list hash path self list path prefix progress callback file home jhyland local lib python site packag object base line list path file info self path prefix prefix file home jhyland local lib python site packag fsspec wrapper line yield self path file home jhyland local lib python site packag pydriv spec line size int item files file home jhyland local lib python site packag pydriv file line getitem rais keyerror keyerror keyerror files",
        "Question_preprocessed_content":"push files larg list csv file repositori try push complain edit search help includ verbos log regard",
        "Question_gpt_summary_original":"The user is encountering an error while trying to push a large list of CSV files to their DVC repository. The error message states \"KeyError('fileSize')\" and the user has tried including verbose logs to troubleshoot the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to insert JSON along with PDF into Document AI Warehouse using API",
        "Question_body":"Hi,\u00a0\n\nOur usecase is to process the PDF documents from Document AI process and pass the JSON file along with the PDF to the document warehouse. I am using\u00a0contentwarehouse.CreateDocumentRequest function, the function works well if I only supply the PDF document, but if I process the file from the document and push the JSON along with the PDF the it gives an error saying the following:\n\n\nFile \"<ipython-input-63-d034c5106990>\", line 1, in <module>\nrunfile('C:\/Users\/HP\/Downloads\/test simple.py', wdir='C:\/Users\/HP\/Downloads')\n\nFile \"D:\\Anaconda3\\lib\\site-packages\\spyder_kernels\\customize\\spydercustomize.py\", line 827, in runfile\nexecfile(filename, namespace)\n\nFile \"D:\\Anaconda3\\lib\\site-packages\\spyder_kernels\\customize\\spydercustomize.py\", line 110, in execfile\nexec(compile(f.read(), filename, 'exec'), namespace)\n\nFile \"C:\/Users\/HP\/Downloads\/test simple.py\", line 110, in <module>\nprocess_document_sample(config['project_id'],config['location'],config['Custom_processor_id'],file_path,mime_type)\n\nFile \"C:\/Users\/HP\/Downloads\/test simple.py\", line 88, in process_document_sample\ndoc=documentai.types.Document(docDictionary)\n\nFile \"D:\\Anaconda3\\lib\\site-packages\\proto\\message.py\", line 566, in __init__\n\"Unknown field for {}: {}\".format(self.__class__.__name__, key)\n\nValueError: Unknown field for Document: _pb\n\n\u00a0\n\n\nFollowing is the code Snippet:\n\ndef process_document_sample(\nproject_id: str,\nlocation: str,\nprocessor_id: str,\nfile_path: str,\nmime_type: str,\nfield_mask: str = None,\n\n# You must set the api_endpoint if you use a location other than 'us'.\nopts = storage.Client(project_id)\n\nclient = documentai.DocumentProcessorServiceClient()\n\n# The full resource name of the processor, e.g.:\n# projects\/{project_id}\/locations\/{location}\/processors\/{processor_id}\nname = client.processor_path(project_id, location, processor_id)\n\n# Read the file into memory\nwith open(file_path, \"rb\") as image:\nimage_content = image.read()\n\n# Load Binary Data into Document AI RawDocument Object\nraw_document = documentai.RawDocument(content=image_content, mime_type=mime_type)\n\n# Configure the process request\nrequest = documentai.ProcessRequest(\nname=name, raw_document=raw_document, field_mask=field_mask\n)\n\nresult = client.process_document(request=request)\n\n# return result\n# TODO(developer): Uncomment these variables before running the sample.\n# project_number = 'YOUR_PROJECT_NUMBER'\n# location = 'YOUR_PROJECT_LOCATION' # Format is 'us' or 'eu'\n#print(result.document.entities)\n\n# Create a Schema Service client\nimport json\nwith open('test.json','w') as f:\njson.dump(documentai.Document.to_dict(result.document),f)\n# documentai.Document.to_dict(result)\ndocument_schema_client = contentwarehouse.DocumentSchemaServiceClient()\n\n# The full resource name of the location, e.g.:\n# projects\/{project_number}\/locations\/{location}\nparent = document_schema_client.common_location_path(\nproject=config['project_number'], location=config['location']\n)\n\n\u00a0\n\n# Create a Document Service client\ndocument_client = contentwarehouse.DocumentServiceClient()\n\n# The full resource name of the location, e.g.:\n# projects\/{project_number}\/locations\/{location}\nparent = document_client.common_location_path(\nproject=config['project_number'], location=config['location']\n)\n#print(result.document._pb)\ndocDictionary = result.document.__dict__\ndoc=documentai.types.Document(docDictionary)\n# Define Document\ndocument = contentwarehouse.Document(\n# raw_document_file_type=1,\ndisplay_name=\"60.pdf\",\ndocument_schema_name=schema_URI,\ninline_raw_document=open('60.pdf','rb').read(),\n#plain_text=str(result.document)\ncloud_ai_document=doc\n)\n\n# Define Request\ncreate_document_request = contentwarehouse.CreateDocumentRequest(\nparent=parent, document=document\n)\n\n# Create a Document for the given schema\nresponse = document_client.create_document(request=create_document_request)\n# print(response)\n\n\nprocess_document_sample(config['project_id'],config['location'],config['Custom_processor_id'],file_path,mime_type)\n\n\nI have read all the documentation, but couldn't find why the dictionary is not being picked by the object.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1681889340000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":193.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-insert-JSON-along-with-PDF-into-Document-AI-Warehouse\/m-p\/545296#M1699",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"insert json pdf document warehous api usecas process pdf document document process pass json file pdf document warehous usingcontentwarehous createdocumentrequest function function work suppli pdf document process file document push json pdf give error sai follow file line runfil user download test simpl wdir user download file anaconda lib site packag spyder kernel custom spydercustom line runfil execfil filenam namespac file anaconda lib site packag spyder kernel custom spydercustom line execfil exec compil read filenam exec namespac file user download test simpl line process document sampl config project config locat config custom processor file path mime type file user download test simpl line process document sampl doc documentai type document docdictionari file anaconda lib site packag proto messag line init unknown field format self class kei valueerror unknown field document follow code snippet def process document sampl project str locat str processor str file path str mime type str field mask str set api endpoint us locat opt storag client project client documentai documentprocessorservicecli resourc processor project project locat locat processor processor client processor path project locat processor read file memori open file path imag imag content imag read load binari data document rawdocu object raw document documentai rawdocu content imag content mime type mime type configur process request request documentai processrequest raw document raw document field mask field mask result client process document request request return result todo develop uncom variabl run sampl project number project number locat project locat format print result document entiti creat schema servic client import json open test json json dump documentai document dict result document documentai document dict result document schema client contentwarehous documentschemaservicecli resourc locat project project number locat locat parent document schema client common locat path project config project number locat config locat creat document servic client document client contentwarehous documentservicecli resourc locat project project number locat locat parent document client common locat path project config project number locat config locat print result document docdictionari result document dict doc documentai type document docdictionari defin document document contentwarehous document raw document file type displai pdf document schema schema uri inlin raw document open pdf read plain text str result document cloud document doc defin request creat document request contentwarehous createdocumentrequest parent parent document document creat document given schema respons document client creat document request creat document request print respons process document sampl config project config locat config custom processor file path mime type read document couldn dictionari pick object",
        "Question_preprocessed_content":"insert json pdf document warehous api usecas pdf document document json file pdf document warehous function function work pdf document file document push json pdf give sai file line file line runfil execfil file line execfil filenam exec namespac file line file line file line unknown field kei unknown field document code def str locat str str str str str set us locat opt client resourc locat read file memori imag load binari data document rawdocu object configur request request result return result todo variabl sampl locat format creat schema servic client import json resourc locat parent locat config creat document servic client resourc locat parent locat config docdictionari defin document document defin request parent parent document document creat document given schema respons print read document couldn dictionari pick object",
        "Question_gpt_summary_original":"The user is trying to pass a JSON file along with a PDF to the Document AI warehouse using the contentwarehouse.CreateDocumentRequest function. The function works well if only the PDF document is supplied, but when the user tries to push the JSON along with the PDF, an error occurs. The error message indicates that there is an unknown field for Document: _pb. The user has tried to resolve the issue by reading the documentation but has been unsuccessful.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ml for data series in 3 states (stages)",
        "Question_body":"<p>Hello! I am new to using azure ml and I am trying to recreate in azure ml a process that is composed of 3 different states. State 1 influences state 2, state 1 and 2 influence state 3. Indeed I need azure ml to predict what will happen in stage 2, after analyzing stage 1 data, then what will happen in stage 3 after analyzing stage 1 data and 2. I can't find any way to put the data in azure ml in this configuration.If anyone has a suggestion ... it would help me. Thanks in advance for any help.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1610145100317,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/224370\/azure-ml-for-data-series-in-3-states-(stages)",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"data seri state stage hello new try recreat process compos differ state state influenc state state influenc state need predict happen stage analyz stage data happen stage analyz stage data wai data configur suggest help thank advanc help",
        "Question_preprocessed_content":"data seri state new try recreat compos state state influenc state state influenc state predict stage analyz stage data stage analyz stage data wai data help thank advanc help",
        "Question_gpt_summary_original":"The user is new to using Azure ML and is trying to recreate a process that involves three different states. They need Azure ML to predict what will happen in stage 2 and stage 3 after analyzing data from stage 1 and stage 1 and 2 respectively. However, they are unable to find a way to put the data in Azure ML in this configuration and are seeking suggestions for a solution.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to set multiple environment variables in AWS Sagemaker notebook instance?",
        "Question_body":"<p>I am using the AWS Sagemaker notebook instances for some of my experiments. As I am also using the lifecycle configurations scripts that are executed during notebook startup and also want to set some environment variables.<\/p>\n\n<p>For some reason, when I set multiple env variables in the lifecycle shell script, they are not set by the instance, i.e. when I execute\n<code>echo $FOO<\/code> \nthe relevant variable is not printed. <\/p>\n\n<p>However, when I set only one env variable it is working and I can use it in my notebook session. <\/p>\n\n<p>My understanding is that I start the desired Kernel, <\/p>\n\n<p>I have also tried to set the env variables inside the notebook by running <code>export FOO=BAR<\/code> but that also did not work. \nFollowing the example script provided by AWS, I made my changes to set the variables, however when I print $FOO, it doesn't seem to be displayed.<\/p>\n\n<p>I have tried setting the envs before and after switching to ec2-user (before the commands are executed as root), still nothing helped.<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>#!\/bin\/bash\n\n\ncd \/home\/ec2-user\/anaconda3\/envs\/python3\nmkdir -p .\/etc\/conda\/activate.d\nmkdir -p .\/etc\/conda\/deactivate.d\ntouch .\/etc\/conda\/activate.d\/env_vars.sh\ntouch .\/etc\/conda\/deactivate.d\/env_vars.sh\n\necho export FOO=BAR &gt;&gt; .\/etc\/conda\/activate.d\/env_vars.sh\necho unset FOO &gt;&gt; .\/etc\/conda\/deactivate.d\/env_vars.sh\n\necho export FOO2=BAR2 &gt;&gt; .\/etc\/conda\/activate.d\/env_vars.sh\necho unset FOO2 &gt;&gt; .\/etc\/conda\/deactivate.d\/env_vars.sh\n\nsudo -u ec2-user -i &lt;&lt;'EOF'\n\ncd \/home\/ec2-user\n\n# This will affect only the Jupyter kernel called \"conda_python3\".\nsource activate python3\n\npip install --upgrade pip\n\npip install scipy xgboost sklearn\n\n# You can also perform \"conda install\" here as well.\n\n\nsource deactivate\n\nEOF\n\n\n<\/code><\/pre>\n\n<p>I want to set multiple environment variables for this Sagemaker notebook upon start, what is the best way to do this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_created_time":1565020147883,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1574242772027,
        "Question_score_count":4.0,
        "Question_view_count":5171.0,
        "Poster_created_time":1432024993980,
        "Poster_location":"Berlin, Germany",
        "Poster_reputation_count":411.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57362038",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"set multipl environ variabl notebook instanc notebook instanc experi lifecycl configur script execut notebook startup want set environ variabl reason set multipl env variabl lifecycl shell script set instanc execut echo foo relev variabl print set env variabl work us notebook session understand start desir kernel tri set env variabl insid notebook run export foo bar work follow exampl script provid aw chang set variabl print foo displai tri set env switch user command execut root help bin bash home user anaconda env python mkdir conda activ mkdir conda deactiv touch conda activ env var touch conda deactiv env var echo export foo bar conda activ env var echo unset foo conda deactiv env var echo export foo bar conda activ env var echo unset foo conda deactiv env var sudo user eof home user affect jupyt kernel call conda python sourc activ python pip instal upgrad pip pip instal scipi xgboost sklearn perform conda instal sourc deactiv eof want set multipl environ variabl notebook start best wai",
        "Question_preprocessed_content":"set multipl environ variabl instanc instanc experi lifecycl configur script execut startup want set environ variabl reason set multipl env variabl lifecycl script set instanc execut relev variabl print set env variabl work us understand start desir kernel tri set env variabl insid work exampl script provid aw chang set variabl print displai tri env switch help want set multipl environ variabl start best wai",
        "Question_gpt_summary_original":"The user is facing issues while setting multiple environment variables in AWS Sagemaker notebook instance. They have tried setting the variables in the lifecycle shell script and also inside the notebook, but none of them seem to work. However, setting a single environment variable is working fine. The user has also shared a script that they have tried to modify to set the variables, but it did not work. The user is seeking advice on the best way to set multiple environment variables for the Sagemaker notebook upon start.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"MLflow 1.26.1 released!",
        "Question_body":"We are happy to announce the availability of\u00a0MLflow 1.26.1!\n\n\n\nMLflow 1.26.1 is a patch release containing the following bug fixes:\n\n[Installation] Fix compatibility issue with\u00a0protobuf >= 4.21.0\u00a0(#5945,\u00a0@harupy)\n[Models] Fix\u00a0get_model_dependencies\u00a0behavior for\u00a0models:\u00a0URIs containing artifact paths (#5921,\u00a0@harupy)\n[Models] Revert a problematic change to\u00a0artifacts\u00a0persistence in\u00a0mlflow.pyfunc.log_model()\u00a0that was introduced in MLflow 1.25.0 (#5891,\u00a0@kyle-jarvis)\n[Models] Close associated image files when\u00a0EvaluationArtifact\u00a0outputs from\u00a0mlflow.evaluate()\u00a0are garbage collected (#5900,\u00a0@WeichenXu123)\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.\n\n\n\nNote: Version 1.26.1 of the MLflow R package has not yet been released. It will be available on CRAN within the next week.",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1653686824000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":12.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/OkDlyI-k6Ss",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"releas happi announc avail patch releas contain follow bug fix instal fix compat issu withprotobuf harupi model fixget model dependenciesbehavior formodel uri contain artifact path harupi model revert problemat chang toartifactspersist pyfunc log model introduc kyle jarvi model close associ imag file whenevaluationartifactoutput evalu garbag collect weichenxu comprehens list chang thereleas chang log check latest document org note version packag releas avail cran week",
        "Question_preprocessed_content":"releas avail patch releas contain bug fix fix compat withprotobuf model formodel uri contain artifact path model revert problemat chang toartifactspersist introduc model close imag file whenevaluationartifactoutput garbag comprehens list chang thereleas chang log check latest document note version packag releas avail cran",
        "Question_gpt_summary_original":"MLflow 1.26.1 has been released, which includes bug fixes related to installation, model dependencies, and artifacts persistence. The R package version is not yet available but will be released soon.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Sagemaker: MemoryError: Unable to allocate ___for an array with shape ___ and data type float64",
        "Question_body":"<p>I am running a notebook in sagemaker and it seems like one of the arrays produced after vectorizing text is causing issues.<\/p>\n\n<p>Reading other answers it seems like it is an issue with <a href=\"https:\/\/www.kernel.org\/doc\/Documentation\/vm\/overcommit-accounting\" rel=\"noreferrer\">overcommit<\/a>. And one of the solutions proposed is to set it to always overcommit with this:<\/p>\n\n<pre><code>$ echo 1 &gt; \/proc\/sys\/vm\/overcommit_memory\n<\/code><\/pre>\n\n<p>Is there any documentation or do you have any suggestion on how to do the same thing in sagemaker?<\/p>\n\n<p>Thank you very much.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1589441004223,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":8.0,
        "Question_view_count":2821.0,
        "Poster_created_time":1517932507092,
        "Poster_location":null,
        "Poster_reputation_count":331.0,
        "Poster_view_count":73.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61791589",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"memoryerror unabl alloc arrai shape data type float run notebook like arrai produc vector text caus issu read answer like issu overcommit solut propos set overcommit echo proc sy overcommit memori document suggest thing thank",
        "Question_preprocessed_content":"unabl shape data type float like produc vector text caus read answer like solut propos set document thing thank",
        "Question_gpt_summary_original":"The user is encountering a MemoryError while running a notebook in Sagemaker, which seems to be caused by an array produced after vectorizing text. The issue is related to overcommit and the user is seeking documentation or suggestions on how to set it to always overcommit in Sagemaker.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to install python ta-lib library in Azure Machine Learning Juypyter Notebooks",
        "Question_body":"<p>SO I need to use this python library explained here:<\/p>\n<p><a href=\"https:\/\/medium.com\/analytics-vidhya\/recognizing-over-50-candlestick-patterns-with-python-4f02a1822cb5\" rel=\"nofollow noreferrer\">https:\/\/medium.com\/analytics-vidhya\/recognizing-over-50-candlestick-patterns-with-python-4f02a1822cb5<\/a><\/p>\n<p>However when I try to execute:<\/p>\n<p>!pip install talib\nimport talib<\/p>\n<p>I get lots of errors:<\/p>\n<pre><code>Collecting talib\n  Using cached talib-0.1.1.tar.gz (1.3 kB)\nBuilding wheels for collected packages: talib\n  Building wheel for talib (setup.py) ... error\n  ERROR: Command errored out with exit status 1:\n   command: \/anaconda\/envs\/azureml_py36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' bdist_wheel -d \/tmp\/pip-wheel-1dvr6fd9\n       cwd: \/tmp\/pip-install-lof3_wuc\/talib\/\n  Complete output (29 lines):\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build\/lib\n  creating build\/lib\/talib\n  copying talib\/__init__.py -&gt; build\/lib\/talib\n  copying talib\/cli.py -&gt; build\/lib\/talib\n  installing to build\/bdist.linux-x86_64\/wheel\n  running install\n  Traceback (most recent call last):\n    File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\n    File &quot;\/tmp\/pip-install-lof3_wuc\/talib\/setup.py&quot;, line 47, in &lt;module&gt;\n      'talib = talib.cli:cli',\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/core.py&quot;, line 148, in setup\n      dist.run_commands()\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 955, in run_commands\n      self.run_command(cmd)\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 974, in run_command\n      cmd_obj.run()\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/wheel\/bdist_wheel.py&quot;, line 326, in run\n      self.run_command('install')\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/cmd.py&quot;, line 313, in run_command\n      self.distribution.run_command(command)\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 974, in run_command\n      cmd_obj.run()\n    File &quot;\/tmp\/pip-install-lof3_wuc\/talib\/setup.py&quot;, line 20, in run\n      raise Exception(&quot;You probably meant to install and run ta-lib&quot;)\n  Exception: You probably meant to install and run ta-lib\n  ----------------------------------------\n  ERROR: Failed building wheel for talib\n  Running setup.py clean for talib\nFailed to build talib\nInstalling collected packages: talib\n    Running setup.py install for talib ... error\n    ERROR: Command errored out with exit status 1:\n     command: \/anaconda\/envs\/azureml_py36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' install --record \/tmp\/pip-record-7fqjayvz\/install-record.txt --single-version-externally-managed --compile --install-headers \/anaconda\/envs\/azureml_py36\/include\/python3.6m\/talib\n         cwd: \/tmp\/pip-install-lof3_wuc\/talib\/\n    Complete output (14 lines):\n    running install\n    Traceback (most recent call last):\n      File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\n      File &quot;\/tmp\/pip-install-lof3_wuc\/talib\/setup.py&quot;, line 47, in &lt;module&gt;\n        'talib = talib.cli:cli',\n      File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/core.py&quot;, line 148, in setup\n        dist.run_commands()\n      File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 955, in run_commands\n        self.run_command(cmd)\n      File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/distutils\/dist.py&quot;, line 974, in run_command\n        cmd_obj.run()\n      File &quot;\/tmp\/pip-install-lof3_wuc\/talib\/setup.py&quot;, line 20, in run\n        raise Exception(&quot;You probably meant to install and run ta-lib&quot;)\n    Exception: You probably meant to install and run ta-lib\n    ----------------------------------------\nERROR: Command errored out with exit status 1: \/anaconda\/envs\/azureml_py36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'\/tmp\/pip-install-lof3_wuc\/talib\/setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\r\\n'&quot;'&quot;', '&quot;'&quot;'\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' install --record \/tmp\/pip-record-7fqjayvz\/install-record.txt --single-version-externally-managed --compile --install-headers \/anaconda\/envs\/azureml_py36\/include\/python3.6m\/talib Check the logs for full command output.\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-56-ef2dd36041a5&gt; in &lt;module&gt;\n      1 get_ipython().system('pip install talib')\n----&gt; 2 import talib\n\nModuleNotFoundError: No module named 'talib'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1604608935850,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":770.0,
        "Poster_created_time":1302030303092,
        "Poster_location":"Brussels, B\u00e9lgica",
        "Poster_reputation_count":30340.0,
        "Poster_view_count":2937.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64704974",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"instal python lib librari juypyt notebook need us python librari explain http medium com analyt vidhya recogn candlestick pattern python facb try execut pip instal talib import talib lot error collect talib cach talib tar build wheel collect packag talib build wheel talib setup error error command error exit statu command anaconda env bin python import sy setuptool token sy argv tmp pip instal lof wuc talib setup file tmp pip instal lof wuc talib setup getattr token open open file code read replac close exec compil code file exec bdist wheel tmp pip wheel dvrfd cwd tmp pip instal lof wuc talib complet output line run bdist wheel run build run build creat build creat build lib creat build lib talib copi talib init build lib talib copi talib cli build lib talib instal build bdist linux wheel run instal traceback recent file line file tmp pip instal lof wuc talib setup line talib talib cli cli file anaconda env lib python distutil core line setup dist run command file anaconda env lib python distutil dist line run command self run command cmd file anaconda env lib python distutil dist line run command cmd obj run file anaconda env lib python site packag wheel bdist wheel line run self run command instal file anaconda env lib python distutil cmd line run command self distribut run command command file anaconda env lib python distutil dist line run command cmd obj run file tmp pip instal lof wuc talib setup line run rais except probabl meant instal run lib except probabl meant instal run lib error fail build wheel talib run setup clean talib fail build talib instal collect packag talib run setup instal talib error error command error exit statu command anaconda env bin python import sy setuptool token sy argv tmp pip instal lof wuc talib setup file tmp pip instal lof wuc talib setup getattr token open open file code read replac close exec compil code file exec instal record tmp pip record fqjayvz instal record txt singl version extern manag compil instal header anaconda env includ python talib cwd tmp pip instal lof wuc talib complet output line run instal traceback recent file line file tmp pip instal lof wuc talib setup line talib talib cli cli file anaconda env lib python distutil core line setup dist run command file anaconda env lib python distutil dist line run command self run command cmd file anaconda env lib python distutil dist line run command cmd obj run file tmp pip instal lof wuc talib setup line run rais except probabl meant instal run lib except probabl meant instal run lib error command error exit statu anaconda env bin python import sy setuptool token sy argv tmp pip instal lof wuc talib setup file tmp pip instal lof wuc talib setup getattr token open open file code read replac close exec compil code file exec instal record tmp pip record fqjayvz instal record txt singl version extern manag compil instal header anaconda env includ python talib check log command output modulenotfounderror traceback recent ipython pip instal talib import talib modulenotfounderror modul name talib",
        "Question_preprocessed_content":"python librari juypyt us python librari explain try execut pip talib import talib lot",
        "Question_gpt_summary_original":"The user is trying to install the ta-lib library in Azure Machine Learning Jupyter Notebooks to use it for recognizing over 50 candlestick patterns with Python. However, when the user tries to execute the installation command, they encounter multiple errors and are unable to install the library.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Vertex AI model showing failure but 0 bytes in prediction.errors",
        "Question_body":"<p>I'm running a vertex batch job on a custom model with 676 instances in my jsonl.<\/p>\n<p>I get results for all 676 instances but the job shows &quot;Due to one or more errors, this batch prediction job was canceled on Aug 22, 2022 at 09:04PM&quot;<\/p>\n<p>The error file prediction.errors_stats-00000-of-00001 has 0 bytes and there is a directory:<\/p>\n<pre><code>beam-temp-prediction.errors_stats-e289aa8c228c11eda06642010a800fdc \n<\/code><\/pre>\n<p>with 4 files with 0 bytes\u00a0in them.<\/p>\n<pre><code>34e19e3d-e717-4c6f-860c-5c2a177f1e93.prediction.errors_stats\n7c9374c8-65f7-4a97-8a95-6068ba9cd936.prediction.errors_stats\n981a634b-d27c-4285-b871-648b25ca87b8.prediction.errors_stats\nf14dbc29-42d7-480e-8b79-95e799e132bf.prediction.errors_stats\n<\/code><\/pre>\n<p>Any ideas on why the job is showing failure but the results seem ok?<\/p>\n<p>Job params:<\/p>\n<pre><code>{&quot;displayName&quot;: &lt;MY_DISPLAY_NAME&gt;,\n &quot;model&quot;: &lt;MY_MODEL&gt;,\n &quot;inputConfig&quot;: {&quot;instancesFormat&quot;: &quot;jsonl&quot;,\n                 &quot;gcsSource&quot;: {&quot;uris&quot;: [&quot;gs:\/\/&lt;MY_BUCKET&gt;\/MY_INSTANCES.jsonl&quot;]}},\n &quot;outputConfig&quot;: {&quot;predictionsFormat&quot;: &quot;jsonl&quot;,\n                  &quot;gcsDestination&quot;: {&quot;outputUriPrefix&quot;: &quot;gs:\/\/&lt;MY_OUTPUTS&gt;\/outputs\/2022-08-23&quot;}},\n&quot;dedicatedResources&quot;: {&quot;machineSpec&quot;: {&quot;machineType&quot;: &quot;n1-standard-8&quot;, \n&quot;acceleratorType&quot;: null, &quot;acceleratorCount&quot;: null},\n&quot;startingReplicaCount&quot;: 2},\n&quot;manualBatchTuningParameters&quot;: {&quot;batch_size&quot;: 1}}\n<\/code><\/pre>\n<p>Note: I've also tried leaving out the 'startingReplicaCount and manualBatchTuningParameters.<\/p>\n<p>I'm using a curl command to initiate the batch job:<\/p>\n<pre><code>    curl -X POST \\\n-H &quot;Authorization: Bearer &quot;$(gcloud auth application-default print-access-token) \\\n-H &quot;Content-Type: application\/json; charset=utf-8&quot; \\\n-d @$INPUT_JSON \\\n&quot;https:\/\/$LOCATION-aiplatform.googleapis.com\/v1\/projects\/$PROJECT\/locations\/$LOCATION\/batchPredictionJobs&quot;\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1661278466123,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1661279037728,
        "Question_score_count":1.0,
        "Question_view_count":42.0,
        "Poster_created_time":1462581330168,
        "Poster_location":"Berkeley, CA, United States",
        "Poster_reputation_count":329.0,
        "Poster_view_count":65.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73463378",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model show failur byte predict error run vertex batch job custom model instanc jsonl result instanc job show error batch predict job cancel aug error file predict error stat byte directori beam temp predict error stat eaaccedaafdc file bytesin eed cafe predict error stat bacd predict error stat bcab predict error stat fdbc eebf predict error stat idea job show failur result job param displaynam model inputconfig instancesformat jsonl gcssourc uri instanc jsonl outputconfig predictionsformat jsonl gcsdestin outputuriprefix output dedicatedresourc machinespec machinetyp standard acceleratortyp null acceleratorcount null startingreplicacount manualbatchtuningparamet batch size note tri leav startingreplicacount manualbatchtuningparamet curl command initi batch job curl post author bearer gcloud auth applic default print access token content type applic json charset utf input json http locat aiplatform googleapi com project project locat locat batchpredictionjob",
        "Question_preprocessed_content":"model show failur byte vertex batch job custom model instanc jsonl result instanc job show batch predict job cancel aug file byte directori file bytesin idea job show failur result job param note tri leav startingreplicacount manualbatchtuningparamet curl initi batch job",
        "Question_gpt_summary_original":"The user is running a vertex batch job on a custom model with 676 instances in their jsonl. They get results for all 676 instances but the job shows \"Due to one or more errors, this batch prediction job was canceled\" and the error file prediction.errors_stats-00000-of-00001 has 0 bytes. The user is unsure why the job is showing failure but the results seem okay. They have tried leaving out the 'startingReplicaCount and manualBatchTuningParameters' and are using a curl command to initiate the batch job.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Can you add widgets to SageMaker Notebooks similar to Azure DataBricks?",
        "Question_body":"<p>I have used Azure DataBricks in my earlier job and it comes with extended support for Notebook widgets to execute notebook manually\/ commission a notebook job by selecting some values (Ideally your run state params or variables.)<\/p>\n<p>For information here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/notebooks\/widgets\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/notebooks\/widgets<\/a><\/p>\n<p>Is there a similar service or option that I can build while working on SageMaker notebooks?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1657767572897,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":45.0,
        "Poster_created_time":1582444257040,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72974712",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"add widget notebook similar azur databrick azur databrick earlier job come extend support notebook widget execut notebook manual commiss notebook job select valu ideal run state param variabl inform http doc microsoft com azur databrick notebook widget similar servic option build work notebook",
        "Question_preprocessed_content":"widget similar azur databrick azur databrick earlier job come extend widget execut job select valu inform similar servic option build work",
        "Question_gpt_summary_original":"The user is looking for a way to add widgets to SageMaker Notebooks similar to what is available in Azure DataBricks, which allows for extended support for Notebook widgets to execute notebook manually or commission a notebook job by selecting some values. The user is seeking information on whether there is a similar service or option available in SageMaker notebooks.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Private endpoint in hub-and-spoke architecture (Try to access a storage account in my different vnets)",
        "Question_body":"<p>Hello,    <\/p>\n<p>I'm trying to register a dataset in my different Azure Machine Learning workspaces (of each vnet spoke) but for that <strong>I need to connect from my ML workspaces to my storage account<\/strong> (dev or prod) located in the vnet 'spoke-pdata'. (screenshot)     <\/p>\n<p>The datastore (refer to storage account) is already register with Access key.     <br \/>\nI have already checked:    <\/p>\n<ul>\n<li> peering between my hub and my different spoke    <\/li>\n<li> private dns zone (privatelink.blob.core.windows.net) in my hub vnet with <strong>record set for storage<\/strong>     <\/li>\n<li> all virtual network links between hub and each spoke (privatelink blob)    <\/li>\n<li> private dns zone (privatelink.api.azureml.ms) in my hub vnet with <strong>record set for each azure machine learning<\/strong>     <\/li>\n<li> all virtual network links between hub and each spoke (privatelink azureml)    <\/li>\n<li> storage account roles for each azure ML    <\/li>\n<li> contributor role for each azure ml in storage account (to be sure it's not role issue)    <\/li>\n<li> NSG off for storage account     <\/li>\n<\/ul>\n<p>When I set ''All network'' in network of my storage account, Azure ML is connected to my storage account and I can register my dataset... So it's a network issue.    <br \/>\nI tried nslookup in AML and I can get the private ip of my storage account:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/173224-unknown.png?platform=QnA\" alt=\"173224-unknown.png\" \/>    <\/p>\n<p>What did I forget? Maybe I misunderstood the concept of private endpoint... From my point of view, I just need a private endpoint connected to a private dns. And in case there are two different vnet, I need to connect them with a private link and a vnet peering.     <br \/>\nI read the documentation but did not find a similar case... I am still confused.    <\/p>\n<p>Error:     <br \/>\n*    <\/p>\n<blockquote>\n<p>ScriptExecutionException was caused by StreamAccessException.    <br \/>\n  StreamAccessException was caused by AuthenticationException.    <br \/>\n    Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthorizationFailure'. Please make sure the SAS token or the account key is correct.    <br \/>\n      Failed due to inner exception of type: StorageException    <\/p>\n<\/blockquote>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/173262-effij.png?platform=QnA\" alt=\"173262-effij.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1644509273567,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/730824\/private-endpoint-in-hub-and-spoke-architecture-(tr",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"privat endpoint hub spoke architectur try access storag account differ vnet hello try regist dataset differ workspac vnet spoke need connect workspac storag account dev prod locat vnet spoke pdata screenshot datastor refer storag account regist access kei check peer hub differ spoke privat dn zone privatelink blob core window net hub vnet record set storag virtual network link hub spoke privatelink blob privat dn zone privatelink api hub vnet record set virtual network link hub spoke privatelink storag account role contributor role storag account sure role issu nsg storag account set network network storag account connect storag account regist dataset network issu tri nslookup aml privat storag account forget mayb misunderstood concept privat endpoint point view need privat endpoint connect privat dn case differ vnet need connect privat link vnet peer read document similar case confus error scriptexecutionexcept caus streamaccessexcept streamaccessexcept caus authenticationexcept authent fail azureblob getrefer oper redact authorizationfailur sure sa token account kei correct fail inner except type storageexcept",
        "Question_preprocessed_content":"privat endpoint architectur try regist dataset workspac workspac storag locat vnet datastor regist kei check hub spoke privat dn zone hub vnet record set storag virtual network link hub spoke privat dn zone hub vnet record set virtual network link hub spoke storag role contributor role storag nsg storag set network network storag storag regist network tri aml privat storag forget mayb concept privat point view privat endpoint privat dn case vnet privat link vnet read document similar confus scriptexecutionexcept caus caus authenticationexcept authent fail azureblob getrefer oper authorizationfailur sure sa token kei fail except type",
        "Question_gpt_summary_original":"The user is facing challenges in connecting their Azure Machine Learning workspaces to their storage account located in a different vnet spoke in a hub-and-spoke architecture. They have checked all virtual network links, private DNS zones, and storage account roles, but the issue persists. The user is unsure if they have misunderstood the concept of private endpoint and is seeking help to resolve the network issue. The error message indicates an authentication failure for the 'AzureBlob GetReference' operation.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Automate AI model training and create endpoint whenever the train data is updated using aws Sagemaker",
        "Question_body":"<p>I am searching for good references(videos or texts) to automate my AI (custom NLP model) training job whenever I update my data in s3 bucket i..e, whenever my pipeline detects change in data, it starts training automatically and create the endpoint. I am currently using aws API gateway and lambda to communicate with the endpoint. However, for each time I update my train data, I need to run the training job manually to create new endpoint. I want to automate the later part.\nIs there anyone in this group who can help me with the relevant resources to achieve this?\nThank You!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1663307946833,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":8.0,
        "Poster_created_time":1640203013416,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73740461",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"autom model train creat endpoint train data updat search good refer video text autom custom nlp model train job updat data bucket pipelin detect chang data start train automat creat endpoint current aw api gatewai lambda commun endpoint time updat train data need run train job manual creat new endpoint want autom later group help relev resourc achiev thank",
        "Question_preprocessed_content":"autom model train creat endpoint train data updat search refer autom train job updat data bucket pipelin detect chang data start train creat endpoint aw api gatewai lambda endpoint time updat train data run train job creat new endpoint want autom later group help relev resourc achiev thank",
        "Question_gpt_summary_original":"The user is looking for resources to automate the training of their custom NLP model in AWS Sagemaker whenever there is an update in their data stored in an S3 bucket. They currently use AWS API Gateway and Lambda to communicate with the endpoint, but they need to manually run the training job each time they update their data to create a new endpoint. The user is seeking help to automate this process.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Convert jpeg image data stored in AWS s3 to TFRecords where the sub-directory is the unique label associated with these images using AWS SageMaker",
        "Question_body":"<p>I have a directory of jpeg images in AWS s3 where the sub-directory is the unique label associated with these images. I am attempting to follow this <a href=\"https:\/\/github.com\/tensorflow\/models\/blob\/f87a58cd96d45de73c9a8330a06b2ab56749a7fa\/research\/inception\/inception\/data\/build_image_data.py\" rel=\"nofollow noreferrer\">example<\/a> using AWS SageMaker and I am making a mess of input and output paths while being inexperienced with flags. Any guidance on applying the linked solution using s3 and SageMaker or another approach to achieve the output of TFRecords then saved back to s3 would be greatly appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1613676013737,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":316.0,
        "Poster_created_time":1554323448856,
        "Poster_location":null,
        "Poster_reputation_count":57.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66266759",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"convert jpeg imag data store aw tfrecord sub directori uniqu label associ imag directori jpeg imag aw sub directori uniqu label associ imag attempt follow exampl make mess input output path inexperienc flag guidanc appli link solut approach achiev output tfrecord save greatli appreci",
        "Question_preprocessed_content":"convert jpeg imag data store aw tfrecord uniqu label imag directori jpeg imag aw uniqu label imag exampl make input output path inexperienc flag guidanc link solut achiev output tfrecord save greatli",
        "Question_gpt_summary_original":"The user is trying to convert jpeg image data stored in AWS s3 to TFRecords where the sub-directory is the unique label associated with these images using AWS SageMaker. They are having difficulty with input and output paths and are seeking guidance on how to apply a linked solution or another approach to achieve the desired output of TFRecords saved back to s3.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to authenticate within Azure ML pipeline and avoid browser interactive authentication?",
        "Question_body":"<p>I have created a very simple azure ml pipeline. Basically, it accesses data through an api and prints it.\nI have tried using a ClientSecretCredential and a ServicePrincipalAuthentication but the pipeline still asks me for a web browser authentication to continue (even though the script runs when I just run the python file in the terminal)<\/p>\n<pre><code>    from azureml.core.compute import ComputeTarget, AmlCompute\n    import azureml.core\n    from azureml.core import Workspace, Datastore\n    from azure.identity import ClientSecretCredential\n    from azureml.core.authentication import ServicePrincipalAuthentication\n    \n    \n    ws = Workspace.from_config()\n    \n    keyvault = ws.get_default_keyvault()\n    \n    client_id = keyvault.get_secret(&quot;ClientID&quot;)\n    tenant_id = keyvault.get_secret(&quot;TENANTID&quot;)\n    secret_id = keyvault.get_secret(&quot;CLIENTSECRET&quot;)\n    \n    sp = ClientSecretCredential(tenant_id = tenant_id, client_id = client_id, client_secret = secret_id)\n\n#  sp = ServicePrincipalAuthentication(tenant_id, client_id, secret_id)\n<\/code><\/pre>\n<p>This is the output from the pipeline:<\/p>\n<p>2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/azureProfile.json. It will be overridden by default settings.\n2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/az.json. It will be overridden by default settings.\n2022-07-06 06:08:21,496|azureml._vendor.azure_cli_core._session|INFO|Failed to load or parse file \/root\/.azureml\/auth\/az.sess. It will be overridden by default settings.\n2022-07-06 06:08:21,498|azureml._vendor.azure_cli_core|DEBUG|Current cloud config:\nAzureCloud\n2022-07-06 06:08:21,501|azureml._vendor.azure_cli_core|DEBUG|Current cloud config:\nAzureCloud\n2022-07-06 06:08:21,527|azureml._vendor.azure_cli_core._profile|INFO|No web browser is available. Fall back to device code.\n<strong>2022-07-06 06:08:21,628|azureml._vendor.azure_cli_core.auth.identity|WARNING|To sign in, use a web browser to open the page <a href=\"https:\/\/microsoft.com\/devicelogin\" rel=\"nofollow noreferrer\">https:\/\/microsoft.com\/devicelogin<\/a> and enter the code XXXXXXXXXX to authenticate.<\/strong>\n2022-07-06 06:08:49,950|azureml.core.authentication|DEBUG|Time to expire 1814345.049124 seconds<\/p>\n<p>What can I do for it to pick up the credential in the code and avoid asking for interactive authentication?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1657088789413,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":67.0,
        "Poster_created_time":1516041506383,
        "Poster_location":null,
        "Poster_reputation_count":43.0,
        "Poster_view_count":21.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72878787",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"authent pipelin avoid browser interact authent creat simpl pipelin basic access data api print tri clientsecretcredenti serviceprincipalauthent pipelin ask web browser authent continu script run run python file termin core comput import computetarget amlcomput import core core import workspac datastor azur ident import clientsecretcredenti core authent import serviceprincipalauthent workspac config keyvault default keyvault client keyvault secret clientid tenant keyvault secret tenantid secret keyvault secret clientsecret clientsecretcredenti tenant tenant client client client secret secret serviceprincipalauthent tenant client secret output pipelin vendor azur cli core session info fail load pars file root auth azureprofil json overridden default set vendor azur cli core session info fail load pars file root auth json overridden default set vendor azur cli core session info fail load pars file root auth sess overridden default set vendor azur cli core debug current cloud config azurecloud vendor azur cli core debug current cloud config azurecloud vendor azur cli core profil info web browser avail fall devic code vendor azur cli core auth ident warn sign us web browser open page http microsoft com devicelogin enter code xxxxxxxxxx authent core authent debug time expir second pick credenti code avoid ask interact authent",
        "Question_preprocessed_content":"authent pipelin avoid browser interact authent creat simpl pipelin data api print tri clientsecretcredenti serviceprincipalauthent pipelin ask web browser authent continu output pipelin load pars file default load pars file default load pars file default cloud config azurecloud cloud config azurecloud web browser avail devic code sign us web browser open page enter code authent expir second pick credenti code avoid ask interact authent",
        "Question_gpt_summary_original":"The user is facing an issue with Azure ML pipeline where even after using ClientSecretCredential and ServicePrincipalAuthentication, the pipeline is asking for web browser authentication. The user is looking for a solution to authenticate within Azure ML pipeline and avoid browser interactive authentication.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"SageMaker Issue: AttributeError: 'AioClientCreator' object has no attribute '_register_lazy_block_unknown_fips_pseudo_regions'",
        "Question_body":"Hi, there\n\nWhen training model using sagemaker and calling panda.read_csv().. we are getting the above error.  It appears that this is a known issue and the workaround is to upgrade aiobotocore to the latest 2.20 release. However, the missing link is where to upgrade the aiobotocore .. since we are running model against SageMaker and its fully managed M5 instance... instead of an EC2 instance.  Any thoughts? \n\nError message in full:\n\/opt\/conda\/lib\/python3.7\/site-packages\/aiobotocore\/client.py in create_client(self, service_name, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, api_version, client_config)\n     43             service_client, endpoint_url, client_config\n     44         )\n---> 45         self._register_lazy_block_unknown_fips_pseudo_regions(service_client)\n     46         return service_client\n     47 \n\nAttributeError: 'AioClientCreator' object has no attribute '_register_lazy_block_unknown_fips_pseudo_regions'\n\nSee notes below under this link:\nhttps:\/\/github.com\/boto\/botocore\/pull\/2558\/files#",
        "Question_answer_count":3,
        "Question_comment_count":1.0,
        "Question_created_time":1649181155664,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668624296784,
        "Question_score_count":0.0,
        "Question_view_count":878.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU1RBibWGuQSymNwJfXkln6A\/sagemaker-issue-attributeerror-aioclientcreator-object-has-no-attribute-register-lazy-block-unknown-fips-pseudo-regions",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"issu attributeerror aioclientcr object attribut regist lazi block unknown fip pseudo region train model call panda read csv get error appear known issu workaround upgrad aiobotocor latest releas miss link upgrad aiobotocor run model fulli manag instanc instead instanc thought error messag opt conda lib python site packag aiobotocor client creat client self servic region secur endpoint url verifi credenti scope config api version client config servic client endpoint url client config self regist lazi block unknown fip pseudo region servic client return servic client attributeerror aioclientcr object attribut regist lazi block unknown fip pseudo region note link http github com boto botocor pull file",
        "Question_preprocessed_content":"aioclientcr object train model known workaround upgrad aiobotocor latest releas link upgrad aiobotocor model manag instead instanc thought verifi credenti return aioclientcr object note link",
        "Question_gpt_summary_original":"The user is encountering an AttributeError while training a model using SageMaker and calling panda.read_csv(). The error message suggests that upgrading aiobotocore to the latest 2.20 release can resolve the issue, but the user is unsure where to upgrade aiobotocore since they are running the model against SageMaker's fully managed M5 instance instead of an EC2 instance.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Deploy inference pipeline with Cross Validate Model component",
        "Question_body":"<p>In Azure ML Studio I have created a pipeline that uses the Cross Validate Model component. According to the reference docs:    <br \/>\n (<a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/cross-validate-model#how-to-use-cross-validate-model\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/cross-validate-model#how-to-use-cross-validate-model<\/a>)    <br \/>\nthis component trains the model multiple times.  Now that I have run the pipeline successfully, I'd like to create an inference pipeline.  Unfortunately, regardless of the type of inference pipeline I choose (&quot;real time&quot; or &quot;batch&quot;) I receive the following message and I don't understand WHY as I have trained the model using the cross  validate model component.  I am new so if I'm missing something &quot;intuitively obvious&quot; I accept that...just need to move my project forward.  Thanks in advance for your help!    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/203788-image.png?platform=QnA\" alt=\"203788-image.png\" \/>    <\/p>\n<p>Below is my full pipeline:    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/203787-image.png?platform=QnA\" alt=\"203787-image.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1652979147437,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/856618\/deploy-inference-pipeline-with-cross-validate-mode",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi infer pipelin cross valid model compon studio creat pipelin us cross valid model compon accord refer doc http learn microsoft com azur machin learn compon refer cross valid model us cross valid model compon train model multipl time run pipelin successfulli like creat infer pipelin unfortun regardless type infer pipelin choos real time batch receiv follow messag understand train model cross valid model compon new miss intuit obviou accept need project forward thank advanc help pipelin",
        "Question_preprocessed_content":"deploi infer pipelin valid model compon studio creat pipelin us valid model compon refer doc compon train model multipl time run pipelin like creat infer pipelin unfortun type infer pipelin receiv understand train model valid model compon new intuit obviou project forward thank advanc help pipelin",
        "Question_gpt_summary_original":"The user has created a pipeline in Azure ML Studio using the Cross Validate Model component, which trains the model multiple times. However, when attempting to create an inference pipeline, regardless of the type chosen, the user receives an error message and is unsure why. The user has provided screenshots of the pipeline and error message for reference.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"normalized_boxes are bigger then one(1) - AWS SageMaker JumpStart SSD VGG16 Atrous 300",
        "Question_body":"<p>I deployed SSD VGG16 Atrous 300 model(COCO 2017, from Gluon CV) by AWS SageMaker JumpStart. Response from pretrained model contains normalized_boxes with values bigger than one(1), e.g.<\/p>\n<pre><code> \n&quot;normalized_boxes&quot;: [\n[\n0.4935379866715316,\n0.20722445845603943,\n0.7275399344308036,\n0.7329685688018799\n],\n[\n1.9931350875686813,\n0.15846982598304749,\n2.275825517256181,\n0.5962902307510376\n],\n...\n&quot;classes&quot;: [\n0,\n0,\n...\n&quot;scores&quot;: [\n0.344256728887558,\n0.4128507971763611,\n...\n&quot;labels&quot;: [\n&quot;person&quot;,\n&quot;bicycle&quot;,\n...\n&quot;mxnet_model_output&quot;: [\n[\n[\n[\n0\n],\n[\n0\n],\n...\n[\n[\n[\n0.9202409386634827\n],\n[\n0.9055193662643433\n],\n...\n[\n[\n[\n1551.213134765625,\n589.4755249023438,\n1808.19921875,\n878.4844360351562\n],\n[\n1557.686767578125,\n310.9128112792969,\n1805.559814453125,\n587.8072509765625\n],\n...\n\n<\/code><\/pre>\n<p>How to read those bounding boxes?<\/p>\n<p>I didn't manage to find the answer on gluon(<a href=\"https:\/\/cv.gluon.ai\/model_zoo\/detection.html\" rel=\"nofollow noreferrer\">https:\/\/cv.gluon.ai\/model_zoo\/detection.html<\/a>)<\/p>\n<p>The model can be fine-tuned, the rules how to prepare annotations(available in model description):\n&quot;The annotations.json file should should have information for bounding_boxes and their class labels. It should have a dictionary with keys &quot;images&quot; and &quot;annotations&quot;. Value for the &quot;images&quot; key should be a list of entries, one for each image of the form {&quot;file_name&quot;: image_name, &quot;height&quot;: height, &quot;width&quot;: width, &quot;id&quot;: image_id}. Value of the 'annotations' key should be a list of entries, one for each bounding box of the form {&quot;image_id&quot;: image_id, &quot;bbox&quot;: [xmin, ymin, xmax, ymax], &quot;category_id&quot;: bbox_label}.&quot;<\/p>\n<p>names of attributes are the same as in the COCO dataset - <a href=\"https:\/\/www.immersivelimit.com\/tutorials\/create-coco-annotations-from-scratch\/#coco-dataset-format\" rel=\"nofollow noreferrer\">https:\/\/www.immersivelimit.com\/tutorials\/create-coco-annotations-from-scratch\/#coco-dataset-format<\/a><\/p>\n<p>only this part is not consistent with COCO: &quot;[xmin, ymin, xmax, ymax]&quot; as I found, COCO has &quot;[x_min, y_min, width, height]&quot;(<a href=\"https:\/\/albumentations.ai\/docs\/getting_started\/bounding_boxes_augmentation\/\" rel=\"nofollow noreferrer\">https:\/\/albumentations.ai\/docs\/getting_started\/bounding_boxes_augmentation\/<\/a>)<\/p>\n<p>I tired also SSD VGG16 Atrous 512(pre-trained on VOC dataset) and faced the same problem, additionally, I received bbox value with a minus:<\/p>\n<pre><code>&quot;normalized_boxes&quot;: [\n        [\n            0.9567698719737294,\n            -0.14875292778015137,\n            1.0963617010430975,\n            0.5834765434265137\n        ],\n...\n<\/code><\/pre>\n<p>How to deal with values smaller than 0?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1654659657573,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":39.0,
        "Poster_created_time":1369428988750,
        "Poster_location":"Poland",
        "Poster_reputation_count":21.0,
        "Poster_view_count":8.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72539799",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"normal box bigger jumpstart ssd vgg atrou deploi ssd vgg atrou model coco gluon jumpstart respons pretrain model contain normal box valu bigger normal box class score label person bicycl mxnet model output read bound box manag answer gluon http gluon model zoo detect html model fine tune rule prepar annot avail model descript annot json file inform bound box class label dictionari kei imag annot valu imag kei list entri imag form file imag height height width width imag valu annot kei list entri bound box form imag imag bbox xmin ymin xmax ymax categori bbox label name attribut coco dataset http www immersivelimit com tutori creat coco annot scratch coco dataset format consist coco xmin ymin xmax ymax coco min min width height http albument doc get start bound box augment tire ssd vgg atrou pre train voc dataset face problem addition receiv bbox valu minu normal box deal valu smaller",
        "Question_preprocessed_content":"jumpstart atrou deploi atrou model jumpstart respons pretrain model contain valu read bound box manag answer model rule prepar json file inform label dictionari kei imag valu imag kei list entri imag form valu kei list entri bound box form name coco dataset consist coco xmin ymin xmax ymax coco width tire atrou voc dataset face problem receiv valu minu deal valu",
        "Question_gpt_summary_original":"The user has deployed an SSD VGG16 Atrous 300 model (COCO 2017) by AWS SageMaker JumpStart and is encountering issues with normalized_boxes having values bigger than one. The user is seeking guidance on how to read the bounding boxes and how to deal with values smaller than 0. The user has not found a solution on Gluon's website and is also facing the same problem with SSD VGG16 Atrous 512 (pre-trained on VOC dataset).",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Error while deserializing the Apache MXNet object",
        "Question_body":"<p>I have trained and saved a model using Amazon SageMaker which saves the model in the format of <code>model.tar.gz<\/code> which when untarred, has a file <code>model_algo-1<\/code> which is a serialized Apache MXNet object. To load the model in memory I need to deserialize the model. I tried doing so as follows:<\/p>\n\n<p><code>import mxnet as mx\nprint(mx.ndarray.load('model_algo-1'))<\/code><\/p>\n\n<p>Reference taken from <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/cdf-training.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/cdf-training.html<\/a><\/p>\n\n<p>However, doing this yields me the following error:<\/p>\n\n<pre><code>Traceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nFile \"\/usr\/local\/lib\/python3.4\/site-packages\/mxnet\/ndarray\/utils.py\", line \n175, in load\nctypes.byref(names)))\nFile \"\/usr\/local\/lib\/python3.4\/site-packages\/mxnet\/base.py\", line 146, in \ncheck_call\nraise MXNetError(py_str(_LIB.MXGetLastError()))\nmxnet.base.MXNetError: [19:06:25] src\/ndarray\/ndarray.cc:1112: Check failed: \nheader == kMXAPINDArrayListMagic Invalid NDArray file format\n\nStack trace returned 10 entries:\n[bt] (0) \/usr\/local\/lib\/python3.4\/site-packages\/mxnet\/libmxnet.so(+0x192112) \n[0x7fe432bfa112]\n[bt] (1) \/usr\/local\/lib\/python3.4\/site-packages\/mxnet\/libmxnet.so(+0x192738) \n[0x7fe432bfa738]\n[bt] (2) \/usr\/local\/lib\/python3.4\/site-\npackages\/mxnet\/libmxnet.so(+0x24a5c44) [0x7fe434f0dc44]\n[bt] (3) \/usr\/local\/lib\/python3.4\/site-\npackages\/mxnet\/libmxnet.so(MXNDArrayLoad+0x248) [0x7fe434d19ad8]\n[bt] (4) \/usr\/lib64\/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe48c5bbcec]\n[bt] (5) \/usr\/lib64\/libffi.so.6(ffi_call+0x1f5) [0x7fe48c5bb615]\n[bt] (6) \/usr\/lib64\/python3.4\/lib-dynload\/_ctypes.cpython-\n34m.so(_ctypes_callproc+0x2fb) [0x7fe48c7ce18b]\n[bt] (7) \/usr\/lib64\/python3.4\/lib-dynload\/_ctypes.cpython-34m.so(+0xa4cf) \n[0x7fe48c7c84cf]\n[bt] (8) \/usr\/lib64\/libpython3.4m.so.1.0(PyObject_Call+0x8c) \n[0x7fe4942fcb5c]\n[bt] (9) \/usr\/lib64\/libpython3.4m.so.1.0(PyEval_EvalFrameEx+0x36c5) \n[0x7fe4943ac915]\n<\/code><\/pre>\n\n<p>Could someone suggest how this can be resolved?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3.0,
        "Question_created_time":1522869667753,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":971.0,
        "Poster_created_time":1474557627236,
        "Poster_location":null,
        "Poster_reputation_count":1039.0,
        "Poster_view_count":89.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49658834",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error deseri apach mxnet object train save model save model format model tar untar file model algo serial apach mxnet object load model memori need deseri model tri follow import mxnet print ndarrai load model algo refer taken http doc aw amazon com latest cdf train html yield follow error traceback recent file line file usr local lib python site packag mxnet ndarrai util line load ctype byref name file usr local lib python site packag mxnet base line check rais mxneterror str lib mxgetlasterror mxnet base mxneterror src ndarrai ndarrai check fail header kmxapindarraylistmag invalid ndarrai file format stack trace return entri usr local lib python site packag mxnet libmxnet xfebfa usr local lib python site packag mxnet libmxnet xfebfa usr local lib python site packag mxnet libmxnet xac xfefdc usr local lib python site packag mxnet libmxnet mxndarrayload xfedad usr lib libffi ffi unix xfecbbcec usr lib libffi ffi xfecbb usr lib python lib dynload ctype cpython ctype callproc xfb xfecceb usr lib python lib dynload ctype cpython xacf xfecccf usr lib libpython pyobject xfefcbc usr lib libpython pyeval evalframeex xfeac suggest resolv",
        "Question_preprocessed_content":"deseri apach mxnet object train save model save model format file serial apach mxnet object load model memori deseri model tri refer taken yield resolv",
        "Question_gpt_summary_original":"The user is encountering an error while trying to deserialize an Apache MXNet object that was saved in the format of 'model.tar.gz' using Amazon SageMaker. The error message indicates that the NDArray file format is invalid. The user is seeking suggestions on how to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to submit local jobs with dsl.pipeline",
        "Question_body":"<p>Trying to run and debug a pipeline locally. Pipeline is imeplemented with <code>azure.ml.component.dsl.pipeline<\/code>. When I try to set <code>default_compute_target='local'<\/code>, the compute target cannot be found:<\/p>\n<pre><code>local not found in workspace, assume this is an AmlCompute\n...\nFile &quot;\/home\/amirabdi\/miniconda3\/envs\/stm\/lib\/python3.8\/site-packages\/azure\/ml\/component\/run_settings.py&quot;, line 596, in _get_compute_type\n    raise InvalidTargetSpecifiedError(message=&quot;Cannot find compute '{}' in workspace.&quot;.format(compute_name))\nazure.ml.component._util._exceptions.InvalidTargetSpecifiedError: InvalidTargetSpecifiedError:\n        Message: Cannot find compute 'local' in workspace.\n        InnerException None\n        ErrorResponse\n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Cannot find compute 'local' in workspace.&quot;\n    }\n}\n<\/code><\/pre>\n<p>The local run, for example, can be achieved with <code>azureml.core.ScriptRunConfig<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>src = ScriptRunConfig(script=&quot;train.py&quot;, compute_target=&quot;local&quot;, environment=myenv)\nrun = exp.submit(src)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1659479334120,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":98.0,
        "Poster_created_time":1445300868316,
        "Poster_location":"Vancouver, BC, Canada",
        "Poster_reputation_count":2059.0,
        "Poster_view_count":252.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73214437",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"submit local job dsl pipelin try run debug pipelin local pipelin imepl azur compon dsl pipelin try set default comput target local comput target local workspac assum amlcomput file home amirabdi miniconda env stm lib python site packag azur compon run set line comput type rais invalidtargetspecifiederror messag comput workspac format comput azur compon util except invalidtargetspecifiederror invalidtargetspecifiederror messag comput local workspac innerexcept errorrespons error code usererror messag comput local workspac local run exampl achiev core scriptrunconfig src scriptrunconfig script train comput target local environ myenv run exp submit src",
        "Question_preprocessed_content":"submit local job try run debug pipelin pipelin imepl try set comput target local run exampl achiev",
        "Question_gpt_summary_original":"The user is encountering an issue while trying to run and debug a pipeline locally using azure.ml.component.dsl.pipeline. When attempting to set default_compute_target='local', the compute target cannot be found, resulting in an InvalidTargetSpecifiedError. The user can achieve local run using azureml.core.ScriptRunConfig.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure Databrick workspace linking to Azure Machine Learning workspace error unable to get Workspace.from_config()",
        "Question_body":"<p>We are in a POC of Azure Databricks and Azure Machine Learning integration so that we can advance our MLOps practice.<\/p>\n<p>We have been dealing the with workspace linking issue for the past few weeks and have hit a wall. We worked with Databricks and search the internet for solution but were not successful. As AML is still in Preview, documentation may not be all there.<\/p>\n<p>I think this example below is the most recent and calls out how the linking should work. Is the statement highlighted below correct and if so, is there detail configuration that we are missing besides clicking the &quot;Link Azure ML Workspace&quot; button?<\/p>\n<p>[https:\/\/tsmatz.github.io\/azure-databricks-exercise\/exercise10-mlflow.html][1]<\/p>\n<p>Note : Here (in this hands-on) we connect to an Azure Machine Learning workspace by running Python code, however, you can now use the following &quot;<strong>Link Azure ML Workspace<\/strong>&quot; button (simplified integrated experience) in Azure Databricks launcher page to connect a new or existing workspace. <strong>Once you have linked with this experience, you don't need to run the following ws.write_config(), Workspace.from_config(), and mlflow.set_tracking_uri(<\/strong>).<\/p>\n<p>We have done the following.  <\/p>\n<ol>\n<li> Linked the workspace via &quot;Link Azure ML Workspace&quot; button  <\/li>\n<li> Run the attached MLFLow + AML \u2013 Combined.dbc  <\/li>\n<li> Failure in Cmd 15  <br \/>\nws = Workspace.from_config()<\/li>\n<\/ol>\n<h2 id=\"usererrorexception-usererrorexception\">UserErrorException: UserErrorException:<\/h2>\n<p>UserErrorException Traceback (most recent call last)  <br \/>\n&lt;command-4338604541924184&gt; in &lt;module&gt;  <br \/>\n3  <br \/>\n4  <br \/>\n----&gt; 5 ws = Workspace.from_config()  <br \/>\n6 exp = &quot;\/adb\/XXXXXXXXXXXXXXX\/XXXXXXXXXXXX\/Users\/######@#######.com\/MLFlow + AML - Combined&quot;  <br \/>\n7 runs = list(exp.get_runs())<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/core\/workspace.py in from_config(path, auth, _logger, _file_name)  <br \/>\n272 'We could not find config.json in: {} or in its parent directories. '  <br \/>\n273 'Please provide the full path to the config file or ensure that '  <br \/>\n--&gt; 274 'config.json exists in the parent directories.'.format(normalized_path))  <br \/>\n275  <br \/>\n276 subscription_id, resource_group, workspace_name = project_info.get_workspace_info(<\/p>\n<p>UserErrorException: UserErrorException:  <br \/>\nMessage: We could not find config.json in: \/databricks\/driver or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.  <br \/>\nInnerException None  <br \/>\nErrorResponse  <br \/>\n{  <br \/>\n&quot;error&quot;: {  <br \/>\n&quot;code&quot;: &quot;UserError&quot;,  <br \/>\n&quot;message&quot;: &quot;We could not find config.json in: \/databricks\/driver or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;  <br \/>\n}  <br \/>\n}  <br \/>\n4. Config.json manually place into directory path specified in error message<\/p>\n<ol start=\"5\">\n<li>  Perform workspace write_config(). But, forces interactive authentication which is blocked by our organization policy.<\/li>\n<\/ol>\n<p>Besides performing the &quot;Link Azure ML Workspace&quot; via the button from Databricks, we have not performed any other configuration. Based on the documentation, it should just work. Appreciate any assistance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1594145605387,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/43845\/azure-databrick-workspace-linking-to-azure-machine",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"azur databrick workspac link workspac error unabl workspac config poc azur databrick integr advanc mlop practic deal workspac link issu past week hit wall work databrick search internet solut success aml preview document think exampl recent call link work statement highlight correct configur miss click link workspac button http tsmatz github azur databrick exercis exercis html note hand connect workspac run python code us follow link workspac button simplifi integr experi azur databrick launcher page connect new exist workspac link experi need run follow write config workspac config set track uri follow link workspac link workspac button run attach aml combin dbc failur cmd workspac config usererrorexcept usererrorexcept usererrorexcept traceback recent workspac config exp adb xxxxxxxxxxxxxxx xxxxxxxxxxxx user com aml combin run list exp run databrick python lib python site packag core workspac config path auth logger file config json parent directori provid path config file ensur config json exist parent directori format normal path subscript resourc group workspac project info workspac info usererrorexcept usererrorexcept messag config json databrick driver parent directori provid path config file ensur config json exist parent directori innerexcept errorrespons error code usererror messag config json databrick driver parent directori provid path config file ensur config json exist parent directori config json manual place directori path specifi error messag perform workspac write config forc interact authent block organ polici perform link workspac button databrick perform configur base document work appreci assist",
        "Question_preprocessed_content":"azur databrick workspac link workspac unabl poc azur databrick integr advanc mlop practic deal workspac link past hit work databrick search internet solut aml preview document think exampl recent link work statement highlight configur click link workspac note workspac python code us link workspac azur databrick launcher page new exist workspac link experi run link workspac link workspac run aml failur cmd traceback exp aml combin run auth parent directori provid path config file ensur exist parent parent directori provid path config file ensur exist parent directori place directori path specifi perform workspac forc interact authent block organ polici perform link workspac databrick perform configur base document work",
        "Question_gpt_summary_original":"The user is facing an issue while linking Azure Databricks workspace to Azure Machine Learning workspace. They have tried linking the workspace via the \"Link Azure ML Workspace\" button and running the attached MLFlow + AML \u2013 Combined.dbc, but they are facing an error in Cmd 15. The error message suggests that the config.json file is missing, and the user has tried manually placing it in the directory path specified in the error message. The user has not performed any other configuration besides linking the workspace via the button from Databricks.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Accessing DynamoDb data from Sagemaker",
        "Question_body":"I have some data in my DynamoDb database and I want to access it in my Sagemaker notebook. To my surprise having done some research it looks like I need to transfer the data from DynamoDb into an S3 bucket and access the data from a csv file in there. Is that correct? What is the best way of doing this?",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1682539673791,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1682886971732,
        "Question_score_count":1.0,
        "Question_view_count":76.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUowJvrZpiRjOS5v0OhDkEXQ\/accessing-dynamodb-data-from-sagemaker",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"access dynamodb data data dynamodb databas want access notebook surpris have research look like need transfer data dynamodb bucket access data csv file correct best wai",
        "Question_preprocessed_content":"dynamodb data data dynamodb databas want surpris have research like transfer data dynamodb bucket data csv file best wai",
        "Question_gpt_summary_original":"The user wants to access data from their DynamoDb database in their Sagemaker notebook, but has discovered that they need to transfer the data to an S3 bucket and access it from a CSV file. They are seeking advice on the best way to do this.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to pre deploy the instances used by sagemaker for training?",
        "Question_body":"<p>Sagemaker takes ~3 mins for <code>preparing the instances for training<\/code> and around ~1 min for the actual training and artifact publishing.<\/p>\n<p>I want to pre-deploy some ec2 instances which it can use for training. However I couldn't find an option to specify pre deployed instances in the <code>ResourceConfig<\/code> part of the <code>createTrainingJob<\/code>.<\/p>\n<p>Is this possible?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1642316278607,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":30.0,
        "Poster_created_time":1551701216487,
        "Poster_location":null,
        "Poster_reputation_count":735.0,
        "Poster_view_count":106.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70727988",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pre deploi instanc train take min prepar instanc train min actual train artifact publish want pre deploi instanc us train couldn option specifi pre deploi instanc resourceconfig createtrainingjob possibl",
        "Question_preprocessed_content":"pre deploi instanc train take min min actual train artifact publish want instanc us train couldn option specifi pre deploi instanc",
        "Question_gpt_summary_original":"The user is facing a challenge with the time taken by Sagemaker to prepare instances for training. They are looking for a way to pre-deploy EC2 instances for Sagemaker to use, but are unable to find an option to specify pre-deployed instances in the ResourceConfig part of the createTrainingJob. They are seeking advice on whether this is possible.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Why do I encounter \"INVALID_PARAMETER VALUE\" error when opening \"Models\" tab in MLFlow UI?",
        "Question_body":"<p>I installed mlflow via pip and opened it in the browser through the terminal. The tab Experiments displays normally; however, when I switch to Models tab, the app crashes due to the following error:<\/p>\n<pre><code>INVALID_PARAMETER_VALUE: Model registry functionality is unavailable; \ngot unsupported URI '.\/mlruns' for model registry data storage. \nSupported URI schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. \nSee https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run \nan MLflow server against one of the supported backend storage locations.\n<\/code><\/pre>\n<p>I would like to log model data locally without connecting to external servers or databases. I thank you in advance for any help!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1659957616140,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1660218063030,
        "Question_score_count":1.0,
        "Question_view_count":39.0,
        "Poster_created_time":1652711404248,
        "Poster_location":null,
        "Poster_reputation_count":51.0,
        "Poster_view_count":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73277043",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"encount invalid paramet valu error open model tab instal pip open browser termin tab experi displai normal switch model tab app crash follow error invalid paramet valu model registri function unavail got unsupport uri mlrun model registri data storag support uri scheme postgresql mysql sqlite mssql http www org doc latest track html storag run server support backend storag locat like log model data local connect extern server databas thank advanc help",
        "Question_preprocessed_content":"encount valu open model tab pip open browser termin tab experi displai switch model tab crash like log model data extern server databas thank advanc help",
        "Question_gpt_summary_original":"The user encounters an \"INVALID_PARAMETER_VALUE\" error when trying to open the \"Models\" tab in MLFlow UI. The error message suggests that the model registry functionality is unavailable due to an unsupported URI for model registry data storage. The user wants to log model data locally without connecting to external servers or databases.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Merge distinct sklearn models into a single one",
        "Question_body":"<p>I have a dataset where, after exploring data, I detect some patron:<\/p>\n<ul>\n<li>The entire dataset have, imagine, 9 numerical variables, 1 dichotomous variable (take 'A' or 'B' value) and 1 numerical output<\/li>\n<li>The output is a cost (in \u20ac)<\/li>\n<li>I find a sklearn regression model that, when 'A', using 4 of 9 variables I can predict output with good performance.<\/li>\n<li>I find another sklearn regression model that, when 'B', using the last 5 variables, I can predict output with good performance.<\/li>\n<li>If I try to find a model which predict output with all the variables as input, encoding the dichotomous one with One-Hot-Encoder, the model has a bad performance.<\/li>\n<\/ul>\n<p>My goal is to implement a unique model in Azure Machine Learning, using a .joblib\/.pkl, but with this approach, I have two separated models with the same output (a cost) but different inputs, depending of dichotomous variable.<\/p>\n<p>Is there any way to merge the two models into a single one? So that with the 10 inputs, estimate a single output (internally discriminate options 'A' and 'B' to select the correct model and its inputs).<\/p>\n<p>Notice that using something like Voting Ensemble it's not valid because there are different inputs on each category (or I think it so)<\/p>\n<p>I accept another approach as a solution. Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1633074956947,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":119.0,
        "Poster_created_time":1611139028547,
        "Poster_location":"Vigo, Espa\u00f1a",
        "Poster_reputation_count":39.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69402391",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"merg distinct sklearn model singl dataset explor data detect patron entir dataset imagin numer variabl dichotom variabl valu numer output output cost sklearn regress model variabl predict output good perform sklearn regress model variabl predict output good perform try model predict output variabl input encod dichotom hot encod model bad perform goal implement uniqu model joblib pkl approach separ model output cost differ input depend dichotom variabl wai merg model singl input estim singl output intern discrimin option select correct model input notic like vote ensembl valid differ input categori think accept approach solut thank",
        "Question_preprocessed_content":"merg distinct sklearn model singl dataset explor data detect patron entir dataset imagin numer variabl dichotom variabl numer output output cost sklearn model variabl predict output perform sklearn model variabl predict output perform try model predict output variabl input encod dichotom model bad perform goal implement uniqu model separ model output input depend dichotom variabl wai merg model singl input estim singl output notic like vote ensembl valid input categori solut thank",
        "Question_gpt_summary_original":"The user has two distinct sklearn regression models that predict output with good performance, but with different inputs depending on a dichotomous variable. The user wants to merge the two models into a single one that can estimate a single output using all 10 inputs, while internally discriminating between the options 'A' and 'B' to select the correct model and its inputs. The user is seeking a solution to implement a unique model in Azure Machine Learning.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'ruamel' when excuting from azureml.core",
        "Question_body":"<p>I am trying to execute the Azure ml sdk from the local system using the Jupyter notebook. When I run the below code i am getting an error.<\/p>\n<pre><code>from azureml.core import Workspace, Datastore, Dataset\n\nModuleNotFoundError: No module named 'ruamel' \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1622646368700,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":332.0,
        "Poster_created_time":1599816833352,
        "Poster_location":"New Delhi, Delhi, India",
        "Poster_reputation_count":329.0,
        "Poster_view_count":58.0,
        "Answer_body":"<p>You have to add pip 20.1.1<\/p>\n<p>Conda ruamel needs higher version of pip<\/p>\n<pre><code>conda install pip=20.1.1\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1626743937907,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1536318818623,
        "Answerer_location":"\u0130zmit, Kocaeli, T\u00fcrkiye",
        "Answerer_reputation_count":1033.0,
        "Answerer_view_count":55.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67807756",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"modulenotfounderror modul name ruamel excut core try execut sdk local jupyt notebook run code get error core import workspac datastor dataset modulenotfounderror modul name ruamel",
        "Question_preprocessed_content":"modul name ruamel excut core try execut sdk local jupyt run code",
        "Question_gpt_summary_original":"The user is encountering a \"ModuleNotFoundError\" when trying to execute the Azure ml sdk from their local system using Jupyter notebook. The error message specifically states that there is no module named 'ruamel'.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Early Stopping and Callbacks with Keras when using SageMaker",
        "Question_body":"<p>I am using sagemaker to train a keras model. I need to implement early stoping approach when training the model. <\/p>\n\n<p>Is there a way to pass callbacks such as EarlyStopping, Histories..etc. <\/p>\n\n<p>In traditional way, we used to pass this as a parameter to keras's fit function:<\/p>\n\n<pre><code>results = model.fit(train_x_trim, train_y_trim, \n                    validation_data=(test_x, test_y), \n                    epochs=FLAGS.epoch,  \n                    verbose=0, \n                    callbacks=[tboard, checkpointer, early_stopping, history])\n<\/code><\/pre>\n\n<p>However, if using SageMaker, we need to call SageMaker's fit function instead which doesn't support callbacks. <\/p>\n\n<pre><code>from sagemaker.tensorflow import TensorFlow \niris_estimator = TensorFlow(entry_point='training_code.py', \n                            role=role, output_path=model_location, \n                            code_location=custom_code_upload_location, \n                            train_instance_count=1, \n                            train_instance_type='ml.c4.xlarge', \n                            training_steps=1000, \n                            evaluation_steps=100)\n<\/code><\/pre>\n\n<p>Any idea how to implement callbacks in SageMaker ? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1543252902240,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1543256081430,
        "Question_score_count":3.0,
        "Question_view_count":557.0,
        "Poster_created_time":1485886879543,
        "Poster_location":"Canada",
        "Poster_reputation_count":71.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53486118",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"earli stop callback kera train kera model need implement earli stope approach train model wai pass callback earlystop histori tradit wai pass paramet kera fit function result model fit train trim train trim valid data test test epoch flag epoch verbos callback tboard checkpoint earli stop histori need fit function instead support callback tensorflow import tensorflow iri estim tensorflow entri point train code role role output path model locat code locat custom code upload locat train instanc count train instanc type xlarg train step evalu step idea implement callback",
        "Question_preprocessed_content":"earli kera train kera model implement earli stope train model wai tradit wai paramet kera fit function fit function instead idea implement",
        "Question_gpt_summary_original":"The user is facing a challenge while using SageMaker to train a Keras model as SageMaker's fit function does not support callbacks such as EarlyStopping and Histories. The user is seeking a solution to implement callbacks in SageMaker.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Aamazon SageMaker feature store throughput and latency",
        "Question_body":"What is the maximum throughput of AWS feature store. Also what is the P99 value of latency of AWS feature store (online store) ?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1639718714901,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1668601320840,
        "Question_score_count":0.0,
        "Question_view_count":763.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUDX9mkJlNQzaR8lF50Z4H2Q\/aamazon-sagemaker-feature-store-throughput-and-latency",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"featur store throughput latenc maximum throughput aw featur store valu latenc aw featur store onlin store",
        "Question_preprocessed_content":"featur store throughput latenc maximum throughput aw featur store valu latenc aw featur store",
        "Question_gpt_summary_original":"The user is inquiring about the maximum throughput and P99 latency value of the AWS feature store, specifically the online store.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"MLFlow Meetup 1.0 @ Microsoft",
        "Question_body":"Hello!\n\n\n\nIf you missed the last\u00a0MLflow meetup,\u00a0here are the slides and the video presentation.\n\nTalks for the meetup are on the SlideShare:\n1. Talk 1:\u00a0https:\/\/www.slideshare.net\/databricks\/flock-data-science-platform-cisl\n2. Talk-2:\u00a0https:\/\/www.slideshare.net\/databricks\/mlflow-10-meetup\n\nAnd the video is now available:\u00a0\u00a0https:\/\/youtu.be\/ILIllCMDEgc\n\n\n\n\n--\u00a0\n\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nApache Spark Developer & Community Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1561656475000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":12.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Xf5Bs8xootI",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"meetup microsoft hello miss meetup slide video present talk meetup slideshar talk http www slideshar net databrick flock data scienc platform cisl talk http www slideshar net databrick meetup video avail http youtu ilillcmdegc best idea simpl jule damji apach spark develop commun advoc databrick databrick com",
        "Question_preprocessed_content":"microsoft slide video present talk slideshar talk video best idea simpl jule damji apach spark develop advoc databrick",
        "Question_gpt_summary_original":"The user is sharing slides and a video presentation from the MLFlow Meetup 1.0 at Microsoft, including talks on the Flock Data Science Platform and MLFlow 1.0.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to pass environment variables to gcloud beta ai custom-jobs create with custom container (Vertex AI)",
        "Question_body":"<p>I'm running custom training jobs in google's Vertex AI. A simple <code>gcloud<\/code> command to execute a custom job would use something like the following syntax (complete documentation for the command can be seen <a href=\"https:\/\/cloud.google.com\/sdk\/gcloud\/reference\/beta\/ai\/custom-jobs\/create#--config\" rel=\"nofollow noreferrer\">here<\/a>):<\/p>\n<pre><code>gcloud beta ai custom-jobs create --region=us-central1 \\\n--display-name=test \\\n--config=config.yaml\n<\/code><\/pre>\n<p>In the <code>config.yaml<\/code> file, it is possible to specify the machine and accelerator (GPU) types, etc., and in my case, point to a custom container living in the Google Artifact Registry that executes the training code (specified in the <code>imageUri<\/code> part of the <code>containerSpec<\/code>). An example config file may look like this:<\/p>\n<pre><code># config.yaml\nworkerPoolSpecs:\n  machineSpec:\n    machineType: n1-highmem-2\n    acceleratorType: NVIDIA_TESLA_P100\n    acceleratorCount: 2\n  replicaCount: 1\n  containerSpec:\n    imageUri: {URI_FOR_CUSTOM_CONATINER}\n    args:\n    - {ARGS TO PASS TO CONTAINER ENTRYPOINT COMMAND}\n<\/code><\/pre>\n<p>The code we're running needs some runtime environment variables (that need to be secure) passed to the container. In the <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/reference\/rest\/v1\/CustomJobSpec#containerspec\" rel=\"nofollow noreferrer\">API documentation<\/a> for the <code>containerSpec<\/code>, it says it is possible to set environment variables as follows:<\/p>\n<pre><code># config.yaml\nworkerPoolSpecs:\n  machineSpec:\n    machineType: n1-highmem-2\n    acceleratorType: NVIDIA_TESLA_P100\n    acceleratorCount: 2\n  replicaCount: 1\n  containerSpec:\n    imageUri: {URI_FOR_CUSTOM_CONATINER}\n    args:\n    - {ARGS TO PASS TO CONTAINER ENTRYPOINT COMMAND}\n    env:\n    - name: SECRET_ONE\n      value: $SECRET_ONE\n    - name: SECRET_TWO\n      value: $SECRET_TWO\n<\/code><\/pre>\n<p>When I try and add the <code>env<\/code> flag to the <code>containerSpec<\/code>, I get an error saying it's not part of the container spec:<\/p>\n<pre><code>ERROR: (gcloud.beta.ai.custom-jobs.create) INVALID_ARGUMENT: Invalid JSON payload received. Unknown name &quot;env&quot; at 'custom_job.job_spec.worker_pool_specs[0].container_spec': Cannot find field.\n- '@type': type.googleapis.com\/google.rpc.BadRequest\n  fieldViolations:\n  - description: &quot;Invalid JSON payload received. Unknown name \\&quot;env\\&quot; at 'custom_job.job_spec.worker_pool_specs[0].container_spec':\\\n      \\ Cannot find field.&quot;\n    field: custom_job.job_spec.worker_pool_specs[0].container_spec\n<\/code><\/pre>\n<p>Any idea how to securely set runtime environment variables in Vertex AI custom jobs using custom containers?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7.0,
        "Question_created_time":1632409414673,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1632410531832,
        "Question_score_count":3.0,
        "Question_view_count":1033.0,
        "Poster_created_time":1464106929608,
        "Poster_location":null,
        "Poster_reputation_count":457.0,
        "Poster_view_count":37.0,
        "Answer_body":"<p>There are two versions of the REST API - \u201c<a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/reference\/rest\/v1\/CustomJobSpec#containerspec\" rel=\"nofollow noreferrer\">v1<\/a>\u201d and \u201c<a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/reference\/rest\/v1beta1\/CustomJobSpec#containerspec\" rel=\"nofollow noreferrer\">v1beta1<\/a>\u201d where &quot;v1beta1&quot; does not have the <code>env<\/code> option in <code>ContainerSpec<\/code> but &quot;v1&quot; does. The <code>gcloud ai custom-jobs create<\/code> command without the <code>beta<\/code> parameter doesn\u2019t throw the error as it uses version \u201cv1\u201d to make the API calls.<\/p>\n<p>The environment variables from the yaml file can be passed to the custom container in the following way:<\/p>\n<p>This is the docker file of the sample custom training application I used to test the requirement. Please refer to this <a href=\"https:\/\/codelabs.developers.google.com\/vertex_custom_training_prediction\" rel=\"nofollow noreferrer\">codelab<\/a> for more information about the training application.<\/p>\n<pre class=\"lang-docker prettyprint-override\"><code>FROM gcr.io\/deeplearning-platform-release\/tf2-cpu.2-3\nWORKDIR \/root\n\nWORKDIR \/\n\n# Copies the trainer code to the docker image.\nCOPY trainer \/trainer\n\n\n# Copies the bash script to the docker image.\nCOPY commands.sh \/scripts\/commands.sh\n\n# Bash command to make the script file an executable\nRUN [&quot;chmod&quot;, &quot;+x&quot;, &quot;\/scripts\/commands.sh&quot;]\n\n\n# Command to execute the file\nENTRYPOINT [&quot;\/scripts\/commands.sh&quot;]\n\n# Sets up the entry point to invoke the trainer.\n# ENTRYPOINT &quot;python&quot; &quot;-m&quot; $SECRET_TWO \u21d2 To use the environment variable  \n# directly in the docker ENTRYPOINT. In case you are not using a bash script, \n# the trainer can be invoked directly from the docker ENTRYPOINT.\n<\/code><\/pre>\n<br \/>\n<p>Below is the <code>commands.sh<\/code> file used in the docker container to test whether the environment variables are passed to the container.<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>#!\/bin\/bash\nmkdir \/root\/.ssh\necho $SECRET_ONE\npython -m $SECRET_TWO\n<\/code><\/pre>\n<br \/>\n<p>The example <code>config.yaml<\/code> file<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code># config.yaml\nworkerPoolSpecs:\n  machineSpec:\n    machineType: n1-highmem-2\n  replicaCount: 1\n  containerSpec:\n    imageUri: gcr.io\/infosys-kabilan\/mpg:v1\n    env:\n    - name: SECRET_ONE\n      value: &quot;Passing the environment variables&quot;\n    - name: SECRET_TWO\n      value: &quot;trainer.train&quot;\n<\/code><\/pre>\n<p>As the next step, I built and pushed the container to Google Container Repository. Now, the <code>gcloud ai custom-jobs create --region=us-central1  --display-name=test --config=config.yaml<\/code> can be run to create the custom training job and the output of the <code>commands.sh<\/code> file can be seen in the job logs as shown below.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qRHV7.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qRHV7.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1632987814700,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1619163566860,
        "Answerer_location":null,
        "Answerer_reputation_count":1730.0,
        "Answerer_view_count":555.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69302528",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pass environ variabl gcloud beta custom job creat custom contain run custom train job googl simpl gcloud command execut custom job us like follow syntax complet document command seen gcloud beta custom job creat region central displai test config config yaml config yaml file possibl specifi machin acceler gpu type case point custom contain live googl artifact registri execut train code specifi imageuri containerspec exampl config file look like config yaml workerpoolspec machinespec machinetyp highmem acceleratortyp nvidia tesla acceleratorcount replicacount containerspec imageuri uri custom conatin arg arg pass contain entrypoint command code run need runtim environ variabl need secur pass contain api document containerspec sai possibl set environ variabl follow config yaml workerpoolspec machinespec machinetyp highmem acceleratortyp nvidia tesla acceleratorcount replicacount containerspec imageuri uri custom conatin arg arg pass contain entrypoint command env secret valu secret secret valu secret try add env flag containerspec error sai contain spec error gcloud beta custom job creat invalid argument invalid json payload receiv unknown env custom job job spec worker pool spec contain spec field type type googleapi com googl rpc badrequest fieldviol descript invalid json payload receiv unknown env custom job job spec worker pool spec contain spec field field custom job job spec worker pool spec contain spec idea secur set runtim environ variabl custom job custom contain",
        "Question_preprocessed_content":"environ variabl gcloud beta creat custom contain custom train job simpl execut custom job us like syntax file specifi machin type case point custom contain live artifact registri execut train code exampl config file like code runtim environ variabl contain api document sai set environ variabl try flag sai contain spec idea secur set runtim environ variabl custom job custom contain",
        "Question_gpt_summary_original":"The user is encountering an issue while trying to pass runtime environment variables to a custom container in Google's Vertex AI. The user is trying to use the \"env\" flag in the \"containerSpec\" section of the \"config.yaml\" file, but is receiving an error message stating that the \"env\" flag is not part of the container spec. The user is seeking a solution to securely set runtime environment variables in Vertex AI custom jobs using custom containers.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML: User errors were found in at least one of the child runs",
        "Question_body":"<p>Hi, I am trying to perform hyperparameter tuning, but I keep getting the error in my Question Title. I am new to Azure, and I am not sure if it is some error in my script. Could someone advise please?    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129278-image.png?platform=QnA\" alt=\"129278-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129364-image.png?platform=QnA\" alt=\"129364-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129328-image.png?platform=QnA\" alt=\"129328-image.png\" \/>    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/129373-image.png?platform=QnA\" alt=\"129373-image.png\" \/>    <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1630835455217,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/540302\/azure-ml-user-errors-were-found-in-at-least-one-of",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"user error child run try perform hyperparamet tune get error question titl new azur sure error script advis",
        "Question_preprocessed_content":"user child run try perform hyperparamet tune question titl new azur sure script advis",
        "Question_gpt_summary_original":"The user is encountering errors while performing hyperparameter tuning in Azure ML, and is unsure if it is due to an error in their script. The error message states that user errors were found in at least one of the child runs.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"The difference between boto3.client and pymysql.connect",
        "Question_body":"<p>I am the novice in using AWS-RDS-mysql, Now I have a problem when connecting this database<\/p>\n\n<p>Here I have two ways to connect to my AWS-RDS-mysql, one is to use 'boto3' package and another is 'pymysql' package.<\/p>\n\n<p>For boto3, four paramaters are required, they are:<\/p>\n\n<pre><code>1) type='rds', \n2) region,\n3) aws_access_key_id\n4) aws_secret_access_key\n<\/code><\/pre>\n\n<p>The function I use is:<\/p>\n\n<pre><code>boto3.client(type, region, aws_access_key_id=key_id, aws_secret_access_key=access_key)\n<\/code><\/pre>\n\n<p>For pymysql, I need 5 parameters, they are:<\/p>\n\n<pre><code>1) host = \"databaseinstancename.cxxxxxxxxxx.ca-central-1.rds.amazonaws.com\"\n2) port = 3306\n3) dbname = \"xxx\"\n4) user = \"admin\"\n5) password = \"ssssss\"\n<\/code><\/pre>\n\n<p>The method I use is:<\/p>\n\n<pre><code>pymysql.connect(host, user=user, port=port, passwd=password, db=dbname)\n<\/code><\/pre>\n\n<p>All of them could connect to the database from my pycharm successfully.<\/p>\n\n<p>My question is <\/p>\n\n<p>1) what's the difference between the first method(using boto3) and the second one(using pymysql)? There are must be something difference because I provide two different kinds of information to connect.<\/p>\n\n<p>2) When I use jupyter notebook in AWS sagemaker to edit python3 code to try to connect to the database, I find only the first method(using boto3) could work, the second method(using pymysql) cannot connect successfully with a error saying that 'time out'. Why does this happen when one method could be accessible to the database but another one fails? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1585463084537,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1585463686460,
        "Question_score_count":0.0,
        "Question_view_count":936.0,
        "Poster_created_time":1585449302723,
        "Poster_location":null,
        "Poster_reputation_count":9.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60910863",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"differ boto client pymysql connect novic aw rd mysql problem connect databas wai connect aw rd mysql us boto packag pymysql packag boto paramat requir type rd region aw access kei aw secret access kei function us boto client type region aw access kei kei aw secret access kei access kei pymysql need paramet host databaseinstancenam cxxxxxxxxxx central rd amazonaw com port dbname xxx user admin password ssssss method us pymysql connect host user user port port passwd password dbname connect databas pycharm successfulli question differ method boto second pymysql differ provid differ kind inform connect us jupyt notebook edit python code try connect databas method boto work second method pymysql connect successfulli error sai time happen method access databas fail",
        "Question_preprocessed_content":" novic problem databas wai us boto packag pymysql packag boto paramat requir function us pymysql paramet method us databas pycharm question method second provid kind inform us jupyt edit python code try databas method work second method sai time method databas fail",
        "Question_gpt_summary_original":"The user is facing a problem while connecting to AWS-RDS-mysql database using two different methods - boto3 and pymysql. The user is confused about the difference between the two methods and why only boto3 is working in AWS Sagemaker while pymysql is giving a timeout error.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to schedule repeated runs of a custom training job in Vertex AI",
        "Question_body":"<p>I have packaged my training code as a python package and then am able to run it as a custom training job on Vertex AI. Now, I wanted to be able to schedule this job to run, say every 2 weeks, and re-train the model. The Scheduling settings in the CustomJoBSpec allow only 2 fields, &quot;timeout&quot; and &quot;restartJobOnWorkerRestart&quot; so it's not possible using the scheduling settings in the CustomJobSpec. One way to achieve this I could think of was to create a Vertex AI pipeline with a single step using the &quot;CustomPythonPackageTrainingJobRunOp&quot; Google Cloud Pipeline Component and then scheduling the pipeline to run as I see fit. Are there better alternatives to achieve this?<\/p>\n<p><strong>Edit:<\/strong><\/p>\n<p>I was able to schedule the custom training job using Cloud Scheduler, but I found using the create_schedule_from_job_spec method in the AIPlatformClient very easy to use in the Vertex AI pipeline. The steps I took to schedule the custom job using Cloud Scheduler in gcp are as follows, <a href=\"https:\/\/cloud.google.com\/scheduler\/docs\/http-target-auth#setting_up_the_service_account\" rel=\"nofollow noreferrer\">link<\/a> to google docs:<\/p>\n<ol>\n<li>Set target type to HTTP<\/li>\n<li>For the url to specify the custom job, I followed <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/training\/create-custom-job#curl\" rel=\"nofollow noreferrer\">this<\/a> link to get the url<\/li>\n<li>For the authentication, under Auth header, I selected the &quot;Add OAauth token&quot;<\/li>\n<\/ol>\n<p>You also need to have a &quot;Cloud Scheduler service account&quot; with  a &quot;Cloud Scheduler Service Agent role granted to it&quot; in your project. Although the docs ay this should have been set up automatically if you enabled the Cloud Scheduler API after March 19, 2019, this was not the case for me and had to add the service account with the role manually.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6.0,
        "Question_created_time":1629043963683,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1629147961556,
        "Question_score_count":2.0,
        "Question_view_count":2669.0,
        "Poster_created_time":1471292986790,
        "Poster_location":null,
        "Poster_reputation_count":700.0,
        "Poster_view_count":90.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68793294",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"schedul repeat run custom train job packag train code python packag abl run custom train job want abl schedul job run week train model schedul set customjobspec allow field timeout restartjobonworkerrestart possibl schedul set customjobspec wai achiev think creat pipelin singl step custompythonpackagetrainingjobrunop googl cloud pipelin compon schedul pipelin run fit better altern achiev edit abl schedul custom train job cloud schedul creat schedul job spec method aiplatformcli easi us pipelin step took schedul custom job cloud schedul gcp follow link googl doc set target type http url specifi custom job follow link url authent auth header select add oaauth token need cloud schedul servic account cloud schedul servic agent role grant project doc set automat enabl cloud schedul api march case add servic account role manual",
        "Question_preprocessed_content":"schedul repeat run custom train job packag train code python packag abl run custom train job want abl schedul job run model schedul customjobspec field timeout schedul customjobspec wai achiev think creat pipelin singl step custompythonpackagetrainingjobrunop cloud pipelin compon schedul pipelin run fit altern achiev edit abl schedul custom train job cloud schedul method aiplatformcli easi us pipelin step schedul custom job cloud schedul gcp link doc set target type url specifi custom job link url authent auth header select token cloud schedul servic cloud schedul servic agent role grant project doc set enabl cloud schedul api march case servic role",
        "Question_gpt_summary_original":"The user wants to schedule a custom training job to run every two weeks on Vertex AI, but the scheduling settings in the CustomJobSpec only allow for two fields. The user suggests creating a Vertex AI pipeline with a single step using the CustomPythonPackageTrainingJobRunOp component and scheduling the pipeline to run. The user later found that they could schedule the custom job using Cloud Scheduler by following specific steps.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to get an Amazon ECR container URI for a specific model image in Sagemaker?",
        "Question_body":"<p>I want to know if it's possible to get an Amazon ECR container URI for a specific image programmatically (using AWS CLI or Python). For example, if I need the URL for the latest <code>linear-learner<\/code> (built-in model) image for the <code>eu-central-1<\/code> region.<\/p>\n<p>Expected result:<\/p>\n<pre><code>664544806723.dkr.ecr.eu-central-1.amazonaws.com\/linear-learner:latest\n<\/code><\/pre>\n<p>EDIT: I have found the solution with <code>get_image_uri<\/code>. It looks like this function will be depreceated and I don't know how to use <code>ImageURIProvider<\/code> instead.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":3.0,
        "Question_created_time":1599474994217,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1599481967088,
        "Question_score_count":4.0,
        "Question_view_count":3017.0,
        "Poster_created_time":1511210305768,
        "Poster_location":"Bad Orb, Germany",
        "Poster_reputation_count":12908.0,
        "Poster_view_count":1267.0,
        "Answer_body":"<p>The newer versions of SageMaker SDK have a more centralized API for getting the URIs:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import sagemaker \nsagemaker.image_uris.retrieve(&quot;linear-learner&quot;, &quot;eu-central-1&quot;)\n<\/code><\/pre>\n<p>which gives the expected result:<\/p>\n<pre><code>664544806723.dkr.ecr.eu-central-1.amazonaws.com\/linear-learner:1\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1617813746592,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1412713062067,
        "Answerer_location":"Munich, Germany",
        "Answerer_reputation_count":3603.0,
        "Answerer_view_count":228.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63775893",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"amazon ecr contain uri specif model imag want know possibl amazon ecr contain uri specif imag programmat aw cli python exampl need url latest linear learner built model imag central region expect result dkr ecr central amazonaw com linear learner latest edit solut imag uri look like function deprec know us imageuriprovid instead",
        "Question_preprocessed_content":"amazon ecr contain uri specif model imag want know amazon ecr contain uri specif imag exampl url latest imag region expect result edit solut like function deprec know us instead",
        "Question_gpt_summary_original":"The user is seeking a way to programmatically obtain an Amazon ECR container URI for a specific image, such as the latest linear-learner built-in model image for the eu-central-1 region, using AWS CLI or Python. The user has found a solution using get_image_uri but is unsure how to use ImageURIProvider instead, as get_image_uri is being deprecated.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is there a way to access compute quotas with the Azure CLI or Python SDK?",
        "Question_body":"<p>I want to tabulate the compute quotas for each Azure ML workspace, in each Azure location, for my organization's Azure subscription. Although it is possible to look at the quotas manually through the Azure Portal (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#workspace-level-quota\" rel=\"nofollow noreferrer\">link<\/a>), I have not found a way to do this with the Azure CLI or Python SDK for Azure. Since there are many resource groups and AML workspaces for different teams under my Azure subscription, it would be much more efficient to do this programmatically rather than manually through the portal. Is this even possible, and if so how can it be done?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1597248542537,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1597249191852,
        "Question_score_count":2.0,
        "Question_view_count":418.0,
        "Poster_created_time":1369863777596,
        "Poster_location":"Cambridge, MA",
        "Poster_reputation_count":335.0,
        "Poster_view_count":23.0,
        "Answer_body":"<p>It does look like these commands are currently in the CLI or the Python SDK. The CLI uses the Python SDK, so what's missing from one does tend to be missing from the other.<\/p>\n<p>Fortunately, you can invoke the rest endpoints directly, either in Python or by using the <code>az rest<\/code> command in the CLI.<\/p>\n<p>There are a few commands that may interest you:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/usages\/list\" rel=\"nofollow noreferrer\">Usage<\/a> and Quotas for a region:\n<code>\/subscriptions\/{subscriptionId}\/providers\/Microsoft.MachineLearningServices\/locations\/{location}\/usages?api-version=2019-05-01<\/code>\n<code>\/subscriptions\/{subscriptionId}\/providers\/Microsoft.MachineLearningServices\/locations\/{location}\/quotas?api-version=2020-04-01<\/code><\/p>\n<p>The process for updating REST specs to the offical documentation is fairly lengthy so it isn't published yet, but if you are willing to use Swagger docs to explore what is available, the 2020-06-01 version of the API is on Github, which includes endpoints for updating quotas as well as retrieving them: <a href=\"https:\/\/github.com\/Azure\/azure-rest-api-specs\/tree\/master\/specification\/machinelearningservices\/resource-manager\/Microsoft.MachineLearningServices\/stable\/2020-06-01\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-rest-api-specs\/tree\/master\/specification\/machinelearningservices\/resource-manager\/Microsoft.MachineLearningServices\/stable\/2020-06-01<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1597341970283,
        "Answer_last_edit_time":1597439016992,
        "Answer_score_count":1.0,
        "Answerer_created_time":1549041651583,
        "Answerer_location":"Atlanta, GA, USA",
        "Answerer_reputation_count":3106.0,
        "Answerer_view_count":428.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63380531",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"wai access comput quota azur cli python sdk want tabul comput quota workspac azur locat organ azur subscript possibl look quota manual azur portal link wai azur cli python sdk azur resourc group aml workspac differ team azur subscript effici programmat manual portal possibl",
        "Question_preprocessed_content":"wai comput quota azur cli python sdk want tabul comput quota workspac azur locat organ azur subscript quota azur portal wai azur cli python sdk azur resourc group aml workspac team azur subscript portal",
        "Question_gpt_summary_original":"The user wants to access compute quotas for each Azure ML workspace in each Azure location for their organization's Azure subscription. They are looking for a way to do this programmatically using the Azure CLI or Python SDK, as it would be more efficient than doing it manually through the Azure Portal.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"build an AZURE ML enviroment from docker image in dockerhub",
        "Question_body":"<p>I want to use <a href=\"https:\/\/hub.docker.com\/layers\/shi2yu3\/mainz\/v7_nccl2804\/images\/sha256-298ca59f25e56ff8d0f3faeb7493618ff7d69149e6a92283ed3176a215b8da8d?context=explore\">https:\/\/hub.docker.com\/layers\/shi2yu3\/mainz\/v7_nccl2804\/images\/sha256-298ca59f25e56ff8d0f3faeb7493618ff7d69149e6a92283ed3176a215b8da8d?context=explore<\/a> in Azure ML as an environment for model training and testing. Any idea how to do this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1635963924763,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/614519\/build-an-azure-ml-enviroment-from-docker-image-in",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"build enviro docker imag dockerhub want us http hub docker com layer shiyu mainz nccl imag sha cafeffdffaebffdeaedabdad context explor environ model train test idea",
        "Question_preprocessed_content":"build enviro docker imag dockerhub want us environ model train test idea",
        "Question_gpt_summary_original":"The user wants to know how to use a Docker image from DockerHub to build an Azure ML environment for model training and testing.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS SageMaker: Create an endpoint using a trained model hosted in S3",
        "Question_body":"<p>I have following this <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/introduction_to_amazon_algorithms\/semantic_segmentation_pascalvoc\/semantic_segmentation_pascalvoc.ipynb\" rel=\"nofollow noreferrer\">tutorial<\/a>, which is mainly for jupyter notebook, and made some minimal modification for external processing. I've created a project that could prepare my dataset locally, upload it to S3, train, and finally deploy the model predictor to the same bucket. Perfect!<\/p>\n<p>So, after to train and saved it in S3 bucket:<\/p>\n<pre><code> ss_model.fit(inputs=data_channels, logs=True)\n<\/code><\/pre>\n<p>it failed while deploying as an endpoint. So, I have found tricks to host an endpoint in many ways, but not from a model already saved in S3. Because in order to host, you probably need to get the estimator, which in normal way is something like:<\/p>\n<pre><code> self.estimator = sagemaker.estimator.Estimator(self.training_image,\n                                                role,\n                                                train_instance_count=1,\n                                                train_instance_type='ml.p3.2xlarge',\n                                                train_volume_size=50,\n                                                train_max_run=360000,\n                                                output_path=output,\n                                                base_job_name='ss-training',\n                                                sagemaker_session=sess)\n<\/code><\/pre>\n<p>My question is: is there a way to load an estimator from a model saved in S3 (.tar)? Or, anyway, to create an endpoint without train it again?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1593283354330,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":1360.0,
        "Poster_created_time":1429270603900,
        "Poster_location":"S\u00e3o Jos\u00e9 dos Campos, Sao Jose dos Campos - State of S\u00e3o Paulo, Brazil",
        "Poster_reputation_count":138.0,
        "Poster_view_count":38.0,
        "Answer_body":"<p>So, after to run on many pages, just found a clue <a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/introduction_to_amazon_algorithms\/blazingtext_hosting_pretrained_fasttext\/blazingtext_hosting_pretrained_fasttext.ipynb\" rel=\"nofollow noreferrer\">here<\/a>. And I finally found out how to load the model and create the endpoint:<\/p>\n<pre><code>def create_endpoint(self):\n    sess = sagemaker.Session()\n    training_image = get_image_uri(sess.boto_region_name, 'semantic-segmentation', repo_version=&quot;latest&quot;)        \n    role = &quot;YOUR_ROLE_ARN_WITH_SAGEMAKER_EXECUTION&quot;\n    model = &quot;s3:\/\/BUCKET\/PREFIX\/...\/output\/model.tar.gz&quot;\n\n    sm_model = sagemaker.Model(model_data=model, image=training_image, role=role, sagemaker_session=sess)\n    sm_model.deploy(initial_instance_count=1, instance_type='ml.p3.2xlarge')\n<\/code><\/pre>\n<p><strong>Please, do not forget to disable your endpoint after using. This is really important! Endpoints are charged by &quot;running&quot; not only by the use<\/strong><\/p>\n<p>I hope it also can help you out!<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1593463280863,
        "Answer_last_edit_time":1595855655040,
        "Answer_score_count":3.0,
        "Answerer_created_time":1429270603900,
        "Answerer_location":"S\u00e3o Jos\u00e9 dos Campos, Sao Jose dos Campos - State of S\u00e3o Paulo, Brazil",
        "Answerer_reputation_count":138.0,
        "Answerer_view_count":38.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62614143",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat endpoint train model host follow tutori mainli jupyt notebook minim modif extern process creat project prepar dataset local upload train final deploi model predictor bucket perfect train save bucket model fit input data channel log true fail deploi endpoint trick host endpoint wai model save order host probabl need estim normal wai like self estim estim estim self train imag role train instanc count train instanc type xlarg train volum size train max run output path output base job train session sess question wai load estim model save tar creat endpoint train",
        "Question_preprocessed_content":"creat endpoint train model host tutori mainli jupyt minim modif extern creat project prepar dataset upload train deploi model predictor bucket perfect train save bucket fail deploi endpoint trick host endpoint wai model save order host probabl estim normal wai like question wai load estim model save creat endpoint train",
        "Question_gpt_summary_original":"The user has followed a tutorial to create a project using AWS SageMaker that prepares a dataset locally, uploads it to S3, trains a model, and deploys the model predictor to the same bucket. However, while deploying the model as an endpoint, it failed. The user is looking for a way to load an estimator from a model saved in S3 or create an endpoint without training it again.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is there any workaround for installing packages ? (deepspeed error)",
        "Question_body":"<p>i was trying to use deepspeed, but when i run the training it shows an error. I have to install mpi4py using pip. However if I try to install mpi4py i get an error.\nFrom that error i found out that to install the package, i must install &quot;libopenmpi-dev &quot; before, using apt. However we dont have the password to sudo. Any workaround to this ?\n(or the only option is to change platforms ?)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":9.0,
        "Question_created_time":1659082147263,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1659169326400,
        "Question_score_count":0.0,
        "Question_view_count":73.0,
        "Poster_created_time":1653740518870,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73163540",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"workaround instal packag deepspe error try us deepspe run train show error instal mpipi pip try instal mpipi error error instal packag instal libopenmpi dev apt dont password sudo workaround option chang platform",
        "Question_preprocessed_content":"workaround packag try us run train show mpi pip try mpi packag apt dont sudo workaround option chang platform",
        "Question_gpt_summary_original":"The user is facing an error while trying to use deepspeed for training. They need to install mpi4py using pip, but it requires installing \"libopenmpi-dev\" using apt, which requires sudo password. The user is looking for a workaround to install the package without sudo or if changing platforms is the only option.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"error to run training job with aws Sagemaker",
        "Question_body":"<p>I am trying to use my own sickit-learn ML model with SageMaker using the github example.<\/p>\n\n<p>The python code is below : <\/p>\n\n<pre><code># Define IAM role import boto3 \nimport re \nimport os \nimport numpy as np \nimport pandas as pd \nfrom sagemaker import get_execution_role \nimport sagemaker as sage from time \nimport gmtime, strftime \nrole = get_execution_role()\n\ness =  sage.Session()\naccount = sess.boto_session.client('sts').get_caller_identity()['Account']\nregion = sess.boto_session.region_name\nimage = '{}.dkr.ecr.{}.amazonaws.com\/decision-trees-sample:latest'.format(account, region)\n\n\noutput_path=\"s3:\/\/output\"\n\nsess\n\ntree = sage.estimator.Estimator(image,\n                      role, 1, 'ml.c4.2xlarge',\n                     output_path='s3-eu-west-1.amazonaws.com\/output',\n                    sagemaker_session=sess)\n\ntree.fit(\"s3:\/\/output\/iris.csv\")\n<\/code><\/pre>\n\n<p>But I get this error : <\/p>\n\n<blockquote>\n  <p>INFO:sagemaker:Creating training-job with name:\n  decision-trees-sample-2018-04-24-13-13-38-281<\/p>\n  \n  <p>--------------------------------------------------------------------------- ClientError                               Traceback (most recent call\n  last)  in ()\n       14                     sagemaker_session=sess)\n       15 \n  ---> 16 tree.fit(\"s3:\/\/inteldatastore-cyrine\/iris.csv\")<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/estimator.py\n  in fit(self, inputs, wait, logs, job_name)\n      161             self.output_path = 's3:\/\/{}\/'.format(self.sagemaker_session.default_bucket())\n      162 \n  --> 163         self.latest_training_job = _TrainingJob.start_new(self, inputs)\n      164         if wait:\n      165             self.latest_training_job.wait(logs=logs)<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/estimator.py\n  in start_new(cls, estimator, inputs)\n      336                                           input_config=input_config, role=role,\n  job_name=estimator._current_job_name,\n      337                                           output_config=output_config, resource_config=resource_config,\n  --> 338                                           hyperparameters=hyperparameters, stop_condition=stop_condition)\n      339 \n      340         return cls(estimator.sagemaker_session, estimator._current_job_name)<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/session.py\n  in train(self, image, input_mode, input_config, role, job_name,\n  output_config, resource_config, hyperparameters, stop_condition)\n      242         LOGGER.info('Creating training-job with name: {}'.format(job_name))\n      243         LOGGER.debug('train request: {}'.format(json.dumps(train_request, indent=4)))\n  --> 244         self.sagemaker_client.create_training_job(**train_request)\n      245 \n      246     def create_model(self, name, role, primary_container):<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/botocore\/client.py\n  in _api_call(self, *args, **kwargs)\n      312                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n      313             # The \"self\" in this scope is referring to the BaseClient.\n  --> 314             return self._make_api_call(operation_name, kwargs)\n      315 \n      316         _api_call.<strong>name<\/strong> = str(py_operation_name)<\/p>\n  \n  <p>~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/botocore\/client.py\n  in _make_api_call(self, operation_name, api_params)\n      610             error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\n      611             error_class = self.exceptions.from_code(error_code)\n  --> 612             raise error_class(parsed_response, operation_name)\n      613         else:\n      614             return parsed_response<\/p>\n  \n  <p>ClientError: An error occurred (AccessDeniedException) when calling\n  the CreateTrainingJob operation: User:\n  arn:aws:sts::307504647302:assumed-role\/default\/SageMaker is\n  not authorized to perform: sagemaker:CreateTrainingJob on resource:\n  arn:aws:sagemaker:eu-west-1:307504647302:training-job\/decision-trees-sample-2018-04-24-13-13-38-281<\/p>\n<\/blockquote>\n\n<p>Can you help me to resolve the problem?<\/p>\n\n<p>Thank you<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1.0,
        "Question_created_time":1524576827563,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":4369.0,
        "Poster_created_time":1518617852856,
        "Poster_location":null,
        "Poster_reputation_count":495.0,
        "Poster_view_count":81.0,
        "Answer_body":"<p>Looks like you don't have access to the resource <\/p>\n\n<pre><code>arn:aws:sagemaker:eu-west-1:307504647302:training-job\/decision-trees-sample-2018-04-24-13-13-38-281\n<\/code><\/pre>\n\n<p>Can you check if the resource url is correct and the proper permissions are set in the security group. <\/p>",
        "Answer_comment_count":5.0,
        "Question_closed_time":1524587840612,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1467237684900,
        "Answerer_location":null,
        "Answerer_reputation_count":613.0,
        "Answerer_view_count":39.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50003050",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error run train job try us sickit learn model github exampl python code defin iam role import boto import import import numpi import panda import execut role import sage time import gmtime strftime role execut role ess sage session account sess boto session client st caller ident account region sess boto session region imag dkr ecr amazonaw com decis tree sampl latest format account region output path output sess tree sage estim estim imag role xlarg output path west amazonaw com output session sess tree fit output iri csv error info creat train job decis tree sampl clienterror traceback recent session sess tree fit inteldatastor cyrin iri csv anaconda env python lib python site packag estim fit self input wait log job self output path format self session default bucket self latest train job trainingjob start new self input wait self latest train job wait log log anaconda env python lib python site packag estim start new cl estim input input config input config role role job estim current job output config output config resourc config resourc config hyperparamet hyperparamet stop condit stop condit return cl estim session estim current job anaconda env python lib python site packag session train self imag input mode input config role job output config resourc config hyperparamet stop condit logger info creat train job format job logger debug train request format json dump train request indent self client creat train job train request def creat model self role primari contain anaconda env python lib python site packag botocor client api self arg kwarg accept keyword argument oper self scope refer basecli return self api oper kwarg api str oper anaconda env python lib python site packag botocor client api self oper api param error code pars respons error code error class self except code error code rais error class pars respons oper return pars respons clienterror error occur accessdeniedexcept call createtrainingjob oper user arn aw st assum role default author perform createtrainingjob resourc arn aw west train job decis tree sampl help resolv problem thank",
        "Question_preprocessed_content":"run train job try us model github exampl python code info creat traceback fit input wait estim input role role hyperparamet hyperparamet return train info debug def role arg kwarg keyword self scope basecli return kwarg rais return createtrainingjob oper user author perform createtrainingjob resourc help resolv problem thank",
        "Question_gpt_summary_original":"The user is encountering an error while trying to run a training job with AWS SageMaker. The error message indicates that the user is not authorized to perform the sagemaker:CreateTrainingJob on the resource. The user has shared the python code used for the training job and is seeking help to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Why Does SageMaker Data Parallel Distributed Training Only Support 3 Instances types?",
        "Question_body":"<p>I see\u00a0<a href=\"https:\/\/sagemaker-examples.readthedocs.io\/en\/latest\/training\/distributed_training\/pytorch\/data_parallel\/mnist\/pytorch_smdataparallel_mnist_demo.html\" rel=\"nofollow noreferrer\">here<\/a>\u00a0that SageMaker Data Distributed Library only supports 3 instance types: ml.p3.16xlarge, ml.p3dn.24xlarge, ml.p4d.24xlarge.<\/p>\n<p>Why is this? I would have thought there might be use cases for parallel training for other GPUs, and even potentially CPUs<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662712414643,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":13.0,
        "Poster_created_time":1662621266503,
        "Poster_location":null,
        "Poster_reputation_count":48.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73659423",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"data parallel distribut train support instanc type seeherethat data distribut librari support instanc type xlarg pdn xlarg xlarg thought us case parallel train gpu potenti cpu",
        "Question_preprocessed_content":"data distribut train instanc type data distribut librari instanc type thought us case train gpu cpu",
        "Question_gpt_summary_original":"The user is questioning why SageMaker Data Parallel Distributed Training only supports three instance types and is curious if there are use cases for parallel training on other GPUs or CPUs.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to fix database disk image is malform",
        "Question_body":"<p>Hi,<br>\nHow to fix in this errot:<br>\nERROR: unexpected error - database disk image is malformed<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1614622947594,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":343.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/how-to-fix-database-disk-image-is-malform\/691",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"fix databas disk imag malform fix errot error unexpect error databas disk imag malform",
        "Question_preprocessed_content":"fix databas disk imag malform fix unexpect databas disk imag malform",
        "Question_gpt_summary_original":"The user is encountering an error message stating \"database disk image is malformed\" and is seeking guidance on how to fix it.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Matplotlib drawing, please can you set the subscript to start at 1 instead of 36",
        "Question_body":"<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270.png\" data-download-href=\"\/uploads\/short-url\/uY79TH4Hvfbkf7OvkKIHtqppHHi.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270_2_690x351.png\" alt=\"image\" data-base62-sha1=\"uY79TH4Hvfbkf7OvkKIHtqppHHi\" width=\"690\" height=\"351\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270_2_690x351.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270_2_1035x526.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d90cdbb2e0a509504a054f682f89557c60393270.png 2x\" data-dominant-color=\"EBEEF4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1136\u00d7578 38.2 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<pre><code class=\"lang-auto\">def plot_embeddings(embeddings, label,dataset_name,epoch):\n    len_embedding = len(embeddings)\n    emb_list = np.array(embeddings.tolist())\n    label = np.array(label.tolist())\n\n    color_idx = {}\n    for i in range(len_embedding):\n        color_idx.setdefault(label[i], [])\n        color_idx[label[i]].append(i)\n\n    fig, ax = plt.subplots(figsize=(20,10), dpi= 120)\n    for c, idx in color_idx.items():\n        ax.scatter(emb_list[idx, 0], emb_list[idx, 1], label=c)\n\n    wandb.log({f\"visualization\/Embedding\u2014\u2014{dataset_name}\": fig,\n               f\"visualization\/epoch\": epoch,\n               })\n<\/code><\/pre>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1677029763995,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":171.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/matplotlib-drawing-please-can-you-set-the-subscript-to-start-at-1-instead-of-36\/3927",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"matplotlib draw set subscript start instead imag def plot embed embed label dataset epoch len embed len embed emb list arrai embed tolist label arrai label tolist color idx rang len embed color idx setdefault label color idx label append fig plt subplot figsiz dpi idx color idx item scatter emb list idx emb list idx label log visual embed dataset fig visual epoch epoch",
        "Question_preprocessed_content":"matplotlib draw set subscript start instead imag",
        "Question_gpt_summary_original":"The user is requesting assistance in setting the subscript to start at 1 instead of 36 in a Matplotlib drawing. The code provided shows a function that plots embeddings with labels and logs the visualization using WandB.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Will the python version of docker image for training be impacted by Azure's notice \"Stop support Python 3.6 on 5 December 2022\"?",
        "Question_body":"<p>Hi guys,    <\/p>\n<p>I received the email notice that &quot;Azure Machine Learning will stop support for Python 3.6 on 5 December 2022 \u2013 transition to Python 3.8 or later.&quot;    <br \/>\nWill the python version of docker image for training be impacted by Azure's notice &quot;Stop support Python 3.6 on 5 December 2022&quot;?    <br \/>\ndocker image for training is the &quot;custom_docker_image&quot; set in &quot;Estimator&quot;.    <br \/>\nCurrently we have several model training using docker with python 3.6.    <\/p>\n<p>Thanks,    <br \/>\nHaoran    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1669968457547,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1113439\/will-the-python-version-of-docker-image-for-traini",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"python version docker imag train impact azur notic stop support python decemb gui receiv email notic stop support python decemb transit python later python version docker imag train impact azur notic stop support python decemb docker imag train custom docker imag set estim current model train docker python thank haoran",
        "Question_preprocessed_content":"python version docker imag train impact azur notic stop python decemb gui receiv email notic stop python decemb transit python python version docker imag train impact azur notic stop python decemb docker imag train set estim model train docker python thank haoran",
        "Question_gpt_summary_original":"The user is concerned about the impact of Azure's notice to stop support for Python 3.6 on December 5, 2022 on the python version of the docker image for training, which is currently set to custom_docker_image in Estimator. The user has several model training using docker with Python 3.6.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How can I use this specific voice? (English (en-gb-x-gbg-network)",
        "Question_body":"Goal: Given text, generate mp3 files using Google Cloud tts services\n\nProblem: Unable to find specific voice I am used to hearing English (en-gb-x-gbg-network).\u00a0\n\nOther info: I've been using this tts app on android in which I can select the aforementioned Voice Type from the Google TTS engine on android. I have since created a Google Cloud account, and followed the tutorial to setup a project to which I can use their selection of voices. However, when I went through the list of voice that I can use, the\u00a0en-gb-x-gbg-network was not available to use. AFAIK,\u00a0en-gb-x-gbg-network is not a premium WaveNet voice type.\u00a0\n\nI suspect it has something to do with android but I can't not see why I can't use this voice on the Google Cloud Platform.\n\n\u00a0\n\nMany thanks for any helpful info or any nudge that can point me to the right direction\n\nCheers,\u00a0\n\nWelp",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1642719360000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":348.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-use-this-specific-voice-English-en-gb-x-gbg-network\/m-p\/184984#M186",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us specif voic english gbg network goal given text gener file googl cloud tt servic problem unabl specif voic hear english gbg network info tt app android select aforement voic type googl tt engin android creat googl cloud account follow tutori setup project us select voic went list voic us theen gbg network avail us afaik gbg network premium wavenet voic type suspect android us voic googl cloud platform thank help info nudg point right direct cheer welp",
        "Question_preprocessed_content":"us specif voic goal given text gener file cloud servic problem unabl specif voic hear english info android select aforement voic type engin android creat cloud tutori setup project us select voic went list voic us avail us premium wavenet voic type suspect android us voic cloud platform thank help info nudg point right direct welp",
        "Question_gpt_summary_original":"The user is trying to generate mp3 files using Google Cloud tts services but is unable to find the specific voice they are used to hearing, which is English (en-gb-x-gbg-network). They have followed the tutorial to set up a project on Google Cloud but the voice is not available to use. The user suspects it may have something to do with Android but is unsure why they can't use the voice on the Google Cloud Platform.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Loading multiple models in an online fully managed endpoint",
        "Question_body":"<p>Hey there!<\/p>\n<p>I am creating an endpoint which chains inference from different models. At the moment I solve the loading of them by doing:<\/p>\n<pre><code class=\"lang-python\"># define models paths\nartifacts_dir = Path(os.getenv(&quot;AZUREML_MODEL_DIR&quot;)) \/ &quot;artifacts&quot;\nmodel_file_path = &quot;runwayml\/stable-diffusion-v1-5&quot;\ngfpgan_model_file_path = artifacts_dir \/ &quot;gfpgan&quot; \/ &quot;gfpgan_v1.4.pth&quot;\ncontrolnet_model_file_path = artifacts_dir \/ &quot;controlnet&quot; \/ &quot;scribble_sd15&quot;\nembedding_file_path = (\n    artifacts_dir \/ &quot;stable_diffusion&quot; \/ &quot;sd15_journal_sketch_inversion.bin&quot;\n)\n\ninference = Inference(\n        model_file_path=model_file_path,\n        gfpgan_model_file_path=gfpgan_model_file_path,\n        enable_xformers=False,\n        controlnet_type=&quot;controlnet&quot;,\n        controlnet_model_file_path=controlnet_model_file_path,\n        embedding_file_path=embedding_file_path,\n)\n<\/code><\/pre>\n<p>The problem with this, is that I have all the models in a single artifact folder registered as a Model in the ML workspace. This works, but if I want to change or update only one of the models, I would need to re-upload the whole folder which is quite expensive in terms of storage and time.<\/p>\n<p>I found an <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb\">example<\/a> using the python SDK v2:<\/p>\n<pre><code>from azureml.core.model import Model\n\ndef init():\n    global model_1, model_2\n    # Here &quot;my_first_model&quot; is the name of the model registered under the workspace.\n    # This call will return the path to the .pkl file on the local disk.\n    model_1_path = Model.get_model_path(model_name='my_first_model')\n    model_2_path = Model.get_model_path(model_name='my_second_model')\n    \n    # Deserialize the model files back into scikit-learn models.\n    model_1 = joblib.load(model_1_path)\n    model_2 = joblib.load(model_2_path)\n<\/code><\/pre>\n<p>And I was wondering if there's anything similar for SDK v2. I tried to find information on the net, but couldn't find any.<\/p>\n<p>If you have any lead would be greatly appreciated!\nThank you so much!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1682113257410,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1251565\/loading-multiple-models-in-an-online-fully-managed",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"load multipl model onlin fulli manag endpoint hei creat endpoint chain infer differ model moment solv load defin model path artifact dir path getenv model dir artifact model file path runwayml stabl diffus gfpgan model file path artifact dir gfpgan gfpgan pth controlnet model file path artifact dir controlnet scribbl embed file path artifact dir stabl diffus journal sketch invers bin infer infer model file path model file path gfpgan model file path gfpgan model file path enabl xformer fals controlnet type controlnet controlnet model file path controlnet model file path embed file path embed file path problem model singl artifact folder regist model workspac work want chang updat model need upload folder expens term storag time exampl python sdk core model import model def init global model model model model regist workspac return path pkl file local disk model path model model path model model model path model model path model second model deseri model file scikit learn model model joblib load model path model joblib load model path wonder similar sdk tri inform net couldn lead greatli appreci thank",
        "Question_preprocessed_content":"load multipl model onlin manag endpoint hei creat endpoint chain infer model moment solv load problem model singl artifact folder regist model workspac work want chang updat model folder expens term storag time exampl python sdk wonder similar sdk tri inform net couldn lead greatli thank",
        "Question_gpt_summary_original":"The user is creating an endpoint that chains inference from different models. They are currently loading the models from a single artifact folder registered as a Model in the ML workspace, but updating one model requires re-uploading the entire folder. The user is looking for a solution using the Python SDK v2 to load multiple models individually without having to upload the entire folder.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Error notification not working in background job Neptune Software",
        "Question_body":"<p>For a particular server script, we are adding a background job.\nIn that ,it has an option to add error notification emails ,which is not working.  There is error in my script, which I can see in job log but not getting any notifications on email.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1639300561957,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1649766671956,
        "Question_score_count":0.0,
        "Question_view_count":36.0,
        "Poster_created_time":1583493572323,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70322291",
        "Tool":"Neptune",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error notif work background job softwar particular server script ad background job option add error notif email work error script job log get notif email",
        "Question_preprocessed_content":"notif work background job softwar particular server script background job option notif email work script job log notif email",
        "Question_gpt_summary_original":"The user is facing an issue with error notification emails not working in a background job for a server script. Although there is an error in the script, the user is not receiving any notifications on email.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"PowerBI and MLflow integration (through AzureML)",
        "Question_body":"<p>I'm currently trying to integrate an ML model currently deployed as a webservice on AzureML with PowerBI.<\/p>\n<p>I see that it can be <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#invoking-the-azure-ml-model-in-power-bi\" rel=\"nofollow noreferrer\">integrated<\/a> but the model requires the addition of a schema file when it is <a href=\"https:\/\/docs.microsoft.com\/en-us\/power-bi\/transform-model\/service-machine-learning-integration#schema-discovery-for-machine-learning-models\" rel=\"nofollow noreferrer\">being deployed as a webservice<\/a>. Without this, the model can't be viewed in PowerBI.<\/p>\n<p>The problem that I have come up against is that I use MLflow to log ML model performances and subsequently to deploy a selected model onto AzureML as a webservice using MLflow's AzureML integration - mlflow.azureml.deploy(). This unfortunately doesn't have the option to define a schema file before the model is deployed, thus resulting in no model being available in PowerBI as it lacks the required schema file.<\/p>\n<p>My options seem to be:<\/p>\n<ol>\n<li>Find a workaround, possibly using the working <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-serving\" rel=\"nofollow noreferrer\">REST api of the model in a power query<\/a>.<\/li>\n<li>Rewrite the deployment code and handle the webservice deployment steps in Azure instead of MLflow.<\/li>\n<\/ol>\n<p>I thought I would ask to see if I am maybe missing something as I can't find a workaround using my current code to define a schema file in MLflow when deploying with mlflow.azureml.deploy().<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1600261190477,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1600855880503,
        "Question_score_count":0.0,
        "Question_view_count":405.0,
        "Poster_created_time":1600260166047,
        "Poster_location":null,
        "Poster_reputation_count":15.0,
        "Poster_view_count":4.0,
        "Answer_body":"<p>Point number 2 is the way we solved this issue. Instead of using MLflow to deploy to a scoring service on Azure, we wrote a custom code which load MLflow model when container is initialised.<\/p>\n<p>Scoring code is something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nfrom mlflow.pyfunc import load_model\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef init():\n    global model\n    model = load_model(os.path.join(os.environ.get(&quot;AZUREML_MODEL_DIR&quot;), &quot;awesome_model&quot;))\n\n@input_schema('data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\n\ndef run(data):\n    return model.predict(data)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1600604920243,
        "Answer_last_edit_time":1600855957376,
        "Answer_score_count":0.0,
        "Answerer_created_time":1285219808283,
        "Answerer_location":"Perth WA, Australia",
        "Answerer_reputation_count":6770.0,
        "Answerer_view_count":1127.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63920599",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"powerbi integr current try integr model current deploi webservic powerbi integr model requir addit schema file deploi webservic model view powerbi problem come us log model perform subsequ deploi select model webservic integr deploi unfortun option defin schema file model deploi result model avail powerbi lack requir schema file option workaround possibl work rest api model power queri rewrit deploy code handl webservic deploy step azur instead thought ask mayb miss workaround current code defin schema file deploi deploi",
        "Question_preprocessed_content":"powerbi integr try integr model deploi webservic powerbi integr model requir schema file deploi webservic model view powerbi problem come us log model perform subsequ deploi select model webservic integr unfortun option defin schema file model deploi result model avail powerbi lack requir schema file option workaround work rest api model power queri rewrit deploy code handl webservic deploy step azur instead thought ask mayb workaround code defin schema file deploi",
        "Question_gpt_summary_original":"The user is trying to integrate an ML model deployed as a webservice on AzureML with PowerBI, but the model requires a schema file to be viewed in PowerBI. The user uses MLflow to deploy the model onto AzureML, but MLflow's AzureML integration does not have the option to define a schema file before deployment, resulting in no model being available in PowerBI. The user is considering finding a workaround using the REST API or rewriting the deployment code to handle the webservice deployment steps in Azure instead of MLflow.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Store trained models without wandb as artifacts",
        "Question_body":"<p>Hello wandb community!<\/p>\n<p>I have a large collection of trained models (with pytorch-lightning), but unfortunately without using wandb back then. So, I am wondering if there is a way to store them as artifacts in a model registry.<\/p>\n<p>Thanks in advance! <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1657190270706,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":310.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/store-trained-models-without-wandb-as-artifacts\/2722",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"store train model artifact hello commun larg collect train model pytorch lightn unfortun wonder wai store artifact model registri thank advanc",
        "Question_preprocessed_content":"store train model artifact larg train model unfortun wonder wai store artifact model registri thank advanc",
        "Question_gpt_summary_original":"The user has a collection of trained models with pytorch-lightning, but they were not stored using wandb. The user is seeking advice on how to store these models as artifacts in a model registry.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to assign two or more time series identifier columns in Vertex AI Tabular Forecasting",
        "Question_body":"<p>I was wondering if it is possible to have more than one time series identifier column in the model? Let's assume I'd like to create a forecast at a product and store level (which the documentation suggests should be possible).<\/p>\n<p>If I select product as the series identifier, the only options I have left for store is either a covariate or an attribute and neither is applicable in this scenario.<\/p>\n<p>Would concatenating product and store and using the individual product and store code values for that concatenated ID as attributes be a solution? It doesn't feel right, but I can't see any other option - am I missing something?<\/p>\n<p>Note: I understand that this feature of Vertex AI is currently in preview and that because of that the options may be limited.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1632228068913,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":269.0,
        "Poster_created_time":1519630645620,
        "Poster_location":"Northampton, UK",
        "Poster_reputation_count":333.0,
        "Poster_view_count":46.0,
        "Answer_body":"<p>There isn't an alternate way to assign 2 or more <strong>Time Series Identifiers<\/strong> in the <strong>Forecasting Model<\/strong> on <strong>Vertex AI<\/strong>. The &quot;<strong>Forecasting model<\/strong>&quot; is in the &quot;<strong>Preview<\/strong>&quot; <a href=\"https:\/\/cloud.google.com\/products#product-launch-stages\" rel=\"nofollow noreferrer\">Product launch stage<\/a>, as you are aware, with all consequences of that fact the options are limited. Please refer to this <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/datasets\/bp-tabular#data_preparation_best_practices\" rel=\"nofollow noreferrer\">doc<\/a> for more information about the best practices for data preparation to train the forecasting model.<\/p>\n<p>As a workaround, the two columns can be concatenated and assigned a Time Series Identifier on that concatenated column, as you have mentioned in the question. This way, the concatenated column carries more contextual information into the training of the model.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1632376096768,
        "Answer_last_edit_time":1632482492492,
        "Answer_score_count":2.0,
        "Answerer_created_time":1619174589310,
        "Answerer_location":"Bangalore, Karnataka, India",
        "Answerer_reputation_count":1200.0,
        "Answerer_view_count":804.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69269073",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"assign time seri identifi column tabular forecast wonder possibl time seri identifi column model let assum like creat forecast product store level document suggest possibl select product seri identifi option left store covari attribut applic scenario concaten product store individu product store code valu concaten attribut solut feel right option miss note understand featur current preview option limit",
        "Question_preprocessed_content":"time seri identifi column tabular forecast wonder time seri identifi column model let like creat forecast product store level select product seri identifi option left store covari scenario concaten product store individu product store code valu concaten solut right option note understand featur preview option limit",
        "Question_gpt_summary_original":"The user is facing a challenge in assigning two or more time series identifier columns in Vertex AI Tabular Forecasting. They want to create a forecast at a product and store level, but the only options available for store are either a covariate or an attribute, which are not applicable in this scenario. The user is considering concatenating product and store and using the individual product and store code values for that concatenated ID as attributes, but they are unsure if this is the right solution. The user acknowledges that this feature is currently in preview and the options may be limited.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to package custom prediction code and serve it using an Endpoint in Vertex AI ?",
        "Question_body":"Goal: serve prediction request from a Vertex AI Endpoint by executing custom prediction logic.\n\nExpected Workflow:\n\n1. Upload a pretrained image_quality.pb model (developed in a non vertex-ai pythonic environment) in a gcs bucket\n\n2. Port existing image inference logic into a container and serve the prediction functionality through a vertex AI endpoint.\u00a0\n\n3. Use Vertex AI api for logging and capturing metrics inside the \u00a0custom inference logic.\n\n4. Finally we want to pass a list of images (stored in another gcs bucket) to that endpoint.\n\n5. We also want to see the logs and metrics in tensorboard.\n\nExisting Vertex AI code samples provide examples for custom training , invoking model.batch_predict \/ endpoint.predict , but don't mention how to execute custom prediction code.\n\nIt would be great if someone can provide guidelines and links to documents\/code in order to implement the above steps.\n\nThanks",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1635161760000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":246.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-package-custom-prediction-code-and-serve-it-using-an\/m-p\/173876#M67",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"packag custom predict code serv endpoint goal serv predict request endpoint execut custom predict logic expect workflow upload pretrain imag qualiti model develop non vertex python environ gc bucket port exist imag infer logic contain serv predict function endpoint us api log captur metric insid custom infer logic final want pass list imag store gc bucket endpoint want log metric tensorboard exist code sampl provid exampl custom train invok model batch predict endpoint predict mention execut custom predict code great provid guidelin link document code order implement step thank",
        "Question_preprocessed_content":"packag custom predict code serv endpoint goal serv predict request endpoint execut custom predict logic expect workflow upload pretrain model gc bucket port exist imag infer logic contain serv predict function endpoint us api captur metric insid custom infer logic want list imag endpoint want log metric tensorboard exist code sampl provid exampl custom train invok mention execut custom predict code great provid guidelin link order implement step thank",
        "Question_gpt_summary_original":"The user is seeking guidance on how to package custom prediction code and serve it using an Endpoint in Vertex AI. They have a pretrained model developed in a non-Vertex AI environment and want to port the existing image inference logic into a container to serve the prediction functionality through a Vertex AI endpoint. They also want to use Vertex AI API for logging and capturing metrics inside the custom inference logic and pass a list of images to that endpoint. The user is looking for guidelines and links to documents\/code to implement these steps.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Convert a datatable string from Azure ML WS to an actual Datatable C# Object?",
        "Question_body":"<p>Basically I'm receiving an output like this from my azure ws output:<\/p>\n\n<pre><code>{\n    'Results': {\n        'WSOutput': {\n            'type': 'table',\n            'value': {\n                'ColumnNames': ['ID', 'Start', 'Ask', 'Not', 'Passed', 'Suggest'],\n                'ColumnTypes': ['Int32', 'Int32', 'Int32', 'Double', 'Int64', 'Int32'],\n                'Values': [['13256025', '25000', '19000', '0.35', '1', '25000']]\n            }\n        }\n    }\n}\n<\/code><\/pre>\n\n<p>The string, as you can see, has the info to create a datatable object. Now, I can't seem to find an easy way to cast it to an actual datatable POCO. I'm able to manually code a parser with Newtonsoft.Json.Linq but there has to be an easier way. <\/p>\n\n<p>Does anybody know how? I can't seem to find anything on the net.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":7.0,
        "Question_created_time":1519929782813,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1519930038023,
        "Question_score_count":2.0,
        "Question_view_count":83.0,
        "Poster_created_time":1324654920387,
        "Poster_location":"Waterloo, ON, Canada",
        "Poster_reputation_count":5211.0,
        "Poster_view_count":449.0,
        "Answer_body":"<p>Yes, there is a open source online gernator on the net (<a href=\"http:\/\/jsonutils.com\/\" rel=\"nofollow noreferrer\">http:\/\/jsonutils.com\/<\/a>). Copy paste your result will give you that:<\/p>\n\n<pre><code> public class Value\n    {\n        public IList&lt;string&gt; ColumnNames { get; set; }\n        public IList&lt;string&gt; ColumnTypes { get; set; }\n        public IList&lt;IList&lt;string&gt;&gt; Values { get; set; }\n    }\n\n    public class WSOutput\n    {\n        public string type { get; set; }\n        public Value value { get; set; }\n    }\n\n    public class Results\n    {\n        public WSOutput WSOutput { get; set; }\n    }\n\n    public class Example\n    {\n        public Results Results { get; set; }\n    }\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1519929928907,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1327234712912,
        "Answerer_location":"Germany",
        "Answerer_reputation_count":53015.0,
        "Answerer_view_count":3262.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49056593",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"convert datat string actual datat object basic receiv output like azur output result wsoutput type tabl valu columnnam start ask pass suggest columntyp int int int doubl int int valu string info creat datat object easi wai cast actual datat poco abl manual code parser newtonsoft json linq easier wai anybodi know net",
        "Question_preprocessed_content":"convert datat string actual datat object receiv output like azur output string info creat datat object easi wai cast actual datat poco abl code parser easier wai anybodi know net",
        "Question_gpt_summary_original":"The user is having trouble converting a datatable string received from Azure ML WS into an actual Datatable C# object. The string contains the necessary information to create a datatable object, but the user is unable to find an easy way to cast it. The user has tried manually coding a parser with Newtonsoft.Json.Linq but is looking for an easier solution.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Undo 'dvc add' operation",
        "Question_body":"<p>I <code>dvc add<\/code>-ed a file I did not mean to add. I have not yet committed.<\/p>\n\n<p>How do I undo this operation? In Git, you would do <code>git rm --cached &lt;filename&gt;<\/code>.<\/p>\n\n<p>To be clear: I want to make DVC forget about the file, and I want the file to remain untouched in my working tree. This is the opposite of what <code>dvc remove<\/code> does.<\/p>\n\n<p>One <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/1524\" rel=\"nofollow noreferrer\">issue<\/a> on the DVC issue tracker suggests that <code>dvc unprotect<\/code> is the right command. But reading the <a href=\"https:\/\/dvc.org\/doc\/commands-reference\/unprotect\" rel=\"nofollow noreferrer\">manual page<\/a> suggests otherwise.<\/p>\n\n<p>Is this possible with DVC?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1568689927047,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":1304.0,
        "Poster_created_time":1383611307000,
        "Poster_location":"New York",
        "Poster_reputation_count":10846.0,
        "Poster_view_count":984.0,
        "Answer_body":"<p>As per mroutis on the DVC Discord server:<\/p>\n\n<ol>\n<li><code>dvc unprotect<\/code> the file; this won't be necessary if you don't use <code>symlink<\/code> or <code>hardlink<\/code> caching, but it can't hurt.<\/li>\n<li>Remove the .dvc file<\/li>\n<li>If you need to delete the cache entry itself, run <code>dvc gc<\/code>, or look up the MD5 in <code>data.dvc<\/code> and manually remove it from <code>.dvc\/cache<\/code>.<\/li>\n<\/ol>\n\n<p><em>Edit<\/em> -- there is now an issue on their Github page to add this to the manual: <a href=\"https:\/\/github.com\/iterative\/dvc.org\/issues\/625\" rel=\"nofollow noreferrer\">https:\/\/github.com\/iterative\/dvc.org\/issues\/625<\/a><\/p>",
        "Answer_comment_count":6.0,
        "Question_closed_time":1568693889196,
        "Answer_last_edit_time":1568725966083,
        "Answer_score_count":7.0,
        "Answerer_created_time":1383611307000,
        "Answerer_location":"New York",
        "Answerer_reputation_count":10846.0,
        "Answerer_view_count":984.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57966851",
        "Tool":"DVC",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"undo add oper add file mean add commit undo oper git git cach clear want forget file want file remain untouch work tree opposit remov issu issu tracker suggest unprotect right command read manual page suggest possibl",
        "Question_preprocessed_content":"undo oper file mean undo oper git clear want forget file want file remain untouch work tracker right read manual page",
        "Question_gpt_summary_original":"The user accidentally added a file using the 'dvc add' command and wants to undo the operation without affecting the file in the working tree. They are seeking guidance on how to make DVC forget about the file, and are unsure if 'dvc unprotect' is the right command to use.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How do you load an existing S3 bucket in Sagemaker using R Programming?",
        "Question_body":"<p>I know how to use python to load an existing s3 bucket in sage maker using R. Something like this:<\/p>\n\n<pre><code>role = get_execution_role()\nregion = boto3.Session().region_name\nbucket='existing S3 Bucket' \ndata_key = 'Data file in the existing s3 bucket'\ndata_location = 's3:\/\/{}\/{}'.format(bucket, data_key)\n<\/code><\/pre>\n\n<p>How can one recreate this using R in Sage maker? All i see in the available documentation is how to create a new bucket but none of it mentions how to use an existing S3 bucket. Help would be appreciated.<\/p>\n\n<p>link to documentation for R in sage maker:\n<a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-r-with-amazon-sage\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-r-with-amazon-sage<\/a> maker\/<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1575069896083,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":1591.0,
        "Poster_created_time":1575069492660,
        "Poster_location":null,
        "Poster_reputation_count":31.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59111930",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"load exist bucket program know us python load exist bucket sage maker like role execut role region boto session region bucket exist bucket data kei data file exist bucket data locat format bucket data kei recreat sage maker avail document creat new bucket mention us exist bucket help appreci link document sage maker http aw amazon com blog machin learn amazon sage maker",
        "Question_preprocessed_content":"load exist bucket know us python load exist bucket sage maker like recreat sage maker avail document creat new bucket mention us exist bucket help link document sage maker maker",
        "Question_gpt_summary_original":"The user is seeking help to load an existing S3 bucket in SageMaker using R programming. They have provided a Python code snippet for reference but are unable to find any documentation on how to do the same in R. The user is requesting assistance in recreating the Python code in R.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Optuna catboost pruning",
        "Question_body":"<p>is there a way to have pruning with CatBoost and Optuna (in LightGBM it's easy but in Catboost I can't find any hint).\nMy code is like this<\/p>\n<pre><code>def objective(trial):\n    param = {\n        'iterations':trial.suggest_int('iterations', 100,1500, step=100),\n        'learning_rate':trial.suggest_uniform(&quot;learning_rate&quot;, 0.001, 0.3),\n        'random_strength':trial.suggest_int(&quot;random_strength&quot;, 1,10),\n        'max_bin':trial.suggest_categorical('max_bin', [2,3,4,5,6,8,10,20,30]),\n        'grow_policy':trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),        \n        &quot;colsample_bylevel&quot;: trial.suggest_uniform(&quot;colsample_bylevel&quot;, 0.1, 1),\n        'od_type' : &quot;Iter&quot;,\n        'od_wait' : 30,\n        &quot;depth&quot;: trial.suggest_int(&quot;max_depth&quot;, 1,12),\n        &quot;l2_leaf_reg&quot;: trial.suggest_loguniform(&quot;l2_leaf_reg&quot;, 1e-8, 100),\n        'custom_metric' : ['AUC'],\n        &quot;loss_function&quot;: &quot;Logloss&quot;,\n        }\n    \n    if param['grow_policy'] == &quot;SymmetricTree&quot;: \n        param[&quot;boosting_type&quot;]= trial.suggest_categorical(&quot;boosting_type&quot;, [&quot;Ordered&quot;, &quot;Plain&quot;])\n    else:\n        param[&quot;boosting_type&quot;] = &quot;Plain&quot;\n        \n    # Added subsample manually\n    param[&quot;subsample&quot;] = trial.suggest_float(&quot;subsample&quot;, 0.1, 1)\n\n### CV ###\n\n    # How to add a callback for pruning?\n    scores = cv(train_dataset,\n            param,\n            fold_count=5, \n            early_stopping_rounds=30,         \n            plot=False, verbose=False)\n    \n    return scores['test-AUC-mean'].mean()\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1615153279437,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1238.0,
        "Poster_created_time":1487099213112,
        "Poster_location":null,
        "Poster_reputation_count":138.0,
        "Poster_view_count":21.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66521731",
        "Tool":"Optuna",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"catboost prune wai prune catboost lightgbm easi catboost hint code like def object trial param iter trial suggest int iter step learn rate trial suggest uniform learn rate random strength trial suggest int random strength max bin trial suggest categor max bin grow polici trial suggest categor grow polici symmetrictre depthwis lossguid colsampl bylevel trial suggest uniform colsampl bylevel type iter wait depth trial suggest int max depth leaf reg trial suggest loguniform leaf reg custom metric auc loss function logloss param grow polici symmetrictre param boost type trial suggest categor boost type order plain param boost type plain ad subsampl manual param subsampl trial suggest float subsampl add callback prune score train dataset param fold count earli stop round plot fals verbos fals return score test auc mean mean",
        "Question_preprocessed_content":"prune wai prune code like",
        "Question_gpt_summary_original":"The user is trying to implement pruning with CatBoost and Optuna, but is unable to find any hints on how to do so. They have provided their code and are specifically looking for guidance on how to add a callback for pruning.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to use Azure DevOps artifacts repository as source for DatabricksStep of AzureML?",
        "Question_body":"<p>If we have PyPi Packages added as Artifacts to an Azure DevOps Project Feed, how can we use these packages as a source for installing packages in <code>DatabricksStep<\/code> of Azure Machine Learning Service?<\/p>\n<p>While using <code>pip<\/code> in any environment, we use our Azure DevOps Project Artifacts feed in the following way:<\/p>\n<pre><code>pip install example-package --index-url=https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/\n<\/code><\/pre>\n<p>The DatabricksStep class of the Azure Machine Learning Service accepts the following parameters:<\/p>\n<pre><code>python_script_name = &quot;&lt;Some-Script&gt;.py&quot;\nsource_directory = &quot;&lt;Path-To-Script&gt;&quot;\n\n&lt;Some-Placeholder-Name-for-the-step&gt; = DatabricksStep(\n    name=&lt;Some-Placeholder-Name-for-the-step&gt;,\n    num_workers=1,\n    python_script_name=python_script_name,\n    source_directory=source_directory,\n    run_name= &lt;Name-of-the-run&gt;,\n    compute_target=databricks_compute,\n    pypi_libraries = [\n                      PyPiLibrary(package = 'scikit-learn'), \n                      PyPiLibrary(package = 'scipy'), \n                      PyPiLibrary(package = 'azureml-sdk'), \n                      PyPiLibrary(package = 'joblib'), \n                      PyPiLibrary(package = 'azureml-dataprep[pandas]'),\n                      PyPiLibrary(package = 'example-package', repo='https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/')\n                    ], \n\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>However, <code>PyPiLibrary(package = 'example-package', repo='https:\/\/&lt;Personal-Access-Token&gt;@pkgs.dev.azure.com\/&lt;Organization-Name&gt;\/_packaging\/&lt;Artifacts-Feed-Name&gt;\/pypi\/simple\/')<\/code> will give an error. How exactly should we consume the Artifacts Feed as an input to the <code>PyPiLibrary<\/code> property of the <code>DatabricksStep<\/code> Class in Azure Machine Learning Service?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1611234834813,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":5.0,
        "Question_view_count":341.0,
        "Poster_created_time":1601729162436,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":887.0,
        "Poster_view_count":130.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65828200",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us azur devop artifact repositori sourc databricksstep pypi packag ad artifact azur devop project feed us packag sourc instal packag databricksstep servic pip environ us azur devop project artifact feed follow wai pip instal exampl packag index url http pkg dev azur com packag pypi simpl databricksstep class servic accept follow paramet python script sourc directori databricksstep num worker python script python script sourc directori sourc directori run comput target databrick comput pypi librari pypilibrari packag scikit learn pypilibrari packag scipi pypilibrari packag sdk pypilibrari packag joblib pypilibrari packag dataprep panda pypilibrari packag exampl packag repo http pkg dev azur com packag pypi simpl allow reus true pypilibrari packag exampl packag repo http pkg dev azur com packag pypi simpl error exactli consum artifact feed input pypilibrari properti databricksstep class servic",
        "Question_preprocessed_content":"us azur devop artifact repositori sourc pypi packag artifact azur devop project us packag sourc packag servic environ us azur devop project artifact wai servic paramet exactli consum artifact input properti servic",
        "Question_gpt_summary_original":"The user is trying to use PyPi packages added as Artifacts to an Azure DevOps Project Feed as a source for installing packages in DatabricksStep of Azure Machine Learning Service. They are encountering an error while trying to consume the Artifacts Feed as an input to the PyPiLibrary property of the DatabricksStep Class in Azure Machine Learning Service.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure Data Factory : How to pass DataPath as a parameter to Azure ML Pipeline activity?",
        "Question_body":"<p>Hello All,  <\/p>\n<p>How to pass a Datapath as a parameter in Azure ML Pipeline activity?   <\/p>\n<p>More details here : Have opened an issue here : <a href=\"https:\/\/github.com\/Azure\/Azure-DataFactory\/issues\/216\">https:\/\/github.com\/Azure\/Azure-DataFactory\/issues\/216<\/a>  <\/p>\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4.0,
        "Question_created_time":1599771191990,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Thanks <a href=\"\/users\/na\/?userid=1e1dfdb6-a824-42dc-8b1c-8e2c3f669d59\">@Sriram Narayanan  <\/a> for your patience!    <\/p>\n<p>I discussed with the Product team and they confirmed that there is no datatype supported for &quot;DataPath&quot; parameter today in Azure Data Factory(ADF). However, there is a feature already raised for the same and work is in progress for it.     <\/p>\n<p>I would recommend you also to submit an idea in <a href=\"https:\/\/feedback.azure.com\/forums\/270578-data-factory\">feedback forum<\/a>. The ideas in this forum are closely monitored by data factory product team and will prioritize implementing them in future releases.    <\/p>\n<p>Sorry for the inconvenience!     <\/p>\n",
        "Answer_comment_count":8.0,
        "Question_closed_time":1601023399256,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/91785\/azure-data-factory-how-to-pass-datapath-as-a-param",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"azur data factori pass datapath paramet pipelin activ hello pass datapath paramet pipelin activ detail open issu http github com azur azur datafactori issu thank",
        "Question_preprocessed_content":"azur data factori datapath paramet pipelin activ datapath paramet pipelin activ detail open thank",
        "Question_gpt_summary_original":"The user is seeking help on how to pass a Datapath as a parameter in Azure ML Pipeline activity and has opened an issue on GitHub for assistance.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"how i can recover my compute instance ?",
        "Question_body":"<p>error: The specified Azure ML Compute Instance cs-bi-cloud2 encountered an unusable node. Please try to restart the compute instance to recover. If it failed at creation time, please delete and try to recreate the compute instance. If the problem persists, please follow up with Azure Suppor    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/210912-image.png?platform=QnA\" alt=\"210912-image.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1655132409567,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/887255\/how-i-can-recover-my-compute-instance",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"recov comput instanc error specifi comput instanc cloud encount unus node try restart comput instanc recov fail creation time delet try recreat comput instanc problem persist follow azur suppor",
        "Question_preprocessed_content":"recov comput instanc specifi comput instanc encount unus node try restart comput instanc recov fail creation time delet try recreat comput instanc problem persist azur",
        "Question_gpt_summary_original":"The user's Azure ML Compute Instance, cs-bi-cloud2, encountered an unusable node and needs to be restarted or recreated. If the problem persists, the user should contact Azure Support.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Free tier usage Sagemaker",
        "Question_body":"Hi, I have a question about the free tier usage of AWS Sagemaker.   \nIt says on the free tier page:   \n  \nAmazon SageMaker  \n250 Hours  \nper month of t2.medium notebook usage for the first two months  \n  \nDoes this mean that you have to start using Sagemaker right away when you start your account or your two months will be void? Or does this mean that the first two months you're using Sagemaker, up to 250 hours per month of t2.medium notebook usage is free?  \n  \nI really just want to test something but I have to know if I can still do this for free. I've had my account since september 2018 so >2 months.   \n  \nThe FAQ page that's referred to about expiring offers FREE TRIAL (What's the difference between expiring and non-expiring offers? VIEW FAQs >> https:\/\/aws.amazon.com\/free\/faqs\/?ft=n) doesn't give an answer to my question.   \n  \nThanks in advance.",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1548335489000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668454454976,
        "Question_score_count":0.0,
        "Question_view_count":326.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUWzc5HuoeQZOuo79E8SQwxg\/free-tier-usage-sagemaker",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"free tier usag question free tier usag sai free tier page hour month medium notebook usag month mean start right awai start account month void mean month hour month medium notebook usag free want test know free account septemb month faq page refer expir offer free trial differ expir non expir offer view faq http aw amazon com free faq answer question thank advanc",
        "Question_preprocessed_content":"tier usag question tier usag sai tier page hour month usag month mean start right awai start month void mean month hour month usag want test know septemb month faq page expir trial answer question thank advanc",
        "Question_gpt_summary_original":"The user is inquiring about the free tier usage of AWS Sagemaker and is unsure if they can still use it for free after the first two months. They are seeking clarification on whether the 250 hours per month of t2.medium notebook usage is only applicable during the first two months of account creation or if it can be used anytime within the free tier period. The user has checked the FAQ page but did not find an answer to their question.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Use an Azure ML compute cluster to run Kedro + Mlflow pipeline",
        "Question_body":"<p>I want to use an Azure Machine Learning compute cluster as a compute target to run a Kedro pipeline integrated with Mlflow.<\/p>\n<p>Here's the code snippet (hooks.py) that integrates experiment tracking using Mlflow and Azure ML as backend\/artifact stores.<\/p>\n<pre><code>&quot;&quot;&quot;Project hooks.&quot;&quot;&quot;\nfrom typing import Any, Dict, Iterable, Optional\nimport git\nimport os\nimport mlflow\nimport mlflow.sklearn\nfrom kedro.config import ConfigLoader\nfrom kedro.framework.hooks import hook_impl\nfrom kedro.io import DataCatalog\nfrom kedro.pipeline.node import Node\nfrom kedro.versioning import Journal\nfrom azureml.core import Workspace\nfrom azureml.core.experiment import Experiment\n\nclass ProjectHooks:\n    @hook_impl\n    def register_config_loader(\n        self,\n        conf_paths: Iterable[str],\n        env: str,\n        extra_params: Dict[str, Any],\n    ) -&gt; ConfigLoader:\n        return ConfigLoader(conf_paths)\n\n    @hook_impl\n    def register_catalog(\n        self,\n        catalog: Optional[Dict[str, Dict[str, Any]]],\n        credentials: Dict[str, Dict[str, Any]],\n        load_versions: Dict[str, str],\n        save_version: str,\n        journal: Journal,\n    ) -&gt; DataCatalog:\n        return DataCatalog.from_config(\n            catalog, credentials, load_versions, save_version, journal\n        )\n\n\nclass ModelTrackingHooks:\n    &quot;&quot;&quot;Namespace for grouping all model-tracking hooks with MLflow together.&quot;&quot;&quot;\n\n    @hook_impl\n    def before_pipeline_run(self, run_params: Dict[str, Any]) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to start an MLflow run\n        with the same run_id as the Kedro pipeline run.\n        &quot;&quot;&quot;\n\n        # Get Azure workspace\n        ws = Workspace.get(name=workspace_name,\n                           subscription_id=subscription_id,\n                           resource_group=resource_group)\n\n        # Set tracking uri\n        mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n\n        # Create an Azure ML experiment in the workspace\n        experiment = Experiment(workspace=ws, name='kedro-mlflow-experiment')\n        mlflow.set_experiment(experiment.name)\n\n        mlflow.start_run(run_name=run_params[&quot;run_id&quot;])\n        mlflow.log_params(run_params)\n\n    @hook_impl\n    def after_node_run(\n        self, node: Node, outputs: Dict[str, Any], inputs: Dict[str, Any]\n    ) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to add model tracking after some node runs.\n        In this example, we will:\n        * Log the parameters after the data splitting node runs.\n        * Log the model after the model training node runs.\n        * Log the model's metrics after the model evaluating node runs.\n        &quot;&quot;&quot;\n        if node._func_name == &quot;function_name&quot;:\n            mlflow.log_metrics(...)\n\n    @hook_impl\n    def after_pipeline_run(self) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to end the MLflow run\n        after the Kedro pipeline finishes.\n        &quot;&quot;&quot;\n        mlflow.end_run()\n<\/code><\/pre>\n<p>This works well on a <strong>compute instance<\/strong> that I created in my Azure ML workspace, simply by doing the following :<\/p>\n<ol>\n<li><code>git clone<\/code> the source code into the Azure ML compute instance<\/li>\n<li>Do a <code>kedro run<\/code> in the compute instance Terminal<\/li>\n<\/ol>\n<p>That's ok but what I really want is to use <strong>compute clusters<\/strong> to deal with hyperparameter tuning and other heavy workloads... I Just want to mention here that I still want to git clone to the compute instance and submit the run to the compute cluster from within the compute instance (but if anyone has a better approach, please feel free to share).<\/p>\n<p>I know of two ways (listed below) to specify a compute cluster as a compute target in Azure ML but both require to pass a <code>script<\/code> parameter.<\/p>\n<ol>\n<li>Pure Azure ML <code>ScriptRunConfig()<\/code> method to submit experiments by specifying <code>script<\/code> and <code>compute_target<\/code> parameters. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Submit remote run with Azure Ml<\/a><\/li>\n<li>Mlflow integration with Azure ML : that requires to add an MLproject file to the project folder. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-mlflow-projects\" rel=\"nofollow noreferrer\">Submit an mlflow project run<\/a>.<\/li>\n<\/ol>\n<p>I tried for quite some time now to figure out how to do that within the Kedro structure but without success. So my question here, what's the best way to push experiment runs in a Kedro Pipeline to Azure ML compute clusters?<\/p>\n<p>Thank you in advance for your help !<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1639418195970,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1639471244520,
        "Question_score_count":1.0,
        "Question_view_count":271.0,
        "Poster_created_time":1586517832390,
        "Poster_location":null,
        "Poster_reputation_count":127.0,
        "Poster_view_count":20.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70338955",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us comput cluster run pipelin want us comput cluster comput target run pipelin integr code snippet hook integr experi track backend artifact store project hook type import dict iter option import git import import import sklearn config import configload framework hook import hook impl import datacatalog pipelin node import node version import journal core import workspac core experi import experi class projecthook hook impl def regist config loader self conf path iter str env str extra param dict str configload return configload conf path hook impl def regist catalog self catalog option dict str dict str credenti dict str dict str load version dict str str save version str journal journal datacatalog return datacatalog config catalog credenti load version save version journal class modeltrackinghook namespac group model track hook hook impl def pipelin run self run param dict str hook implement start run run pipelin run azur workspac workspac workspac subscript subscript resourc group resourc group set track uri set track uri track uri creat experi workspac experi experi workspac experi set experi experi start run run run param run log param run param hook impl def node run self node node output dict str input dict str hook implement add model track node run exampl log paramet data split node run log model model train node run log model metric model evalu node run node func function log metric hook impl def pipelin run self hook implement end run pipelin finish end run work comput instanc creat workspac simpli follow git clone sourc code comput instanc run comput instanc termin want us comput cluster deal hyperparamet tune heavi workload want mention want git clone comput instanc submit run comput cluster comput instanc better approach feel free share know wai list specifi comput cluster comput target requir pass script paramet pure scriptrunconfig method submit experi specifi script comput target paramet submit remot run integr requir add mlproject file project folder submit project run tri time figur structur success question best wai push experi run pipelin comput cluster thank advanc help",
        "Question_preprocessed_content":"us comput cluster run pipelin want us comput cluster comput target run pipelin integr code integr experi track store work comput instanc creat workspac simpli sourc code comput instanc comput instanc termin want us comput cluster deal hyperparamet tune heavi want mention want git clone comput instanc submit run comput cluster comput instanc know wai specifi comput cluster comput target requir paramet pure method submit experi specifi paramet submit remot run integr requir mlproject file project folder submit project run tri time figur structur question best wai push experi run pipelin comput cluster thank advanc help",
        "Question_gpt_summary_original":"The user wants to use an Azure Machine Learning compute cluster as a compute target to run a Kedro pipeline integrated with Mlflow. They have successfully integrated experiment tracking using Mlflow and Azure ML as backend\/artifact stores on a compute instance. However, they are struggling to use compute clusters for hyperparameter tuning and other heavy workloads. The user is seeking advice on the best way to push experiment runs in a Kedro Pipeline to Azure ML compute clusters.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"DTMF updation through client sdk",
        "Question_body":"can we update DTMF values through client SDK from backend?. if yes how?",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1677109620000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":64.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/DTMF-updation-through-client-sdk\/m-p\/525382#M1318",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"dtmf updat client sdk updat dtmf valu client sdk backend ye",
        "Question_preprocessed_content":"dtmf updat client sdk updat dtmf valu client sdk backend ye",
        "Question_gpt_summary_original":"The user is inquiring about the possibility of updating DTMF values through client SDK from the backend and is seeking guidance on how to do so.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Make custom kernels available to SageMaker Studio notebooks",
        "Question_body":"<p>On starting the SageMaker Studio server, I can only see a set of predefined kernels when\nI select kernel for any notebook.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/pGJIw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/pGJIw.png\" alt=\"Predefined Kernels\" \/><\/a><\/p>\n<p>I create conda environments and persist them between sessions by pointing <code>.condarc<\/code> to a custom miniconda directory stored on EFS.<\/p>\n<p>I want all notebooks to have access to environments stored in the custom miniconda directory. I can do that on the system terminal but can't seem to find a way to make the kernels available to notebooks.<\/p>\n<p>I am aware of <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/notebook-lifecycle-config.html\" rel=\"nofollow noreferrer\">Life Cycle Configuration<\/a> but that seems to be working only with notebooks instances rather than SageMaker Studio.<\/p>\n<p><strong>Desired outcomes<\/strong><\/p>\n<p>Ideally making custom kernels persistently available to notebooks but if that isn't feasible or requires custom docker image, I am happy with running a script manually every time I run the server.<\/p>\n<p><strong>What I have tried so far:<\/strong><\/p>\n<p>I ran the following which is a tweaked version of <a href=\"https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/blob\/master\/scripts\/persistent-conda-ebs\/on-start.sh\" rel=\"nofollow noreferrer\">start.sh<\/a> meant to be for Life Cycle Configuration.<\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>#!\/bin\/bash\n\nset -e\n\nsudo -u sagemaker-user -i &lt;&lt;'EOF'\nunset SUDO_UID\nWORKING_DIR=\/home\/sagemaker-user\/.SageMaker\/custom-miniconda\/\nsource \"$WORKING_DIR\/miniconda\/bin\/activate\"\nfor env in $WORKING_DIR\/miniconda\/envs\/*; do\n    BASENAME=$(basename \"$env\")\n    source activate \"$BASENAME\"\n    python -m ipykernel install --user --name \"$BASENAME\" --display-name \"$BASENAME\"\ndone\n\nEOF<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p>That didn't work and I couldn't access the kernels from the notebooks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1631856553007,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1616.0,
        "Poster_created_time":1398880184052,
        "Poster_location":null,
        "Poster_reputation_count":2245.0,
        "Poster_view_count":213.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69218162",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"custom kernel avail studio notebook start studio server set predefin kernel select kernel notebook creat conda environ persist session point condarc custom miniconda directori store ef want notebook access environ store custom miniconda directori termin wai kernel avail notebook awar life cycl configur work notebook instanc studio desir outcom ideal make custom kernel persist avail notebook isn feasibl requir custom docker imag happi run script manual time run server tri far ran follow tweak version start meant life cycl configur bin bash set sudo user eof unset sudo uid work dir home user custom miniconda sourc work dir miniconda bin activ env work dir miniconda env basenam basenam env sourc activ basenam python ipykernel instal user basenam displai basenam eof work couldn access kernel notebook",
        "Question_preprocessed_content":"custom kernel avail studio start studio server set predefin kernel select kernel creat conda environ persist point custom miniconda directori store ef want environ store custom miniconda directori termin wai kernel avail awar life cycl configur work instanc studio desir outcom make custom kernel persist avail isn feasibl requir custom docker imag script time run server tri far ran tweak version meant life cycl configur work couldn kernel",
        "Question_gpt_summary_original":"The user is facing an issue with SageMaker Studio where they can only see predefined kernels and cannot access custom kernels stored in a custom miniconda directory. They have tried persisting the environments between sessions using .condarc but cannot find a way to make the kernels available to notebooks. The user has tried running a tweaked version of start.sh but it did not work. They are looking for a solution to make custom kernels persistently available to notebooks or are willing to run a script manually every time they run the server.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML Designer- Language Detection",
        "Question_body":"<p>Hello,    <\/p>\n<p>We have a clustering model in AzureML designer and we are using the &quot;Preprocess Text&quot; component to clean the messages.    <br \/>\nBut, the messages can be in different languages and in the dropdown of the Language in the &quot;Preprocess Text&quot; component there is only English and no other language. Is there a way to detect the language of a text in azureml designer?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/182400-capture.png?platform=QnA\" alt=\"182400-capture.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1647103939673,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/769728\/azure-ml-designer-language-detection",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"design languag detect hello cluster model design preprocess text compon clean messag messag differ languag dropdown languag preprocess text compon english languag wai detect languag text design",
        "Question_preprocessed_content":"design languag detect cluster model design text compon clean languag dropdown languag text compon english languag wai detect languag text design",
        "Question_gpt_summary_original":"The user is facing a challenge in AzureML designer while using the \"Preprocess Text\" component to clean messages as the dropdown for language detection only has English and not other languages. The user is looking for a way to detect the language of a text in AzureML designer.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Deploy Azure ML Designer Web Service model",
        "Question_body":"<p>Im trying to run R code to detect outliers in datasets.\nIm trying to publish as a webservice so it can be used to pre process data.<\/p>\n\n<p>In Azure ML Designer,I have a Execute R script which contains my model.<\/p>\n\n<p>When I try to publish as a web service I get the error \"Cannot create inference because there is no model on this pipeline\".\nI see python has a Create Python module.<\/p>\n\n<p>Can I use an Execute R Script to create a webservice with my model?<\/p>\n\n<p>Im good at R and still learning Azure and would really appreciate some advice on. the above.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1583419993597,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":244.0,
        "Poster_created_time":1542820108076,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60548089",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi design web servic model try run code detect outlier dataset try publish webservic pre process data design execut script contain model try publish web servic error creat infer model pipelin python creat python modul us execut script creat webservic model good learn azur appreci advic",
        "Question_preprocessed_content":"deploi design web servic model try run code detect outlier dataset try publish webservic pre data design execut script contain model try publish web servic creat infer model pipelin python creat python modul us execut script creat webservic model learn azur advic",
        "Question_gpt_summary_original":"The user is trying to deploy an R code to detect outliers in datasets as a web service using Azure ML Designer. However, when trying to publish the web service, they receive an error message stating that there is no model on the pipeline. The user is seeking advice on whether they can use an Execute R Script to create a web service with their model.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"amazon-sagemaker-lab:: libXrender.so.1 package",
        "Question_body":"<p>I am trying to use the amazon sagemaker lab environment and the package libXrender is not installed.<\/p>\n<p>sudo privileges are removed and it's not possible to install it with:<\/p>\n<p><code>apt-get install libxrender1<\/code><\/p>\n<p>Is there an easy fix or do I have to contact their support to install the package in their docker container?<\/p>\n<p>Thanks in advance!<\/p>\n<p>Error results from this piece of code:<\/p>\n<pre><code>from rdkit.Chem.Draw import rdMolDraw2D\nfrom rdkit.Chem.Draw.rdMolDraw2D import *\n\nImportError: libXrender.so.1: cannot open shared object file: No such file or directory\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1656667948847,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":77.0,
        "Poster_created_time":1465911951740,
        "Poster_location":"Cambridge, UK",
        "Poster_reputation_count":1.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72827239",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"amazon lab libxrend packag try us lab environ packag libxrend instal sudo privileg remov possibl instal apt instal libxrend easi fix contact support instal packag docker contain thank advanc error result piec code rdkit chem draw import rdmoldrawd rdkit chem draw rdmoldrawd import importerror libxrend open share object file file directori",
        "Question_preprocessed_content":"packag try us lab environ packag libxrend sudo privileg remov easi fix contact packag docker contain thank advanc result piec code",
        "Question_gpt_summary_original":"The user is facing an issue with the Amazon SageMaker lab environment where the libXrender package is not installed. The user does not have sudo privileges to install it using \"apt-get install libxrender1\". The error is caused by a missing libXrender.so.1 file while running a code related to rdkit.Chem.Draw. The user is seeking an easy fix or support from Amazon to install the package in their docker container.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to predict train model time",
        "Question_body":"<p>How to predict the time for train model for data with 10 millions lines and zero columns with decision tree?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1653903513477,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/869641\/how-to-predict-train-model-time",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"predict train model time predict time train model data million line zero column decis tree",
        "Question_preprocessed_content":"predict train model time predict time train model data line zero column decis",
        "Question_gpt_summary_original":"The user is seeking guidance on how to predict the time it will take to train a decision tree model on a dataset with 10 million lines and zero columns.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML: Upload File to Step Run's Output - Authentication Error",
        "Question_body":"<p>During a PythonScriptStep in an Azure ML Pipeline, I'm saving a model as joblib pickle dump to a directory in a Blob Container in the Azure Blob Storage which I've created during the setup of the Azure ML Workspace. Afterwards I'm trying to upload this model file to the step run's output directory using<\/p>\n<pre><code>Run.upload_file (name, path_or_stream)\n<\/code><\/pre>\n<p>(for the function's documentation, see <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#upload-file-name--path-or-stream--datastore-name-none-\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#upload-file-name--path-or-stream--datastore-name-none-<\/a>)<\/p>\n<p>Some time ago when I created the script using the azureml-sdk version 1.18.0, everything worked fine. Now, I've updated the script's functionalities and upgraded the azureml-sdk to version 1.33.0 during the process and the upload function now runs into the following error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 64, in upload_blob_from_stream\n    validate_content=True)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 93, in execute_func_with_reset\n    return ClientBase._execute_func_internal(backoff, retries, module_logger, func, reset_func, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 367, in _execute_func_internal\n    left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 399, in _handle_retry\n    raise error\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py&quot;, line 358, in _execute_func_internal\n    response = func(*args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py&quot;, line 614, in create_blob_from_stream\n    initialization_vector=iv\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 98, in _upload_blob_chunks\n    range_ids = [f.result() for f in futures]\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 98, in &lt;listcomp&gt;\n    range_ids = [f.result() for f in futures]\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/_base.py&quot;, line 435, in result\n    return self.__get_result()\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/_base.py&quot;, line 384, in __get_result\n    raise self._exception\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 210, in process_chunk\n    return self._upload_chunk_with_progress(chunk_offset, chunk_bytes)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 224, in _upload_chunk_with_progress\n    range_id = self._upload_chunk(chunk_offset, chunk_data)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py&quot;, line 269, in _upload_chunk\n    timeout=self.timeout,\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py&quot;, line 1013, in _put_block\n    self._perform_request(request)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 432, in _perform_request\n    raise ex\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 357, in _perform_request\n    raise ex\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py&quot;, line 343, in _perform_request\n    HTTPError(response.status, response.message, response.headers, response.body))\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/_error.py&quot;, line 115, in _http_error_handler\n    raise ex\nazure.common.AzureHttpError: Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n\n2019-07-07\nb\n\n&lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/...\/azureml-setup\/context_manager_injector.py&quot;, line 243, in execute_with_context\n    runpy.run_path(sys.argv[0], globals(), run_name=&quot;__main__&quot;)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 263, in run_path\n    pkg_name=pkg_name, script_name=fname)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 96, in _run_module_code\n    mod_name, mod_spec, pkg_name, script_name)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/runpy.py&quot;, line 85, in _run_code\n    exec(code, run_globals)\n  File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 318, in &lt;module&gt;\n    main()\n  File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 286, in main\n    path_or_stream=model_path)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 53, in wrapped\n    return func(self, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 1989, in upload_file\n    datastore_name=datastore_name)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 114, in upload_artifact\n    return self.upload_artifact_from_path(artifact, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 107, in upload_artifact_from_path\n    return self.upload_artifact_from_stream(stream, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 99, in upload_artifact_from_stream\n    content_type=content_type, session=session)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 88, in upload_stream_to_existing_artifact\n    timeout=TIMEOUT, backoff=BACKOFF_START, retries=RETRY_LIMIT)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 71, in upload_blob_from_stream\n    raise AzureMLException._with_error(azureml_error, inner_exception=e)\nazureml._common.exceptions.AzureMLException: AzureMLException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n\n2019-07-07\nb\n\n&lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: mystorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;Auth&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;Authorization&quot;\n            }\n        }\n    }\n}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 318, in &lt;module&gt;\n    main()\n  File &quot;401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py&quot;, line 286, in main\n    path_or_stream=model_path)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 53, in wrapped\n    return func(self, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py&quot;, line 1989, in upload_file\n    datastore_name=datastore_name)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 114, in upload_artifact\n    return self.upload_artifact_from_path(artifact, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 107, in upload_artifact_from_path\n    return self.upload_artifact_from_stream(stream, *args, **kwargs)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 99, in upload_artifact_from_stream\n    content_type=content_type, session=session)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py&quot;, line 88, in upload_stream_to_existing_artifact\n    timeout=TIMEOUT, backoff=BACKOFF_START, retries=RETRY_LIMIT)\n  File &quot;\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py&quot;, line 71, in upload_blob_from_stream\n    raise AzureMLException._with_error(azureml_error, inner_exception=e)\nUserScriptException: UserScriptException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException AzureMLException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;Error&gt;&lt;Code&gt;AuthenticationFailed&lt;\/Code&gt;&lt;Message&gt;Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z&lt;\/Message&gt;&lt;AuthenticationErrorDetail&gt;Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n\n2019-07-07\nb\n\n&lt;\/AuthenticationErrorDetail&gt;&lt;\/Error&gt;\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: verovisionstorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;Auth&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;Authorization&quot;\n            }\n        }\n    }\n}\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: mystorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403&quot;\n    }\n}\n<\/code><\/pre>\n<p>As far as I can tell from the code of the azureml.core.Run class and the subsequent function calls, the Run object tries to upload the file to the step run's output directory using SAS-Token-Authentication (which fails). This documentation article is linked in the code (but I don't know if this relates to the issue): <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/storageservices\/create-service-sas#service-sas-example\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/rest\/api\/storageservices\/create-service-sas#service-sas-example<\/a><\/p>\n<p>Did anybody encounter this error as well and knows what causes it or how it can be resolved?<\/p>\n<p>Best,\nJonas<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1630074825080,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":215.0,
        "Poster_created_time":1594877973727,
        "Poster_location":"Germany",
        "Poster_reputation_count":51.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68955197",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"upload file step run output authent error pythonscriptstep pipelin save model joblib pickl dump directori blob contain azur blob storag creat setup workspac try upload model file step run output directori run upload file path stream function document http doc microsoft com python api core core run class view azur upload file path stream datastor time ago creat script sdk version work fine updat script function upgrad sdk version process upload function run follow error traceback recent file opt miniconda lib python site packag file util upload line upload blob stream valid content true file opt miniconda lib python site packag restclient clientbas line execut func reset return clientbas execut func intern backoff retri modul logger func reset func arg kwarg file opt miniconda lib python site packag restclient clientbas line execut func intern left retri cl handl retri left retri total retri error logger func file opt miniconda lib python site packag restclient clientbas line handl retri rais error file opt miniconda lib python site packag restclient clientbas line execut func intern respons func arg kwarg file opt miniconda lib python site packag vendor azur storag blob blockblobservic line creat blob stream initi vector file opt miniconda lib python site packag vendor azur storag blob upload chunk line upload blob chunk rang id result futur file opt miniconda lib python site packag vendor azur storag blob upload chunk line rang id result futur file opt miniconda lib python concurr futur base line result return self result file opt miniconda lib python concurr futur base line result rais self except file opt miniconda lib python concurr futur thread line run result self self arg self kwarg file opt miniconda lib python site packag vendor azur storag blob upload chunk line process chunk return self upload chunk progress chunk offset chunk byte file opt miniconda lib python site packag vendor azur storag blob upload chunk line upload chunk progress rang self upload chunk chunk offset chunk data file opt miniconda lib python site packag vendor azur storag blob upload chunk line upload chunk timeout self timeout file opt miniconda lib python site packag vendor azur storag blob blockblobservic line block self perform request request file opt miniconda lib python site packag vendor azur storag common storagecli line perform request rais file opt miniconda lib python site packag vendor azur storag common storagecli line perform request rais file opt miniconda lib python site packag vendor azur storag common storagecli line perform request httperror respons statu respons messag respons header respons bodi file opt miniconda lib python site packag vendor azur storag common error line http error handler rais azur common azurehttperror server fail authent request sure valu author header form correctli includ signatur errorcod authenticationfail authenticationfailedserv fail authent request sure valu author header form correctli includ signatur requestid debe bfa time zsignatur match string sign rcw blob mystorag experimentrun dcid dab aac bbdeeb output model model pkl handl except except occur traceback recent file mnt batch task share root job setup context manag injector line execut context runpi run path sy argv global run main file opt miniconda lib python runpi line run path pkg pkg script fname file opt miniconda lib python runpi line run modul code mod mod spec pkg script file opt miniconda lib python runpi line run code exec code run global file aml pipelin time seri model train azur cpu line main file aml pipelin time seri model train azur cpu line main path stream model path file opt miniconda lib python site packag core run line wrap return func self arg kwarg file opt miniconda lib python site packag core run line upload file datastor datastor file opt miniconda lib python site packag restclient artifact client line upload artifact return self upload artifact path artifact arg kwarg file opt miniconda lib python site packag restclient artifact client line upload artifact path return self upload artifact stream stream arg kwarg file opt miniconda lib python site packag restclient artifact client line upload artifact stream content type content type session session file opt miniconda lib python site packag restclient artifact client line upload stream exist artifact timeout timeout backoff backoff start retri retri limit file opt miniconda lib python site packag file util upload line upload blob stream rais except error error inner except common except except except messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set storageaccount mystorag containernam statuscod innerexcept server fail authent request sure valu author header form correctli includ signatur errorcod authenticationfail authenticationfailedserv fail authent request sure valu author header form correctli includ signatur requestid debe bfa time zsignatur match string sign rcw blob mystorag experimentrun dcid dab aac bbdeeb output model model pkl errorrespons error code usererror messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set tstorageaccount mystorag tcontainernam tstatuscod inner error code auth inner error code author handl except except occur traceback recent file aml pipelin time seri model train azur cpu line main file aml pipelin time seri model train azur cpu line main path stream model path file opt miniconda lib python site packag core run line wrap return func self arg kwarg file opt miniconda lib python site packag core run line upload file datastor datastor file opt miniconda lib python site packag restclient artifact client line upload artifact return self upload artifact path artifact arg kwarg file opt miniconda lib python site packag restclient artifact client line upload artifact path return self upload artifact stream stream arg kwarg file opt miniconda lib python site packag restclient artifact client line upload artifact stream content type content type session session file opt miniconda lib python site packag restclient artifact client line upload stream exist artifact timeout timeout backoff backoff start retri retri limit file opt miniconda lib python site packag file util upload line upload blob stream rais except error error inner except userscriptexcept userscriptexcept messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set storageaccount mystorag containernam statuscod innerexcept except messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set storageaccount mystorag containernam statuscod innerexcept server fail authent request sure valu author header form correctli includ signatur errorcod authenticationfail authenticationfailedserv fail authent request sure valu author header form correctli includ signatur requestid debe bfa time zsignatur match string sign rcw blob mystorag experimentrun dcid dab aac bbdeeb output model model pkl errorrespons error code usererror messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set tstorageaccount verovisionstorag tcontainernam tstatuscod inner error code auth inner error code author errorrespons error code usererror messag encount author error upload blob storag check storag account attach workspac sure current user author access storag account request block firewal virtual network secur set tstorageaccount mystorag tcontainernam tstatuscod far tell code core run class subsequ function call run object tri upload file step run output directori sa token authent fail document articl link code know relat issu http doc microsoft com rest api storageservic creat servic sa servic sa exampl anybodi encount error know caus resolv best jona",
        "Question_preprocessed_content":"upload file step run output authent pythonscriptstep pipelin save model joblib pickl dump directori blob contain azur blob storag creat setup workspac try upload model file step run output directori function document time ago creat script sdk version work fine updat script function upgrad sdk version upload function run far code subsequ function run object tri upload file step run output directori document articl link code anybodi encount know caus resolv best jona",
        "Question_gpt_summary_original":"the user encountered an authentication error while attempting to upload a file to the step run's output directory using run.upload_file, which was caused by a sas-token authentication failure.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Download logged table in run locally",
        "Question_body":"<p>Hi all,<\/p>\n<p>I have been trying to download and open Wandb table locally. I have managed to get the corresponding table and its id, however, I cannot find way to download the table and open it as CSV for example.<\/p>\n<pre><code class=\"lang-auto\">runs[0].summary['avg_results'].keys()\ndict_keys(['_type', 'ncols', 'nrows', 'sha256', 'artifact_path', '_latest_artifact_path', 'path', 'size'])```\n\nAbove is a snippet of what I have managed to reach, how can I go from this point to get the table file and read it as cdv<\/code><\/pre>",
        "Question_answer_count":10,
        "Question_comment_count":null,
        "Question_created_time":1670384556861,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":516.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/download-logged-table-in-run-locally\/3507",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"download log tabl run local try download open tabl local manag correspond tabl wai download tabl open csv exampl run summari avg result kei dict kei type ncol nrow sha artifact path latest artifact path path size snippet manag reach point tabl file read cdv",
        "Question_preprocessed_content":"download tabl run try download open tabl manag tabl wai download tabl open csv exampl",
        "Question_gpt_summary_original":"The user is having trouble downloading and opening a Wandb table locally. They have obtained the table and its ID, but are unable to find a way to download it and open it as a CSV file. They have shared a code snippet of what they have managed to achieve so far.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML Deploy cannot connect to Kafka Server",
        "Question_body":"<p>In the run function of the entry script to deploy a model in azure ml, I included a producer function from kafka-python. However, using the deployed service, I can't seem to connect to the bootstrap_servers\/topics in Kafka.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1599861372500,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/92960\/azure-ml-deploy-cannot-connect-to-kafka-server",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi connect kafka server run function entri script deploi model includ produc function kafka python deploi servic connect bootstrap server topic kafka",
        "Question_preprocessed_content":"deploi kafka server run function entri script deploi model includ produc function deploi servic kafka",
        "Question_gpt_summary_original":"The user is facing challenges in connecting Azure ML Deploy to Kafka Server while using the producer function from kafka-python in the entry script of the deployed model.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Optuna returns the last value, not the best one for one trial",
        "Question_body":"<p>I'm using Optuna. Imagine these are the value for &quot;1 trial&quot; with &quot;5 epochs or steps&quot;:<\/p>\n<p>Epoch 0: 18 - Epoch 1: 32 - Epoch 2: 14 - Epoch 3: 28 - Epoch 4: 25<\/p>\n<p>I expect Optuna to return 14 as the value for this trial but it gives me 25 (value of the last epoch). I want optuna to return the best intermediate value as the final value, not the last one. Any explanation, as well as the solution to solve the problem, will be appreciated.<\/p>\n<p>P.s: I am talking about just one trial, not a study.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1634714319767,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":321.0,
        "Poster_created_time":1634713278736,
        "Poster_location":"Germany",
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69641832",
        "Tool":"Optuna",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"return valu best trial imagin valu trial epoch step epoch epoch epoch epoch epoch expect return valu trial give valu epoch want return best intermedi valu final valu explan solut solv problem appreci talk trial studi",
        "Question_preprocessed_content":"return valu best trial imagin valu trial epoch step epoch epoch epoch epoch epoch expect return valu trial give want return best intermedi valu final valu explan solut solv problem talk trial studi",
        "Question_gpt_summary_original":"The user is facing an issue with Optuna where it returns the last value instead of the best intermediate value for one trial with 5 epochs or steps. The user expects Optuna to return the best intermediate value, which is 14, but it returns the last value, which is 25. The user is seeking an explanation and a solution to this problem.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"can I use mlflow python API to register a spark UDF & then use the UDF in Spark scala code?",
        "Question_body":"<p>I'm trying to use mlflow to do the machine learning work. I register the ML model as UDF using the following python code. The question is how can I use the UDF(test_predict) in my scala code? The reason is that our main code is in Scala. The problem is that UDF created below is a temporary UDF and SparkSession scoped. thanks!<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import sys\nimport mlflow\nfrom mlflow import pyfunc\nimport numpy as np\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark import SQLContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.sql.types import *\n\nsc=SparkContext()\nspark = SparkSession.builder.appName(\"Python UDF example\").getOrCreate()\npyfunc_udf=mlflow.pyfunc.spark_udf(spark=spark, model_uri=\".\/sk\",result_type=\"float\")\nspark.udf.register(\"test_predict\",pyfunc_udf)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1587824105457,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1588065231427,
        "Question_score_count":2.0,
        "Question_view_count":617.0,
        "Poster_created_time":1553506414607,
        "Poster_location":null,
        "Poster_reputation_count":129.0,
        "Poster_view_count":47.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61427012",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us python api regist spark udf us udf spark scala code try us machin learn work regist model udf follow python code question us udf test predict scala code reason main code scala problem udf creat temporari udf sparksess scope thank import sy import import pyfunc import numpi pyspark import sparkcontext sparkconf pyspark import sqlcontext pyspark sql session import sparksess pyspark sql type import sparkcontext spark sparksess builder appnam python udf exampl getorcr pyfunc udf pyfunc spark udf spark spark model uri result type float spark udf regist test predict pyfunc udf",
        "Question_preprocessed_content":"us python api regist spark udf us udf spark scala code try us machin learn work regist model udf python code question us scala code reason main code scala problem udf creat temporari udf scope thank",
        "Question_gpt_summary_original":"The user is trying to register a machine learning model as a UDF using mlflow Python API and wants to use the UDF in their Scala code. However, the UDF created is temporary and SparkSession scoped, which is causing a problem as their main code is in Scala.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How can I save more metadata on an MLFlow model",
        "Question_body":"<p>I am trying to save a model to MLFlow, but as I have a custom prediction pipeline to retrieve data, I need to save extra metadata into the model.<\/p>\n<p>I tried using my custom signature class, which It does the job correctly and saves the model with the extra metadata in the MLModel file (YAML format). But when want to load the model from the MLFlow registry, the signature is not easy accesible.<\/p>\n<pre><code>mlflow.sklearn.log_model(model, &quot;model&quot;, signature = signature)\n<\/code><\/pre>\n<p>I've also tried to save an extra dictionary at the log_model function, but it saves it in the conda.yaml file:<\/p>\n<pre><code>mlflow.sklearn.log_model(model, &quot;model&quot;, {&quot;metadata1&quot;:&quot;value1&quot;, &quot;metadata2&quot;:&quot;value2&quot;})\n<\/code><\/pre>\n<p>Should I make my own flavour? Or my own Model inheritance? I've seen <a href=\"https:\/\/github1s.com\/mlflow\/mlflow\/blob\/HEAD\/mlflow\/pyfunc\/__init__.py\" rel=\"nofollow noreferrer\">here<\/a> that the PyFuncModel recieves some metadata class and an implementation to solve this, but I don't know where should I pass my own implementations to PyFuncModel on an experiment script. Here's a minimal example:<\/p>\n<pre><code>import mlflow\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\nmetadata_dic = {&quot;metadata1&quot;: &quot;value1&quot;, \n                &quot;metadata2&quot;: &quot;value2&quot;}\n\nX = np.array([[-2, -1, 0, 1, 2, 1],[-2, -1, 0, 1, 2, 1]]).T\ny = np.array([0, 0, 1, 1, 1, 0])\n\nX = pd.DataFrame(X, columns=[&quot;X1&quot;, &quot;X2&quot;])\ny = pd.DataFrame(y, columns=[&quot;y&quot;])\n\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\n\nmlflow.sklearn.log_model(model, &quot;model&quot;)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1638276045390,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":323.0,
        "Poster_created_time":1550233102176,
        "Poster_location":null,
        "Poster_reputation_count":621.0,
        "Poster_view_count":103.0,
        "Answer_body":"<p>Finally, I made a class that contains every metadata and saved it as an model argument:<\/p>\n<pre><code>model = LogisticRegression()\nmodel.fit(X, y)\nmodel.metadata = ModelMetadata(**metadata_dic)\nmlflow.sklearn.log_model(model, &quot;model&quot;)\n<\/code><\/pre>\n<p>Here I lost the customizable <code>predict<\/code> process, but after reading the <code>MLFlow<\/code> documentation is not very clear how to proceed.<\/p>\n<p>If anyone finds a good approach It would be very appreciated.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1638361888372,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1550233102176,
        "Answerer_location":null,
        "Answerer_reputation_count":621.0,
        "Answerer_view_count":103.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70169519",
        "Tool":"MLflow",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save metadata model try save model custom predict pipelin retriev data need save extra metadata model tri custom signatur class job correctli save model extra metadata mlmodel file yaml format want load model registri signatur easi acces sklearn log model model model signatur signatur tri save extra dictionari log model function save conda yaml file sklearn log model model model metadata valu metadata valu flavour model inherit seen pyfuncmodel reciev metadata class implement solv know pass implement pyfuncmodel experi script minim exampl import import numpi import panda sklearn linear model import logisticregress metadata dic metadata valu metadata valu arrai arrai datafram column datafram column model logisticregress model fit sklearn log model model model",
        "Question_preprocessed_content":"save metadata model try save model custom predict pipelin retriev data save extra metadata model tri custom signatur job save model extra metadata mlmodel file want load model registri signatur easi tri save extra dictionari function save file flavour model inherit pyfuncmodel reciev metadata implement solv know implement pyfuncmodel experi script minim exampl",
        "Question_gpt_summary_original":"The user is trying to save a model to MLFlow with extra metadata using a custom signature class or a dictionary, but is unable to access the signature when loading the model from the MLFlow registry. The user is considering creating their own flavor or model inheritance and is seeking guidance on how to pass their own implementations to PyFuncModel on an experiment script.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"The default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'",
        "Question_body":"<p>I am trying to fit XGBClassifier to my dataset after hyperparameter tuning using optuna and I keep getting this warning:<\/p>\n<blockquote>\n<p>the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'<\/p>\n<\/blockquote>\n<p>Below is my code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>#XGBC MODEL\nmodel = XGBClassifier(random_state = 69)\n\ncross_rfc_score = -1 * cross_val_score(model, train_x1, train_y,\n                           cv = 5, n_jobs = -1, scoring = 'neg_mean_squared_error')\nbase_rfc_score = cross_rfc_score.mean()\n<\/code><\/pre>\n<p>But if I use Optuna and then fit the obtained parameters it gives me the warning. Below is the code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def objective(trial):\n    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.01)\n    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n    sub_sample = trial.suggest_float('sub_sample', 0.0, 1.0)\n    max_depth = trial.suggest_int('max_depth', 1, 20)\n\n    params = {'max_depth' : max_depth,\n           'n_estimators' : n_estimators,\n           'sub_sample' : sub_sample,\n           'learning_rate' : learning_rate}\n\n    model.set_params(**params)\n\n    return np.mean(-1 * cross_val_score(model, train_x1, train_y,\n                            cv = 5, n_jobs = -1, scoring = 'neg_mean_squared_error'))\n\nxgbc_study = optuna.create_study(direction = 'minimize')\nxgbc_study.optimize(objective, n_trials = 10)\n\nxgbc_study.best_params\noptuna_rfc_mse = xgbc_study.best_value\n\nmodel.set_params(**xgbc_study.best_params)\nmodel.fit(train_x1, train_y)\nxgbc_optuna_pred = model.predict(test_x1)\nxgbc_optuna_mse1 = mean_squared_error(test_y, xgbc_optuna_pred)\n<\/code><\/pre>\n<p>The full warning is:<\/p>\n<blockquote>\n<p>Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.<\/p>\n<\/blockquote>\n<p>I want <code>MSE<\/code> as my metric of choice.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1628068876503,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1628327539816,
        "Question_score_count":7.0,
        "Question_view_count":5691.0,
        "Poster_created_time":1614760458072,
        "Poster_location":"India",
        "Poster_reputation_count":396.0,
        "Poster_view_count":70.0,
        "Answer_body":"<p>Just as described <a href=\"https:\/\/xgboost.readthedocs.io\/en\/latest\/parameter.html\" rel=\"noreferrer\">here<\/a>, try to add <code>eval_metric<\/code> to your <code>.fit<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>model.fit(train_x1, train_y, eval_metric='rmse')\n<\/code><\/pre>\n<p>as optimizing <code>rmse<\/code> and <code>mse<\/code> is leading towards the same results.<\/p>",
        "Answer_comment_count":4.0,
        "Question_closed_time":1628083548827,
        "Answer_last_edit_time":null,
        "Answer_score_count":6.0,
        "Answerer_created_time":1536872853240,
        "Answerer_location":"Copenhagen, Denmark",
        "Answerer_reputation_count":478.0,
        "Answerer_view_count":27.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68648689",
        "Tool":"Optuna",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"default evalu metric object binari logist chang error logloss try fit xgbclassifi dataset hyperparamet tune get warn default evalu metric object binari logist chang error logloss code xgbc model model xgbclassifi random state cross rfc score cross val score model train train job score neg mean squar error base rfc score cross rfc score mean us fit obtain paramet give warn code def object trial learn rate trial suggest float learn rate estim trial suggest int estim sub sampl trial suggest float sub sampl max depth trial suggest int max depth param max depth max depth estim estim sub sampl sub sampl learn rate learn rate model set param param return mean cross val score model train train job score neg mean squar error xgbc studi creat studi direct minim xgbc studi optim object trial xgbc studi best param rfc mse xgbc studi best valu model set param xgbc studi best param model fit train train xgbc pred model predict test xgbc mse mean squar error test xgbc pred warn start xgboost default evalu metric object binari logist chang error logloss explicitli set eval metric like restor old behavior want mse metric choic",
        "Question_preprocessed_content":"default evalu metric object binari logist chang try fit dataset hyperparamet tune warn default evalu metric object binari logist chang code us fit obtain paramet give warn code warn start default evalu metric object binari logist chang explicitli set like restor old behavior want metric choic",
        "Question_gpt_summary_original":"The user is encountering a warning message while fitting XGBClassifier to their dataset after hyperparameter tuning using optuna. The warning message states that the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss' in XGBoost 1.3.0. The user wants to use MSE as their metric of choice.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Retirement Announcement - Transition to Azure Machine Learning by 31 August 2024",
        "Question_body":"<p>Because Azure Machine Learning now provides rich, consolidated capabilities for model training and deploying,\u202fwe'll retire the older Machine Learning Studio (classic) service on 31 August 2024. Please transition to using Azure Machine Learning by that date. If you have a question, please post it in this thread.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1630044593657,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Follow these steps to transition using Azure Machine Learning before 31 August 2024. Pricing may be subject to change, please view pricing <a href=\"https:\/\/azure.microsoft.com\/pricing\/details\/machine-learning\/\">here<\/a>.    <\/p>\n<ul>\n<li> Steps to migrate <a href=\"https:\/\/learn.microsoft.com\/azure\/machine-learning\/migrate-overview\">link<\/a>    <\/li>\n<li> Price <a href=\"https:\/\/azure.microsoft.com\/pricing\/details\/machine-learning\/#:%7E:text=Consumed%20Azure%20resources%20%28e.g.%20compute%2C%20storage%29%20%28No%20Azure,%24-%20%2B%20per%20vCPU%20hour%20Edition%3A%20Basic%20Enterprise\">link<\/a>    <\/li>\n<\/ul>\n<p>If you have any additional queries regarding this retirement, please use comments on this thread to ask your specific queries and we will try our best to answer those queries.    <\/p>\n",
        "Answer_comment_count":6.0,
        "Question_closed_time":1630044774267,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/530215\/retirement-announcement-transition-to-azure-machin",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retir announc transit august provid rich consolid capabl model train deploi retir older machin learn studio classic servic august transit date question post thread",
        "Question_preprocessed_content":"retir transit august provid rich consolid capabl model train deploi retir older machin learn studio servic august transit date question post thread",
        "Question_gpt_summary_original":"The older Machine Learning Studio (classic) service will be retired on 31 August 2024, and users are advised to transition to Azure Machine Learning, which provides consolidated capabilities for model training and deploying. Users are encouraged to ask any questions they may have in the provided thread.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How can I import the latest version of pandas in my Jupyter Sagemaker notebook instance?",
        "Question_body":"<p>Whenever I run this code in a cell:<\/p>\n\n<pre><code>import pandas as pd\npd.__version__\n<\/code><\/pre>\n\n<p>I get the following:<\/p>\n\n<pre><code>'0.24.2'\n<\/code><\/pre>\n\n<p>I would like to be able to import the latest version of pandas right off the bat.  When I look at the Conda Packages under <em>Kernel<\/em> -> <em>Conda Packages<\/em>, I can see that pandas 1.0.1 is installed.  I would like to avoid having to do <code>!pip install --upgrade pandas<\/code> every time I run this notebook.  Is there a way to do that?  I'm confused by the fact that conda seems to have pandas 1.0.1 installed but it only imports version 0.24.2.<\/p>\n\n<p>I saw that you can specify the version of pandas via lifecycle configurations, but I was hoping there was a more permanent solution that automatically does it instead of me having to specify it.  <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_created_time":1582589550860,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1532.0,
        "Poster_created_time":1455042292696,
        "Poster_location":null,
        "Poster_reputation_count":43.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60385799",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"import latest version panda jupyt notebook instanc run code cell import panda version follow like abl import latest version panda right bat look conda packag kernel conda packag panda instal like avoid have pip instal upgrad panda time run notebook wai confus fact conda panda instal import version saw specifi version panda lifecycl configur hope perman solut automat instead have specifi",
        "Question_preprocessed_content":"import latest version panda jupyt instanc run code like abl import latest version panda right bat conda packag kernel conda packag panda like avoid have time run wai confus fact conda panda import version saw specifi version panda lifecycl configur hope perman solut instead have specifi",
        "Question_gpt_summary_original":"The user wants to import the latest version of pandas in their Jupyter Sagemaker notebook instance. They have pandas 1.0.1 installed in their Conda Packages, but when they run the code, it imports version 0.24.2. The user wants a permanent solution to automatically import the latest version without having to specify it every time.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is it possible to log confidence intervals?",
        "Question_body":"<p>I log model scores by steps and at every step I have metric value, confidence interval lower bound, confidence interval upper bound. Is it possible to log confidence intervals (on one graph) and show the confidence interval using different color?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1673459967645,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":223.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Thank you so much for the example! This helps a whole lot. Currently this isn\u2019t a feature we have in our product, but I\u2019ll create a feature request for this and our team will reach out to you once there are any updates on this ticket.<\/p>",
        "Answer_comment_count":null,
        "Question_closed_time":1674027872136,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/is-it-possible-to-log-confidence-intervals\/3684",
        "Tool":"Weights & Biases",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl log confid interv log model score step step metric valu confid interv lower bound confid interv upper bound possibl log confid interv graph confid interv differ color",
        "Question_preprocessed_content":"log confid interv log model score step step metric valu confid interv lower bound confid interv bound log confid interv confid interv color",
        "Question_gpt_summary_original":"The user wants to know if it is possible to log confidence intervals on one graph and show them using different colors. They currently log model scores by steps and have metric value, confidence interval lower bound, and confidence interval upper bound at every step.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How do I figure out the duration of my AutoML run?",
        "Question_body":"<p>I am a newbie to Machine Learning.  I am using AutoML to run an experiment as I learn about machine learning. My current model has been running for 18 hours; 24-hour exit criterion training time is selected.<\/p>\n<p>Is there a way to figure out the duration of a model run?  <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1678128410413,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1187015\/how-do-i-figure-out-the-duration-of-my-automl-run",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"figur durat automl run newbi machin learn automl run experi learn machin learn current model run hour hour exit criterion train time select wai figur durat model run",
        "Question_preprocessed_content":"figur durat automl run newbi machin learn automl run experi learn machin learn model hour exit criterion train time select wai figur durat model run",
        "Question_gpt_summary_original":"The user is a newbie to Machine Learning and is using AutoML to run an experiment. They are unsure how to figure out the duration of their model run, which has been running for 18 hours with a 24-hour exit criterion training time selected.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Log (and then apply) Spark MLlib model from R to MLflow",
        "Question_body":"<p>I'm using Spark MLlib functions (through the <em>sparklyr<\/em> package) to train a model but now seem unable to save the model in <em>MLflow<\/em> for future use.<\/p>\n<pre><code>iris_tbl &lt;- sparklyr::copy_to(sc, iris, &quot;iris_spark&quot;)\nmdl_mllib &lt;- iris_tbl %&gt;% sparklyr::ml_linear_regression(formula = Sepal_Width ~ Sepal_Length)\nmlflow::mlflow_log_model(mdl_mllib, &quot;artifact_path_where_saved&quot;)\nError in UseMethod(&quot;mlflow_save_model&quot;) : \n  no applicable method for 'mlflow_save_model' applied to an object of class &quot;c('ml_model_linear_regression', 'ml_model_regression', 'ml_model_prediction', 'ml_model')&quot;\n\npackageVersion(&quot;mlflow&quot;)\n[1] \u20181.17.0\u2019\n<\/code><\/pre>\n<p>What is a simple way to save this model in <em>mlflow<\/em> for later use <strong>on a Spark DataFrame<\/strong> such as:<\/p>\n<p><code>mlflow::mlflow_load_model(model_uri = &quot;models:\/mdl_mllib_project01\/Staging&quot;)<\/code><\/p>\n<p>For context, I'm using Azure Databricks as the ecosystem.<\/p>\n<h3>Other places I've looked for answers<\/h3>\n<ul>\n<li>These links don't seem to directly solve my problem (<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#id28;\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/models.html#id28;<\/a> <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.spark.html#mlflow.spark.log_model\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.spark.html#mlflow.spark.log_model<\/a>), although maybe it's that I need to make a &quot;pipeline&quot; or that this works for Python but not yet for R?<\/li>\n<li>This question seems relevant but offers abstract answers rather than details (<a href=\"https:\/\/stackoverflow.com\/questions\/40533582\/how-to-serve-a-spark-mllib-model\">How to serve a Spark MLlib model?<\/a>).<\/li>\n<\/ul>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1627896006663,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":107.0,
        "Poster_created_time":1619023423856,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68619132",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"log appli spark mllib model spark mllib function sparklyr packag train model unabl save model futur us iri tbl sparklyr linear regress formula sepal width sepal length log model mdl mllib artifact path save error usemethod save model applic method save model appli object class model linear regress model regress model predict model packagevers simpl wai save model later us spark datafram load model model uri model mdl mllib project stage context azur databrick ecosystem place look answer link directli solv problem http www org doc latest model html http www org doc latest python api spark html spark log model mayb need pipelin work python question relev offer abstract answer detail serv spark mllib model",
        "Question_preprocessed_content":"log spark model spark function train model unabl save model futur us simpl wai save model later us spark datafram context azur databrick ecosystem place answer link directli solv problem mayb pipelin work python question relev abstract answer detail",
        "Question_gpt_summary_original":"The user is facing challenges in saving a Spark MLlib model in MLflow for future use. They are using the sparklyr package to train the model and are encountering an error when trying to log the model in MLflow. The user is seeking a simple way to save the model in MLflow for later use on a Spark DataFrame. They have looked at various resources but have not found a solution yet. The user is working in the Azure Databricks ecosystem.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to track parameter and metrics from Vertex AI pipelines",
        "Question_body":"<p>We are using both Vertex AI training jobs and Kubeflow pipelines in Google Clouds  Vertex AI.<\/p>\n<p>In training jobs we log parameters and metrics to Vertex AI Experiments through the python sdk.<\/p>\n<p>Can Vertex AI Pipelines track metrics from the Kubeflow pipeline to Experiments? Or failing that is it possible to get the pipeline run id and log manually through the sdk using this id is the run id? Any other approaches for experiment tracking in Vertex AI Pipelines?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1633589909387,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":404.0,
        "Poster_created_time":1546942930440,
        "Poster_location":null,
        "Poster_reputation_count":111.0,
        "Poster_view_count":10.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69476702",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"track paramet metric pipelin train job kubeflow pipelin googl cloud train job log paramet metric experi python sdk pipelin track metric kubeflow pipelin experi fail possibl pipelin run log manual sdk run approach experi track pipelin",
        "Question_preprocessed_content":"track paramet metric pipelin train job kubeflow pipelin cloud train job log paramet metric experi python sdk pipelin track metric kubeflow pipelin experi fail pipelin run log sdk run experi track pipelin",
        "Question_gpt_summary_original":"The user is seeking information on how to track parameters and metrics from Kubeflow pipelines in Vertex AI, specifically if it is possible to log them to Vertex AI Experiments or if there are alternative approaches for experiment tracking.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Suppress output during SigOpt runs optimization",
        "Question_body":"<p>Right now, when I run with<\/p>\n<pre><code class=\"lang-python\">while not experiment.is_finished():\n    with experiment.create_run() as run:\n<\/code><\/pre>\n<p>I get <code>Run started<\/code> and <code>Run finished<\/code> calls.  How can I suppress these if I don\u2019t want to see this output?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1644202800217,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":179.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.sigopt.com\/t\/suppress-output-during-sigopt-runs-optimization\/84",
        "Tool":"SigOpt",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"suppress output run optim right run experi finish experi creat run run run start run finish call suppress dont want output",
        "Question_preprocessed_content":"output run optim right run dont want output",
        "Question_gpt_summary_original":"The user wants to know how to suppress the \"Run started\" and \"Run finished\" output when running with SigOpt optimization.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to fix ModuleNotFoundError in azureml-sdk when installed inside conda environment",
        "Question_body":"<p>I'm setting up a conda environment on Windows 10 Pro x64 using Miniconda 4.5.12 and have done a pip install of azureml-sdk inside the environment but get a ModuleNotFoundError when attempting to execute the following code:<\/p>\n\n<pre><code>import azureml.core\nazureml.core.VERSION\n<\/code><\/pre>\n\n<p>This is the output:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"azureml.py\", line 1, in &lt;module&gt;\n    import azureml.core\n  File \"D:\\Projects\\style-transfer\\azureml.py\", line 1, in &lt;module&gt;\n    import azureml.core\nModuleNotFoundError: No module named 'azureml.core'; 'azureml' is not a package\n<\/code><\/pre>\n\n<p>The code above has been run from the conda prompt, with the test environment active as well as in vscode with the same environment selected.<\/p>\n\n<p>I setup the conda environment as per the following:<\/p>\n\n<ol>\n<li>Created the conda environment <code>conda create -n test<\/code>.<\/li>\n<li>Activated the environment <code>activate test<\/code>.<\/li>\n<li>Installed pip <code>conda install pip<\/code>.<\/li>\n<li>Installed azureml-sdk <code>pip install azureml-sdk<\/code>.<\/li>\n<\/ol>\n\n<p>This results in the following packages being installed in the environment as per <code>conda list<\/code>:<\/p>\n\n<pre><code>adal                      1.2.0                     &lt;pip&gt;\nantlr4-python3-runtime    4.7.2                     &lt;pip&gt;\napplicationinsights       0.11.7                    &lt;pip&gt;\nargcomplete               1.9.4                     &lt;pip&gt;\nasn1crypto                0.24.0                    &lt;pip&gt;\nazure-cli-command-modules-nspkg 2.0.2                     &lt;pip&gt;\nazure-cli-core            2.0.54                    &lt;pip&gt;\nazure-cli-nspkg           3.0.3                     &lt;pip&gt;\nazure-cli-profile         2.1.2                     &lt;pip&gt;\nazure-cli-telemetry       1.0.0                     &lt;pip&gt;\nazure-common              1.1.16                    &lt;pip&gt;\nazure-graphrbac           0.53.0                    &lt;pip&gt;\nazure-mgmt-authorization  0.51.1                    &lt;pip&gt;\nazure-mgmt-containerregistry 2.5.0                     &lt;pip&gt;\nazure-mgmt-keyvault       1.1.0                     &lt;pip&gt;\nazure-mgmt-nspkg          3.0.2                     &lt;pip&gt;\nazure-mgmt-resource       2.0.0                     &lt;pip&gt;\nazure-mgmt-storage        3.1.0                     &lt;pip&gt;\nazure-nspkg               3.0.2                     &lt;pip&gt;\nazure-storage-blob        1.4.0                     &lt;pip&gt;\nazure-storage-common      1.4.0                     &lt;pip&gt;\nazure-storage-nspkg       3.1.0                     &lt;pip&gt;\nazureml-core              1.0.6                     &lt;pip&gt;\nazureml-pipeline          1.0.6                     &lt;pip&gt;\nazureml-pipeline-core     1.0.6                     &lt;pip&gt;\nazureml-pipeline-steps    1.0.6                     &lt;pip&gt;\nazureml-sdk               1.0.6                     &lt;pip&gt;\nazureml-telemetry         1.0.6                     &lt;pip&gt;\nazureml-train             1.0.6                     &lt;pip&gt;\nazureml-train-core        1.0.6                     &lt;pip&gt;\nazureml-train-restclients-hyperdrive 1.0.6                     &lt;pip&gt;\nbackports.tempfile        1.0                       &lt;pip&gt;\nbackports.weakref         1.0.post1                 &lt;pip&gt;\nbcrypt                    3.1.5                     &lt;pip&gt;\nca-certificates           2018.03.07                    0\ncertifi                   2018.11.29               py37_0\ncffi                      1.11.5                    &lt;pip&gt;\nchardet                   3.0.4                     &lt;pip&gt;\ncolorama                  0.4.1                     &lt;pip&gt;\ncontextlib2               0.5.5                     &lt;pip&gt;\ncryptography              2.4.2                     &lt;pip&gt;\ndocker                    3.6.0                     &lt;pip&gt;\ndocker-pycreds            0.4.0                     &lt;pip&gt;\nfutures                   3.1.1                     &lt;pip&gt;\nhumanfriendly             4.17                      &lt;pip&gt;\nidna                      2.8                       &lt;pip&gt;\nisodate                   0.6.0                     &lt;pip&gt;\njmespath                  0.9.3                     &lt;pip&gt;\njsonpickle                1.0                       &lt;pip&gt;\nknack                     0.5.1                     &lt;pip&gt;\nmsrest                    0.6.2                     &lt;pip&gt;\nmsrestazure               0.6.0                     &lt;pip&gt;\nndg-httpsclient           0.5.1                     &lt;pip&gt;\noauthlib                  2.1.0                     &lt;pip&gt;\nopenssl                   1.1.1a               he774522_0\nparamiko                  2.4.2                     &lt;pip&gt;\npathspec                  0.5.9                     &lt;pip&gt;\npip                       18.1                     py37_0\nportalocker               1.2.1                     &lt;pip&gt;\npyasn1                    0.4.4                     &lt;pip&gt;\npycparser                 2.19                      &lt;pip&gt;\nPygments                  2.3.1                     &lt;pip&gt;\nPyJWT                     1.7.1                     &lt;pip&gt;\nPyNaCl                    1.3.0                     &lt;pip&gt;\npyOpenSSL                 18.0.0                    &lt;pip&gt;\npypiwin32                 223                       &lt;pip&gt;\npyreadline                2.1                       &lt;pip&gt;\npython                    3.7.1                h8c8aaf0_6\npython-dateutil           2.7.5                     &lt;pip&gt;\npytz                      2018.7                    &lt;pip&gt;\npywin32                   224                       &lt;pip&gt;\nPyYAML                    3.13                      &lt;pip&gt;\nrequests                  2.21.0                    &lt;pip&gt;\nrequests-oauthlib         1.0.0                     &lt;pip&gt;\nruamel.yaml               0.15.51                   &lt;pip&gt;\nSecretStorage             2.3.1                     &lt;pip&gt;\nsetuptools                40.6.3                   py37_0\nsix                       1.12.0                    &lt;pip&gt;\nsqlite                    3.26.0               he774522_0\ntabulate                  0.8.2                     &lt;pip&gt;\nurllib3                   1.23                      &lt;pip&gt;\nvc                        14.1                 h0510ff6_4\nvs2015_runtime            14.15.26706          h3a45250_0\nwebsocket-client          0.54.0                    &lt;pip&gt;\nwheel                     0.32.3                   py37_0\nwheel                     0.30.0                    &lt;pip&gt;\nwincertstore              0.2                      py37_0\n<\/code><\/pre>\n\n<p>If I run <code>which pip<\/code>, I get the following output, which confirms that I used the pip inside the environment to install azureml-sdk, I think:<\/p>\n\n<pre><code>\/c\/Users\/allan\/Miniconda3\/envs\/test\/Scripts\/pip\n<\/code><\/pre>\n\n<p>I can also see that the azureml packages do in fact exist within the environment folder structure.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1545617082117,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":6343.0,
        "Poster_created_time":1460456204196,
        "Poster_location":"Australia",
        "Poster_reputation_count":140.0,
        "Poster_view_count":10.0,
        "Answer_body":"<p>It's probably because the name if your python file is the same as a module name you are trying import. In this case, rename the file to something other than <code>azureml.py<\/code>.<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1545633498167,
        "Answer_last_edit_time":null,
        "Answer_score_count":3.0,
        "Answerer_created_time":1401187183867,
        "Answerer_location":"Sweden",
        "Answerer_reputation_count":1709.0,
        "Answerer_view_count":112.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53908529",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"fix modulenotfounderror sdk instal insid conda environ set conda environ window pro miniconda pip instal sdk insid environ modulenotfounderror attempt execut follow code import core core version output traceback recent file line import core file project style transfer line import core modulenotfounderror modul name core packag code run conda prompt test environ activ vscode environ select setup conda environ follow creat conda environ conda creat test activ environ activ test instal pip conda instal pip instal sdk pip instal sdk result follow packag instal environ conda list adal antlr python runtim applicationinsight argcomplet asncrypto azur cli command modul nspkg azur cli core azur cli nspkg azur cli profil azur cli telemetri azur common azur graphrbac azur mgmt author azur mgmt containerregistri azur mgmt keyvault azur mgmt nspkg azur mgmt resourc azur mgmt storag azur nspkg azur storag blob azur storag common azur storag nspkg core pipelin pipelin core pipelin step sdk telemetri train train core train restclient hyperdr backport tempfil backport weakref post bcrypt certif certifi cffi chardet colorama contextlib cryptographi docker docker pycr futur humanfriendli idna isod jmespath jsonpickl knack msrest msrestazur ndg httpsclient oauthlib openssl paramiko pathspec pip portalock pyasn pycpars pygment pyjwt pynacl pyopenssl pypiwin pyreadlin python hcaaf python dateutil pytz pywin pyyaml request request oauthlib ruamel yaml secretstorag setuptool sqlite tabul urllib hff runtim websocket client wheel wheel wincertstor run pip follow output confirm pip insid environ instal sdk think user allan miniconda env test script pip packag fact exist environ folder structur",
        "Question_preprocessed_content":"fix sdk insid conda environ conda environ window pro miniconda pip sdk insid environ execut code output code run conda prompt test environ activ vscode environ select setup conda environ creat conda environ activ environ pip sdk result packag environ run output confirm pip insid environ sdk think packag fact exist environ folder structur",
        "Question_gpt_summary_original":"The user has installed azureml-sdk inside a conda environment on Windows 10 Pro x64 using Miniconda 4.5.12. However, when attempting to execute the code, the user gets a ModuleNotFoundError. The user has installed pip, azureml-sdk, and other packages inside the environment, and the azureml packages do exist within the environment folder structure.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure Machine Learning exit code 134",
        "Question_body":"<p>I have an Azure ML job running which has a big training step code. This runs fine on the Azure ML without any error, but still it produces exit code 134 and fails the execution. As I understand exit code 134 relates to <strong>SIGABRT .<\/strong> But, also possible that it runs out of memory. I have not checked the memory yet, but will check this out. Still, does anyone have a clearer idea about this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1677234865300,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1183958\/azure-machine-learning-exit-code-134",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"exit code job run big train step code run fine error produc exit code fail execut understand exit code relat sigabrt possibl run memori check memori check clearer idea",
        "Question_preprocessed_content":"exit code job big train step code run fine produc exit code fail execut understand exit code relat sigabrt run memori check memori check clearer idea",
        "Question_gpt_summary_original":"The user is encountering an issue with Azure Machine Learning where their job produces exit code 134 and fails the execution, despite running without any errors. The exit code is related to SIGABRT and may be caused by running out of memory. The user is seeking clarification on this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Keras Custom Data Generator - Stuck on First Epoch, No Output?",
        "Question_body":"<p>I've been trying to get a multi-input data generator to work in Keras for a muti-input model. The inputs are in the form of an image and an associated number.<\/p>\n<p>I've tried two different custom data generators, but the simpler one merely uses ImageDataGenerator and flowfromdataframe with two outputs. Later on, I switch one of the outputs into an input and feed it into the model. The relevant code is as follows, where y_col is the output, number_col is the associated number and path_col is the path to the images:<\/p>\n<pre><code># data generator\ndf_gen = img_data_gen.flow_from_dataframe(\n        **all_args,\n        x_col=path_col,\n        y_col=[y_col, number_col],\n        shuffle=False,\n        class_mode='raw')\n\n  \n\n\n# sending data to model, wrapped in a larger function\nwhile True:\n    data_batch = next(df_gen)\n\n    #fake data, works in the model perfectly\n    number_labels = np.random.randint(1,219,len(data_batch[1]))\n  \n    outputdata, numberdata = data_batch[1].T\n    outputdata = np.asarray(outputdata).astype('float32')\n\n    #this code never works, the model freezes\n    numberdata = np.asarray(numberdata).astype(np.int32)\n  \n    yield [numberdata, data_batch[0]], outputdata\n\n#fitting the model\nhistory = model.fit(\n            train_generator,\n            steps_per_epoch=int(len(train_df) \/ batch_size),\n            validation_data=val_generator,\n            validation_steps=int(len(validation_df) \/ batch_size),\n            epochs=epochs,\n            callbacks=callbacks,\n            verbose = 1\n        )\n<\/code><\/pre>\n<p><strong>When I run this model, the output freezes at 'Epoch 1\/12'.<\/strong> I've checked that the data is in the right format, the right length, and matching properly to the other input.<\/p>\n<p>When I generate a random list of numbers, the model runs perfectly. I can also see that when fake data is generated, the number data is also getting generated.<\/p>\n<p>However, when I use the correct number data as an input into the model, the model <strong>freezes at the second 'next' call.<\/strong> I can also use a smaller sub-dataset with the same data structure and the model runs correctly. But when I use the entire dataset, the problem occurs again.<\/p>\n<p><strong>Do you know what could be causing this problem?<\/strong> I'm using AWS Sagemaker to run the model and can't seem to figure out where this problem is coming from. Thank you for your help!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1629139040917,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":248.0,
        "Poster_created_time":1629137397396,
        "Poster_location":null,
        "Poster_reputation_count":21.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68807732",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"kera custom data gener stuck epoch output try multi input data gener work kera muti input model input form imag associ number tri differ custom data gener simpler mere us imagedatagener flowfromdatafram output later switch output input feed model relev code follow col output number col associ number path col path imag data gener gen img data gen flow datafram arg col path col col col number col shuffl fals class mode raw send data model wrap larger function true data batch gen fake data work model perfectli number label random randint len data batch outputdata numberdata data batch outputdata asarrai outputdata astyp float code work model freez numberdata asarrai numberdata astyp int yield numberdata data batch outputdata fit model histori model fit train gener step epoch int len train batch size valid data val gener valid step int len valid batch size epoch epoch callback callback verbos run model output freez epoch check data right format right length match properli input gener random list number model run perfectli fake data gener number data get gener us correct number data input model model freez second us smaller sub dataset data structur model run correctli us entir dataset problem occur know caus problem run model figur problem come thank help",
        "Question_preprocessed_content":"kera custom data gener stuck epoch output try data gener work kera model input form imag number tri custom data gener simpler mere us imagedatagener flowfromdatafram output later switch output input model relev code output number path imag run model output epoch check data right format right length match properli input gener random list number model run perfectli fake data gener number data gener us number data input model model second us data structur model run us entir dataset problem know caus problem run model figur problem come thank help",
        "Question_gpt_summary_original":"The user is facing issues with a custom data generator in Keras for a multi-input model. The model freezes at the second 'next' call when the correct number data is used as input. The user has tried two different custom data generators, and the simpler one uses ImageDataGenerator and flowfromdataframe with two outputs. The user is seeking help to identify the cause of the problem.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Agent Assist - Simulator View - no smart reply suggestion",
        "Question_body":"I was trying to use \"smart reply\" option in the google agent assist but no suggestion were populated.\n\nI have tried \"smart reply\" using sample data with option \"I would like to try it with sample data\" which autopopulated the conversation UI as snapshot given below. After this it took good amount of time approx 10-12 hrs to train with given data. Once conversation profile was set with trained data, I tried smart reply on simulator view but was not getting any suggestion as smart reply. Please suggest where I am going wrong.",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1675227780000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":83.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Agent-Assist-Simulator-View-no-smart-reply-suggestion\/m-p\/516396#M1164",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"agent assist simul view smart repli suggest try us smart repli option googl agent assist suggest popul tri smart repli sampl data option like try sampl data autopopul convers snapshot given took good time approx hr train given data convers profil set train data tri smart repli simul view get suggest smart repli suggest go wrong",
        "Question_preprocessed_content":"agent simul view smart repli try us smart repli option agent popul tri smart repli sampl data option like try sampl data autopopul convers snapshot given time hr train given data convers profil set train data tri smart repli simul view smart repli go wrong",
        "Question_gpt_summary_original":"The user is facing an issue with the \"smart reply\" option in Google Agent Assist. Despite training the conversation profile with sample data, no suggestions are being populated in the simulator view. The user is seeking guidance on how to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to build a sweeps model for different numbers of hidden layers?",
        "Question_body":"<p>I am making a simple network in PyTorch with linear units as a practise project. I\u2019d like to use sweeps to find the best hyper parameters for the network. Some of these hyperparameters include batch_norm, dropout value, number of hidden layers, number of units in each hidden layer.<\/p>\n<p>I can\u2019t figure out how to set up the model and sweep config so that two different model structures can be swept without being confusing. For example, I want to use batch_norm OR have dropout values of <code>[0, 0.2, 0.4, 0.5]<\/code>. I never want <code>batch_norm<\/code> AND <code>dropout<\/code> to be used. If I use random search with wandb, it may choose both <code>0.4<\/code> dropout AND <code>batch_norm<\/code> which I don\u2019t want.<\/p>\n<p>I know how to set up the network class with simple if statements so it adds either <code>batch_norm<\/code> or <code>dropout<\/code>, but the <code>wandb.config<\/code> would still select a value for <code>dropout<\/code> and a boolean for <code>batch_norm<\/code>, and I don\u2019t want the sweep report to show both these parameters if the network only uses one.<\/p>\n<p>Another example is, I\u2019d like 2, 3, 4 or 5 hidden layers. I\u2019d also like each layer to have a randomly selected  number of neurons from the range <code>[64, 128, 256, 512]<\/code>.<\/p>\n<p>I can forsee a problem where wandb will select the model to have 3 hidden layers but also pick say, 256 neurons for the 4th or 5th layer which will be misleading on the sweep parameter graph.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1651579869475,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":158.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-build-a-sweeps-model-for-different-numbers-of-hidden-layers\/2363",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"build sweep model differ number hidden layer make simpl network pytorch linear unit practis project like us sweep best hyper paramet network hyperparamet includ batch norm dropout valu number hidden layer number unit hidden layer figur set model sweep config differ model structur swept confus exampl want us batch norm dropout valu want batch norm dropout us random search choos dropout batch norm dont want know set network class simpl statement add batch norm dropout config select valu dropout boolean batch norm dont want sweep report paramet network us exampl like hidden layer like layer randomli select number neuron rang forse problem select model hidden layer pick neuron layer mislead sweep paramet graph",
        "Question_preprocessed_content":"build model number layer make simpl network pytorch linear unit practis project like us best hyper paramet network hyperparamet includ dropout valu number layer number unit layer figur set model config model structur swept confus exampl want us dropout valu want us random search dropout dont want know set network simpl statement select valu dont want report paramet network us exampl like layer like layer randomli select number neuron rang problem select model layer pick neuron layer mislead paramet graph",
        "Question_gpt_summary_original":"The user is trying to use sweeps in PyTorch to find the best hyperparameters for a network with linear units. They want to sweep different hyperparameters such as batch_norm, dropout value, number of hidden layers, and number of units in each hidden layer. However, they are having trouble setting up the model and sweep config to avoid confusion when sweeping two different model structures. For example, they want to use either batch_norm or dropout values but not both. They also want to sweep different numbers of hidden layers and units in each layer but are concerned about misleading results if wandb selects conflicting values.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"SageMaker create PyTorchModel without deploying",
        "Question_body":"<p>If I instantiate a SageMaker <code>PyTorchModel<\/code> object like this:<\/p>\n\n<pre><code>from sagemaker.pytorch import PyTorchModel\n\nmodel = PyTorchModel(name=name_from_base('model-name'),\n                     model_data=model_data,\n                     role=role,\n                     framework_version='1.0.0',\n                     entry_point='serve.py',\n                     source_dir='src',\n                     sagemaker_session=sagemaker_session,\n                     predictor_cls=ImagePredictor)\n\n#model.create_without_deploying??\n<\/code><\/pre>\n\n<p>Is there a way that I can create this model using the sagemaker python SDK so that the model shows up in the SageMaker console, but <em>without<\/em> actually deploying it to an endpoint?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1559938343560,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1559938910380,
        "Question_score_count":2.0,
        "Question_view_count":434.0,
        "Poster_created_time":1361339272692,
        "Poster_location":"NYC",
        "Poster_reputation_count":6281.0,
        "Poster_view_count":958.0,
        "Answer_body":"<p>I don't think it is possible to do so using the high-level SageMaker Pyhton SDK. However, you should be able to do it by calling the CreateModel API using the low-level boto3 <a href=\"https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_model\" rel=\"nofollow noreferrer\">https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_model<\/a>. For your reference, below is an example snippet code on how to do it.<\/p>\n\n<pre><code>%%time\nimport boto3\nimport time\n\nsage = boto3.Session().client(service_name='sagemaker')\n\nimage_uri = '520713654638.dkr.ecr.us-east-1.amazonaws.com\/sagemaker-pytorch:1.0.0-cpu-py3'\nmodel_data ='s3:\/\/&lt;bucket&gt;\/&lt;prefix&gt;\/output\/model.tar.gz'\nsource = 's3:\/\/&lt;bucket&gt;\/&lt;prefix&gt;\/sourcedir.tar.gz'\nrole = 'arn:aws:iam::xxxxxxxx:role\/service-role\/AmazonSageMaker-ExecutionRole-xxxxxx'\n\ntimestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\nmodel_name = 'my-pytorch-model' + timestamp\n\nresponse = sage.create_model(\n    ModelName=model_name,\n    PrimaryContainer={\n        'Image': image_uri,\n        'ModelDataUrl': model_data,\n        'Environment': { 'SAGEMAKER_CONTAINER_LOG_LEVEL':'20', 'SAGEMAKER_ENABLE_CLOUDWATCH_METRICS': 'False', \n                   'SAGEMAKER_PROGRAM': 'generate.py','SAGEMAKER_REGION': 'us-east-1','SAGEMAKER_SUBMIT_DIRECTORY': source}\n         },\n         ExecutionRoleArn=role\n}\nprint(response)\n<\/code><\/pre>\n\n<p>If you get no error message, then the model will shows up in the SageMaker console<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1561626837347,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1395737095150,
        "Answerer_location":null,
        "Answerer_reputation_count":81.0,
        "Answerer_view_count":18.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56500704",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat pytorchmodel deploi instanti pytorchmodel object like pytorch import pytorchmodel model pytorchmodel base model model data model data role role framework version entri point serv sourc dir src session session predictor cl imagepredictor model creat deploi wai creat model python sdk model show consol actual deploi endpoint",
        "Question_preprocessed_content":"creat pytorchmodel deploi instanti object like wai creat model python sdk model show consol deploi endpoint",
        "Question_gpt_summary_original":"The user is trying to create a SageMaker PyTorchModel object using the sagemaker python SDK, but wants to know if there is a way to create the model without deploying it to an endpoint, while still having it show up in the SageMaker console.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS Sagemaker Kernel appears to have died and restarts",
        "Question_body":"<p>I am getting a kernel error while trying to retrieve the data from an API that includes 100 pages. The data size is huge but the code runs well when executed on Google Colab or on local machine.<\/p>\n\n<p>The error I see in a window is-<\/p>\n\n<p><strong>Kernel Restarting\nThe kernel appears to have died. It will restart automatically.<\/strong><\/p>\n\n<p>I am using an ml.m5.xlarge machine with a memory allocation of 1000GB and there are no pre-saved datasets in the instance. Also, the expected data size is around 60 GB split into multiple datasets of 4 GB each.<\/p>\n\n<p>Can anyone help?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1584774759840,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":1026.0,
        "Poster_created_time":1570163855220,
        "Poster_location":"Mumbai, Maharashtra, India",
        "Poster_reputation_count":11.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60785324",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"kernel appear di restart get kernel error try retriev data api includ page data size huge code run execut googl colab local machin error window kernel restart kernel appear di restart automat xlarg machin memori alloc pre save dataset instanc expect data size split multipl dataset help",
        "Question_preprocessed_content":"kernel di restart kernel try retriev data api includ page data size huge code run execut colab local machin window kernel restart kernel di restart machin memori dataset instanc expect data size split multipl dataset help",
        "Question_gpt_summary_original":"The user is encountering a kernel error while trying to retrieve data from an API that includes 100 pages. The error message states that the kernel appears to have died and will restart automatically. The user is using an ml.m5.xlarge machine with a memory allocation of 1000GB and there are no pre-saved datasets in the instance. The expected data size is around 60 GB split into multiple datasets of 4 GB each. The code runs well on Google Colab or on a local machine.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Connecting to Azure SQL database from \"Execute R Script\" module in \"Azure Machine Learning Studio\"",
        "Question_body":"<p>I have already set up an <strong>Azure SQL Database<\/strong> and loaded results into it form my local machine via <strong>R (RODBC)<\/strong> successfully.  I can do queries in R Studio with no problem. <\/p>\n\n<p>However when I use the same code in <strong>Execute R script<\/strong> module in the  ML studio, I get an error that the connection is not open. <\/p>\n\n<p>What do I need to change? Have tried different strings for the driver with no avail.   <\/p>\n\n<p><em>The reason Reader or Import Data module is not working for my case is that I am creating an API that provides me with the information to query the database before doing analytics. The database is very big and I do not want to load whole table and then use project columns, etc.<\/em><\/p>\n\n<p>Any help is really appreciated<\/p>\n\n<p>Thanks all<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1463678195617,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1136.0,
        "Poster_created_time":1332513926592,
        "Poster_location":"Boston, MA, USA",
        "Poster_reputation_count":45.0,
        "Poster_view_count":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37329999",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect azur sql databas execut script modul studio set azur sql databas load result form local machin rodbc successfulli queri studio problem us code execut script modul studio error connect open need chang tri differ string driver avail reason reader import data modul work case creat api provid inform queri databas analyt databas big want load tabl us project column help appreci thank",
        "Question_preprocessed_content":"azur sql databas execut script modul studio set azur sql databas load result form local machin queri studio problem us code execut script modul studio open chang tri string driver avail reason reader import data modul work case creat api provid inform queri databas analyt databas big want load tabl us project column help thank",
        "Question_gpt_summary_original":"The user is facing challenges while trying to connect to an Azure SQL database from the \"Execute R Script\" module in \"Azure Machine Learning Studio\". The user has already successfully loaded results into the database using R (RODBC) from their local machine and can do queries in R Studio without any problem. However, when using the same code in the \"Execute R Script\" module, the user is getting an error that the connection is not open. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"ValidationException Importing from Redshift into Data Wrangler",
        "Question_body":"<p>I'm trying to build a model workflow in AWS SageMaker using Data Wrangler for preprocessing. I'm loading data from various tables in a Redshift instance, before mutating and joining them as required to build the model input data.<\/p>\n<p>I'm a contractor working for a company who has provisioned some resource in their AWS environment for me to work, and am reading from a production database. If I do not load open the Data Wrangler flow early enough in the day (which I suspect is related to load on their system), some of the nodes which I have created will not validate, and instead show a red cross and the following error message:<\/p>\n<p><code>RedshiftQueryExecutionIdValidationError: An error occurred when trying to invoke `describe_statement`: An error occurred (ValidationException) when calling the DescribeStatement operation: Could not retrieve the query result as it has expired after 1655759552.<\/code><\/p>\n<p>The remaining un-errored nodes appear to hang in a loading\/validating state. Here's a screenshot of part of the flow in this state:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AewzK.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AewzK.png\" alt=\"An image showing some currently loading AWS Data Wrangler nodes, with some errored nodes joining in towards the end of the flow, rendering the end product errored and thus unusable\" \/><\/a><\/p>\n<p>I'm not sure if it's related, but I occasionally see error messages pop up saying something about &quot;too many inflight requests&quot;.<\/p>\n<p>My main issue, I think, is a lack of context. I have not worked in this environment before, and am finding it difficult to diagnose the issue. It might be possible to provision more resource, and I could likely trim down some of the information before reading it in, but I'd like to be able to read the error messages and understand what's <em>causing<\/em> the nodes to error, so that I can decide on the appropriate course of action.<\/p>\n<p>Can somebody please help explain what's going on here?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1655774625443,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":57.0,
        "Poster_created_time":1427947978892,
        "Poster_location":"Auckland, New Zealand",
        "Poster_reputation_count":25.0,
        "Poster_view_count":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72694415",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"validationexcept import redshift data wrangler try build model workflow data wrangler preprocess load data tabl redshift instanc mutat join requir build model input data contractor work compani provis resourc aw environ work read product databas load open data wrangler flow earli dai suspect relat load node creat valid instead red cross follow error messag redshiftqueryexecutionidvalidationerror error occur try invok statement error occur validationexcept call describestat oper retriev queri result expir remain error node appear hang load valid state screenshot flow state sure relat occasion error messag pop sai inflight request main issu think lack context work environ find difficult diagnos issu possibl provis resourc like trim inform read like abl read error messag understand caus node error decid appropri cours action somebodi help explain go",
        "Question_preprocessed_content":"validationexcept import redshift data wrangler try build model workflow data wrangler load data tabl redshift instanc mutat join requir build model input data contractor work compani provis resourc aw environ work read product databas load open data wrangler flow earli dai node creat valid instead red remain node hang state flow state sure relat pop sai inflight request main think lack context work environ find diagnos provis resourc like trim inform read like abl read understand caus node decid cours action somebodi help explain go",
        "Question_gpt_summary_original":"The user is encountering a ValidationException error while importing data from Redshift into Data Wrangler for preprocessing in AWS SageMaker. Some nodes are not validating and showing a red cross with an error message related to query result expiration. The un-errored nodes are hanging in a loading\/validating state, and the user occasionally sees error messages about too many inflight requests. The user is seeking help to understand the cause of the error messages and decide on the appropriate course of action.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Understanding Intermediate Values and Pruning in Optuna",
        "Question_body":"<p>I am just curious for more information on what an intermediate step actually is and how to use pruning if you're using a different ml library that isn't in the tutorial section eg) XGB, Pytorch etc.<\/p>\n<p>For example:<\/p>\n<pre><code>X, y = load_iris(return_X_y=True)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y)\nclasses = np.unique(y)\nn_train_iter = 100\n\ndef objective(trial):\n    global num_pruned\n    alpha = trial.suggest_float(&quot;alpha&quot;, 0.0, 1.0)\n    clf = SGDClassifier(alpha=alpha)\n    for step in range(n_train_iter):\n        clf.partial_fit(X_train, y_train, classes=classes)\n\n        intermediate_value = clf.score(X_valid, y_valid)\n        trial.report(intermediate_value, step)\n\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n\n    return clf.score(X_valid, y_valid)\n\n\nstudy = optuna.create_study(\n    direction=&quot;maximize&quot;,\n    pruner=optuna.pruners.HyperbandPruner(\n        min_resource=1, max_resource=n_train_iter, reduction_factor=3\n    ),\n)\nstudy.optimize(objective, n_trials=30)\n<\/code><\/pre>\n<p>What is the point of the <code>for step in range()<\/code> section? Doesn't doing this just make the optimisation take more time and won't you yield the same result for every step in the loop?<\/p>\n<p>I'm really trying to figure out the need for <code>for step in range()<\/code> and is it required every time you wish to use pruning?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1637069214753,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":841.0,
        "Poster_created_time":1482279816096,
        "Poster_location":null,
        "Poster_reputation_count":138.0,
        "Poster_view_count":28.0,
        "Answer_body":"<p>The basic model creation can be done by passing a complete training datasets once. But there are models that can still be improved (an increase in accuracy) by re-training again on the same training datasets.<\/p>\n<p>To see to it that we are not wasting resources here, we would check the accuracy after every step using the validation datasets via <code>intermediate_score<\/code> if accuracy improves, if not we prune the whole trial skipping other steps. Then we go for next trial asking another value of alpha - the hyperparameter that we are trying to determine to have the greatest accuracy on the validation datasets.<\/p>\n<p>For other libraries, it is just a matter of asking ourselves what do we want with our model, accuracy for sure is a good criteria to measure the model's competency. There can be others.<\/p>\n<p>Example optuna pruning, I want the model to continue re-training but only at my specific conditions. If intermediate value cannot defeat my best_accuracy and if steps are already more than half of my max iteration then prune this trial.<\/p>\n<pre><code>best_accuracy = 0.0\n\n\ndef objective(trial):\n    global best_accuracy\n\n    alpha = trial.suggest_float(&quot;alpha&quot;, 0.0, 1.0)\n    clf = SGDClassifier(alpha=alpha)\n\n    for step in range(n_train_iter):\n        clf.partial_fit(X_train, y_train, classes=classes)\n\n        if step &gt; n_train_iter\/\/2:\n            intermediate_value = clf.score(X_valid, y_valid)\n\n            if intermediate_value &lt; best_accuracy:\n                raise optuna.TrialPruned()\n\n    best_accuracy = clf.score(X_valid, y_valid)\n\n    return best_accuracy\n<\/code><\/pre>\n<p>Optuna has specialized pruners at <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/pruners.html\" rel=\"nofollow noreferrer\">https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/pruners.html<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1637119128723,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1634692867416,
        "Answerer_location":"Philippines",
        "Answerer_reputation_count":3105.0,
        "Answerer_view_count":290.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69990009",
        "Tool":"Optuna",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"understand intermedi valu prune curiou inform intermedi step actual us prune differ librari isn tutori section xgb pytorch exampl load iri return true train valid train valid train test split class uniqu train iter def object trial global num prune alpha trial suggest float alpha clf sgdclassifi alpha alpha step rang train iter clf partial fit train train class class intermedi valu clf score valid valid trial report intermedi valu step trial prune rais trialprun return clf score valid valid studi creat studi direct maxim pruner pruner hyperbandprun min resourc max resourc train iter reduct factor studi optim object trial point step rang section optimis time won yield result step loop try figur need step rang requir time wish us prune",
        "Question_preprocessed_content":"understand intermedi valu prune curiou inform intermedi step us prune librari isn tutori section xgb pytorch exampl point section optimis time won yield result step try figur requir time wish us prune",
        "Question_gpt_summary_original":"The user is seeking clarification on intermediate values and pruning in Optuna. They are specifically curious about the purpose of the \"for step in range()\" section in the code and whether it is necessary for using pruning. They also want to know how to use pruning with ML libraries other than those in the tutorial section, such as XGB and Pytorch.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to tune conditional objective function using optuna or hyperopt",
        "Question_body":"<p>I tried to use optuna to tune hyperparameters. But my objective function is conditional which creates issues in getting optimal parameters.<\/p>\n\n<p>i want to get cwc only if the condtion is met otherwise continue trial for next hyperparameters.\nBut i guess since the condition is not met and objective func reurns cwc it gives error<\/p>\n\n<p>UnboundLocalError: local variable 'cwc_train' referenced before assignment<\/p>\n\n<pre><code>define objective (trial):\n    k_dis = trial.suggest_uniform('k_dis', 0.0, 5.0)\n    l_dis = trial.suggest_uniform('l_dis', 0.0, 5.0)\n    k_bound = trial.suggest_uniform('k_bound', 0.0, 5.0)\n    l_bound = trial.suggest_uniform('l_bound', 0.0, 5.0) \n\n    picp = .....\n    pinrw = .....\n\n\n    if picp_train &gt;= 0.8 and pinrw_train &lt; 0.18: \n        cwc_train = fc.CWC_proposed(predict_bound_train, Y_train)\n    else:\n        print(\"error = \")\n    return  cwc_train\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=100)\n<\/code><\/pre>\n\n<p>UnboundLocalError: local variable 'cwc_train' referenced before assignment<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1564371554813,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1564379241136,
        "Question_score_count":1.0,
        "Question_view_count":814.0,
        "Poster_created_time":1564369929972,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57246939",
        "Tool":"Optuna",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tune condit object function hyperopt tri us tune hyperparamet object function condit creat issu get optim paramet want cwc condtion met continu trial hyperparamet guess condit met object func reurn cwc give error unboundlocalerror local variabl cwc train referenc assign defin object trial di trial suggest uniform di di trial suggest uniform di bound trial suggest uniform bound bound trial suggest uniform bound picp pinrw picp train pinrw train cwc train cwc propos predict bound train train print error return cwc train studi creat studi studi optim object trial unboundlocalerror local variabl cwc train referenc assign",
        "Question_preprocessed_content":"tune condit object function hyperopt tri us tune hyperparamet object function condit creat optim paramet want cwc condtion met continu trial hyperparamet condit met object func reurn cwc give local variabl referenc local variabl referenc",
        "Question_gpt_summary_original":"The user is trying to use optuna to tune hyperparameters for an objective function that is conditional. They want to get a specific value only if a certain condition is met, otherwise, they want to continue the trial for the next set of hyperparameters. However, the code is giving an error \"UnboundLocalError: local variable 'cwc_train' referenced before assignment\" because the condition is not met and the objective function returns 'cwc_train'.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"About the Troubleshooting category",
        "Question_body":"<p><a href=\"\/new-topic?category=troubleshooting\">Get help<\/a> with a problem you\u2019re facing. If you have a general question, use <a href=\"\/c\/general\">General<\/a>.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1591308511920,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":432.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/about-the-troubleshooting-category\/13",
        "Tool":"Guild AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"troubleshoot categori help problem your face gener question us gener",
        "Question_preprocessed_content":"categori help problem your face gener question us gener",
        "Question_gpt_summary_original":"The Troubleshooting category is available for users who need help with a problem they are facing. If the user has a general question, they should use the General category instead.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AzureML: How to delete detached Kubernetes service clusters?",
        "Question_body":"<p>On AzureMl, I have created some Kubernetes service clusters using <code>ComputeTarget.create()<\/code>.<\/p>\n<p>Unfortunately, I have detached some of them and I can no longer see them from the AzureML page (Compute &gt; Inference Clusters). I can re-attach them on the AzureMl page but the delete bottom is not available for the re-attached clusters.<\/p>\n<p>Because those idle clusters occupy the Total Regional Cores quota I can't create new clusters, I am wondering if there is a way to delete them?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1607139798633,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1610662691496,
        "Question_score_count":0.0,
        "Question_view_count":112.0,
        "Poster_created_time":1493509098560,
        "Poster_location":null,
        "Poster_reputation_count":155.0,
        "Poster_view_count":30.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65153543",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"delet detach kubernet servic cluster creat kubernet servic cluster computetarget creat unfortun detach longer page comput infer cluster attach page delet avail attach cluster idl cluster occupi total region core quota creat new cluster wonder wai delet",
        "Question_preprocessed_content":"delet detach kubernet servic cluster creat kubernet servic cluster unfortun detach longer page page delet avail cluster idl cluster total region core quota creat new cluster wonder wai delet",
        "Question_gpt_summary_original":"The user has created Kubernetes service clusters on AzureML using ComputeTarget.create(), but some of them have been detached and cannot be seen on the AzureML page. The delete button is not available for the re-attached clusters, and they are occupying the Total Regional Cores quota, preventing the user from creating new clusters. The user is looking for a way to delete these idle clusters.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"entry_point file using XGBoost as a framework in sagemaker",
        "Question_body":"<p>Looking at the following source code taken from <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/xgboost.html\" rel=\"nofollow noreferrer\">here<\/a> (SDK v2):<\/p>\n<pre><code>import boto3\nimport sagemaker\nfrom sagemaker.xgboost.estimator import XGBoost\nfrom sagemaker.session import Session\nfrom sagemaker.inputs import TrainingInput\n\n# initialize hyperparameters\nhyperparameters = {\n        &quot;max_depth&quot;:&quot;5&quot;,\n        &quot;eta&quot;:&quot;0.2&quot;,\n        &quot;gamma&quot;:&quot;4&quot;,\n        &quot;min_child_weight&quot;:&quot;6&quot;,\n        &quot;subsample&quot;:&quot;0.7&quot;,\n        &quot;verbosity&quot;:&quot;1&quot;,\n        &quot;objective&quot;:&quot;reg:linear&quot;,\n        &quot;num_round&quot;:&quot;50&quot;}\n\n# set an output path where the trained model will be saved\nbucket = sagemaker.Session().default_bucket()\nprefix = 'DEMO-xgboost-as-a-framework'\noutput_path = 's3:\/\/{}\/{}\/{}\/output'.format(bucket, prefix, 'abalone-xgb-framework')\n\n# construct a SageMaker XGBoost estimator\n# specify the entry_point to your xgboost training script\nestimator = XGBoost(entry_point = &quot;your_xgboost_abalone_script.py&quot;, \n                    framework_version='1.2-2',\n                    hyperparameters=hyperparameters,\n                    role=sagemaker.get_execution_role(),\n                    instance_count=1,\n                    instance_type='ml.m5.2xlarge',\n                    output_path=output_path)\n\n# define the data type and paths to the training and validation datasets\ncontent_type = &quot;libsvm&quot;\ntrain_input = TrainingInput(&quot;s3:\/\/{}\/{}\/{}\/&quot;.format(bucket, prefix, 'train'), content_type=content_type)\nvalidation_input = TrainingInput(&quot;s3:\/\/{}\/{}\/{}\/&quot;.format(bucket, prefix, 'validation'), content_type=content_type)\n\n# execute the XGBoost training job\nestimator.fit({'train': train_input, 'validation': validation_input})\n<\/code><\/pre>\n<p>I wonder where the your_xgboost_abalone_script.py file has to be placed please? So far I used XGBoost as a built-in algorithm from my local machine with similar code (i.e. I span up a training job remotely). Thanks!<\/p>\n<p>PS:<\/p>\n<p>Looking at <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/training\/estimators.html\" rel=\"nofollow noreferrer\">this<\/a>, and source_dir, I wonder if one can upload Python files to S3. In this case, I take it is has to be tar.gz? Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1653478466700,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1653482394636,
        "Question_score_count":0.0,
        "Question_view_count":74.0,
        "Poster_created_time":1267440784443,
        "Poster_location":"Somewhere",
        "Poster_reputation_count":15705.0,
        "Poster_view_count":2150.0,
        "Answer_body":"<p><code>your_xgboost_abalone_script.py<\/code> can be created locally. The path you provide is relative to where the code is running.<\/p>\n<p>I.e. <code>your_xgboost_abalone_script.py<\/code> can be located in the same directory where you are running the SageMaker SDK (&quot;source code&quot;).<\/p>\n<p>For example if you have <code>your_xgboost_abalone_script.py<\/code> in the same directory as the source code:<\/p>\n<pre><code>.\n\u251c\u2500\u2500 source_code.py\n\u2514\u2500\u2500 your_xgboost_abalone_script.py\n<\/code><\/pre>\n<p>Then you can point to this file exactly how the documentation depicts:<\/p>\n<pre><code>estimator = XGBoost(entry_point = &quot;your_xgboost_abalone_script.py&quot;, \n.\n.\n.\n)\n<\/code><\/pre>\n<p>The SDK will take <code>your_xgboost_abalone_script.py<\/code> repackage it into a model tar ball and upload it to S3 on your behalf.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1654714910812,
        "Answer_last_edit_time":1654796658207,
        "Answer_score_count":1.0,
        "Answerer_created_time":1645475560783,
        "Answerer_location":null,
        "Answerer_reputation_count":466.0,
        "Answerer_view_count":32.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72376872",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"entri point file xgboost framework look follow sourc code taken sdk import boto import xgboost estim import xgboost session import session input import traininginput initi hyperparamet hyperparamet max depth eta gamma min child weight subsampl verbos object reg linear num round set output path train model save bucket session default bucket prefix demo xgboost framework output path output format bucket prefix abalon xgb framework construct xgboost estim specifi entri point xgboost train script estim xgboost entri point xgboost abalon script framework version hyperparamet hyperparamet role execut role instanc count instanc type xlarg output path output path defin data type path train valid dataset content type libsvm train input traininginput format bucket prefix train content type content type valid input traininginput format bucket prefix valid content type content type execut xgboost train job estim fit train train input valid valid input wonder xgboost abalon script file place far xgboost built algorithm local machin similar code span train job remot thank look sourc dir wonder upload python file case tar thank",
        "Question_preprocessed_content":"file framework sourc code taken wonder file place far algorithm local machin similar code thank wonder upload python file case thank",
        "Question_gpt_summary_original":"The user is trying to use XGBoost as a framework in Sagemaker and is unsure where to place the \"your_xgboost_abalone_script.py\" file. They are also wondering if Python files can be uploaded to S3 and if they need to be in tar.gz format.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to retrieve the model signature from the MLflow Model Registry",
        "Question_body":"<p>I have registered a scikit learn model on my MLflow Tracking server, and I am loading it with <code>sklearn.load_model(model_uri)<\/code>.<\/p>\n<p>Now, I would like to access the signature of the model so I can get a list of the model's required inputs\/features so I can retrieve them from my feature store by name. I can't seem to find any utility or method in the <code>mlflow<\/code> API or the <code>MLFlowClient<\/code> API that will let me access a signature or inputs\/outputs attribute, even though I can see a list of inputs and outputs under each version of the model in the UI.<\/p>\n<p>I know that I can find the input sample and the model configuration in the model's artifacts, but that would require me actually downloading the artifacts and loading them manually in my script. I don't need to avoid that, but I am surprised that I can't just return the signature as a dictionary the same way I can return a run's parameters or metrics.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1643655088920,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":904.0,
        "Poster_created_time":1466188731112,
        "Poster_location":"Michigan",
        "Poster_reputation_count":414.0,
        "Poster_view_count":39.0,
        "Answer_body":"<p>The way to access the model's signature without downloading the MLModel file is under the loaded model. And then you'll access the model's attributes, such as its signature or even other Pyfunc-defined methods.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\nmodel = mlflow.pyfunc.load_model(&quot;runs:\/&lt;run_id&gt;\/model&quot;)\nprint(model._model_meta._signature)\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1645469817663,
        "Answer_last_edit_time":null,
        "Answer_score_count":3.0,
        "Answerer_created_time":1508924024027,
        "Answerer_location":null,
        "Answerer_reputation_count":118.0,
        "Answerer_view_count":17.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70931309",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retriev model signatur model registri regist scikit learn model track server load sklearn load model model uri like access signatur model list model requir input featur retriev featur store util method api client api let access signatur input output attribut list input output version model know input sampl model configur model artifact requir actual download artifact load manual script need avoid surpris return signatur dictionari wai return run paramet metric",
        "Question_preprocessed_content":"retriev model signatur model registri regist scikit learn model track server load like signatur model list model requir retriev featur store util method api api let signatur list input output version model know input sampl model configur model artifact requir download artifact load script avoid surpris return signatur dictionari wai return run paramet metric",
        "Question_gpt_summary_original":"The user has registered a scikit learn model on their MLflow Tracking server and is trying to access the model signature to retrieve a list of required inputs\/features. However, they are unable to find any utility or method in the mlflow API or the MLFlowClient API that will let them access the signature or inputs\/outputs attribute. They can see a list of inputs and outputs under each version of the model in the UI, but they don't want to download the artifacts and load them manually in their script.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Connecting sagemaker using java sdk",
        "Question_body":"<p>Can anyone tell me how to connect to sagemaker using aws java sdk and invoke a endpoint which is arleady created using jupyter notebook?<\/p>\n\n<p>Link -<a href=\"https:\/\/docs.aws.amazon.com\/AWSJavaSDK\/latest\/javadoc\/com\/amazonaws\/services\/sagemaker\/AmazonSageMaker.html#createNotebookInstance-com.amazonaws.services.sagemaker.model.CreateNotebookInstanceRequest-\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/AWSJavaSDK\/latest\/javadoc\/com\/amazonaws\/services\/sagemaker\/AmazonSageMaker.html#createNotebookInstance-com.amazonaws.services.sagemaker.model.CreateNotebookInstanceRequest-<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1560072156127,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1112.0,
        "Poster_created_time":1539596007860,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":39.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56513409",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect java sdk tell connect aw java sdk invok endpoint arleadi creat jupyt notebook link http doc aw amazon com awsjavasdk latest javadoc com amazonaw servic amazon html createnotebookinst com amazonaw servic model createnotebookinstancerequest",
        "Question_preprocessed_content":"java sdk aw java sdk invok endpoint arleadi creat jupyt link",
        "Question_gpt_summary_original":"The user is seeking guidance on how to connect to Sagemaker using AWS Java SDK and invoke an endpoint that was created using Jupyter Notebook. They have provided a link to the AWS Java SDK documentation for creating a Notebook Instance.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to customize Advanced Legend to display a string",
        "Question_body":"<p>Hello W&amp;B community!<br>\nFor a custom project within our company, we attempt to compare various models across a list of category.<br>\nWe therefore want to visualize, for each version of our model:<\/p>\n<ul>\n<li>for each category (a string)<\/li>\n<li>a score (float in 0,1).<\/li>\n<\/ul>\n<p>Here is how we log scores in W&amp;B (simplified for easy understanding):<\/p>\n<pre><code class=\"lang-auto\">    scores = [0.3, 0.5, 0.6, ...]\n    categories = ['dog', 'cat', 'fish', ...]\n    for k, (val, name) in enumerate(zip(scores, categories)):\n        wandb.log({\n                    f\"score\": val,\n                    f\"category\": name,\n                    f\"id\": k\n                })\n<\/code><\/pre>\n<p>Here is the graph associated with this code:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d.jpeg\" data-download-href=\"\/uploads\/short-url\/xDQmaIYqXkpCtcwGLMp3ch9QtmR.jpeg?dl=1\" title=\"Screenshot from 2022-12-05 14-29-41\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_690x373.jpeg\" alt=\"Screenshot from 2022-12-05 14-29-41\" data-base62-sha1=\"xDQmaIYqXkpCtcwGLMp3ch9QtmR\" width=\"690\" height=\"373\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_690x373.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_1035x559.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/e\/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_1380x746.jpeg 2x\" data-dominant-color=\"F6F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot from 2022-12-05 14-29-41<\/span><span class=\"informations\">1389\u00d7751 103 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>\n<p>Now as you can see in the picture: For each version (td_ver), we display the \u201cscore\u201d (y) for each \u201cid\u201d (x). When we hover over the score itself, we do not want to show the \u201cid\u201d, but the \u201cname\u201d<br>\n(In the image, instead of displaying \u201c25\u201d highlighted in red, we want to display \u201cfish\u201d.<\/p>\n<p>I assume this change needs to happen in the \u201cAdvanced Legend\u201d section, but I could not find the correct spelling for that formula.<\/p>\n<pre><code class=\"lang-auto\">original:\n [[ ${x}: ${y} (${original})]] ${run:displayName}\n\nnew:\n???\n<\/code><\/pre>\n<p>Thanks a lot for your help!<\/p>",
        "Question_answer_count":9,
        "Question_comment_count":null,
        "Question_created_time":1670218529261,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":340.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-customize-advanced-legend-to-display-a-string\/3498",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"custom advanc legend displai string hello commun custom project compani attempt compar model list categori want visual version model categori string score float log score simplifi easi understand score categori dog cat fish val enumer zip score categori log score val categori graph associ code screenshot pictur version ver displai score hover score want imag instead displai highlight red want displai fish assum chang need happen advanc legend section correct spell formula origin origin run displaynam new thank lot help",
        "Question_preprocessed_content":"custom advanc legend displai string custom project compani compar model list categori want visual version model categori score log score graph code pictur version displai score hover score want imag instead displai highlight red want displai fish chang advanc legend section formula thank lot help",
        "Question_gpt_summary_original":"The user wants to customize the Advanced Legend in W&B to display a string instead of an ID when hovering over a score in a graph. They log scores and categories using W&B and want to display the category name instead of the ID in the legend. The user is seeking help with the correct formula for the Advanced Legend section.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"unable to identify current timezone 'C'",
        "Question_body":"<p>all,<\/p>\n\n<p>I am using R on the Azure machine learning, and I have some problems.<\/p>\n\n<p>I want to use program R to calculate the difference between two date, for example, 2014\/11\/01 and 2014\/11\/03.<\/p>\n\n<p>I using the function \"strptime\" in R to do this thing, it can work on my own computer, but when I want to run the same code on Azure ml, it came out the error.<\/p>\n\n<p>The error is : <\/p>\n\n<pre><code>[ModuleOutput] 1: In strptime(x, format, tz = tz) :\n[ModuleOutput] \n[ModuleOutput]   unable to identify current timezone 'C':\n[ModuleOutput] \n[ModuleOutput] please set environment variable 'TZ'\n[ModuleOutput] \n[ModuleOutput] 2: In strptime(x, format, tz = tz) : unknown timezone 'localtime'\n<\/code><\/pre>\n\n<p>I think the problem is that it can't detect the timezone on Azure ml, but I'm not sure.<\/p>\n\n<p>Is there any way to solve this problem?<\/p>\n\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1415262044470,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":4.0,
        "Question_view_count":1456.0,
        "Poster_created_time":1413344613203,
        "Poster_location":"Taipei City, Taiwan",
        "Poster_reputation_count":579.0,
        "Poster_view_count":73.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/26774724",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl identifi current timezon problem want us program calcul differ date exampl function strptime thing work want run code came error error moduleoutput strptime format moduleoutput moduleoutput unabl identifi current timezon moduleoutput moduleoutput set environ variabl moduleoutput moduleoutput strptime format unknown timezon localtim think problem detect timezon sure wai solv problem thank advanc",
        "Question_preprocessed_content":"unabl identifi timezon problem want us program calcul date exampl function strptime thing work want run code came think problem detect timezon sure wai solv problem thank advanc",
        "Question_gpt_summary_original":"The user is facing an issue while using the \"strptime\" function in R on Azure machine learning to calculate the difference between two dates. The error message suggests that the current timezone 'C' cannot be identified, and the user needs to set the environment variable 'TZ'. The user suspects that the problem is related to the inability to detect the timezone on Azure ml.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML Studio: How to change input value with Python before it goes through data process",
        "Question_body":"<p>I am currently attempting to change the value of input as it goes through data process in Azure ML. However, I cannot find a clue about how to access to the input data with python.<\/p>\n\n<p>For example, if you were to use python, you can access to the column of data with<\/p>\n\n<pre><code>print(dataframe1[\"Hello World\"])\n<\/code><\/pre>\n\n<p>I tried to change the name of Web Service Input and tried to do it like how I did for other dataframe (e.g. sample)<\/p>\n\n<pre><code>print(dataframe[\"sample\"])\n<\/code><\/pre>\n\n<p>But it returns an error with no luck, and from what I read from an error, it's not compatible to dataframe:<\/p>\n\n<pre><code>object of type 'NoneType' has no len()\n<\/code><\/pre>\n\n<p>I tried to look up a solution with Nonetype error, but there is no good solution.\nThe whole error message:<\/p>\n\n<pre><code>requestId = 1f0f621f1d8841baa7862d5c05154942 errorComponent=Module. taskStatusCode=400. {\"Exception\":{\"ErrorId\":\"FailedToEvaluateScript\",\"ErrorCode\":\"0085\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 0085: The following error occurred during script evaluation, please view the output log for more information:\\r\\n---------- Start of error message from Python interpreter ----------\\r\\nCaught exception while executing function: Traceback (most recent call last):\\r\\n File \\\"C:\\\\server\\\\invokepy.py\\\", line 211, in batch\\r\\n xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True)\\r\\n File \\\"C:\\\\server\\\\XDRReader\\\\xdrutils.py\\\", line 51, in DataFrameToRFile\\r\\n attributes = XDRBridge.DataFrameToRObject(dataframe)\\r\\n File \\\"C:\\\\server\\\\XDRReader\\\\xdrbridge.py\\\", line 40, in DataFrameToRObject\\r\\n if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):\\r\\nTypeError: object of type 'NoneType' has no len()\\r\\nProcess returned with non-zero exit code 1\\r\\n\\r\\n---------- End of error message from Python interpreter ----------\"}}Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:---------- Start of error message from Python interpreter ----------Caught exception while executing function: Traceback (most recent call last): File \"C:\\server\\invokepy.py\", line 211, in batch xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True) File \"C:\\server\\XDRReader\\xdrutils.py\", line 51, in DataFrameToRFile attributes = XDRBridge.DataFrameToRObject(dataframe) File \"C:\\server\\XDRReader\\xdrbridge.py\", line 40, in DataFrameToRObject if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):TypeError: object of type 'NoneType' has no len()Process returned with non-zero exit code 1---------- End of error message from Python interpreter ---------- Process exited with error code -2\n<\/code><\/pre>\n\n<p>I have also tried to <a href=\"https:\/\/i.stack.imgur.com\/DWZK6.png\" rel=\"nofollow noreferrer\">a way to pass python script in data<\/a>, but it is not able to make any change to Web Service Input value as I want it to be.<\/p>\n\n<p>I have tried to look on forums like msdn or SO, but it's been difficult to find any information about it. Please let me know if you need any more information if needed. I would greatly appreciate your help!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1533163130393,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":309.0,
        "Poster_created_time":1508281047960,
        "Poster_location":null,
        "Poster_reputation_count":25.0,
        "Poster_view_count":22.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51643168",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio chang input valu python goe data process current attempt chang valu input goe data process clue access input data python exampl us python access column data print datafram hello world tri chang web servic input tri like datafram sampl print datafram sampl return error luck read error compat datafram object type nonetyp len tri look solut nonetyp error good solut error messag requestid fffdbaadc errorcompon modul taskstatuscod except errorid failedtoevaluatescript errorcod exceptiontyp moduleexcept messag error follow error occur script evalu view output log inform start error messag python interpret ncaught except execut function traceback recent file server invokepi line batch xdrutil xdrutil dataframetorfil outlist outfil true file server xdrreader xdrutil line dataframetorfil attribut xdrbridg dataframetorobject datafram file server xdrreader xdrbridg line dataframetorobject len datafram type datafram datafram ntypeerror object type nonetyp len nprocess return non zero exit code end error messag python interpret error error follow error occur script evalu view output log inform start error messag python interpret caught except execut function traceback recent file server invokepi line batch xdrutil xdrutil dataframetorfil outlist outfil true file server xdrreader xdrutil line dataframetorfil attribut xdrbridg dataframetorobject datafram file server xdrreader xdrbridg line dataframetorobject len datafram type datafram datafram typeerror object type nonetyp len process return non zero exit code end error messag python interpret process exit error code tri wai pass python script data abl chang web servic input valu want tri look forum like msdn difficult inform let know need inform need greatli appreci help",
        "Question_preprocessed_content":"studio chang input valu python goe data chang valu input goe data clue input data python exampl us python column data tri chang web servic input tri like datafram return luck read compat datafram tri solut nonetyp solut tri wai python script data abl chang web servic input valu want tri forum like msdn inform let know inform greatli help",
        "Question_gpt_summary_original":"The user is trying to change the value of input data as it goes through data processing in Azure ML Studio using Python, but is unable to access the input data with Python. The user has tried to change the name of the Web Service Input and has encountered a 'NoneType' error. The user has also tried to pass a Python script in data, but it did not make any changes to the Web Service Input value. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"_InactiveRpcError while querying Vertex AI Matching Engine Index",
        "Question_body":"<p>I am following the example <a href=\"https:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/master\/notebooks\/community\/matching_engine\/matching_engine_for_indexing.ipynb\" rel=\"nofollow noreferrer\">notebook<\/a> as per GCP <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/matching-engine\/using-matching-engine#example_notebook\" rel=\"nofollow noreferrer\">docs<\/a> to test Vertex Matching Engine. I have deployed an index but while trying to query the index I am getting <code>_InactiveRpcError<\/code>. The VPC network is in <code>us-west2<\/code> with private service access enabled and the Index is deployed in <code>us-central1<\/code>. My VPC network contains the <a href=\"https:\/\/cloud.google.com\/vpc\/docs\/firewalls#more_rules_default_vpc\" rel=\"nofollow noreferrer\">pre-populated firewall rules<\/a>.<\/p>\n<p>Index<\/p>\n<pre><code>createTime: '2021-11-23T15:25:53.928606Z'\ndeployedIndexes:\n- deployedIndexId: brute_force_glove_deployed_v3\n  indexEndpoint: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexEndpoints\/XXXXXXXXXXXX\ndescription: testing python script for creating index\ndisplayName: glove_100_brute_force_20211123152551\netag: AMEw9yOVPWBOTpbAvJLllqxWMi2YurEV_sad2n13QvbIlqjOdMyiq_j20gG1ldhdZNTL\nmetadata:\n  config:\n    algorithmConfig:\n      bruteForceConfig: {}\n    dimensions: 100\n    distanceMeasureType: DOT_PRODUCT_DISTANCE\nmetadataSchemaUri: gs:\/\/google-cloud-aiplatform\/schema\/matchingengine\/metadata\/nearest_neighbor_search_1.0.0.yaml\nname: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexes\/XXXXXXXXXXXX\nupdateTime: '2021-11-23T16:04:17.993730Z'\n<\/code><\/pre>\n<p>Index-Endpoint<\/p>\n<pre><code>createTime: '2021-11-24T10:59:51.975949Z'\ndeployedIndexes:\n- automaticResources:\n    maxReplicaCount: 1\n    minReplicaCount: 1\n  createTime: '2021-11-30T15:16:12.323028Z'\n  deploymentGroup: default\n  displayName: brute_force_glove_deployed_v3\n  enableAccessLogging: true\n  id: brute_force_glove_deployed_v3\n  index: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexes\/XXXXXXXXXXXX\n  indexSyncTime: '2021-11-30T16:37:35.597200Z'\n  privateEndpoints:\n    matchGrpcAddress: 10.242.4.5\ndisplayName: index_endpoint_for_demo\netag: AMEw9yO6cuDfgpBhGVw7-NKnlS1vdFI5nnOtqVgW1ddMP-CMXM7NfGWVpqRpMRPsNCwc\nname: projects\/XXXXXXXXXXXX\/locations\/us-central1\/indexEndpoints\/XXXXXXXXXXXX\nnetwork: projects\/XXXXXXXXXXXX\/global\/networks\/XXXXXXXXXXXX\nupdateTime: '2021-11-24T10:59:53.271100Z'\n<\/code><\/pre>\n<p>Code<\/p>\n<pre><code>\nimport grpc\n\n# import the generated classes\nimport match_service_pb2\nimport match_service_pb2_grpc\n\nDEPLOYED_INDEX_SERVER_IP = '10.242.0.5'\nDEPLOYED_INDEX_ID = 'brute_force_glove_deployed_v3'\n\nquery = [-0.11333, 0.48402, 0.090771, -0.22439, 0.034206, -0.55831, 0.041849, -0.53573, 0.18809, -0.58722, 0.015313, -0.014555, 0.80842, -0.038519, 0.75348, 0.70502, -0.17863, 0.3222, 0.67575, 0.67198, 0.26044, 0.4187, -0.34122, 0.2286, -0.53529, 1.2582, -0.091543, 0.19716, -0.037454, -0.3336, 0.31399, 0.36488, 0.71263, 0.1307, -0.24654, -0.52445, -0.036091, 0.55068, 0.10017, 0.48095, 0.71104, -0.053462, 0.22325, 0.30917, -0.39926, 0.036634, -0.35431, -0.42795, 0.46444, 0.25586, 0.68257, -0.20821, 0.38433, 0.055773, -0.2539, -0.20804, 0.52522, -0.11399, -0.3253, -0.44104, 0.17528, 0.62255, 0.50237, -0.7607, -0.071786, 0.0080131, -0.13286, 0.50097, 0.18824, -0.54722, -0.42664, 0.4292, 0.14877, -0.0072514, -0.16484, -0.059798, 0.9895, -0.61738, 0.054169, 0.48424, -0.35084, -0.27053, 0.37829, 0.11503, -0.39613, 0.24266, 0.39147, -0.075256, 0.65093, -0.20822, -0.17456, 0.53571, -0.16537, 0.13582, -0.56016, 0.016964, 0.1277, 0.94071, -0.22608, -0.021106]\n\nchannel = grpc.insecure_channel(&quot;{}:10000&quot;.format(DEPLOYED_INDEX_SERVER_IP))\nstub = match_service_pb2_grpc.MatchServiceStub(channel)\n\nrequest = match_service_pb2.MatchRequest()\nrequest.deployed_index_id = DEPLOYED_INDEX_ID\nfor val in query:\n    request.float_val.append(val)\n\nresponse = stub.Match(request)\nresponse\n<\/code><\/pre>\n<p>Error<\/p>\n<pre><code>_InactiveRpcError                         Traceback (most recent call last)\n\/tmp\/ipykernel_3451\/467153318.py in &lt;module&gt;\n    108     request.float_val.append(val)\n    109 \n--&gt; 110 response = stub.Match(request)\n    111 response\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in __call__(self, request, timeout, metadata, credentials, wait_for_ready, compression)\n    944         state, call, = self._blocking(request, timeout, metadata, credentials,\n    945                                       wait_for_ready, compression)\n--&gt; 946         return _end_unary_response_blocking(state, call, False, None)\n    947 \n    948     def with_call(self,\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in _end_unary_response_blocking(state, call, with_call, deadline)\n    847             return state.response\n    848     else:\n--&gt; 849         raise _InactiveRpcError(state)\n    850 \n    851 \n\n_InactiveRpcError: &lt;_InactiveRpcError of RPC that terminated with:\n    status = StatusCode.UNAVAILABLE\n    details = &quot;failed to connect to all addresses&quot;\n    debug_error_string = &quot;{&quot;created&quot;:&quot;@1638277076.941429628&quot;,&quot;description&quot;:&quot;Failed to pick subchannel&quot;,&quot;file&quot;:&quot;src\/core\/ext\/filters\/client_channel\/client_channel.cc&quot;,&quot;file_line&quot;:3093,&quot;referenced_errors&quot;:[{&quot;created&quot;:&quot;@1638277076.941428202&quot;,&quot;description&quot;:&quot;failed to connect to all addresses&quot;,&quot;file&quot;:&quot;src\/core\/lib\/transport\/error_utils.cc&quot;,&quot;file_line&quot;:163,&quot;grpc_status&quot;:14}]}&quot;\n&gt;\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1638291169620,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1639486727367,
        "Question_score_count":2.0,
        "Question_view_count":350.0,
        "Poster_created_time":1463607987528,
        "Poster_location":"Lahore, Pakistan",
        "Poster_reputation_count":143.0,
        "Poster_view_count":23.0,
        "Answer_body":"<p>Currently, Matching Engine only supports Query from the same region. Can you try running the code from VM in <code>us-central1<\/code>.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1638293279416,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1638293279416,
        "Answerer_location":null,
        "Answerer_reputation_count":26.0,
        "Answerer_view_count":13.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70173096",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"inactiverpcerror queri match engin index follow exampl notebook gcp doc test vertex match engin deploi index try queri index get inactiverpcerror vpc network west privat servic access enabl index deploi central vpc network contain pre popul firewal rule index createtim deployedindex deployedindexid brute forc glove deploi indexendpoint project xxxxxxxxxxxx locat central indexendpoint xxxxxxxxxxxx descript test python script creat index displaynam glove brute forc etag amewyovpwbotpbavjlllqxwmiyurev sadnqvbilqjodmyiq jggldhdzntl metadata config algorithmconfig bruteforceconfig dimens distancemeasuretyp dot product distanc metadataschemauri googl cloud aiplatform schema matchingengin metadata nearest neighbor search yaml project xxxxxxxxxxxx locat central index xxxxxxxxxxxx updatetim index endpoint createtim deployedindex automaticresourc maxreplicacount minreplicacount createtim deploymentgroup default displaynam brute forc glove deploi enableaccesslog true brute forc glove deploi index project xxxxxxxxxxxx locat central index xxxxxxxxxxxx indexsynctim privateendpoint matchgrpcaddress displaynam index endpoint demo etag amewyocudfgpbhgvw nknlsvdfinnotqvgwddmp cmxmnfgwvpqrpmrpsncwc project xxxxxxxxxxxx locat central indexendpoint xxxxxxxxxxxx network project xxxxxxxxxxxx global network xxxxxxxxxxxx updatetim code import grpc import gener class import match servic import match servic grpc deploi index server deploi index brute forc glove deploi queri channel grpc insecur channel format deploi index server stub match servic grpc matchservicestub channel request match servic matchrequest request deploi index deploi index val queri request float val append val respons stub match request respons error inactiverpcerror traceback recent tmp ipykernel request float val append val respons stub match request respons opt conda lib python site packag grpc channel self request timeout metadata credenti wait readi compress state self block request timeout metadata credenti wait readi compress return end unari respons block state fals def self opt conda lib python site packag grpc channel end unari respons block state deadlin return state respons rais inactiverpcerror state inactiverpcerror",
        "Question_preprocessed_content":"queri match engin index exampl gcp doc test vertex match engin deploi index try queri index vpc network privat servic enabl index deploi vpc network contain rule index code",
        "Question_gpt_summary_original":"The user is encountering an _InactiveRpcError while querying a Vertex AI Matching Engine Index. The VPC network is in us-west2 with private service access enabled and the Index is deployed in us-central1. The user has pre-populated firewall rules in their VPC network. The error message indicates that the RPC terminated with a status code of UNAVAILABLE and failed to connect to all addresses.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Scheduling Vertex AI Pipeline - Error 503",
        "Question_body":"Hi,\n\nI successfully trained and deployed a pipeline in Vertex AI using Kubeflow for a retrieval model, Two Towers.\n\nNow I want to schedule this pipeline run every 8 minutes. Here's my code:\n\n\u00a0\n\nfrom kfp.v2.google.client import AIPlatformClient\napi_client = AIPlatformClient(project_id='my-project', region='us-central1')\n\napi_client.create_schedule_from_job_spec(\n    job_spec_path='vacantes_pipeline.json',\n    schedule=\"\/8 * * * *\", # every 8 minutes\n    time_zone='America\/Sao_Paulo',\n    parameter_values={\n        \"epochs_\": 5,\n    \"embed_length\":768,  \n        \"maxsplit_\" : 130\n    }\n)\n\n\u00a0\n\nThe JSON is successfuly created, but the Scheduler Job fails immediately.\n\nLogging tells me the httpRequest has an error 503 plus:\n\n\u00a0\n\njsonPayload: {\n@type: \"type.googleapis.com\/google.cloud.scheduler.logging.AttemptFinished\"\njobName: \"projects\/my-project\/locations\/us-central1\/jobs\/pipeline_vacantes-pipeline-with-deployment_c7e98a8f_59-14-a-a-a\"\nstatus: \"UNAVAILABLE\"\ntargetType: \"HTTP\"\nurl: \"https:\/\/us-central1-bogotatrabaja.cloudfunctions.net\/templated_http_request-v1\"\n}\n\n\u00a0\n\nAny ideas on how to solve this issue ?",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1683717540000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":92.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"I solved with Compute Engine and cron jobs.\n\nView solution in original post",
        "Answer_comment_count":null,
        "Question_closed_time":"05-13-2023 09:52 AM",
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Scheduling-Vertex-AI-Pipeline-Error-503\/m-p\/552124#M1849",
        "Tool":"Vertex AI",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"schedul pipelin error successfulli train deploi pipelin kubeflow retriev model tower want schedul pipelin run minut code kfp googl client import aiplatformcli api client aiplatformcli project project region central api client creat schedul job spec job spec path vacant pipelin json schedul minut time zone america sao paulo paramet valu epoch emb length maxsplit json successfuli creat schedul job fail immedi log tell httprequest error plu jsonpayload type type googleapi com googl cloud schedul log attemptfinish jobnam project project locat central job pipelin vacant pipelin deploy ceaf statu unavail targettyp http url http central bogotatrabaja cloudfunct net templat http request idea solv issu",
        "Question_preprocessed_content":"schedul pipelin train deploi pipelin kubeflow retriev model tower want schedul pipelin run minut code import aiplatformcli minut json creat schedul job fail plu jsonpayload idea solv",
        "Question_gpt_summary_original":"The user is encountering an error 503 while trying to schedule a pipeline run every 8 minutes in Vertex AI using Kubeflow. The JSON is successfully created, but the Scheduler Job fails immediately with an \"UNAVAILABLE\" status. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"OCR in Sage Maker",
        "Question_body":"<p>Guys i am trying to build infrastructure on aws for getting help from others on annotation. currently we uses label-studio for text annotation. as might know you can label text by selecting through polygon and than writing what does selected area mean. ex: if polygon is made around english word than what writing out label  of it to annotate that given english word. for more see image below.<a href=\"https:\/\/i.stack.imgur.com\/8jvaj.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8jvaj.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>How can i do this in <strong>SageMaker Ground Truth<\/strong>. as far as i have gone i think it can just label pre defined words. you cant create custom label in it by selecting any given area using polygon in image am i right ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1644428834663,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":67.0,
        "Poster_created_time":1482044943532,
        "Poster_location":"Gurgaon, Haryana, India",
        "Poster_reputation_count":549.0,
        "Poster_view_count":50.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71054340",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"ocr sage maker gui try build infrastructur aw get help annot current us label studio text annot know label text select polygon write select area mean polygon english word write label annot given english word imag ground truth far gone think label pre defin word creat custom label select given area polygon imag right",
        "Question_preprocessed_content":"ocr sage maker gui try build infrastructur aw help us text know label text select polygon write select area mean polygon english word write label given english word imag ground truth far gone think label pre defin word creat custom label select given area polygon imag right",
        "Question_gpt_summary_original":"The user is trying to build infrastructure on AWS for text annotation using SageMaker Ground Truth. They are currently using Label-Studio for text annotation, which allows them to label text by selecting through a polygon and writing the label for the selected area. The user is wondering if they can do the same in SageMaker Ground Truth, but they believe it can only label pre-defined words and cannot create custom labels by selecting any given area using a polygon in an image.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Compute Instance: Best practice for custom Anaconda env",
        "Question_body":"<p>I'd like to use a compute instance as my develop machine.\nAre there any best practices on how to handle custom Anaconda enviroments on these machines?<\/p>\n\n<p>So far, I do it this way:<\/p>\n\n<pre><code>conda create --name testenv python=3\nconda activate testenv\nconda install ipykernel\nipython kernel install --user --name=testenv\nsudo systemctl restart jupyter.service\n<\/code><\/pre>\n\n<p>--> Reload the JupyterHub in your browser.<\/p>\n\n<p>Do you see any drawbacks by doing it this way? I know, some special package combinations in the standard env are lost, but I'd like to know what I've installed in my system.\nOf course, one could combine it with an <code>environment.yml<\/code>.<\/p>\n\n<p>What do you think?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1591178661870,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1591865477772,
        "Question_score_count":1.0,
        "Question_view_count":116.0,
        "Poster_created_time":1589205020747,
        "Poster_location":"Germany",
        "Poster_reputation_count":163.0,
        "Poster_view_count":16.0,
        "Answer_body":"<p>Your workaround is the best option as of now. But I know that the Azure ML product group has been working on exactly this problem, but I can't make any promises as to timeline.<\/p>\n\n<p>I share your dream of an easily configurable data science cloud development environment that allows for Git repo cloning and environment creation w\/ a conda yml. We're so close especially given all the press &amp; announcements around Visual Studio Codespaces!<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1591290256907,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1405457120427,
        "Answerer_location":"Seattle, WA, USA",
        "Answerer_reputation_count":3359.0,
        "Answerer_view_count":555.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62170192",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"comput instanc best practic custom anaconda env like us comput instanc develop machin best practic handl custom anaconda enviro machin far wai conda creat testenv python conda activ testenv conda instal ipykernel ipython kernel instal user testenv sudo systemctl restart jupyt servic reload jupyterhub browser drawback wai know special packag combin standard env lost like know instal cours combin environ yml think",
        "Question_preprocessed_content":"comput instanc best practic custom anaconda env like us comput instanc develop machin best practic handl custom anaconda enviro machin far wai reload jupyterhub browser drawback wai know special packag combin standard env lost like know cours combin think",
        "Question_gpt_summary_original":"The user is seeking best practices for handling custom Anaconda environments on a compute instance used as a development machine. The user currently creates a new environment using conda, installs necessary packages, and restarts the Jupyter service. The user is concerned about losing special package combinations in the standard environment but wants to know what is installed in the system. The user is considering combining the process with an environment.yml file.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"MLflow remote tracking",
        "Question_body":"Hi folks,\n\n\nI am using mlflow 'version 1.1.0' in a model written in python for tracking purpose. I have created a project for the same with MLproject file inside it. I want to store the tracking details in a remote server and hence I am making use of set_tracking_uri() function. Below is the sample code;\n\n\nset_tracking_uri('172.16.0.80:5000')\n\ntry:\n\u00a0 \u00a0 \u00a0 \u00a0 create_experiment(\"SampleExp\")\nexcept:\n\u00a0 \u00a0 \u00a0 \u00a0 set_experiment(\"SampleExp\")\nset_tag(\"Script\", \"SampleExp1\")\n\n\nThe mlflow server is running in the remote server. When I execute the model with 'mlflow run' command, only the experiment name gets created in the remote server path but mlruns directory and other tracking data gets stored in the path from where mlflow run command is getting executed locally. Kindly help me in resolving this issue.",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1579651256000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":37.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/9wmaxy3no30",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"remot track folk version model written python track purpos creat project mlproject file insid want store track detail remot server make us set track uri function sampl code set track uri try creat experi sampleexp set experi sampleexp set tag script sampleexp server run remot server execut model run command experi get creat remot server path mlrun directori track data get store path run command get execut local kindli help resolv issu",
        "Question_preprocessed_content":"remot track folk version model python track purpos creat project mlproject file insid want store track detail remot server make us function sampl code try server remot server execut model run experi get creat remot server path mlrun directori track data get store path run execut kindli help resolv",
        "Question_gpt_summary_original":"The user is facing an issue with MLflow remote tracking while using version 1.1.0. They have created a project with an MLproject file and are trying to store tracking details in a remote server using the set_tracking_uri() function. However, when executing the model with 'mlflow run' command, only the experiment name gets created in the remote server path, and the mlruns directory and other tracking data get stored in the path from where mlflow run command is getting executed locally.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"DVC Files Incomplete",
        "Question_body":"<p>I'm in a team using dvc with git to version-control data files. We are using dvc 1.3.1, with the an S3 bucket remote. I'm getting this error when executing <code>dvc fetch<\/code> or <code>dvc pull<\/code> on a colleague's branch:<\/p>\n<pre><code>ERROR: failed to fetch data from the cloud - DVC-file 'C:\\Users\\blah\\Documents\\repo\\data\\processed_data.dvc' format error: extra keys not allowed @ data['outs'][0]['size']\n<\/code><\/pre>\n<p>When I check the dvc file for a cached file with which I have no problem I see this:<\/p>\n<pre><code>md5: ded591aacbe363f0518ceb9c3bc1836b\nouts:\n- md5: efdab20e8b59903b9523cc188ff727e5\n  path: completion_header.p\n  cache: true\n  metric: false\n  persist: false\n<\/code><\/pre>\n<p>but a problematic file only has this:<\/p>\n<pre><code>outs:\n- md5: f4e15187d9a0bbb328e629eabd8d1784.dir\n  size: 112007\n  nfiles: 3\n  path: processed_data\n<\/code><\/pre>\n<p>In all cases, files are added to dvc with the command <code>dvc add %dirname%<\/code>. This is the second time I've seen this on a colleague's branch (2 different people).<\/p>\n<p>Since posting, I have realized that my colleague dvc'd a directory. I have attempted creating the directory first, then calling <code>dvc fetch<\/code>, but get the same error.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1618565400113,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1618826341416,
        "Question_score_count":2.0,
        "Question_view_count":548.0,
        "Poster_created_time":1348150034832,
        "Poster_location":"Glasgow, UK",
        "Poster_reputation_count":2400.0,
        "Poster_view_count":263.0,
        "Answer_body":"<blockquote>\n<p>In all cases, files are added to dvc with the command dvc add %filename%.<\/p>\n<\/blockquote>\n<p>It seems like there is a high chance that one of the dvc files created in newer versions of dvc and you are trying to operate with an older version. Are all of your colleagues use the same dvc version when adding new files?<\/p>",
        "Answer_comment_count":4.0,
        "Question_closed_time":1618566517710,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1614873430827,
        "Answerer_location":null,
        "Answerer_reputation_count":169.0,
        "Answerer_view_count":7.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67122683",
        "Tool":"DVC",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"file incomplet team git version control data file bucket remot get error execut fetch pull colleagu branch error fail fetch data cloud file user blah document repo data process data format error extra kei allow data out size check file cach file problem dedaacbefcebcbcb out efdabebbccff path complet header cach true metric fals persist fals problemat file out fedabbbeeabdd dir size nfile path process data case file ad command add dirnam second time seen colleagu branch differ peopl post realiz colleagu directori attempt creat directori call fetch error",
        "Question_preprocessed_content":"file incomplet team git data file bucket remot execut branch check file cach file problem problemat file case file second time branch post realiz directori creat directori",
        "Question_gpt_summary_original":"The user is encountering an error while using DVC with Git to version-control data files. The error occurs when executing \"dvc fetch\" or \"dvc pull\" on a colleague's branch, and the error message indicates a DVC-file format error. The problematic file has incomplete information in comparison to a cached file that is working fine. The files are added to DVC with the command \"dvc add %dirname%\". The user has attempted creating the directory first, but the error persists.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Sagemaker with windows",
        "Question_body":"<p>I am trying to use aws sagemaker with Windows using Docker :\nHere is the docker file :<\/p>\n\n<pre><code># Build an image that can do training and inference in SageMaker\n# This is a Python 2 image that uses the nginx, gunicorn, flask stack\n# for serving inferences in a stable way.\n\nFROM ubuntu:16.04\n\nMAINTAINER Amazon AI &lt;sage-learner@amazon.com&gt;\n\n\nRUN apt-get -y update &amp;&amp; apt-get install -y --no-install-recommends \\\n         wget \\\n         python3.5 \\\n         nginx \\\n         libgcc-5-dev \\\n         ca-certificates \\\n    &amp;&amp; rm -rf \/var\/lib\/apt\/lists\/*\n\n# Here we get all python packages.\n# There's substantial overlap between scipy and numpy that we eliminate by\n# linking them together. Likewise, pip leaves the install caches populated which uses\n# a significant amount of space. These optimizations save a fair amount of space in the\n# image, which reduces start up time.\nRUN wget https:\/\/bootstrap.pypa.io\/3.3\/get-pip.py &amp;&amp; python3.5 get-pip.py &amp;&amp; \\\n    pip3 install numpy==1.14.3 scipy scikit-learn==0.19.1 xgboost==0.72.1 pandas==0.22.0 flask gevent gunicorn &amp;&amp; \\\n        (cd \/usr\/local\/lib\/python3.5\/dist-packages\/scipy\/.libs; rm *; ln ..\/..\/numpy\/.libs\/* .) &amp;&amp; \\\n        rm -rf \/root\/.cache\n\n# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\n# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\n# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\n# PATH so that the train and serve programs are found when the container is invoked.\n\nENV PYTHONUNBUFFERED=TRUE\nENV PYTHONDONTWRITEBYTECODE=TRUE\nENV PATH=\"\/opt\/program:${PATH}\"\n\n# Set up the program in the image\nCOPY xgboost \/opt\/program\nWORKDIR \/opt\/program\n<\/code><\/pre>\n\n<p>My question is should I, since I work under windows 7, change these path : ?<\/p>\n\n<p>Thank you<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1534427312350,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":359.0,
        "Poster_created_time":1518617852856,
        "Poster_location":null,
        "Poster_reputation_count":495.0,
        "Poster_view_count":81.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51878668",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"window try us window docker docker file build imag train infer python imag us nginx gunicorn flask stack serv infer stabl wai ubuntu maintain amazon run apt updat apt instal instal recommend wget python nginx libgcc dev certif var lib apt list python packag substanti overlap scipi numpi elimin link likewis pip leav instal cach popul us signific space optim save fair space imag reduc start time run wget http bootstrap pypa pip python pip pip instal numpi scipi scikit learn xgboost panda flask gevent gunicorn usr local lib python dist packag scipi lib numpi lib root cach set environ variabl pythonunbuff keep python buffer standard output stream mean log deliv user quickli pythondontwritebytecod keep python write pyc file unnecessari case updat path train serv program contain invok env pythonunbuff true env pythondontwritebytecod true env path opt program path set program imag copi xgboost opt program workdir opt program question work window chang path thank",
        "Question_preprocessed_content":"window try us window docker docker file question work window chang path thank",
        "Question_gpt_summary_original":"The user is trying to use AWS Sagemaker with Windows using Docker and has provided a Docker file. The user is unsure if they need to change the paths in the file since they are working under Windows 7.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is my Jupyter Notebook hung?",
        "Question_body":"Is there anyway to tell if the current cell I am executing is hung? I am running an AutoGluon TabularPredictor().fit(). The cell it is executing is has the * indication that it is running, I checked the notebook running tab, and it says my notebook is running, but when I look at the AutoGluon models folder, it does not look like anything new has being written for hours.  \nAre there any other ways I can check to see if my model is still trying to fit?",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1662151013058,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1667926512076,
        "Question_score_count":0.0,
        "Question_view_count":47.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUmBX_HRdkTjKnKzg_15etmw\/is-my-jupyter-notebook-hung",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"jupyt notebook hung tell current cell execut hung run autogluon tabularpredictor fit cell execut indic run check notebook run tab sai notebook run look autogluon model folder look like new written hour wai check model try fit",
        "Question_preprocessed_content":"jupyt hung execut hung autogluon execut indic check tab sai autogluon model folder like new hour wai check model try fit",
        "Question_gpt_summary_original":"The user is running an AutoGluon TabularPredictor() in a Jupyter Notebook and is unsure if the current cell is hung. They have checked the notebook running tab and the AutoGluon models folder, but nothing new has been written for hours. The user is seeking advice on other ways to check if the model is still trying to fit.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML Python SDK v2 user defined environment",
        "Question_body":"<p>Hi, I'm trying to use v2 of the AML Python SDK, but I'm having problems defining a user defined environment. When I create a command object it requires an environment to be provided. But I can't find any documentation on how to create an environment that is user defined.     <\/p>\n<p>If I list the environments that the system has (az ml environment list) it has an environment called user-managed-env, but if I try and use it, I get an error stating that it can't be found.     <\/p>\n<p>Anyone know how to define a user managed environment with the v2 Python SDK?    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1670489210250,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1121319\/azure-ml-python-sdk-v2-user-defined-environment",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"python sdk user defin environ try us aml python sdk have problem defin user defin environ creat command object requir environ provid document creat environ user defin list environ environ list environ call user manag env try us error state know defin user manag environ python sdk",
        "Question_preprocessed_content":"python sdk user defin environ try us aml python sdk have problem defin user defin environ creat object requir environ provid document creat environ user defin list environ environ try us state know defin user manag environ python sdk",
        "Question_gpt_summary_original":"The user is having trouble defining a user-defined environment while using v2 of the Azure ML Python SDK. They are unable to find any documentation on how to create such an environment and are encountering errors when trying to use the pre-existing \"user-managed-env\" environment. They are seeking assistance in defining a user-managed environment with the v2 Python SDK.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Cloud Translation Permission",
        "Question_body":"So I'm pulling my hair out over this and reaching out here for help. I'm trying to set up a service account with Cloud Translation, and Text-to-speech enabled, but we keep getting this response:\n\n [error]  {\n    \"message\": \"Cloud IAM permission 'cloudtranslate.generalModels.predict' denied. \",\n    \"code\": 7,\n    \"status\": \"PERMISSION_DENIED\",\n    \"details\": []\n} \n\nI have confirmed that the service account has the \"cloudtranslate.generalModels.predict\" permission, and showing the \"Cloud Translation API User\" role. We've also confirmed that it works with a different Service account that my colleague set up in his personal Google console profile. But, we need this setup with an account through our org.\u00a0\n\nI did verify that the service account has the permission from the\u00a0https:\/\/console.cloud.google.com\/iam-admin\/troubleshooter\u00a0so and that my organization's admin sees that the service account is granted access through ancestor policies.\u00a0\u00a0\n\nSo what else can we check?",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1668497880000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":726.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Ok, turned out we had a hard-coded value for resource location, which was set to the wrong project. So of course it was coming back as permission denied.\u00a0\n\nView solution in original post",
        "Answer_comment_count":null,
        "Question_closed_time":"11-15-2022 08:30 AM",
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-Translation-Permission\/m-p\/489632#M785",
        "Tool":"Vertex AI",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"cloud translat permiss pull hair reach help try set servic account cloud translat text speech enabl get respons error messag cloud iam permiss cloudtransl generalmodel predict deni code statu permiss deni detail confirm servic account cloudtransl generalmodel predict permiss show cloud translat api user role confirm work differ servic account colleagu set person googl consol profil need setup account org verifi servic account permiss thehttp consol cloud googl com iam admin troubleshooterso organ admin see servic account grant access ancestor polici check",
        "Question_preprocessed_content":"cloud translat hair reach help try set servic cloud translat enabl respons confirm servic show cloud translat api user role confirm work servic set person consol profil setup org verifi servic organ admin servic grant ancestor polici check",
        "Question_gpt_summary_original":"The user is encountering an error message while setting up a service account with Cloud Translation and Text-to-speech enabled. The error message indicates that the Cloud IAM permission 'cloudtranslate.generalModels.predict' is denied. The user has confirmed that the service account has the required permission and works with a different service account set up by a colleague. The user is seeking help to resolve the issue and is unsure of what else to check.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to export a MLFlow Model from Azure Databricks as an Azure DevOps Artifacts for CD phase?",
        "Question_body":"<p>I am trying to create an MLOps Pipeline using Azure DevOps and Azure Databricks. From Azure DevOps, I am submitting a Databricks job to a cluster, which trains a Machine Learning Model and saves it into MLFlow Model Registry with a custom flavour (using PyFunc Custom Model).<\/p>\n<p>Now after the job gets over, I want to export this MLFlow Object (with all dependencies - Conda dependencies, two model files - one <code>.pkl<\/code> and one <code>.h5<\/code>, the Python Class with <code>load_context()<\/code> and <code>predict()<\/code> functions defined so that after exporting I can import it and call predict as we do with MLFlow Models).<\/p>\n<p>How do I export this entire MLFlow Model and save it as an AzureDevOps Artifact to be used in the CD phase (where I will deploy it to an AKS cluster with a custom base image)?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1629179063687,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":575.0,
        "Poster_created_time":1601729162436,
        "Poster_location":"Bengaluru, Karnataka, India",
        "Poster_reputation_count":887.0,
        "Poster_view_count":130.0,
        "Answer_body":"<p>There is no official way to export a Databricks MLflow run from one workspace to another. However, there is an &quot;unofficial&quot; tool that does most of the job with the main limitation being that notebook revisions linked to a run cannot be exported due to lack of a REST API endpoint for this.<\/p>\n<p><a href=\"https:\/\/github.com\/amesar\/mlflow-export-import\" rel=\"nofollow noreferrer\">https:\/\/github.com\/amesar\/mlflow-export-import<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1629787454223,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1595479476676,
        "Answerer_location":"Massachusetts, USA",
        "Answerer_reputation_count":246.0,
        "Answerer_view_count":21.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68812238",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"export model azur databrick azur devop artifact phase try creat mlop pipelin azur devop azur databrick azur devop submit databrick job cluster train machin learn model save model registri custom flavour pyfunc custom model job get want export object depend conda depend model file pkl python class load context predict function defin export import predict model export entir model save azuredevop artifact phase deploi ak cluster custom base imag",
        "Question_preprocessed_content":"export model azur databrick azur devop artifact phase try creat mlop pipelin azur devop azur databrick azur devop databrick job cluster train machin learn model save model registri custom flavour job get want export object export entir model save azuredevop artifact phase",
        "Question_gpt_summary_original":"The user is trying to create an MLOps Pipeline using Azure DevOps and Azure Databricks. They have trained a Machine Learning Model and saved it into MLFlow Model Registry with a custom flavour. The user wants to export this MLFlow Object with all dependencies and save it as an Azure DevOps Artifact to be used in the CD phase. They plan to deploy it to an AKS cluster with a custom base image.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML Designer - Replace existing real-time inference endpoint error",
        "Question_body":"<p>Hi,  <\/p>\n<p>When replacing an existing, healthy Azure ML End-point through the Azure ML Designer, I get the following error:  <\/p>\n<pre><code>Failed on Preparing to deploy. Details: AzureML service API error. Error calling ServicePatch: {&quot;code&quot;:&quot;BadRequest&quot;,&quot;statusCode&quot;:400,&quot;message&quot;:&quot;The request is invalid.&quot;,&quot;details&quot;:[{&quot;code&quot;:&quot;EmptyOrInvalidParameter&quot;,&quot;message&quot;:&quot;Cannot set both number of replicas and auto scale settings in the same request&quot;}],&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;14982e6e-dc63-4732-964b-55027243dac3&quot;}}\n<\/code><\/pre>\n<p>The current endpoint I'm trying to replace was created a few days ago. It has:   <\/p>\n<ul>\n<li> Autoscale enabled == true  <\/li>\n<li> Min\/Max replicas == 1\/10  <\/li>\n<\/ul>\n<p>The deploy menu does not contain an option to change or set these values. Therefore, I do not understand why the request fails.  <\/p>\n<p>Could you help me fix this issue?  <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":7.0,
        "Question_created_time":1613636477313,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/278158\/azure-ml-designer-replace-existing-real-time-infer",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"design replac exist real time infer endpoint error replac exist healthi end point design follow error fail prepar deploi detail servic api error error call servicepatch code badrequest statuscod messag request invalid detail code emptyorinvalidparamet messag set number replica auto scale set request correl requestid dac current endpoint try replac creat dai ago autoscal enabl true min max replica deploi menu contain option chang set valu understand request fail help fix issu",
        "Question_preprocessed_content":"design replac exist infer endpoint replac exist healthi design endpoint try replac creat dai ago autoscal enabl true replica deploi menu contain option chang set valu understand request fail help fix",
        "Question_gpt_summary_original":"The user is encountering an error while trying to replace an existing Azure ML real-time inference endpoint through the Azure ML Designer. The error message indicates that the request is invalid due to an attempt to set both the number of replicas and auto scale settings in the same request. The current endpoint has autoscale enabled with minimum and maximum replicas set to 1 and 10 respectively. The user is unable to change or set these values and is seeking assistance to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Secure Azure Machine Learning REST Endpoints (deployed in ACI) with TLS",
        "Question_body":"<p>We have developed and deployed machine learning models in AML Studio. The models were deployed using ACI and we have REST endpoints that we can make calls to successfully. Next thing that I need to do is to secure the endpoints using TLS. I am going through the following article:    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service#enable\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service#enable<\/a>    <\/p>\n<p>The article suggests that I need to get a domain and then update our DNS point to the IP address of scoring endpoint. I have a subdomain  ready to use but as for the IP address, I can't work out where I would get the IP address of the scoring endpoint and how I would even be able to map this to the endpoint as the current endpoint do not contain and IP address and look nothing like the example in the article.    <\/p>\n<p>URIs currently look like the following:    <br \/>\n<a href=\"http:\/\/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx.northeurope.azurecontainer.io\/score\">http:\/\/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx.northeurope.azurecontainer.io\/score<\/a>    <\/p>\n<p>Anyone able to help with this one please as it's a little confusing and I can't find any guidance online anywhere?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1615991231360,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello,<\/p>\n<p>You can do it according to DNS.<\/p>\n<p>A \u201cURL\u201d is a full specification to a page. For example:<\/p>\n<p><a href=\"http:\/\/example.com\/this_is_example.html\">http:\/\/example.com\/this_is_example.html<\/a> is a URL. It has three parts:<\/p>\n<p>The protocol specifier: http:<\/p>\n<p>The domain name: example.com<\/p>\n<p>The page location: \/this_is_example.html<\/p>\n<p>The protocol specifies the port that will be used. http, for example, is  <br \/>\nport 80. ftp uses ports 20 and 21. SMTP, the mail sending protocol, is usually  <br \/>\non port 25. You can actually find the full list of \u201cofficial\u201d ports here.<\/p>\n<p>It\u2019s only the domain name that has an IP address associated with it. So that\u2019s what you would be looking up.<\/p>\n<p>My approach is to use the \u201cping\u201d command in a Windows command prompt. For  <br \/>\nexample:<\/p>\n<p>C:\\&gt;ping example.com<\/p>\n<p>Then you can get it.<\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Answer_comment_count":2.0,
        "Question_closed_time":1616038303612,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/318807\/secure-azure-machine-learning-rest-endpoints-(depl",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"secur rest endpoint deploi aci tl develop deploi machin learn model aml studio model deploi aci rest endpoint call successfulli thing need secur endpoint tl go follow articl http learn microsoft com azur machin learn secur web servic enabl articl suggest need domain updat dn point address score endpoint subdomain readi us address work address score endpoint abl map endpoint current endpoint contain address look like exampl articl uri current look like follow http xxxxxxxx xxxx xxxx xxxx xxxxxxxxxxx northeurop azurecontain score abl help littl confus guidanc onlin",
        "Question_preprocessed_content":"secur rest endpoint tl develop deploi machin learn model aml studio model deploi aci rest endpoint thing secur endpoint tl go articl articl domain updat dn point score endpoint subdomain readi us work score endpoint abl map endpoint endpoint contain like exampl articl uri like abl help confus guidanc onlin",
        "Question_gpt_summary_original":"The user has developed and deployed machine learning models in AML Studio using ACI and has REST endpoints that need to be secured using TLS. They are following an article that suggests getting a domain and updating DNS point to the IP address of the scoring endpoint. However, the user is unable to find the IP address of the scoring endpoint and is confused about how to map it to the endpoint as the current endpoint does not contain an IP address. They are seeking help to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"mlflow How to save a sklearn pipeline with custom transformer?",
        "Question_body":"<p>I am trying to save with mlflow a sklearn machine-learning model, which is a pipeline containing a custom transformer I have defined, and load it in another project.\nMy custom transformer inherits from BaseEstimator and TransformerMixin.<\/p>\n\n<p>Let's say I have 2 projects:<\/p>\n\n<ul>\n<li>train_project: it has the custom transformers in src.ml.transformers.py<\/li>\n<li>use_project: it has other things in src, or has no src catalog at all<\/li>\n<\/ul>\n\n<p>So in my train_project I do :<\/p>\n\n<pre><code>mlflow.sklearn.log_model(preprocess_pipe, 'model\/preprocess_pipe')\n<\/code><\/pre>\n\n<p>and then when I try to load it into use_project :<\/p>\n\n<pre><code>preprocess_pipe = mlflow.sklearn.load_model(f'{ref_model_path}\/preprocess_pipe')\n<\/code><\/pre>\n\n<p>An error occurs :<\/p>\n\n<pre><code>[...]\nFile \"\/home\/quentin\/anaconda3\/envs\/api_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py\", line 210, in _load_model_from_local_file\n    return pickle.load(f)\nModuleNotFoundError: No module named 'train_project'\n<\/code><\/pre>\n\n<p>I tried to use format mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE :<\/p>\n\n<pre><code>mlflow.sklearn.log_model(preprocess_pipe, 'model\/preprocess_pipe', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n<\/code><\/pre>\n\n<p>but I get the same error during load.<\/p>\n\n<p>I saw option <strong>code_path<\/strong> into <strong>mlflow.pyfunc.log_model<\/strong> but its use and purpose is not clear to me. <\/p>\n\n<p>I thought mlflow provide a easy way to save model and serialize them so they can be used anywhere, Is that true only if you have native sklearn models (or keras, ...)?<\/p>\n\n<p>It's seem that this issue is more related to pickle functioning (mlflow use it and pickle needs to have all dependencies installed). <\/p>\n\n<p>The only solution I found so far is to make my transformer a package, import it in both project. Save version of my transformer library with <em>conda_env<\/em> argument of <em>log_model<\/em>, and check if it's same version when I load the model into my use_project.\nBut it's painfull if I have to change my transformer or debug in it...<\/p>\n\n<p>Is anybody have a better solution? \nMore elegent? Maybe there is some mlflow functionality I would have missed?<\/p>\n\n<p>other informations :<br>\nworking on linux (ubuntu)<br>\nmlflow=1.5.0<br>\npython=3.7.3   <\/p>\n\n<p>I saw in test of mlflow.sklearn api that they do a test with custom transformer, but they load it into the same file so it seems not resolve my issue but maybe it can helps other poeple :<\/p>\n\n<p><a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/tests\/sklearn\/test_sklearn_model_export.py\" rel=\"noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/tests\/sklearn\/test_sklearn_model_export.py<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1583338083850,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":8.0,
        "Question_view_count":3317.0,
        "Poster_created_time":1583251456143,
        "Poster_location":null,
        "Poster_reputation_count":81.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60530176",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save sklearn pipelin custom transform try save sklearn machin learn model pipelin contain custom transform defin load project custom transform inherit baseestim transformermixin let project train project custom transform src transform us project thing src src catalog train project sklearn log model preprocess pipe model preprocess pipe try load us project preprocess pipe sklearn load model ref model path preprocess pipe error occur file home quentin anaconda env api env lib python site packag sklearn line load model local file return pickl load modulenotfounderror modul name train project tri us format sklearn serial format cloudpickl sklearn log model preprocess pipe model preprocess pipe serial format sklearn serial format cloudpickl error load saw option code path pyfunc log model us purpos clear thought provid easi wai save model serial true nativ sklearn model kera issu relat pickl function us pickl need depend instal solut far transform packag import project save version transform librari conda env argument log model check version load model us project painful chang transform debug anybodi better solut eleg mayb function miss inform work linux ubuntu python saw test sklearn api test custom transform load file resolv issu mayb help poepl http github com blob master test sklearn test sklearn model export",
        "Question_preprocessed_content":"save sklearn pipelin custom transform try save sklearn model pipelin contain custom transform defin load project custom transform inherit transformermixin let project custom transform thing src src catalog try load tri us format load saw option us purpos clear thought provid easi wai save model serial true nativ sklearn model relat pickl function solut far transform packag import project save version transform librari argument check version load model chang transform debug anybodi solut eleg mayb function inform work linux saw test sklearn api test custom transform load file resolv mayb help poepl",
        "Question_gpt_summary_original":"The user is trying to save a machine learning model with a custom transformer using mlflow and load it into another project. However, an error occurs during loading, indicating that the module 'train_project' is not found. The user tried using the mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE option, but the error persists. The user is looking for a better solution to this issue and mentions that it may be related to the functioning of pickle. The only solution found so far is to make the transformer a package and import it in both projects.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Training yoloX",
        "Question_body":"<p>hi,<br>\ni am trying to enable logging for yolox nano, but when i start training i get this error :<\/p>\n<p>File \u201c\/content\/YOLOX\/yolox\/utils\/logger.py\u201d, line 206, in <strong>init<\/strong><br>\nself.cats = val_dataset.cats<br>\n\u2502           \u2514 &lt;yolox.data.datasets.voc.VOCDetection object at 0x7f6f1d379e10&gt;<br>\n\u2514 &lt;yolox.utils.logger.WandbLogger object at 0x7f6f1e77ed10&gt;<\/p>\n<p>AttributeError: \u2018VOCDetection\u2019 object has no attribute \u2018cats\u2019<\/p>\n<p>also this is my colab code:<br>\n!python tools\/train.py -f exps\/example\/yolox_voc\/yolox_voc_nano.py -d 1 -b 16 --fp16 -o --logger wandb wandb-project object-detectiontemp -c weights\/yolox_nano.pth<\/p>\n<p>could you please guide me or give me some hints on what should i do ?<br>\nbecause as i see there is a val_dataset variable, but i have no idea how do you fill that .<\/p>\n<p>thanks.<\/p>",
        "Question_answer_count":6,
        "Question_comment_count":null,
        "Question_created_time":1659089650950,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":151.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/training-yolox\/2825",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train yolox try enabl log yolox nano start train error file content yolox yolox util logger line init self cat val dataset cat attributeerror vocdetect object attribut cat colab code python tool train exp exampl yolox voc yolox voc nano logger project object detectiontemp weight yolox nano pth guid hint val dataset variabl idea thank",
        "Question_preprocessed_content":"train yolox try enabl yolox nano start train file line init vocdetect object cat colab code python project guid hint variabl idea thank",
        "Question_gpt_summary_original":"The user is encountering an error while trying to enable logging for yolox nano during training. The error is related to the 'cats' attribute of the 'VOCDetection' object. The user has shared their Colab code and is seeking guidance on how to fill the 'val_dataset' variable.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Using \"cv_splits_indices\" in AutoMLConfig (azureml)",
        "Question_body":"<p>When training an regression model with AutoMLConfig with n_cross_validations being a normal int, I'm facing no problems.<\/p>\n<p>Now I want to use TimeSeriesSplit as the cross validation method for training a model with AutoMLConfig. For this there is a &quot;cv_splits_indices&quot; argument where I put in a list of lists of indicis like the following when n_splits=5 in TimeSeriesSplit :<\/p>\n<pre><code>array([[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n        array([11, 12, 13, 14])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n        array([15, 16, 17, 18])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18]),\n        array([19, 20, 21, 22])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22]),\n        array([23, 24, 25, 26])],\n       [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26]),\n        array([27, 28, 29, 30])]], dtype=object)\n<\/code><\/pre>\n<p>Unfortunately when running the following cell:<\/p>\n<pre><code>automl_settings = {\n    &quot;iteration_timeout_minutes&quot;: 15,\n    &quot;experiment_timeout_hours&quot;: 0.3,\n    &quot;max_cores_per_iteration&quot; : -1,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;primary_metric&quot;: 'normalized_root_mean_squared_error',\n    &quot;featurization&quot;: 'auto',\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;cv_splits_indices&quot;: idxs\n}\n\nautoml_config = AutoMLConfig(task='regression',\n                             debug_log=f'automated_ml_errors_.log',\n                             training_data=train,\n                             validation_data=train,\n                             label_column_name=y_var,\n                             **automl_settings)\n<\/code><\/pre>\n<p>I receive the following error:<\/p>\n<pre><code>ConfigException: ConfigException:\n Message: cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.\n InnerException: None\n ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.&quot;,\n        &quot;details_uri&quot;: &quot;https:\/\/aka.ms\/AutoMLConfig&quot;,\n        &quot;target&quot;: &quot;cv_splits_indices&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;BadArgument&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;ArgumentInvalid&quot;\n            }\n        },\n        &quot;reference_code&quot;: &quot;XXXXXXREDACTEDXXXX&quot;\n    }\n}\n<\/code><\/pre>\n<p>What is going wrong here? Does my input look correct?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1614847805423,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1614857962623,
        "Question_score_count":1.0,
        "Question_view_count":37.0,
        "Poster_created_time":1506851088052,
        "Poster_location":"Vlaardingen, Netherlands",
        "Poster_reputation_count":175.0,
        "Poster_view_count":56.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66471547",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"split indic automlconfig train regress model automlconfig cross valid normal int face problem want us timeseriessplit cross valid method train model automlconfig split indic argument list list indici like follow split timeseriessplit arrai arrai arrai arrai arrai arrai arrai arrai arrai arrai arrai dtype object unfortun run follow cell automl set iter timeout minut experi timeout hour max core iter enabl earli stop true primari metric normal root mean squar error featur auto verbos log info split indic idx automl config automlconfig task regress debug log autom error log train data train valid data train label column var automl set receiv follow error configexcept configexcept messag split indic list list numpi ndarrai list numpi ndarrai correspond fold element indic train set valid set innerexcept errorrespons error code usererror messag split indic list list numpi ndarrai list numpi ndarrai correspond fold element indic train set valid set detail uri http aka automlconfig target split indic inner error code badargu inner error code argumentinvalid refer code xxxxxxredactedxxxx go wrong input look correct",
        "Question_preprocessed_content":"automlconfig train model automlconfig normal int face problem want us valid method train model automlconfig argument list list indici like unfortun receiv go wrong input",
        "Question_gpt_summary_original":"The user is facing an issue while using the \"cv_splits_indices\" argument in AutoMLConfig for training a regression model with TimeSeriesSplit as the cross-validation method. The user is receiving a ConfigException error stating that the \"cv_splits_indices\" argument should be a List of List[numpy.ndarray] with just 2 elements for each CV fold, but the user's input does not match this format.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Customize metric visualization in MLFlow UI when using mlflow.tensorflow.autolog()",
        "Question_body":"<p>I'm trying to integrate MLFlow to my project. Because I'm using <code>tf.keras.fit_generator()<\/code> for my training so I take advantage of <code>mlflow.tensorflow.autolog()<\/code>(<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.tensorflow.html#mlflow.tensorflow.autolog\" rel=\"nofollow noreferrer\">docs<\/a> here) to enable automatic logging of metrics and parameters:<\/p>\n<pre><code>    model = Unet()\n    optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n\n    metrics = [IOUScore(threshold=0.5), FScore(threshold=0.5)]\n    model.compile(optimizer, customized_loss, metrics)\n\n    callbacks = [\n        tf.keras.callbacks.ModelCheckpoint(&quot;model.h5&quot;, save_weights_only=True, save_best_only=True, mode='min'),\n        tf.keras.callbacks.TensorBoard(log_dir='.\/logs', profile_batch=0, update_freq='batch'),\n    ]\n\n\n    train_dataset = Dataset(src_dir=SOURCE_DIR)\n\n    train_data_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n\n   \n    with mlflow.start_run():\n        mlflow.tensorflow.autolog()\n        mlflow.log_param(&quot;batch_size&quot;, BATCH_SIZE)\n\n        model.fit_generator(\n            train_data_loader,\n            steps_per_epoch=len(train_data_loader),\n            epochs=EPOCHS,\n            callbacks=callbacks   \n            )\n<\/code><\/pre>\n<p>I expected something like this (just a demonstration taken from the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#visualizing-metrics\" rel=\"nofollow noreferrer\">docs<\/a>):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eG56Z.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eG56Z.png\" alt=\"Visualization on the docs\" \/><\/a><\/p>\n<p>However, after the training finished, this is what I got:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/fS1JD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fS1JD.png\" alt=\"f1_score visualization\" \/><\/a><\/p>\n<p>How can I configure so that the metric plot will update and display its value at each epoch instead of just showing the latest value?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1593764146630,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1594008626392,
        "Question_score_count":2.0,
        "Question_view_count":1035.0,
        "Poster_created_time":1467943515392,
        "Poster_location":"Danang, H\u1ea3i Ch\u00e2u District, Da Nang, Vietnam",
        "Poster_reputation_count":173.0,
        "Poster_view_count":28.0,
        "Answer_body":"<p>After searching around, I found <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/2390\" rel=\"nofollow noreferrer\">this issue<\/a> related to my problem above. Actually, all my metrics just logged once each training (instead of each epoch as my intuitive thought). The reason is I didn't specify the <code>every_n_iter<\/code> parameter in <code>mlflow.tensorflow.autolog()<\/code>, which indicates how many 'iterations' must pass before MLflow logs metric executed (see the <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tensorflow.html#mlflow.tensorflow.autolog\" rel=\"nofollow noreferrer\">docs<\/a>). So, changing my code to:<\/p>\n<p><code>mlflow.tensorflow.autolog(every_n_iter=1)<\/code><\/p>\n<p>fixed the problem.<\/p>\n<p>P\/s: Remember that in TF 2.x, an 'iteration' is an epoch (in TF 1.x it's a batch).<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1594008525280,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1467943515392,
        "Answerer_location":"Danang, H\u1ea3i Ch\u00e2u District, Da Nang, Vietnam",
        "Answerer_reputation_count":173.0,
        "Answerer_view_count":28.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62711259",
        "Tool":"MLflow",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"custom metric visual tensorflow autolog try integr project kera fit gener train advantag tensorflow autolog doc enabl automat log metric paramet model unet optim kera optim adam learn rate metric iouscor threshold fscore threshold model compil optim custom loss metric callback kera callback modelcheckpoint model save weight true save best true mode min kera callback tensorboard log dir log profil batch updat freq batch train dataset dataset src dir sourc dir train data loader dataload train dataset batch size shuffl true start run tensorflow autolog log param batch size batch size model fit gener train data loader step epoch len train data loader epoch epoch callback callback expect like demonstr taken doc train finish got configur metric plot updat displai valu epoch instead show latest valu",
        "Question_preprocessed_content":"custom metric visual try integr project train advantag enabl automat metric paramet expect like train finish got configur metric plot updat displai valu epoch instead show latest valu",
        "Question_gpt_summary_original":"The user is trying to integrate MLFlow into their project and is using mlflow.tensorflow.autolog() to enable automatic logging of metrics and parameters. They expected a visualization of metrics to be displayed at each epoch during training, but instead, only the latest value is shown. The user is seeking guidance on how to configure the metric plot to update and display its value at each epoch.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Missing delimiter error when importing html text",
        "Question_body":"<p>Playing with Azure Machine Learning using the Designer and am getting a &quot;Delimiter not found&quot; error when importing my data.<\/p>\n<p>I originally started with a few hundred html files stored as azure blobs. Each file would be considered a single row of text, however, I had no luck importing these files for further text analytics.<\/p>\n<p>I created a Data Factory job that imported each file, stripped all the tabs, quotes, cr\/lf from the text, added a column for the file name and stored it all as a combined tab-delimited file. In notepad++ I can confirm that the format is <code>FileName tab HtmlText<\/code>. This is the file I'm trying to import into ML and getting the missing delimiter message as I'm trying to define the import module.<\/p>\n<p>Here is the error when I try and create a dataset:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>{\n  &quot;message&quot;: &quot;'Delimiter' is not specified or invalid.&quot;\n}\n<\/code><\/pre>\n<p>Question 1: Is there a better way to do text analytics on a large collection of html files?<\/p>\n<p>Question 2: Is there a format I need to use in my combined .tsv file that works?<\/p>\n<p>Question 3: Is there maybe a max length to the string column? My html can be 10's of thousands of characters long.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1598396437553,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1598498523072,
        "Question_score_count":0.0,
        "Question_view_count":209.0,
        "Poster_created_time":1221591235460,
        "Poster_location":null,
        "Poster_reputation_count":936.0,
        "Poster_view_count":105.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63588251",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"miss delimit error import html text plai design get delimit error import data origin start html file store azur blob file consid singl row text luck import file text analyt creat data factori job import file strip tab quot text ad column file store combin tab delimit file notepad confirm format filenam tab htmltext file try import get miss delimit messag try defin import modul error try creat dataset messag delimit specifi invalid question better wai text analyt larg collect html file question format need us combin tsv file work question mayb max length string column html thousand charact long",
        "Question_preprocessed_content":"delimit import html text plai design delimit import data start html file store azur blob file consid singl row text luck import file text analyt creat data factori job import file tab quot text column file store combin file notepad confirm format file try import delimit try defin import modul try creat dataset question wai text analyt larg html file question format us combin tsv file work question mayb max length string column html thousand charact long",
        "Question_gpt_summary_original":"The user is encountering a \"Delimiter not found\" error when trying to import a combined tab-delimited file containing html text into Azure Machine Learning. They had previously imported hundreds of html files stored as azure blobs, but were unable to use them for text analytics. The user is seeking advice on a better way to perform text analytics on a large collection of html files, the correct format for the combined .tsv file, and whether there is a maximum length for the string column.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"SageMaker Distributed Training in Local Mode (inside Notebook Instances)",
        "Question_body":"<p>I've been using SageMaker for a while and have performed several experiments already with distributed training. I am wondering if it is possible to test and run SageMaker distributed training in local mode (using SageMaker Notebook Instances)?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662649911493,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":19.0,
        "Poster_created_time":1662649653072,
        "Poster_location":null,
        "Poster_reputation_count":3.0,
        "Poster_view_count":1.0,
        "Answer_body":"<p>No, not possible yet. <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/overview.html#local-mode\" rel=\"nofollow noreferrer\">local mode<\/a> does not support the distributed training with <code>local_gpu<\/code>for Gzip compression, Pipe Mode, or manifest files for inputs<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1662652096572,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1662621266503,
        "Answerer_location":null,
        "Answerer_reputation_count":48.0,
        "Answerer_view_count":6.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73651368",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"distribut train local mode insid notebook instanc perform experi distribut train wonder possibl test run distribut train local mode notebook instanc",
        "Question_preprocessed_content":"distribut train local mode perform experi distribut train wonder test run distribut train local mode",
        "Question_gpt_summary_original":"The user is familiar with SageMaker and has performed distributed training experiments. They are now seeking to know if it is possible to test and run SageMaker distributed training in local mode using SageMaker Notebook Instances.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Cannot use ```%matplotlib qt``` in Jupyter notebook in Azure Machine Learning",
        "Question_body":"<p>I am asking this question again, because I haven't got any update for my previous question, even though I have made new comments 20 days ago to describe my issue. The question can be found <a href=\"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/459776\/cannot-use-matplotlib-qt-in-jupyter-notebook-in-az.html\">here<\/a>.    <\/p>\n<p>To summarize:     <br \/>\nAfter restarting the kernel, I run the following suggested solution    <br \/>\n<code>import matplotlib<\/code>    <br \/>\n<code>matplotlib.use('Qt5Agg')<\/code>    <br \/>\n<code>import matplotlib.pyplot as plt<\/code>    <br \/>\n, and still got the same error:    <\/p>\n<pre><code>   ImportError: Cannot load backend 'Qt5Agg' which requires the 'qt5' interactive framework, as 'headless' is currently running  \n<\/code><\/pre>\n<p>Can someone please help me to solve this problem? It is really important for me to use interactive plots.    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1626886810050,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/484527\/cannot-use-matplotlib-qt-in-jupyter-notebook-in-az",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us matplotlib jupyt notebook ask question haven got updat previou question new comment dai ago issu question summar restart kernel run follow suggest solut import matplotlib matplotlib us qtagg import matplotlib pyplot plt got error importerror load backend qtagg requir interact framework headless current run help solv problem import us interact plot",
        "Question_preprocessed_content":"us jupyt ask question haven got updat previou question new dai ago question restart kernel run solut got help solv problem import us interact plot",
        "Question_gpt_summary_original":"The user is unable to use `%matplotlib qt` in Jupyter notebook in Azure Machine Learning. They have tried a suggested solution but still receive an error message stating that the backend 'Qt5Agg' cannot be loaded as 'headless' is currently running. The user is seeking help to resolve this issue as interactive plots are important for their work.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"mlflow.pyfunc.log_model doesn't work correctly when artifact storage is HDFS and artifact size is size higher than 2gb",
        "Question_body":"Hello MLflow team\n\n\nThere is an issue on pyarrow side which leads to the following misbehaving of MLflow when artifacts are kept on HDFS:\n\n\n1. When a size of an artifact is less than 6144mb, then\u00a0mlflow.pyfunc.log_model uploads corrupted artifact to HDFS with size not greater than 2gb.\n\n2. When a size of an artifact is higher or equals to 6144mb, then there will be an exception.\n\n\nStacktrace:\n\"\"\"\nsite-packages\/mlflow\/store\/artifact\/hdfs_artifact_repo.py in log_artifacts(self, local_dir, artifact_path)\n\u00a0 \u00a0 \u00a066\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0destination = posixpath.join(hdfs_subdir_path, each_file)\n\u00a0 \u00a0 \u00a067\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0with hdfs.open(destination, 'wb') as output_stream:\n---> 68\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0output_stream.write(open(source, \"rb\").read())\n\u00a0 \u00a0 \u00a069\u00a0\n\u00a0 \u00a0 \u00a070\u00a0 \u00a0 \u00a0def list_artifacts(self, path=None):\n\n\nsite-packages\/pyarrow\/io.pxi in pyarrow.lib.NativeFile.write()\nsite-packages\/pyarrow\/error.pxi in pyarrow.lib.check_status()\n\n\nOSError: HDFS Write failed, errno: 22 (Invalid argument)\n\"\"\"\n\n\n\nPython script to reproduce the issue just on pyarrow lib:\n\"\"\"\n\nimport os\nimport pyarrow as pa\n\nos.environ[\"JAVA_HOME\"]=\"<java_home>\"\nos.environ['ARROW_LIBHDFS_DIR'] = \"<path>\/libhdfs.so\"\nconnected = pa.hdfs.connect(host=\"<host>\",port=8020)\ndestination = \"hdfs:\/\/<host>:8020\/user\/tmp\/6144m.txt\"\nsource = \"\/tmp\/6144m.txt\"\nwith connected.open(destination, \"wb\") as output_stream:\n\u00a0 \u00a0 output_stream.write(open(source, \"rb\").read())\nconnected.close()\n\n\"\"\"\n\n\n\nThe issue was reported to pyarrow team and the answer is:\n\"\"\"\nIt appears that writes over 2GB are implemented incorrectly.\nhttps:\/\/github.com\/apache\/arrow\/blob\/master\/cpp\/src\/arrow\/io\/hdfs.cc#L277\n\nthe tSize type in libhdfs is an int32_t. So that static cast is truncating data\nhttps:\/\/issues.apache.org\/jira\/browse\/ARROW-11391\n\nI would recommend breaking the work into smaller pieces as a workaround\n\n\"\"\"\n\n\nCheers,\nSergey",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1611675747000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":165.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/xKI3gYkayYU",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pyfunc log model work correctli artifact storag hdf artifact size size higher hello team issu pyarrow lead follow misbehav artifact kept hdf size artifact pyfunc log model upload corrupt artifact hdf size greater size artifact higher equal except stacktrac site packag store artifact hdf artifact repo log artifact self local dir artifact path destin posixpath join hdf subdir path file hdf open destin output stream output stream write open sourc read def list artifact self path site packag pyarrow pxi pyarrow lib nativefil write site packag pyarrow error pxi pyarrow lib check statu oserror hdf write fail errno invalid argument python script reproduc issu pyarrow lib import import pyarrow environ java home environ arrow libhdf dir libhdf connect hdf connect host port destin hdf user tmp txt sourc tmp txt connect open destin output stream output stream write open sourc read connect close issu report pyarrow team answer appear write implement incorrectli http github com apach arrow blob master cpp src arrow hdf tsize type libhdf int static cast truncat data http issu apach org jira brows arrow recommend break work smaller piec workaround cheer sergei",
        "Question_preprocessed_content":"work artifact storag hdf artifact size size higher team lead misbehav artifact kept hdf size artifact upload artifact hdf size greater size artifact higher equal except stacktrac destin def path hdf write fail python script reproduc lib import import destin sourc open close report team answer write implement tsize type libhdf static cast truncat data break work piec workaround sergei",
        "Question_gpt_summary_original":"The user is facing an issue with mlflow.pyfunc.log_model when the artifact storage is HDFS and the artifact size is greater than 2GB. When the artifact size is less than 6144MB, the uploaded artifact is corrupted. When the artifact size is equal to or greater than 6144MB, an exception is thrown. The issue has been reported to the pyarrow team, who suggest breaking the work into smaller pieces as a workaround.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure machine learning compute local",
        "Question_body":"<p>Hello all, I have followed the <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-azure-ml-in-a-day\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-azure-ml-in-a-day<\/a> tutorial with successful result. Now, instead of using the compute cluster, i would like to use the resources of my local computer to run the job. I change the compute option to 'local' in the command function, but throws me an error: JobException: Failed to read in local executable job. Do i need additional configuration? Thanks in advance.<\/p>",
        "Question_answer_count":6,
        "Question_comment_count":3.0,
        "Question_created_time":1669634912270,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1106844\/azure-machine-learning-compute-local",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"comput local hello follow http learn microsoft com azur machin learn tutori azur dai tutori success result instead comput cluster like us resourc local run job chang comput option local command function throw error jobexcept fail read local execut job need addit configur thank advanc",
        "Question_preprocessed_content":"comput local tutori result instead comput cluster like us resourc local run job chang comput option local function throw jobexcept fail read local execut job configur thank advanc",
        "Question_gpt_summary_original":"The user followed a tutorial on Azure machine learning and wants to use their local computer resources instead of the compute cluster. However, changing the compute option to 'local' in the command function results in an error: JobException: Failed to read in local executable job. The user is seeking advice on whether additional configuration is needed.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"SageMaker Model Monitor Data Quality on Random Cut Forest configuration issues",
        "Question_body":"I am trying to set up a Random Cut Forest model with a Data Quality job attached.\nI managed to train and deploy the model with the \"data_capture\" feature enabled.\n\n``` python\n# Training\nrcf = sagemaker.RandomCutForest(\n    role=role,\n    instance_count=1,\n    instance_type='ml.m4.xlarge',\n    data_location=f\"s3:\/\/{BUCKET}\/random_cut_forest\/input\",\n    output_path=f's3:\/\/{BUCKET}\/random_cut_forest\/output',\n    num_sample_per_tree=1024,\n    num_trees=50,\n    serializer=JSONSerializer(),\n    deserializer=CSVDeserializer()\n)\nrs = rcf.record_set(df_multi_measurements.drop(\"datetime\", axis=1).to_numpy())\nrcf.fit(rs, wait=False)\n```\n\n``` python\n# Deploy\ndata_capture_config = DataCaptureConfig(\n    enable_capture=True, \n    sampling_percentage=100, \n    destination_s3_uri=s3_capture_upload_path\n)\nrcf_inference = rcf.deploy(\n    initial_instance_count=1, \n    instance_type='ml.m4.xlarge',\n    endpoint_name=ENDPOINT_NAME,\n    data_capture_config=data_capture_config,\n    serializer=CSVSerializer(),\n    deserializer=JSONDeserializer(),\n    )\n```\nThen, I configured and started the ModelMonitor job\n\n``` python\n# Model Monitor\nmy_default_monitor = DefaultModelMonitor(\n    role=role,\n    instance_count=1,\n    instance_type=\"ml.m4.xlarge\",\n    volume_size_in_gb=5,\n    max_runtime_in_seconds=3600\n)\n\nmy_default_monitor.suggest_baseline(\n    baseline_dataset=baseline_data_uri + \"\/df_multi_measurements.csv\",\n    dataset_format=DatasetFormat.csv(header=True),\n    output_s3_uri=baseline_results_uri,\n    wait=True,\n    logs=False\n)\n\nmy_default_monitor.create_monitoring_schedule(\n    monitor_schedule_name=mon_schedule_name,\n    endpoint_input=rcf_inference.endpoint,\n    output_s3_uri=s3_report_path,\n    statistics=my_default_monitor.baseline_statistics(),\n    constraints=my_default_monitor.suggested_constraints(),\n    schedule_cron_expression=CronExpressionGenerator.hourly(),\n    enable_cloudwatch_metrics=True,\n)\n```\n\nBut at the first run of the job I got this error:\n\n> Error: Encoding mismatch: Encoding is CSV for endpointInput, but Encoding is JSON for endpointOutput. We currently only support the same type of input and output encoding at the moment.\n\nData captured looked like: \n```\n{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text\/csv\",\"mode\":\"INPUT\",\"data\":\"4.150000013333333,3.330000003333333,...\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"application\/json\",\"mode\":\"OUTPUT\",\"data\":\"{\\\"scores\\\":[{\\\"score\\\":0.5794829282}]}\",\"encoding\":\"JSON\"}},\"eventMetadata\":{\"eventId\":\"79add993-68cf-4903-9dfe-8275d164496f\",\"inferenceTime\":\"2023-03-17T14:10:08Z\"},\"eventVersion\":\"0\"}\n...\n```\n\nSo later I tried to force input and output to be both CSV but no luck.\n\nAfter some tuning, I managed to instruct DataCapture to only collect requests in JSON so, since I couldn't change the output, now DataCapture has both input and output in the same (JSON) form. \n\nThe JSON requests look like this:\n``` json\n{\n    \"instances\": [\n        {\n            'features': [3.8600000533333336, 3.5966666533333336...]\n        }, \n        ...\n    ]\n}\n```\nand the model correctly works, returning its predictions: \n```\nb'{\"scores\":[{\"score\":0.6015237349},...]}'\n```\n\nData captured now looks like: \n```\n{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"application\/json\",\"mode\":\"INPUT\",\"data\":\"{\\\"instances\\\": [{\\\"features\\\": [3.8600000533333336, 3.5966666533333336, ...]}]}\",\"encoding\":\"JSON\"},\"endpointOutput\":{\"observedContentType\":\"application\/json\",\"mode\":\"OUTPUT\",\"data\":\"{\\\"scores\\\":[{\\\"score\\\":0.6015237349},{\\\"score\\\":0.4439660733},{\\\"score\\\":0.5100689867},{\\\"score\\\":0.5456048291},{\\\"score\\\":0.5099260466}]}\",\"encoding\":\"JSON\"}},\"eventMetadata\":{\"eventId\":\"27e2c9cd-3301-419c-8d06-9ede4c6380e6\",\"inferenceTime\":\"2023-03-17T17:10:18Z\"},\"eventVersion\":\"0\"}\n```\n\nBUT... at the first run of this new configuration, the job returns an error on the data analysis part.\n\nSo, after some search, I found that model monitor only works with tabular data or plain json, so I added a preprocessing step into the ModelMonitor\nhttps:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-monitor-pre-and-post-processing.html\n\nThe preprocessing script looks like this:\n\n```\nimport json\nimport random\n\n\"\"\"\n{\n    \"instances\": [\n        {\n            'features': [3.8600000533333336, 3.5966666533333336...]\n        }\n        ...\n    ]\n}\n\"\"\"\n\ndef preprocess_handler(inference_record):\n    input_record = inference_record.endpoint_input.data\n    print(input_record)\n    input_record_dict = json.loads(input_record)\n    \n    features = input_record_dict[\"instances\"][0]['features']\n    \n    return { str(i).zfill(20) : d for i, d in enumerate(features) }\n\n```\n\nAnd now, at the first run, again, I get an error that this time is absolutely NOT understandable at all:\n```\n2023-03-17 18:08:46,326 ERROR Main: No usable value for features\n2023-03-17T19:08:46.935+01:00\tNo usable value for completeness\n2023-03-17T19:08:46.935+01:00\tDid not find value which can be converted into double\n```\n\nAt this stage I feel a bit stuck. \nHow can this be fixed? RCF and ModelMonitor should be easier to be integrated in my opinion.\n\nWhat I am doing wrong?",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1679132698384,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1679480883548,
        "Question_score_count":0.0,
        "Question_view_count":119.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU4b9exAY8TJOwKGMUCRfZFg\/sagemaker-model-monitor-data-quality-on-random-cut-forest-configuration-issues",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model monitor data qualiti random cut forest configur issu try set random cut forest model data qualiti job attach manag train deploi model data captur featur enabl python train rcf randomcutforest role role instanc count instanc type xlarg data locat bucket random cut forest input output path bucket random cut forest output num sampl tree num tree serial jsonseri deseri csvdeseri rcf record set multi measur drop datetim axi numpi rcf fit wait fals python deploi data captur config datacaptureconfig enabl captur true sampl percentag destin uri captur upload path rcf infer rcf deploi initi instanc count instanc type xlarg endpoint endpoint data captur config data captur config serial csvserial deseri jsondeseri configur start modelmonitor job python model monitor default monitor defaultmodelmonitor role role instanc count instanc type xlarg volum size max runtim second default monitor suggest baselin baselin dataset baselin data uri multi measur csv dataset format datasetformat csv header true output uri baselin result uri wait true log fals default monitor creat monitor schedul monitor schedul mon schedul endpoint input rcf infer endpoint output uri report path statist default monitor baselin statist constraint default monitor suggest constraint schedul cron express cronexpressiongener hourli enabl cloudwatch metric true run job got error error encod mismatch encod csv endpointinput encod json endpointoutput current support type input output encod moment data captur look like capturedata endpointinput observedcontenttyp text csv mode input data encod csv endpointoutput observedcontenttyp applic json mode output data score score encod json eventmetadata eventid add dfe inferencetim eventvers later tri forc input output csv luck tune manag instruct datacaptur collect request json couldn chang output datacaptur input output json form json request look like json instanc featur model correctli work return predict score score data captur look like capturedata endpointinput observedcontenttyp applic json mode input data instanc featur encod json endpointoutput observedcontenttyp applic json mode output data score score score score score score encod json eventmetadata eventid eccd edec inferencetim eventvers run new configur job return error data analysi search model monitor work tabular data plain json ad preprocess step modelmonitor http doc aw amazon com latest model monitor pre post process html preprocess script look like import json import random instanc featur def preprocess handler infer record input record infer record endpoint input data print input record input record dict json load input record featur input record dict instanc featur return str zfill enumer featur run error time absolut understand error main usabl valu featur usabl valu complet valu convert doubl stage feel bit stuck fix rcf modelmonitor easier integr opinion wrong",
        "Question_preprocessed_content":"model monitor data qualiti random cut forest configur try set random cut forest model data qualiti job manag train deploi model featur enabl configur start modelmonitor job run job got encod mismatch encod csv endpointinput encod json endpointoutput type input output encod moment data captur like later tri forc input output csv luck tune manag instruct datacaptur request json couldn chang output datacaptur input output form json request like model work return predict data captur like run new configur job return data analysi search model monitor work tabular data plain json step modelmonitor script like run time absolut understand stage bit stuck fix rcf modelmonitor easier integr opinion wrong",
        "Question_gpt_summary_original":"The user is encountering issues with configuring SageMaker Model Monitor Data Quality on Random Cut Forest. They were able to train and deploy the model with the \"data_capture\" feature enabled, but encountered an error with encoding mismatch during the first run of the ModelMonitor job. They tried to force input and output to be both CSV but were unsuccessful. Later, they managed to instruct DataCapture to only collect requests in JSON, but encountered an error on the data analysis part. They added a preprocessing step into the ModelMonitor, but encountered an error that is not understandable. The user is seeking help to fix the issue and feels that RCF and ModelMonitor should be easier to integrate.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Export panel between sweeps",
        "Question_body":"<p>Hi,<\/p>\n<p>Is there a way to export custom plots I created in one sweep to the dashboard of another?<br>\nSpecifically, I used the \u201cadd section\u201d button to create a new section, and added custom plots to it. I would like to move this section \\ panel as a whole to another sweep.<\/p>\n<p>Is it possible somehow? It could save me a lot of time instead of setting it again and again for every sweep.<\/p>\n<p>Thanks,<br>\nTom<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1649060013695,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":347.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/export-panel-between-sweeps\/2186",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"export panel sweep wai export custom plot creat sweep dashboard specif add section button creat new section ad custom plot like section panel sweep possibl save lot time instead set sweep thank tom",
        "Question_preprocessed_content":"export panel wai export custom plot creat dashboard section creat new section custom plot like section panel save lot time instead thank tom",
        "Question_gpt_summary_original":"The user is looking for a way to export custom plots created in one sweep to the dashboard of another sweep. They have created a new section using the \"add section\" button and added custom plots to it, and want to move this section as a whole to another sweep to save time.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Batch size and other config parameters are inaccessible in the dashboard",
        "Question_body":"<p>I run this line right before the training loop:<\/p>\n<pre><code class=\"lang-auto\">wandb.config = {\n\"train_steps\": train_steps,\n\"batch_size\": batch_size,\n\"unet1_dim\": unet1_dim,\n\"unet2_dim\": unet2_dim,\n\"unet_training\": unet_training,\n}\n<\/code><\/pre>\n<p>But on the dashboard, I can\u2019t seem to find anything related to batch size. All of the data logged with <code>wandb.log<\/code> is present, but nothing about my hyperparameters. It may be relevant that I\u2019m running offline and syncing with the command <code>wandb sync --sync-all<\/code>.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1676583103752,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":143.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello Jaden!<\/p>\n<p>Could try logging your  <code>wandb.config<\/code>  using the following code snippet? Just in case, some further documentation on logging your config can be found <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/config#overview\">here<\/a>.<\/p>\n<pre><code class=\"lang-auto\">config = { \"train_steps\": train_steps, \"batch_size\": batch_size, \"unet1_dim\": unet1_dim, \"unet2_dim\": unet2_dim, \"unet_training\": unet_training }\nwandb.init(project = '&lt;your-project&gt;', config = config)\n<\/code><\/pre>",
        "Answer_comment_count":null,
        "Question_closed_time":1676671449996,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/batch-size-and-other-config-parameters-are-inaccessible-in-the-dashboard\/3897",
        "Tool":"Weights & Biases",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"batch size config paramet inaccess dashboard run line right train loop config train step train step batch size batch size unet dim unet dim unet dim unet dim unet train unet train dashboard relat batch size data log log present hyperparamet relev run offlin sync command sync sync",
        "Question_preprocessed_content":"batch size config paramet dashboard run line right train dashboard relat batch size data present hyperparamet relev sync",
        "Question_gpt_summary_original":"The user is unable to access batch size and other configuration parameters in the dashboard despite logging them using wandb.log. The user suspects that running offline and syncing with the command wandb sync --sync-all may be the cause of the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to automate dvc pull request for a single file?",
        "Question_body":"<p>We are using dvc for heavy AI-ML model files in our gitlab repository.<br>\nLets say, with the help of DVC, we can easily push a model file \u2018X\u2019 to cloud but while pulling    same file on some other server, we have to use command \u201cdvc pull X\u201d.<\/p>\n<p>Currently, we run this command \u201cdvc pull X\u201d manually everytime we update our file X. Since, we dont want to pull all the updated files on cloud therefore it is necessary for us to specify \u2018X\u2019 in our dvc pull requests.<\/p>\n<p>My question is how can we automate this dvc pull request in our CI yaml file for a single file X, if this X is a variable for our file name ?<\/p>",
        "Question_answer_count":6,
        "Question_comment_count":null,
        "Question_created_time":1613106444368,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":2491.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/how-to-automate-dvc-pull-request-for-a-single-file\/666",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"autom pull request singl file heavi model file gitlab repositori let help easili push model file cloud pull file server us command pull current run command pull manual everytim updat file dont want pull updat file cloud necessari specifi pull request question autom pull request yaml file singl file variabl file",
        "Question_preprocessed_content":"autom request singl file heavi model file gitlab repositori let help easili push model file cloud file server us run everytim updat file dont want updat file cloud specifi request question autom request yaml file singl file variabl file",
        "Question_gpt_summary_original":"The user is facing a challenge in automating the dvc pull request for a single file in their gitlab repository. They are currently manually running the command \"dvc pull X\" every time they update the file and want to automate this process in their CI yaml file. They need to specify 'X' in their dvc pull requests and are looking for a way to automate this process for a variable file name.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Can not pull public ECR image using AWS SageMaker Estimator",
        "Question_body":"<p>I would like to pass a public Docker Image on ECR through the image_uri parameter to the Estimator. However, the training job fails to find this image.\nI'm running my code using AWS SageMaker Notebook instance.<\/p>\n<pre><code>from sagemaker.estimator import Estimator\n\nbyoc_image_uri = 'public.ecr.aws\/v8x6t9d9\/train-image-classifier-firefly'\n\nestimator = Estimator(image_uri=byoc_image_uri,\n                      role=role,\n                      base_job_name='tf-custom-container-test-job',\n                      instance_count=1,\n                      hyperparameters=hyperparameters,\n                      output_path=output_path,\n                      instance_type='ml.p2.xlarge')\n<\/code><\/pre>\n<p>What I have tried:<\/p>\n<ul>\n<li>I first tried to use the same image on an ECR privet repo. This works<\/li>\n<li>Then pushed the same image to a public ECR repo that I had created. The image was successfully pushed and I could pull this image successfully.<\/li>\n<li>However, when I tried to use the same image url through Estimator image_uri parameter. I get the following error message<\/li>\n<\/ul>\n<pre><code>    ClientError: An error occurred (ValidationException) when calling the CreateTrainingJob operation: TrainingImageConfig with TrainingRepositoryAccessMode set to VPC must be provided when using a training image from a private Docker registry. Please provideTrainingImageConfig and TrainingRepositoryAccessMode set to VPC when using a training image from a private Docker registry.\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1631756389253,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1632521317307,
        "Question_score_count":1.0,
        "Question_view_count":396.0,
        "Poster_created_time":1631755332636,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69201461",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pull public ecr imag estim like pass public docker imag ecr imag uri paramet estim train job fail imag run code notebook instanc estim import estim byoc imag uri public ecr aw vxtd train imag classifi firefli estim estim imag uri byoc imag uri role role base job custom contain test job instanc count hyperparamet hyperparamet output path output path instanc type xlarg tri tri us imag ecr privet repo work push imag public ecr repo creat imag successfulli push pull imag successfulli tri us imag url estim imag uri paramet follow error messag clienterror error occur validationexcept call createtrainingjob oper trainingimageconfig trainingrepositoryaccessmod set vpc provid train imag privat docker registri providetrainingimageconfig trainingrepositoryaccessmod set vpc train imag privat docker registri",
        "Question_preprocessed_content":"public ecr imag estim like public docker imag ecr paramet estim train job fail imag code instanc tri tri us imag ecr privet repo work push imag public ecr repo creat imag push imag tri us imag url estim paramet",
        "Question_gpt_summary_original":"The user is unable to pull a public Docker image from ECR using AWS SageMaker Estimator. The training job fails to find the image, and the user receives an error message stating that TrainingImageConfig with TrainingRepositoryAccessMode set to VPC must be provided when using a training image from a private Docker registry. The user has tried using the same image on a private ECR repo, which works, but encounters issues when using a public ECR repo.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AzureMLCompute job failed with `FailedLoginToImageRegistry`",
        "Question_body":"<p>I've been trying to send a train job through azure ml python sdk with:<\/p>\n<pre><code>from azureml.core import Workspace, Experiment, ScriptRunConfig \n\nif __name__ == &quot;__main__&quot;:\n    ws = Workspace.from_config()\n    experiment = Experiment(workspace=ws, name='ConstructionTopicsModel')\n\n    config = ScriptRunConfig(source_directory='.\/',\n                         script='src\/azureml\/train.py',\n                         arguments=None,\n                         compute_target='ComputeTargetName',\n                         )\n\n    env = ws.environments['test-env']\n    config.run_config.environment = env\n    run = experiment.submit(config)\n    \n    run.wait_for_completion(show_output=True)\n\n    aml_url = run.get_portal_url()\n    print(aml_url)\n<\/code><\/pre>\n<p>But I was getting the <code>ServiceError<\/code> message:<\/p>\n<pre><code>AzureMLCompute job failed. FailedLoginToImageRegistry: Unable to login to docker image repo\nReason: Failed to login to the docker registry\nerror: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nserviceURL: 7ac86b04d6564d36aa80ae2ad090582c.azurecr.io\nReason: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n<\/code><\/pre>\n<p>I also tried using the azure cli without success, same error message<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1643645330913,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":202.0,
        "Poster_created_time":1589293508567,
        "Poster_location":null,
        "Poster_reputation_count":833.0,
        "Poster_view_count":55.0,
        "Answer_body":"<p>The only way I've found so far to make this work, was to run it on a terminal of the compute-target itself. That's how the docker error goes away. Trying to run the experiment from a terminal of a different compute instance raises the exception.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1643645330912,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1589293508567,
        "Answerer_location":null,
        "Answerer_reputation_count":833.0,
        "Answerer_view_count":55.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70929123",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"comput job fail failedlogintoimageregistri try send train job python sdk core import workspac experi scriptrunconfig main workspac config experi experi workspac constructiontopicsmodel config scriptrunconfig sourc directori script src train argument comput target computetargetnam env environ test env config run config environ env run experi submit config run wait complet output true aml url run portal url print aml url get serviceerror messag comput job fail failedlogintoimageregistri unabl login docker imag repo reason fail login docker registri error warn password cli insecur us password stdin error save credenti error store credenti err exit statu autolaunch bu displai serviceurl acbddaaaeadc azurecr reason warn password cli insecur us password stdin error save credenti error store credenti err exit statu autolaunch bu displai info fail setup runtim job execut job environ prepar fail err exit statu tri azur cli success error messag",
        "Question_preprocessed_content":"comput job fail try send train job python sdk tri azur cli",
        "Question_gpt_summary_original":"The user encountered an issue while trying to send a train job through Azure ML Python SDK. The job failed with a \"FailedLoginToImageRegistry\" error message, indicating that the user was unable to login to the docker image repo. The error message also suggested using \"--password-stdin\" instead of \"--password\" via the CLI. The user also tried using the Azure CLI but encountered the same error message.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Response From AWS SageMaker InvokeEndpoint Returning NULL Body (Guzzle Stream) (AWS SDK for PHP)",
        "Question_body":"<p>I am using the AWS PHP SDK to retrieve a prediction from a SageMaker Model.  The response comes back as successful, however, the body is a Null or Guzzle stream.  I know it's getting the prediction successfully since the content-length value is exactly the same as what I get when using the AWS CLI to run the prediction (which works fine).  Below is my code as well as the $result object.  I have also tested adding the &quot;accept&quot; field to the InvokeEndpoint with various MIME types with no success.  If anyone has run into similar issues please let me know!<\/p>\n<p>Any help is greatly appreciated!<\/p>\n<p><strong>Code<\/strong><\/p>\n<pre><code>use Aws\\SageMakerRuntime\\SageMakerRuntimeClient;\n\n\/\/ Build Client\n$client = new Aws\\SageMakerRuntime\\SageMakerRuntimeClient([\n                        'region' =&gt; 'us-east-1',\n                        'version' =&gt; &quot;latest&quot;,\n                        'credentials' =&gt; [\n                            'key'    =&gt; 'XXXXXXXXXXXXXX',\n                            'secret' =&gt; 'XXXXXXXXXXXXXX',\n                        ]\n]);\n\n\/\/ Invoke Endpoint\n$result = $client-&gt;invokeEndpoint([\n    'Body' =&gt; '{&quot;instances&quot;: [{&quot;in0&quot;:[13127,Sunrise Tells The Story,Midland,605,1\/16\/22,50,2197,9329,2071,53,574,39,483,122]}]}',\n    'ContentType' =&gt; 'text\/csv',\n    'EndpointName' =&gt; 'Sagemaker-Before-10-24-21'\n]);\n<\/code><\/pre>\n<p><strong>Result<\/strong><\/p>\n<pre><code>object(Aws\\Result)#124 (2) {\n  [&quot;data&quot;:&quot;Aws\\Result&quot;:private]=&gt;\n  array(5) {\n    [&quot;Body&quot;]=&gt;\n    object(GuzzleHttp\\Psr7\\Stream)#119 (7) {\n      [&quot;stream&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      resource(9) of type (stream)\n      [&quot;size&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      NULL\n      [&quot;seekable&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      bool(true)\n      [&quot;readable&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      bool(true)\n      [&quot;writable&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      bool(true)\n      [&quot;uri&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      string(10) &quot;php:\/\/temp&quot;\n      [&quot;customMetadata&quot;:&quot;GuzzleHttp\\Psr7\\Stream&quot;:private]=&gt;\n      array(0) {\n      }\n    }\n    [&quot;ContentType&quot;]=&gt;\n    string(23) &quot;text\/csv; charset=utf-8&quot;\n    [&quot;InvokedProductionVariant&quot;]=&gt;\n    string(17) &quot;AllTrafficVariant&quot;\n    [&quot;CustomAttributes&quot;]=&gt;\n    string(0) &quot;&quot;\n    [&quot;@metadata&quot;]=&gt;\n    array(4) {\n      [&quot;statusCode&quot;]=&gt;\n      int(200)\n      [&quot;effectiveUri&quot;]=&gt;\n      string(105) &quot;https:\/\/runtime.sagemaker.us-east-1.amazonaws.com\/endpoints\/Before-10-24-21\/invocations&quot;\n      [&quot;headers&quot;]=&gt;\n      array(5) {\n        [&quot;x-amzn-requestid&quot;]=&gt;\n        string(36) &quot;e523ea41-0bd9-4bcd-9a80-8b5e3f710bbf&quot;\n        [&quot;x-amzn-invoked-production-variant&quot;]=&gt;\n        string(17) &quot;AllTrafficVariant&quot;\n        [&quot;date&quot;]=&gt;\n        string(29) &quot;Mon, 24 Jan 2022 15:22:54 GMT&quot;\n        [&quot;content-type&quot;]=&gt;\n        string(23) &quot;text\/csv; charset=utf-8&quot;\n        [&quot;content-length&quot;]=&gt;\n        string(2) &quot;18&quot;\n      }\n      [&quot;transferStats&quot;]=&gt;\n      array(1) {\n        [&quot;http&quot;]=&gt;\n        array(1) {\n          [0]=&gt;\n          array(0) {\n          }\n        }\n      }\n    }\n  }\n  [&quot;monitoringEvents&quot;:&quot;Aws\\Result&quot;:private]=&gt;\n  array(0) {\n  }\n}\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1643038641057,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":173.0,
        "Poster_created_time":1538025294107,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70836427",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"respons invokeendpoint return null bodi guzzl stream aw sdk php aw php sdk retriev predict model respons come success bodi null guzzl stream know get predict successfulli content length valu exactli aw cli run predict work fine code result object test ad accept field invokeendpoint mime type success run similar issu let know help greatli appreci code us aw runtim runtimecli build client client new aw runtim runtimecli region east version latest credenti kei xxxxxxxxxxxxxx secret xxxxxxxxxxxxxx invok endpoint result client invokeendpoint bodi instanc sunris tell stori midland contenttyp text csv endpointnam result object aw result data aw result privat arrai bodi object guzzlehttp psr stream stream guzzlehttp psr stream privat resourc type stream size guzzlehttp psr stream privat null seekabl guzzlehttp psr stream privat bool true readabl guzzlehttp psr stream privat bool true writabl guzzlehttp psr stream privat bool true uri guzzlehttp psr stream privat string php temp custommetadata guzzlehttp psr stream privat arrai contenttyp string text csv charset utf invokedproductionvari string alltrafficvari customattribut string metadata arrai statuscod int effectiveuri string http runtim east amazonaw com endpoint invoc header arrai amzn requestid string eea bcd befbbf amzn invok product variant string alltrafficvari date string mon jan gmt content type string text csv charset utf content length string transferstat arrai http arrai arrai monitoringev aw result privat arrai",
        "Question_preprocessed_content":"respons return bodi aw php sdk retriev predict model respons come bodi stream know predict valu exactli aw cli run predict code result object test field mime type run similar let know help greatli code result",
        "Question_gpt_summary_original":"The user is using the AWS PHP SDK to retrieve a prediction from a SageMaker Model, but the response comes back as successful with a Null or Guzzle stream body. The content-length value is the same as what the user gets when using the AWS CLI to run the prediction. The user has tested adding the \"accept\" field to the InvokeEndpoint with various MIME types with no success.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Connect Lambda function within VPC to Sagemaker Serverless Inference Endpoint",
        "Question_body":"Hello! \n\nI have a Lambda function which needs to connect to a MySQL RDS instance which is within a private VPC. The Lambda function also needs to connect to a Sagemaker Serverless Inference Endpoint, taking data from the RDS instance and passing it to a Sagemaker model for inference. \n\nI have tested a vanilla Lambda function from outside of the private VPC to connect to the Sagemaker Endpoint which was successful. However, in order for Lambda to access data from the RDS database, I have associated the Lambda function with the same private VPC and subnets as the RDS instance. As a result, the Lambda function can no longer access the Sagemaker Endpoint as it now lies within the private VPC. \n\nI need advice on **how to create a VPC Interface Endpoint** to enable the Lambda function to access the Sagemaker Endpoint, and on** how to build the associated security groups** to enable the network access. I am unsure of how to implement the VPC Interface Endpoint or how to implement the correct security groups, so I would appreciate advice on the implementation. \n\nAs an alternative architecture, I could create two lambda functions: one which is associated with the private VPC and connects to the RDS instance then stores the required data in an S3 bucket; and another lambda function which is not within the VPC which pulls the data from the S3 bucket and serves it to the Sagemaker Endpoint. **Would this be a better option? **",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1682612681713,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1682959694208,
        "Question_score_count":0.0,
        "Question_view_count":53.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU3hIvhm-IRiG4uElDlq7jBg\/connect-lambda-function-within-vpc-to-sagemaker-serverless-inference-endpoint",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect lambda function vpc serverless infer endpoint hello lambda function need connect mysql rd instanc privat vpc lambda function need connect serverless infer endpoint take data rd instanc pass model infer test vanilla lambda function outsid privat vpc connect endpoint success order lambda access data rd databas associ lambda function privat vpc subnet rd instanc result lambda function longer access endpoint li privat vpc need advic creat vpc interfac endpoint enabl lambda function access endpoint build associ secur group enabl network access unsur implement vpc interfac endpoint implement correct secur group appreci advic implement altern architectur creat lambda function associ privat vpc connect rd instanc store requir data bucket lambda function vpc pull data bucket serv endpoint better option",
        "Question_preprocessed_content":"lambda function vpc infer endpoint lambda function mysql rd instanc privat vpc lambda function infer endpoint take data rd instanc model infer test lambda function outsid privat vpc endpoint order lambda data rd databas lambda function privat vpc subnet rd instanc result lambda function longer endpoint li privat vpc advic creat vpc interfac endpoint enabl lambda function endpoint build secur group enabl network unsur implement vpc interfac endpoint implement secur group advic implement altern architectur creat lambda function privat vpc rd instanc store requir data bucket lambda function vpc data bucket serv endpoint option",
        "Question_gpt_summary_original":"The user needs advice on how to create a VPC Interface Endpoint and associated security groups to enable a Lambda function within a private VPC to access a Sagemaker Serverless Inference Endpoint, while also connecting to a MySQL RDS instance within the same VPC. They are also considering an alternative architecture involving two Lambda functions.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Ground Truth Labeling of 3d Point Clouds - Center of Rotation",
        "Question_body":"I'm trying to label a 3D point cloud using the Ground Truth 3d Point Cloud labeling tool.  The image is an immersive 3d object.  Therefore, in order to make the UI usable, I need to be able to rotate the image around the view position, versus the point cloud origin. For example, if you were walking through a maze, to turn left or right, you would rotate around where you were standing, not the center of the maze.\n\nIs it possible to move the axis of rotation?\n\nThanks!",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1680621259002,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1680968525708,
        "Question_score_count":0.0,
        "Question_view_count":14.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUmNgheRVRSMe0HRUqagijdA\/ground-truth-labeling-of-3d-point-clouds-center-of-rotation",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"ground truth label point cloud center rotat try label point cloud ground truth point cloud label tool imag immers object order usabl need abl rotat imag view posit versu point cloud origin exampl walk maze turn left right rotat stand center maze possibl axi rotat thank",
        "Question_preprocessed_content":"ground truth label point cloud center rotat try label point cloud ground truth point cloud label imag object order usabl abl rotat imag view posit versu point cloud origin exampl walk maze turn left right rotat stand center maze axi rotat thank",
        "Question_gpt_summary_original":"The user is facing challenges in labeling a 3D point cloud using the Ground Truth 3D Point Cloud labeling tool due to the immersiveness of the object. The user needs to rotate the image around the view position instead of the point cloud origin to make the UI usable. The user is seeking help to move the axis of rotation.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Unable to sign into Azure Machine Learning Studio (classic), page constantly refreshes.",
        "Question_body":"<p>Hi,  <\/p>\n<p>I am trying to sign into my Free Workspace within the Microsoft Azure Machine Learning Studio (classic).   <\/p>\n<p>I am trying to access the RICT2 Prediction and Classification Experiment: <a href=\"https:\/\/gallery.azure.ai\/Experiment\/RICT-Prediction-and-Classification-GB-Single-Year-v4-0\">https:\/\/gallery.azure.ai\/Experiment\/RICT-Prediction-and-Classification-GB-Single-Year-v4-0<\/a>  <\/p>\n<p>The page refreshes inexplicably on a loop several times, before displaying a sign-in error.  <\/p>\n<p>Would anyone be able to assist?  <\/p>\n<p>Thank you!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1647878967167,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/780770\/unable-to-sign-into-azure-machine-learning-studio",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl sign studio classic page constantli refresh try sign free workspac studio classic try access rict predict classif experi http galleri azur experi rict predict classif singl year page refresh inexplic loop time displai sign error abl assist thank",
        "Question_preprocessed_content":"unabl sign studio page constantli refresh try sign workspac studio try rict predict experi page refresh inexplic time displai abl thank",
        "Question_gpt_summary_original":"The user is unable to sign into their Free Workspace within the Microsoft Azure Machine Learning Studio (classic) to access the RICT2 Prediction and Classification Experiment. The page constantly refreshes and displays a sign-in error. The user is seeking assistance.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"what is the best IoT architecture for AI in Azure ?",
        "Question_body":"<p>I'm here to ask for advice on an architecture I've set up for real-time data processing. The goal is to have a Dashboard able to display all the metrics coming from the connected objects and to be able to make predictions in real time (cost prediction, maintenance prediction etc..) using AI.     <\/p>\n<p>I set up the architecture below with a script simulating a machine. But I have a lot of doubts about this one.    <\/p>\n<p>Especially for Stream Analytics. I would like to be able to clean the raw data, before storing them (aggregation in particular) to calculate an OEE and other things.    <\/p>\n<p>But SA is limited in terms of data aggregation, so I would like to know what would be the best alternative for real-time data processing before storing it.    <\/p>\n<p>Should I use Azure Function combined with SA?     <br \/>\nCan Azure Machine Learning studio do this processing work with or without SA?     <br \/>\nAzure Databricks seemed to be a good alternative but I'm having a lot of trouble setting up a real-time data processing stream and CSV\/Json storage in my data lake but I don't know if I'm doing it wrong or if it's just impossible.    <\/p>\n<p>Azure Data Factory didn't seem to be adapted to real time data processing so I abandoned this option    <\/p>\n<p> There are so many options and I have no idea in which direction to go, I've been working on it for several months.    <\/p>\n<p>Thanks to all the people who will take the time to answer.    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1663849334273,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1019237\/what-is-the-best-iot-architecture-for-ai-in-azure",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"best iot architectur azur ask advic architectur set real time data process goal dashboard abl displai metric come connect object abl predict real time cost predict mainten predict set architectur script simul machin lot doubt especi stream analyt like abl clean raw data store aggreg particular calcul oee thing limit term data aggreg like know best altern real time data process store us azur function combin studio process work azur databrick good altern have lot troubl set real time data process stream csv json storag data lake know wrong imposs azur data factori adapt real time data process abandon option option idea direct work month thank peopl time answer",
        "Question_preprocessed_content":"best iot architectur azur ask advic architectur set data goal dashboard abl displai metric come object abl predict real time set architectur script simul machin lot doubt stream analyt like abl clean raw data store calcul thing limit term data like know best altern data store us azur function combin studio work azur databrick altern have lot troubl data stream storag data lake know wrong azur data factori adapt real time data abandon option option idea direct work month thank peopl time answer",
        "Question_gpt_summary_original":"The user is seeking advice on the best IoT architecture for real-time data processing and AI in Azure. They have set up an architecture but have doubts about it, especially for Stream Analytics. They are looking for alternatives for real-time data processing before storing it and are considering using Azure Function, Azure Machine Learning studio, or Azure Databricks. They have abandoned Azure Data Factory as it is not adapted to real-time data processing. The user is seeking guidance as they have been working on it for several months.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"[RFC] Extended Search and Pagination functionality",
        "Question_body":"Overview\n\nSearch is one of the most used APIs in MLflow to read logged experiment and run data. As organizations and projects scale and an increasing number of ML runs are logged, users have a need to severely limit the search results returned. In addition to selecting specific rows, there may be needs to limit the number of parameters, metrics, tags, and run attributes returned with searches. In cases where a large number of runs are produced from a search, there is a need to paginate the results at server-side and return only a limited set of runs at a time.\n\nIn this RFC, we present proposals to extend search functionality for advanced use cases along with some optimizations. We also discuss proposed solution for server-side pagination of results.\n\n\n\nRequest for comment\n\nFull RFC for these 2 features is in this google doc\u00a0(which has comment access). We are looking forward to your feedback directly in this document.Thank you!\n\n\n\n\nMani Parkhe\n\nma...@databricks.com",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1557323729000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":8.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/IdVF99MAgyM",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"rfc extend search pagin function overview search api read log experi run data organ project scale increas number run log user need sever limit search result return addit select specif row need limit number paramet metric tag run attribut return search case larg number run produc search need pagin result server return limit set run time rfc present propos extend search function advanc us case optim discuss propos solut server pagin result request comment rfc featur googl doc comment access look forward feedback directli document thank mani parkh databrick com",
        "Question_preprocessed_content":"extend search pagin function overview search api read experi run data organ project scale increas number run user sever limit search result return select specif row limit number paramet metric tag run return search case larg number run produc search pagin result return limit set run time rfc present propos extend search function advanc us case optim propos solut pagin result request rfc featur doc forward directli mani parkh",
        "Question_gpt_summary_original":"The RFC proposes extending the search functionality in MLflow to limit search results and paginate large numbers of runs. The proposal includes optimizing the search for advanced use cases and implementing server-side pagination of results. Feedback is requested on the proposals.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Kedro - how to pass nested parameters directly to node",
        "Question_body":"<p><a href=\"https:\/\/stackoverflow.com\/questions\/tagged\/kedro\"><code>kedro<\/code><\/a> recommends storing parameters in <code>conf\/base\/parameters.yml<\/code>. Let's assume it looks like this:<\/p>\n\n<pre><code>step_size: 1\nmodel_params:\n    learning_rate: 0.01\n    test_data_ratio: 0.2\n    num_train_steps: 10000\n<\/code><\/pre>\n\n<p>And now imagine I have some <code>data_engineering<\/code> pipeline whose <code>nodes.py<\/code> has a function that looks something like this:<\/p>\n\n<pre><code>def some_pipeline_step(num_train_steps):\n    \"\"\"\n    Takes the parameter `num_train_steps` as argument.\n    \"\"\"\n    pass\n<\/code><\/pre>\n\n<p>How would I go about and pass that nested parameters straight to this function in <code>data_engineering\/pipeline.py<\/code>? I unsuccessfully tried:<\/p>\n\n<pre><code>from kedro.pipeline import Pipeline, node\n\nfrom .nodes import split_data\n\n\ndef create_pipeline(**kwargs):\n    return Pipeline(\n        [\n            node(\n                some_pipeline_step,\n                [\"params:model_params.num_train_steps\"],\n                dict(\n                    train_x=\"train_x\",\n                    train_y=\"train_y\",\n                ),\n            )\n        ]\n    )\n<\/code><\/pre>\n\n<p>I know that I could just pass all parameters into the function by using <code>['parameters']<\/code> or just pass all <code>model_params<\/code> parameters with <code>['params:model_params']<\/code> but it seems unelegant and I feel like there must be a way. Would appreciate any input!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1587965065520,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1403.0,
        "Poster_created_time":1525290575943,
        "Poster_location":"Toronto, ON, Canada",
        "Poster_reputation_count":143.0,
        "Poster_view_count":17.0,
        "Answer_body":"<p>(Disclaimer: I'm part of the Kedro team)<\/p>\n\n<p>Thank you for your question. Current version of Kedro, unfortunately, does not support nested parameters. The interim solution would be to use top-level keys inside the node (as you already pointed out) or decorate your node function with some sort of a parameter filter, which is not elegant either.<\/p>\n\n<p>Probably the most viable solution would be to customise your <code>ProjectContext<\/code> (in <code>src\/&lt;package_name&gt;\/run.py<\/code>) class by overwriting <code>_get_feed_dict<\/code> method as follows:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>class ProjectContext(KedroContext):\n    # ...\n\n\n    def _get_feed_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Get parameters and return the feed dictionary.\"\"\"\n        params = self.params\n        feed_dict = {\"parameters\": params}\n\n        def _add_param_to_feed_dict(param_name, param_value):\n            \"\"\"This recursively adds parameter paths to the `feed_dict`,\n            whenever `param_value` is a dictionary itself, so that users can\n            specify specific nested parameters in their node inputs.\n\n            Example:\n\n                &gt;&gt;&gt; param_name = \"a\"\n                &gt;&gt;&gt; param_value = {\"b\": 1}\n                &gt;&gt;&gt; _add_param_to_feed_dict(param_name, param_value)\n                &gt;&gt;&gt; assert feed_dict[\"params:a\"] == {\"b\": 1}\n                &gt;&gt;&gt; assert feed_dict[\"params:a.b\"] == 1\n            \"\"\"\n            key = \"params:{}\".format(param_name)\n            feed_dict[key] = param_value\n\n            if isinstance(param_value, dict):\n                for key, val in param_value.items():\n                    _add_param_to_feed_dict(\"{}.{}\".format(param_name, key), val)\n\n        for param_name, param_value in params.items():\n            _add_param_to_feed_dict(param_name, param_value)\n\n        return feed_dict\n<\/code><\/pre>\n\n<p>Please also note that this issue has already been <a href=\"https:\/\/github.com\/quantumblacklabs\/kedro\/commit\/529606273e201a736f10338ada73ac6206081730\" rel=\"nofollow noreferrer\">addressed on develop<\/a> and will become available in the next release. The fix uses the approach from the snippet above.<\/p>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1587979890916,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1393579668636,
        "Answerer_location":"London, United Kingdom",
        "Answerer_reputation_count":1450.0,
        "Answerer_view_count":162.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61452211",
        "Tool":"Kedro",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pass nest paramet directli node recommend store paramet conf base paramet yml let assum look like step size model param learn rate test data ratio num train step imagin data engin pipelin node function look like def pipelin step num train step take paramet num train step argument pass pass nest paramet straight function data engin pipelin unsuccessfulli tri pipelin import pipelin node node import split data def creat pipelin kwarg return pipelin node pipelin step param model param num train step dict train train train train know pass paramet function paramet pass model param paramet param model param uneleg feel like wai appreci input",
        "Question_preprocessed_content":"nest paramet directli node store paramet let like imagin pipelin function like nest paramet straight function tri know paramet function paramet uneleg like wai input",
        "Question_gpt_summary_original":"The user is trying to pass nested parameters directly to a function in Kedro's data engineering pipeline, but is having trouble doing so. They have tried using the \"params:model_params.num_train_steps\" syntax, but it did not work. The user is looking for a more elegant solution to pass the nested parameters.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Dialogflow CX - DTMF Barge in not working",
        "Question_body":"Dialogflow CX\u00a0Barge in does not work for DTMF input.\n\n-- Steps to reproduce the issue:\n1. Enable Barge in at Agent level settings\n2. Create a page with a parameter with DTMF enabled\n3. Call agent via phone connector like Twilio and use phone keypad to provide parameter value\n\n-- Expected behavior \u00a0--\nThe agent prompt should stop on DTMF input, similar to how it stops on voice input.\n\n-- Actual behavior \u00a0--\nThe agent prompt does not stop on DTMF input.https:\/\/issuetracker.google.com\/issues\/259816857\n\nIssue report url:\u00a0https:\/\/issuetracker.google.com\/issues\/259816857\u00a0 Please upvote.\u00a0\nCX phone experience is highly degraded without DTMF barge in.",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1670048880000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":6.0,
        "Question_view_count":196.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-CX-DTMF-Barge-in-not-working\/m-p\/495732#M897",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"dialogflow dtmf barg work dialogflow cxbarg work dtmf input step reproduc issu enabl barg agent level set creat page paramet dtmf enabl agent phone connector like twilio us phone keypad provid paramet valu expect behavior agent prompt stop dtmf input similar stop voic input actual behavior agent prompt stop dtmf input http issuetrack googl com issu issu report url http issuetrack googl com issu upvot phone experi highli degrad dtmf barg",
        "Question_preprocessed_content":"dialogflow dtmf barg work dialogflow cxbarg work dtmf input step reproduc enabl barg agent level creat page paramet dtmf enabl agent phone like twilio us phone keypad provid paramet valu expect behavior agent prompt stop dtmf input similar stop voic input actual behavior agent prompt stop dtmf report upvot phone experi highli degrad dtmf barg",
        "Question_gpt_summary_original":"The user is facing an issue with Dialogflow CX where the DTMF barge in is not working. Despite enabling barge in at the agent level settings and creating a page with a parameter with DTMF enabled, the agent prompt does not stop on DTMF input when the user calls via phone connector like Twilio. This issue has been reported on the Google issue tracker and the user has requested others to upvote it as the CX phone experience is highly degraded without DTMF barge in.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"start, monitor and define script of SageMaker processing job from local machine",
        "Question_body":"<p>I am looking at <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/sagemaker_processing\/scikit_learn_data_processing_and_model_evaluation\/scikit_learn_data_processing_and_model_evaluation.ipynb\" rel=\"nofollow noreferrer\">this<\/a>, which makes all sense. Let us focus on this bit of code:<\/p>\n<pre><code>from sagemaker.processing import ProcessingInput, ProcessingOutput\n\nsklearn_processor.run(\n    code=&quot;preprocessing.py&quot;,\n    inputs=[\n        ProcessingInput(source=&quot;s3:\/\/your-bucket\/path\/to\/your\/data&quot;, destination=&quot;\/opt\/ml\/processing\/input&quot;),\n    ],\n    outputs=[\n        ProcessingOutput(output_name=&quot;train_data&quot;, source=&quot;\/opt\/ml\/processing\/train&quot;),\n        ProcessingOutput(output_name=&quot;test_data&quot;, source=&quot;\/opt\/ml\/processing\/test&quot;),\n    ],\n    arguments=[&quot;--train-test-split-ratio&quot;, &quot;0.2&quot;],\n)\n\npreprocessing_job_description = sklearn_processor.jobs[-1].describe() \n<\/code><\/pre>\n<p>Here preprocessing.py has to be obviously in the cloud. I am curious, could one also put scripts into an S3 bucket and trigger the job remotely. I can easily to this with hyper parameter optimisation, which does not require dedicated scripts though as I use an OOTB training image.<\/p>\n<p>In this case I can fire off the job like so:<\/p>\n<pre><code>tuning_job_name = &quot;amazing-hpo-job-&quot; + strftime(&quot;%d-%H-%M-%S&quot;, gmtime())\n\nsmclient = boto3.Session().client(&quot;sagemaker&quot;)\nsmclient.create_hyper_parameter_tuning_job(\n    HyperParameterTuningJobName=tuning_job_name,\n    HyperParameterTuningJobConfig=tuning_job_config,\n    TrainingJobDefinition=training_job_definition\n)\n<\/code><\/pre>\n<p>and then monitor the job's progress:<\/p>\n<pre><code>smclient = boto3.Session().client(&quot;sagemaker&quot;)\n\ntuning_job_result = smclient.describe_hyper_parameter_tuning_job(\n    HyperParameterTuningJobName=tuning_job_name\n)\n\nstatus = tuning_job_result[&quot;HyperParameterTuningJobStatus&quot;]\nif status != &quot;Completed&quot;:\n    print(&quot;Reminder: the tuning job has not been completed.&quot;)\n\njob_count = tuning_job_result[&quot;TrainingJobStatusCounters&quot;][&quot;Completed&quot;]\nprint(&quot;%d training jobs have completed&quot; % job_count)\n\nobjective = tuning_job_result[&quot;HyperParameterTuningJobConfig&quot;][&quot;HyperParameterTuningJobObjective&quot;]\nis_minimize = objective[&quot;Type&quot;] != &quot;Maximize&quot;\nobjective_name = objective[&quot;MetricName&quot;]\n\nif tuning_job_result.get(&quot;BestTrainingJob&quot;, None):\n    print(&quot;Best model found so far:&quot;)\n    pprint(tuning_job_result[&quot;BestTrainingJob&quot;])\nelse:\n    print(&quot;No training jobs have reported results yet.&quot;) \n<\/code><\/pre>\n<p>I would think starting and monitoring a SageMaker processing job from a local machine should be possible as with an HPO job but what about the script(s)? Ideally I would like to develop and test them locally and the run remotely. Hope this makes sense?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1662209372887,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":38.0,
        "Poster_created_time":1267440784443,
        "Poster_location":"Somewhere",
        "Poster_reputation_count":15705.0,
        "Poster_view_count":2150.0,
        "Answer_body":"<p>Im not sure I understand the comparison to a Tuning Job.<\/p>\n<p>Based on what you have described, in this case the <code>preprocessing.py<\/code> is actually stored locally. The SageMaker SDK will upload it to S3 for the remote Processing Job to access it. I suggest launching the Job and then taking a look at the inputs in the SageMaker Console.<\/p>\n<p>If you wanted to test the Processing Job locally you can do so using <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/overview.html#local-mode\" rel=\"nofollow noreferrer\">Local Mode<\/a>. This will basically imitate the Job locally which aids in debugging the script before kicking off a remote Processing Job. Kindly note docker is required to make use of Local Mode.<\/p>\n<p>Example code for local mode:<\/p>\n<pre><code>from sagemaker.local import LocalSession\nfrom sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n\nsagemaker_session = LocalSession()\nsagemaker_session.config = {'local': {'local_code': True}}\n\n# For local training a dummy role will be sufficient\nrole = 'arn:aws:iam::111111111111:role\/service-role\/AmazonSageMaker-ExecutionRole-20200101T000001'\n\nprocessor = ScriptProcessor(command=['python3'],\n                    image_uri='sagemaker-scikit-learn-processing-local',\n                    role=role,\n                    instance_count=1,\n                    instance_type='local')\n\nprocessor.run(code='processing_script.py',\n                    inputs=[ProcessingInput(\n                        source='.\/input_data\/',\n                        destination='\/opt\/ml\/processing\/input_data\/')],\n                    outputs=[ProcessingOutput(\n                        output_name='word_count_data',\n                        source='\/opt\/ml\/processing\/processed_data\/')],\n                    arguments=['job-type', 'word-count']\n                    )\n\npreprocessing_job_description = processor.jobs[-1].describe()\noutput_config = preprocessing_job_description['ProcessingOutputConfig']\n\nprint(output_config)\n\nfor output in output_config['Outputs']:\n    if output['OutputName'] == 'word_count_data':\n        word_count_data_file = output['S3Output']['S3Uri']\n\nprint('Output file is located on: {}'.format(word_count_data_file))\n\n\n<\/code><\/pre>",
        "Answer_comment_count":4.0,
        "Question_closed_time":1662504468407,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1645475560783,
        "Answerer_location":null,
        "Answerer_reputation_count":466.0,
        "Answerer_view_count":32.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73592371",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"start monitor defin script process job local machin look make sens let focu bit code process import processinginput processingoutput sklearn processor run code preprocess input processinginput sourc bucket path data destin opt process input output processingoutput output train data sourc opt process train processingoutput output test data sourc opt process test argument train test split ratio preprocess job descript sklearn processor job preprocess obvious cloud curiou script bucket trigger job remot easili hyper paramet optimis requir dedic script us ootb train imag case job like tune job amaz hpo job strftime gmtime smclient boto session client smclient creat hyper paramet tune job hyperparametertuningjobnam tune job hyperparametertuningjobconfig tune job config trainingjobdefinit train job definit monitor job progress smclient boto session client tune job result smclient hyper paramet tune job hyperparametertuningjobnam tune job statu tune job result hyperparametertuningjobstatu statu complet print remind tune job complet job count tune job result trainingjobstatuscount complet print train job complet job count object tune job result hyperparametertuningjobconfig hyperparametertuningjobobject minim object type maxim object object metricnam tune job result besttrainingjob print best model far pprint tune job result besttrainingjob print train job report result think start monitor process job local machin possibl hpo job script ideal like develop test local run remot hope make sens",
        "Question_preprocessed_content":"start monitor defin script job local machin make sens let focu bit code obvious cloud curiou script bucket job remot easili hyper paramet optimis requir dedic script us train imag case job like monitor job think start monitor job local machin hpo job script like develop test run remot hope make sens",
        "Question_gpt_summary_original":"The user is trying to understand if it is possible to start, monitor, and define a script for a SageMaker processing job from a local machine. They have provided code examples for running a processing job and monitoring a hyperparameter tuning job remotely, but they are unsure if they can put scripts into an S3 bucket and trigger the processing job remotely. The user would like to develop and test the scripts locally and then run them remotely.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML Tutorial - Failed to load entrypoint automl",
        "Question_body":"<p>I'm doing following tutorial. I run successfully &quot;Create and run a Python script&quot;, but failed failed to run &quot;Create a control script&quot;.    <\/p>\n<p>What could be wrong?    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world<\/a>    <\/p>\n<pre><code>azureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$ python run-hello.py   \nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl =   \nazureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 4.0.0   \n(\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages),   \nRequirement.parse('pyarrow&lt;4.0.0,&gt;=0.17.0'), {'azureml-dataset-runtime'}).  \nhttps:\/\/ml.azure.com\/runs\/day1-experiment-hello_1623766747_073126f5?   \nwsid=\/subscriptions\/1679753a-501e-4e46-9bff-   \n6120ed5694cf\/resourcegroups\/kensazuremlrg\/workspaces\/kensazuremlws&amp;tid=94fe1041-ba47-4f49-   \n866b-   \n06c297c116cc  \nazureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$  \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1623826462663,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/438183\/azure-ml-tutorial-failed-to-load-entrypoint-automl",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tutori fail load entrypoint automl follow tutori run successfulli creat run python script fail fail run creat control script wrong http learn microsoft com azur machin learn tutori experi hello world azureus kensmlcomput cloudfil code user start python run hello failur load run type provid fail load entrypoint automl train automl run automlrun run dto except pyarrow anaconda env lib python site packag requir pars pyarrow dataset runtim http azur com run dai experi hello wsid subscript bff edcf resourcegroup kensrg workspac kensw tid cccc azureus kensmlcomput cloudfil code user start",
        "Question_preprocessed_content":"tutori fail load entrypoint automl tutori run creat run python script fail fail run creat control script wrong",
        "Question_gpt_summary_original":"The user encountered an issue while following an Azure ML tutorial. They were able to run one script successfully but failed to run another script due to an error related to loading the entrypoint automl. The error message suggests that there is an issue with the pyarrow package.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to handle entrypoints nested in folders with amazon sagemaker pytorch estimator?",
        "Question_body":"<p>I am attempting to run a training job on amazon sagemaker using the python-sagemaker-sdk, estimator class.<\/p>\n\n<p>I have the following<\/p>\n\n<pre><code>estimator = PyTorch(entry_point='training_scripts\/train_MSCOCO.py',\n                            source_dir='.\/',\n                            role=#dummy_role,\n                            train_instance_type='ml.p3.2xlarge',\n                            train_instance_count=1,\n                            framework_version='1.0.0',\n                            output_path=#dummy_output_path,\n                            hyperparameters={'lr': 0.001,\n                                             'batch_size': 32,\n                                             'num_workers': 4,\n                                             'description': description})\n<\/code><\/pre>\n\n<p>role and output_path hidden for privacy.<\/p>\n\n<p>I get the following error, \"No module named training_scripts\\train_MSCOCO\".<\/p>\n\n<p>When I run python -m training_scripts.train_MSCOCO the script runs fine. However when I pass <code>entry_point='training_script.train_MSCOCO.py<\/code> it will not run as, \"No file named \"training_scripts.train_MSCOCO.py\" was found in directory \".\/\"\".<\/p>\n\n<p>I am confused as to how to run a nested training script from the top level of my repository within AWS sagemaker, as they seem to have conflicting path needs, one in python module dot notation, the other in standard filepath slash notation.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1563984389853,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":222.0,
        "Poster_created_time":1469720606203,
        "Poster_location":"New Jersey, United States",
        "Poster_reputation_count":65.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57187148",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"handl entrypoint nest folder pytorch estim attempt run train job python sdk estim class follow estim pytorch entri point train script train mscoco sourc dir role dummi role train instanc type xlarg train instanc count framework version output path dummi output path hyperparamet batch size num worker descript descript role output path hidden privaci follow error modul name train script train mscoco run python train script train mscoco script run fine pass entri point train script train mscoco run file name train script train mscoco directori confus run nest train script level repositori conflict path need python modul dot notat standard filepath slash notat",
        "Question_preprocessed_content":"handl entrypoint nest folder pytorch estim run train job estim role privaci modul name run python script run fine run file name directori confus run nest train script level repositori conflict path python modul dot notat standard filepath slash notat",
        "Question_gpt_summary_original":"The user is facing challenges while attempting to run a training job on Amazon SageMaker using the python-sagemaker-sdk, estimator class. The user is encountering an error \"No module named training_scripts\\train_MSCOCO\" while trying to run a nested training script from the top level of the repository within AWS SageMaker. The user is confused about how to run a nested training script from the top level of the repository within AWS SageMaker, as they seem to have conflicting path needs, one in python module dot notation, the other in standard filepath slash notation.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is it a good idea to store my dataset in my notebook instance in sagemaker?",
        "Question_body":"<p>I'm new to AWS and I am considering to use amazon sagemaker to train my deep learning model because I'm having memory issues due to the large dataset and neural network that I have to train. I'm confused whether to store my data in my notebook instance or in S3? If I store it in my s3 would I be able to access it to train on my notebook instance? I'm confused on the concepts. Can anyone explain the use of S3 in machine learning in AWS?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1619054238143,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":322.0,
        "Poster_created_time":1605938672327,
        "Poster_location":"Jakarta Selatan, South Jakarta City, Jakarta, Indonesia",
        "Poster_reputation_count":97.0,
        "Poster_view_count":34.0,
        "Answer_body":"<p>Yes you can use S3 as storage for your training datasets.<\/p>\n<p>Refer diagram in this link describing how everything works together: <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/how-it-works-training.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/how-it-works-training.html<\/a><\/p>\n<p>You may also want to checkout following blogs that details about File mode and Pipe mode, two mechanisms for transferring training data:<\/p>\n<ol>\n<li><a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker\/<\/a><\/li>\n<\/ol>\n<blockquote>\n<p>In File mode, the training data is downloaded first to an encrypted EBS volume attached to the training instance prior to commencing the training. However, in Pipe mode the input data is streamed directly to the training algorithm while it is running.<\/p>\n<\/blockquote>\n<ol start=\"2\">\n<li><a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-pipe-input-mode-for-amazon-sagemaker-algorithms\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/using-pipe-input-mode-for-amazon-sagemaker-algorithms\/<\/a><\/li>\n<\/ol>\n<blockquote>\n<p>With Pipe input mode, your data is fed on-the-fly into the algorithm container without involving any disk I\/O. This approach shortens the lengthy download process and dramatically reduces startup time. It also offers generally better read throughput than File input mode. This is because your data is fetched from Amazon S3 by a highly optimized multi-threaded background process. It also allows you to train on datasets that are much larger than the 16 TB Amazon Elastic Block Store (EBS) volume size limit.<\/p>\n<\/blockquote>\n<p>The blog also contains python code snippets using Pipe input mode for reference.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1619062178832,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1336887489390,
        "Answerer_location":null,
        "Answerer_reputation_count":758.0,
        "Answerer_view_count":44.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67205469",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"good idea store dataset notebook instanc new aw consid us train deep learn model have memori issu larg dataset neural network train confus store data notebook instanc store abl access train notebook instanc confus concept explain us machin learn aw",
        "Question_preprocessed_content":"idea store dataset instanc new aw consid us train learn model have memori larg dataset neural network train confus store data instanc store abl train instanc confus concept explain us machin learn aw",
        "Question_gpt_summary_original":"The user is new to AWS and is considering using Amazon SageMaker to train a deep learning model due to memory issues caused by a large dataset and neural network. They are unsure whether to store their data in their notebook instance or in S3 and are seeking clarification on the use of S3 in machine learning in AWS.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How could I upload notebooks to my AzureML workspace programatically",
        "Question_body":"<p>Would like to upload Jupyter notebooks from different sources like GitHub into my workspace either directly or through my local machine (download locally first and then upload) but I would like to do it programmatically. Either with the AzureML SDK or azure cli  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1651101620807,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi, thanks for reaching out. You can use compute instance <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal\">terminal<\/a> in AML notebooks to <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/samples-notebooks#get-samples-on-azure-machine-learning-compute-instance\">clone<\/a> the GitHub repo. There's currently no option to upload notebooks to your workspace programmatically using sdk or cli.<\/p>\n<p>--- *Kindly <em><strong>Accept Answer<\/strong><\/em> if the information helps. Thanks.*<\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1651104442392,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/829311\/how-could-i-upload-notebooks-to-my-azureml-workspa",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"upload notebook workspac programat like upload jupyt notebook differ sourc like github workspac directli local machin download local upload like programmat sdk azur cli",
        "Question_preprocessed_content":"upload workspac like upload jupyt sourc like github workspac directli local machin like sdk azur cli",
        "Question_gpt_summary_original":"The user wants to upload Jupyter notebooks from various sources like GitHub to their AzureML workspace programmatically using either AzureML SDK or Azure CLI.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Default grouping range",
        "Question_body":"<p>When I group runs using the \u201cgroup\u201d field, all my plots are grouped nicely. However, the default range for all is min\/max. I need to use std dev, and the only way to do that is to manually change it for every plot. This is very annoying. Isn\u2019t there a way to select std dev as default grouping range?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1683837974151,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":51.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/default-grouping-range\/4381",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"default group rang group run group field plot group nice default rang min max need us std dev wai manual chang plot annoi isnt wai select std dev default group rang",
        "Question_preprocessed_content":"default group rang group run group field plot group nice default rang us std dev wai chang plot isnt wai select std dev default group rang",
        "Question_gpt_summary_original":"The user is facing an issue where the default grouping range for their plots is set to min\/max when they group runs using the \"group\" field. They need to use std dev as the default grouping range, but have to manually change it for every plot, which is very annoying. They are looking for a way to select std dev as the default grouping range.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to configure comet (comet.ml) to log Tensorflow?",
        "Question_body":"<p>Im trying to set comet (<a href=\"https:\/\/www.comet.ml\" rel=\"nofollow noreferrer\">https:\/\/www.comet.ml<\/a>) to track my Tensorflow experiment, after I create an Experiment and log the data set i dont get the accuracy in my report.<\/p>\n\n<p>my code:<\/p>\n\n<pre><code>mnist = get_data()\ntrain_step, cross_entropy, accuracy, x, y, y_ = build_model_graph(hyper_params)\n\nexperiment = Experiment(api_key=\"XXXX\", log_code=True)\nexperiment.log_multiple_params(hyper_params)\nexperiment.log_dataset_hash(mnist)\n<\/code><\/pre>\n\n<p>in the example account : <a href=\"https:\/\/www.comet.ml\/view\/Jon-Snow\" rel=\"nofollow noreferrer\">https:\/\/www.comet.ml\/view\/Jon-Snow<\/a> I see that accuracy is reported<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1506094686057,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1514341154200,
        "Question_score_count":3.0,
        "Question_view_count":338.0,
        "Poster_created_time":1506066897167,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":4.0,
        "Answer_body":"<p>you can report accuracy using this method:<\/p>\n\n<ul>\n<li><code>experiment.log_accuracy(train_accuracy)<\/code><\/li>\n<\/ul>\n\n<p>take a look at the full Tensorflow example in our guide:<\/p>\n\n<ul>\n<li><a href=\"https:\/\/github.com\/comet-ml\/comet-quickstart-guide\/tree\/master\/tensorflow\" rel=\"nofollow noreferrer\">https:\/\/github.com\/comet-ml\/comet-quickstart-guide\/tree\/master\/tensorflow<\/a><\/li>\n<\/ul>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1506100257932,
        "Answer_last_edit_time":1513514205487,
        "Answer_score_count":3.0,
        "Answerer_created_time":1359884693920,
        "Answerer_location":"Israel",
        "Answerer_reputation_count":9637.0,
        "Answerer_view_count":609.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46368389",
        "Tool":"Comet",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"configur log tensorflow try set http www track tensorflow experi creat experi log data set dont accuraci report code mnist data train step cross entropi accuraci build model graph hyper param experi experi api kei xxxx log code true experi log multipl param hyper param experi log dataset hash mnist exampl account http www view jon snow accuraci report",
        "Question_preprocessed_content":"configur log tensorflow try set track tensorflow experi creat experi log data set dont report code exampl report",
        "Question_gpt_summary_original":"The user is trying to configure comet.ml to track their Tensorflow experiment, but after creating an experiment and logging the data set, they are not getting accuracy in their report. They have shared their code and noticed that accuracy is reported in an example account on comet.ml.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Vertex AI Notebook deleting cells",
        "Question_body":"Hello everyone, I have been facing an issue for the past few months where on occasion my vertex AI notebooks will completely wipe and delete all the cells in a .ipynb file. This happens at what appears to be random times.\u00a0\n\nContext to reproduce:\u00a0\n\nN96 High Memory instance 624 gb of ram\n\nIdle time: 1440\n\nsingle user only notebook\u00a0\n\nWhat happens: notebook with shutdown in the midst of running. Once the notebook is back up and running all the cells in the ipynb file are gone. There is no error message\u00a0\n\nIf anyone has faced this issue in the past and knows how to resolve I would really appreciate and information!\u00a0\n\nThank you",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1661849640000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":82.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Notebook-deleting-cells\/m-p\/461480#M550",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"notebook delet cell hello face issu past month occas notebook complet wipe delet cell ipynb file happen appear random time context reproduc high memori instanc ram idl time singl user notebook happen notebook shutdown midst run notebook run cell ipynb file gone error messag face issu past know resolv appreci inform thank",
        "Question_preprocessed_content":"delet face past month complet wipe delet ipynb file random time context reproduc high memori instanc ram idl time singl user shutdown midst ipynb file gone face past know resolv inform thank",
        "Question_gpt_summary_original":"The user is facing an issue with Vertex AI Notebook where all the cells in a .ipynb file get deleted at random times without any error message. This happens when the notebook shuts down in the midst of running and there is no way to recover the deleted cells. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Both GPU usage and GPU TIme Spent Accessing Memory is low",
        "Question_body":"<p>What does it mean when both GPU Usage and GPU Time Spent Accessing Memory is low. I was under the impression that these two would normally add to 100. My GPU Usage is at about 20% and the GPU time spent accessing memory is at 4%. Could someone help me understand what might be causing this and potentially how  I might be able to solve this.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1685135386269,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":21.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/both-gpu-usage-and-gpu-time-spent-accessing-memory-is-low\/4476",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"gpu usag gpu time spent access memori low mean gpu usag gpu time spent access memori low impress normal add gpu usag gpu time spent access memori help understand caus potenti abl solv",
        "Question_preprocessed_content":"gpu usag gpu time spent memori low mean gpu usag gpu time spent memori low gpu usag gpu time spent memori help understand caus abl solv",
        "Question_gpt_summary_original":"The user is experiencing low GPU usage and low GPU time spent accessing memory, which is unusual as they are expected to add up to 100. They are seeking help to understand the cause of this issue and how to solve it.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Using DVC to keep track of multiple model variants",
        "Question_body":"<p>I have to keep track of models that use the same feature engineering, the same features, the same algorithm, but a different subset of data e.g.the raw data is the same but then it\u2019s filtered to a certain group and then make a model.<\/p>\n<p>My repo structure looks like this<\/p>\n<pre><code>root\n     |- models\n                   |- model_group1\n                                            |- model.xgb\n                                            | params.json\n                   |- model_group2\n                                            |- ...\n                   |- ...\n    |- metrics\n                  |- model_group1\n                                           |- model_eval.json\n                  |- model_group2\n                                           |- ...\n                  |- ...\n<\/code><\/pre>\n<p>AFAIK DVC assumes the pipeline produces one model, which makes total sense.<br>\nMaking one model in which the group is a variant is not possible in my case.<\/p>\n<p>Any suggestions? do I need multiple DVC pipelines in the same repo?<\/p>",
        "Question_answer_count":8,
        "Question_comment_count":null,
        "Question_created_time":1597760331365,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1757.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/using-dvc-to-keep-track-of-multiple-model-variants\/471",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"track multipl model variant track model us featur engin featur algorithm differ subset data raw data filter certain group model repo structur look like root model model group model xgb param json model group metric model group model eval json model group afaik assum pipelin produc model make total sens make model group variant possibl case suggest need multipl pipelin repo",
        "Question_preprocessed_content":"track multipl model variant track model us featur featur algorithm subset data raw data filter certain group model repo structur like afaik pipelin produc model make total sens make model group variant case multipl pipelin repo",
        "Question_gpt_summary_original":"The user needs to keep track of multiple model variants that use the same feature engineering, features, and algorithm but a different subset of data. They have a repository structure with different model groups and metrics. However, DVC assumes the pipeline produces one model, which is not possible in this case. The user is seeking suggestions on how to handle this and whether they need multiple DVC pipelines in the same repository.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Push image error: Get \"https:\/\/https\/v2\/\": dial tcp: lookup https on SOME-IP: no such host",
        "Question_body":"This is question\/issue from Polyaxon Slack that was resolved. I am posting it for visibility if someone stumbles on the same issue with answer down below.\n\nGiven setup:\nDocker-registry provider: Amazon Elastic Container Registry (ECR)\nPolyaxon version: 1.7.3 CE\nDeployed with Kubernetes on AWS\nAnd Kaniko configuration:\nconnections:\n  - name: docker-registry\n    kind: registry\n    description: \"aws docker repository\"\n    schema:\n      url: https:\/\/ID.dkr.ecr.SOME-REGION.amazonaws.com\n secret:\n      name: aws-secret\n      mountPath: \/root\/.aws\/\n    configMap:\n      name: docker-config\n      mountPath: \/kaniko\/.docker\nAnd polyaxonfile for the build:\nversion: 1.1\nkind: operation\nname: build\nparams:\n  destination:\n    connection: docker-registry\n    value: polyaxon\nrunPatch:\n  init:\n  - dockerfile:\n      image: \"tensorflow\/tensorflow:2.0.1-py3\"\n      run:\n      - 'pip3 install --no-cache-dir -U polyaxon[\"polyboard\",\"polytune\"]'\n      langEnv: 'en_US.UTF-8'\nhubRef: kaniko\nThen raised error:\nConditions:\nTYPE    STATUS    REASON                MESSAGE                                      LAST_UPDATE_TIME    LAST_TRANSITION_TIME\n------  --------  --------------------  -------------------------------------------  ------------------  ----------------------\nfailed  True      BackoffLimitExceeded  Job has reached the specified backoff limit  a few seconds ago   a few seconds ago\n2021-04-19 08:18:08.805683+02:00 | error checking push permissions -- make sure you entered the correct tag name, and that you are authenticated correctly,\n and try again: checking push permission for \"https:\/\/ID.dkr.ecr.REGION.amazonaws.com\/SOME-NAME:SOME-TAG\": creating push check transport for https: failed: Get \"https:\/\/https\/v2\/\": dial tcp: lookup https on SOME-IP: no such host",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1619178414000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Resolution:\n\nThis was error on the ECR side. The repo SOME-NAME:SOME-TAG was not existing inside docker registry. Creating SOME-NAME in ECR allowed successful build and push.",
        "Answer_comment_count":0.0,
        "Question_closed_time":1619182738000,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1292",
        "Tool":"Polyaxon",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"push imag error http http dial tcp lookup http host question issu slack resolv post visibl stumbl issu answer given setup docker registri provid amazon elast contain registri ecr version deploi kubernet aw kaniko configur connect docker registri kind registri descript aw docker repositori schema url http dkr ecr region amazonaw com secret aw secret mountpath root aw configmap docker config mountpath kaniko docker file build version kind oper build param destin connect docker registri valu runpatch init dockerfil imag tensorflow tensorflow run pip instal cach dir polyboard polytun langenv utf hubref kaniko rais error condit type statu reason messag updat time transit time fail true backofflimitexceed job reach specifi backoff limit second ago second ago error check push permiss sure enter correct tag authent correctli try check push permiss http dkr ecr region amazonaw com tag creat push check transport http fail http http dial tcp lookup http host",
        "Question_preprocessed_content":"push imag dial tcp host slack resolv post visibl stumbl answer given setup provid amazon elast contain registri version deploi kubernet aw kaniko configur kind registri descript aw docker repositori schema url secret mountpath configmap mountpath file build version kind oper build param destin valu runpatch init dockerfil imag run pip langenv hubref kaniko rais condit type statu reason fail true job reach specifi limit second ago second ago check push sure enter tag authent try check push creat push check transport fail dial tcp host",
        "Question_gpt_summary_original":"The user encountered an error while trying to push an image to a Docker registry provider, Amazon Elastic Container Registry (ECR), using Polyaxon version 1.7.3 CE deployed with Kubernetes on AWS. The error message indicated that there was a problem with the push permissions and that the user should check the tag name and authentication. The error was caused by a failed attempt to create a push check transport for https, resulting in a lookup failure for https on the specified IP address.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"MLFlow SparkTrials maxNumConcurrentTasks([]) does not exist",
        "Question_body":"<p>I'm very new at using mlflow and I'm currently having some issues on its SparkTrials. I'm running the following code in my Jupyter notebook using Anaconda:<\/p>\n<pre><code>import mlflow\nfrom hyperopt import hp, fmin, tpe, rand, SparkTrials, STATUS_OK, STATUS_FAIL, space_eval\n\n# replicate input_pd dataframe to workers in Spark cluster\ninputs = sc.broadcast(input_pd)\n\n# configure hyperopt settings to distribute to all executors on workers\nspark_trials = SparkTrials()\n\n# select optimization algorithm\nalgo = tpe.suggest\n\n# perform hyperparameter tuning (logging iterations to mlflow)\nargmin = fmin(\n  fn=evaluate_model,\n  space=search_space,\n  algo=algo,\n  max_evals=100,\n  trials=spark_trials\n  )\n\n# release the broadcast dataset\ninputs.unpersist()\n<\/code><\/pre>\n<p>But, I get the following error:<\/p>\n<pre><code>  Py4JError: An error occurred while calling o233.maxNumConcurrentTasks. Trace:\n    py4j.Py4JException: Method maxNumConcurrentTasks([]) does not exist\n        at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n        at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n        at py4j.Gateway.invoke(Gateway.java:274)\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\n        at py4j.GatewayConnection.run(GatewayConnection.java:238)\n        at java.lang.Thread.run(Unknown Source)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1625197883137,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":187.0,
        "Poster_created_time":1617289926807,
        "Poster_location":null,
        "Poster_reputation_count":165.0,
        "Poster_view_count":68.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68219396",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sparktrial maxnumconcurrenttask exist new current have issu sparktrial run follow code jupyt notebook anaconda import hyperopt import fmin tpe rand sparktrial statu statu fail space eval replic input datafram worker spark cluster input broadcast input configur hyperopt set distribut executor worker spark trial sparktrial select optim algorithm algo tpe suggest perform hyperparamet tune log iter argmin fmin evalu model space search space algo algo max eval trial spark trial releas broadcast dataset input unpersist follow error pyjerror error occur call maxnumconcurrenttask trace pyj pyjexcept method maxnumconcurrenttask exist pyj reflect reflectionengin getmethod reflectionengin java pyj reflect reflectionengin getmethod reflectionengin java pyj gatewai invok gatewai java pyj command abstractcommand invokemethod abstractcommand java pyj command callcommand execut callcommand java pyj gatewayconnect run gatewayconnect java java lang thread run unknown sourc",
        "Question_preprocessed_content":"sparktrial exist new have sparktrial code jupyt anaconda",
        "Question_gpt_summary_original":"The user is encountering an error while using MLFlow's SparkTrials for hyperparameter tuning. The error message indicates that the method maxNumConcurrentTasks([]) does not exist.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure ML studio (Error 0009 Exception occurs when the Azure storage account name or container name is specified incorrectly)",
        "Question_body":"<p>Hi Team,  <\/p>\n<p>I have tried to connect Azure blob and Azure ML studio but am facing following error (Error 0009 Exception occurs when the Azure storage account name or container name is specified incorrectly).  <\/p>\n<p>Tried out some solution as suggested by Microsoft . However we were facing the same issue again.   <\/p>\n<p>Could you please help me on this.  <\/p>\n<p>Thanks,  <br \/>\nCharles  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1607923602410,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/197005\/azure-ml-studio-(error-0009-exception-occurs-when",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio error except occur azur storag account contain specifi incorrectli team tri connect azur blob studio face follow error error except occur azur storag account contain specifi incorrectli tri solut suggest microsoft face issu help thank charl",
        "Question_preprocessed_content":"studio team tri azur blob studio face tri solut microsoft face help thank charl",
        "Question_gpt_summary_original":"The user is encountering an Error 0009 Exception while trying to connect Azure blob and Azure ML studio, which occurs when the Azure storage account name or container name is specified incorrectly. The user has tried some solutions suggested by Microsoft but is still facing the same issue and is seeking help.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Update same output dir in different stages",
        "Question_body":"<p>Hi, I have a pipeline with many stages that write the output in different subdirectories of the same dir.<br>\nSo basically each stage has as input a dir like this:<\/p>\n<ul>\n<li>input-dir\n<ul>\n<li>file1<\/li>\n<li>file2<\/li>\n<li>fileN<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<p>The nth stage writes its output:<\/p>\n<ul>\n<li>output-dir (same for all the stages)\n<ul>\n<li>results-file1\n<ul>\n<li>output-stage1<\/li>\n<li>output-stage2<\/li>\n<li>output-stageN<\/li>\n<\/ul>\n<\/li>\n<li>results-file2<br>\n.<br>\n.<br>\n.<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<p>Actually, results-file* is  a zarr group (<a href=\"https:\/\/zarr.readthedocs.io\/en\/stable\/api\/hierarchy.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Groups (zarr.hierarchy) \u2014 zarr 2.6.1 documentation<\/a>), whereas each stage appends new arrays (that correspond to output-stage* dirs).<br>\nIs there a way to achieve these with dvc? the command <code>dvc run<\/code> complains the output is already specified in another stage.<\/p>\n<p>Thanks in advance<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1610622285769,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1474.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/update-same-output-dir-in-different-stages\/620",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"updat output dir differ stage pipelin stage write output differ subdirectori dir basic stage input dir like input dir file file filen nth stage write output output dir stage result file output stage output stage output stagen result file actual result file zarr group group zarr hierarchi zarr document stage append new arrai correspond output stage dir wai achiev command run complain output specifi stage thank advanc",
        "Question_preprocessed_content":"updat output dir stage pipelin stage write output subdirectori dir stage input dir like file file filen nth stage write output group document stage new wai achiev complain output specifi stage thank advanc",
        "Question_gpt_summary_original":"The user has a pipeline with multiple stages that write output to different subdirectories of the same directory. Each stage appends new arrays to a zarr group. The user is facing challenges in updating the same output directory in different stages using dvc, as the command \"dvc run\" complains that the output is already specified in another stage.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Sagemaker Ground Truth completes with labelling errors",
        "Question_body":"Hi all,\n\nI set a Sagemaker Ground Truth labelling task. All the labelled objects results with \"Failed\" status, though it is possible retrieve the labels from S3. Eventually, nothing apart from the job status is wrong - but I am worried that I could and I would like to resolve it. There are no logs in cloudwatch with anything FAILED. Would you know how to get rid of this issue? For start, it would be good to see a specific issue in cloudwatch and then try to resolve the problem with failed jobs.\n\nThe logs show the following (I filtered out repeating events for different input objects):\n\n```\n{\n    \"labeling-job-name\": \"test-job51\",\n    \"event-name\": \"INPUT_REQUEST_VALIDATED\",\n    \"event-log-message\": \"Input request validated.\"\n}\n{\n    \"labeling-job-name\": \"test-job51\",\n    \"event-name\": \"CREATED_WORKER_INTERFACE\",\n    \"event-log-message\": \"Human task UI created.\"\n}\n{\n    \"labeling-job-name\": \"test-job51\",\n    \"event-name\": \"INPUT_MANIFEST_PARSED\",\n    \"event-log-message\": \"Input manifest parsed successfully.\"\n}\n{\n    \"labeling-job-name\": \"test-job51\",\n    \"event-name\": \"PRE_HUMAN_LAMBDA_INVOKED\",\n    \"event-log-message\": \"Pre-human task Lambda invoked for line 6.\"\n}\n{\n    \"labeling-job-name\": \"test-job51\",\n    \"event-name\": \"PRE_HUMAN_LAMBDA_SUCCEEDED\",\n    \"event-log-message\": \"Pre-human task Lambda returned successfully for line 6.\"\n}\n{\n    \"labeling-job-name\": \"test-job51\",\n    \"event-name\": \"HUMAN_TASK_CREATED\",\n    \"event-log-message\": \"Human task created successfully for line 6.\"\n}\n{\n    \"event-name\": \"HUMAN_TASK_COMPLETED\",\n    \"event-log-message\": \"Human task completed successfully for line 6.\",\n    \"labeling-job-name\": \"test-job51\"\n}\n{\n    \"labeling-job-name\": \"test-job51\",\n    \"event-name\": \"LABELING_JOB_PROGRESS\",\n    \"event-log-message\": \"Labeling job progress for batch number:1 | #Total data set objects:2 | #Data set objects completed:0 | #Data set objects waiting for humans:0 | #Data set objects failed:2 | #Data set objects expired:0 | #Data set objects cancelled:0\"\n}\n```\n\n\nThe setup goes as follows\n- using VPC\n- using Private Labelling team\n- CORS set on S3 bucket (per suggestion from `https:\/\/repost.aws\/knowledge-center\/sagemaker-ground-truth-errors`)\n- the execution role has permission to use cloudwatch (per suggestion from https:\/\/repost.aws\/knowledge-center\/sagemaker-ground-truth-errors)\n- Cognito App callback url is `https:\/\/XXX.labeling.us-east-1.sagemaker.aws\/oauth2\/idpresponse` and logout URL is `https:\/\/XXX.labeling.us-east-1.sagemaker.aws\/logout` (I noticed that when the labelling job\/workforce is created from Console, there is an additional allowed callback `https:\/\/XXX.cloudfront.net`; I did not add it)",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1680685751465,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1681033088987,
        "Question_score_count":0.0,
        "Question_view_count":52.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUh8WSJpuNTVqQ4-gW6_e6LQ\/sagemaker-ground-truth-completes-with-labelling-errors",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"ground truth complet label error set ground truth label task label object result fail statu possibl retriev label eventu apart job statu wrong worri like resolv log cloudwatch fail know rid issu start good specif issu cloudwatch try resolv problem fail job log follow filter repeat event differ input object label job test job event input request valid event log messag input request valid label job test job event creat worker interfac event log messag human task creat label job test job event input manifest pars event log messag input manifest pars successfulli label job test job event pre human lambda invok event log messag pre human task lambda invok line label job test job event pre human lambda succeed event log messag pre human task lambda return successfulli line label job test job event human task creat event log messag human task creat successfulli line event human task complet event log messag human task complet successfulli line label job test job label job test job event label job progress event log messag label job progress batch number total data set object data set object complet data set object wait human data set object fail data set object expir data set object cancel setup goe follow vpc privat label team cor set bucket suggest http repost aw knowledg center ground truth error execut role permiss us cloudwatch suggest http repost aw knowledg center ground truth error cognito app callback url http xxx label east aw oauth idprespons logout url http xxx label east aw logout notic label job workforc creat consol addit allow callback http xxx cloudfront net add",
        "Question_preprocessed_content":"ground truth complet set ground truth task object result fail statu retriev label apart job statu wrong like resolv log cloudwatch fail know rid start specif cloudwatch try resolv problem fail job log setup goe vpc privat team cor set bucket execut role us cloudwatch cognito url logout url",
        "Question_gpt_summary_original":"The user has encountered an issue with Sagemaker Ground Truth labelling task where all the labelled objects result in a \"Failed\" status, despite being able to retrieve the labels from S3. There are no logs in cloudwatch with anything FAILED, and the user is seeking help to resolve the problem with failed jobs. The setup includes using VPC, Private Labelling team, CORS set on S3 bucket, and the execution role has permission to use cloudwatch.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to create azure machine learning resource using terraform resource providers?",
        "Question_body":"<p>I wants to create azure machine learning workspace using terraform scripts.Is there any terraform provider to achieve this.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1.0,
        "Question_created_time":1581577491623,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1152.0,
        "Poster_created_time":1565633099383,
        "Poster_location":null,
        "Poster_reputation_count":110.0,
        "Poster_view_count":12.0,
        "Answer_body":"<p>In the meantime Microsoft has added a Terraform resource for ML Workspace in the Azure Provider. This should make any custom scripting obsolete.<\/p>\n<p><a href=\"https:\/\/www.terraform.io\/docs\/providers\/azurerm\/r\/machine_learning_workspace.html\" rel=\"nofollow noreferrer\">https:\/\/www.terraform.io\/docs\/providers\/azurerm\/r\/machine_learning_workspace.html<\/a><\/p>\n<pre><code>resource &quot;azurerm_machine_learning_workspace&quot; &quot;example&quot; {\n  name                    = &quot;example-workspace&quot;\n  location                = azurerm_resource_group.example.location\n  resource_group_name     = azurerm_resource_group.example.name\n  application_insights_id = azurerm_application_insights.example.id\n  key_vault_id            = azurerm_key_vault.example.id\n  storage_account_id      = azurerm_storage_account.example.id\n\n  identity {\n    type = &quot;SystemAssigned&quot;\n  }\n}\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1600285333648,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1391261341596,
        "Answerer_location":null,
        "Answerer_reputation_count":76.0,
        "Answerer_view_count":4.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60202189",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat resourc terraform resourc provid want creat workspac terraform script terraform provid achiev",
        "Question_preprocessed_content":"creat resourc resourc provid want creat workspac provid achiev",
        "Question_gpt_summary_original":"The user is looking for a way to create an Azure machine learning workspace using Terraform scripts and is seeking information on whether there is a Terraform provider available for this purpose.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Summarize Complex Configuration Dictionaries",
        "Question_body":"<p>Hello,<br>\nIs there a way I can access the nested dictionaries in the <code>run.config<\/code> object for custom panels, weaves and reports. Apart from sweeps, I am manipulating a variable space and logging them as an array to the config as below:<\/p>\n<pre><code class=\"lang-python\">wandb.config.update({'observation\/experiment': AN_ARRAY })\n<\/code><\/pre>\n<p>I would like to access and visualize\/summarize this variable in text or weave form. However when I call <code>run.config<\/code> in a weave, this variable doesn\u2019t show up even though I can see it in the run overview.<br>\nThank you for your support!<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1653291234729,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":187.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/summarize-complex-configuration-dictionaries\/2481",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"summar complex configur dictionari hello wai access nest dictionari run config object custom panel weav report apart sweep manipul variabl space log arrai config config updat observ experi arrai like access visual summar variabl text weav form run config weav variabl doesnt run overview thank support",
        "Question_preprocessed_content":"complex configur dictionari wai nest dictionari object custom panel weav report apart manipul variabl space config like variabl text weav form weav variabl doesnt run overview thank",
        "Question_gpt_summary_original":"The user is trying to access nested dictionaries in the \"run.config\" object for custom panels, weaves, and reports. They are manipulating a variable space and logging it as an array to the config, but are unable to access and visualize\/summarize this variable in text or weave form. The variable doesn't show up when calling \"run.config\" in a weave, even though it is visible in the run overview.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Logging Artifacts from MlFlow on GCS Bucket",
        "Question_body":"<p>I have a running MlFlow server on GCS VM instance. I have created a bucket to log the artifacts.\nThis is the command I'm running to start the server and for specifying bucket path-<\/p>\n\n<pre><code>mlflow server --default-artifact-root gs:\/\/gcs_bucket\/artifacts --host x.x.x.x\n<\/code><\/pre>\n\n<p>But facing this error:<\/p>\n\n<pre><code>TypeError: stat: path should be string, bytes, os.PathLike or integer, not ElasticNet\n<\/code><\/pre>\n\n<p>Note- The mlflow server is running fine with the specified host alone. The problem is in the way when I'm specifying the storage bucket path.\nI have given permission of storage api by using these commands:<\/p>\n\n<pre><code>gcloud auth application-default login\ngcloud auth login\n<\/code><\/pre>\n\n<p>Also, on printing the artifact URI, this is what I'm getting:<\/p>\n\n<pre><code>mlflow.get_artifact_uri()\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>gs:\/\/gcs_bucket\/artifacts\/0\/122481bf990xxxxxxxxxxxxxxxxxxxxx\/artifacts\n<\/code><\/pre>\n\n<p>So in the above path from where this is coming <code>0\/122481bf990xxxxxxxxxxxxxxxxxxxxx\/artifacts<\/code> and why it's not getting auto-created at <code>gs:\/\/gcs_bucket\/artifacts<\/code><\/p>\n\n<p>After debugging more, why it's not able to get the local path from VM:\n<a href=\"https:\/\/i.stack.imgur.com\/ubDU0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ubDU0.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And this error I'm getting on VM:<\/p>\n\n<pre><code>ARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '.\/mlruns\/mlruns\/meta.yaml' does not exist.\nTraceback (most recent call last):\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 197, in list_experiments\n   experiment = self._get_experiment(exp_id, view_type)\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 256, in _get_experiment\n   meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/utils\/file_utils.py\", line 160, in read_yaml\n   raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\nmlflow.exceptions.MissingConfigException: Yaml file '.\/mlruns\/mlruns\/meta.yaml' does not exist.\n<\/code><\/pre>\n\n<p>Can I get a solution to this and what I'm missing?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7.0,
        "Question_created_time":1583840420677,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1583922371776,
        "Question_score_count":4.0,
        "Question_view_count":2153.0,
        "Poster_created_time":1451124057623,
        "Poster_location":"India",
        "Poster_reputation_count":736.0,
        "Poster_view_count":234.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60616879",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"log artifact gc bucket run server gc instanc creat bucket log artifact command run start server specifi bucket path server default artifact root gc bucket artifact host face error typeerror stat path string byte pathlik integ elasticnet note server run fine specifi host problem wai specifi storag bucket path given permiss storag api command gcloud auth applic default login gcloud auth login print artifact uri get artifact uri output gc bucket artifact bfxxxxxxxxxxxxxxxxxxxxx artifact path come bfxxxxxxxxxxxxxxxxxxxxx artifact get auto creat gc bucket artifact debug abl local path error get arn root malform experi mlrun detail error yaml file mlrun mlrun meta yaml exist traceback recent file usr local lib python dist packag store track file store line list experi experi self experi exp view type file usr local lib python dist packag store track file store line experi meta read yaml experi dir filestor meta data file file usr local lib python dist packag util file util line read yaml rais missingconfigexcept yaml file exist file path except missingconfigexcept yaml file mlrun mlrun meta yaml exist solut miss",
        "Question_preprocessed_content":"artifact gc bucket server gc instanc creat bucket log artifact start server specifi bucket path face note server fine specifi host problem wai specifi storag bucket path given storag api print artifact uri output path come abl local path solut",
        "Question_gpt_summary_original":"The user is encountering an error while trying to log artifacts from MlFlow on a GCS bucket. The error message states that the path should be a string, bytes, os.PathLike or integer, not ElasticNet. The user has given permission of storage API and is getting an output on printing the artifact URI. However, the path is not getting auto-created at the specified location. The user is also getting an error on the VM and is looking for a solution to the problem.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to get preprocess\/postprocess steps from model created using Google Vertex AI?",
        "Question_body":"<p>A client of mine wants to run their Google Vertex AI model on NVIDIA Jetson boards using TensorRT as accelerator. The problem with this is that their model uses certain operators (DecodeJpeg) that are not supported by ONNX. I've been able to isolate the feature extrator subgraph from the model, so everything supported by ONNX is being used, while the preprocess and postprocess will be written separate from the model.<\/p>\n<p>I'm asking because I need to be provided the pre\/postprocess of the model so I could implement them separately, so is there a way to get pre\/postprocess from Google Vertex AI console?<\/p>\n<p>I've tried running a loop that rescales the image to a squared tile from 0 to 512, but none of those gave the adequate result.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_created_time":1649079409933,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":107.0,
        "Poster_created_time":1616415228996,
        "Poster_location":null,
        "Poster_reputation_count":16.0,
        "Poster_view_count":8.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71738221",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"preprocess postprocess step model creat client want run model nvidia jetson board tensorrt acceler problem model us certain oper decodejpeg support onnx abl isol featur extrat subgraph model support onnx preprocess postprocess written separ model ask need provid pre postprocess model implement separ wai pre postprocess consol tri run loop rescal imag squar tile gave adequ result",
        "Question_preprocessed_content":"step model creat client want run model nvidia jetson board problem model us certain oper abl isol featur extrat subgraph model separ model ask provid model implement separ wai consol tri rescal imag squar tile gave adequ result",
        "Question_gpt_summary_original":"The user wants to run a Google Vertex AI model on NVIDIA Jetson boards using TensorRT as an accelerator. However, certain operators used in the model are not supported by ONNX. The user has isolated the feature extractor subgraph from the model, but needs the preprocess and postprocess steps separately. The user is asking if there is a way to get the pre\/postprocess from the Google Vertex AI console. The user has tried rescaling the image but has not achieved the desired result.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Tensorflow error. TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn",
        "Question_body":"<p>I am trying to run this on Amazon Sagemaker but I am getting this error while when I try to run it on my local machine, it works very fine.<\/p>\n<p>this is my code:<\/p>\n<pre><code>import tensorflow as tf\n\nimport IPython.display as display\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nmpl.rcParams['figure.figsize'] = (12,12)\nmpl.rcParams['axes.grid'] = False\n\nimport numpy as np\nimport PIL.Image\nimport time\nimport functools\n    \ndef tensor_to_image(tensor):\n  tensor = tensor*255\n  tensor = np.array(tensor, dtype=np.uint8)\n  if np.ndim(tensor)&gt;3:\n    assert tensor.shape[0] == 1\n    tensor = tensor[0]\n  return PIL.Image.fromarray(tensor)\n\ncontent_path = tf.keras.utils.get_file('YellowLabradorLooking_nw4.jpg', 'https:\/\/example.com\/IMG_20200216_163015.jpg')\n\n\nstyle_path = tf.keras.utils.get_file('kandinsky3.jpg','https:\/\/example.com\/download+(2).png')\n\n\ndef load_img(path_to_img):\n    max_dim = 512\n    img = tf.io.read_file(path_to_img)\n    img = tf.image.decode_image(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n    long_dim = max(shape)\n    scale = max_dim \/ long_dim\n\n    new_shape = tf.cast(shape * scale, tf.int32)\n\n    img = tf.image.resize(img, new_shape)\n    img = img[tf.newaxis, :]\n    return img\n\n\ndef imshow(image, title=None):\n  if len(image.shape) &gt; 3:\n    image = tf.squeeze(image, axis=0)\n\n  plt.imshow(image)\n  if title:\n    plt.title(title)\n\n\ncontent_image = load_img(content_path)\nstyle_image = load_img(style_path)\n\nplt.subplot(1, 2, 1)\nimshow(content_image, 'Content Image')\n\nplt.subplot(1, 2, 2)\nimshow(style_image, 'Style Image')\n\nimport tensorflow_hub as hub\nhub_module = hub.load('https:\/\/tfhub.dev\/google\/magenta\/arbitrary-image-stylization-v1-256\/1')\nstylized_image = hub_module(tf.constant(content_image), tf.constant(style_image))[0]\ntensor_to_image(stylized_image)\n\n\nfile_name = 'stylized-image5.png'\ntensor_to_image(stylized_image).save(file_name)\n<\/code><\/pre>\n<p>This is the exact error I get:<\/p>\n<pre><code>---------------------------------------------------------------------------\n<\/code><\/pre>\n<p>TypeError                                 Traceback (most recent call last)<\/p>\n<pre><code>&lt;ipython-input-24-c47a4db4880c&gt; in &lt;module&gt;()\n     53 \n     54 \n---&gt; 55 content_image = load_img(content_path)\n     56 style_image = load_img(style_path)\n     57 \n<\/code><\/pre>\n<p> in load_img(path_to_img)<\/p>\n<pre><code>     34 \n     35     shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n---&gt; 36     long_dim = max(shape)\n     37     scale = max_dim \/ long_dim\n     38 \n<\/code><\/pre>\n<p>~\/anaconda3\/envs\/amazonei_tensorflow_p36\/lib\/python3.6\/site-packages\/tensorflow\/python\/framework\/ops.py in <strong>iter<\/strong>(self)<\/p>\n<pre><code>    475     if not context.executing_eagerly():\n    476       raise TypeError(\n--&gt; 477           &quot;Tensor objects are only iterable when eager execution is &quot;\n    478           &quot;enabled. To iterate over this tensor use tf.map_fn.&quot;)\n    479     shape = self._shape_tuple()\n<\/code><\/pre>\n<p>TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1594076057097,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":1530.0,
        "Poster_created_time":1565307837780,
        "Poster_location":null,
        "Poster_reputation_count":570.0,
        "Poster_view_count":37.0,
        "Answer_body":"<p>Your error is being raised in this function <code>load_img<\/code>:<\/p>\n<pre><code>def load_img(path_to_img):\n    max_dim = 512\n    img = tf.io.read_file(path_to_img)\n    img = tf.image.decode_image(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n    long_dim = max(shape)\n    scale = max_dim \/ long_dim\n\n    new_shape = tf.cast(shape * scale, tf.int32)\n\n    img = tf.image.resize(img, new_shape)\n    img = img[tf.newaxis, :]\n    return img\n<\/code><\/pre>\n<p>Specifically, this line:<\/p>\n<pre><code>    long_dim = max(shape)\n<\/code><\/pre>\n<p>You are passing a tensor to the <a href=\"https:\/\/docs.python.org\/3\/library\/functions.html#max\" rel=\"nofollow noreferrer\">built-in Python max function<\/a> in graph execution mode. You can only iterate through tensors in eager-execution mode. You probably want to use <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/math\/reduce_max\" rel=\"nofollow noreferrer\">tf.reduce_max<\/a> instead:<\/p>\n<pre><code>    long_dim = tf.reduce_max(shape)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1594129639003,
        "Answer_last_edit_time":1594159994640,
        "Answer_score_count":1.0,
        "Answerer_created_time":1374169767267,
        "Answerer_location":"San Francisco, CA, USA",
        "Answerer_reputation_count":548.0,
        "Answerer_view_count":70.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62765658",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"tensorflow error typeerror tensor object iter eager execut enabl iter tensor us map try run get error try run local machin work fine code import tensorflow import ipython displai displai import matplotlib pyplot plt import matplotlib mpl mpl rcparam figur figsiz mpl rcparam ax grid fals import numpi import pil imag import time import functool def tensor imag tensor tensor tensor tensor arrai tensor dtype uint ndim tensor assert tensor shape tensor tensor return pil imag fromarrai tensor content path kera util file yellowlabradorlook jpg http exampl com img jpg style path kera util file kandinski jpg http exampl com download png def load img path img max dim img read file path img img imag decod imag img channel img imag convert imag dtype img float shape cast shape img float long dim max shape scale max dim long dim new shape cast shape scale int img imag resiz img new shape img img newaxi return img def imshow imag titl len imag shape imag squeez imag axi plt imshow imag titl plt titl titl content imag load img content path style imag load img style path plt subplot imshow content imag content imag plt subplot imshow style imag style imag import tensorflow hub hub hub modul hub load http tfhub dev googl magenta arbitrari imag styliz styliz imag hub modul constant content imag constant style imag tensor imag styliz imag file styliz imag png tensor imag styliz imag save file exact error typeerror traceback recent content imag load img content path style imag load img style path load img path img shape cast shape img float long dim max shape scale max dim long dim anaconda env amazonei tensorflow lib python site packag tensorflow python framework op iter self context execut eagerli rais typeerror tensor object iter eager execut enabl iter tensor us map shape self shape tupl typeerror tensor object iter eager execut enabl iter tensor us map",
        "Question_preprocessed_content":"tensorflow tensor object iter eager execut enabl iter tensor us try run try run local machin work fine code exact traceback iter tensor object iter eager execut enabl iter tensor us",
        "Question_gpt_summary_original":"The user is encountering a Tensorflow error while trying to run a code on Amazon Sagemaker. The error message states that Tensor objects are only iterable when eager execution is enabled and suggests using tf.map_fn to iterate over the tensor. The code runs fine on the user's local machine.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"RuntimeError: as_numpy_iterator() is not supported while tracing functions on tensorflow 2.x dataset on sagemaker",
        "Question_body":"<p>I am preparing a <a href=\"https:\/\/pypi.org\/project\/sagemaker-tensorflow\/\" rel=\"noreferrer\">sagemaker PIPE mode dataset<\/a> to train a time series model on <code>SageMaker<\/code> with <code>PIPE<\/code> mode. The <code>PipeModeDataset<\/code> is a <code>TensorFlow Dataset<\/code> for reading <code>SageMaker<\/code> Pipe Mode channels. I am using an augmented manifest file which contains image location on <code>S3<\/code> and the label each line. My model accept batches of images (512 x 512 x 1) with single label per batch as input. I thought of using the window function to bundle the images read from pipe. Please refer to following partial code for dataset generation.<\/p>\n<pre><code>def _input_fn(channel):\n    &quot;&quot;&quot;Returns a Dataset for reading from a SageMaker PipeMode channel.&quot;&quot;&quot;\n    features = {\n        'image-ref': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([3], tf.int64),\n    }\n    \n    def parse(record):\n        parsed = tf.io.parse_single_example(record, features)\n        image = tf.io.decode_png(parsed['image-ref'], channels=1, dtype=tf.uint8)\n        image = tf.reshape(image, [512, 512, 1])\n        label = parsed['label']\n        return (image, label)\n\n    ds = PipeModeDataset(channel, record_format='TFRecord', benchmark=True, benchmark_records_interval=100)\n    ds = ds.map(parse)\n    \n    print (&quot;PipeModeDataset print0 = &quot; + str(ds))\n    ds = ds.window(16, shift=1, drop_remainder=True)\n    print (&quot;PipeModeDataset print1 = &quot; + str(ds))\n    \n    def window_func(window, label):\n        window = window.batch(16, drop_remainder=True)\n        label = label.batch(16, drop_remainder=True)\n        \n        print (&quot;window batch is = &quot; + str(window))\n        print (&quot;label batch is = &quot; + str(label))\n        \n        window_np = np.stack(list(window.as_numpy_iterator()))\n        label_np = np.stack(list(label.as_numpy_iterator())) # TODO: only get the last label\n        \n        return tf.data.Dataset.from_tensor_slices((window_np, label_np))\n    \n    ds = ds.flat_map(lambda window, label: window_func(window, label))\n    ....\n    ....\n<\/code><\/pre>\n<p>Getting following error at the moment. How to fix this? Recommend better ways if there is any.<\/p>\n<pre><code>PipeModeDataset print0 = &lt;MapDataset shapes: ((512, 512, 1), (3,)), types: (tf.uint8, tf.int64)&gt;\nPipeModeDataset print1 = &lt;WindowDataset shapes: (DatasetSpec(TensorSpec(shape=(512, 512, 1), dtype=tf.uint8, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(3,), dtype=tf.int64, name=None), TensorShape([]))), types: (DatasetSpec(TensorSpec(shape=(512, 512, 1), dtype=tf.uint8, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(3,), dtype=tf.int64, name=None), TensorShape([])))&gt;\nwindow batch is = &lt;BatchDataset shapes: (16, 512, 512, 1), types: tf.uint8&gt;\nlabel batch is = &lt;BatchDataset shapes: (16, 3), types: tf.int64&gt;\n\nRuntimeError: in user code:\n\n    \/opt\/ml\/code\/train_on_pipemode.py:104 None  *\n        ds = ds.flat_map(lambda window, label: window_func(window, label))\n    \/opt\/ml\/code\/train_on_pipemode.py:96 window_func  *\n        window_np = np.stack(list(window.as_numpy_iterator()))\n    \/usr\/local\/lib\/python3.7\/site-packages\/tensorflow\/python\/data\/ops\/dataset_ops.py:518 as_numpy_iterator  **\n        raise RuntimeError(&quot;as_numpy_iterator() is not supported while tracing &quot;\n\n    RuntimeError: as_numpy_iterator() is not supported while tracing functions\n<\/code><\/pre>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/60045971\/runtimeerror-as-numpy-iterator-is-not-supported-while-tracing-functions\">This answer<\/a> says to enable eager execution, but it is enabled in my case when I printed <code>tf.executing_eagerly()<\/code>. I am training on <code>tensorflow 2.x<\/code>.<\/p>\n<pre><code>Tensorflow version: 2.3.1\nEager execution: True\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1606932510877,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":5.0,
        "Question_view_count":322.0,
        "Poster_created_time":1393576024047,
        "Poster_location":"Sri Lanka",
        "Poster_reputation_count":879.0,
        "Poster_view_count":138.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65113746",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"runtimeerror numpi iter support trace function tensorflow dataset prepar pipe mode dataset train time seri model pipe mode pipemodedataset tensorflow dataset read pipe mode channel augment manifest file contain imag locat label line model accept batch imag singl label batch input thought window function bundl imag read pipe refer follow partial code dataset gener def input channel return dataset read pipemod channel featur imag ref fixedlenfeatur string label fixedlenfeatur int def pars record pars pars singl exampl record featur imag decod png pars imag ref channel dtype uint imag reshap imag label pars label return imag label pipemodedataset channel record format tfrecord benchmark true benchmark record interv map pars print pipemodedataset print str window shift drop remaind true print pipemodedataset print str def window func window label window window batch drop remaind true label label batch drop remaind true print window batch str window print label batch str label window stack list window numpi iter label stack list label numpi iter todo label return data dataset tensor slice window label flat map lambda window label window func window label get follow error moment fix recommend better wai pipemodedataset print pipemodedataset print window batch label batch runtimeerror user code opt code train pipemod flat map lambda window label window func window label opt code train pipemod window func window stack list window numpi iter usr local lib python site packag tensorflow python data op dataset op numpi iter rais runtimeerror numpi iter support trace runtimeerror numpi iter support trace function answer sai enabl eager execut enabl case print execut eagerli train tensorflow tensorflow version eager execut true",
        "Question_preprocessed_content":"trace function tensorflow dataset prepar pipe mode dataset train time seri model mode read pipe mode augment manifest file contain imag locat label line model batch imag singl label batch input thought window function bundl imag read pipe refer partial code dataset gener moment fix wai answer sai enabl eager execut enabl case print train",
        "Question_gpt_summary_original":"The user is encountering a RuntimeError while preparing a sagemaker PIPE mode dataset to train a time series model on SageMaker with PIPE mode. The error occurs when using the window function to bundle the images read from pipe. The error message suggests that as_numpy_iterator() is not supported while tracing functions on tensorflow 2.x dataset on sagemaker. The user has already enabled eager execution and is training on tensorflow 2.3.1.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Having Issues with authentication using REST API",
        "Question_body":"Hello,\n\nI'm building a rust application that needs to use cloud vision ocr. I use\u00a0service account key JSON file\u00a0to authenticate, and I had no problems with it using the Python and Go libraries. I wasn't able to understand how to use this authentication method in the rust library, so I decided to use the POST request method. To do such thing I need to somehow include my key in the request header, and I have not been able to do it. My code and the response I get are below.\n\n```\u00a0\n\npub\u00a0async\u00a0fn\u00a0req(url:\u00a0&str)\u00a0->\u00a0Result<String,\u00a0Box<dyn\u00a0std::error::Error>> {\nlet\u00a0auth_token\u00a0=\u00a0fs::read_to_string(String::from(\"auth_sin.json\"))\n.expect(\"Should have been able to read the file\");\nlet\u00a0client\u00a0=\u00a0reqwest::Client::builder().build()?;\nlet\u00a0reqtext\u00a0=\u00a0format!(\"Bearer -d\u00a0{}\",&auth_token[..]);\nlet\u00a0request\u00a0=\u00a0client\n.post(\"https:\/\/vision.googleapis.com\/v1\/images:annotate\")\n.header(String::from(\"Authorization\"),\u00a0reqtext.replace(\"\\n\",\"\"))\n.header(\"Content-Type\",\u00a0\"application\/json; charset=utf-8\")\n.json(&build_request(url));\nprintln!(\"{:?}\",\u00a0request);\nlet\u00a0response\u00a0=request\n.send()\n.await?;\nlet\u00a0t\u00a0=\u00a0response\n.text()\n.await?;\nOk(t)\n}\n```\n\u00a0\nReponse\u00a0\n```\n{\n\"error\": {\n\"code\": 401,\n\"message\": \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See\u00a0https:\/\/developers.google.com\/identity\/sign-in\/web\/devconsole-project.\",\n\"status\": \"UNAUTHENTICATED\",\n\"details\": [\n{\n\"@type\": \"type.googleapis.com\/google.rpc.ErrorInfo\",\n\"reason\": \"ACCESS_TOKEN_TYPE_UNSUPPORTED\",\n\"metadata\": {\n\"method\": \"google.cloud.vision.v1.ImageAnnotator.BatchAnnotateImages\",\n\"service\": \"vision.googleapis.com\"\n}\n}\n]\n}\n}\n```",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1678979220000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":147.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Having-Issues-with-authentication-using-REST-API\/m-p\/533517#M1433",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"have issu authent rest api hello build rust applic need us cloud vision ocr useservic account kei json fileto authent problem python librari wasn abl understand us authent method rust librari decid us post request method thing need includ kei request header abl code respons pubasyncfnreq url str result letauth token read string string auth sin json expect abl read file letclient reqwest client builder build letreqtext format bearer auth token letrequest client post http vision googleapi com imag annot header string author reqtext replac header content type applic json charset utf json build request url println request letrespons request send await lett respons text await repons error code messag request invalid authent credenti expect oauth access token login cooki valid authent credenti seehttp develop googl com ident sign web devconsol project statu unauthent detail type type googleapi com googl rpc errorinfo reason access token type unsupport metadata method googl cloud vision imageannot batchannotateimag servic vision googleapi com",
        "Question_preprocessed_content":"have authent rest api build rust us cloud vision ocr useservic kei json fileto authent problem python librari wasn abl understand us authent method rust librari decid us post request method thing includ kei request header abl code respons repons",
        "Question_gpt_summary_original":"The user is building a Rust application that needs to use cloud vision OCR. They are having issues with authentication using REST API and are unable to include their key in the request header. The response they receive indicates that the request had invalid authentication credentials and that an OAuth 2 access token or other valid authentication credential was expected.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"dataframe.corr error on execute python script",
        "Question_body":"<p>\u0131 want run &quot;dataframe.corr()&quot; how can \u0131 do this?    <br \/>\n<img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/105080-ekran-goruntusu-13.png?platform=QnA\" alt=\"105080-ekran-goruntusu-13.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/105161-ekran-goruntusu-14.png?platform=QnA\" alt=\"105161-ekran-goruntusu-14.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1623566454357,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/433653\/dataframe-corr-error-on-execute-python-script",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"datafram corr error execut python script want run datafram corr",
        "Question_preprocessed_content":"execut python script want run",
        "Question_gpt_summary_original":"The user is encountering an error while trying to execute a Python script that involves using \"dataframe.corr()\" and is seeking guidance on how to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to handle resuming and changing config file",
        "Question_body":"<p>I have the following scenario:<\/p>\n<p>Let\u2019s say I have started a run with a specific config, e.g. at the beginning of my run I would do something like this<\/p>\n<pre><code class=\"lang-auto\">config = {\"lr\" : 0.01, \"a\": \"b\", ..., \"sample_interval\": 2000}\nwandb.init(config = config, ...)\n<\/code><\/pre>\n<p>Now after some time, I realize I want to change something about my model. For example, here I want to sample more often. I would then stop the run and rerun my script with the correct resume ID<\/p>\n<pre><code class=\"lang-auto\">config = {\"lr\" : 0.01, \"a\": \"b\", ..., \"sample_interval\": 1000}\nwandb.init(config = config, id = OLD_ID, resume = \"allow\",  ...)\n<\/code><\/pre>\n<p>I think the behaviour wandb has, is to then have the config be changed to the second config online. Is the first config just overwritten or can it still be seen somewhere?<\/p>\n<p>In my more concrete usecase, I might want to change more big things. For example: I have trained with one dataloader for some time, then wrote a more efficient dataloader and would like to switch.<br>\nIdeally I would want both of the information, the old and the new config to be seen. Is there a way to do this?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1682855718818,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":50.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-handle-resuming-and-changing-config-file\/4301",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"handl resum chang config file follow scenario let start run specif config begin run like config sampl interv init config config time realiz want chang model exampl want sampl stop run rerun script correct resum config sampl interv init config config old resum allow think behaviour config chang second config onlin config overwritten seen concret usecas want chang big thing exampl train dataload time wrote effici dataload like switch ideal want inform old new config seen wai",
        "Question_preprocessed_content":"handl resum chang config file scenario let start run specif config run like time realiz want chang model exampl want sampl stop run rerun script resum think behaviour config chang second config onlin config concret usecas want chang big thing exampl train dataload time wrote dataload like switch want inform old new config wai",
        "Question_gpt_summary_original":"The user is facing a challenge in handling resuming and changing the config file while running a script using wandb. They want to know if the first config is overwritten or can still be seen somewhere after changing the config and resuming the run. Additionally, they want to know if there is a way to see both the old and new config when making big changes like switching dataloaders.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Amazon sagemaker. SKlearn estimator vs Tensorflow estimator - why requirements_file is not present in one of them?",
        "Question_body":"<p>I am looking at definitions of two estimators SKLearn and Tensorflow in Amazon Sagemaker:<\/p>\n\n<p><a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/sagemaker.sklearn.html\" rel=\"nofollow noreferrer\">SKLearn<\/a><\/p>\n\n<p><a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/sagemaker.tensorflow.html\" rel=\"nofollow noreferrer\">Tensorflow<\/a><\/p>\n\n<pre><code>class sagemaker.sklearn.estimator.SKLearn(entry_point, framework_version='0.20.0', source_dir=None, hyperparameters=None, py_version='py3', image_name=None, **kwargs)\n\nclass sagemaker.tensorflow.estimator.TensorFlow(training_steps=None, evaluation_steps=None, checkpoint_path=None, py_version='py2', framework_version=None, model_dir=None, requirements_file='', image_name=None, script_mode=False, distributions=None, **kwargs)\n<\/code><\/pre>\n\n<p>Tensorflow has requirements_file parameter, while SKLearn does not. Is there reason why? How can I add <code>requirements.txt<\/code> to SKLearn estimator?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1557166184387,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":221.0,
        "Poster_created_time":1348677250368,
        "Poster_location":null,
        "Poster_reputation_count":6498.0,
        "Poster_view_count":988.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56010337",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"sklearn estim tensorflow estim requir file present look definit estim sklearn tensorflow sklearn tensorflow class sklearn estim sklearn entri point framework version sourc dir hyperparamet version imag kwarg class tensorflow estim tensorflow train step evalu step checkpoint path version framework version model dir requir file imag script mode fals distribut kwarg tensorflow requir file paramet sklearn reason add requir txt sklearn estim",
        "Question_preprocessed_content":"sklearn estim tensorflow estim present definit estim sklearn tensorflow sklearn tensorflow tensorflow paramet sklearn reason sklearn estim",
        "Question_gpt_summary_original":"The user is comparing the definitions of two Amazon Sagemaker estimators, SKLearn and Tensorflow, and has noticed that Tensorflow has a \"requirements_file\" parameter while SKLearn does not. The user is seeking to understand the reason for this difference and how to add a \"requirements.txt\" file to the SKLearn estimator.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"What is the Differences between SageMaker pytorch SDK and tensorflow SDK?",
        "Question_body":"Dear SageMaker makers,\n\nHi, I'm reading the docs about sagemaker pytorch, tensorflow SDK.\nBut I can't get how each framework sdks are optimized for that framework.\nLiterally, What makes using pytorch sdk more beneficial to train and deploy pytorch model than using just sagemaker sdk \n(sagemaker.pytorch.estimator.PyTorch vs. sagemaker.estimator.Estimator)\n\nthank you!",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1670914204892,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1671260763107,
        "Question_score_count":0.0,
        "Question_view_count":51.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUHU8LsOMtQlexXJzmf2iZ6w\/what-is-the-differences-between-sagemaker-pytorch-sdk-and-tensorflow-sdk",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"differ pytorch sdk tensorflow sdk dear maker read doc pytorch tensorflow sdk framework sdk optim framework liter make pytorch sdk benefici train deploi pytorch model sdk pytorch estim pytorch estim estim thank",
        "Question_preprocessed_content":"pytorch sdk tensorflow sdk dear maker read doc pytorch tensorflow sdk framework sdk optim framework make pytorch sdk benefici train deploi pytorch model sdk thank",
        "Question_gpt_summary_original":"The user is seeking clarification on the differences between SageMaker pytorch SDK and tensorflow SDK, and how each framework is optimized for their respective SDKs. They are specifically asking what makes using pytorch SDK more beneficial for training and deploying pytorch models compared to just using the sagemaker SDK.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Multiple params.yaml",
        "Question_body":"<p>Is it possible to have more than one params.yaml? If so, how should they be organised and named?<\/p>\n<p>The context is I am considering of breaking up my dvc.yaml to multiple pipelines and would like to do the same for the params as well. Is the answer to save a params.yaml at the same place where the pipeline for dvc.yaml will live? something like pipelines\/pip1\/dvc.yaml,params.yaml and pipelines\/pip2\/dvc.yaml,params.yaml<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1618304562199,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":1251.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/multiple-params-yaml\/720",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"multipl param yaml possibl param yaml organis name context consid break yaml multipl pipelin like param answer save param yaml place pipelin yaml live like pipelin pip yaml param yaml pipelin pip yaml param yaml",
        "Question_preprocessed_content":"multipl organis name context consid break yaml multipl pipelin like param answer save place pipelin yaml live like",
        "Question_gpt_summary_original":"The user is asking if it is possible to have multiple params.yaml files and how they should be organized and named. They are considering breaking up their dvc.yaml into multiple pipelines and want to do the same for the params. They are wondering if they should save a params.yaml file in the same place as the pipeline for dvc.yaml.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Can my workspace be an s3 location?",
        "Question_body":"<p>I would like to run <code>dvc pull<\/code> directly into an s3 bucket. Is that possible?<\/p>\n<p>Long story short: I would like end users to version control their csv files using dvc. I then would like to have a recurring process that will do a dvc pull, of the main branch, directly into an s3 bucket. I understand that dvc can use s3 for storage, but I would like to re-create the data in s3, in an identical structure as the dvc git repository.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1646192567568,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":250.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/can-my-workspace-be-an-s3-location\/1083",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"workspac locat like run pull directli bucket possibl long stori short like end user version control csv file like recur process pull main branch directli bucket understand us storag like creat data ident structur git repositori",
        "Question_preprocessed_content":"workspac locat like run directli bucket long stori short like end user version control csv file like main branch directli bucket understand us storag like data ident structur git repositori",
        "Question_gpt_summary_original":"The user wants to know if it is possible to run \"dvc pull\" directly into an s3 bucket to version control csv files using dvc and recreate the data in s3 in an identical structure as the dvc git repository.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Logistic regression in sagemaker",
        "Question_body":"<p>I am using the aws sagemaker for logistic regression. For validating the model on test data, the following code is used <\/p>\n\n<pre><code>runtime= boto3.client('runtime.sagemaker')\n\npayload = np2csv(test_X)\nresponse = runtime.invoke_endpoint(EndpointName=linear_endpoint,\n                                   ContentType='text\/csv',\n                                   Body=payload)\nresult = json.loads(response['Body'].read().decode())\ntest_pred = np.array([r['score'] for r in result['predictions']])\n<\/code><\/pre>\n\n<p>The result contains the prediction values and the probability scores. \nI want to know how I can run a prediction model to predict the outcome based on two specific features. Eg. I have 30 features in the model and have trained model using those features. Now for my prediction, I want to know the outcome when feature1='x' and feature2='y'. But when I filter the data to those columns and pass that in the same code, I get the following error.<\/p>\n\n<pre><code>Customer Error: The feature dimension of the input: 4 does not match the feature dimension of the model: 30. Please fix the input and try again.\n<\/code><\/pre>\n\n<p>What is the equivalent of say glm.predict('feature1','feature2')in R in AWS Sagemaker implementation?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1533920085857,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":1557.0,
        "Poster_created_time":1490822961492,
        "Poster_location":null,
        "Poster_reputation_count":960.0,
        "Poster_view_count":122.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51790953",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"logist regress logist regress valid model test data follow code runtim boto client runtim payload npcsv test respons runtim invok endpoint endpointnam linear endpoint contenttyp text csv bodi payload result json load respons bodi read decod test pred arrai score result predict result contain predict valu probabl score want know run predict model predict outcom base specif featur featur model train model featur predict want know outcom featur featur filter data column pass code follow error custom error featur dimens input match featur dimens model fix input try equival glm predict featur featur implement",
        "Question_preprocessed_content":"logist logist valid model test data code result contain predict valu probabl score want know run predict model predict outcom base specif featur featur model train model featur predict want know outcom featur featur filter data column code equival implement",
        "Question_gpt_summary_original":"The user is facing an issue while trying to predict the outcome based on two specific features using logistic regression in AWS Sagemaker. They have trained the model using 30 features and want to know the outcome when feature1='x' and feature2='y'. However, when they filter the data to those columns and pass it in the code, they get an error stating that the feature dimension of the input does not match the feature dimension of the model. The user is seeking guidance on how to predict the outcome based on specific features in AWS Sagemaker.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to add more photos to AWS Sagemaker Labelling job?",
        "Question_body":"<p>We wish to add more photos to the AWS Sagemaker Labelling job. We tried adding the photo's directly to the s3 path and editing the input manifest file but they don't seem to update on the Labelling task. Is there any workaround for it?<\/p>\n<p>Reference used: <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sms-input-data-input-manifest.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sms-input-data-input-manifest.html<\/a><\/p>\n<p>On a side note: Is there any reference for chaining the jobs, since the documentation on Amazon is confusing and there are no practical examples out there either.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1631557077603,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1632136492540,
        "Question_score_count":1.0,
        "Question_view_count":51.0,
        "Poster_created_time":1631533148667,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69167374",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"add photo label job wish add photo label job tri ad photo directli path edit input manifest file updat label task workaround refer http doc aw amazon com latest sm input data input manifest html note refer chain job document amazon confus practic exampl",
        "Question_preprocessed_content":"photo job wish photo job tri photo directli path edit input manifest file updat task workaround refer note refer chain job document amazon confus practic exampl",
        "Question_gpt_summary_original":"The user is facing challenges in adding more photos to their AWS Sagemaker Labelling job. They have tried adding the photos directly to the s3 path and editing the input manifest file, but the Labelling task does not update. They are looking for a workaround. Additionally, they are seeking references for chaining jobs, as the documentation on Amazon is confusing and lacks practical examples.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"need guidance to use train models in ML studio",
        "Question_body":"<p>hello new to ML studio. We have some trained model already but I want to use the studio for my next step. How should I import my model and retrain them? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1664405211343,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hello <a href=\"\/users\/na\/?userid=94bb880d-285d-4901-b0c8-d07117e001d8\">@Manuel  <\/a>     <\/p>\n<p>Thanks for using Microsoft Q&amp;A platform. Yes you can import your trained model to Azure Machine Learning Studio - <a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local<\/a>    <\/p>\n<p>You can learn how to register a model from different locations, and how to use the Azure Machine Learning SDK, the user interface (UI), and the Azure Machine Learning CLI to manage your models.    <\/p>\n<p>Please check on above article to see how to register your model. I hope it helps.    <\/p>\n<p>Regards,    <br \/>\nYutong    <\/p>\n<p>-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.    <\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1664410354943,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1027872\/need-guidance-to-use-train-models-in-ml-studio",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"need guidanc us train model studio hello new studio train model want us studio step import model retrain",
        "Question_preprocessed_content":"guidanc us train model studio new studio train model want us studio step import model retrain",
        "Question_gpt_summary_original":"The user is new to ML studio and needs guidance on how to import and retrain their already trained models in the studio.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Training multiple model in AWS Sagemaker",
        "Question_body":"<p>Can I train multiple model in AWS Sagemaker by evaluating the models is train.py script and also how to get back multiple metrics from multiple models?<\/p>\n\n<p>Any links, docs or videos would be useful.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1584503168147,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1584511840576,
        "Question_score_count":0.0,
        "Question_view_count":695.0,
        "Poster_created_time":1502018973843,
        "Poster_location":"Noida, Uttar Pradesh, India",
        "Poster_reputation_count":311.0,
        "Poster_view_count":115.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60733257",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train multipl model train multipl model evalu model train script multipl metric multipl model link doc video us",
        "Question_preprocessed_content":"train multipl model train multipl model evalu model script multipl metric multipl model link doc video us",
        "Question_gpt_summary_original":"The user is seeking information on how to train multiple models in AWS Sagemaker and how to evaluate them in the train.py script. They are also looking for guidance on how to obtain multiple metrics from these models. They are requesting links, documentation, or videos that could be helpful.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Deploying custom model on Azure ML Studio",
        "Question_body":"<p>In Azure ML Studio, we have the option of choosing a number of inbuilt ML models like Classification, Regression, etc. , which we can drag and drop to our workflow.<\/p>\n\n<p>My question is, can I upload a custom ML model that I have built locally on my system in Python, and add it to the workflow?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1565761282107,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1565767277470,
        "Question_score_count":1.0,
        "Question_view_count":1187.0,
        "Poster_created_time":1565761178208,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":10.0,
        "Answer_body":"<ol>\n<li>Take the model.pkl file, zip it, and upload it into Azure Machine Learning Studio. Click the \u201cNew\u201d icon in the bottom left:\n<a href=\"https:\/\/i.stack.imgur.com\/Iwvhi.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Iwvhi.jpg\" alt=\"\"><\/a><\/li>\n<li>In the pane that comes up, click on dataset, and then \u201cFrom Local File\u201d:\n<a href=\"https:\/\/i.stack.imgur.com\/DvyjO.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DvyjO.jpg\" alt=\"\"><\/a><\/li>\n<li>Select the zip file where you stored your serialized model and click the tick. You expirement should look like this:\n<a href=\"https:\/\/i.stack.imgur.com\/0efka.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0efka.jpg\" alt=\"\"><\/a><\/li>\n<li>Put the following code to run your classification experiment:<\/li>\n<\/ol>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport sys\nimport pickle\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    sys.path.insert(0,\".\\Script Bundle\")\n    model = pickle.load(open(\".\\Script Bundle\\model.pkl\", 'rb'))\n    pred = model.predict(dataframe1)\n    return pd.DataFrame([pred[0]])\n<\/code><\/pre>\n\n<p><strong>Update<\/strong> \nIf you want to declare this experiment as an API you need to add web input and output to the Python script module.\n<a href=\"https:\/\/i.stack.imgur.com\/eqV8W.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eqV8W.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":7.0,
        "Question_closed_time":1566202471556,
        "Answer_last_edit_time":1566565696980,
        "Answer_score_count":0.0,
        "Answerer_created_time":1528790837107,
        "Answerer_location":"Paris, France",
        "Answerer_reputation_count":610.0,
        "Answerer_view_count":203.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57488706",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi custom model studio studio option choos number inbuilt model like classif regress drag drop workflow question upload custom model built local python add workflow",
        "Question_preprocessed_content":"deploi custom model studio studio option number inbuilt model like drag drop workflow question upload custom model built python workflow",
        "Question_gpt_summary_original":"The user wants to know if they can upload a custom ML model that they have built locally on their system in Python and add it to the workflow in Azure ML Studio, instead of using the inbuilt ML models.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS AI\/ML integration with Power BI",
        "Question_body":"Customer wants to know if AWS AI\/ML services integrate with Power BI. The customer currently uses Power BI that integrates with Azure ML for sentiment analysis, opinion mining, etc. Customer is looking for a push button solution where the business analyst can do text analytics on the response from the model. Is there a way to do this on AWS or a marketplace solution?",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1607495476000,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668614604512,
        "Question_score_count":0.0,
        "Question_view_count":360.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"PowerBI can connect to Amazon Redshift and leverage the [new SQL based ML capability in Redshift][1] that uses Sagemaker under the hood.  \n\nAs an alternative thought the customer can integrate Amazon Sagemaker Model with Amazon Quicksight to achieve functionality very similar to PowerBI with Azure ML. Quicksight does have some embedded ML capability like forecasting and anomaly detection but Opinion mining is not one of them yet.\n\nYou should be able to leverage [Blazing Text Algorithm][2] in Sagemaker or some market place solution like [Twinword sentiment model][3] in sagemaker for sentiment analysis for Text mining after the integration.\n\n\n\n  [1]: https:\/\/aws.amazon.com\/redshift\/features\/redshift-ml\/\n  [2]: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/blazingtext.html\n  [3]: https:\/\/aws.amazon.com\/marketplace\/pp\/Twinword-Inc-Sentiment-Analysis-Inference-Model\/prodview-wa74yx5z5qsvw",
        "Answer_comment_count":0.0,
        "Question_closed_time":1607528438000,
        "Answer_last_edit_time":1614011625614,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU4VexAnfiSFi4Jf5i9RyO_A\/aws-ai-ml-integration-with-power-bi",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":1.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"aw integr power custom want know aw servic integr power custom current us power integr sentiment analysi opinion mine custom look push button solut busi analyst text analyt respons model wai aw marketplac solut",
        "Question_preprocessed_content":"aw integr power custom want know aw servic integr power custom us power integr sentiment analysi opinion mine custom push solut analyst text analyt respons model wai aw marketplac solut",
        "Question_gpt_summary_original":"The customer is looking for a way to integrate AWS AI\/ML services with Power BI for text analytics. They currently use Power BI with Azure ML for sentiment analysis and opinion mining, and are seeking a push button solution for business analysts to analyze model responses. They are wondering if there is a way to do this on AWS or through a marketplace solution.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Unable to resolve the private dns name of a Sagemaker runtime VPC interface endpoint",
        "Question_body":"I deployed interface endpoints for multiple AWS services into a dedicated subnet in my VPC. Besides a Sagemaker runtime interface endpoint I also created endpoints for CloudWatch logs, KMS and more.\n\nThe resolving of the service domain name (e.g. kms.eu-central-1.amazonaws.com) works for all endpoints, except for the Sagemaker runtime (e.g. runtime.sagemaker.eu-central-1.amazonaws.com).The endpoint specific domain names of the Sagemaker runtime endpoint also work, only the resolving of runtime.sagemaker.eu-central-1.amazonaws.com fails with no answers from the DNS server.\n\nI tried multiple times to recreate the endpoint, but that didn't help either. The resolving of the domain works if I deploy the endpoint into another test VPC.\n\nAny ideas on what could be wrong? Thanks in advance!\nBert",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1657193804686,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668594825292,
        "Question_score_count":0.0,
        "Question_view_count":476.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUL78EiZhMTeq3v_FVsB-kXQ\/unable-to-resolve-the-private-dns-name-of-a-sagemaker-runtime-vpc-interface-endpoint",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl resolv privat dn runtim vpc interfac endpoint deploi interfac endpoint multipl aw servic dedic subnet vpc runtim interfac endpoint creat endpoint cloudwatch log km resolv servic domain km central amazonaw com work endpoint runtim runtim central amazonaw com endpoint specif domain name runtim endpoint work resolv runtim central amazonaw com fail answer dn server tri multipl time recreat endpoint help resolv domain work deploi endpoint test vpc idea wrong thank advanc bert",
        "Question_preprocessed_content":"unabl resolv privat dn runtim vpc interfac endpoint deploi interfac endpoint multipl aw servic dedic subnet vpc runtim interfac endpoint creat endpoint cloudwatch log km resolv servic domain work endpoint runtim endpoint specif domain name runtim endpoint work resolv fail answer dn server tri multipl time recreat endpoint help resolv domain work deploi endpoint test vpc idea wrong thank advanc bert",
        "Question_gpt_summary_original":"The user is unable to resolve the private DNS name of a Sagemaker runtime VPC interface endpoint, while the resolving of the service domain name works for all other endpoints. The user has tried recreating the endpoint multiple times, but the issue persists. The resolving of the domain works in another test VPC.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is there any limitations for the number of runs per user in each experiment in Azure ML?",
        "Question_body":"<p>I and my team members are working on a machine learning project through the Azure ML portal. We have created a specific experiment in our workspace in Azure ML and are submitting our Python script runs from our local or remote machines in this experiment.  <\/p>\n<p>Although I'm collaborating with my colleagues, most of the runs in this specific experiment are submitted by me.  <\/p>\n<p>Recently, I have faced a problem with experiment submissions. The problem is that after some number of experiments created by me, I cannot add any other runs to this experiment, but my colleagues can!!!  <\/p>\n<p>Unfortunately, the Azure ML portal does not show any clear error message for this problem. It continues submitting the run till a timeout exception occurs!  <\/p>\n<p>As a temporary solution, I've just changed the name of the experiment and I could conquer this problem.  <\/p>\n<p>This solution helped me to submit my run on Azure ML but it didn\u2019t satisfy me because. We want to collect all related runs under a specific experiment. On the other hand creating multiple number of experiments for each run is overwhelming!  <\/p>\n<p>What I know is that there are some service limits for the number of runs in a workspace on this page. I am sure that the number of runs in our workspace has not reached to the 10 millions, because I can created new runs under new experiments dashboard. But I don\u2019t know anything about the limitations on the number of runs in a specific experiment or even any limitations for the number of runs per users in a specific experiment. I couldn't find any clear document explaining this fact.  <\/p>\n<p>Is there anyone who can help me for this issue?  <\/p>\n<p>I have also put myquestion in <a href=\"https:\/\/stackoverflow.com\/questions\/72516242\/is-there-any-limitations-for-runs-per-users-in-azure-ml-experiments\">StackoverFlow<\/a>. I would be grateful if you could help me with this issue.  <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1654530231357,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/878540\/is-there-any-limitations-for-the-number-of-runs-pe",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"limit number run user experi team member work machin learn project portal creat specif experi workspac submit python script run local remot machin experi collabor colleagu run specif experi submit recent face problem experi submiss problem number experi creat add run experi colleagu unfortun portal clear error messag problem continu submit run till timeout except occur temporari solut chang experi conquer problem solut help submit run didnt satisfi want collect relat run specif experi hand creat multipl number experi run overwhelm know servic limit number run workspac page sure number run workspac reach million creat new run new experi dashboard dont know limit number run specif experi limit number run user specif experi couldn clear document explain fact help issu myquest stackoverflow grate help issu",
        "Question_preprocessed_content":"limit number run user experi team member work machin learn project portal creat specif experi workspac python script run local remot machin experi run specif experi recent face problem experi problem number experi creat run experi unfortun portal clear problem continu run timeout except temporari solut chang experi conquer problem solut help submit run didnt satisfi want relat run specif experi hand creat multipl number experi run overwhelm know servic limit number run workspac page sure number run workspac reach creat new run new experi dashboard dont know limit number run specif experi limit number run user specif experi couldn clear document explain fact help myquest stackoverflow grate help",
        "Question_gpt_summary_original":"The user is facing a problem with submitting runs to a specific experiment in Azure ML. After submitting a certain number of runs, the user is unable to add any more runs to the experiment, but their colleagues can. The Azure ML portal does not provide a clear error message for this issue. The user has temporarily solved the problem by changing the name of the experiment, but they want to collect all related runs under a specific experiment. The user is unsure if there are any limitations for the number of runs per user in a specific experiment or any limitations for the number of runs in a specific experiment. They have asked for help on StackOverflow.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Change model file save location on AWS SageMaker Training Job",
        "Question_body":"<p>I am trying to run custom python\/sklearn sagemaker script on AWS, basically learning from these examples: <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/scikit_learn_randomforest\/Sklearn_on_SageMaker_end2end.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/scikit_learn_randomforest\/Sklearn_on_SageMaker_end2end.ipynb<\/a><\/p>\n<p>All works fine, if define the arguments, train the model and output the file:<\/p>\n<pre><code>parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\nparser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\nparser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n\n# train the model...\n\njoblib.dump(model, os.path.join(args.model_dir, &quot;model.joblib&quot;))\n<\/code><\/pre>\n<p>And call the job with:<\/p>\n<pre><code>aws_sklearn.fit({'train': 's3:\/\/path\/to\/train', 'test': 's3:\/\/path\/to\/test'}, wait=False)\n<\/code><\/pre>\n<p>In this case model gets stored on different auto-generated bucket, which I do not want. I want to get the output (.joblib file) in the same s3 bucket I took data from. So I add the parameter <code>model-dir<\/code>:<\/p>\n<pre><code>aws_sklearn.fit({'train': 's3:\/\/path\/to\/train', 'test': 's3:\/\/path\/to\/test', `model-dir`: 's3:\/\/path\/to\/model'}, wait=False)\n<\/code><\/pre>\n<p>But it results in error:\n<code>FileNotFoundError: [Errno 2] No such file or directory: 's3:\/\/path\/to\/model\/model.joblib'<\/code><\/p>\n<p>Same happens if I hardcode the output path inside the training script.<\/p>\n<p>So the main question, how can I get the output file in the bucket of my choice?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1610533493827,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":1244.0,
        "Poster_created_time":1572957474856,
        "Poster_location":null,
        "Poster_reputation_count":123.0,
        "Poster_view_count":18.0,
        "Answer_body":"<p>You can use parameter <code>output_path<\/code> when you define the estimator. If you use the\n<code>model_dir<\/code> I guess you have to create that bucket beforehand, but you have the advantage that artifacts can be saved in real time during the training (if the instance has rights on S3). You can take a look at my <a href=\"https:\/\/github.com\/roccopietrini\/TFSagemakerDetection\" rel=\"nofollow noreferrer\">repo<\/a> for this specific case.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1610545645387,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1416346350292,
        "Answerer_location":"Jesi, Italy",
        "Answerer_reputation_count":2302.0,
        "Answerer_view_count":227.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65699980",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"chang model file save locat train job try run custom python sklearn script aw basic learn exampl http github com aw amazon exampl blob master python sdk scikit learn randomforest sklearn endend ipynb work fine defin argument train model output file parser add argument model dir type str default environ model dir parser add argument train type str default environ channel train parser add argument test type str default environ channel test train model joblib dump model path join arg model dir model joblib job aw sklearn fit train path train test path test wait fals case model get store differ auto gener bucket want want output joblib file bucket took data add paramet model dir aw sklearn fit train path train test path test model dir path model wait fals result error filenotfounderror errno file directori path model model joblib happen hardcod output path insid train script main question output file bucket choic",
        "Question_preprocessed_content":"chang model file save locat train job try run custom script aw learn exampl work fine defin argument train model output file job case model get store bucket want want output bucket data paramet result hardcod output path insid train script main question output file bucket choic",
        "Question_gpt_summary_original":"The user is trying to run a custom python\/sklearn sagemaker script on AWS and wants to save the output (.joblib file) in the same S3 bucket from where the data was taken. However, when the user adds the parameter \"model-dir\" to specify the output location, it results in an error \"FileNotFoundError: [Errno 2] No such file or directory\". The user is seeking a solution to save the output file in the bucket of their choice.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Question: distinction between Modules and Models in Designer",
        "Question_body":"<p>In Azure ML, under designer, there are 3 categories:  <\/p>\n<ul>\n<li> Datasets  <\/li>\n<li> Modules  <\/li>\n<li> Models  <\/li>\n<\/ul>\n<p>Datasets are pretty straightforward, but I don't understand the distinction between Modules and Models. As an ML researcher, when I think of a &quot;model&quot;, I think of something like linear regression or SVM. However, those are listed under Modules -&gt; Machine Learning Algorithms. So what exactly qualifies as a Model?  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1594756919963,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi,  <\/p>\n<p>Thanks for reaching out.  <\/p>\n<p>Model is a concept of Machine Learning itself. A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data. Once you have trained the model, you can use it to reason over data that it hasn't seen before, and make predictions about those data. For example, let's say you want to build an application that can recognize a user's emotions based on their facial expressions. You can train a model by providing it with images of faces that are each tagged with a certain emotion, and then you can use that model in an application that can recognize any user's emotion.   <\/p>\n<p>Modules is one of the concept of Azure Machine Learning Designer. Each module represents a set of code that can run independently and perform a machine learning task, given the required inputs. A module might contain a particular algorithm, or perform a task that is important in machine learning, such as missing value replacement, or statistical analysis.  <\/p>\n<p>Let me know if you have any question.  <\/p>\n<p>Regards,  <br \/>\nYutong<\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1594759184476,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/46991\/question-distinction-between-modules-and-models-in",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"question distinct modul model design design categori dataset modul model dataset pretti straightforward understand distinct modul model research think model think like linear regress svm list modul machin learn algorithm exactli qualifi model",
        "Question_preprocessed_content":"question distinct modul model design design categori dataset modul model dataset straightforward understand distinct modul model research think model think like linear svm list modul machin learn algorithm exactli qualifi model",
        "Question_gpt_summary_original":"The user is confused about the difference between Modules and Models in Azure ML's designer. They understand that Datasets are straightforward, but they are unsure about what qualifies as a Model since Machine Learning Algorithms are listed under Modules.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Saving data with DataCatalog",
        "Question_body":"<p>I was looking at <code>iris<\/code> project example provided by kedro. Apart from logging the accuracy I also wanted to save the <code>predictions<\/code> and <code>test_y<\/code> as a csv.<\/p>\n<p>This is the example node provided by kedro.<\/p>\n<pre><code>def report_accuracy(predictions: np.ndarray, test_y: pd.DataFrame) -&gt; None:\n    &quot;&quot;&quot;Node for reporting the accuracy of the predictions performed by the\n    previous node. Notice that this function has no outputs, except logging.\n    &quot;&quot;&quot;\n    # Get true class index\n    target = np.argmax(test_y.to_numpy(), axis=1)\n    # Calculate accuracy of predictions\n    accuracy = np.sum(predictions == target) \/ target.shape[0]\n    # Log the accuracy of the model\n    log = logging.getLogger(__name__)\n    log.info(&quot;Model accuracy on test set: %0.2f%%&quot;, accuracy * 100)\n<\/code><\/pre>\n<p>I added the following to save the data.<\/p>\n<pre><code>data = pd.DataFrame({&quot;target&quot;: target , &quot;prediction&quot;: predictions})\ndata_set = CSVDataSet(filepath=&quot;data\/test.csv&quot;)\ndata_set.save(data)\n<\/code><\/pre>\n<p>This works as intended, however, my question is &quot;is it the kedro way of doing thing&quot; ? Can I provide the <code>data_set <\/code> in <code>catalog.yml<\/code> and later save <code>data<\/code> to it? If I want to do it, how do I access the <code>data_set<\/code> from <code>catalog.yml<\/code> inside a node.<\/p>\n<p>Is there a way to save data without creating a catalog inside a node like this <code>data_set = CSVDataSet(filepath=&quot;data\/test.csv&quot;)<\/code> ? I want this in <code>catalog.yml<\/code>, if possible and if it follows kedro convention!.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1629897723887,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1629897818943,
        "Question_score_count":0.0,
        "Question_view_count":333.0,
        "Poster_created_time":1519724643532,
        "Poster_location":null,
        "Poster_reputation_count":453.0,
        "Poster_view_count":79.0,
        "Answer_body":"<p>Kedro actually abstracts this part for you. You don't need to access the datasets via their Python API.<\/p>\n<p>Your <code>report_accuracy<\/code> method does need to be tweaked to return the <code>DataFrame<\/code> instead of <code>None<\/code>.<\/p>\n<p>Your node needs to be defined as such:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>node(\n  func=report_accuracy,\n  inputs='dataset_a',\n  outputs='dataset_b'\n)\n<\/code><\/pre>\n<p>Kedro then looks at your catalog and will load\/save <code>dataset_a<\/code> and <code>dataset_b<\/code> as required:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>dataset_a:\n   type: pandas.CSVDataSet\n   path: xxxx.csv\n\ndataset_b:\n   type: pandas.ParquetDataSet\n   path: yyyy.pq\n<\/code><\/pre>\n<p>As you run the node\/pipeline Kedro will handle the load\/save operations for you. You also don't need to save every dataset if it's only used mid-way in a pipeline, you can read about <code>MemoryDataSet<\/code>s <a href=\"https:\/\/kedro.readthedocs.io\/en\/stable\/11_tools_integration\/01_pyspark.html#use-memorydataset-for-intermediary-dataframe\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1629898742263,
        "Answer_last_edit_time":1643038306147,
        "Answer_score_count":7.0,
        "Answerer_created_time":1359113510580,
        "Answerer_location":null,
        "Answerer_reputation_count":1076.0,
        "Answerer_view_count":81.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68923747",
        "Tool":"Kedro",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"save data datacatalog look iri project exampl provid apart log accuraci want save predict test csv exampl node provid def report accuraci predict ndarrai test datafram node report accuraci predict perform previou node notic function output log true class index target argmax test numpi axi calcul accuraci predict accuraci sum predict target target shape log accuraci model log log getlogg log info model accuraci test set accuraci ad follow save data data datafram target target predict predict data set csvdataset filepath data test csv data set save data work intend question wai thing provid data set catalog yml later save data want access data set catalog yml insid node wai save data creat catalog insid node like data set csvdataset filepath data test csv want catalog yml possibl follow convent",
        "Question_preprocessed_content":"save data datacatalog project exampl provid apart want save csv exampl node provid save data work intend question wai thing provid later save want insid node wai save data creat catalog insid node like want convent",
        "Question_gpt_summary_original":"The user is trying to save predictions and test data as a CSV file in a Kedro project. They have added code to save the data, but they are unsure if it follows the Kedro convention. They want to know if they can provide the data set in catalog.yml and access it from a node. They also want to know if there is a way to save data without creating a catalog inside a node.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Schedule the deployment of a sagemaker model",
        "Question_body":"<p>I'm trying out SageMaker and I've created a model using autopilot. The point is that SageMaker only allows you to deploy directly to an endpoint. But since I'll only be using the model a couple of times a day, what is the most direct way to  schedule deployments by events (for example when loading new csv's into an s3 directory or when I see a queue in sqs) or at least periodically?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1583361587500,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1583362462607,
        "Question_score_count":0.0,
        "Question_view_count":225.0,
        "Poster_created_time":1544205695740,
        "Poster_location":"Santiago, Chile",
        "Poster_reputation_count":410.0,
        "Poster_view_count":46.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60535760",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"schedul deploy model try creat model autopilot point allow deploi directli endpoint model coupl time dai direct wai schedul deploy event exampl load new csv directori queue sq period",
        "Question_preprocessed_content":"schedul deploy model try creat model autopilot point deploi directli endpoint model coupl time dai direct wai schedul deploy event",
        "Question_gpt_summary_original":"The user has created a model using autopilot in SageMaker but is facing challenges in scheduling deployments by events or periodically as SageMaker only allows direct deployment to an endpoint. The user wants to know the most direct way to schedule deployments.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"MLflow run example gives me CommandNotFoundError",
        "Question_body":"<p>I was trying to run the mlflow run exercise in the anaconda prompt, and it keeps giving me the error.\nI'm using mlflow version 1.40, and the code above works fine if I execute it with --no-conda <\/p>\n\n<p><code>mlflow run https:\/\/github.com\/mlflow\/mlflow-example -P alpha=0.5<\/code> - doesn't work<\/p>\n\n<p><code>mlflow run https:\/\/github.com\/mlflow\/mlflow-example -P alpha=0.5 --no-conda<\/code> - works<\/p>\n\n<p>It gives me the error when activating the conda environment. The specific conda environment works fine if I manually activate it. It just doesn't work within the mlflow command. <\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/ehUXl.png\" alt=\"capture of prompt\"><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LjSoJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LjSoJ.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1573801005183,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1574210709447,
        "Question_score_count":1.0,
        "Question_view_count":251.0,
        "Poster_created_time":1546094080583,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58871771",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run exampl give commandnotfounderror try run run exercis anaconda prompt keep give error version code work fine execut conda run http github com exampl alpha work run http github com exampl alpha conda work give error activ conda environ specif conda environ work fine manual activ work command",
        "Question_preprocessed_content":"run exampl give try run run exercis anaconda prompt give version code work fine execut work work give activ conda environ specif conda environ work fine activ work",
        "Question_gpt_summary_original":"The user is encountering a CommandNotFoundError while trying to run the mlflow run exercise in the anaconda prompt using mlflow version 1.40. The error occurs when activating the conda environment, and the code works fine if executed with --no-conda. The specific conda environment works fine if manually activated, but it doesn't work within the mlflow command.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"DVC with git worktree",
        "Question_body":"<p>Hi all,<\/p>\n<p>I\u2019ve recently started using git worktree to practice parallel development. It comes very handy when I want to work on two branches in the same repo at the same time.<\/p>\n<p>However, I\u2019m came across issue with adding data to DVC on a tree other than the original dir.<\/p>\n<p>I wonder if anyone has experience on this?<\/p>\n<p>Many thanks,<br>\nMaggie<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1602863664967,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":416.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-with-git-worktree\/532",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"git worktre iv recent start git worktre practic parallel develop come handi want work branch repo time came issu ad data tree origin dir wonder experi thank maggi",
        "Question_preprocessed_content":"git iv recent start git practic develop come handi want work branch repo time came data origin dir wonder experi thank",
        "Question_gpt_summary_original":"The user is experiencing an issue with adding data to DVC on a tree other than the original directory while using git worktree for parallel development. They are seeking advice from others who may have experience with this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Vertex AI create pipeline file content error",
        "Question_body":"Have been trying to build a pipeline using several generic examples. Python created the following yaml file, but when I upload it into vertex ai pipeline page, I always get the following error \"Invalid File Content\".\n\n\u00a0\n\n\u00a0\n\napiVersion: argoproj.io\/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: tfrecord-processing-pipeline-\n  annotations: {pipelines.kubeflow.org\/kfp_sdk_version: 1.8.22, pipelines.kubeflow.org\/pipeline_compilation_time: '2023-05-23T21:47:19.096627',\n    pipelines.kubeflow.org\/pipeline_spec: '{\"inputs\": [{\"default\": \"gs:\/\/aa.bb.cc.dd\/data\",\n      \"name\": \"tfrecord_dir\", \"optional\": true, \"type\": \"String\"}], \"name\": \"TFRecord\n      Processing Pipeline\"}'}\n  labels: {pipelines.kubeflow.org\/kfp_sdk_version: 1.8.22}\nspec:\n  entrypoint: tfrecord-processing-pipeline\n  templates:\n  - name: load-tfrecord-dataset\n    container:\n      args:\n      - \"\\n            import tensorflow as tf\\n            file_pattern = \\\"{{inputs.parameters.tfrecord_dir}}\\\"\\\n        \\ + '\/*.block'\\n            files = tf.io.gfile.glob(file_pattern)\\n     \\\n        \\       for file in files:\\n                dataset = tf.data.TFRecordDataset(file)\\n\\\n        \\            \"\n      command: [python, -c]\n      image: tensorflow\/tensorflow:2.6.0\n    inputs:\n      parameters:\n      - {name: tfrecord_dir}\n    metadata:\n      labels:\n        pipelines.kubeflow.org\/kfp_sdk_version: 1.8.22\n        pipelines.kubeflow.org\/pipeline-sdk-type: kfp\n        pipelines.kubeflow.org\/enable_caching: \"true\"\n  - name: tfrecord-processing-pipeline\n    inputs:\n      parameters:\n      - {name: tfrecord_dir}\n    dag:\n      tasks:\n      - name: load-tfrecord-dataset\n        template: load-tfrecord-dataset\n        arguments:\n          parameters:\n          - {name: tfrecord_dir, value: '{{inputs.parameters.tfrecord_dir}}'}\n  arguments:\n    parameters:\n    - {name: tfrecord_dir, value: 'gs:\/\/aa.bb.cc.dd\/data'}\n  serviceAccountName: pipeline-runner\n\n\u00a0\n\n\u00a0Any thoughts?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1684882080000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":54.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-create-pipeline-file-content-error\/m-p\/596343#M2009",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat pipelin file content error try build pipelin gener exampl python creat follow yaml file upload pipelin page follow error invalid file content apivers argoproj valpha kind workflow metadata generatenam tfrecord process pipelin annot pipelin kubeflow org kfp sdk version pipelin kubeflow org pipelin compil time pipelin kubeflow org pipelin spec input default data tfrecord dir option true type string tfrecord process pipelin label pipelin kubeflow org kfp sdk version spec entrypoint tfrecord process pipelin templat load tfrecord dataset contain arg import tensorflow file pattern input paramet tfrecord dir block file gfile glob file pattern file file dataset data tfrecorddataset file command python imag tensorflow tensorflow input paramet tfrecord dir metadata label pipelin kubeflow org kfp sdk version pipelin kubeflow org pipelin sdk type kfp pipelin kubeflow org enabl cach true tfrecord process pipelin input paramet tfrecord dir dag task load tfrecord dataset templat load tfrecord dataset argument paramet tfrecord dir valu input paramet tfrecord dir argument paramet tfrecord dir valu data serviceaccountnam pipelin runner thought",
        "Question_preprocessed_content":"creat pipelin file content try build pipelin gener exampl python creat yaml file upload pipelin page invalid file content apivers kind workflow metadata generatenam tfrecord pipelin label spec entrypoint templat contain arg import tensorflow file file dataset imag input paramet metadata label kfp true input paramet dag task templat argument paramet argument paramet thought",
        "Question_gpt_summary_original":"The user is facing an issue while uploading a YAML file created by Python for building a pipeline into Vertex AI pipeline page. The error message \"Invalid File Content\" is displayed every time the user tries to upload the file.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Delete my account",
        "Question_body":"<p>Can you delete my account please? Username is cengizk<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1647678914265,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":143.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/delete-my-account\/2116",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"delet account delet account usernam cengizk",
        "Question_preprocessed_content":"delet delet usernam cengizk",
        "Question_gpt_summary_original":"The user is requesting to delete their account with the username cengizk.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"MLFlow Projects throw JSONDecode error when run",
        "Question_body":"<p>I'm trying to get MLFlow Projects to run using the MLFlow CLI and its following the tutorial leads to an error.  For any project I try to run from the CLI, I get the following error<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"\/home\/rbc\/.local\/bin\/mlflow\", line 11, in &lt;module&gt;\n    sys.exit(cli())\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/cli.py\", line 139, in run\n    run_id=run_id,\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 230, in run\n    storage_dir=storage_dir, block=block, run_id=run_id)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 88, in _run\n    active_run = _create_run(uri, experiment_id, work_dir, entry_point)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 579, in _create_run\n    active_run = tracking.MlflowClient().create_run(experiment_id=experiment_id, tags=tags)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 101, in create_run\n    source_version=source_version\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 156, in create_run\n    response_proto = self._call_endpoint(CreateRun, req_body)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 66, in _call_endpoint\n    js_dict = json.loads(response.text)\n  File \"\/usr\/lib\/python3.6\/json\/__init__.py\", line 354, in loads\n    return _default_decoder.decode(s)\n  File \"\/usr\/lib\/python3.6\/json\/decoder.py\", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"\/usr\/lib\/python3.6\/json\/decoder.py\", line 357, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n<\/code><\/pre>\n\n<p>Here's an example of the type of command I'm using to start the run, which comes directly from the tutorial <\/p>\n\n<pre><code>mlflow run https:\/\/github.com\/mlflow\/mlflow#examples\/sklearn_elasticnet_wine -m databricks -c cluster-spec.json --experiment-id 72647065958042 -P alpha=2.0 -P l1_ratio=0.5\n<\/code><\/pre>\n\n<p>I've traced the error to something involving MLFLow returning empty when it tries to start a run but I can successfully run MLFlow experiments using the Databricks environment I'm connecting to so I'm not sure where the problem is, I'm running MLFlow 0.9.1 on Ubuntu 18.04<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1557754667253,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":386.0,
        "Poster_created_time":1509471438900,
        "Poster_location":"Orlando, FL, United States",
        "Poster_reputation_count":31.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56113569",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"project throw jsondecod error run try project run cli follow tutori lead error project try run cli follow error traceback recent file home rbc local bin line sy exit cli file home rbc local lib python site packag click core line return self main arg kwarg file home rbc local lib python site packag click core line main self invok ctx file home rbc local lib python site packag click core line invok return process result sub ctx command invok sub ctx file home rbc local lib python site packag click core line invok return ctx invok self callback ctx param file home rbc local lib python site packag click core line invok return callback arg kwarg file home rbc local lib python site packag cli line run run run file home rbc local lib python site packag project init line run storag dir storag dir block block run run file home rbc local lib python site packag project init line run activ run creat run uri experi work dir entri point file home rbc local lib python site packag project init line creat run activ run track client creat run experi experi tag tag file home rbc local lib python site packag track client line creat run sourc version sourc version file home rbc local lib python site packag store rest store line creat run respons proto self endpoint createrun req bodi file home rbc local lib python site packag store rest store line endpoint dict json load respons text file usr lib python json init line load return default decod decod file usr lib python json decod line decod obj end self raw decod idx end file usr lib python json decod line raw decod rais jsondecodeerror expect valu err valu json decod jsondecodeerror expect valu line column char exampl type command start run come directli tutori run http github com exampl sklearn elasticnet wine databrick cluster spec json experi alpha ratio trace error involv return tri start run successfulli run experi databrick environ connect sure problem run ubuntu",
        "Question_preprocessed_content":"project throw jsondecod run try project run cli tutori lead project try run cli exampl type start run come directli tutori trace involv return tri start run run experi databrick environ sure problem ubuntu",
        "Question_gpt_summary_original":"The user is encountering a JSONDecode error when trying to run MLFlow Projects using the MLFlow CLI. The error occurs when MLFlow returns empty while trying to start a run. The user has traced the error to MLFlow and is unsure of the problem. The user is running MLFlow 0.9.1 on Ubuntu 18.04 and can successfully run MLFlow experiments using the Databricks environment.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Wandb error by usage of mlflow",
        "Question_body":"<p>I 'm getting the exact same error with this <a href=\"https:\/\/community.wandb.ai\/t\/wandb-error-by-usage-of-mlflow-and-hydra-regarding-protobuf-lib\/3866\/1\">one<\/a> .  I tried to  create a new venv either with conda, venv but, downgrade protobuf but it persists.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1684092272896,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":56.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-error-by-usage-of-mlflow\/4401",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error usag get exact error tri creat new venv conda venv downgrad protobuf persist",
        "Question_preprocessed_content":"usag exact tri creat new venv conda venv downgrad protobuf persist",
        "Question_gpt_summary_original":"The user is encountering an error while using Wandb and mlflow, which has been previously reported by another user. The user has attempted to create a new virtual environment and downgrade protobuf, but the error persists.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to feed seed code to GitHub Repository from Sagemaker Projects Organization Template created with Service Catalog?",
        "Question_body":"The objective is to replicate \"MLOps template for model building, training, and deployment with third-party Git repositories using Jenkins\" builtin Sagemaker Project template. I want to feed custom seed code to the Github repository each time a project is created using my organization custom template instead of the default seed code that the builtin template feeds.\n\nI am able to create the custom template using service catalog but I could not find a solution for feeding the seed code to github repo. So, I decided to see how the built in project template is doing this and it is using resources from this bucket \"s3:\/\/sagemaker-servicecatalog-seedcode-us-east-1\/bootstrap\/GitRepositorySeedCodeCheckinCodeBuildProject-v1.0.zip\" but I could not access it. I am not sure how to achieve the objective?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1657259337697,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1668617915380,
        "Question_score_count":0.0,
        "Question_view_count":416.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"You can download the seed package using awscli s3 cp <s3_uri> <target_path> or by using this URL: https:\/\/sagemaker-servicecatalog-seedcode-us-east-1.s3.amazonaws.com\/bootstrap\/GitRepositorySeedCodeCheckinCodeBuildProject-v1.0.zip\n\nThis .zip is used by CodeBuild that is called when the template is deployed (by a lambda mapped to a CFN custom component). If you take a look in the template you'll find a component named \"SageMakerModelBuildSeedCodeCheckinProjectTriggerLambdaInvoker\". You can find some env vars defined for this component like: SEEDCODE_BUCKET_NAME and SEEDCODE_BUCKET_KEY. These vars point to an S3 uri that has another .zip file with the content of the seed for the git repo. If you get the default values defined there you can re-create the URL and download the .zip file as well:\nhttps:\/\/sagemaker-servicecatalog-seedcode-us-east-1.s3.amazonaws.com\/toolchain\/model-building-workflow-jenkins-v1.0.zip\n\nSo, in the end, if you want to change the content that is pushed to the git repo, you can redefine these 2 vars and point to an S3 path that contains a .zip file you created.\n\nBonus: If you're a curious person, I recommend you to take a look at the .java file (src\/main\/java\/GitRepositorySeedCodeBootStrapper.java) inside the .zip of the CodeBuild .zip for you to understand what it does to prepare the git repo like: download a .zip, unpack it, commit\/push to the git repo.",
        "Answer_comment_count":1.0,
        "Question_closed_time":1657560195771,
        "Answer_last_edit_time":1657560195771,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU_Y4T-A3aQySFeRr3feBscA\/how-to-feed-seed-code-to-github-repository-from-sagemaker-projects-organization-template-created-with-service-catalog",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":1.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"feed seed code github repositori project organ templat creat servic catalog object replic mlop templat model build train deploy parti git repositori jenkin builtin project templat want feed custom seed code github repositori time project creat organ custom templat instead default seed code builtin templat feed abl creat custom templat servic catalog solut feed seed code github repo decid built project templat resourc bucket servicecatalog seedcod east bootstrap gitrepositoryseedcodecheckincodebuildproject zip access sure achiev object",
        "Question_preprocessed_content":"code github repositori project organ templat creat servic catalog object replic mlop templat model build train deploy git repositori jenkin builtin project templat want custom code github repositori time project creat organ custom templat instead default code builtin templat abl creat custom templat servic catalog solut code github repo decid built project templat resourc bucket sure achiev object",
        "Question_gpt_summary_original":"The user wants to feed custom seed code to a GitHub repository each time a project is created using their organization's custom template in Sagemaker Projects. They have created the custom template using service catalog but are unable to find a solution for feeding the seed code to the GitHub repo. They have tried to replicate the built-in project template but are unable to access the resources from the bucket used by the template. The user is seeking guidance on how to achieve their objective.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Training data in S3 in AWS Sagemaker",
        "Question_body":"<p>I've uploaded my own Jupyter notebook to Sagemaker, and am trying to create an iterator for my training \/ validation data which is in S3, as follow:<\/p>\n\n<pre><code>train = mx.io.ImageRecordIter(\n        path_imgrec         = \u2018s3:\/\/bucket-name\/train.rec\u2019 \u2026\u2026 )\n<\/code><\/pre>\n\n<p>I receive the following exception: <\/p>\n\n<pre><code>MXNetError: [04:33:32] src\/io\/s3_filesys.cc:899: Need to set enviroment variable AWS_SECRET_ACCESS_KEY to use S3\n<\/code><\/pre>\n\n<p>I've checked that the IAM role attached with this notebook instance has S3 access. Any clues on what might be needed to fix this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1522300028073,
        "Question_favorite_count":3.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":1353.0,
        "Poster_created_time":1449031669083,
        "Poster_location":null,
        "Poster_reputation_count":777.0,
        "Poster_view_count":103.0,
        "Answer_body":"<p>If your IAM roles are setup correctly, then you need to download the file to the Sagemaker instance first and then work on it. Here's how:<\/p>\n\n<pre><code># Import roles\nimport sagemaker\nrole = sagemaker.get_execution_role()\n\n# Download file locally\ns3 = boto3.resource('s3')\ns3.Bucket(bucket).download_file('your_training_s3_file.rec', 'training.rec')\n\n#Access locally\ntrain = mx.io.ImageRecordIter(path_imgrec=\u2018training.rec\u2019 \u2026\u2026 )\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1522305475727,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1411212343683,
        "Answerer_location":"Vancouver, BC, Canada",
        "Answerer_reputation_count":3592.0,
        "Answerer_view_count":268.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49548422",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"train data upload jupyt notebook try creat iter train valid data follow train imagerecordit path imgrec bucket train rec receiv follow except mxneterror src filesi need set enviro variabl aw secret access kei us check iam role attach notebook instanc access clue need fix",
        "Question_preprocessed_content":"train data upload jupyt try creat iter train valid data receiv except check iam role instanc clue fix",
        "Question_gpt_summary_original":"The user is trying to create an iterator for their training\/validation data in S3 using AWS Sagemaker, but is encountering an exception that requires setting the AWS_SECRET_ACCESS_KEY environment variable to use S3. The user has checked that the IAM role attached to the notebook instance has S3 access and is seeking help to fix the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"not authorized to perform: sagemaker:CreateModel on resource",
        "Question_body":"I have been given AmazonSagemakerFullAccess by my companie's AWS admin. No one at our company can figure out why I can't get this line to run to launch the model.\n\n***** CODE PRODUCING ERROR *****\n\nlang_id = sagemaker.Model(\n    image_uri=container, model_data=model_location, role=role, sagemaker_session=sess\n)\nlang_id.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")\n\n\n\n***** ERROR MESSAGE *****\n---------------------------------------------------------------------------\nClientError                               Traceback (most recent call last)\n<ipython-input-5-4c80ec284a4b> in <module>\n      2     image_uri=container, model_data=model_location, role=role, sagemaker_session=sess\n      3 )\n----> 4 lang_id.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")\n      5 \n      6 from sagemaker.deserializers import JSONDeserializer\n\n~\/anaconda3\/envs\/tensorflow2_p36\/lib\/python3.6\/site-packages\/sagemaker\/model.py in deploy(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, **kwargs)\n   1132 \n   1133         self._create_sagemaker_model(\n-> 1134             instance_type, accelerator_type, tags, serverless_inference_config\n   1135         )\n   1136 \n\n~\/anaconda3\/envs\/tensorflow2_p36\/lib\/python3.6\/site-packages\/sagemaker\/model.py in _create_sagemaker_model(self, instance_type, accelerator_type, tags, serverless_inference_config)\n    671             tags=tags,\n    672         )\n--> 673         self.sagemaker_session.create_model(**create_model_args)\n    674 \n    675     def _ensure_base_name_if_needed(self, image_uri, script_uri, model_uri):\n\n~\/anaconda3\/envs\/tensorflow2_p36\/lib\/python3.6\/site-packages\/sagemaker\/session.py in create_model(self, name, role, container_defs, vpc_config, enable_network_isolation, primary_container, tags)\n   2715                     raise\n   2716 \n-> 2717         self._intercept_create_request(create_model_request, submit, self.create_model.__name__)\n   2718         return name\n   2719 \n\n~\/anaconda3\/envs\/tensorflow2_p36\/lib\/python3.6\/site-packages\/sagemaker\/session.py in _intercept_create_request(self, request, create, func_name)\n   4294             func_name (str): the name of the function needed intercepting\n   4295         \"\"\"\n-> 4296         return create(request)\n   4297 \n   4298 \n\n~\/anaconda3\/envs\/tensorflow2_p36\/lib\/python3.6\/site-packages\/sagemaker\/session.py in submit(request)\n   2703             LOGGER.debug(\"CreateModel request: %s\", json.dumps(request, indent=4))\n   2704             try:\n-> 2705                 self.sagemaker_client.create_model(**request)\n   2706             except ClientError as e:\n   2707                 error_code = e.response[\"Error\"][\"Code\"]\n\n~\/anaconda3\/envs\/tensorflow2_p36\/lib\/python3.6\/site-packages\/botocore\/client.py in _api_call(self, *args, **kwargs)\n    506                 )\n    507             # The \"self\" in this scope is referring to the BaseClient.\n--> 508             return self._make_api_call(operation_name, kwargs)\n    509 \n    510         _api_call.__name__ = str(py_operation_name)\n\n~\/anaconda3\/envs\/tensorflow2_p36\/lib\/python3.6\/site-packages\/botocore\/client.py in _make_api_call(self, operation_name, api_params)\n    909             error_code = parsed_response.get(\"Error\", {}).get(\"Code\")\n    910             error_class = self.exceptions.from_code(error_code)\n--> 911             raise error_class(parsed_response, operation_name)\n    912         else:\n    913             return parsed_response\n\nClientError: An error occurred (AccessDeniedException) when calling the CreateModel operation: User: arn:aws:sts::XXXXXXXXXX:assumed-role\/sagemakeraccesstoservices\/SageMaker is not authorized to perform: sagemaker:CreateModel on resource: arn:aws:sagemaker:us-east-2:XXXXXXXXXX:model\/blazingtext-2022-08-09-13-58-21-739 because no identity-based policy allows the sagemaker:CreateModel action",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1660056986989,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1667925651923,
        "Question_score_count":0.0,
        "Question_view_count":432.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU1sGemgvLQQS-w46eoBoo6w\/not-authorized-to-perform-sagemaker-createmodel-on-resource",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"author perform createmodel resourc given amazonfullaccess compani aw admin compani figur line run launch model code produc error lang model imag uri contain model data model locat role role session sess lang deploi initi instanc count instanc type medium error messag clienterror traceback recent imag uri contain model data model locat role role session sess lang deploi initi instanc count instanc type medium deseri import jsondeseri anaconda env tensorflow lib python site packag model deploi self initi instanc count instanc type serial deseri acceler type endpoint tag km kei wait data captur config async infer config serverless infer config kwarg self creat model instanc type acceler type tag serverless infer config anaconda env tensorflow lib python site packag model creat model self instanc type acceler type tag serverless infer config tag tag self session creat model creat model arg def ensur base need self imag uri script uri model uri anaconda env tensorflow lib python site packag session creat model self role contain def vpc config enabl network isol primari contain tag rais self intercept creat request creat model request submit self creat model return anaconda env tensorflow lib python site packag session intercept creat request self request creat func func str function need intercept return creat request anaconda env tensorflow lib python site packag session submit request logger debug createmodel request json dump request indent try self client creat model request clienterror error code respons error code anaconda env tensorflow lib python site packag botocor client api self arg kwarg self scope refer basecli return self api oper kwarg api str oper anaconda env tensorflow lib python site packag botocor client api self oper api param error code pars respons error code error class self except code error code rais error class pars respons oper return pars respons clienterror error occur accessdeniedexcept call createmodel oper user arn aw st xxxxxxxxxx assum role accesstoservic author perform createmodel resourc arn aw east xxxxxxxxxx model blazingtext ident base polici allow createmodel action",
        "Question_preprocessed_content":"author perform createmodel resourc given compani aw admin compani figur line run launch model code produc model traceback role role deseri import jsondeseri deploi tag tag tag tag def role tag rais submit return request creat function intercept return creat submit debug try arg kwarg self scope basecli return kwarg rais return createmodel oper user author perform createmodel resourc polici createmodel action",
        "Question_gpt_summary_original":"The user has been given AmazonSagemakerFullAccess by their company's AWS admin, but they are encountering an AccessDeniedException when trying to run a code to launch the model. The error message indicates that the user is not authorized to perform sagemaker:CreateModel on the resource.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is it Possible to train data in s3 bucket without downloading to local machine with DVC?",
        "Question_body":"<p>Is it Possible to train data in s3 bucket without downloading to local machine with DVC?<br>\nIf we have TBS of data, is it possible to train without taking to local machine?<\/p>",
        "Question_answer_count":11,
        "Question_comment_count":null,
        "Question_created_time":1671676533145,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":194.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/is-it-possible-to-train-data-in-s3-bucket-without-downloading-to-local-machine-with-dvc\/1429",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl train data bucket download local machin possibl train data bucket download local machin tb data possibl train take local machin",
        "Question_preprocessed_content":"train data bucket download local machin train data bucket download local machin tb data train take local machin",
        "Question_gpt_summary_original":"The user is asking if it is possible to train data in an s3 bucket without downloading it to their local machine using DVC, especially if they have a large amount of data.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Load .asc file into azure machine learning",
        "Question_body":"<p>For my Azure Machine Learning experiment I want to load a .asc file into an Execute R script in my experiment. It is in fact a tab delimited file with some comments on the first couple of rows. Can anyone tell me how to do this?<\/p>\n\n<p>A csv goes well, but with this file I get an error.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_created_time":1457552318890,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1457561625260,
        "Question_score_count":0.0,
        "Question_view_count":69.0,
        "Poster_created_time":1387445364536,
        "Poster_location":"Netherlands",
        "Poster_reputation_count":81.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35901044",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"load asc file experi want load asc file execut script experi fact tab delimit file comment coupl row tell csv goe file error",
        "Question_preprocessed_content":"load asc file experi want load asc file execut script experi fact tab delimit file coupl row csv goe file",
        "Question_gpt_summary_original":"The user is facing challenges in loading a .asc file into an Execute R script in their Azure Machine Learning experiment. The file is tab-delimited with comments on the first few rows, and the user is seeking guidance on how to accomplish this task. They have tried using a csv file but encountered an error.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Framing API for Azure Workspace Experiments Runs",
        "Question_body":"<p>Hi there,    <\/p>\n<p><a href=\"https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest\">https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest<\/a>    <\/p>\n<p>As explained in the doc here, could you help me to frame the API URL to fetch all the runs of an experiment of a workspace.     <\/p>\n<p>Thanks,    <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_created_time":1612790580067,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/263728\/framing-api-for-azure-workspace-experiments-runs",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"frame api azur workspac experi run http learn microsoft com azur machin learn manag rest explain doc help frame api url fetch run experi workspac thank",
        "Question_preprocessed_content":"frame api azur workspac experi run explain doc help frame api url fetch run experi workspac thank",
        "Question_gpt_summary_original":"The user is seeking assistance in framing an API URL to fetch all the runs of an experiment of a workspace in Azure.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"LightFM on AWS sagemaker | Is it possible to train model",
        "Question_body":"<p>I am using LightFM for recommender system \n<a href=\"https:\/\/github.com\/lyst\/lightfm\" rel=\"nofollow noreferrer\">https:\/\/github.com\/lyst\/lightfm<\/a><\/p>\n\n<p>Now I want to move my model to AWS Sagemaker where this is not part of build in algorithm, now I want to train my model using this algorithm and also want to leverage Sagemaker capability for huge data, I am following this link to run my custom model \n<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms.html<\/a><\/p>\n\n<p>Now, it seems I need to install docker image of this algorithm and too much other things too, is it any simple way to train my model without pre-build algorithm.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1540899526740,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":418.0,
        "Poster_created_time":1501403168107,
        "Poster_location":"Delhi, India",
        "Poster_reputation_count":1370.0,
        "Poster_view_count":125.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53063492",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"lightfm possibl train model lightfm recommend http github com lyst lightfm want model build algorithm want train model algorithm want leverag capabl huge data follow link run custom model http doc aw amazon com latest algorithm html need instal docker imag algorithm thing simpl wai train model pre build algorithm",
        "Question_preprocessed_content":"lightfm train model lightfm want model build algorithm want train model algorithm want leverag capabl huge data link run custom model docker imag algorithm thing simpl wai train model algorithm",
        "Question_gpt_summary_original":"The user is trying to use LightFM for a recommender system and wants to move the model to AWS Sagemaker. However, LightFM is not a built-in algorithm in Sagemaker, so the user is trying to train the model using a custom algorithm. The user is facing challenges in installing the required docker image and other dependencies and is looking for a simpler way to train the model without a pre-built algorithm.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"ML.NET Detect anomalies with gaps\/missings in data",
        "Question_body":"<p>I have done some tests with <a href=\"https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/microsoft.ml.timeseriescatalog.detectiidspike?view=ml-dotnet\" rel=\"nofollow noreferrer\">DetectSpike<\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/microsoft.ml.timeseriescatalog.detectanomalybysrcnn?view=ml-dotnet\" rel=\"nofollow noreferrer\">DetectAnomaly<\/a> but despite differences and whole pipeline building - both methods require input of 1-dimensional float[]<\/p>\n<p>Its fine to find anomalies and spikes but I was asked to find anomalies &quot;normal&quot;, and anomalies with gaps. (this can be one scenario no need to separate this by kind)<\/p>\n<p>Example 1: WebService receives about 30-100 requests\/min, then theres break\/gap and no requests for few minutes.<\/p>\n<p>Example 2: I am receiving one bill invoice with random value each month, and theres two months without invoices.\n<a href=\"https:\/\/i.stack.imgur.com\/8DJ8n.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8DJ8n.png\" alt=\"enter image description here\" \/><\/a>\nI guess, that I am not able to do this without Date\/Time dimension\/column.\nAny ideas?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1658833883307,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":38.0,
        "Poster_created_time":1353149902688,
        "Poster_location":"Cracow, Poland",
        "Poster_reputation_count":887.0,
        "Poster_view_count":111.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73122328",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"net detect anomali gap miss data test detectspik detectanomali despit differ pipelin build method requir input dimension float fine anomali spike ask anomali normal anomali gap scenario need separ kind exampl webservic receiv request min there break gap request minut exampl receiv invoic random valu month there month invoic guess abl date time dimens column idea",
        "Question_preprocessed_content":"detect anomali data test detectspik detectanomali despit pipelin build method requir input float fine anomali spike ask anomali normal anomali gap exampl webservic receiv there request minut exampl receiv invoic random valu month there month invoic abl idea",
        "Question_gpt_summary_original":"The user has tested DetectSpike and DetectAnomaly to find anomalies and spikes in data, but both methods require input of 1-dimensional float[]. The user needs to find anomalies with gaps\/missings in data, such as a scenario where there are no requests for a few minutes after receiving 30-100 requests\/min or when there are two months without invoices. The user believes that a Date\/Time dimension\/column is necessary to accomplish this task and is seeking ideas.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Which techniques are used by SageMaker Neo for model optimizations",
        "Question_body":"<p>Does SageMaker Neo (SageMaker compilation job) use any techniques for model optimization? Are there any compression techniques used (distillation, quantization etc) to reduce the model size?<\/p>\n<p>I found some description here (<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/neo.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/neo.html<\/a>) regarding quantization but it's not clear how it could be used.<\/p>\n<p>Thanks very much for any insight.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1663683615587,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":15.0,
        "Poster_created_time":1340961229400,
        "Poster_location":null,
        "Poster_reputation_count":91.0,
        "Poster_view_count":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73788252",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"techniqu neo model optim neo compil job us techniqu model optim compress techniqu distil quantiz reduc model size descript http doc aw amazon com latest neo html quantiz clear thank insight",
        "Question_preprocessed_content":"techniqu neo model optim neo us techniqu model optim techniqu reduc model size descript quantiz clear thank insight",
        "Question_gpt_summary_original":"The user is seeking information about the techniques used by SageMaker Neo for model optimization, specifically if compression techniques such as distillation and quantization are used to reduce model size. The user found some information on quantization but is unclear on how it is used.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AzureML Model Register",
        "Question_body":"<p>I was trying to register a model using the <code>Run<\/code> Class like this:<\/p>\n<pre><code>model = run.register_model(\n    model_name=model_name,\n    model_path=model_path)\n<\/code><\/pre>\n<p>Errors with message: <code>Could not locate the provided model_path ... in the set of files uploaded to the run...<\/code><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1643643837027,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":319.0,
        "Poster_created_time":1589293508567,
        "Poster_location":null,
        "Poster_reputation_count":833.0,
        "Poster_view_count":55.0,
        "Answer_body":"<p>The only way I found to fix the issue was to use the <code>Model<\/code> Class instead:<\/p>\n<pre><code>        model = Model.register(\n            workspace=ws,\n            model_name=model_name,\n            model_path=model_path,\n            model_framework=Model.Framework.SCIKITLEARN,\n            model_framework_version=sklearn.__version__,\n            description='Model Deescription',\n            tags={'Name' : 'ModelName', 'Type' : 'Production'},\n            model_framework=Model.Framework.SCIKITLEARN,\n            model_framework_version='1.0'\n            )\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1643643837027,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1589293508567,
        "Answerer_location":null,
        "Answerer_reputation_count":833.0,
        "Answerer_view_count":55.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70928761",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model regist try regist model run class like model run regist model model model model path model path error messag locat provid model path set file upload run",
        "Question_preprocessed_content":"model regist try regist model like",
        "Question_gpt_summary_original":"The user encountered an error while trying to register a model using the Run Class in AzureML. The error message stated that the provided model_path could not be located in the uploaded files.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How do I take an already existing MLflow model on my local filesystem and log it to a remote tracking server?",
        "Question_body":"<p>Let's say I already have an existing MLflow model on my local system of the <code>mlflow.pyfunc<\/code> flavor.<\/p>\n<p>The directory looks like this<\/p>\n<pre><code>model\/\n  data\/\n  code\/\n  conda.yml\n  MLmodel\n<\/code><\/pre>\n<p>Where <code>MLmodel<\/code> is something like<\/p>\n<pre><code>flavors:\n  python_function:\n    code: code\n    data: data\n    env: conda.yml\n    loader_module: loader # model\/code\/loader.py has the entrypoint\n<\/code><\/pre>\n<p>I now try and log this model to a remote tracking server using (I'm in the directory above <code>model\/<\/code>, so <code>.\/model\/data<\/code> works, etc)<\/p>\n<pre><code>import mlflow\nmlflow.set_tracking_uri(&quot;http:\/\/localhost:5000&quot;)\nmlflow.pyfunc.log_model(\n  &quot;my-model-artifact&quot;,\n  registered_model_name=&quot;my-model&quot;, # same for all model versions,\n  data_path=&quot;model\/data&quot;,\n  code_path=&quot;model\/code&quot;,\n  loader_module=&quot;model\/code\/loader&quot;\n)\n<\/code><\/pre>\n<p>The tracking server ends up logging a nested MLflow model.. this is inside of the <code>.\/artifacts\/my-model-artifact<\/code> directory on the tracking server<\/p>\n<pre><code>.\/artifacts\/my-model-artifact\n  conda.yaml\n  MLmodel # *not* my MLmodel, one newly generated by MLflow\n  data\/\n  code\/\n<\/code><\/pre>\n<p>Where <code>data<\/code> now points nested to my entire <code>model\/data<\/code> directory and <code>code<\/code> points to a nested <code>model\/code<\/code> directory.<\/p>\n<p>It's like it doesn't understand that I already have this full artifact..<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1646174584637,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":336.0,
        "Poster_created_time":1425965839876,
        "Poster_location":"Santa Cruz, CA",
        "Poster_reputation_count":3256.0,
        "Poster_view_count":164.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71315446",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"exist model local filesystem log remot track server let exist model local pyfunc flavor directori look like model data code conda yml mlmodel mlmodel like flavor python function code code data data env conda yml loader modul loader model code loader entrypoint try log model remot track server directori model model data work import set track uri http localhost pyfunc log model model artifact regist model model model version data path model data code path model code loader modul model code loader track server end log nest model insid artifact model artifact directori track server artifact model artifact conda yaml mlmodel mlmodel newli gener data code data point nest entir model data directori code point nest model code directori like understand artifact",
        "Question_preprocessed_content":"exist model local filesystem log remot track server let exist model local flavor directori like like try log model remot track server track server end nest insid directori track server point nest entir directori point nest directori like understand",
        "Question_gpt_summary_original":"The user is trying to log an existing MLflow model of the pyfunc flavor to a remote tracking server using the log_model function. However, the tracking server ends up logging a nested MLflow model instead of the existing one, which is causing confusion for the user.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to specifify the class of an AWS client in Python?",
        "Question_body":"<p>In Java, for instance, we have a class that represents the SageMaker client class: <code>AmazonSageMakerClient<\/code>, but I couldn't find the equivalent for Python.<\/p>\n<p>I was hoping to be able to do something like:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from sagemaker import SageMakerClient\nclient: SageMakerClient = boto3.client(&quot;sagemaker&quot;)\n<\/code><\/pre>\n<p>I looked into the library code and docs but I couldn't find any references to such class containing the defined methods for that client. In fact, I couldn't find any classes for AWS clients like <code>s3<\/code>, <code>sqs<\/code>, etc. Are those hidden somewhere or am I missing something obvious?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1.0,
        "Question_created_time":1660582010733,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":42.0,
        "Poster_created_time":1362417569863,
        "Poster_location":"Brussels, Belgium",
        "Poster_reputation_count":506.0,
        "Poster_view_count":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73364018",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"specififi class aw client python java instanc class repres client class amazoncli couldn equival python hope abl like import client client client boto client look librari code doc couldn refer class contain defin method client fact couldn class aw client like sq hidden miss obviou",
        "Question_preprocessed_content":"specififi aw client python java instanc repres client couldn equival python hope abl like librari code doc couldn refer contain defin method client fact couldn aw client like obviou",
        "Question_gpt_summary_original":"The user is trying to specify the class of an AWS client in Python, specifically for the SageMaker client. They are unable to find the equivalent class in Python and have looked into the library code and documentation but could not find any references to such a class. They are wondering if they are missing something obvious or if the classes are hidden somewhere.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to call a model's artifacts (pickeled vectorizer) when the model is on Production in databricks?",
        "Question_body":"<p>I am using databrick, machine learning view. I have successfully created and saved my model and also logged my pickled vectorizer as artifacts to it. I would like to load it in a different notebook; the model and the artifacts belong to the model which is currently in production.<\/p>\n<pre><code>   import mlflow.pyfunc\n\nmodel_name = &quot;Sentiment&quot;\nstage = 'Production'\n\nmodel = mlflow.pyfunc.load_model(\n    model_uri=f&quot;models:\/{model_name}\/{stage}&quot;\n)\n<\/code><\/pre>\n<p>So this code seems to be working but it does not load the artifacts or if it does, i do not know how to display them.<\/p>\n<p>I have found this code but not sure what to do with it to only get the artifacts from the model which is in Production.<\/p>\n<pre><code>  from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\nversion =1\nmodel_uri = MlflowClient.get_model_version_download_uri(name=model_name, version=version)\nModelsArtifactRepository(model_uri).download_artifacts(artifact_path=&quot;&quot;)\n<\/code><\/pre>\n<p>even when i run this i get an error :<\/p>\n<p>TypeError: get_model_version_download_uri() missing 1 required positional argument: 'self'<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1663332985133,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1663334102563,
        "Question_score_count":0.0,
        "Question_view_count":10.0,
        "Poster_created_time":1654503897990,
        "Poster_location":null,
        "Poster_reputation_count":47.0,
        "Poster_view_count":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73745159",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model artifact pickel vector model product databrick databrick machin learn view successfulli creat save model log pickl vector artifact like load differ notebook model artifact belong model current product import pyfunc model sentiment stage product model pyfunc load model model uri model model stage code work load artifact know displai code sure artifact model product store artifact model artifact repo import modelsartifactrepositori version model uri client model version download uri model version version modelsartifactrepositori model uri download artifact artifact path run error typeerror model version download uri miss requir posit argument self",
        "Question_preprocessed_content":"model artifact model product databrick databrick machin learn view creat save model pickl vector artifact like load model artifact belong model product code work load artifact know displai code sure artifact model product run requir posit argument self",
        "Question_gpt_summary_original":"The user is trying to load a pickled vectorizer from a model that is currently in production on Databricks. They have tried using the mlflow.pyfunc.load_model() function but are unable to display the artifacts. They have also attempted to use the ModelsArtifactRepository() function but are encountering an error.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Sagemaker requirements.txt unable to find certain packages",
        "Question_body":"Hi,\n\nI'm trying to run a sagemaker job on p3.2xlarge instance using the PyTorch estimator. My script has dependencies on several packages (possibly not pre-installed on the instance) for which I have a requirements.txt file. After loading the instance, it installs several packages but the job fails with following error:\n\n**sagemaker-training-toolkit ERROR InstallRequirementsError:\nCommand \"\/opt\/conda\/bin\/python3.6 -m pip install -r requirements.txt\"\nERROR: Could not find a version that satisfies the requirement scikit_image==0.18.3\nERROR: No matching distribution found for scikit_image==0.18.3**\n\nIt fails for other packages too, like h5py, numpy etc.\n\nAny help is greatly appreciated.\n\nThank you,\nAditya",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_created_time":1649797399439,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668530990016,
        "Question_score_count":0.0,
        "Question_view_count":428.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUl7yzFGwfSEauI7yesYeXiw\/sagemaker-requirements-txt-unable-to-find-certain-packages",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"requir txt unabl certain packag try run job xlarg instanc pytorch estim script depend packag possibl pre instal instanc requir txt file load instanc instal packag job fail follow error train toolkit error installrequirementserror command opt conda bin python pip instal requir txt error version satisfi requir scikit imag error match distribut scikit imag fail packag like hpy numpi help greatli appreci thank aditya",
        "Question_preprocessed_content":"unabl certain packag try run job instanc pytorch estim script depend packag file load instanc packag job fail pip version satisfi requir match distribut fail packag like numpi help greatli thank aditya",
        "Question_gpt_summary_original":"The user is encountering an issue while running a sagemaker job on a PyTorch estimator. The job fails due to the inability to find certain packages mentioned in the requirements.txt file, such as scikit_image, h5py, and numpy. The user is seeking help to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"DefaultAzureCredential failed to retrieve a token from the included credentials.",
        "Question_body":"<p>Hi, While trying authentication in AzureML SDK v2 the DefaultAzureCredential failed to retrieve a token from the included credentials. Attempted credentials: \tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1671076439927,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p><a href=\"\/users\/na\/?userid=71c0cf97-895c-43f1-ac54-98e1e9833ae4\">@A-4824  <\/a>  Thanks for the question. Hers is the <a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/blob\/main\/sdk\/identity\/azure-identity\/TROUBLESHOOTING.md#troubleshoot-environmentcredential-authentication-issues\">Troubleshooting guide<\/a> for Default Azure credential errors.    <\/p>\n<p> from azure.core.exceptions import ClientAuthenticationError    <br \/>\n    from azure.identity import DefaultAzureCredential  <br \/>\n    from azure.keyvault.secrets import SecretClient  <\/p>\n<pre><code># Create a secret client using the DefaultAzureCredential  \nclient = SecretClient(&quot;https:\/\/myvault.vault.azure.net\/&quot;, DefaultAzureCredential())  \ntry:  \n    secret = client.get_secret(&quot;secret1&quot;)  \nexcept ClientAuthenticationError as ex:  \n    print(ex.message)  \n<\/code><\/pre>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1671083438316,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1129620\/defaultazurecredential-failed-to-retrieve-a-token",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"defaultazurecredenti fail retriev token includ credenti try authent sdk defaultazurecredenti fail retriev token includ credenti attempt credenti environmentcredenti environmentcredenti authent unavail environ variabl fulli configur",
        "Question_preprocessed_content":"defaultazurecredenti fail retriev token includ credenti try authent sdk defaultazurecredenti fail retriev token includ credenti credenti environmentcredenti environmentcredenti authent unavail environ variabl configur",
        "Question_gpt_summary_original":"The user encountered an issue with AzureML SDK v2 where the DefaultAzureCredential failed to retrieve a token from the included credentials. The attempted credentials, EnvironmentCredential, were unavailable due to incomplete configuration of environment variables.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"NameError: name 'argparse' is not defined",
        "Question_body":"<p>Hi,<br>\nStarting from a fresh environment with python 3.7.3 and doing a <code>pip install guildai<\/code>, when trying to run<br>\n<code>guild tensorboard<\/code><br>\nI get this error:<br>\nFile \u201c\/Users\/louis-emmanuelmartinet\/.pyenv\/versions\/3.7.3\/envs\/ds-gathering\/lib\/python3.7\/site-packages\/tensorboard_plugin_wit\/wit_plugin_loader.py\u201d, line 73, in define_flags<br>\nexcept argparse.ArgumentError:<br>\nNameError: name \u2018argparse\u2019 is not defined<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1595612979502,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":3760.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/nameerror-name-argparse-is-not-defined\/256",
        "Tool":"Guild AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"nameerror argpars defin start fresh environ python pip instal try run tensorboard error file user loui emmanuelmartinet pyenv version env gather lib python site packag tensorboard plugin wit wit plugin loader line defin flag argpars argumenterror nameerror argpars defin",
        "Question_preprocessed_content":"argpars defin start fresh environ python try run file line argpars defin",
        "Question_gpt_summary_original":"The user encountered a NameError while trying to run 'guild tensorboard' after installing guildai in a fresh environment with Python 3.7.3. The error message indicates that the name 'argparse' is not defined.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to stop weights & biases (wandb) from creating random tmp files?",
        "Question_body":"<p>I have a million tmp files due to wandb on my home folder. I don\u2019t know why. Why are they being created &amp; how do I stop it?<\/p>\n<pre><code class=\"lang-auto\">anaconda\t\t\t\t\t   tmpa0wf77f_wandb-artifacts  tmpmv2ewoi1wandb-media\nanaconda.sh\t\t\t\t\t   tmpa3t655lewandb-media      tmpmvhp3i6ewandb-media\ndata\t\t\t\t\t\t   tmpa6roiz80wandb\t       tmpmwszwea4\ndebug-cli.brando9.log\t\t\t\t   tmpal7kticfwandb-artifacts  tmpn0p49w1hwandb-media\ndiversity-for-predictive-success-of-meta-learning  tmpalsnd4g1wandb-media      tmpnbxtnojbwandb-artifacts\ndiv_install_miniconda\t\t\t\t   tmpambb3rm9wandb-artifacts  tmpngpy96dawandb-artifacts\ndiv_install.out\t\t\t\t\t   tmpapco0xetwandb-media      tmpnqezeggnwandb-media\niit-term-synthesis\t\t\t\t   tmpaqf80v_hwandb-media      tmpo3cug5nzwandb-media\nmain.sh.e449240\t\t\t\t\t   tmpaqigpze6wandb-artifacts  tmpoc4x6l22wandb\nmain.sh.e457075\t\t\t\t\t   tmpaw1kvgtgwandb-media      tmpofql583uwandb-media\nmain.sh.e760266\t\t\t\t\t   tmpay63rbxgwandb-media      tmponqiggzswandb-artifacts\nmain.sh.err748250\t\t\t\t   tmpb2clycf5\t\t       tmpoqem6uclwandb-media\nmain.sh.err849450\t\t\t\t   tmpbbrfn_kmwandb-artifacts  tmpoqth0mgpwandb-media\nmain.sh.err923818\t\t\t\t   tmpbcxatqdiwandb-artifacts  tmppbd5bfm_wandb\nmain.sh.err962904\t\t\t\t   tmpbgewkz10wandb\t       tmppbnpm41gwandb-media\nmain.sh.o449240\t\t\t\t\t   tmpbsd96o99wandb-media      tmppwxmebn1\nmain.sh.o457075\t\t\t\t\t   tmpbtlp8zomwandb\t       tmpq396kfo1wandb-artifacts\nmain.sh.o748250\t\t\t\t\t   tmpby3a9u8ywandb\t       tmpq8jryat0wandb-media\nmain.sh.o760266\t\t\t\t\t   tmpc45e2nlxwandb-media      tmpqc65bfs0wandb\nmain.sh.o849450\t\t\t\t\t   tmpc4m5b21_\t\t       tmpqexdhp6gwandb-artifacts\nmain.sh.o923818\t\t\t\t\t   tmpcap20jmdwandb-media      tmpqh3uu7v2wandb-media\nmain.sh.o950686\t\t\t\t\t   tmpcl2sb6j_wandb\t       tmpqh99a72vwandb-media\nmain.sh.o962904\t\t\t\t\t   tmpcsncx8x4wandb-media      tmpqmim4sxywandb\nminiconda\t\t\t\t\t   tmpd7dhluxmwandb\t       tmpqpfcq9uwwandb\nminiconda.sh\t\t\t\t\t   tmpdbbb3hw_wandb-artifacts  tmpqtds4jdiwandb-artifacts\nnohup.out\t\t\t\t\t   tmpdfrjyk90wandb-media      tmp_qz8pu0xwandb-artifacts\nnohup.out449240\t\t\t\t\t   tmpdhqwaxygwandb\t       tmpr98qj7auwandb\nnohup.out457075\t\t\t\t\t   tmpdpj3bfz0wandb-artifacts  tmprfwooa22wandb-artifacts\nnohup.out760266\t\t\t\t\t   tmpdqzzy7v3\t\t       tmpri9xu8i_wandb-media\npycoq\t\t\t\t\t\t   tmpdr6fbpctwandb\t       tmprj4g0kkhwandb\ntest.py\t\t\t\t\t\t   tmpejwo7axlwandb\t       tmp_rla0cb9wandb-media\ntmp\t\t\t\t\t\t   tmpekqp7b2dwandb-media      tmprmrasn0fwandb-media\ntmp03kmjan0wandb\t\t\t\t   tmpf3pk0_3t\t\t       tmpr_yrhzj_wandb\ntmp07zhon11wandb-media\t\t\t\t   tmpf4w8yhsswandb-media      tmprzxltg0lwandb\ntmp0pkwjwg8wandb\t\t\t\t   tmpf_6vd6hkwandb-media      tmps0beul64wandb-media\ntmp0ypuhnktwandb-media\t\t\t\t   tmpf7vuwlipwandb\t       tmps5qf0_w0wandb\ntmp0zk3_ok1wandb\t\t\t\t   tmpfc8ltujrwandb-media      tmpsp2djjg6wandb-artifacts\ntmp14xa24j_wandb\t\t\t\t   tmpfmcmwgb8\t\t       tmpsqe0vylnwandb\ntmp1f3gqdq1wandb-media\t\t\t\t   tmpfqhl6c9vwandb\t       tmpstniop3twandb-media\ntmp1hmrx3xnwandb\t\t\t\t   tmpfvkvyklpwandb-media      tmpsv3n4fi7wandb-media\ntmp1nxq8dmowandb\t\t\t\t   tmpfxuc2zwjwandb-artifacts  tmp_t3mkuy4\ntmp1r2xah97wandb-media\t\t\t\t   tmpg051c49z\t\t       tmptb0urf26wandb\ntmp1sdb3vnqwandb-media\t\t\t\t   tmpg16e6zpxwandb-media      tmptgq1h308wandb-media\ntmp1wq9i7tmwandb-media\t\t\t\t   tmpg2qfjo5pwandb-artifacts  tmpthtghn1wwandb-media\ntmp27k3evykwandb-artifacts\t\t\t   tmpg34wt2g1wandb-media      tmptkp9qpgxwandb-media\ntmp2ncmg9jmwandb-media\t\t\t\t   tmpggaltim9wandb-media      tmptqn9w7rawandb-artifacts\ntmp2qxmugpjwandb-media\t\t\t\t   tmpgj6gyqw6wandb-media      tmptsqb0lwrwandb\ntmp2w92xlzowandb\t\t\t\t   tmpgpv_1hxk\t\t       tmptub9i1zzwandb-media\ntmp39lds7tywandb-media\t\t\t\t   tmpgswv7jpn\t\t       tmpu0k6cuycwandb-media\ntmp3ncj9tdewandb-artifacts\t\t\t   tmpgvz0_o1h\t\t       tmpu6uv_y0pwandb\ntmp3qlpfrylwandb-media\t\t\t\t   tmpgyarr2jxwandb\t       tmpumz7hmaiwandb-artifacts\ntmp3snbanfnwandb\t\t\t\t   tmph6m9dpa_wandb\t       tmpun08cdmwwandb-artifacts\ntmp3xrxd920wandb-artifacts\t\t\t   tmph8n3b36swandb-media      tmp_uqnbz5n\ntmp3zmnx6jxwandb-artifacts\t\t\t   tmphddkq3_3wandb\t       tmpurv7_fe2wandb\ntmp4103eum2wandb\t\t\t\t   tmphmva83y4wandb\t       tmpuwoxzzfvwandb-media\ntmp421qmhu3wandb\t\t\t\t   tmphs6erdxrwandb-media      tmpvb5bk2js\ntmp48khxd0nwandb-artifacts\t\t\t   tmphshrf9juwandb-artifacts  tmpvd_wklrtwandb\ntmp49fv73y2wandb-media\t\t\t\t   tmpi31q87a0wandb-artifacts  tmpvg_71vtdwandb-media\ntmp49sad_g1wandb-artifacts\t\t\t   tmpiu05wr2_wandb\t       tmpvlxyr3eawandb-media\ntmp4c4800_xwandb-media\t\t\t\t   tmpivnhmojfwandb\t       tmpvqmyjo4pwandb-media\ntmp4clbe6xvwandb-media\t\t\t\t   tmpj16iv0rbwandb-media      tmpw10pvrxxwandb-media\ntmp4nuizjduwandb-media\t\t\t\t   tmpj4nmef2_wandb-media      tmpw8eaus7xwandb-media\ntmp5aiik94rwandb-media\t\t\t\t   tmpj6k4pajlwandb-artifacts  tmpw97zp6pqwandb-media\ntmp5jusc1czwandb-media\t\t\t\t   tmpjetcrm92wandb-media      tmpwkzzglljwandb-media\ntmp5ks7vxpqwandb\t\t\t\t   tmp_jfnbfwcwandb-artifacts  tmpwlpoppuwwandb-media\ntmp5ss5gfoqwandb-media\t\t\t\t   tmpjhcfo3sjwandb-media      tmpwok9yxtqwandb-media\ntmp61l257guwandb-media\t\t\t\t   tmpjhkja0n4wandb-media      tmpwqbb7793wandb\ntmp66a_30crwandb\t\t\t\t   tmpjq3bc0iywandb-media      tmpwu7oid1swandb-media\ntmp6_95ss09\t\t\t\t\t   tmpjseq6pjrwandb\t       tmpwwmlqm3gwandb-artifacts\ntmp6eb3e1v_wandb-artifacts\t\t\t   tmpjywyihxswandb\t       tmpwys0txyz\ntmp6ev3bw0kwandb-media\t\t\t\t   tmpk7eb9cxxwandb-artifacts  tmpx0i8_uxdwandb-media\ntmp6j_pagmjwandb-media\t\t\t\t   tmpki8mvo7pwandb\t       tmpxby6g44swandb-media\ntmp6uz84wzpwandb\t\t\t\t   tmpkiqc2rxywandb-media      tmpxdsg3tk8wandb-artifacts\ntmp7dmpqrecwandb\t\t\t\t   tmpklsmildcwandb-media      tmpxm2j1915wandb\ntmp7fzpg3pjwandb-artifacts\t\t\t   tmpkvhsusnzwandb-artifacts  tmp_xmydpcnwandb-media\ntmp7iafm3cywandb-media\t\t\t\t   tmpkvt13pjiwandb\t       tmpxpj1qkhnwandb-media\ntmp7m0tkcx7wandb\t\t\t\t   tmpkxhoutmnwandb\t       tmpxqnwoio_wandb-media\ntmp7p7ko5c1\t\t\t\t\t   tmpl32i_q8cwandb-artifacts  tmpy3sbukw0wandb-artifacts\ntmp7xmnpnjxwandb-media\t\t\t\t   tmpldwit_dswandb-media      tmpy4tqgd9q\ntmp80lef2dvwandb\t\t\t\t   tmplf9oolt5wandb\t       tmpy5mlqvf2\ntmp89e0j4bjwandb-artifacts\t\t\t   tmplgmiofgnwandb-artifacts  tmpy5y0mxbrwandb\ntmp8h7rchd9wandb-artifacts\t\t\t   tmplw1n5b69wandb-media      tmpydoskv75wandb\ntmp8l4njuz2\t\t\t\t\t   tmplx9285iywandb\t       tmpyx791iakwandb-media\ntmp8lxb4u_0wandb\t\t\t\t   tmp_lzx3b9dwandb-media      tmpyy2hv95pwandb-artifacts\ntmp8lyo8smzwandb\t\t\t\t   tmpm1c4zy4twandb-artifacts  tmpz0gx4ikiwandb-media\ntmp8q4h8lu7wandb-artifacts\t\t\t   tmpm2755ginwandb-artifacts  tmpz26cajmh\ntmp_8uvnuf2wandb\t\t\t\t   tmpm56u1aa5wandb-media      tmpz5s198hnwandb-artifacts\ntmp96o0qfii\t\t\t\t\t   tmpm9gk_r6swandb-media      tmpz6oxqu4vwandb-media\ntmp974f9ciawandb-media\t\t\t\t   tmpm_9gv20owandb-media      tmpzgz2lbnmwandb\ntmp98ec7tz8wandb-media\t\t\t\t   tmpmdak3eqkwandb-media      tmpzyqel_hcwandb-artifacts\ntmp9i4bx28vwandb\t\t\t\t   tmpmekovp_5wandb-artifacts  tmpzzjlqqh8wandb-media\ntmp9l8xrnlqwandb-media\t\t\t\t   tmp_mpucxdiwandb-artifacts  ultimate-utils\ntmp9y_56adfwandb-media\t\t\t\t   tmpmsn3sy8mwandb-artifacts  wandb\n<\/code><\/pre>\n<h3>\n<a name=\"additional-files-1\" class=\"anchor\" href=\"#additional-files-1\"><\/a>Additional Files<\/h3>\n<p><em>No response<\/em><\/p>\n<h3>\n<a name=\"environment-2\" class=\"anchor\" href=\"#environment-2\"><\/a>Environment<\/h3>\n<p>WandB version:<br>\n(metalearning_gpu) brando9~ $ python<br>\nPython 3.9.13 (main, Oct 13 2022, 21:15:33)<br>\n[GCC 11.2.0] :: Anaconda, Inc. on linux<br>\nType \u201chelp\u201d, \u201ccopyright\u201d, \u201ccredits\u201d or \u201clicense\u201d for more information.<\/p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>import wandb<br>\nwandb.<strong>version<\/strong><br>\n\u20180.13.5\u2019<\/p>\n<\/blockquote>\n<\/blockquote>\n<\/blockquote>\n<p>OS: ubuntu\/linux<\/p>\n<p>(metalearning_gpu) brando9~ $ cat \/etc\/os-release<br>\nNAME=\u201cUbuntu\u201d<br>\nVERSION=\u201c16.04.7 LTS (Xenial Xerus)\u201d<br>\nID=ubuntu<br>\nID_LIKE=debian<br>\nPRETTY_NAME=\u201cUbuntu 16.04.7 LTS\u201d<br>\nVERSION_ID=\u201c16.04\u201d<br>\nHOME_URL=\u201c<a href=\"http:\/\/www.ubuntu.com\/\" rel=\"noopener nofollow ugc\">http:\/\/www.ubuntu.com\/<\/a>\u201d<br>\nSUPPORT_URL=\u201c<a href=\"http:\/\/help.ubuntu.com\/\" rel=\"noopener nofollow ugc\">http:\/\/help.ubuntu.com\/<\/a>\u201d<br>\nBUG_REPORT_URL=\u201c<a href=\"http:\/\/bugs.launchpad.net\/ubuntu\/\" rel=\"noopener nofollow ugc\">http:\/\/bugs.launchpad.net\/ubuntu\/<\/a>\u201d<br>\nVERSION_CODENAME=xenial<br>\nUBUNTU_CODENAME=xenial<\/p>\n<p>Python version: 3.9.13<\/p>\n<p>Versions of relevant libraries:<\/p>\n<hr>\n<p>related:<\/p>\n<ul>\n<li>cross: <a href=\"https:\/\/github.com\/wandb\/wandb\/issues\/4535\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: Random tmp files being made -- why? \u00b7 Issue #4535 \u00b7 wandb\/wandb \u00b7 GitHub<\/a>\n<\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/74566670\/how-to-stop-weights-biases-wandb-from-creating-random-tmp-files\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">machine learning - How to stop weights &amp; biases (wandb) from creating random tmp files? - Stack Overflow<\/a><\/li>\n<\/ul>",
        "Question_answer_count":7,
        "Question_comment_count":null,
        "Question_created_time":1669328009419,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":655.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-stop-weights-biases-wandb-from-creating-random-tmp-files\/3460",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"stop creat random tmp file million tmp file home folder dont know creat stop anaconda tmpawff artifact tmpmvewoi media anaconda tmpatl media tmpmvhpie media data tmparoiz tmpmwszwea debug cli brando log tmpalkticf artifact tmpnpwh media divers predict success meta learn tmpalsndg media tmpnbxtnojb artifact div instal miniconda tmpambbrm artifact tmpngpyda artifact div instal tmpapcoxet media tmpnqezeggn media iit term synthesi tmpaqfv media tmpocugnz media main tmpaqigpz artifact tmpocxl main tmpawkvgtg media tmpofqlu media main tmpayrbxg media tmponqiggz artifact main err tmpbclycf tmpoqemucl media main err tmpbbrfn artifact tmpoqthmgp media main err tmpbcxatqdi artifact tmppbdbfm main err tmpbgewkz tmppbnpmg media main tmpbsdo media tmppwxmebn main tmpbtlpzom tmpqkfo artifact main tmpbyaui tmpqjryat media main tmpcenlx media tmpqcbf main tmpcmb tmpqexdhpg artifact main tmpcapjmd media tmpqhuuv media main tmpclsbj tmpqhav media main tmpcsncxx media tmpqmimsxi miniconda tmpddhluxm tmpqpfcquw miniconda tmpdbbbhw artifact tmpqtdsjdi artifact nohup tmpdfrjyk media tmp qzpux artifact nohup tmpdhqwaxyg tmprqjau nohup tmpdpjbfz artifact tmprfwooa artifact nohup tmpdqzzyv tmprixui media pycoq tmpdrfbpct tmprjgkkh test tmpejwoaxl tmp rlacb media tmp tmpekqpbd media tmprmrasnf media tmpkmjan tmpfpk tmpr yrhzj tmpzhon media tmpfwyhss media tmprzxltgl tmppkwjwg tmpf vdhk media tmpsbeul media tmpypuhnkt media tmpfvuwlip tmpsqf tmpzk tmpfcltujr media tmpspdjjg artifact tmpxaj tmpfmcmwgb tmpsqevyln tmpfgqdq media tmpfqhlcv tmpstniopt media tmphmrxxn tmpfvkvyklp media tmpsvnfi media tmpnxqdmo tmpfxuczwj artifact tmp tmkui tmprxah media tmpgcz tmptburf tmpsdbvnq media tmpgezpx media tmptgqh media tmpwqitm media tmpgqfjop artifact tmpthtghnw media tmpkevyk artifact tmpgwtg media tmptkpqpgx media tmpncmgjm media tmpggaltim media tmptqnwra artifact tmpqxmugpj media tmpgjgyqw media tmptsqblwr tmpwxlzo tmpgpv hxk tmptubizz media tmpldsty media tmpgswvjpn tmpukcuyc media tmpncjtde artifact tmpgvz tmpuuv tmpqlpfryl media tmpgyarrjx tmpumzhmai artifact tmpsnbanfn tmphmdpa tmpuncdmw artifact tmpxrxd artifact tmphnb media tmp uqnbzn tmpzmnxjx artifact tmphddkq tmpurv tmpeum tmphmvai tmpuwoxzzfv media tmpqmhu tmphserdxr media tmpvbbkj tmpkhxdn artifact tmphshrfju artifact tmpvd wklrt tmpfvy media tmpiqa artifact tmpvg vtd media tmpsad artifact tmpiuwr tmpvlxyrea media tmpc media tmpivnhmojf tmpvqmyjop media tmpclbexv media tmpjivrb media tmpwpvrxx media tmpnuizjdu media tmpjnmef media tmpweausx media tmpaiikr media tmpjkpajl artifact tmpwzppq media tmpjusccz media tmpjetcrm media tmpwkzzgllj media tmpksvxpq tmp jfnbfwc artifact tmpwlpoppuw media tmpssgfoq media tmpjhcfosj media tmpwokyxtq media tmplgu media tmpjhkjan media tmpwqbb tmpa tmpjqbcii media tmpwuoid media tmp tmpjseqpjr tmpwwmlqmg artifact tmpebev artifact tmpjywyihx tmpwystxyz tmpevbwk media tmpkebcxx artifact tmpxi uxd media tmpj pagmj media tmpkimvop tmpxbyg media tmpuzwzp tmpkiqcrxi media tmpxdsgtk artifact tmpdmpqrec tmpklsmildc media tmpxmj tmpfzpgpj artifact tmpkvhsusnz artifact tmp xmydpcn media tmpiafmci media tmpkvtpji tmpxpjqkhn media tmpmtkcx tmpkxhoutmn tmpxqnwoio media tmppkoc tmpli artifact tmpysbukw artifact tmpxmnpnjx media tmpldwit media tmpytqgdq tmplefdv tmplfoolt tmpymlqvf tmpejbj artifact tmplgmiofgn artifact tmpyymxbr tmphrchd artifact tmplwnb media tmpydoskv tmplnjuz tmplxii tmpyxiak media tmplxbu tmp lzxbd media tmpyyhvp artifact tmplyosmz tmpmczyt artifact tmpzgxiki media tmpqhlu artifact tmpmgin artifact tmpzcajmh tmp uvnuf tmpmuaa media tmpzshn artifact tmpoqfii tmpmgk media tmpzoxquv media tmpfcia media tmpm gvo media tmpzgzlbnm tmpectz media tmpmdakeqk media tmpzyqel artifact tmpibxv tmpmekovp artifact tmpzzjlqqh media tmplxrnlq media tmp mpucxdi artifact ultim util tmpy adf media tmpmsnsym artifact addit file respons environ version metalearn gpu brando python python main oct gcc anaconda linux type help copyright credit licens inform import version ubuntu linux metalearn gpu brando cat releas ubuntu version lt xenial xeru ubuntu like debian pretti ubuntu lt version home url http www ubuntu com support url http help ubuntu com bug report url http bug launchpad net ubuntu version codenam xenial ubuntu codenam xenial python version version relev librari relat cross cli random tmp file issu github machin learn stop creat random tmp file stack overflow",
        "Question_preprocessed_content":"stop creat random tmp file tmp file home folder dont know creat stop file respons environ version brando python python anaconda linux type help copyright credit licens inform import version brando cat ubuntu lt ubuntu lt python version version relev librari relat random tmp file github machin learn stop creat random tmp file stack overflow",
        "Question_gpt_summary_original":"The user is facing an issue where WandB is creating a large number of random tmp files in their home folder and they are unsure why this is happening. They are seeking advice on how to stop this from happening.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"how to predict more multiple values in azure ml?",
        "Question_body":"<p>I am creating Azure ML experienment to predict multiple values. but in azure ml we can not train a model to predict multiple values. my question is how to bring multiple trained models in single experienment and create webout put that gives me multiple prediction.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1517479996490,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1517995658060,
        "Question_score_count":0.0,
        "Question_view_count":666.0,
        "Poster_created_time":1517479193607,
        "Poster_location":null,
        "Poster_reputation_count":3.0,
        "Poster_view_count":7.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48560183",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"predict multipl valu creat experien predict multipl valu train model predict multipl valu question bring multipl train model singl experien creat webout give multipl predict",
        "Question_preprocessed_content":"predict multipl valu creat experien predict multipl valu train model predict multipl valu question bring multipl train model singl experien creat webout give multipl predict",
        "Question_gpt_summary_original":"The user is facing a challenge in creating an Azure ML experiment to predict multiple values as Azure ML does not allow training a model to predict multiple values. The user is seeking a solution to bring multiple trained models in a single experiment and create web output that provides multiple predictions.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Dialogflow ES - Chat Window Content Customization to fix scroll issue",
        "Question_body":"Hello,\n\nI'm working on a Dialogflow ES agent where the bot has long responses in my use cases to where the beginning of most responses get hidden under the titlebar in the header of the chot window.\u00a0 The user would have to scroll up to see the start of the message which is not an ideal UX.\u00a0\n\nA thought to fix this issue is show one paragraph at a time in the response by using a delay and maybe showing three dots like someone is typing so a user would have time to read the response and has some kind of signal that there's more to the response vs dialogflow showing all the response at once.\u00a0 How would I go about setting that up either through configurations and\/or scripts? The HTML is something like:\n\n<div id=\"messageList\">\n\u00a0 \u00a0 <div class=\"message\">Paragraph 1<\/div>\n\u00a0 \u00a0\u00a0<div class=\"message\">Paragraph 2<\/div>\n\u00a0 \u00a0<div class=\"message\">Paragraph 3<\/div>\n\u00a0 \u00a0<div class=\"message\">Paragraph 4<\/div>\n<\/div>\n\nThanks!",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1678891860000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":80.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-ES-Chat-Window-Content-Customization-to-fix-scroll\/m-p\/533030#M1428",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"dialogflow chat window content custom fix scroll issu hello work dialogflow agent bot long respons us case begin respons hidden titlebar header chot window user scroll start messag ideal thought fix issu paragraph time respons delai mayb show dot like type user time read respons kind signal respons dialogflow show respons set configur script html like paragraph paragraph paragraph paragraph thank",
        "Question_preprocessed_content":"dialogflow chat window content custom fix work dialogflow agent bot long respons us case respons titlebar header chot window user start ideal thought fix paragraph time respons delai mayb show dot like type user time read respons kind signal respons dialogflow show respons configur script html like paragraph paragraph paragraph paragraph thank",
        "Question_gpt_summary_original":"The user is facing a scroll issue in the Dialogflow ES chat window where long responses get hidden under the title bar in the header. To fix this, the user wants to show one paragraph at a time with a delay and three dots to signal that there's more to the response. The user is seeking guidance on how to set this up through configurations and\/or scripts.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Vertax AI pipeline quota",
        "Question_body":"<p>I got a custom_model_training_cpus error when runing a submitted pipeline on Vertex AI. I could not find any documents. And I am using the n1-standard-4 for the deployment machine, I do not see any issue. Any commnents would be much appriciated.<\/p>\n<blockquote>\n<p>com.google.cloud.ai.platform.common.errors.AiPlatformException: code=RESOURCE_EXHAUSTED, message=The following quota metrics exceed quota limits: aiplatform.googleapis.com\/custom_model_training_cpus, cause=null; Failed to create custom job for the task.<\/p>\n<\/blockquote>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TgCJD.png\" rel=\"nofollow noreferrer\">DAG flow and error message<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1660618735810,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":3.0,
        "Question_view_count":110.0,
        "Poster_created_time":1660618422463,
        "Poster_location":null,
        "Poster_reputation_count":31.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73368320",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"vertax pipelin quota got custom model train cpu error rune submit pipelin document standard deploy machin issu commnent apprici com googl cloud platform common error aiplatformexcept code resourc exhaust messag follow quota metric exce quota limit aiplatform googleapi com custom model train cpu caus null fail creat custom job task dag flow error messag",
        "Question_preprocessed_content":"vertax pipelin quota got rune pipelin document deploy machin quota metric quota limit caus fail creat custom job task dag flow",
        "Question_gpt_summary_original":"The user encountered a custom_model_training_cpus error while running a submitted pipeline on Vertex AI. The error message indicates that the quota metrics exceed the quota limits, and the user is unable to find any relevant documents to resolve the issue. The user is using n1-standard-4 for the deployment machine and seeks comments to address the problem.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"forecast package versions different result",
        "Question_body":"<p>I am using R forecast package auto.arima() function, testing it against a predictable sine wave time series. When I run the R code on local machine in R studio, I get a significantly different output to running exactly the same code with the same source data as in azure ML. The only difference I can see is that azure has an older version of forecast package 5.4 whereas i have downloaded the latest version on local machine 5.9. (Interestingly the older version in azure ML correctly forecasts future values, the newer version predicts an attenuating amplitude, which is incorrect). <\/p>\n\n<p>My question then is for anyone who may know why a function's behaviour would change so significantly between package versions, which strikes me as very strange. Or am I missing something here? I am new to both R and azure ML.. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1430172286407,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1483523471852,
        "Question_score_count":0.0,
        "Question_view_count":212.0,
        "Poster_created_time":1430171674327,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29906812",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"forecast packag version differ result forecast packag auto arima function test predict sine wave time seri run code local machin studio significantli differ output run exactli code sourc data differ azur older version forecast packag download latest version local machin interestingli older version correctli forecast futur valu newer version predict attenu amplitud incorrect question know function behaviour chang significantli packag version strike strang miss new",
        "Question_preprocessed_content":"forecast packag version result forecast packag function test predict sine wave time seri run code local machin studio significantli output exactli code sourc data azur older version forecast packag download latest version local machin question know function behaviour chang significantli packag version strike strang new",
        "Question_gpt_summary_original":"The user is facing a challenge with the R forecast package auto.arima() function, as the output differs significantly when run on their local machine in R studio compared to running the same code with the same source data in Azure ML. The only difference is that Azure ML has an older version of the forecast package (5.4) while the user has the latest version (5.9). The older version in Azure ML correctly forecasts future values, while the newer version predicts an attenuating amplitude, which is incorrect. The user is seeking help to understand why a function's behavior would change so significantly between package versions.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure Machine Learning - Use personal container registry",
        "Question_body":"<p>I tried to run this code to create an ml workspace from the azure-ml-cli, referencing an existing azure container registry from another subscription:<\/p>\n<pre><code>az ml workspace create --workspace-name &quot;test-mlws&quot; --keyvault &quot;&lt;key-vault-service-id&gt;&quot; --container-registry &quot;&lt;container-registry-zervice-id&gt;&quot; --location westeurope\n<\/code><\/pre>\n<p>The deploy failed with this error code:<\/p>\n<pre><code>{'code': 'InternalServerError', 'message': 'Received 403 from a service request'}\n<\/code><\/pre>\n<p>I can't find any documentation about it, and I guess it's due to the container registry I used which belongs to another subscription. Anyone who knows if it's mandatory for the registry to be in the same subscription?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1617971298560,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1618194925572,
        "Question_score_count":0.0,
        "Question_view_count":773.0,
        "Poster_created_time":1519297984923,
        "Poster_location":"Cagliari, CA, Italia",
        "Poster_reputation_count":127.0,
        "Poster_view_count":21.0,
        "Answer_body":"<p>From <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#limitations\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#limitations<\/a><\/p>\n<blockquote>\n<p>If you want to use <strong>existing services from a different Azure\nsubscription<\/strong> than the workspace, you must register the Azure Machine\nLearning namespace in the subscription that contains those services.<\/p>\n<\/blockquote>\n<p>So, in order to use the ACR in that different subscription, you need to register resource provider <code>Microsoft.MachineLearningServices<\/code> in that subscription contains ACR. For information on how to see if it is registered and how to register it, see the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/resource-providers-and-types\" rel=\"nofollow noreferrer\">Azure resource providers and types<\/a> article.<\/p>\n<p>To register a resource provider, use:<\/p>\n<pre><code>Register-AzResourceProvider -ProviderNamespace Microsoft.MachineLearningServices\n<\/code><\/pre>\n<p>To see information for a particular resource provider, use:<\/p>\n<pre><code>Get-AzResourceProvider -ProviderNamespace Microsoft.MachineLearningServices\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1618194887616,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1527065173880,
        "Answerer_location":null,
        "Answerer_reputation_count":25218.0,
        "Answerer_view_count":2553.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67021176",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us person contain registri tri run code creat workspac azur cli referenc exist azur contain registri subscript workspac creat workspac test mlw keyvault contain registri locat westeurop deploi fail error code code internalservererror messag receiv servic request document guess contain registri belong subscript know mandatori registri subscript",
        "Question_preprocessed_content":"us person contain registri tri run code creat workspac referenc exist azur contain registri subscript deploi fail code document contain registri belong subscript know mandatori registri subscript",
        "Question_gpt_summary_original":"The user encountered an error while trying to create an ml workspace from the azure-ml-cli, referencing an existing azure container registry from another subscription. The error code received was 'InternalServerError' with a message stating 'Received 403 from a service request'. The user suspects that the error is due to the container registry belonging to another subscription and is unsure if it is mandatory for the registry to be in the same subscription.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Error importing JSONL dataset into Vertex AI",
        "Question_body":"<p>I tried importing a JSONL dataset into Google's Vertex AI and get a weird and seemingly unrelated error:<\/p>\n<pre><code>Error: Could not parse the line, json is invalid or the format does not match the input schema: Cannot find field: classificationAnnotation in message google.cloud.aiplatform.master.schema.ImageBoundingBoxIoFormat. for: gs:\/\/[bucketname]\/set.jsonl line 10\n<\/code><\/pre>\n<p>It happens every 4 lines of code. All of my lines are identical except the image name changes.<\/p>\n<p>Line 10:<\/p>\n<pre><code>{&quot;imageGcsUri&quot;:&quot;gs:\/\/[mybucket]\/path\/to\/image.png&quot;,&quot;classificationAnnotation&quot;:{&quot;displayName&quot;:&quot;MyLabel&quot;,&quot;annotationResourceLabels&quot;:{&quot;aiplatform.googleapis.com\/annotation_set_name&quot;:&quot;MyLabel&quot;}},&quot;dataItemResourceLabels&quot;:{&quot;aiplatform.googleapis.com\/ml_use&quot;:&quot;training&quot;}}\n<\/code><\/pre>\n<p>Why am I getting this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1660139623310,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":93.0,
        "Poster_created_time":1297920350390,
        "Poster_location":"Perth, Australia",
        "Poster_reputation_count":2950.0,
        "Poster_view_count":367.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73307573",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error import jsonl dataset tri import jsonl dataset googl weird seemingli unrel error error pars line json invalid format match input schema field classificationannot messag googl cloud aiplatform master schema imageboundingboxioformat bucketnam set jsonl line happen line code line ident imag chang line imagegcsuri mybucket path imag png classificationannot displaynam mylabel annotationresourcelabel aiplatform googleapi com annot set mylabel dataitemresourcelabel aiplatform googleapi com us train get error",
        "Question_preprocessed_content":"import jsonl dataset tri import jsonl dataset weird unrel line code line ident imag chang line",
        "Question_gpt_summary_original":"The user is encountering an error while trying to import a JSONL dataset into Google's Vertex AI. The error message suggests that there is an issue with the format of the input schema and that the field \"classificationAnnotation\" cannot be found in the message. The error occurs every 4 lines of code, and all lines are identical except for the image name. The user is seeking help to understand why this error is occurring.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Does dvc have a model sharing feature?",
        "Question_body":"<p>Data versioning of models is possible using DVC, but is there a way to centralize all models so that users can share and resuse models?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1671113441042,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":71.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/does-dvc-have-a-model-sharing-feature\/1418",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"model share featur data version model possibl wai central model user share resus model",
        "Question_preprocessed_content":"model share featur data version model wai central model user share resus model",
        "Question_gpt_summary_original":"The user is inquiring about whether DVC has a model sharing feature that would allow for centralized storage and sharing of models among users.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS SageMaker Canvas Model usage on Edge device in Python",
        "Question_body":"<p>This way I wanted to ask a question about AWS Sagemaker. I must confess that I'm quite a newbee to the subject and therefor I was very happy with the SageMaker Canvas app. It works really easy and gives me some nice results.<\/p>\n<p>First of all my model. I try to predict solar power production based on the time (dt), the AWS IoT Thingname (thingname), clouds percentage (clouds) and temperature (temp). I have a csv filled with data measured by IoT things<\/p>\n<p><code>clouds<\/code> + <code>temp<\/code> + <code>dt<\/code> + <code>thingname<\/code> =&gt; <code>import<\/code><\/p>\n<pre><code>dt,clouds,temp,import,thingname\n2022-08-30 07:45:00+02:00,1.0,0.1577,0.03,***\n2022-08-30 08:00:00+02:00,1.0,0.159,0.05,***\n2022-08-30 08:15:00+02:00,1.0,0.1603,0.06,***\n2022-08-30 08:30:00+02:00,1.0,0.16440000000000002,0.08,***\n2022-08-30 08:45:00+02:00,,,0.09,***\n2022-08-30 09:00:00+02:00,1.0,0.17,0.12,***\n2022-08-30 09:15:00+02:00,1.0,0.1747,0.13,***\n2022-08-30 09:30:00+02:00,1.0,0.1766,0.15,***\n2022-08-30 09:45:00+02:00,0.75,0.1809,0.18,***\n2022-08-30 10:00:00+02:00,1.0,0.1858,0.2,***\n2022-08-30 10:15:00+02:00,1.0,0.1888,0.21,***\n2022-08-30 10:30:00+02:00,0.75,0.1955,0.24,***\n<\/code><\/pre>\n<p>In AWS SageMaker canvas I upload the csv and build the model. All is very easy and when I use the predict tab I upload a CSV where the import column is missing and containing API weather data for some future moment:<\/p>\n<pre><code>dt,thingname,temp,clouds\n2022-09-21 10:15:00+02:00,***,0.1235,1.0\n2022-09-21 10:30:00+02:00,***,0.1235,1.0\n2022-09-21 10:45:00+02:00,***,0.1235,1.0\n2022-09-21 11:00:00+02:00,***,0.1235,1.0\n2022-09-21 11:15:00+02:00,***,0.12689999999999999,0.86\n2022-09-21 11:30:00+02:00,***,0.12689999999999999,0.86\n2022-09-21 11:45:00+02:00,***,0.12689999999999999,0.86\n2022-09-21 12:00:00+02:00,***,0.12689999999999999,0.86\n2022-09-21 12:15:00+02:00,***,0.1351,0.69\n2022-09-21 12:30:00+02:00,***,0.1351,0.69\n2022-09-21 12:45:00+02:00,***,0.1351,0.69\n<\/code><\/pre>\n<p>From this data SageMaker Canvas predicts some real realistic numbers, from which I assume the model is nicely build. So I want to move this model to my Greengrass Core Device to do predictions on site. I found the best model location using the sharing link to the Junyper notebook.<\/p>\n<p>From reading in the AWS docs I seem to have a few options to run the model on an edge device:<\/p>\n<ul>\n<li>Run the Greengrass SageMaker Edge component and run the model as a component and write an inference component<\/li>\n<li>Run the SageMaker Edge Agent yourself<\/li>\n<li>Just download the model yourself and do your thing with it on the device<\/li>\n<\/ul>\n<p>Now it seems that SageMaker used XGBoost to create the model and I found the <code>xgboost-model<\/code> file and downloaded it to the device.<\/p>\n<p>But here is where the trouble started:\nSageMaker Canvas never gives any info on what it does with the CSV to format it, so I have really no clue on how to make a prediction using the model.\nI get some results when I try to open the same csv file I used for the Canvas prediction, but the data is completely different and not realistic at all<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># pip install xgboost==1.6.2\nimport xgboost as xgb\n\nfilename = f'solar-prediction-data.csv'\ndpredict = xgb.DMatrix(f'{filename}?format=csv')\nmodel = xgb.Booster()\nmodel.load_model('xgboost-model')\nresult = model.predict(dpredict)\nprint('Prediction result::')\nprint(result)\n<\/code><\/pre>\n<p>I read that the column order matters, the CSV may not contain a header.  But it does not get close to the SageMaker Canvas result.<\/p>\n<p>I also tried using <code>pandas<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># pip install xgboost==1.6.2\nimport xgboost as xgb\nimport pandas as pd\n\nfilename = f'solar-prediction-data.csv'\ndf = pd.read_csv(filename, index_col=None, header=None)\n\ndpredict = xgb.DMatrix(df, enable_categorical=True)\n\nmodel = xgb.Booster()\nmodel.load_model('xgboost-model')\nresult = model.predict(dpredict, pred_interactions=True)\nprint('Prediction result::')\nprint('===============')\nprint(result)\n<\/code><\/pre>\n<p>But this last one always gives me following error:<\/p>\n<pre><code>ValueError: DataFrame.dtypes for data must be int, float, bool or category.  When\ncategorical type is supplied, DMatrix parameter `enable_categorical` must\nbe set to `True`. Invalid columns:dt, thingname\n<\/code><\/pre>\n<p>To be honest, I'm completely stuck and hope someone around here can give me some advice or clue on how I can proceed.<\/p>\n<p>Thanks!\nKind regards<\/p>\n<p>Hacor<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1663940700760,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":18.0,
        "Poster_created_time":1455091044887,
        "Poster_location":null,
        "Poster_reputation_count":43.0,
        "Poster_view_count":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73828700",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"canva model usag edg devic python wai want ask question confess newbe subject therefor happi canva app work easi give nice result model try predict solar power product base time aw iot thingnam thingnam cloud percentag cloud temperatur temp csv fill data measur iot thing cloud temp thingnam import cloud temp import thingnam canva upload csv build model easi us predict tab upload csv import column miss contain api weather data futur moment thingnam temp cloud data canva predict real realist number assum model nice build want model greengrass core devic predict site best model locat share link junyp notebook read aw doc option run model edg devic run greengrass edg compon run model compon write infer compon run edg agent download model thing devic xgboost creat model xgboost model file download devic troubl start canva give info csv format clue predict model result try open csv file canva predict data complet differ realist pip instal xgboost import xgboost xgb filenam solar predict data csv dpredict xgb dmatrix filenam format csv model xgb booster model load model xgboost model result model predict dpredict print predict result print result read column order matter csv contain header close canva result tri panda pip instal xgboost import xgboost xgb import panda filenam solar predict data csv read csv filenam index col header dpredict xgb dmatrix enabl categor true model xgb booster model load model xgboost model result model predict dpredict pred interact true print predict result print print result give follow error valueerror datafram dtype data int float bool categori categor type suppli dmatrix paramet enabl categor set true invalid column thingnam honest complet stuck hope advic clue proce thank kind regard hacor",
        "Question_preprocessed_content":"canva model usag edg devic python wai want ask question subject therefor canva work easi give nice result model try predict solar power product base time aw iot thingnam cloud percentag temperatur csv data measur iot thing canva upload csv build model easi us predict tab upload csv import column contain api weather data futur moment data canva predict real realist number model nice build want model core devic predict site best model locat share link junyp read aw doc option run model edg devic run edg compon run model compon write infer compon run edg agent download model thing devic creat model file download devic troubl start canva give info csv format clue predict model result try open csv file canva predict data complet realist read column order csv contain header close canva result tri give honest complet stuck hope advic clue thank kind regard hacor",
        "Question_gpt_summary_original":"The user is trying to use an AWS SageMaker Canvas app to predict solar power production based on data from an IoT device. They have successfully built a model in SageMaker Canvas and are now trying to move the model to their Greengrass Core Device to do predictions on site. However, they are having trouble making predictions using the model on the device, as they do not know how to format the CSV data correctly. They have tried using xgboost and pandas libraries but have not been successful. They are seeking advice on how to proceed.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"VertexAI Batch Inference Failing for Custom Container Model",
        "Question_body":"<p>I'm having trouble executing VertexAI's batch inference, despite endpoint deployment and inference working perfectly. My TensorFlow model has been trained in a custom Docker container with the following arguments:<\/p>\n<pre><code>aiplatform.CustomContainerTrainingJob(\n        display_name=display_name,\n        command=[&quot;python3&quot;, &quot;train.py&quot;],\n        container_uri=container_uri,\n        model_serving_container_image_uri=container_uri,\n        model_serving_container_environment_variables=env_vars,\n        model_serving_container_predict_route='\/predict',\n        model_serving_container_health_route='\/health',\n        model_serving_container_command=[\n            &quot;gunicorn&quot;,\n            &quot;src.inference:app&quot;,\n            &quot;--bind&quot;,\n            &quot;0.0.0.0:5000&quot;,\n            &quot;-k&quot;,\n            &quot;uvicorn.workers.UvicornWorker&quot;,\n            &quot;-t&quot;,\n            &quot;6000&quot;,\n        ],\n        model_serving_container_ports=[5000],\n)\n<\/code><\/pre>\n<p>I have a Flask endpoint defined for predict and health essentially defined below:<\/p>\n<pre><code>@app.get(f&quot;\/health&quot;)\ndef health_check_batch():\n    return 200\n\n@app.post(f&quot;\/predict&quot;)\ndef predict_batch(request_body: dict):\n    pred_df = pd.DataFrame(request_body['instances'],\n                           columns = request_body['parameters']['columns'])\n    # do some model inference things\n    return {&quot;predictions&quot;: predictions.tolist()}\n<\/code><\/pre>\n<p>As described, when training a model and deploying to an endpoint, I can successfully hit the API with JSON schema like:<\/p>\n<pre><code>{&quot;instances&quot;:[[1,2], [1,3]], &quot;parameters&quot;:{&quot;columns&quot;:[&quot;first&quot;, &quot;second&quot;]}}\n<\/code><\/pre>\n<p>This also works when using the endpoint Python SDK and feeding in instances\/parameters as functional arguments.<\/p>\n<p>However, I've tried performing batch inference with a CSV file and a JSONL file, and every time it fails with an Error Code 3. I can't find logs on why it failed in Logs Explorer either. I've read through all the documentation I could find and have seen other's successfully invoke batch inference, but haven't been able to find a guide. Does anyone have recommendations on batch file structure or the structure of my APIs? Thank you!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_created_time":1650785345693,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":111.0,
        "Poster_created_time":1467136510360,
        "Poster_location":null,
        "Poster_reputation_count":33.0,
        "Poster_view_count":7.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71986344",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"vertexai batch infer fail custom contain model have troubl execut vertexai batch infer despit endpoint deploy infer work perfectli tensorflow model train custom docker contain follow argument aiplatform customcontainertrainingjob displai displai command python train contain uri contain uri model serv contain imag uri contain uri model serv contain environ variabl env var model serv contain predict rout predict model serv contain health rout health model serv contain command gunicorn src infer app bind uvicorn worker uvicornwork model serv contain port flask endpoint defin predict health essenti defin app health def health check batch return app post predict def predict batch request bodi dict pred datafram request bodi instanc column request bodi paramet column model infer thing return predict predict tolist describ train model deploi endpoint successfulli hit api json schema like instanc paramet column second work endpoint python sdk feed instanc paramet function argument tri perform batch infer csv file jsonl file time fail error code log fail log explor read document seen successfulli invok batch infer haven abl guid recommend batch file structur structur api thank",
        "Question_preprocessed_content":"vertexai batch infer fail custom contain model have troubl execut vertexai batch infer despit endpoint deploy infer work perfectli tensorflow model train custom docker contain argument flask endpoint defin predict health defin describ train model deploi endpoint hit api json schema like work endpoint python sdk function argument tri perform batch infer csv file jsonl file time fail code log fail log explor read document invok batch infer haven abl guid batch file structur structur api thank",
        "Question_gpt_summary_original":"The user is facing issues while performing batch inference using VertexAI despite successful endpoint deployment and inference. The TensorFlow model has been trained in a custom Docker container, and the Flask endpoint is defined for predict and health. The user has tried performing batch inference with a CSV file and a JSONL file, but it fails every time with an Error Code 3, and the logs do not provide any information on why it failed. The user is seeking recommendations on batch file structure or API structure to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Website section \"organizations using MLflow\"",
        "Question_body":"Hi,\n\n\nI am from https:\/\/mlcertific.com which provides the certification on machine learning\u00a0 we are using mlflow in our organisation and want to contribute to it. Please add our organization\u00a0in the list\u00a0 .\n\n\nThanks,\nhttps:\/\/mlcertific.com\/",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1604036380000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":25.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/AL3eITG_MP8",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"websit section organ http mlcertif com provid certif machin learn organis want contribut add organizationin list thank http mlcertif com",
        "Question_preprocessed_content":"websit section organ provid certif machin learn organis want contribut organizationin list thank",
        "Question_gpt_summary_original":"The user is requesting to have their organization added to the \"organizations using MLflow\" section on a website. They are from a company that provides certification on machine learning and are currently using MLflow in their organization.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Package usage in AzureML: ggplot2 and ggrepel",
        "Question_body":"<p>I have a code in Azure ML which uses the function <code>ggrepel<\/code>. That function requires the version 2.0.0 of the package <code>ggplot2<\/code>. When I try to use it I obtain the error:<\/p>\n\n<pre><code>Error 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\npackage 'ggplot2' 1.0.0 was found, but &gt;= 2.0.0 is required by 'ggrepel'\n<\/code><\/pre>\n\n<p>So, what I did was: <\/p>\n\n<ol>\n<li>updated the R package <code>ggplot2<\/code> of my local version (is there a command to use to check the version of a package?);<\/li>\n<li>taken the folder related to <code>ggplot2<\/code>, and put it in the zip file I pass to Azure. So the x.zip wil contain generic functions, then ggrepel.zip and ggplot2.zip.<\/li>\n<\/ol>\n\n<p>At the end I have written:<\/p>\n\n<pre><code>install.packages(\"src\/ggplot2.zip\",lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggrepel.zip\",lib = \".\", repos = NULL, verbose = TRUE)\nlibrary(ggrepel, lib.loc=\".\", verbose=TRUE)\nlibrary(ggplot2, lib.loc=\".\", verbose=TRUE)\n<\/code><\/pre>\n\n<p>It seems working for ggrepel, but not for ggplot, because I obtain the same issue shown at the beginning. It's like the system does not see the updated package, but the default ggplot2 of Azure ML.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1465908944767,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":142.0,
        "Poster_created_time":1436432728608,
        "Poster_location":"Colleferro, Italy",
        "Poster_reputation_count":809.0,
        "Poster_view_count":361.0,
        "Answer_body":"<p>At the end I have solved adding an additional package. The problem is in the fact that you have to check the log of the error and not only the error output (that does not insert all you need). At the end I have solved in this way:<\/p>\n\n<pre><code>install.packages(\"src\/scales_0.4.0.zip\" ,lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggplot2_2.1.0.zip\",lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggrepel.zip\"      ,lib = \".\", repos = NULL, verbose = TRUE)\n\nlibrary(scales,  lib.loc=\".\", verbose=TRUE)\nlibrary(ggplot2, lib.loc=\".\", verbose=TRUE)\nlibrary(ggrepel, lib.loc=\".\", verbose=TRUE)\n...\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1466607112096,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1436432728608,
        "Answerer_location":"Colleferro, Italy",
        "Answerer_reputation_count":809.0,
        "Answerer_view_count":361.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37812686",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"packag usag ggplot ggrepel code us function ggrepel function requir version packag ggplot try us obtain error error follow error occur evalu script start error messag packag ggplot requir ggrepel updat packag ggplot local version command us check version packag taken folder relat ggplot zip file pass azur zip wil contain gener function ggrepel zip ggplot zip end written instal packag src ggplot zip lib repo null verbos true instal packag src ggrepel zip lib repo null verbos true librari ggrepel lib loc verbos true librari ggplot lib loc verbos true work ggrepel ggplot obtain issu shown begin like updat packag default ggplot",
        "Question_preprocessed_content":"packag usag code us function function requir version packag try us obtain updat packag local version taken folder relat zip file azur wil contain gener function zip end work obtain shown like updat packag default",
        "Question_gpt_summary_original":"The user is facing an issue while using the function 'ggrepel' in Azure ML, which requires version 2.0.0 of the package 'ggplot2'. The user tried updating the package and including it in the zip file passed to Azure, but the system still uses the default version of ggplot2 and shows the same error.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"unable to install AzureStor in R script in Azure ML Studio",
        "Question_body":"<p>I got this error when trying to install older version  <\/p>\n<p>0063: The following error occurred during evaluation of R script:  <br \/>\n---------- Start of error message from R ----------  <br \/>\n'AzureStor' is not a valid installed package  <\/p>\n<p>when tried to install newer version of zip downloaded from cran. then it was giving error can not read version 3 <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1619361821370,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/370607\/unable-to-install-azurestor-in-r-script-in-azure-m",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl instal azurestor script studio got error try instal older version follow error occur evalu script start error messag azurestor valid instal packag tri instal newer version zip download cran give error read version",
        "Question_preprocessed_content":"unabl azurestor script studio got try older version evalu script start azurestor valid packag tri newer version zip download cran give read version",
        "Question_gpt_summary_original":"The user is unable to install AzureStor in an R script in Azure ML Studio. They encountered an error message stating that AzureStor is not a valid installed package. When attempting to install a newer version of the package downloaded from CRAN, they received an error message stating that version 3 could not be read.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Why can't a label the rest of my set?",
        "Question_body":"<p>Can anyone suggest why I can't label the rest of my pending images??    <\/p>\n<p>See screenshot for example..    <\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/82041-image.png?platform=QnA\" alt=\"82041-image.png\" \/>    <\/p>\n<p>Regards,    <br \/>\nChris<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":6.0,
        "Question_created_time":1616799706400,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/333975\/why-cant-a-label-the-rest-of-my-set",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"label rest set suggest label rest pend imag screenshot exampl regard chri",
        "Question_preprocessed_content":"label rest set label rest pend imag regard chri",
        "Question_gpt_summary_original":"The user is facing an issue with labeling the rest of their pending images and is seeking suggestions for a solution. A screenshot has been provided for reference.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to strip HTML from a text column in Azure ML Execute Python Script step",
        "Question_body":"<p>If I have a column of data of type string in an incoming Azure ML dataset that contains HTML tags screwing up my results, how can I remove those tags?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1484610622880,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":325.0,
        "Poster_created_time":1265234764768,
        "Poster_location":"Denver, CO",
        "Poster_reputation_count":30577.0,
        "Poster_view_count":6460.0,
        "Answer_body":"<p>Like this:<\/p>\n\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n  dataframe1[1] = dataframe1['text'].str.replace('&lt;[^&lt;]+?&gt;', ' ', case=False)\n  return dataframe1,\n<\/code><\/pre>\n\n<p>Remember to precede the <code>Execute Python Script<\/code> step with <code>Clean Missing Data<\/code> step and change the action to remove the entire row (if appropriate). This is important because the <code>Execute Python Script<\/code> step cannot return an empty <code>dataframe<\/code>. Only you know your data, in this case.<\/p>\n\n<p>Let me also point out that the <code>Preprocessing Text<\/code> step allows you to apply a Regular Expression. That is another alternative that might be right for your situation.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1484610622880,
        "Answer_last_edit_time":1484679092912,
        "Answer_score_count":1.0,
        "Answerer_created_time":1265234764768,
        "Answerer_location":"Denver, CO",
        "Answerer_reputation_count":30577.0,
        "Answerer_view_count":6460.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41686871",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"strip html text column execut python script step column data type string incom dataset contain html tag screw result remov tag",
        "Question_preprocessed_content":"strip html text column execut python script step column data type string incom dataset contain html tag screw result remov tag",
        "Question_gpt_summary_original":"The user is facing a challenge in removing HTML tags from a string column in an incoming Azure ML dataset to avoid interference with the results.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Trying to run wandb on azure ml, running into issues",
        "Question_body":"<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py\", line 1133, in init\n    run = wi.init()\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py\", line 787, in init\n    run_start_result = run_start_handle.wait(timeout=30)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/lib\/mailbox.py\", line 271, in wait\n    raise MailboxError(\"transport failed\")\nwandb.errors.MailboxError: transport failed\nwandb: ERROR Abnormal program exit\n2023-02-13 22:32:43,972 - mmseg - INFO - Loaded 20000 images\n\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/mmseg\/models\/backbones\/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/mmseg\/models\/losses\/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n  warnings.warn(\n2023-02-13 22:32:52,439 - mmseg - INFO - Loaded 2500 images\n2023-02-13 22:32:52,458 - mmseg - INFO - Start running, host: azureuser@vardhan-cvml, work_dir: \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/work_dirs\/logs\/deeplabv3plus\n2023-02-13 22:32:52,459 - mmseg - INFO - Hooks will be executed in the following order:\nbefore_run:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_train_epoch:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_train_iter:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n -------------------- \nafter_train_iter:\n(ABOVE_NORMAL) OptimizerHook                      \n(NORMAL      ) CheckpointHook                     \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nafter_train_epoch:\n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_val_epoch:\n(LOW         ) IterTimerHook                      \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_epoch:\n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nafter_run:\n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \n2023-02-13 22:32:52,460 - mmseg - INFO - workflow: [('train', 1)], max: 50000 iters\n2023-02-13 22:32:52,460 - mmseg - INFO - Checkpoints will be saved to \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/work_dirs\/logs\/deeplabv3plus by HardDiskBackend.\n2023-02-13 22:32:52.816987: I tensorflow\/core\/platform\/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-13 22:32:59.646354: W tensorflow\/compiler\/xla\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/cv2\/..\/..\/lib64:\n2023-02-13 22:32:59.646501: W tensorflow\/compiler\/xla\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/cv2\/..\/..\/lib64:\n2023-02-13 22:32:59.646517: W tensorflow\/compiler\/tf2tensorrt\/utils\/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\nwandb: Currently logged in as: don_v. Use `wandb login --relogin` to force relogin\nThread HandlerThread:\nTraceback (most recent call last):\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 49, in run\n    self._run()\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/internal.py\", line 280, in _process\n    self._hm.handle(record)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 136, in handle\n    handler(record)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 146, in handle_request\n    handler(record)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/handler.py\", line 695, in handle_request_run_start\n    self._system_monitor.probe(publish=True)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/system\/system_monitor.py\", line 186, in probe\n    self.system_info.publish(system_info)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/system\/system_info.py\", line 252, in publish\n    self._save_patches()\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/internal\/system\/system_info.py\", line 134, in _save_patches\n    if self.git.dirty:\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/lib\/git.py\", line 76, in dirty\n    return self.repo.is_dirty()\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/git\/repo\/base.py\", line 795, in is_dirty\n    if osp.isfile(self.index.path) and len(self.git.diff(\"--cached\", *default_args)):\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/git\/cmd.py\", line 696, in &lt;lambda&gt;\n    return lambda *args, **kwargs: self._call_process(name, *args, **kwargs)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/git\/cmd.py\", line 1270, in _call_process\n    return self.execute(call, **exec_kwargs)\n  File \"\/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/git\/cmd.py\", line 1064, in execute\n    raise GitCommandError(redacted_command, status, stderr_value, stdout_value)\ngit.exc.GitCommandError: Cmd('git') failed due to: exit code(129)\n  cmdline: git diff --cached --abbrev=40 --full-index --raw\n  stderr: 'error: unknown option `cached'\nusage: git diff --no-index [&lt;options&gt;] &lt;path&gt; &lt;path&gt;\n\nDiff output format options\n    -p, --patch           generate patch\n    -s, --no-patch        suppress diff output\n    -u                    generate patch\n    -U, --unified[=&lt;n&gt;]   generate diffs with &lt;n&gt; lines context\n    -W, --function-context\n                          generate diffs with &lt;n&gt; lines context\n    --raw                 generate the diff in raw format\n    --patch-with-raw      synonym for '-p --raw'\n    --patch-with-stat     synonym for '-p --stat'\n    --numstat             machine friendly --stat\n    --shortstat           output only the last line of --stat\n    -X, --dirstat[=&lt;param1,param2&gt;...]\n                          output the distribution of relative amount of changes for each sub-directory\n    --cumulative          synonym for --dirstat=cumulative\n    --dirstat-by-file[=&lt;param1,param2&gt;...]\n                          synonym for --dirstat=files,param1,param2...\n    --check               warn if changes introduce conflict markers or whitespace errors\n    --summary             condensed summary such as creations, renames and mode changes\n    --name-only           show only names of changed files\n    --name-status         show only names and status of changed files\n    --stat[=&lt;width&gt;[,&lt;name-width&gt;[,&lt;count&gt;]]]\n                          generate diffstat\n    --stat-width &lt;width&gt;  generate diffstat with a given width\n    --stat-name-width &lt;width&gt;\n                          generate diffstat with a given name width\n    --stat-graph-width &lt;width&gt;\n                          generate diffstat with a given graph width\n    --stat-count &lt;count&gt;  generate diffstat with limited lines\n    --compact-summary     generate compact summary in diffstat\n    --binary              output a binary diff that can be applied\n    --full-index          show full pre- and post-image object names on the \"index\" lines\n    --color[=&lt;when&gt;]      show colored diff\n    --ws-error-highlight &lt;kind&gt;\n                          highlight whitespace errors in the 'context', 'old' or 'new' lines in the diff\n    -z                    do not munge pathnames and use NULs as output field terminators in --raw or --numstat\n    --abbrev[=&lt;n&gt;]        use &lt;n&gt; digits to display object names\n    --src-prefix &lt;prefix&gt;\n                          show the given source prefix instead of \"a\/\"\n    --dst-prefix &lt;prefix&gt;\n                          show the given destination prefix instead of \"b\/\"\n    --line-prefix &lt;prefix&gt;\n                          prepend an additional prefix to every line of output\n    --no-prefix           do not show any source or destination prefix\n    --inter-hunk-context &lt;n&gt;\n                          show context between diff hunks up to the specified number of lines\n    --output-indicator-new &lt;char&gt;\n                          specify the character to indicate a new line instead of '+'\n    --output-indicator-old &lt;char&gt;\n                          specify the character to indicate an old line instead of '-'\n    --output-indicator-context &lt;char&gt;\n                          specify the character to indicate a context instead of ' '\n\nDiff rename options\n    -B, --break-rewrites[=&lt;n&gt;[\/&lt;m&gt;]]\n                          break complete rewrite changes into pairs of delete and create\n    -M, --find-renames[=&lt;n&gt;]\n                          detect renames\n    -D, --irreversible-delete\n                          omit the preimage for deletes\n    -C, --find-copies[=&lt;n&gt;]\n                          detect copies\n    --find-copies-harder  use unmodified files as source to find copies\n    --no-renames          disable rename detection\n    --rename-empty        use empty blobs as rename source\n    --follow              continue listing the history of a file beyond renames\n    -l &lt;n&gt;                prevent rename\/copy detection if the number of rename\/copy targets exceeds given limit\n\nDiff algorithm options\n    --minimal             produce the smallest possible diff\n    -w, --ignore-all-space\n                          ignore whitespace when comparing lines\n    -b, --ignore-space-change\n                          ignore changes in amount of whitespace\n    --ignore-space-at-eol\n                          ignore changes in whitespace at EOL\n    --ignore-cr-at-eol    ignore carrier-return at the end of line\n    --ignore-blank-lines  ignore changes whose lines are all blank\n    -I, --ignore-matching-lines &lt;regex&gt;\n                          ignore changes whose all lines match &lt;regex&gt;\n    --indent-heuristic    heuristic to shift diff hunk boundaries for easy reading\n    --patience            generate diff using the \"patience diff\" algorithm\n    --histogram           generate diff using the \"histogram diff\" algorithm\n    --diff-algorithm &lt;algorithm&gt;\n                          choose a diff algorithm\n    --anchored &lt;text&gt;     generate diff using the \"anchored diff\" algorithm\n    --word-diff[=&lt;mode&gt;]  show word diff, using &lt;mode&gt; to delimit changed words\n    --word-diff-regex &lt;regex&gt;\n                          use &lt;regex&gt; to decide what a word is\n    --color-words[=&lt;regex&gt;]\n                          equivalent to --word-diff=color --word-diff-regex=&lt;regex&gt;\n    --color-moved[=&lt;mode&gt;]\n                          moved lines of code are colored differently\n    --color-moved-ws &lt;mode&gt;\n                          how white spaces are ignored in --color-moved\n\nOther diff options\n    --relative[=&lt;prefix&gt;]\n                          when run from subdir, exclude changes outside and show relative paths\n    -a, --text            treat all files as text\n    -R                    swap two inputs, reverse the diff\n    --exit-code           exit with 1 if there were differences, 0 otherwise\n    --quiet               disable all output of the program\n    --ext-diff            allow an external diff helper to be executed\n    --textconv            run external text conversion filters when comparing binary files\n    --ignore-submodules[=&lt;when&gt;]\n                          ignore changes to submodules in the diff generation\n    --submodule[=&lt;format&gt;]\n                          specify how differences in submodules are shown\n    --ita-invisible-in-index\n                          hide 'git add -N' entries from the index\n    --ita-visible-in-index\n                          treat 'git add -N' entries as real in the index\n    -S &lt;string&gt;           look for differences that change the number of occurrences of the specified string\n    -G &lt;regex&gt;            look for differences that change the number of occurrences of the specified regex\n    --pickaxe-all         show all changes in the changeset with -S or -G\n    --pickaxe-regex       treat &lt;string&gt; in -S as extended POSIX regular expression\n    -O &lt;file&gt;             control the order in which files appear in the output\n    --rotate-to &lt;path&gt;    show the change in the specified path first\n    --skip-to &lt;path&gt;      skip the output to the specified path\n    --find-object &lt;object-id&gt;\n                          look for differences that change the number of occurrences of the specified object\n    --diff-filter [(A|C|D|M|R|T|U|X|B)...[*]]\n                          select files by diff type\n    --output &lt;file&gt;       output to a specific file\n'\nwandb: ERROR Internal wandb error: file data was not synced\nProblem at: \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/hooks\/logger\/wandb.py 83 before_run\n---------------------------------------------------------------------------\nMailboxError                              Traceback (most recent call last)\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py:1133, in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1132 try:\n-&gt; 1133     run = wi.init()\n   1134     except_exit = wi.settings._except_exit\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py:787, in _WandbInit.init(self)\n    786 # TODO: add progress to let user know we are doing something\n--&gt; 787 run_start_result = run_start_handle.wait(timeout=30)\n    788 if run_start_result is None:\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/lib\/mailbox.py:271, in MailboxHandle.wait(self, timeout, on_probe, on_progress, release, cancel)\n    270     if self._interface._transport_keepalive_failed():\n--&gt; 271         raise MailboxError(\"transport failed\")\n    273 found, abandoned = self._slot._get_and_clear(timeout=wait_timeout)\n\nMailboxError: transport failed\n\nThe above exception was the direct cause of the following exception:\n\nException                                 Traceback (most recent call last)\nInput In [8], in &lt;cell line: 20&gt;()\n     14 model.CLASSES = datasets[0].CLASSES\n     16 # Create work_dir\n     17 # mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n---&gt; 20 train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n     21                 meta=dict())\n\nFile \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/mmseg\/apis\/train.py:194, in train_segmentor(model, dataset, cfg, distributed, validate, timestamp, meta)\n    192 elif cfg.load_from:\n    193     runner.load_checkpoint(cfg.load_from)\n--&gt; 194 runner.run(data_loaders, cfg.workflow)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/iter_based_runner.py:126, in IterBasedRunner.run(self, data_loaders, workflow, max_iters, **kwargs)\n    122 self.logger.info('Hooks will be executed in the following order:\\n%s',\n    123                  self.get_hook_info())\n    124 self.logger.info('workflow: %s, max: %d iters', workflow,\n    125                  self._max_iters)\n--&gt; 126 self.call_hook('before_run')\n    128 iter_loaders = [IterLoader(x) for x in data_loaders]\n    130 self.call_hook('before_epoch')\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/base_runner.py:317, in BaseRunner.call_hook(self, fn_name)\n    310 \"\"\"Call all hooks.\n    311 \n    312 Args:\n    313     fn_name (str): The function name in each hook to be called, such as\n    314         \"before_train_epoch\".\n    315 \"\"\"\n    316 for hook in self._hooks:\n--&gt; 317     getattr(hook, fn_name)(self)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/dist_utils.py:135, in master_only.&lt;locals&gt;.wrapper(*args, **kwargs)\n    133 rank, _ = get_dist_info()\n    134 if rank == 0:\n--&gt; 135     return func(*args, **kwargs)\n\nFile \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/vardhan-cvml\/code\/Users\/Vardhan.Dongre\/mmsegmentation\/mmseg\/core\/hook\/wandblogger_hook.py:106, in MMSegWandbHook.before_run(self, runner)\n    104 @master_only\n    105 def before_run(self, runner):\n--&gt; 106     super(MMSegWandbHook, self).before_run(runner)\n    108     # Check if EvalHook and CheckpointHook are available.\n    109     for hook in runner.hooks:\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/dist_utils.py:135, in master_only.&lt;locals&gt;.wrapper(*args, **kwargs)\n    133 rank, _ = get_dist_info()\n    134 if rank == 0:\n--&gt; 135     return func(*args, **kwargs)\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/mmcv\/runner\/hooks\/logger\/wandb.py:83, in WandbLoggerHook.before_run(self, runner)\n     81     self.import_wandb()\n     82 if self.init_kwargs:\n---&gt; 83     self.wandb.init(**self.init_kwargs)  # type: ignore\n     84 else:\n     85     self.wandb.init()\n\nFile \/anaconda\/envs\/azureml_py310_sdkv2\/lib\/python3.10\/site-packages\/wandb\/sdk\/wandb_init.py:1170, in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1168         if except_exit:\n   1169             os._exit(1)\n-&gt; 1170         raise Exception(\"problem\") from error_seen\n   1171 return run\n\nException: problem\n\n<\/code><\/pre>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1676327813326,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":394.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/trying-to-run-wandb-on-azure-ml-running-into-issues\/3876",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"try run run issu traceback recent file anaconda env sdkv lib python site packag sdk init line init run init file anaconda env sdkv lib python site packag sdk init line init run start result run start handl wait timeout file anaconda env sdkv lib python site packag sdk lib mailbox line wait rais mailboxerror transport fail error mailboxerror transport fail error abnorm program exit mmseg info load imag mnt batch task share root mount cluster vardhan cvml code user vardhan dongr mmsegment mmseg model backbon resnet userwarn deprecationwarn pretrain deprec us init cfg instead warn warn deprecationwarn pretrain deprec mnt batch task share root mount cluster vardhan cvml code user vardhan dongr mmsegment mmseg model loss cross entropi loss userwarn default avg non ignor fals like ignor certain label averag loss non ignor label pytorch offici cross entropi set avg non ignor true warn warn mmseg info load imag mmseg info start run host azureus vardhan cvml work dir mnt batch task share root mount cluster vardhan cvml code user vardhan dongr mmsegment work dir log deeplabvplu mmseg info hook execut follow order run high polylrupdaterhook normal checkpointhook low evalhook low textloggerhook low tensorboardloggerhook low mmseghook train epoch high polylrupdaterhook low itertimerhook low evalhook low textloggerhook low tensorboardloggerhook low mmseghook train iter high polylrupdaterhook low itertimerhook low evalhook train iter normal optimizerhook normal checkpointhook low itertimerhook low evalhook low textloggerhook low tensorboardloggerhook low mmseghook train epoch normal checkpointhook low evalhook low textloggerhook low tensorboardloggerhook low mmseghook val epoch low itertimerhook low textloggerhook low tensorboardloggerhook low mmseghook val iter low itertimerhook val iter low itertimerhook val epoch low textloggerhook low tensorboardloggerhook low mmseghook run low textloggerhook low tensorboardloggerhook low mmseghook mmseg info workflow train max iter mmseg info checkpoint save mnt batch task share root mount cluster vardhan cvml code user vardhan dongr mmsegment work dir log deeplabvplu harddiskbackend tensorflow core platform cpu featur guard tensorflow binari optim oneapi deep neural network librari onednn us follow cpu instruct perform critic oper avx fma enabl oper rebuild tensorflow appropri compil flag tensorflow compil xla stream executor platform default dso loader load dynam librari libnvinf dlerror libnvinf open share object file file directori librari path anaconda env sdkv lib python site packag lib tensorflow compil xla stream executor platform default dso loader load dynam librari libnvinf plugin dlerror libnvinf plugin open share object file file directori librari path anaconda env sdkv lib python site packag lib tensorflow compil tftensorrt util util trt warn dlopen tensorrt librari like us nvidia gpu tensorrt sure miss librari mention instal properli current log us login relogin forc relogin thread handlerthread traceback recent file anaconda env sdkv lib python site packag sdk intern intern util line run self run file anaconda env sdkv lib python site packag sdk intern intern util line run self process record file anaconda env sdkv lib python site packag sdk intern intern line process self handl record file anaconda env sdkv lib python site packag sdk intern handler line handl handler record file anaconda env sdkv lib python site packag sdk intern handler line handl request handler record file anaconda env sdkv lib python site packag sdk intern handler line handl request run start self monitor probe publish true file anaconda env sdkv lib python site packag sdk intern monitor line probe self info publish info file anaconda env sdkv lib python site packag sdk intern info line publish self save patch file anaconda env sdkv lib python site packag sdk intern info line save patch self git dirti file anaconda env sdkv lib python site packag sdk lib git line dirti return self repo dirti file anaconda env sdkv lib python site packag git repo base line dirti osp isfil self index path len self git diff cach default arg file anaconda env sdkv lib python site packag git cmd line return lambda arg kwarg self process arg kwarg file anaconda env sdkv lib python site packag git cmd line process return self execut exec kwarg file anaconda env sdkv lib python site packag git cmd line execut rais gitcommanderror redact command statu stderr valu stdout valu git exc gitcommanderror cmd git fail exit code cmdline git diff cach abbrev index raw stderr error unknown option cach usag git diff index diff output format option patch gener patch patch suppress diff output gener patch unifi gener diff line context function context gener diff line context raw gener diff raw format patch raw synonym raw patch stat synonym stat numstat machin friendli stat shortstat output line stat dirstat output distribut rel chang sub directori cumul synonym dirstat cumul dirstat file synonym dirstat file param param check warn chang introduc conflict marker whitespac error summari condens summari creation renam mode chang name chang file statu name statu chang file stat gener diffstat stat width gener diffstat given width stat width gener diffstat given width stat graph width gener diffstat given graph width stat count gener diffstat limit line compact summari gener compact summari diffstat binari output binari diff appli index pre post imag object name index line color color diff error highlight highlight whitespac error context old new line diff mung pathnam us nul output field termin raw numstat abbrev us digit displai object name src prefix given sourc prefix instead dst prefix given destin prefix instead line prefix prepend addit prefix line output prefix sourc destin prefix inter hunk context context diff hunk specifi number line output indic new specifi charact indic new line instead output indic old specifi charact indic old line instead output indic context specifi charact indic context instead diff renam option break rewrit break complet rewrit chang pair delet creat renam detect renam irrevers delet omit preimag delet copi detect copi copi harder us unmodifi file sourc copi renam disabl renam detect renam us blob renam sourc follow continu list histori file renam prevent renam copi detect number renam copi target exce given limit diff algorithm option minim produc smallest possibl diff ignor space ignor whitespac compar line ignor space chang ignor chang whitespac ignor space eol ignor chang whitespac eol ignor eol ignor carrier return end line ignor blank line ignor chang line blank ignor match line ignor chang line match indent heurist heurist shift diff hunk boundari easi read patienc gener diff patienc diff algorithm histogram gener diff histogram diff algorithm diff algorithm choos diff algorithm anchor gener diff anchor diff algorithm word diff word diff delimit chang word word diff regex us decid word color word equival word diff color word diff regex color move move line code color differ color move white space ignor color move diff option rel run subdir exclud chang outsid rel path text treat file text swap input revers diff exit code exit differ quiet disabl output program ext diff allow extern diff helper execut textconv run extern text convers filter compar binari file ignor submodul ignor chang submodul diff gener submodul specifi differ submodul shown ita invis index hide git add entri index ita visibl index treat git add entri real index look differ chang number occurr specifi string look differ chang number occurr specifi regex pickax chang changeset pickax regex treat extend posix regular express control order file appear output rotat chang specifi path skip skip output specifi path object look differ chang number occurr specifi object diff filter select file diff type output output specif file error intern error file data sync problem anaconda env sdkv lib python site packag mmcv runner hook logger run mailboxerror traceback recent file anaconda env sdkv lib python site packag sdk init init job type dir config project entiti reinit tag group note magic config exclud kei config includ kei anonym mode allow val chang resum forc tensorboard sync tensorboard monitor gym save code set try run init exit set exit file anaconda env sdkv lib python site packag sdk init init init self todo add progress let user know run start result run start handl wait timeout run start result file anaconda env sdkv lib python site packag sdk lib mailbox mailboxhandl wait self timeout probe progress releas cancel self interfac transport keepal fail rais mailboxerror transport fail abandon self slot clear timeout wait timeout mailboxerror transport fail except direct caus follow except except traceback recent input model class dataset class creat work dir mmcv mkdir exist osp abspath cfg work dir train segmentor model dataset cfg distribut fals valid true meta dict file mnt batch task share root mount cluster vardhan cvml code user vardhan dongr mmsegment mmseg api train train segmentor model dataset cfg distribut valid timestamp meta elif cfg load runner load checkpoint cfg load runner run data loader cfg workflow file anaconda env sdkv lib python site packag mmcv runner iter base runner iterbasedrunn run self data loader workflow max iter kwarg self logger info hook execut follow order self hook info self logger info workflow max iter workflow self max iter self hook run iter loader iterload data loader self hook epoch file anaconda env sdkv lib python site packag mmcv runner base runner baserunn hook self hook arg str function hook call train epoch hook self hook getattr hook self file anaconda env sdkv lib python site packag mmcv runner dist util master wrapper arg kwarg rank dist info rank return func arg kwarg file mnt batch task share root mount cluster vardhan cvml code user vardhan dongr mmsegment mmseg core hook logger hook mmseghook run self runner master def run self runner super mmseghook self run runner check evalhook checkpointhook avail hook runner hook file anaconda env sdkv lib python site packag mmcv runner dist util master wrapper arg kwarg rank dist info rank return func arg kwarg file anaconda env sdkv lib python site packag mmcv runner hook logger loggerhook run self runner self import self init kwarg self init self init kwarg type ignor self init file anaconda env sdkv lib python site packag sdk init init job type dir config project entiti reinit tag group note magic config exclud kei config includ kei anonym mode allow val chang resum forc tensorboard sync tensorboard monitor gym save code set exit exit rais except problem error seen return run except problem",
        "Question_preprocessed_content":"try run ",
        "Question_gpt_summary_original":"The user is encountering issues while trying to run wandb on Azure ML. The error message suggests that there is a problem with the transport, resulting in an abnormal program exit.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Run a pipeline using cvs files from a folder in the datastore",
        "Question_body":"<p>I want to run a model using as input CVS files in a folder (UI\/date) in the default datastore. I want the model to train based on the CVS files and to pick a random between them as each file represents an object to be randomly selected.  <\/p>\n<p>I already have in design the pipeline I want to use; is just that I want to run it with the files of the datastore and not from a tabular dataset. I have tried to call these folder by a python script using os.listdir and then read_cvs, however the path for this folder doesn\u2019t seem valid. I have done this activity in python using the path of folder in my computer and it works. But I don\u2019t know how to proceed in python.  <\/p>\n<p>Thank you for your help.  <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1630494672977,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/535935\/run-a-pipeline-using-cvs-files-from-a-folder-in-th",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"run pipelin cv file folder datastor want run model input cv file folder date default datastor want model train base cv file pick random file repres object randomli select design pipelin want us want run file datastor tabular dataset tri folder python script listdir read cv path folder doesnt valid activ python path folder work dont know proce python thank help",
        "Question_preprocessed_content":"run pipelin cv file folder datastor want run model input cv file folder default datastor want model train base cv file pick random file repres object randomli select design pipelin want us want run file datastor tabular dataset tri folder python script path folder doesnt valid activ python path folder work dont know python thank help",
        "Question_gpt_summary_original":"The user wants to run a model using CSV files from a folder in the default datastore and wants the model to randomly select a file as each file represents an object to be randomly selected. The user has designed the pipeline but is facing challenges in calling the folder using a python script and reading the CSV files. The user has tried using os.listdir and read_csv but the path for the folder doesn't seem valid. The user is seeking help to proceed with the task.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to optimize for multiple metrics in Optuna",
        "Question_body":"<p>How do I optimize for multiple metrics simultaneously inside the <code>objective<\/code> function of Optuna. For example, I am training an LGBM classifier and want to find the best hyperparameter set for all common classification metrics like F1, precision, recall, accuracy, AUC, etc.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def objective(trial):\n    # Train\n    gbm = lgb.train(param, dtrain)\n\n    preds = gbm.predict(X_test)\n    pred_labels = np.rint(preds)\n    # Calculate metrics\n    accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels)\n    recall = metrics.recall_score(pred_labels, y_test)\n    precision = metrics.precision_score(pred_labels, y_test)\n    f1 = metrics.f1_score(pred_labels, y_test, pos_label=1)\n\n    ...\n<\/code><\/pre>\n<p>How do I do it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1630917852487,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1630917952870,
        "Question_score_count":2.0,
        "Question_view_count":1887.0,
        "Poster_created_time":1565697423932,
        "Poster_location":"Uzbekistan",
        "Poster_reputation_count":602.0,
        "Poster_view_count":117.0,
        "Answer_body":"<p>After defining the grid and fitting the model with these params and generate predictions, calculate all metrics you want to optimize for:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def objective(trial):\n    param_grid = {&quot;n_estimators&quot;: trial.suggest_int(&quot;n_estimators&quot;, 2000, 10000, step=200)}\n    clf = lgbm.LGBMClassifier(objective='binary', **param_grid)\n    clf.fit(X_train, y_train)\n    preds = clf.predict(X_valid)\n    probs = clf.predict_proba(X_valid)\n \n    # Metrics\n    f1 = sklearn.metrics.f1_score(y_valid, press)\n    accuracy = ...\n    precision = ...\n    recall = ...\n    logloss = ...\n<\/code><\/pre>\n<p>and return them in the order you want:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def objective(trial):\n    ...\n\n    return f1, logloss, accuracy, precision, recall\n<\/code><\/pre>\n<p>Then, in the study object, specify whether you want to minimize or maximize each metric to <code>directions<\/code> like so:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>study = optuna.create_study(directions=['maximize', 'minimize', 'maximize', 'maximize', 'maximize'])\n\nstudy.optimize(objective, n_trials=100)\n<\/code><\/pre>\n<p>For more details, see <a href=\"https:\/\/optuna.readthedocs.io\/en\/stable\/tutorial\/20_recipes\/002_multi_objective.html#sphx-glr-tutorial-20-recipes-002-multi-objective-py\" rel=\"nofollow noreferrer\">Multi-objective Optimization with Optuna<\/a> in the documentation.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1630917852487,
        "Answer_last_edit_time":1659853446112,
        "Answer_score_count":6.0,
        "Answerer_created_time":1565697423932,
        "Answerer_location":"Uzbekistan",
        "Answerer_reputation_count":602.0,
        "Answerer_view_count":117.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69071684",
        "Tool":"Optuna",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"optim multipl metric optim multipl metric simultan insid object function exampl train lgbm classifi want best hyperparamet set common classif metric like precis recal accuraci auc def object trial train gbm lgb train param dtrain pred gbm predict test pred label rint pred calcul metric accuraci sklearn metric accuraci score test pred label recal metric recal score pred label test precis metric precis score pred label test metric score pred label test po label",
        "Question_preprocessed_content":"optim multipl metric optim multipl metric simultan insid function exampl train lgbm want best hyperparamet set metric like precis auc",
        "Question_gpt_summary_original":"The user is seeking guidance on how to optimize for multiple metrics simultaneously inside the objective function of Optuna, specifically for a scenario where they are training an LGBM classifier and want to find the best hyperparameter set for all common classification metrics like F1, precision, recall, accuracy, AUC, etc.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure Machine Learning Studio - Predict multiple values",
        "Question_body":"<p>I am trying to build a model using the designer in Azure Machine Learning Studio that will need to predict multiple values simultaneously.<\/p>\n<p>The scenario I am working with is there are a set of codes assigned to an order. When the order is audited, the codes may be adjusted (either added, removed, changed or a combination of all). What this results in is a before and after set of codes assigned to an order.<\/p>\n<p>What I want to do is feed the before and after codes plus other characteristics of the order into a model so going forward it is possible to provide suggestions to the auditor on potential changes to 'before' codes to create the 'after' codes.<\/p>\n<p>I want to understand if this can be done using the designer or if it would need to be done using code. If it can be done with the designer, how would it be done?<\/p>\n<p>With the experimentation I have done so far, I can only find ways for it to predict a single value, not a collection or values.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1643870170150,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1643895912543,
        "Question_score_count":0.0,
        "Question_view_count":48.0,
        "Poster_created_time":1559879904440,
        "Poster_location":"Melbourne VIC, Australia",
        "Poster_reputation_count":1.0,
        "Poster_view_count":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70966856",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"studio predict multipl valu try build model design studio need predict multipl valu simultan scenario work set code assign order order audit code adjust ad remov chang combin result set code assign order want feed code plu characterist order model go forward possibl provid suggest auditor potenti chang code creat code want understand design need code design experiment far wai predict singl valu collect valu",
        "Question_preprocessed_content":"studio predict multipl valu try build model design studio predict multipl valu simultan scenario work set code order order audit code adjust result set code order want code plu characterist order model go forward provid auditor potenti chang code creat code want understand design code design experiment far wai predict singl valu valu",
        "Question_gpt_summary_original":"The user is trying to build a model in Azure Machine Learning Studio that can predict multiple values simultaneously. The model needs to suggest potential changes to 'before' codes to create the 'after' codes based on a set of codes assigned to an order. The user is unsure if this can be done using the designer or if it would need to be done using code. The user has only been able to find ways for the model to predict a single value, not a collection of values.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Best practice for python package dependency?",
        "Question_body":"<p>Hi all,<\/p>\n<p>I\u2019m figuring out how to structure my project and found your tutorials a very helpful introduction.<\/p>\n<p>In them, however, you only rely on a single script for each stage, for example:<\/p>\n<pre><code class=\"lang-auto\">dvc run -d code\/xml_to_tsv.py -d data\/Posts.xml -o data\/Posts.tsv \\\n          -f prepare.dvc \\\n          python code\/xml_to_tsv.py data\/Posts.xml data\/Posts.tsv\n<\/code><\/pre>\n<p><a href=\"https:\/\/dvc.org\/doc\/tutorials\/pipelines\" rel=\"nofollow noopener\">Source<\/a><\/p>\n<p>Now my understanding is the following:<br>\nIf inside of <code>xml_to_tsv.py<\/code> are imports of some other of my libraries (e.g., a <code>my_special_xml_importer.py<\/code>), and I make changes to <code>my_special_xml_importer.py<\/code>, these changes would not be picked up by dvc, since <code>my_special_xml_importer.py<\/code> is not an explicit dependency of the stage, correct?<\/p>\n<p>What\u2019s the best practice here for bigger projects, where each DVC stage is not just contained in a single script?<\/p>\n<p>Our use case will be the following: For each stage we\u2019ll be having a jupyter notebook, which will import some of our python packages. I\u2019m assuming I should create a stage like this:<\/p>\n<pre><code class=\"lang-auto\">dvc run -d my_notebook.ipynb -d code\/my_lib.py -d data\/Posts.xml -o data\/Posts.tsv\n  -f prepare.dvc\n   papermill my_notebook.ipynb my_notebook_out.ipynb\n<\/code><\/pre>\n<p>Is this a good way, are there other ways, how are people with bigger projects dealing with this issue?<\/p>\n<p>Thanks in advance,<br>\nFabi<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_created_time":1587641178959,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":695.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/best-practice-for-python-package-dependency\/358",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"best practic python packag depend figur structur project tutori help introduct reli singl script stage exampl run code xml tsv data post xml data post tsv prepar python code xml tsv data post xml data post tsv sourc understand follow insid xml tsv import librari special xml import chang special xml import chang pick special xml import explicit depend stage correct what best practic bigger project stage contain singl script us case follow stage have jupyt notebook import python packag assum creat stage like run notebook ipynb code lib data post xml data post tsv prepar papermil notebook ipynb notebook ipynb good wai wai peopl bigger project deal issu thank advanc fabi",
        "Question_preprocessed_content":"best practic python packag depend figur structur project tutori help introduct reli singl script stage exampl sourc understand insid import librari chang chang pick explicit depend stage what best practic project stage contain singl script us case stage have jupyt import python packag creat stage like wai wai peopl project deal thank advanc fabi",
        "Question_gpt_summary_original":"The user is seeking advice on the best practice for managing dependencies in a Python project using DVC. They are concerned that changes made to a library that is not an explicit dependency of a DVC stage will not be picked up by DVC. They are asking for suggestions on how to handle this issue in larger projects where each DVC stage is not contained in a single script. The user proposes creating a stage that includes all necessary dependencies, including Jupyter notebooks and Python packages. They are seeking feedback on this approach and other ways to manage dependencies in larger projects.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Add model description when registering model after hyperdrive successful run",
        "Question_body":"<p>I have successfully trained a model on Azure Machine Learning Service using Hyperdrive that has now yielded a hyperdrive run instance<\/p>\n\n<pre><code>hyperdrive_run = exp.submit(config=hypertune_config)\nhyperdrive_run\nbest_run = hyperdrive_run.get_best_run_by_primary_metric()\n<\/code><\/pre>\n\n<p>As a next step, I would like to register a model while adding a description to the model.:<\/p>\n\n<pre><code>pumps_rf = best_run.register_model(model_name='pumps_rf', model_path='outputs\/rf.pkl')\n<\/code><\/pre>\n\n<p>There is a <code>description<\/code> column in the Models section of my AML Workspace on Azure portal but the <code>register_model<\/code> method does not seem to have a <code>description<\/code> flag. So how do I go about adding a description to the model so I see it in Azure Portal?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1550539380057,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":453.0,
        "Poster_created_time":1408574571227,
        "Poster_location":"Toronto, Canada",
        "Poster_reputation_count":2754.0,
        "Poster_view_count":124.0,
        "Answer_body":"<p>Good question :).<\/p>\n\n<p>Looking at the current version of the API, it doesn't look like you can add the description using <code>Run.register_model<\/code>, as confirmed <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run?view=azure-ml-py#register-model-model-name--model-path-none--tags-none--properties-none----kwargs-\" rel=\"nofollow noreferrer\">by the docs<\/a>. <\/p>\n\n<p>You can go around this however by registering the model using the <code>Model.register<\/code> method which, fortunately, includes an argument for <code>description<\/code> as detailed <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none-\" rel=\"nofollow noreferrer\">here<\/a>. In your case, you also need to <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#download-file-name--output-file-path-none-\" rel=\"nofollow noreferrer\">download the files<\/a> first.<\/p>\n\n<p>In short, use something like:<\/p>\n\n<pre class=\"lang-python prettyprint-override\"><code>best_run.download_file('outputs\/rf.pkl', output_file_path='.\/rf.pkl')\n\nModel.register(workspace=ws, model_path='.\/rf.pkl', model_name=\"pumps_rf\", description=\"There are many models like it, but this one is mine.\")\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Question_closed_time":1550668517447,
        "Answer_last_edit_time":1550686459150,
        "Answer_score_count":1.0,
        "Answerer_created_time":1250158552416,
        "Answerer_location":"Romania",
        "Answerer_reputation_count":7916.0,
        "Answerer_view_count":801.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54757598",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"add model descript regist model hyperdr success run successfulli train model servic hyperdr yield hyperdr run instanc hyperdr run exp submit config hypertun config hyperdr run best run hyperdr run best run primari metric step like regist model ad descript model pump best run regist model model pump model path output pkl descript column model section aml workspac azur portal regist model method descript flag ad descript model azur portal",
        "Question_preprocessed_content":"model descript regist model hyperdr run train model servic hyperdr yield hyperdr run instanc step like regist model descript column model section aml workspac azur portal method flag descript model azur portal",
        "Question_gpt_summary_original":"The user has successfully trained a model on Azure Machine Learning Service using Hyperdrive and wants to register the model while adding a description to it. However, the register_model method does not seem to have a description flag, and the user is unsure how to add a description to the model so that it appears in the Azure Portal.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS Sagemaker Project from template Model building testing and deployment failing default pipeline.",
        "Question_body":"After creating the domain and adding a user for AWS Sagemaker, I opened Sagemaker Studio and created a project using the template \"Model building Training and deployment\", project got successfully created and I also cloned the files from template to local in studio, till this point it was fine,\n\nNow, when I am seeing the pipelines, I see a pipeline already runs by default after project creation, but here this pipeline is failing with the below error from output tab :-\n\"**ClientError: Failed to invoke sagemaker:CreateProcessingJob. Error Details: The account-level service limit 'ml.m5.xlarge for processing job usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.**\" \n\nHere is the screenshot - ![Failure_Screenshot_From_project_Pipeline](\/media\/postImages\/original\/IMlUFN0FJHTuyWlUe4p5YTRw)\n\nPlease help me with this, I am new to SageMaker.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1677675538986,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1678022390643,
        "Question_score_count":0.0,
        "Question_view_count":28.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUkI4ldx2oR2OGvuMUDKiOoQ\/aws-sagemaker-project-from-template-model-building-testing-and-deployment-failing-default-pipeline",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"project templat model build test deploy fail default pipelin creat domain ad user open studio creat project templat model build train deploy project got successfulli creat clone file templat local studio till point fine see pipelin pipelin run default project creation pipelin fail error output tab clienterror fail invok createprocessingjob error detail account level servic limit xlarg process job usag instanc current util instanc request delta instanc contact aw support request increas limit screenshot failur screenshot project pipelin media postimag origin imlufnfjhtuywluepytrw help new",
        "Question_preprocessed_content":"project templat model build test deploy fail default pipelin creat domain user open studio creat project templat model build train deploy project got creat clone file templat local studio point fine pipelin pipelin run default project creation pipelin fail output tab fail invok detail level servic limit job usag instanc util instanc request delta instanc contact aw request increas help new",
        "Question_gpt_summary_original":"The user created a project using the AWS Sagemaker template \"Model building Training and deployment\" successfully. However, the default pipeline is failing with an error message stating that the account-level service limit for processing job usage is 0 instances, and the current utilization is also 0 instances. The user needs to contact AWS support to request an increase in this limit.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Why am I getting unexplained charges on my Microsoft Azure free account?",
        "Question_body":"<p>Hi, hope everyone is well. I opened an Azure free account on the 10th of January. I used the Azure portal for Azure Fundamentals and Azure AI Fundamentals. One day I noticed that I didn't have access to the AI Fundamentals on the portal only to find out that costs have been incurred on my free account. I am not sure where these costs are coming from, because when I checked my invoice, it is not giving me a clear explanation of where these costs are coming from only labeled them as &quot;other Microsoft services&quot;  <\/p>\n<p>Please if someone could provide me with some clarity as to why I am getting these charges. Thank you<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1678896697733,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi,<\/p>\n<p>Please create a new billing support request.  Below is link to open new billing support request in portal:<\/p>\n<p><a href=\"https:\/\/portal.azure.com\/#view\/Microsoft_Azure_CostManagement\/Menu\/%7E\/support\/openedBy\/AzurePortal\">https:\/\/portal.azure.com\/#view\/Microsoft_Azure_CostManagement\/Menu\/~\/support\/openedBy\/AzurePortal<\/a><\/p>\n<p>It will look similar to below sample screenshot:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/6882cb8e-c0c1-4aed-bffe-59c1e098af00?platform=QnA\" alt=\"azure new billing support request sample\" \/><\/p>\n<p>Enter summary, select Problem type, select Problem subtype, then click Next. After a delay, some potential solutions will be shown. Click <strong>Return to support request<\/strong> as shown below:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/cfc06bb3-704f-44f5-af90-c32082ab5821?platform=QnA\" alt=\"azure support request solutions page\" \/><\/p>\n<p>This will return you to the recommended solution tab. Click <strong>Next<\/strong>, as shown below:<\/p>\n<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/e17dbf4b-713a-4c8c-aa0d-6a3f60edf3ea?platform=QnA\" alt=\"azure support request after solutions page\" \/><\/p>\n<p>Fill out the information on the Additional details tab making sure your email address\/phone are correct, click <strong>Next<\/strong>, then finally click <strong>Create<\/strong>. At this point your support request will be created and you should receive a Case email from Microsoft Support and will be contacted in near future by support engineer.<\/p>\n<p>If the above was helpful, please click <strong>Accept Answer<\/strong>.<\/p>\n<p>Thanks.<\/p>\n<p>-TP<\/p>\n",
        "Answer_comment_count":1.0,
        "Question_closed_time":1678897172116,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/1189971\/why-am-i-getting-unexplained-charges-on-my-microso",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"get unexplain charg microsoft azur free account hope open azur free account januari azur portal azur fundament azur fundament dai notic access fundament portal cost incur free account sure cost come check invoic give clear explan cost come label microsoft servic provid clariti get charg thank",
        "Question_preprocessed_content":"unexplain charg microsoft azur hope open azur januari azur portal azur fundament azur fundament dai notic fundament portal cost sure cost come check invoic give clear explan cost come label microsoft servic provid clariti charg thank",
        "Question_gpt_summary_original":"The user opened a free Microsoft Azure account and used it for Azure Fundamentals and Azure AI Fundamentals. However, they noticed unexplained charges on their account labeled as \"other Microsoft services\" and are seeking clarity on where these charges are coming from.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Read only mode add dataset",
        "Question_body":"<p>My dataset folder only read mode. I dont want to active write mode. So, how can \u0131 add and track my dataset?<\/p>",
        "Question_answer_count":8,
        "Question_comment_count":null,
        "Question_created_time":1613568661758,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":810.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/read-only-mode-add-dataset\/674",
        "Tool":"DVC",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"read mode add dataset dataset folder read mode dont want activ write mode add track dataset",
        "Question_preprocessed_content":"read mode dataset dataset folder read mode dont want activ write mode track dataset",
        "Question_gpt_summary_original":"The user's dataset folder is in read-only mode and they want to know how to add and track their dataset without activating write mode.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How send to image payload to the Deep learning model using lambda and send get the Image respone",
        "Question_body":"<p>I am working on Deploying background removal using AWS lambda, I didn't understand how to create a proper image payload to model and get the response back as an image.\nplease help me with this, I am struggling with this for one week.\nhere I tried:<\/p>\n<pre><code> model_dir='model\/u2net.pth'\n    model=load_models(model_dir)\n    \n    def lambda_handler(event, context):\n        \n        url = event['url']\n        img = io.imread(url)\n        # classify image\n        img = u2net_api_call(img, model)\n        output_image = img.numpy()\n        output_image = np.uint8(output_image.transpose(1, 2, 0) * 255)\n        output_image = Image.fromarray(output_image)\n    \n      # convert the PIL image to base64\n        result = {\n          &quot;output&quot;: img_to_base64_str(output_image)\n      }\n    \n      # send the result back to the client inside the body field\n        return {\n          &quot;statusCode&quot;: 200,\n          &quot;body&quot;: json.dumps(result),\n          &quot;headers&quot;: {\n              'Content-Type': 'application\/json',\n              'Access-Control-Allow-Origin': '*'\n          }\n      }\n<\/code><\/pre>\n<p>I have deployed these with lambda and docker images, I have created the docker image and push ECR and I am adding with lambda.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1646168848977,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":32.0,
        "Poster_created_time":1583415050007,
        "Poster_location":"Bangalore, Karnataka, India",
        "Poster_reputation_count":1.0,
        "Poster_view_count":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71314659",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"send imag payload deep learn model lambda send imag respon work deploi background remov aw lambda understand creat proper imag payload model respons imag help struggl week tri model dir model unet pth model load model model dir def lambda handler event context url event url img imread url classifi imag img unet api img model output imag img numpi output imag uint output imag transpos output imag imag fromarrai output imag convert pil imag base result output img base str output imag send result client insid bodi field return statuscod bodi json dump result header content type applic json access control allow origin deploi lambda docker imag creat docker imag push ecr ad lambda",
        "Question_preprocessed_content":"send imag payload learn model lambda send imag respon work deploi background remov aw lambda understand creat proper imag payload model respons imag help tri deploi lambda docker imag creat docker imag push ecr lambda",
        "Question_gpt_summary_original":"The user is struggling to create a proper image payload to send to a deep learning model using AWS Lambda and receive the response back as an image. They have tried deploying the model with Lambda and Docker images, but are still facing difficulties.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Failing to read data from s3 to a spark dataframe in Sagemaker",
        "Question_body":"<p>I'm trying to read a csv file on an s3 bucket (for which the sagemaker notebook has full access to) into a spark dataframe however I am hitting the following issue where <code>sagemaker-spark_2.11-spark_2.2.0-1.1.1.jar<\/code> can't be found. Any tips on how to resolve this is appreciate!<\/p>\n\n<pre><code>bucket = \"mybucket\"\nprefix = \"folder\/file.csv\"\ndf = spark.read.csv(\"s3:\/\/{}\/{}\/\".format(bucket,prefix))\n\nPy4JJavaError: An error occurred while calling o388.csv.\n: java.util.ServiceConfigurationError: org.apache.spark.sql.sources.DataSourceRegister: Error reading configuration file\nat java.util.ServiceLoader.fail(ServiceLoader.java:232)\nat java.util.ServiceLoader.parse(ServiceLoader.java:309)\nat java.util.ServiceLoader.access$200(ServiceLoader.java:185)\nat java.util.ServiceLoader$LazyIterator.hasNextService(ServiceLoader.java:357)\nat java.util.ServiceLoader$LazyIterator.hasNext(ServiceLoader.java:393)\nat java.util.ServiceLoader$1.hasNext(ServiceLoader.java:474)\nat scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42)\nat scala.collection.Iterator$class.foreach(Iterator.scala:893)\nat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\nat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\nat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\nat scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)\nat scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)\nat scala.collection.AbstractTraversable.filter(Traversable.scala:104)\nat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:614)\nat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:190)\nat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:596)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:498)\nat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\nat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\nat py4j.Gateway.invoke(Gateway.java:282)\nat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\nat py4j.commands.CallCommand.execute(CallCommand.java:79)\nat py4j.GatewayConnection.run(GatewayConnection.java:238)\nat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.FileNotFoundException: \/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker_pyspark\/jars\/sagemaker-spark_2.11-spark_2.2.0-1.1.1.jar (No such file or directory)\n    at java.util.zip.ZipFile.open(Native Method)\n    at java.util.zip.ZipFile.&lt;init&gt;(ZipFile.java:219)\n    at java.util.zip.ZipFile.&lt;init&gt;(ZipFile.java:149)\n    at java.util.jar.JarFile.&lt;init&gt;(JarFile.java:166)\n    at java.util.jar.JarFile.&lt;init&gt;(JarFile.java:103)\n    at sun.net.www.protocol.jar.URLJarFile.&lt;init&gt;(URLJarFile.java:93)\n    at sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:69)\n    at sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:84)\n    at sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:122)\n    at sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:150)\n    at java.net.URL.openStream(URL.java:1045)\n    at java.util.ServiceLoader.parse(ServiceLoader.java:304)\n    ... 26 more\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1532387294417,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":1532387921180,
        "Question_score_count":0.0,
        "Question_view_count":2283.0,
        "Poster_created_time":1444524456120,
        "Poster_location":"Los Angeles, CA, USA",
        "Poster_reputation_count":973.0,
        "Poster_view_count":82.0,
        "Answer_body":"<p>(Making comment to the original question as answer)<\/p>\n\n<p>It looks like a jupyter kernel issue. I had a similar issue and I used <code>Sparkmagic (pyspark)<\/code> kernel instead of <code>Sparkmagic (pyspark3)<\/code> and it is working fine. Follow instructions on this <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/build-amazon-sagemaker-notebooks-backed-by-spark-in-amazon-emr\/\" rel=\"nofollow noreferrer\">blog<\/a> and see if it helps.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1532493818792,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1458100127643,
        "Answerer_location":null,
        "Answerer_reputation_count":1083.0,
        "Answerer_view_count":86.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51488308",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"fail read data spark datafram try read csv file bucket notebook access spark datafram hit follow issu spark spark jar tip resolv appreci bucket mybucket prefix folder file csv spark read csv format bucket prefix pyjjavaerror error occur call csv java util serviceconfigurationerror org apach spark sql sourc datasourceregist error read configur file java util serviceload fail serviceload java java util serviceload pars serviceload java java util serviceload access serviceload java java util serviceload lazyiter hasnextservic serviceload java java util serviceload lazyiter hasnext serviceload java java util serviceload hasnext serviceload java scala collect convert wrapper jiteratorwrapp hasnext wrapper scala scala collect iter class foreach iter scala scala collect abstractiter foreach iter scala scala collect iterablelik class foreach iterablelik scala scala collect abstractiter foreach iter scala scala collect traversablelik class filterimpl traversablelik scala scala collect traversablelik class filter traversablelik scala scala collect abstracttravers filter travers scala org apach spark sql execut datasourc datasourc lookupdatasourc datasourc scala org apach spark sql dataframeread load dataframeread scala org apach spark sql dataframeread csv dataframeread scala sun reflect nativemethodaccessorimpl invok nativ method sun reflect nativemethodaccessorimpl invok nativemethodaccessorimpl java sun reflect delegatingmethodaccessorimpl invok delegatingmethodaccessorimpl java java lang reflect method invok method java pyj reflect methodinvok invok methodinvok java pyj reflect reflectionengin invok reflectionengin java pyj gatewai invok gatewai java pyj command abstractcommand invokemethod abstractcommand java pyj command callcommand execut callcommand java pyj gatewayconnect run gatewayconnect java java lang thread run thread java caus java filenotfoundexcept home user anaconda env python lib python site packag pyspark jar spark spark jar file directori java util zip zipfil open nativ method java util zip zipfil zipfil java java util zip zipfil zipfil java java util jar jarfil jarfil java java util jar jarfil jarfil java sun net www protocol jar urljarfil urljarfil java sun net www protocol jar urljarfil getjarfil urljarfil java sun net www protocol jar jarfilefactori jarfilefactori java sun net www protocol jar jarurlconnect connect jarurlconnect java sun net www protocol jar jarurlconnect getinputstream jarurlconnect java java net url openstream url java java util serviceload pars serviceload java",
        "Question_preprocessed_content":"fail read data spark datafram try read csv file bucket spark datafram tip resolv",
        "Question_gpt_summary_original":"The user is facing an issue while trying to read a CSV file from an S3 bucket into a Spark dataframe in Sagemaker. The error message indicates that the sagemaker-spark_2.11-spark_2.2.0-1.1.1.jar file cannot be found, resulting in a java.util.ServiceConfigurationError. The user is seeking tips on how to resolve this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Error while accessing the dataset from a datastore",
        "Question_body":"<p>I have tried to read the dataset from datastore. Also tried to create the dataset also.<\/p>\n<p>The code for reading the dataset is below<\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.from_config()\ndatastore = Datastore.get(ws, 'qdataset')\n<\/code><\/pre>\n<p>It works fine still now.<\/p>\n<pre><code>from azureml.core.dataset import Dataset\nsix_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')\n<\/code><\/pre>\n<p>Also i have tried from <code>azureml.core import Dataset<\/code><\/p>\n<p>It shows the following error:<\/p>\n<p>2021-04-29 11:56:47.284077 | ActivityCompleted: Activity=_dataflow, HowEnded=Failure, Duration=0.0 [ms], Info = {'activity_id': 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'activity_name': '_dataflow', 'activity_type': 'InternalCall', 'app_name': 'dataset', 'source': 'azureml.dataset', 'version': '1.27.0', 'dataprepVersion': '2.14.2', 'subscription': '', 'run_id': '', 'resource_group': '', 'workspace_name': '', 'experiment_id': '', 'location': '', 'completionStatus': 'Failure', 'durationMs': 962.01}, Exception=AttributeError; module 'azureml.dataprep' has no attribute 'api'<\/p>\n<hr \/>\n<p>AttributeError Traceback (most recent call last)  <br \/>\n&lt;ipython-input-34-ac7a8d35da4d&gt; in &lt;module&gt;  <br \/>\n1 from azureml.core.dataset import Dataset  <br \/>\n----&gt; 2 six_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in get_by_name(workspace, name, version)  <br \/>\n87 :rtype: typing.Union[azureml.data.TabularDataset, azureml.data.FileDataset]  <br \/>\n88 &quot;&quot;&quot;  <br \/>\n---&gt; 89 dataset = AbstractDataset._get_by_name(workspace, name, version)  <br \/>\n90 AbstractDataset._track_lineage([dataset])  <br \/>\n91 return dataset<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _get_by_name(workspace, name, version)  <br \/>\n652 if not success:  <br \/>\n653 raise result  <br \/>\n--&gt; 654 dataset = _dto_to_dataset(workspace, result)  <br \/>\n655 warn_deprecated_blocks(dataset)  <br \/>\n656 return dataset<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_dataset_rest_helper.py in _dto_to_dataset(workspace, dto)  <br \/>\n93 registration=registration)  <br \/>\n94 if dto.dataset_type == _DATASET_TYPE_FILE:  <br \/>\n---&gt; 95 return FileDataset._create(  <br \/>\n96 definition=dataflow_json,  <br \/>\n97 properties=dto.latest.properties,<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _create(cls, definition, properties, registration, telemetry_info)  <br \/>\n555 from azureml.data._partition_format import parse_partition_format  <br \/>\n556  <br \/>\n--&gt; 557 steps = dataset._dataflow._get_steps()  <br \/>\n558 partition_keys = []  <br \/>\n559 for step in steps:<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(*args, **kwargs)  <br \/>\n127 with _LoggerFactory.track_activity(logger, func.<strong>name<\/strong>, activity_type, custom_dimensions) as al:  <br \/>\n128 try:  <br \/>\n--&gt; 129 return func(*args, **kwargs)  <br \/>\n130 except Exception as e:  <br \/>\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):<\/p>\n<p>~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _dataflow(self)  <br \/>\n215 raise UserErrorException('Dataset definition is missing. Please check how the dataset is created.')  <br \/>\n216 if self._registration and self._registration.workspace:  <br \/>\n--&gt; 217 dataprep().api._datastore_helper._set_auth_type(self._registration.workspace)  <br \/>\n218 if not isinstance(self._definition, dataprep().Dataflow):  <br \/>\n219 try:<\/p>\n<p>AttributeError: module 'azureml.dataprep' has no attribute 'api'<\/p>\n<p>Please give a solution to solve this<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1619698599813,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>It now worked..   <br \/>\nWe need to install azure-ml-api-sdk using this command  <\/p>\n<p>pip install azure-ml-api-sdk  <\/p>\n",
        "Answer_comment_count":0.0,
        "Question_closed_time":1619702571567,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/377203\/error-while-accessing-the-dataset-from-a-datastore",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error access dataset datastor tri read dataset datastor tri creat dataset code read dataset core import workspac workspac config datastor datastor qdataset work fine core dataset import dataset dataset dataset workspac combin classifi tri core import dataset show follow error activitycomplet activ dataflow howend failur durat info activ xxxxxxxx xxxx xxxx xxxx xxxxxxxxxxxx activ dataflow activ type internalcal app dataset sourc dataset version dataprepvers subscript run resourc group workspac experi locat completionstatu failur durationm except attributeerror modul dataprep attribut api attributeerror traceback recent core dataset import dataset dataset dataset workspac combin classifi appdata roam python python site packag data loggerfactori wrapper arg kwarg loggerfactori track activ logger func activ type custom dimens try return func arg kwarg except hasattr activ info hasattr error code appdata roam python python site packag data abstract dataset workspac version rtype type union data tabulardataset data filedataset dataset abstractdataset workspac version abstractdataset track lineag dataset return dataset appdata roam python python site packag data abstract dataset workspac version success rais result dataset dto dataset workspac result warn deprec block dataset return dataset appdata roam python python site packag data dataset rest helper dto dataset workspac dto registr registr dto dataset type dataset type file return filedataset creat definit dataflow json properti dto latest properti appdata roam python python site packag data loggerfactori wrapper arg kwarg loggerfactori track activ logger func activ type custom dimens try return func arg kwarg except hasattr activ info hasattr error code appdata roam python python site packag data abstract dataset creat cl definit properti registr telemetri info data partit format import pars partit format step dataset dataflow step partit kei step step appdata roam python python site packag data loggerfactori wrapper arg kwarg loggerfactori track activ logger func activ type custom dimens try return func arg kwarg except hasattr activ info hasattr error code appdata roam python python site packag data abstract dataset dataflow self rais usererrorexcept dataset definit miss check dataset creat self registr self registr workspac dataprep api datastor helper set auth type self registr workspac isinst self definit dataprep dataflow try attributeerror modul dataprep attribut api solut solv",
        "Question_preprocessed_content":"dataset datastor tri read dataset datastor tri creat dataset code read dataset work fine tri show activitycomplet howend failur info except modul api traceback import dataset try return func except version rtype dataset version return dataset version rais result dataset result return dataset dto registr registr return try return func except definit properti registr import step step step try return func except rais try modul api solut solv",
        "Question_gpt_summary_original":"The user encountered an error while trying to access a dataset from a datastore using the Azure Machine Learning service. The error occurred when trying to read the dataset using the code provided, and the error message suggests that there is an issue with the dataprep module. The user is seeking a solution to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Sagemaker Data Capture does not write files",
        "Question_body":"I want to enable data capture for a specific endpoint (so far, only via the console). The endpoint works fine and also logs & returns the desired results. However, no files are written to the specified S3 location.\n\n### Endpoint Configuration ###\n\nThe endpoint is based on a training job with a scikit learn classifier. It has only one variant which is a `ml.m4.xlarge` instance type. Data Capture is enabled with a sampling percentage of 100%. As data capture storage locations I tried `s3:\/\/<bucket-name>` as well as `s3:\/\/<bucket-name>\/<some-other-path>`. With the \"Capture content type\" I tried leaving everything blank, setting `text\/csv` in \"CSV\/Text\" and `application\/json` in \"JSON\".\n\n### Endpoint Invokation ###\n\nThe endpoint is invoked in a Lambda function with a client. Here's the call:\n```\nsagemaker_body_source = {\n            \"segments\": segments,\n            \"language\": language\n        }\npayload = json.dumps(sagemaker_body_source).encode()\nresponse = self.client.invoke_endpoint(EndpointName=endpoint_name,\n                                       Body=payload,\n                                       ContentType='application\/json',\n                                       Accept='application\/json')\nresult = json.loads(response['Body'].read().decode())\nreturn result[\"predictions\"]\n```\nInternally, the endpoint uses a Flask API with an `\/invocation` path that returns the result.\n\n### Logs ###\n\nThe endpoint itself works fine and the Flask API is logging input and output:\n```\nINFO:api:body: {'segments': [<strings...>], 'language': 'de'}\n```\n\n```\nINFO:api:output: {'predictions': [{'text': 'some text', 'label': 'some_label'}, ....]}\n```",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1660135320930,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668490449198,
        "Question_score_count":0.0,
        "Question_view_count":77.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"So the issue seemed to be related to the IAM role. The default role (`ModelEndpoint-Role`) does not have access to write S3 files. It worked via the SDK since it uses another role in the sagemaker studio. I did not receive any error message about this.",
        "Answer_comment_count":0.0,
        "Question_closed_time":1660656368966,
        "Answer_last_edit_time":1660656368966,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUKWPP4eXTTZe5qIUDJAXnsQ\/sagemaker-data-capture-does-not-write-files",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":1.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":0.0,
        "Answerer_isModerator":0.0,
        "Answerer_isExpert":0.0,
        "Answerer_isCse":0.0,
        "Question_original_content":"data captur write file want enabl data captur specif endpoint far consol endpoint work fine log return desir result file written specifi locat endpoint configur endpoint base train job scikit learn classifi variant xlarg instanc type data captur enabl sampl percentag data captur storag locat tri captur content type tri leav blank set text csv csv text applic json json endpoint invok endpoint invok lambda function client bodi sourc segment segment languag languag payload json dump bodi sourc encod respons self client invok endpoint endpointnam endpoint bodi payload contenttyp applic json accept applic json result json load respons bodi read decod return result predict intern endpoint us flask api invoc path return result log endpoint work fine flask api log input output info api bodi segment languag info api output predict text text label label",
        "Question_preprocessed_content":"data captur write file want enabl data captur specif endpoint endpoint work fine log return desir result file specifi locat endpoint configur endpoint base train job scikit learn variant instanc type data captur enabl sampl percentag data captur storag locat tri captur content type tri leav blank json endpoint invok endpoint invok lambda function client endpoint us flask api path return result log endpoint work fine flask api input output",
        "Question_gpt_summary_original":"The user is trying to enable data capture for a specific endpoint in Sagemaker via the console, but no files are being written to the specified S3 location. The endpoint is based on a training job with a scikit learn classifier and is invoked in a Lambda function with a client. The endpoint works fine and logs input and output, but data capture is not working.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Retrain the classification model automatically based on updated data set",
        "Question_body":"<p>We have created an experiment in Azure ML Studio to predict some scheduling activities based on the system data and user data. System data consists of the CPU time, Heap Usage and other system parameters while user data has active sessions of the user and some user-specific data.\nOur experiment is working fine and returning the results quite similar to what we are expecting, but we are struggling with the following:-<\/p>\n\n<p>1) Our experiment is not considering the updated data for training its models.<\/p>\n\n<p>2) Every time we are required to upload the data and retrain the models manually.<\/p>\n\n<p>I wonder if it is really possible to feed in live data to the azure experiments using some web-services or by using Azure DB. We are trying to update the data in CSV file that we have created in Azure storage. That probably would solve our 1st query.<\/p>\n\n<p>Now, this updated data should be considered to train the model periodically automatically.<\/p>\n\n<p>It would be great if someone could help us out with it?<\/p>\n\n<p>Note: We are using our model using the web services created with the help of Azure studio.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1550724960020,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1550942353507,
        "Question_score_count":0.0,
        "Question_view_count":772.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Step 1 : Create 2 web services with Azure ML Studio ( One for the training model and one for the predictive model)<\/p>\n\n<p>Step 2: Create endpoint through the web service with the link Manage Endpoint on Azure ML Studio for each web service<\/p>\n\n<p>Step 3: Create 2 new connections on Azure Data Factory \/ Find Azure ML (on compute tab) and copy the Endpoint key and API Key that you will find under the Consume tab in the endpoint configuration (the one that you created on step 2) Endpoint Key = Batch Requests Key and API Key = Primary Key <\/p>\n\n<p>Set Disable Update Resource for the training model endpoint\nSet Enable Update Resource for the predictive model endpoint ( Update Resource End Point = Patch key )<\/p>\n\n<p>Step 4 : Create a pipeline with 2 activities ( ML Batch Execution and ML Update Resource)\nSet the AML Linked service for the ML batch Execution with the connection that has  disable Update Resource<\/p>\n\n<p>Set the AML Linked service for the ML Update Resource with the connection that has  Enable Update Resource<\/p>\n\n<p>Step 5 : Set the Web Service Inputs and Outputs<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1551972299452,
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":1521189557296,
        "Answerer_location":null,
        "Answerer_reputation_count":160.0,
        "Answerer_view_count":27.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54799512",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"retrain classif model automat base updat data set creat experi studio predict schedul activ base data user data data consist cpu time heap usag paramet user data activ session user user specif data experi work fine return result similar expect struggl follow experi consid updat data train model time requir upload data retrain model manual wonder possibl feed live data azur experi web servic azur try updat data csv file creat azur storag probabl solv queri updat data consid train model period automat great help note model web servic creat help azur studio",
        "Question_preprocessed_content":"retrain model base updat data set creat experi studio predict schedul activ base data user data data consist cpu time heap usag paramet user data activ user data experi work fine return result similar expect experi consid updat data train model time requir upload data retrain model wonder live data azur experi azur try updat data csv file creat azur storag probabl solv queri updat data consid train model great help note model web servic creat help azur studio",
        "Question_gpt_summary_original":"The user has created an experiment in Azure ML Studio to predict scheduling activities based on system and user data. However, the experiment is not considering updated data for training its models and requires manual retraining every time. The user is seeking a solution to feed live data to the experiment and train the model periodically automatically. They are using the model through web services created with Azure Studio.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Changing files after starting a long sweep",
        "Question_body":"<p>Hey,<\/p>\n<p>I think it\u2019s okay, but I just want to make sure. Say that I start a long hyperparameter sweep with many options, is it okay to change the code files after the sweep has started? or it might break something?<\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1674239733147,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":159.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/changing-files-after-starting-a-long-sweep\/3727",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"chang file start long sweep hei think okai want sure start long hyperparamet sweep option okai chang code file sweep start break thank",
        "Question_preprocessed_content":"chang file start long hei think okai want sure start long hyperparamet option okai chang code file start break thank",
        "Question_gpt_summary_original":"The user is inquiring whether it is safe to modify code files while a long hyperparameter sweep with many options is ongoing or if it could cause any issues.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"how to create a custom model tar file via create model step in sagemaker pipeline step?",
        "Question_body":"based on the sample\/docs provided here => https:\/\/www.philschmid.de\/mlops-sagemaker-huggingface-transformers, I am fine tuning a hugging face distilbert model in sagemaker studio via pipeline. this example works. when the model is created , i specify    entry_point = 'predict.py', \n   and  source_dir = 'script' (see below ) , which creates following directory structure in the model.tar file. there are other files like tokenizer.json , tokenizer_config.json. , is it possible put these files into another folder next to my script folder during the model create\/package step ? these files , i assume are downloaded from hugging face along with the pytorch model file and are put at the root of the tar model file generated. \n\nmodel directory structure\n```\nmodel.tar.gz\/\n|- pytorch_model.bin\n|- tokenizer.json\n|- tokenizer_config.json\n|- special_tokens_map.json\n|- ...\n|- script\/\n   |- predict.py\n   |- requirements.txt \n```\n\n```\n# Create Model\nmodel = Model(\n    entry_point = 'predict.py', \n    source_dir = 'script'\n```\n\n```\nhuggingface_estimator = HuggingFace(entry_point='train.py',\n                            source_dir='.\/scripts',\n                            instance_type='ml.p3.2xlarge',\n                            instance_count=1,\n                            role=role,\n                            transformers_version='4.6',\n                            pytorch_version='1.7',\n                            py_version='py36',\n                            hyperparameters = hyperparameters)\n\nstep_train = TrainingStep(\n    name=\"TrainHuggingFaceModel\",\n    estimator=huggingface_estimator,\n    inputs={\n        \"train\": TrainingInput( ...  ),\n        \"test\": TrainingInput( ...     ),\n    },\n....\n)\n\n# Create Model\nmodel = Model(\n    entry_point = 'predict.py', \n    source_dir = 'script'\n    image_uri=image_uri,\n    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n    sagemaker_session=pipeline_session,\n    role=role,\n    ....\n)\n\nstep_create_model = ModelStep(\n    name=\"CreateModel\",\n    step_args=model.create(\"ml.m4.large\"),\n)\n```",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1674099113152,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1674445424984,
        "Question_score_count":0.0,
        "Question_view_count":42.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU_aRkG2vZSaaPaIdxO7sofA\/how-to-create-a-custom-model-tar-file-via-create-model-step-in-sagemaker-pipeline-step",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"creat custom model tar file creat model step pipelin step base sampl doc provid http www philschmid mlop huggingfac transform fine tune hug face distilbert model studio pipelin exampl work model creat specifi entri point predict sourc dir script creat follow directori structur model tar file file like token json token config json possibl file folder script folder model creat packag step file assum download hug face pytorch model file root tar model file gener model directori structur model tar pytorch model bin token json token config json special token map json script predict requir txt creat model model model entri point predict sourc dir script huggingfac estim huggingfac entri point train sourc dir script instanc type xlarg instanc count role role transform version pytorch version version hyperparamet hyperparamet step train trainingstep trainhuggingfacemodel estim huggingfac estim input train traininginput test traininginput creat model model model entri point predict sourc dir script imag uri imag uri model data step train properti modelartifact smodelartifact session pipelin session role role step creat model modelstep createmodel step arg model creat larg",
        "Question_preprocessed_content":"creat custom model tar file creat model step pipelin step base provid fine tune face distilbert model studio pipelin exampl work model creat specifi script creat directori structur file file like file folder script folder model step file download face pytorch model file tar model file gener model directori structur",
        "Question_gpt_summary_original":"The user is fine-tuning a Hugging Face DistilBERT model in SageMaker Studio via pipeline and wants to know if it is possible to put files like tokenizer.json and tokenizer_config.json into another folder next to the script folder during the model create\/package step. The current model directory structure has these files downloaded from Hugging Face along with the PyTorch model file and put at the root of the tar model file generated.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to deploy an automl model from gcp as a web app using streamlit on GCP",
        "Question_body":"<p>I plan to build an application which asks user input in the form of news and predicts it as fake or true.\ni have trained the model using automl google cloud platform (GCP) on vertex AI platform. I have created the endpoint.<\/p>\n<p>How to proceed further? How to build an app without downloading anything on local system? (all of this should be built on GCP)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_created_time":1647671495320,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":112.0,
        "Poster_created_time":1611850729940,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71535888",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi automl model gcp web app streamlit gcp plan build applic ask user input form new predict fake true train model automl googl cloud platform gcp platform creat endpoint proce build app download local built gcp",
        "Question_preprocessed_content":"deploi automl model gcp web streamlit gcp plan build ask user input form new predict fake true train model automl cloud platform platform creat endpoint build download local",
        "Question_gpt_summary_original":"The user has trained an automl model on GCP's Vertex AI platform to predict whether a news article is fake or true. They are now seeking guidance on how to deploy the model as a web app using Streamlit on GCP without downloading anything on their local system.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How do I solve this ML Studio Classic error ?",
        "Question_body":"<p><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/173364-error-image.png?platform=QnA\" alt=\"173364-error-image.png\" \/>    <\/p>\n<p>Hi,     <\/p>\n<p>I just used the platform for 2 days and I'm now unable to enter to access my models I have created. Not sure if it's a problem with my account or just the whole server is down... I understand we need to switch to Azure Machine Learning by 31 August 2024 looks like there is still time right? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1644552367593,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/731370\/how-do-i-solve-this-ml-studio-classic-error",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"solv studio classic error platform dai unabl enter access model creat sure problem account server understand need switch august look like time right",
        "Question_preprocessed_content":"solv studio platform dai unabl enter model creat sure problem server understand switch august like time right",
        "Question_gpt_summary_original":"The user is encountering an error while trying to access their models on ML Studio Classic after using the platform for 2 days. It is unclear whether the issue is related to their account or if the server is down. The user also mentions the upcoming switch to Azure Machine Learning by August 31, 2024.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AzureML endpoint - gunicorn worker timeout",
        "Question_body":"<p>Hello everyone,    <br \/>\nI am trying to deploy a large model using AzureML endpoint.     <br \/>\nThe model is made up of many sub-models which get loaded by the init() method as described in the documentation <a href=\"https:\/\/learn.microsoft.com\/bs-cyrl-ba\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\">here<\/a>.    <br \/>\nThe model is trained and then registered in AzureML.     <\/p>\n<p>When I deploy the model I can see in the logs that the gunicorn worker resets themselves after 300 seconds, so the whole ensemble of sub-models never have time to completely be loaded.    <\/p>\n<p>Is there a way to manually set the timeout of the gunicorn workers?    <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_created_time":1630071044527,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/530811\/azureml-endpoint-gunicorn-worker-timeout",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"endpoint gunicorn worker timeout hello try deploi larg model endpoint model sub model load init method describ document model train regist deploi model log gunicorn worker reset second ensembl sub model time complet load wai manual set timeout gunicorn worker",
        "Question_preprocessed_content":"endpoint gunicorn worker timeout try deploi larg model endpoint model load init method describ document model train regist deploi model log gunicorn worker reset second ensembl time complet load wai set timeout gunicorn worker",
        "Question_gpt_summary_original":"The user is facing an issue with AzureML endpoint where the gunicorn worker resets after 300 seconds, causing the sub-models to not load completely. The user is looking for a way to manually set the timeout of the gunicorn workers.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"ML Pipeline on AWS SageMaker: How to create long-running query\/preprocessing tasks",
        "Question_body":"<p>I'm a software engineer transitioning toward machine learning engineering, but need some assistance.<\/p>\n<p>I'm currently using AWS Lambda and Step Functions to run query and preprocessing jobs for my ML pipeline, but am restrained by Lambda's 15m runtime limitation.<\/p>\n<p>We're a strictly AWS shop, so I'm kind of stuck with SageMaker and other AWS tools for the time being. Later on we'll consider experimenting with something like Kubeflow if it looks advantageous enough.<\/p>\n<p><strong>My current process<\/strong><\/p>\n<ul>\n<li>I have my data scientists write python scripts (in a git repo) for the query and preprocessing steps of a model, and deploy them (via Terraform) as Lambda functions, then use Step Functions to sequence the ML Pipeline steps as a DAG (query -&gt; preprocess -&gt; train -&gt; deploy)<\/li>\n<li>The Query lambda pulls data from our data warehouse (Redshift), and writes the unprocessed dataset to S3<\/li>\n<li>The Preprocessing lambda loads the unprocessed dataset from S3, manipulates it as needed, and writes it as training &amp; validation datasets to a different S3 location<\/li>\n<li>The Train and Deploy tasks use the SageMaker python api to train and deploy the models as SageMaker Endpoints<\/li>\n<\/ul>\n<p>Do I need to be using Glue and SageMaker Processing jobs? From what I can tell, Glue seems more targeted towards ETLs than for writing to S3, and SageMaker Processing jobs seem a bit more complex to deploy to than Lambda.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_created_time":1604367008457,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":468.0,
        "Poster_created_time":1268298510172,
        "Poster_location":"Austin, TX",
        "Poster_reputation_count":1209.0,
        "Poster_view_count":55.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64655582",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"pipelin creat long run queri preprocess task softwar engin transit machin learn engin need assist current aw lambda step function run queri preprocess job pipelin restrain lambda runtim limit strictli aw shop kind stuck aw tool time later consid experi like kubeflow look advantag current process data scientist write python script git repo queri preprocess step model deploi terraform lambda function us step function sequenc pipelin step dag queri preprocess train deploi queri lambda pull data data warehous redshift write unprocess dataset preprocess lambda load unprocess dataset manipul need write train valid dataset differ locat train deploi task us python api train deploi model endpoint need glue process job tell glue target etl write process job bit complex deploi lambda",
        "Question_preprocessed_content":"pipelin creat task softwar transit machin learn aw lambda step function run queri job pipelin restrain lambda runtim limit strictli aw shop kind stuck aw time later consid experi like kubeflow advantag data scientist write python script queri step model deploi lambda function us step function sequenc pipelin step dag queri lambda data data warehous write dataset lambda load dataset manipul write train valid dataset locat train deploi task us python api train deploi model endpoint glue job glue target etl write job bit complex deploi lambda",
        "Question_gpt_summary_original":"The user is facing a challenge in running query and preprocessing jobs for their ML pipeline on AWS Lambda due to its 15-minute runtime limitation. They are currently using AWS Lambda and Step Functions to sequence the ML Pipeline steps as a DAG. The user is unsure if they need to use Glue and SageMaker Processing jobs instead of Lambda. They are a strictly AWS shop and plan to experiment with Kubeflow in the future.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Submit Job But Never Ran",
        "Question_body":"I am trying to test a bash script on the cloud, but when I submit it, it repeatedly switch between SCHEDULE and QUEUE and never ran. Here is the bash script that I am trying to run:\u00a0\n\n\u00a0\n\n#!\/bin\/bash\n\n\nsource \/opt\/conda\/etc\/profile.d\/conda.sh\nconda activate WaifuDiffusion\n\nexport FOLDER=\/home\/kannachan\/SeaSalt-Downloader\n\npython $FOLDER\/main.py -u \"https:\/\/danbooru.donmai.us\/posts?tags=mika_pikazo\" \\\n       --scraper danbooru \\\n       --filter tag_filter animated video \\\n       --saver folder mika_pikazo       \n\n\u00a0\n\n\nI config my job as follows:\n\n\u00a0\n\n{\n    \"taskGroups\": [\n        {\n            \"taskSpec\": {\n                \"runnables\": [\n                    {\n                       \"script\": {\n\t\t\t      \"text\": \"#!\/bin.bash\\n bash ..\/run.sh\" \n\t\t\t}\n                    }\n                ],\n                \"computeResource\": {\n                    \"cpuMilli\": 2000,\n                    \"memoryMib\": 16\n                },\n                \"maxRetryCount\": 2,\n                \"maxRunDuration\": \"3600s\"\n            },\n            \"taskCount\": 4,\n            \"parallelism\": 2\n        }\n    ],\n    \"allocationPolicy\": {\n        \"instances\": [\n            {\n                \"policy\": { \"machineType\": \"g2-standard-8\" }\n            }\n        ]\n    },\n    \"labels\": {\n        \"department\": \"ai\",\n        \"env\": \"web-scrapper\"\n    },\n    \"logsPolicy\": {\n        \"destination\": \"CLOUD_LOGGING\"\n    }\n}\n\n\u00a0\n\n\u00a0\n\nBoth run.sh and config.json is in the same directory. I ran:\ngcloud batch jobs submit batch-job-1 --location us-central1 --config config.json\n\n\u00a0\n\ngcloud batch jobs submit batch-job-1 --location us-central1 --config config.json",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1684493940000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":67.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Submit-Job-But-Never-Ran\/m-p\/554999#M1963",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"submit job ran try test bash script cloud submit repeatedli switch schedul queue ran bash script try run bin bash sourc opt conda profil conda conda activ waifudiffus export folder home kannachan seasalt download python folder main http danbooru donmai post tag mika pikazo scraper danbooru filter tag filter anim video saver folder mika pikazo config job follow taskgroup taskspec runnabl script text bin bash bash run computeresourc cpumilli memorymib maxretrycount maxrundur taskcount parallel allocationpolici instanc polici machinetyp standard label depart env web scrapper logspolici destin cloud log run config json directori ran gcloud batch job submit batch job locat central config config json gcloud batch job submit batch job locat central config config json",
        "Question_preprocessed_content":"submit job ran try test bash script cloud submit repeatedli switch schedul queue ran bash script try run sourc conda activ export python anim video folder config job taskgroup computeresourc maxretrycount maxrundur taskcount label logspolici directori ran gcloud batch job submit gcloud batch job submit",
        "Question_gpt_summary_original":"The user is trying to test a bash script on the cloud, but the job repeatedly switches between SCHEDULE and QUEUE and never runs. The user has provided the bash script and job configuration details, including the task groups, allocation policy, and logs policy. The user ran the job using the gcloud batch jobs submit command.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Use custom modules in Sagemaker MXNet",
        "Question_body":"<p>I\u2019ve been trying to use Sagemaker to run my custom MXNet training job. In all the examples I\u2019ve seen, the code sample looks like this<\/p>\n\n<pre><code>estimator = MXNet(\u2018train.py\u2019, role=role, other_params)\nestimator.fit(inputs)\n<\/code><\/pre>\n\n<p>\u2028\u2028What if my <code>train.py<\/code> relies on a custom module? Given a directory structure like so<\/p>\n\n<pre><code>.\n\u251c\u2500\u2500 awesome\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lib.py\n\u2514\u2500\u2500 train.py \n<\/code><\/pre>\n\n<p>With my <code>train.py<\/code> file importing from <code>awesome\/lib.py<\/code>, what\u2019s the best way for me to deploy this job on Sagemaker without going through the hassle of creating a Docker container. <\/p>\n\n<p>Note: all the code in the custom module is just regular mxnet code, organized across various files and helper methods<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1590078681800,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":139.0,
        "Poster_created_time":1590078591488,
        "Poster_location":null,
        "Poster_reputation_count":11.0,
        "Poster_view_count":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61939275",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"us custom modul mxnet iv try us run custom mxnet train job exampl iv seen code sampl look like estim mxnet train role role param estim fit input train reli custom modul given directori structur like awesom init lib train train file import awesom lib what best wai deploi job go hassl creat docker contain note code custom modul regular mxnet code organ file helper method",
        "Question_preprocessed_content":"us custom modul mxnet iv try us run custom mxnet train job exampl iv code sampl like reli custom modul given directori structur like file import what best wai deploi job go creat docker contain note code custom modul regular mxnet code organ file helper method",
        "Question_gpt_summary_original":"The user is facing a challenge while using Sagemaker to run a custom MXNet training job that relies on a custom module. The user is unsure about the best way to deploy the job on Sagemaker without creating a Docker container. The custom module contains regular MXNet code organized across various files and helper methods.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"MLflow 1.27.0 released, including new MLflow Pipelines component!",
        "Question_body":"We are very excited to announce the availability of\u00a0MLflow\u00a01.27.0!\n\n\n\n\nMLflow 1.27.0 includes several major features and improvements:\n\n[Pipelines] With MLflow 1.27.0, we are excited to announce the release of\nMLflow Pipelines, an opinionated framework for\nstructuring MLOps workflows that simplifies and standardizes machine learning application development\nand productionization. MLflow Pipelines makes it easy for data scientists to follow best practices\nfor creating production-ready ML deliverables, allowing them to focus on developing excellent models.\nMLflow Pipelines also enables ML engineers and DevOps teams to seamlessly deploy models to production\nand incorporate them into applications. To get started with MLflow Pipelines, check out the documentation at\nhttps:\/\/mlflow.org\/docs\/latest\/pipelines.html. (#6115)\n\n[UI] Introduce UI support for searching and comparing runs across multiple Experiments (#5971,\u00a0@r3stl355)\n\nMore features:\n\n[Tracking] When using batch logging APIs, automatically split large sets of metrics, tags, and params into multiple requests (#6052,\u00a0@nzw0301)\n[Tracking] When an Experiment is deleted, SQL-based backends also move the associate Runs to the \"deleted\" lifecycle stage (#6064,\u00a0@AdityaIyengar27)\n[Tracking] Add support for logging single-element\u00a0ndarray\u00a0and tensor instances as metrics via the\u00a0mlflow.log_metric()\u00a0API (#5756,\u00a0@ntakouris)\n[Models] Add support for\u00a0CatBoostRanker\u00a0models to the\u00a0mlflow.catboost\u00a0flavor (#6032,\u00a0@danielgafni)\n[Models] Integrate SHAP's\u00a0KernelExplainer\u00a0with\u00a0mlflow.evaluate(), enabling model explanations on categorical data (#6044,\u00a0#5920,\u00a0@WeichenXu123)\n[Models] Extend\u00a0mlflow.evaluate()\u00a0to automatically log the\u00a0score()\u00a0outputs of scikit-learn models as metrics (#5935,\u00a0#5903,\u00a0@WeichenXu123)\n\nBug fixes and documentation updates:\n\n[UI] Fix broken model links in the Runs table on the MLflow Experiment Page (#6014,\u00a0@hctpbl)\n[Tracking\/Installation] Require\u00a0sqlalchemy>=1.4.0\u00a0upon MLflow installation, which is necessary for usage of SQL-based MLflow Tracking backends (#6024,\u00a0@sniafas)\n[Tracking] Fix a regression that caused\u00a0mlflow server\u00a0to reject\u00a0LogParam\u00a0API requests containing empty string values (#6031,\u00a0@harupy)\n[Tracking] Fix a failure in scikit-learn autologging that occurred when\u00a0matplotlib\u00a0was not installed on the host system (#5995,\u00a0@fa9r)\n[Tracking] Fix a failure in TensorFlow autologging that occurred when training models on\u00a0tf.data.Dataset\u00a0inputs (#6061,\u00a0@dbczumar)\n[Artifacts] Address artifact download failures from SFTP locations that occurred due to mismanaged concurrency (#5840,\u00a0@rsundqvist)\n[Models] Fix a bug where MLflow Models did not restore bundled code properly if multiple models use the same code module name (#5926,\u00a0@BFAnas)\n[Models] Address an issue where\u00a0mlflow.sklearn.model()\u00a0did not properly restore bundled model code (#6037,\u00a0@WeichenXu123)\n[Models] Fix a bug in\u00a0mlflow.evaluate()\u00a0that caused input data objects to be mutated when evaluating certain scikit-learn models (#6141,\u00a0@dbczumar)\n[Models] Fix a failure in\u00a0mlflow.pyfunc.spark_udf\u00a0that occurred when the UDF was invoked on an empty RDD partition (#6063,\u00a0@WeichenXu123)\n[Models] Fix a failure in\u00a0mlflow models build-docker\u00a0that occurred when\u00a0env-manager=local\u00a0was specified (#6046,\u00a0@bneijt)\n[Projects] Improve robustness of the git repository check that occurs prior to MLflow Project execution (#6000,\u00a0@dkapur17)\n[Projects] Address a failure that arose when running a Project that does not have a\u00a0master\u00a0branch (#5889,\u00a0@harupy)\n[Docs] Correct several typos throughout the MLflow docs (#5959,\u00a0@ryanrussell)\n\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_created_time":1656460642000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":null,
        "Question_view_count":25.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/7H5WdbTpuYk",
        "Tool":"MLflow",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"releas includ new pipelin compon excit announc avail includ major featur improv pipelin excit announc releas pipelin opinion framework structur mlop workflow simplifi standard machin learn applic develop production pipelin make easi data scientist follow best practic creat product readi deliver allow focu develop excel model pipelin enabl engin devop team seamlessli deploi model product incorpor applic start pipelin check document http org doc latest pipelin html introduc support search compar run multipl experi rstl featur track batch log api automat split larg set metric tag param multipl request nzw track experi delet sql base backend associ run delet lifecycl stage adityaiyengar track add support log singl elementndarrayand tensor instanc metric log metric api ntakouri model add support forcatboostrankermodel catboostflavor danielgafni model integr shap skernelexplainerwith evalu enabl model explan categor data weichenxu model extend evalu automat log thescor output scikit learn model metric weichenxu bug fix document updat fix broken model link run tabl experi page hctpbl track instal requiresqlalchemi instal necessari usag sql base track backend sniafa track fix regress caus serverto rejectlogparamapi request contain string valu harupi track fix failur scikit learn autolog occur whenmatplotlibwa instal host far track fix failur tensorflow autolog occur train model ontf data datasetinput dbczumar artifact address artifact download failur sftp locat occur mismanag concurr rsundqvist model fix bug model restor bundl code properli multipl model us code modul bfana model address issu sklearn model properli restor bundl model code weichenxu model fix bug evalu caus input data object mutat evalu certain scikit learn model dbczumar model fix failur pyfunc spark udfthat occur udf invok rdd partit weichenxu model fix failur model build dockerthat occur whenenv manag localwa specifi bneijt project improv robust git repositori check occur prior project execut dkapur project address failur aros run project amasterbranch harupi doc correct typo doc ryanrussel comprehens list chang thereleas chang log check latest document org",
        "Question_preprocessed_content":"releas includ new pipelin compon excit avail includ major featur improv pipelin excit releas pipelin opinion framework structur mlop workflow simplifi standard machin learn develop production pipelin make easi data scientist best practic creat deliver focu develop model pipelin enabl devop team deploi model product incorpor start pipelin check document introduc search compar run multipl experi featur track batch api split larg set metric tag param multipl request track experi delet backend run delet lifecycl stage track tensor instanc metric model model integr enabl model explan categor data model log thescor output model metric bug fix document updat fix broken model link run tabl experi page usag track backend track fix caus serverto rejectlogparamapi request contain string valu track fix failur whenmatplotlibwa host track fix failur tensorflow train model artifact artifact download failur locat mismanag model fix bug model restor bundl code properli multipl model us code modul model properli restor bundl model code model fix bug caus input data object mutat evalu certain model model fix failur udf invok partit model fix failur model specifi project improv git repositori check prior project execut project failur aros project amasterbranch doc typo doc comprehens list chang thereleas chang log check latest document",
        "Question_gpt_summary_original":"MLflow 1.27.0 has been released with new features and improvements, including the release of MLflow Pipelines, an opinionated framework for structuring MLOps workflows that simplifies and standardizes machine learning application development and productionization. The update also includes UI support for searching and comparing runs across multiple experiments, bug fixes, and documentation updates.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Unable to deploy model to endpoint",
        "Question_body":"Hi,\n\nI am trying to deploy a simple model on an endpoint in order to start making predictions.\n\nI followed these steps:\n\n1. Create the model, create a docker image, push it into Artifact Registry\n\n2. Upload the model to Vertex AI:\n\n\u00a0\n\n! gcloud ai models upload --container-image-uri=<REGION>-docker.pkg.dev\/<PROJECT>\/<REPOS>\/<MODEL>:latest --region=<REGION> --display-name=my-model\n\n\u00a0\n\n3. Create an endpoint on Vertex AI:\n\n\u00a0\n\n! gcloud ai endpoints create --display-name=my-model-endpoint --region=<REGION>\n\n\u00a0\n\n4. Deploy the model to the endpoint:\n\n\u00a0\n\n! gcloud ai endpoints deploy-model <ENDPOINT_ID> --model <MODEL_ID> -display-name my-model --traffic-split=0=100 --region <REGION> --machine-type=n1-standard-8 --enable-access-logging \n\n\u00a0\n\nHere's the message:\n\nModel server terminated: model server container terminated: exit_code: 0 reason: \"Completed\" started_at { seconds: 1684309447 } finished_at { seconds: 1684309449 } . Model server logs can be found at xxxxx\n\nWhen i check the logs:\u00a0\n\nAs you can see i have no errors.\n\nWhat i tried:\n\n- upsized the machine-type\u00a0\n\n- deployed with a python script\u00a0\n\n- deployed manually using the portal\u00a0\u00a0\n\n- changed my model to a simple linear regression to test",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1684285800000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":173.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unable-to-deploy-model-to-endpoint\/m-p\/554155#M1939",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"unabl deploi model endpoint try deploi simpl model endpoint order start make predict follow step creat model creat docker imag push artifact registri upload model gcloud model upload contain imag uri docker pkg dev latest region displai model creat endpoint gcloud endpoint creat displai model endpoint region deploi model endpoint gcloud endpoint deploi model model displai model traffic split region machin type standard enabl access log messag model server termin model server contain termin exit code reason complet start second finish second model server log xxxxx check log error tri upsiz machin type deploi python script deploi manual portal chang model simpl linear regress test",
        "Question_preprocessed_content":"unabl deploi model endpoint try deploi simpl model endpoint order start make predict step creat model creat docker imag push artifact registri upload model gcloud model upload creat endpoint gcloud endpoint creat deploi model endpoint gcloud endpoint model server termin model server contain termin reason complet model server log check log tri upsiz deploi python script deploi portal chang model simpl linear test",
        "Question_gpt_summary_original":"The user is facing challenges in deploying a simple model to an endpoint for making predictions. The user has followed the necessary steps, including creating a model, creating a docker image, pushing it into Artifact Registry, uploading the model to Vertex AI, creating an endpoint, and deploying the model to the endpoint. However, the model server terminated with no errors, and the user has tried various solutions, including upsizing the machine-type, deploying with a python script, deploying manually using the portal, and changing the model to a simple linear regression to test.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"What is a 'XGBoostLabelEncoder' object?",
        "Question_body":"<p>I'm trying to load a model from an mlflow run. When I do that I get an 'XGBoostLabelEncoder' object, an object with no attributes like predict or predict_proba. I don't really know what you can do with it.<\/p>\n<p>I've googled around but can't find any information about what an 'XGBoostLabelEncoder' object is.<\/p>\n<p>Anybody who knows?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_created_time":1663571938730,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1663573301816,
        "Question_score_count":0.0,
        "Question_view_count":25.0,
        "Poster_created_time":1503559541763,
        "Poster_location":"Malm\u00f6, Sverige",
        "Poster_reputation_count":796.0,
        "Poster_view_count":136.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73769728",
        "Tool":"MLflow",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"xgboostlabelencod object try load model run xgboostlabelencod object object attribut like predict predict proba know googl inform xgboostlabelencod object anybodi know",
        "Question_preprocessed_content":"object try load model run object object like predict know inform object anybodi know",
        "Question_gpt_summary_original":"The user is encountering an issue while trying to load a model from an mlflow run. They are getting an 'XGBoostLabelEncoder' object which has no attributes like predict or predict_proba. The user is unsure about what can be done with this object and is seeking help to understand it.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How to invoke a rich response button in Diagflow CX through API",
        "Question_body":"I have a diagflow agent that it does return a custom Payload (buttons which transition the session to another flow). Also I have a standalone client (Java client) that queries the Diagflow agent and return response back to the End User.\n\nUsers will interact with the Diagflow agent through Java client developed using google Java SDK. I need help in how can I invoke action button that is retuned by diagflow agent in my Java Client, so the User is transitioned to another flow?\n\nBelow is the custom payload response after calling detectIntent function on SessionClient.\u00a0\n\n\u00a0\n\nType: payload\npayload {\n  fields {\n    key: \"richContent\"\n    value {\n      list_value {\n        values {\n          list_value {\n            values {\n              struct_value {\n                fields {\n                  key: \"event\"\n                  value {\n                    struct_value {\n                      fields {\n                        key: \"name\"\n                        value {\n                          string_value: \"EN_TXT\"\n                        }\n                      }\n                    }\n                  }\n                }\n                fields {\n                  key: \"icon\"\n                  value {\n                    struct_value {\n                      fields {\n                        key: \"color\"\n                        value {\n                          string_value: \"#FF9800\"\n                        }\n                      }\n                      fields {\n                        key: \"type\"\n                        value {\n                          string_value: \"chevron_right\"\n                        }\n                      }\n                    }\n                  }\n                }\n                fields {\n                  key: \"link\"\n                  value {\n                    string_value: \"\"\n                  }\n                }\n                fields {\n                  key: \"text\"\n                  value {\n                    string_value: \"English\"\n                  }\n                }\n                fields {\n                  key: \"type\"\n                  value {\n                    string_value: \"button\"\n                  }\n                }\n              }\n            }\n            values {\n              struct_value {\n                fields {\n                  key: \"event\"\n                  value {\n                    struct_value {\n                      fields {\n                        key: \"name\"\n                        value {\n                          string_value: \"\\331\\220AR_TXT\"\n                        }\n                      }\n                    }\n                  }\n                }\n                fields {\n                  key: \"icon\"\n                  value {\n                    struct_value {\n                      fields {\n                        key: \"color\"\n                        value {\n                          string_value: \"#FF9800\"\n                        }\n                      }\n                      fields {\n                        key: \"type\"\n                        value {\n                          string_value: \"chevron_right\"\n                        }\n                      }\n                    }\n                  }\n                }\n                fields {\n                  key: \"link\"\n                  value {\n                    string_value: \"\"\n                  }\n                }\n                fields {\n                  key: \"text\"\n                  value {\n                    string_value: \"\\330\\271\\330\\261\\330\\250\\331\\212\"\n                  }\n                }\n                fields {\n                  key: \"type\"\n                  value {\n                    string_value: \"button\"\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1674547920000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":69.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-invoke-a-rich-response-button-in-Diagflow-CX-through-API\/m-p\/513390#M1126",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"invok rich respons button diagflow api diagflow agent return custom payload button transit session flow standalon client java client queri diagflow agent return respons end user user interact diagflow agent java client develop googl java sdk need help invok action button retun diagflow agent java client user transit flow custom payload respons call detectint function sessioncli type payload payload field kei richcont valu list valu valu list valu valu struct valu field kei event valu struct valu field kei valu string valu txt field kei icon valu struct valu field kei color valu string valu field kei type valu string valu chevron right field kei link valu string valu field kei text valu string valu english field kei type valu string valu button valu struct valu field kei event valu struct valu field kei valu string valu txt field kei icon valu struct valu field kei color valu string valu field kei type valu string valu chevron right field kei link valu string valu field kei text valu string valu field kei type valu string valu button",
        "Question_preprocessed_content":"invok rich respons diagflow api diagflow agent return custom payload standalon client queri diagflow agent return respons end user user interact diagflow agent java client develop java sdk help invok action retun diagflow agent java client user transit flow custom payload respons detectint function type payload payload field field field field field valu field field field field field",
        "Question_gpt_summary_original":"The user is seeking help in invoking an action button that is returned by Diagflow CX agent in their Java client. The agent returns a custom payload with buttons that transition the session to another flow. The user wants to know how to invoke the action button in their Java client so that the user is transitioned to another flow.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Staged pipeline steps not given labels",
        "Question_body":"<p>I\u2019ve noticed that guild applies that labels I give to pipelines to each pipeline step when the pipeline stage is ran directly.  However, if I instead stage the pipeline operation and then run the staged pipeline operation this doesn\u2019t happen.  Instead only the pipeline operation receives label, not the steps of the pipeline.   For example, lets say my <code>guild.yml<\/code> is given as follows.  The contents of <code>train.py<\/code> and <code>test.py<\/code> aren\u2019t really important.<\/p>\n<pre><code>- operations:\n    mypipeline:\n        steps:\n            - train\n            - test\n\n    train:\n        sourcecode:\n            dest: .\n            select: train.py\n        exec: \"python train.py\"\n\n    test:\n        sourcecode:\n            dest: .\n            select: test.py\n        exec: \"python test.py\"\n<\/code><\/pre>\n<p>If I run <code>guild run mypipeline -y --label debug<\/code> I get<\/p>\n<pre><code>[1:b21131b7]   test                                      2022-01-03 17:27:55  completed  debug\n[2:8dd06463]   train                                     2022-01-03 17:27:55  completed  debug\n[3:092f43f2]   mypipeline                                2022-01-03 17:27:54  completed  debug\n<\/code><\/pre>\n<p>But if I run <code>guild run mypipeline -y --label debug --stage &amp;&amp; guild run queue -y<\/code> I get the following.  Note that only the <code>mypipeline<\/code> operation receives the label <code>debug<\/code> while the step operations receive no label.<\/p>\n<pre><code>[1:5b2c8b79]   test                                      2022-01-03 17:28:48  completed\n[2:85ae374c]   train                                     2022-01-03 17:28:47  completed\n[3:a0dc7ef1]   mypipeline                                2022-01-03 17:28:46  completed   debug\n<\/code><\/pre>\n<p>Note that similar commands like <code>guild run mypipeline -y --label debug --stage &amp;&amp; guild run --start $(guild select 1)<\/code> have the same effect.<\/p>\n<p>Is this intended behavior? If so how can I make it so that the steps of the staged pipeline operation receive the same label as the pipeline operation that started them?  Thanks<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1641249403629,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":254.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/staged-pipeline-steps-not-given-labels\/791",
        "Tool":"Guild AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"stage pipelin step given label iv notic appli label pipelin pipelin step pipelin stage ran directli instead stage pipelin oper run stage pipelin oper doesnt happen instead pipelin oper receiv label step pipelin exampl let yml given follow content train test arent import oper mypipelin step train test train sourcecod dest select train exec python train test sourcecod dest select test exec python test run run mypipelin label debug test complet debug train complet debug mypipelin complet debug run run mypipelin label debug stage run queue follow note mypipelin oper receiv label debug step oper receiv label bcb test complet aec train complet adcef mypipelin complet debug note similar command like run mypipelin label debug stage run start select effect intend behavior step stage pipelin oper receiv label pipelin oper start thank",
        "Question_preprocessed_content":"stage pipelin step given label iv notic label pipelin pipelin step pipelin stage ran directli instead stage pipelin oper run stage pipelin oper doesnt instead pipelin oper receiv label step pipelin exampl let given content arent import run run note oper receiv label step oper receiv label note similar like intend behavior step stage pipelin oper receiv label pipelin oper start thank",
        "Question_gpt_summary_original":"The user has noticed that when they run a pipeline stage directly, the labels they give to the pipeline are applied to each pipeline step. However, when they stage the pipeline operation and then run the staged pipeline operation, only the pipeline operation receives the label, not the steps of the pipeline. The user is asking if this is intended behavior and how they can make it so that the steps of the staged pipeline operation receive the same label as the pipeline operation that started them.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Is it possible to use Lambda functions along with other services to scale up and scale down(probably to 0 instances) Ec2 Deployed apps",
        "Question_body":"Hi there, hope you are fine.\nRecently I came across Sagemaker Async inference API, there we can scale down even to 0 instances. What I want is that I deploy my solution to EC2 instances using FastAPI, uvicorn and Celery or Rabbit-MQ(as message broker, for queuing). Then I can scale up and scale down instances based on traffic.\nAlso, if that's not the case, then I keep a minimal CPU instance on always and based on that I scale up and scale down GPU instances for handling requests.\n\n\n\nThanks  , for any help.\n\nBest Regards\nMuhammad Ali",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1649176043559,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1668483340736,
        "Question_score_count":0.0,
        "Question_view_count":399.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUl2PMA3JZRU2QmN7_knI7fQ\/is-it-possible-to-use-lambda-functions-along-with-other-services-to-scale-up-and-scale-down-probably-to-0-instances-ec2-deployed-apps",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"possibl us lambda function servic scale scale probabl instanc deploi app hope fine recent came async infer api scale instanc want deploi solut instanc fastapi uvicorn celeri rabbit messag broker queu scale scale instanc base traffic case minim cpu instanc base scale scale gpu instanc handl request thank help best regard muhammad ali",
        "Question_preprocessed_content":"us lambda function servic scale scale deploi hope fine recent came async infer api scale instanc want deploi solut instanc fastapi uvicorn celeri scale scale instanc base case minim cpu instanc base scale scale gpu instanc handl request thank help best regard ali",
        "Question_gpt_summary_original":"The user is seeking advice on whether it is possible to use Lambda functions in conjunction with other services to scale up and down EC2 deployed apps, potentially to 0 instances. They are considering using FastAPI, uvicorn, and Celery or Rabbit-MQ as a message broker for queuing. They are also considering keeping a minimal CPU instance always on and scaling up and down GPU instances based on traffic.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Azure container instances deployment failed",
        "Question_body":"<p>I am deploying a machine learning image to Azure Container Instances from Azure Machine Learning services according to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml\" rel=\"nofollow noreferrer\">this article<\/a>, but am always stuck with the error message:<\/p>\n\n<blockquote>\n  <p>Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.<br>\n  Please check the logs for your container instance xxxxxxx'.<\/p>\n<\/blockquote>\n\n<p>I tried:<\/p>\n\n<ol>\n<li>increasing memory_gb=4 in aci_config.<\/li>\n<li>I did\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-troubleshoot-deployment#debug-the-docker-image-locally\" rel=\"nofollow noreferrer\">troubleshooting<\/a> locally, but I could not have found any.<\/li>\n<\/ol>\n\n<p>Below is my score.py<\/p>\n\n<pre><code>def init():\n    global model\n    model_path = Model.get_model_path('pofc_fc_model')\n    model = joblib.load(model_path)\n\ndef run(raw_data):\n    data = np.array(json.loads(raw_data)['data'])\n    y_hat = model.predict(data)\n    return y_hat.tolist()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1553593173310,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1562618473092,
        "Question_score_count":2.0,
        "Question_view_count":3020.0,
        "Poster_created_time":1510960409296,
        "Poster_location":"Bangkok Thailand",
        "Poster_reputation_count":306.0,
        "Poster_view_count":32.0,
        "Answer_body":"<p>Have you registered the model <code>'pofc_fc_model'<\/code> in your workspace using the <code>register()<\/code> function on the model object? If not, there will be no model path and that can cause failure.<\/p>\n\n<p>See this section on model registration: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#registermodel\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#registermodel<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1553715289510,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1468951834403,
        "Answerer_location":"Seattle, WA, United States",
        "Answerer_reputation_count":645.0,
        "Answerer_view_count":101.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55353889",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"azur contain instanc deploy fail deploi machin learn imag azur contain instanc servic accord articl stuck error messag aci deploy fail except contain applic crash caus error score file init function check log contain instanc xxxxxxx tri increas memori aci config troubleshoot local score def init global model model path model model path pofc model model joblib load model path def run raw data data arrai json load raw data data hat model predict data return hat tolist",
        "Question_preprocessed_content":"azur contain instanc deploy fail deploi machin learn imag azur contain instanc servic articl stuck aci deploy fail except contain crash caus score file init function check log contain instanc tri increas",
        "Question_gpt_summary_original":"The user is facing issues while deploying a machine learning image to Azure Container Instances from Azure Machine Learning services. The deployment is failing with an error message indicating that the container application crashed, which may be caused by errors in the scoring file's init() function. The user has tried increasing memory_gb and troubleshooting locally but could not find any issues. The score.py file is also provided.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Error while running gp optimizer for Hyperparameter optimization: Cannot find objective 'loss'",
        "Question_body":"<p>Hi,<\/p>\n<p>I am trying to use Guild to do hyperparameter optimization using the gp optimizer. The first three runs started using random initializations as expected. However, even after the 3rd run, it continues to perform random initializations. On examining the output, I noticed that the following information was posted:<\/p>\n<p>INFO: [guild] Random start for optimization (cannot find objective \u2018loss\u2019)<\/p>\n<p>Is this expected? Or am I missing something?<\/p>\n<p>I looked at the scalars using guild runs info and found that all the scalars that I am logging using Tensorboard are displayed correctly.<\/p>\n<p>I would appreciate any help in this matter.<\/p>\n<p>Thanks,<br>\nVishal<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_created_time":1618193158528,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":597.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/error-while-running-gp-optimizer-for-hyperparameter-optimization-cannot-find-objective-loss\/679",
        "Tool":"Guild AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error run optim hyperparamet optim object loss try us hyperparamet optim optim run start random initi expect run continu perform random initi examin output notic follow inform post info random start optim object loss expect miss look scalar run info scalar log tensorboard displai correctli appreci help matter thank vishal",
        "Question_preprocessed_content":"optim hyperparamet optim object try us hyperparamet optim optim run start random initi expect run continu perform random initi examin output notic inform post info random start optim expect scalar run info scalar tensorboard displai help thank vishal",
        "Question_gpt_summary_original":"The user is encountering an error while running gp optimizer for hyperparameter optimization. The optimizer is unable to find the objective 'loss' and continues to perform random initializations even after the third run. The user has checked the scalars using guild runs info and found that all the scalars are displayed correctly. The user is seeking help to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Google Document AI - The Caller Does Not Have Permission Error",
        "Question_body":"Hi , i'm trying to use Google Document API to parse invoices using invoice parser. Followed the doc and imported 10 invoices to train the parser. Used Auto Labeling option. While trying to mark the imported invoices as \"Mark as Labeled\" after few corrections, Im getting an error saying \"The caller does not have permission\". The user trying to mark is the owner of the project. The owner of the project has all permissions to the parser and storage. Can some one please help.",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1677504540000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":142.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"Howdy\u00a0ganeshsarathi,\nWhat an awesome post.\u00a0 THANK YOU for providing all these details.\u00a0 I used the post content as search arguments inside Google to see if other customers have had similar problems.\u00a0 I immediately got lucky and found a report (for my records\u00a0b\/266677102).\u00a0 This report had exactly the same symptoms and was reported on 2023-01-25 which means that it is recent.\u00a0 The problem (for that client) was that the GCS bucket that was being used to host the documents had a \"retention policy\" defined on it.\u00a0 As I understand retention policies, they effectively mean that once an object has been written into the bucket, it may not be deleted or updated.\u00a0 Retention policies are used to prevent accidental deletion and mean that the content becomes immutable for the period of time that the documents are being retained.\u00a0 We can read more about buckets with retention policies here.\n\nWhat I'd like you to do is examine your environment as it relates to Document AI.\u00a0 Let's see which Google Cloud Storage buckets may be in play (i.e. where the documents may be living) and whether or not they have retention policies applied.\u00a0 If the answer is yes, then we have an exact match.\u00a0 If no, then we will have to look for other reasons ... but we'll start here.\n\nThe other customer switched to using a bucket that did not have a retention policy.\u00a0 However, the ticket remains open while Google considers what this means in terms of retaining documents while at the same time allowing HITL processing.\u00a0 Looking forward to hearing back.\n\nView solution in original post",
        "Answer_comment_count":null,
        "Question_closed_time":"\u200e--\/--\/---- --:-- AM",
        "Answer_last_edit_time":null,
        "Answer_score_count":0.0,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Document-AI-The-Caller-Does-Not-Have-Permission-Error\/m-p\/526760#M1351",
        "Tool":"Vertex AI",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"googl document caller permiss error try us googl document api pars invoic invoic parser follow doc import invoic train parser auto label option try mark import invoic mark label correct get error sai caller permiss user try mark owner project owner project permiss parser storag help",
        "Question_preprocessed_content":"document try us document api pars invoic invoic parser doc import invoic train parser auto label option try mark import invoic mark label sai user try mark owner project owner project parser storag help",
        "Question_gpt_summary_original":"The user is encountering an error while using Google Document API to parse invoices using invoice parser. The error message \"The caller does not have permission\" appears when trying to mark imported invoices as \"Mark as Labeled\" even though the user is the owner of the project and has all permissions to the parser and storage.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"what is the difference between using amazon sagemaker python SDK vs AWS SDK for python (Boto3)",
        "Question_body":"<p>I am new to AWS, and just started to learn sagemaker, and I found there are two ways to train a model: \n<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/ex1-train-model.html\" rel=\"noreferrer\">train a model using sagemaker<\/a><\/p>\n\n<ol>\n<li>Create and Run a Training Job (Amazon SageMaker Python SDK)<\/li>\n<li>Create and Run a Training Job (AWS SDK for Python (Boto 3))<\/li>\n<\/ol>\n\n<p>Is there anyone can explain what is the difference between this two ways and is there advantage and disadvantage of both ways?<\/p>\n\n<p>Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1563782678607,
        "Question_favorite_count":2.0,
        "Question_last_edit_time":null,
        "Question_score_count":6.0,
        "Question_view_count":2041.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57141552",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"differ python sdk aw sdk python boto new aw start learn wai train model train model creat run train job python sdk creat run train job aw sdk python boto explain differ wai advantag disadvantag wai thank",
        "Question_preprocessed_content":"python sdk aw sdk python new aw start learn wai train model train model creat run train job creat run train job explain wai advantag disadvantag wai thank",
        "Question_gpt_summary_original":"The user is new to AWS and is learning about SageMaker. They have found two ways to train a model: using the SageMaker Python SDK or the AWS SDK for Python (Boto3). The user is seeking an explanation of the differences between the two methods and any advantages or disadvantages of each.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"vertex AI Workbench is hanging with error \"Opening notebook with JupyterLab\" for more than a day",
        "Question_body":"I am trying to follow instructions in\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/jupyter-notebooks\u00a0(vertex AI Jupyter Notebooks tutorials). Steps done\n\n1. For the first notebook \"Text Classification model\" I have clicked on \"Vertex AI Workbench\". It takes me to GCP console & workbench.\n\n2. I am supposed to click on the \"Create\" button, which I did.\n\n3. THen the message \"Opening notebook with JupyterLab\" will come. But it is there for past 1 day, and still it hasn't finished creating. So I canceled the same. I tried once more the same thing happens. Not sure why?\n\nI have screen shots, but can't see anywhere to attach.\n\nHave anyone tried this tutorial, especially in workbench?\u00a0\n\nThanks,",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1662624720000,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":348.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/vertex-AI-Workbench-is-hanging-with-error-quot-Opening-notebook\/m-p\/464300#M570",
        "Tool":"Vertex AI",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"workbench hang error open notebook jupyterlab dai try follow instruct inhttp cloud googl com vertex doc tutori jupyt notebook jupyt notebook tutori step notebook text classif model click workbench take gcp consol workbench suppos click creat button messag open notebook jupyterlab come past dai hasn finish creat cancel tri thing happen sure screen shot attach tri tutori especi workbench thank",
        "Question_preprocessed_content":"workbench hang open jupyterlab dai try instruct jupyt tutori step text model click workbench take gcp consol workbench click creat open jupyterlab come past dai hasn finish creat cancel tri thing sure shot tri tutori workbench thank",
        "Question_gpt_summary_original":"The user is encountering an issue with Vertex AI Workbench while following the instructions for the Vertex AI Jupyter Notebooks tutorials. After clicking on the \"Create\" button, the message \"Opening notebook with JupyterLab\" has been hanging for more than a day, and the notebook has not been created. The user has tried the process twice with the same result and is unsure why it is happening.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Segmentation fault (core dumped) with optuna",
        "Question_body":"<p>I'm running a python script in the command line with <code>python3 CTGAN_noscale.py --database_name CTGAN_noshift<\/code> and receive the following error (with faulthandler):<\/p>\n<pre><code>Fatal Python error: Segmentation fault\n\nCurrent thread 0x00007f57e97fe700 (most recent call first):\n&lt;no Python frame&gt;\n\nThread 0x00007f593db07740 (most recent call first):\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/torch\/autograd\/__init__.py&quot;, line 145 in backward\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/torch\/tensor.py&quot;, line 245 in backward\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/ctgan\/synthesizers\/ctgan.py&quot;, line 374 in fit\n  File &quot;CTGAN_noscale.py&quot;, line 140 in objective\n  File &quot;CTGAN_noscale.py&quot;, line 162 in &lt;lambda&gt;\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/optuna\/_optimize.py&quot;, line 216 in _run_trial\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/optuna\/_optimize.py&quot;, line 162 in _optimize_sequential\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/optuna\/_optimize.py&quot;, line 65 in _optimize\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/optuna\/study.py&quot;, line 401 in optimize\n  File &quot;CTGAN_noscale.py&quot;, line 162 in run_CTGAN\n  File &quot;CTGAN_noscale.py&quot;, line 210 in &lt;module&gt;\nSegmentation fault (core dumped)\n<\/code><\/pre>\n<p>It seems that the problem is somehow with optuna.\nThe weird part is that everything worked fine on another server, after changing the server it crashed like this.<\/p>\n<p><strong>Update<\/strong><\/p>\n<p>I found out that the the problem doesn't occur when I don't use a docker container OR use a docker container without GPU.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1630053103290,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1659952934500,
        "Question_score_count":0.0,
        "Question_view_count":255.0,
        "Poster_created_time":1604138895270,
        "Poster_location":"Straubing, Deutschland",
        "Poster_reputation_count":11.0,
        "Poster_view_count":6.0,
        "Answer_body":"<p>I solved the problem by rebuilding a new image and derived a container from this image. In this container somehow the error didn't appear anymore.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1630389747607,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1604138895270,
        "Answerer_location":"Straubing, Deutschland",
        "Answerer_reputation_count":11.0,
        "Answerer_view_count":6.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68950349",
        "Tool":"Optuna",
        "Question_self_resolution":1.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"segment fault core dump run python script command line python ctgan noscal databas ctgan noshift receiv follow error faulthandl fatal python error segment fault current thread xfefe recent thread xfdb recent file usr local lib python dist packag torch autograd init line backward file usr local lib python dist packag torch tensor line backward file usr local lib python dist packag ctgan synthes ctgan line fit file ctgan noscal line object file ctgan noscal line file usr local lib python dist packag optim line run trial file usr local lib python dist packag optim line optim sequenti file usr local lib python dist packag optim line optim file usr local lib python dist packag studi line optim file ctgan noscal line run ctgan file ctgan noscal line segment fault core dump problem weird work fine server chang server crash like updat problem occur us docker contain us docker contain gpu",
        "Question_preprocessed_content":"segment fault python script line receiv problem weird work fine server chang server crash like updat problem us docker contain us docker contain gpu",
        "Question_gpt_summary_original":"The user is encountering a \"Segmentation fault (core dumped)\" error while running a Python script with optuna. The error seems to be related to the use of a docker container with GPU, as the problem doesn't occur when not using a container or using a container without GPU. The issue worked fine on another server, but after changing the server, it crashed.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Debug error with wandb",
        "Question_body":"<p>Hi,<br>\nI met with a debug error when tuning hyperparams with sweep.<\/p>\n<p><code>wandb: ERROR Run c3yfj87h errored: RuntimeError('cuDNN error: CUDNN_STATUS_INTERNAL_ERROR')<\/code><\/p>\n<p><code>wandb: ERROR Run 542e421i errored: RuntimeError('false INTERNAL ASSERT FAILED at \"..\/c10\/cuda\/CUDAGraphsC10Utils.h\":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32522')<\/code><\/p>\n<p>When I directly run it with a terminal, there is no such error. It only occurs when I debug. Could someone give some clues about the reason why?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1680193421703,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":194.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/debug-error-with-wandb\/4155",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"debug error met debug error tune hyperparam sweep error run cyfjh error runtimeerror cudnn error cudnn statu intern error error run error runtimeerror fals intern assert fail cuda cudagraphscutil report bug pytorch unknown cuda graph capturestatu directli run termin error occur debug clue reason",
        "Question_preprocessed_content":"debug met debug tune hyperparam directli run termin debug clue reason",
        "Question_gpt_summary_original":"The user encountered a debug error while tuning hyperparameters with sweep using wandb. The error message indicates a cuDNN error and an internal assert failure, which only occurs during debugging and not when running directly from the terminal. The user is seeking clues about the reason for this error.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Cant install imbalanced-learn on an Azure ML Environment",
        "Question_body":"<p>I have an Azure ML Workspace which comes by default with some pre-installed packages.<\/p>\n<p>I tried to install<\/p>\n<pre><code>!pip install -U imbalanced-learn\n<\/code><\/pre>\n<p>But I got this error<\/p>\n<pre><code>Requirement already up-to-date: scikit-learn in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (0.24.2)\nRequirement already satisfied, skipping upgrade: scipy&gt;=0.19.1 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (1.4.1)\nRequirement already satisfied, skipping upgrade: joblib&gt;=0.11 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (0.14.1)\nRequirement already satisfied, skipping upgrade: numpy&gt;=1.13.3 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (1.18.5)\nRequirement already satisfied, skipping upgrade: threadpoolctl&gt;=2.0.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from scikit-learn) (2.1.0)\nCollecting imbalanced-learn\n  Using cached imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\nRequirement already satisfied, skipping upgrade: threadpoolctl&gt;=2.0.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (2.1.0)\nRequirement already satisfied, skipping upgrade: joblib&gt;=0.11 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (0.14.1)\nRequirement already satisfied, skipping upgrade: scipy&gt;=1.1.0 in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages (from imbalanced-learn) (1.4.1)\nERROR: Could not find a version that satisfies the requirement scikit-learn&gt;=1.0.1 (from imbalanced-learn) (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0b1, 0.15.0b2, 0.15.0, 0.15.1, 0.15.2, 0.16b1, 0.16.0, 0.16.1, 0.17b1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19b2, 0.19.0, 0.19.1, 0.19.2, 0.20rc1, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21rc2, 0.21.0, 0.21.1, 0.21.2, 0.21.3, 0.22rc2.post1, 0.22rc3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0rc1, 0.23.0, 0.23.1, 0.23.2, 0.24.dev0, 0.24.0rc1, 0.24.0, 0.24.1, 0.24.2)\nERROR: No matching distribution found for scikit-learn&gt;=1.0.1 (from imbalanced-\n<\/code><\/pre>\n<p>learn)<\/p>\n<p>Not sure how to solve this, I have read in other posts to use conda, but that didnt work either.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1644933997077,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1644960360047,
        "Question_score_count":1.0,
        "Question_view_count":219.0,
        "Poster_created_time":1302030303092,
        "Poster_location":"Brussels, B\u00e9lgica",
        "Poster_reputation_count":30340.0,
        "Poster_view_count":2937.0,
        "Answer_body":"<p><a href=\"https:\/\/pypi.org\/project\/scikit-learn\/1.0.1\/\" rel=\"nofollow noreferrer\"><code>scikit-learn<\/code> 1.0.1<\/a> and up require Python &gt;= 3.7; you use Python 3.6. You need to upgrade Python or downgrade <code>imbalanced-learn<\/code>. <a href=\"https:\/\/pypi.org\/project\/imbalanced-learn\/0.8.1\/\" rel=\"nofollow noreferrer\"><code>imbalanced-learn<\/code> 0.8.1<\/a> allows Python 3.6 so<\/p>\n<pre><code>!pip install -U &quot;imbalanced-learn &lt; 0.9&quot;\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Question_closed_time":1644935036627,
        "Answer_last_edit_time":null,
        "Answer_score_count":2.0,
        "Answerer_created_time":1494171603136,
        "Answerer_location":null,
        "Answerer_reputation_count":73187.0,
        "Answerer_view_count":8473.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71127858",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"instal imbalanc learn environ workspac come default pre instal packag tri instal pip instal imbalanc learn got error requir date scikit learn anaconda env lib python site packag requir satisfi skip upgrad scipi anaconda env lib python site packag scikit learn requir satisfi skip upgrad joblib anaconda env lib python site packag scikit learn requir satisfi skip upgrad numpi anaconda env lib python site packag scikit learn requir satisfi skip upgrad threadpoolctl anaconda env lib python site packag scikit learn collect imbalanc learn cach imbalanc learn whl requir satisfi skip upgrad threadpoolctl anaconda env lib python site packag imbalanc learn requir satisfi skip upgrad joblib anaconda env lib python site packag imbalanc learn requir satisfi skip upgrad scipi anaconda env lib python site packag imbalanc learn error version satisfi requir scikit learn imbalanc learn version post post dev error match distribut scikit learn imbalanc learn sure solv read post us conda didnt work",
        "Question_preprocessed_content":"environ workspac come default packag tri got learn sure solv read post us conda didnt work",
        "Question_gpt_summary_original":"The user is trying to install imbalanced-learn on an Azure ML Workspace, but is encountering an error stating that it cannot find a matching distribution for scikit-learn>=1.0.1. The user has tried using conda but it did not work.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Cannot connect PlainText (JSON) to Dataset at Azure Machine Learning",
        "Question_body":"<p>I uploaded a PlainText file in a JSON format to the new Azure Machine Learning Studio (studio.azureml.net), but I cannot connect the PlainText object with any module. I get all the time the error message \"Cannot connect PlainText to Dataset...\". <\/p>\n\n<p>At the documentation (<a href=\"http:\/\/help.azureml.net\/Content\/html\/e8219c57-e8dd-4989-9559-bbd73ba5bcea.htm\" rel=\"nofollow\">here<\/a>) is written that \"Plain text can be read and then split up into columns with the help of downstream preprocessing modules.\", but I can't find any downstream preprocessing modules.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1418490465200,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1446192454607,
        "Question_score_count":5.0,
        "Question_view_count":2157.0,
        "Poster_created_time":1408374893790,
        "Poster_location":null,
        "Poster_reputation_count":53.0,
        "Poster_view_count":11.0,
        "Answer_body":"<p>Actually Azure ML can't process JSON data. It will probably be added in a future update, but the easiest way (in my opinion) to consume that data is to convert it into CSV format. This can be done quickly with Power Query. Then you upload the CSV file as a new dataset.<\/p>",
        "Answer_comment_count":0.0,
        "Question_closed_time":1418919495800,
        "Answer_last_edit_time":null,
        "Answer_score_count":6.0,
        "Answerer_created_time":1345114008840,
        "Answerer_location":"Lyon, France",
        "Answerer_reputation_count":4233.0,
        "Answerer_view_count":151.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/27461432",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"connect plaintext json dataset upload plaintext file json format new studio studio net connect plaintext object modul time error messag connect plaintext dataset document written plain text read split column help downstream preprocess modul downstream preprocess modul",
        "Question_preprocessed_content":"plaintext dataset upload plaintext file json format new studio plaintext object modul time plaintext document plain text read split column help downstream downstream modul",
        "Question_gpt_summary_original":"The user is unable to connect a PlainText file in JSON format to any module in Azure Machine Learning Studio and is receiving an error message stating \"Cannot connect PlainText to Dataset\". The user is also unable to find any downstream preprocessing modules as mentioned in the documentation.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Prevent boto3.client('sagemaker').create_auto_ml_job() from deploying endpoint",
        "Question_body":"When I invoke the .create_auto_ml_job() method both with and without the optional ModelDeployConfig kwarg, the autopilot job deploys an endpoint using the best model. Is there a way to prevent the .create_auto_ml_job() method from behaving this way? I do not wish to deploy the best model to an endpoint, and do not wish to have to delete this endpoint.",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_created_time":1669662766261,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1670009940311,
        "Question_score_count":0.0,
        "Question_view_count":73.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUGEnbfLBgQJKrbdKfizHkEw\/prevent-boto3-client-sagemaker-create-auto-ml-job-from-deploying-endpoint",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":0.0,
        "Poster_isModerator":0.0,
        "Poster_isExpert":0.0,
        "Poster_isCse":0.0,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"prevent boto client creat auto job deploi endpoint invok creat auto job method option modeldeployconfig kwarg autopilot job deploi endpoint best model wai prevent creat auto job method behav wai wish deploi best model endpoint wish delet endpoint",
        "Question_preprocessed_content":"prevent deploi endpoint invok method option modeldeployconfig kwarg autopilot job deploi endpoint best model wai prevent method behav wai wish deploi best model endpoint wish delet endpoint",
        "Question_gpt_summary_original":"The user is facing a challenge with the behavior of the .create_auto_ml_job() method in deploying an endpoint using the best model, even when the optional ModelDeployConfig kwarg is not used. The user is seeking a way to prevent this behavior as they do not wish to deploy the best model to an endpoint and do not want to have to delete the endpoint.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"AWS web service to upload and analyse users video",
        "Question_body":"<p>I'm developing a prototype of a video analysis service on AWS.<\/p>\n<p>The question is: am thinking in the right direction or I will fail to implement this architecture?<\/p>\n<p>Architecture:<\/p>\n<ol>\n<li>Flask on EC2.<\/li>\n<li>User(authenticated) upload file via web view, I'm saving it to S3.<\/li>\n<li>Lambda triggers SageMaker.<\/li>\n<li>SageMaker taking a file from S3, making preparation and analysis then: 1) Saving the results to PostgreSQL DB. 2) Triggers lambda that sends a notification to Flask that analysis is Done<\/li>\n<li>User receives a notification from Flask that the analysis is done.<\/li>\n<li>Flask web page visualizes data from the analysis for the user.<\/li>\n<\/ol>\n<p>It has only a prototyping purpose, I'm trying to keep it as simple as possible.<\/p>\n<p>will appreciate any comments and recommendations.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1631895559793,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":39.0,
        "Poster_created_time":1441637659808,
        "Poster_location":null,
        "Poster_reputation_count":119.0,
        "Poster_view_count":27.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69226644",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"aw web servic upload analys user video develop prototyp video analysi servic aw question think right direct fail implement architectur architectur flask user authent upload file web view save lambda trigger take file make prepar analysi save result postgresql trigger lambda send notif flask analysi user receiv notif flask analysi flask web page visual data analysi user prototyp purpos try simpl possibl appreci comment recommend",
        "Question_preprocessed_content":"aw web servic upload analys user video develop prototyp video analysi servic aw question think right direct fail implement architectur architectur flask user upload file web view save lambda take file make prepar analysi save result postgresql lambda send notif flask analysi user receiv notif flask analysi flask web page visual data analysi user prototyp purpos try simpl",
        "Question_gpt_summary_original":"The user is developing a prototype of a video analysis service on AWS and is seeking feedback on their proposed architecture. The architecture involves Flask on EC2, user-authenticated file uploads to S3, Lambda triggers SageMaker for analysis, and results saved to PostgreSQL DB. The user receives a notification from Flask when the analysis is done, and Flask web page visualizes data from the analysis for the user. The user is seeking comments and recommendations to keep the prototype as simple as possible.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Forecasting and AutoMLConfig do not propagate to UI",
        "Question_body":"<p>Hi! Using the SDK version 19 and setting the blocked_models as none or a given model do not propagate in the triggered run to only block that model, instead it blocks a bunch. Also the forecastingParameters do not propagate as well. <img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/60031-screenshot-2021-01-24-at-220420.png?platform=QnA\" alt=\"60031-screenshot-2021-01-24-at-220420.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/60032-screenshot-2021-01-24-at-220426.png?platform=QnA\" alt=\"60032-screenshot-2021-01-24-at-220426.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/59974-screenshot-2021-01-24-at-220637.png?platform=QnA\" alt=\"59974-screenshot-2021-01-24-at-220637.png\" \/><img src=\"https:\/\/learn-attachment.microsoft.com\/api\/attachments\/59994-screenshot-2021-01-24-at-220642.png?platform=QnA\" alt=\"59994-screenshot-2021-01-24-at-220642.png\" \/>    <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1611539077903,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":null,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/learn.microsoft.com\/en-us\/answers\/questions\/243175\/forecasting-and-automlconfig-do-not-propagate-to-u",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"forecast automlconfig propag sdk version set block model given model propag trigger run block model instead block bunch forecastingparamet propag",
        "Question_preprocessed_content":"forecast automlconfig propag sdk version given model propag run block model instead block bunch forecastingparamet propag",
        "Question_gpt_summary_original":"The user is facing issues with the SDK version 19 where blocked_models are not propagating to the triggered run to block only a specific model, and instead, it blocks multiple models. Additionally, the forecastingParameters are also not propagating. The user has provided screenshots to illustrate the problem.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Digest mismatch error when trying to download model artifact from S3",
        "Question_body":"<p>I\u2019m using AWS Sagemaker to train a Keras model with the Wandb callback. In my Sagemaker script, I save checkpoints to <code>'\/opt\/ml\/checkpoints\/'<\/code> which it redirects to an s3 bucket continuously. After the model has finished training, I create my artifact and add a reference to that bucket.<\/p>\n<p>Later, if I try to download the model with:<\/p>\n<pre><code class=\"lang-auto\">model_path = run.use_artifact(...)\nmodel_path.download()\n<\/code><\/pre>\n<p>I get the following error:<\/p>\n<blockquote>\n<p>ValueError: Digest mismatch for object s3:\/\/\u2026\/variables\/variables.data-00000-of-00001: expected 4f8d37a52a3e87f1f0ee2d3101688848-3 but found 8ad5ef5242d547d7edaa76f620597b60-3<\/p>\n<\/blockquote>\n<p>My guess is that I\u2019ve added the reference to the artifact before Sagemaker has pushed the final model from the local directory to S3. I\u2019m not sure how to get around this, is there a better way to have my Artifacts be linked to an S3 bucket?<\/p>",
        "Question_answer_count":7,
        "Question_comment_count":null,
        "Question_created_time":1666051892610,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":2.0,
        "Question_view_count":308.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":"<p>Hi <a class=\"mention\" href=\"\/u\/dspectrum\">@dspectrum<\/a>,<\/p>\n<p>Looking at your error and tracing back through our code - looks like versioning is not enabled on your S3 bucket, which means the artifact is changing the file itself, leading to different hashes. I would suggest turning on versioning on your S3 bucket and letting me know if you still run into the same error.<\/p>",
        "Answer_comment_count":null,
        "Question_closed_time":1666891898080,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/digest-mismatch-error-when-trying-to-download-model-artifact-from-s3\/3269",
        "Tool":"Weights & Biases",
        "Question_self_resolution":0.0,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"digest mismatch error try download model artifact train kera model callback script save checkpoint opt checkpoint redirect bucket continu model finish train creat artifact add refer bucket later try download model model path run us artifact model path download follow error valueerror digest mismatch object variabl variabl data expect fdaaeffe adefddedaafb guess iv ad refer artifact push final model local directori sure better wai artifact link bucket",
        "Question_preprocessed_content":"digest mismatch try download model artifact train kera model script save checkpoint redirect bucket continu model finish train creat artifact refer bucket later try download model digest mismatch object expect iv refer artifact push final model local directori sure wai artifact link bucket",
        "Question_gpt_summary_original":"The user is encountering a digest mismatch error while trying to download a model artifact from S3 in AWS Sagemaker. The error is caused by adding a reference to the artifact before the final model is pushed from the local directory to S3. The user is unsure how to resolve the issue and is seeking a better way to link Artifacts to an S3 bucket.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Wandb process not getting terminated properly",
        "Question_body":"<p>My process is not getting terminated properly (running in a multi-GPU setting). It is trying to upload information but gets stuck for some reason. I am facing this problem since yesterday, and haven\u2019t made any changes to the version of the library (although this didn\u2019t get resolved after upgrading the library to the latest version). Any help will be highly appreciated. I can disable wandb completely by passing <code>mode = \"disabled\"<\/code> in the test setting, but need it while running sweeps or logging training metrics.<br>\nP.S.: Same code was running just fine till yesterday.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d.png\" data-download-href=\"\/uploads\/short-url\/7rETgzwUz7nuCquITds6NyYKXVj.png?dl=1\" title=\"Screenshot 2021-10-30 at 6.52.11 PM\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d_2_690x69.png\" alt=\"Screenshot 2021-10-30 at 6.52.11 PM\" data-base62-sha1=\"7rETgzwUz7nuCquITds6NyYKXVj\" width=\"690\" height=\"69\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d_2_690x69.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d_2_1035x103.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/342fa335656c0535a9ca21307507f30ef53feb1d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screenshot 2021-10-30 at 6.52.11 PM<\/span><span class=\"informations\">1048\u00d7106 27.4 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_created_time":1635600298677,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":343.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-process-not-getting-terminated-properly\/1166",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"process get termin properli process get termin properli run multi gpu set try upload inform get stuck reason face problem yesterdai havent chang version librari didnt resolv upgrad librari latest version help highli appreci disabl complet pass mode disabl test set need run sweep log train metric code run fine till yesterdai screenshot",
        "Question_preprocessed_content":"termin properli termin properli try upload inform get stuck reason face problem yesterdai havent chang version librari help highli disabl complet test train metric code fine yesterdai",
        "Question_gpt_summary_original":"The user is facing an issue with the Wandb process not getting terminated properly while running in a multi-GPU setting. The process gets stuck while trying to upload information, and the problem persists even after upgrading the library to the latest version. The user seeks help to resolve the issue as they need Wandb while running sweeps or logging training metrics.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Lambda read DynamoDB and send to ML Endpoint",
        "Question_body":"<p><strong>Background:<\/strong><\/p>\n\n<blockquote>\n  <p>I have a DynamoDB table with column's \"TimeStamp | Data1 | Data2\". I\n  also have a ML endpoint in SageMaker which needs Data1 and Data2 to\n  generate one output value(score).<\/p>\n<\/blockquote>\n\n<p><strong>Question:<\/strong><\/p>\n\n<blockquote>\n  <p>My ambition is to script a Lambda function (Java or Python) to read\n  the latest row in the DynamoDB table, and send this through the\n  Endpoint and receive the score.<\/p>\n<\/blockquote>\n\n<p><strong>What I have tried:<\/strong><\/p>\n\n<blockquote>\n  <p>I have only found guides where you do this by exporting the whole\n  DynamoDB table to s3 and in Data Pipeline send it to the Endpoint.\n  This is not how I want it to work!<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1540988846833,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":1.0,
        "Question_view_count":782.0,
        "Poster_created_time":1426492930156,
        "Poster_location":null,
        "Poster_reputation_count":398.0,
        "Poster_view_count":84.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53083329",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"lambda read dynamodb send endpoint background dynamodb tabl column timestamp data data endpoint need data data gener output valu score question ambit script lambda function java python read latest row dynamodb tabl send endpoint receiv score tri guid export dynamodb tabl data pipelin send endpoint want work",
        "Question_preprocessed_content":"lambda read dynamodb send endpoint background dynamodb tabl column timestamp data data endpoint data data gener output valu question ambit script lambda function read latest row dynamodb tabl send endpoint receiv score tri guid export dynamodb tabl data pipelin send endpoint want work",
        "Question_gpt_summary_original":"The user wants to create a Lambda function in Java or Python to read the latest row in a DynamoDB table with columns \"TimeStamp | Data1 | Data2\" and send it to an ML endpoint in SageMaker to generate a score. The user has tried exporting the whole DynamoDB table to s3 and sending it to the endpoint using Data Pipeline, but wants a different solution.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Copy instead of moving runs to team",
        "Question_body":"<p>Hello,<\/p>\n<p>I know how to move runs to a team, but my problem is that the runs are then removed from my profile.<\/p>\n<p>Is there a way to copy the runs, keeping them in my profile and in the team ?<\/p>\n<p>A better solution would be to link them to a team project and if we add things to the run in the user project the changes should  also be  reported in the team project. Basically, both projects would point to the same unique run and if a user deletes a run in his project the run would still be present in team\u2019s project (only the link would be removed). If a run as no links attached to it, it should be erased.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_created_time":1652890834786,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":85.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/copy-instead-of-moving-runs-to-team\/2442",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"copi instead move run team hello know run team problem run remov profil wai copi run keep profil team better solut link team project add thing run user project chang report team project basic project point uniqu run user delet run project run present team project link remov run link attach eras",
        "Question_preprocessed_content":"copi instead move run team know run team problem run remov profil wai copi run profil team solut link team project thing run user project chang report team project project point uniqu run user delet run project run present team project run link eras",
        "Question_gpt_summary_original":"The user is facing a challenge while moving runs to a team as the runs are removed from their profile. They are looking for a way to copy the runs and keep them in both their profile and the team. The user suggests linking the runs to a team project so that any changes made in the user project are also reported in the team project.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"ERROR: Cannot uninstall 'ruamel-yaml' while creating docker image for azure ML ACI deployment",
        "Question_body":"<p><strong>I am trying to deploy machine learning model in azure ACI but i am getting following error while creating a docker image<\/strong><\/p>\n<pre><code>Pip subprocess error:\nERROR: Cannot uninstall 'ruamel-yaml'. It is a distutils installed project and thus we cannot \naccurately determine which files belong to it which would lead to only a partial uninstall.\n<\/code><\/pre>\n<p>Below is my yml file for pip dependencies<\/p>\n<pre><code>name: project_environment\ndependencies:\n# The python interpreter version.\n\n# Currently Azure ML only supports 3.5.2 and later.\n\n\n- pip:\n  # Required packages for AzureML execution, history, and data preparation.\n  - pandas\n  - azureml-defaults\n  - azureml-sdk\n  - azureml-widgets\n  - numpy\n  - tensorflow-gpu\n  - keras\n  - azureml-defaults\n  - torch==1.4.0\n  - scikit-learn==0.22.2.post1\n<\/code><\/pre>\n<p>and if i use conda instead of pip then i am getting following error<\/p>\n<pre><code>Step 11\/13 : RUN CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; if [ -n \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; ]; then conda env update -p \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; -f '\/var\/azureml-app\/binary_2.yml'; else \nconda env update -n base -f '\/var\/azureml-app\/binary_2.yml'; fi &amp;&amp; conda \nclean -aqy &amp;&amp; rm -rf \/root\/.cache\/pip &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; \nfind &quot;$CONDA_ROOT_DIR&quot; -type d -name __pycache__ -exec rm -rf {} +\n---&gt; Running in 9e6eb7278bfc  \n[91mUnable to install package for Conda.\n\nPlease double check and ensure you dependencies file has\nthe correct spelling.  You might also try installing the\nconda-env-Conda package to see if provides the required\ninstaller. \n[0mThe command '\/bin\/sh -c CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; if [ -n \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; ]; then conda env update -p \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; -f '\/var\/azureml-app\/binary_2.yml'; else \n conda env update -n base -f '\/var\/azureml-app\/binary_2.yml'; fi &amp;&amp; conda \nclean \n-aqy &amp;&amp; rm -rf \/root\/.cache\/pip &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find \n&quot;$CONDA_ROOT_DIR&quot; -type d -name __pycache__ -exec rm -rf {} +' returned a \nnon- \n zero code: 255\n 2020\/08\/12 19:36:09 Container failed during run: acb_step_0. No retries \n remaining.\n failed to run step ID: acb_step_0: exit status 255\n<\/code><\/pre>\n<p>**Can anyone please help me **<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":6.0,
        "Question_created_time":1597259959573,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1597261729536,
        "Question_score_count":9.0,
        "Question_view_count":9743.0,
        "Poster_created_time":1426308318630,
        "Poster_location":null,
        "Poster_reputation_count":179.0,
        "Poster_view_count":44.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63383400",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"error uninstal ruamel yaml creat docker imag aci deploy try deploi machin learn model azur aci get follow error creat docker imag pip subprocess error error uninstal ruamel yaml distutil instal project accur determin file belong lead partial uninstal yml file pip depend project environ depend python interpret version current support later pip requir packag execut histori data prepar panda default sdk widget numpi tensorflow gpu kera default torch scikit learn post us conda instead pip get follow error step run conda root dir conda info root conda environ path conda env updat conda environ path var app binari yml conda env updat base var app binari yml conda clean aqi root cach pip conda root dir pkg conda root dir type pycach exec run eebbfc munabl instal packag conda doubl check ensur depend file correct spell try instal conda env conda packag provid requir instal mthe command bin conda root dir conda info root conda environ path conda env updat conda environ path var app binari yml conda env updat base var app binari yml conda clean aqi root cach pip conda root dir pkg conda root dir type pycach exec return non zero code contain fail run acb step retri remain fail run step acb step exit statu help",
        "Question_preprocessed_content":"creat docker imag aci deploy try deploi machin learn model azur aci creat docker imag yml file pip depend us conda instead pip help",
        "Question_gpt_summary_original":"The user is encountering an error while creating a docker image for Azure ML ACI deployment. The error message states that 'ruamel-yaml' cannot be uninstalled as it is a distutils installed project. The user has provided a yml file for pip dependencies, but using conda instead of pip results in another error. The user is seeking help to resolve the issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Can't change virtual environment within Azure ML notebook",
        "Question_body":"<p>For some reason the jupyter notebooks on my VM are in the wrong environment (ie stuck in <code>(base)<\/code>). Furthermore, I can change the environment in the terminal but not in the notebook. Here is what happens when I attempt <code>!conda activate desired_env<\/code> in the notebook:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\nTo initialize your shell, run\n\n    $ conda init &lt;SHELL_NAME&gt;\n\nCurrently supported shells are:\n  - bash\n  - fish\n  - tcsh\n  - xonsh\n  - zsh\n  - powershell\n\nSee 'conda init --help' for more information and options.\n\nIMPORTANT: You may need to close and restart your shell after running 'conda init'.\n\n\n# conda environments:\n#\nbase                  *  \/anaconda\nazureml_py36             \/anaconda\/envs\/azureml_py36\nazureml_py38             \/anaconda\/envs\/azureml_py38\nazureml_py38_pytorch     \/anaconda\/envs\/azureml_py38_pytorch\nazureml_py38_tensorflow     \/anaconda\/envs\/azureml_py38_tensorflow\n<\/code><\/pre>\n<p>I tried the answers <a href=\"https:\/\/stackoverflow.com\/questions\/61915607\/commandnotfounderror-your-shell-has-not-been-properly-configured-to-use-conda\">here<\/a> (e.g., first running <code>!source \/anaconda\/etc\/profile.d\/conda.sh<\/code>).<\/p>\n<p>I also tried activating the environment using <code>source<\/code> rather than 'conda activate': <code>!source \/anaconda\/envs\/desired_env\/bin\/activate<\/code>. This runs but doesn't actually do anything when I see the current environment in <code>conda env list<\/code><\/p>\n<p>Edit: also adding that if I install a package in the <code>(base)<\/code> environment in the terminal, I still don't have access to it in jupyter notebook.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1636646694700,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1636647028003,
        "Question_score_count":1.0,
        "Question_view_count":672.0,
        "Poster_created_time":1586979502910,
        "Poster_location":null,
        "Poster_reputation_count":361.0,
        "Poster_view_count":47.0,
        "Answer_body":"<p>I'm the PM that released AzureML Notebooks, you can't activate a Conda env from a cell, you have to create a new kernel will the Conda Env. Here are the instructions: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#add-new-kernels\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#add-new-kernels<\/a><\/p>",
        "Answer_comment_count":8.0,
        "Question_closed_time":1636652640790,
        "Answer_last_edit_time":null,
        "Answer_score_count":4.0,
        "Answerer_created_time":1614882423070,
        "Answerer_location":"Seattle, WA, USA",
        "Answerer_reputation_count":111.0,
        "Answerer_view_count":13.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69931411",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"chang virtual environ notebook reason jupyt notebook wrong environ stuck base furthermor chang environ termin notebook happen attempt conda activ desir env notebook commandnotfounderror shell properli configur us conda activ initi shell run conda init current support shell bash fish tcsh xonsh zsh powershel conda init help inform option import need close restart shell run conda init conda environ base anaconda anaconda env anaconda env pytorch anaconda env pytorch tensorflow anaconda env tensorflow tri answer run sourc anaconda profil conda tri activ environ sourc conda activ sourc anaconda env desir env bin activ run actual current environ conda env list edit ad instal packag base environ termin access jupyt notebook",
        "Question_preprocessed_content":"chang virtual environ reason jupyt wrong environ furthermor chang environ termin tri answer tri activ environ conda activ run environ edit packag environ termin jupyt",
        "Question_gpt_summary_original":"The user is unable to change the virtual environment within Azure ML notebook and is stuck in the wrong environment. The user tried changing the environment in the terminal but encountered an error message. The user also tried activating the environment using 'source' but it did not work. Additionally, the user is unable to access packages installed in the (base) environment in the notebook.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"How can I deploy AWS SageMaker Linear Learner Model in a Local Environment",
        "Question_body":"<p>I have trained a AWS SageMaker Model using the in-built Linear Learner algorithm. I can download the trained model artifacts (model.tar.gz) from S3.<\/p>\n\n<p>How can I deploy the model in an local environment which is independent of AWS, so I can make predictions inferences calls without internet access?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1533869148300,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":518.0,
        "Poster_created_time":1533787759288,
        "Poster_location":null,
        "Poster_reputation_count":1.0,
        "Poster_view_count":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51778200",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"deploi linear learner model local environ train model built linear learner algorithm download train model artifact model tar deploi model local environ independ aw predict infer call internet access",
        "Question_preprocessed_content":"deploi linear learner model local environ train model linear learner algorithm download train model artifact deploi model local environ independ aw predict infer internet",
        "Question_gpt_summary_original":"The user has trained an AWS SageMaker Model using the Linear Learner algorithm and downloaded the trained model artifacts from S3. They are now looking for a way to deploy the model in a local environment that is independent of AWS, so they can make prediction inference calls without internet access.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Read bytes file from AWS S3 into AWS SageMaker conda_python3",
        "Question_body":"<p>Good morning,\nYesterday I saved a file from SageMaker conda_python3 to S3 like this:<\/p>\n\n<pre><code>s3 = boto3.client(\n            's3',\n            aws_access_key_id='XXXX',\n            aws_secret_access_key='XXXX'\n        )\ny = pandas.DataFrame(df.tag_factor,index = df.index)\ns3.put_object(Body = y.values.tobytes(), Bucket='xxx', Key='xxx')\n<\/code><\/pre>\n\n<p>Today I am trying to open it with conda_python3 as a pandas.Series or as a numpy.array object, with this code:<\/p>\n\n<pre><code>s3 = boto3.client(\n            's3',\n            aws_access_key_id='XXX',\n            aws_secret_access_key='XXX'\n        )\ny_bytes = s3.get_object(Bucket='xxx', Key='xxx')\ny = numpy.load(io.BytesIO(y_bytes['Body'].read()))\n<\/code><\/pre>\n\n<p>but I am getting this error: OSError: Failed to interpret file &lt;_io.BytesIO >object at 0x7fcb0b403258> as a pickle<\/p>\n\n<p>I tried this:<\/p>\n\n<pre><code>y = numpy.fromfile(io.BytesIO(y_bytes['Body'].read()))\n<\/code><\/pre>\n\n<p>and I get this error:<\/p>\n\n<blockquote>\n  <p>UnsupportedOperation: fileno<\/p>\n<\/blockquote>\n\n<p>I tried this:<\/p>\n\n<pre><code>y = pd.read_csv(io.BytesIO(y_bytes['Body'].read()), sep=\" \", header=None)\n<\/code><\/pre>\n\n<p>and I get this error:<\/p>\n\n<blockquote>\n  <p>EmptyDataError: No columns to parse from file<\/p>\n<\/blockquote>\n\n<p>How can I read this file?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_created_time":1544802647203,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1605707872200,
        "Question_score_count":1.0,
        "Question_view_count":1398.0,
        "Poster_created_time":1458416707412,
        "Poster_location":"Ecuador, Quito",
        "Poster_reputation_count":617.0,
        "Poster_view_count":117.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53782956",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"read byte file aw conda python good morn yesterdai save file conda python like boto client aw access kei xxxx aw secret access kei xxxx panda datafram tag factor index index object bodi valu tobyt bucket xxx kei xxx todai try open conda python panda seri numpi arrai object code boto client aw access kei xxx aw secret access kei xxx byte object bucket xxx kei xxx numpi load bytesio byte bodi read get error oserror fail interpret file object xfcbb pickl tri numpi fromfil bytesio byte bodi read error unsupportedoper fileno tri read csv bytesio byte bodi read sep header error emptydataerror column pars file read file",
        "Question_preprocessed_content":"read byte file aw morn yesterdai save file like todai try open object code fail interpret file object fcb pickl tri fileno tri column pars file read file",
        "Question_gpt_summary_original":"The user is facing challenges in reading a file from AWS S3 into AWS SageMaker conda_python3 as a pandas.Series or as a numpy.array object. The user has tried different methods such as numpy.fromfile and pd.read_csv but is encountering errors such as OSError, UnsupportedOperation, and EmptyDataError. The user is seeking guidance on how to read the file.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Interactive Login coming for child run during hyperparameter tuning (hyperdrive) in Azure ML Notebook",
        "Question_body":"<p>I have created a train.py script in Azure and it has the data cleaning, wrangling and classification part using XGBoost. Then I have created a ipynb file to do hyperparameter tuning by calling train.py script.<\/p>\n<p>The child runs keep asking me to perform manual interactive login for every run. Please see the image.\nI did the interactive login for many runs but still it will ask me everytime.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eKutW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eKutW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Here is the code in ipynb file:<\/p>\n<pre><code>subscription_id = 'XXXXXXXXXXXXXXXXXX'\nresource_group = 'XXXXXXXXXXXXXXX'\nworkspace_name = 'XXXXXXXXXXXXXXX'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\nmyenv = Environment(workspace=workspace, name=&quot;myenv&quot;)\n\nfrom azureml.core.conda_dependencies import CondaDependencies\nconda_dep = CondaDependencies()\n\nconda_dep.add_pip_package(&quot;numpy&quot;)\nconda_dep.add_pip_package(&quot;pandas&quot;)\nconda_dep.add_pip_package(&quot;nltk&quot;)\nconda_dep.add_pip_package(&quot;sklearn&quot;)\nconda_dep.add_pip_package(&quot;xgboost&quot;)\n\nmyenv.python.conda_dependencies = conda_dep\n\nexperiment_name = 'experiments_xgboost_hyperparams'\nexperiment = Experiment(workspace, experiment_name)\n\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\n\ncompute_cluster_name = 'shan'\n\ntry:\n    compute_target = ComputeTarget(workspace=workspace, name = compute_cluster_name)\n    print('Found the compute cluster')\n\nexcept ComputeTargetException:\n    compute_config = AmlCompute.provisioning_configuration(vm_size=&quot;STANDARD_DS3_V2&quot;, max_nodes=4)\n    compute_target = ComputeTarget.create(workspace, compute_cluster_name, compute_config)\n    compute_target.wait_for_completion(show_output=True)\n\nearly_termination_policy = BanditPolicy(slack_factor=0.01)\n\nfrom azureml.train.hyperdrive import RandomParameterSampling\nfrom azureml.train.hyperdrive import uniform, choice\nps = RandomParameterSampling( {\n        'learning_rate': uniform(0.1, 0.9),\n        'max_depth': choice(range(3,8)),\n        'n_estimators': choice(300, 400, 500, 600)\n    }\n)\n\nprimary_metric_name=&quot;accuracy&quot;,\nprimary_metric_goal=PrimaryMetricGoal.MAXIMIZE\n\n\n\n from azureml.core import ScriptRunConfig\n    script_run_config = ScriptRunConfig(source_directory='.', script='train.py', compute_target=compute_target, environment=myenv)\n    # script_run_config.run_config.target = compute_target\n    \n    # Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n    hyperdrive_config = HyperDriveConfig(run_config=script_run_config,\n                                        hyperparameter_sampling=ps,\n                                        policy=early_termination_policy,\n                                        primary_metric_name=&quot;accuracy&quot;,\n                                        primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                                        max_total_runs=10,\n                                        max_concurrent_runs=4)\n\nhyperdrive = experiment.submit(config=hyperdrive_config)\n\nRunDetails(hyperdrive).show()\nhyperdrive.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>This just keeps asking me interactive login for every child run.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1613646219407,
        "Question_favorite_count":1.0,
        "Question_last_edit_time":1613646463208,
        "Question_score_count":0.0,
        "Question_view_count":157.0,
        "Poster_created_time":1598018883048,
        "Poster_location":null,
        "Poster_reputation_count":77.0,
        "Poster_view_count":35.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66258663",
        "Tool":"Azure Machine Learning",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"interact login come child run hyperparamet tune hyperdr notebook creat train script azur data clean wrangl classif xgboost creat ipynb file hyperparamet tune call train script child run ask perform manual interact login run imag interact login run ask everytim code ipynb file subscript xxxxxxxxxxxxxxxxxx resourc group xxxxxxxxxxxxxxx workspac xxxxxxxxxxxxxxx workspac workspac subscript resourc group workspac myenv environ workspac workspac myenv core conda depend import condadepend conda dep condadepend conda dep add pip packag numpi conda dep add pip packag panda conda dep add pip packag nltk conda dep add pip packag sklearn conda dep add pip packag xgboost myenv python conda depend conda dep experi experi xgboost hyperparam experi experi workspac experi core comput import computetarget amlcomput core comput target import computetargetexcept comput cluster shan try comput target computetarget workspac workspac comput cluster print comput cluster computetargetexcept comput config amlcomput provis configur size standard max node comput target computetarget creat workspac comput cluster comput config comput target wait complet output true earli termin polici banditpolici slack factor train hyperdr import randomparametersampl train hyperdr import uniform choic randomparametersampl learn rate uniform max depth choic rang estim choic primari metric accuraci primari metric goal primarymetricgo maxim core import scriptrunconfig script run config scriptrunconfig sourc directori script train comput target comput target environ myenv script run config run config target comput target creat hyperdriveconfig estim hyperparamet sampler polici hyperdr config hyperdriveconfig run config script run config hyperparamet sampl polici earli termin polici primari metric accuraci primari metric goal primarymetricgo maxim max total run max concurr run hyperdr experi submit config hyperdr config rundetail hyperdr hyperdr wait complet output true keep ask interact login child run",
        "Question_preprocessed_content":"interact login come child run hyperparamet tune creat script azur data clean wrangl creat ipynb file hyperparamet tune script child run ask perform manual interact login run imag interact login run ask everytim code ipynb file ask interact login child run",
        "Question_gpt_summary_original":"The user has created a train.py script in Azure and an ipynb file to do hyperparameter tuning by calling the train.py script. However, the child runs keep asking for manual interactive login for every run, even after performing the interactive login for many runs. The user has shared the code in the ipynb file and is seeking a solution to this issue.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"SageMaker NodeJS's SDK is not locking the API Version",
        "Question_body":"<p>I am running some code in AWS Lambda that dynamically creates SageMaker models.\nI am locking Sagemaker's API version like so:<\/p>\n\n<p><code>const sagemaker = new AWS.SageMaker({apiVersion: '2017-07-24'});<\/code><\/p>\n\n<p>And here's the code to create the model:<\/p>\n\n<pre><code>await sagemaker.createModel({\n        ExecutionRoleArn: 'xxxxxx',\n        ModelName: sageMakerConfigId,\n        Containers: [{\n            Image: ecrUrl\n        }]\n    }).promise()\n<\/code><\/pre>\n\n<p>This code runs just fine locally with <code>aws-sdk<\/code> on <code>2.418.0<\/code>. <\/p>\n\n<p>However, when this code is deployed to Lambda, it doesn't work due to some validation errors upon creating the model:<\/p>\n\n<blockquote>\n  <ul>\n  <li>MissingRequiredParameter: Missing required key 'PrimaryContainer' in params<\/li>\n  <li>UnexpectedParameter: Unexpected key 'Containers' found in params<\/li>\n  <\/ul>\n<\/blockquote>\n\n<p>Is anyone aware of existing bugs in the <code>aws-sdk<\/code> for NodeJS using the SDK provided by AWS in the Lambda context? I believe the SDK available inside AWS Lambda is more up-to-date than <code>2.418.0<\/code> but apparently there are compatibility issues.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_created_time":1553074522987,
        "Question_favorite_count":0.0,
        "Question_last_edit_time":1553082788147,
        "Question_score_count":1.0,
        "Question_view_count":277.0,
        "Poster_created_time":1548169897263,
        "Poster_location":null,
        "Poster_reputation_count":6496.0,
        "Poster_view_count":759.0,
        "Answer_body":"<p>As you've noticed the 'embedded' lambda version of the aws-sdk lags behind. It's actually on <code>2.290.0<\/code> (you can see the full details on the environment here: <a href=\"https:\/\/docs.aws.amazon.com\/lambda\/latest\/dg\/current-supported-versions.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/lambda\/latest\/dg\/current-supported-versions.html<\/a>)<\/p>\n\n<p>You can see here: <a href=\"https:\/\/github.com\/aws\/aws-sdk-js\/blame\/master\/clients\/sagemaker.d.ts\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/aws-sdk-js\/blame\/master\/clients\/sagemaker.d.ts<\/a> that it is not until <code>2.366.0<\/code> that the params for this method included <code>Containers<\/code> and did not require <code>PrimaryContainer<\/code>.<\/p>\n\n<p>As you've noted, the <em>workaround<\/em> is to deploy your lambda with the <code>aws-sdk<\/code> version that you're using. This is sometimes noted as a best practice, as it pins the <code>aws-sdk<\/code> on the functionality you've built and tested against.<\/p>",
        "Answer_comment_count":2.0,
        "Question_closed_time":1553117574836,
        "Answer_last_edit_time":null,
        "Answer_score_count":1.0,
        "Answerer_created_time":1372408547912,
        "Answerer_location":"Farnborough, United Kingdom",
        "Answerer_reputation_count":7360.0,
        "Answerer_view_count":372.0,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55257580",
        "Tool":"Amazon SageMaker",
        "Question_self_resolution":0.0,
        "Platform":"Stack Overflow",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"nodej sdk lock api version run code aw lambda dynam creat model lock api version like const new aw apivers code creat model await createmodel executionrolearn xxxxxx modelnam configid contain imag ecrurl promis code run fine local aw sdk code deploi lambda work valid error creat model missingrequiredparamet miss requir kei primarycontain param unexpectedparamet unexpect kei contain param awar exist bug aw sdk nodej sdk provid aw lambda context believ sdk avail insid aw lambda date appar compat issu",
        "Question_preprocessed_content":"nodej sdk lock api version code aw lambda creat model lock api version like code creat model code run fine code deploi lambda work valid creat model requir kei primarycontain param unexpectedparamet unexpect kei contain param awar exist bug nodej sdk provid aw lambda context believ sdk avail insid aw lambda compat",
        "Question_gpt_summary_original":"The user is facing compatibility issues while using SageMaker NodeJS's SDK in AWS Lambda. The code runs fine locally but fails to create a model in Lambda due to validation errors. The user suspects that the SDK provided by AWS in the Lambda context is more up-to-date than the version used locally, causing compatibility issues.",
        "Question_gpt_summary":null
    },
    {
        "Question_title":"Configuration sweep key not appearing during sweep run nor changing values",
        "Question_body":"<p>I\u2019m using stable baselines 3 (SB3) and in order to use one activation function or another, you must pass it to the SB3 algo as kwargs, that is:<\/p>\n<pre><code class=\"lang-auto\">model = A2C(\n            policy=config['policy'],\n            env=env,\n            learning_rate=config['learning_rate'],\n            gae_lambda=config['gae_lambda'],\n            ent_coef=config['ent_coef'],\n            tensorboard_log=LOGS_DIR,\n            device=config['device'],\n            verbose=config['verbose'],\n\n            policy_kwargs=dict(\n                net_arch=dict(\n                    pi=config['policy_nn'],\n                    vf=config['value_nn']),\n                activation_fn=config['activation_fn'],\n                optimizer_class=config['optimizer_class'])\n        )\n<\/code><\/pre>\n<p>where:<\/p>\n<pre><code class=\"lang-auto\">config['activation_fn']  = th.nn.ReLU\n<\/code><\/pre>\n<p>or<\/p>\n<pre><code class=\"lang-auto\">config['activation_fn']  = th.nn.Tanh\n<\/code><\/pre>\n<p>If I configure the sweep dictionary key for the \u2018activation_fn\u2019 as:<\/p>\n<pre><code class=\"lang-auto\">'optimizer_fn':{\n    'values': [th.nn.ReLU, th.nn.Tanh]\n}\n<\/code><\/pre>\n<p>Afterwards when running sweeps, those values are not seen by wandb, neither in the plots appears the optimizer_fn been used nor changes to the other option.<\/p>\n<p>Is it because the sweep config dictionary only accepts string for that kind of values?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_created_time":1676235321750,
        "Question_favorite_count":null,
        "Question_last_edit_time":null,
        "Question_score_count":0.0,
        "Question_view_count":69.0,
        "Poster_created_time":null,
        "Poster_location":null,
        "Poster_reputation_count":null,
        "Poster_view_count":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Question_closed_time":null,
        "Answer_last_edit_time":null,
        "Answer_score_count":null,
        "Answerer_created_time":null,
        "Answerer_location":null,
        "Answerer_reputation_count":null,
        "Answerer_view_count":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/configuration-sweep-key-not-appearing-during-sweep-run-nor-changing-values\/3868",
        "Tool":"Weights & Biases",
        "Question_self_resolution":null,
        "Platform":"Tool-specific",
        "Poster_isAwsEmployee":null,
        "Poster_isModerator":null,
        "Poster_isExpert":null,
        "Poster_isCse":null,
        "Answerer_isAwsEmployee":null,
        "Answerer_isModerator":null,
        "Answerer_isExpert":null,
        "Answerer_isCse":null,
        "Question_original_content":"configur sweep kei appear sweep run chang valu stabl baselin order us activ function pass algo kwarg model polici config polici env env learn rate config learn rate gae lambda config gae lambda ent coef config ent coef tensorboard log log dir devic config devic verbos config verbos polici kwarg dict net arch dict config polici config valu activ config activ optim class config optim class config activ relu config activ tanh configur sweep dictionari kei activ optim valu relu tanh run sweep valu seen plot appear optim chang option sweep config dictionari accept string kind valu",
        "Question_preprocessed_content":"configur kei run chang valu stabl baselin order us activ function algo kwarg configur dictionari kei valu plot chang option config dictionari string kind valu",
        "Question_gpt_summary_original":"The user is using stable baselines 3 (SB3) and passing activation function as kwargs to the SB3 algo. The user has configured the sweep dictionary key for the 'activation_fn' but the values are not seen by wandb during sweeps and do not appear in the plots. The user is unsure if this is because the sweep config dictionary only accepts string values.",
        "Question_gpt_summary":null
    }
]