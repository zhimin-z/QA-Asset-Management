[
    {
        "Question_id":58311651.0,
        "Question_title":"AWS SageMaker MXNet USE_CUDA=1",
        "Question_body":"<p>I am using the AWS ml.p2.xlarge sagemaker instance and conda_amazonei_mxnet_p36 kernel after install MXnet CUDA<\/p>\n<pre><code>!pip install mxnet-cu101\n<\/code><\/pre>\n<p>when I try to run the following code<\/p>\n<pre><code>mx_tfidf = mx.nd.sparse.array(tfidf_matrix, ctx=mx.gpu())\n<\/code><\/pre>\n<p>I am getting the following error<\/p>\n<pre><code>MXNetError: [19:54:53] src\/storage\/storage.cc:119: \nCompile with USE_CUDA=1 to enable GPU usage\n<\/code><\/pre>\n<p>Please help me to resolve the issue<\/p>\n<pre><code>nvidia-smi\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/8MX91.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8MX91.png\" alt=\"nvidia configuration as follows\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1570652176880,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "machine-learning",
            "nvidia",
            "amazon-sagemaker",
            "mxnet"
        ],
        "Question_view_count":800.0,
        "Owner_creation_time":1436911761000,
        "Owner_last_access_time":1590724202223,
        "Owner_reputation":194.0,
        "Owner_up_votes":7.0,
        "Owner_down_votes":0.0,
        "Owner_views":38.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"USA",
        "Question_last_edit_time":1592644375060,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58311651",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  mxnet use_cuda=1; content:<p>i am using the aws ml.p2.xlarge  instance and conda_amazonei_mxnet_p36 kernel after install mxnet cuda<\/p>\n<pre><code>!pip install mxnet-cu101\n<\/code><\/pre>\n<p>when i try to run the following code<\/p>\n<pre><code>mx_tfidf = mx.nd.sparse.array(tfidf_matrix, ctx=mx.gpu())\n<\/code><\/pre>\n<p>i am getting the following error<\/p>\n<pre><code>mxneterror: [19:54:53] src\/storage\/storage.cc:119: \ncompile with use_cuda=1 to enable gpu usage\n<\/code><\/pre>\n<p>please help me to resolve the issue<\/p>\n<pre><code>nvidia-smi\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/8mx91.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8mx91.png\" alt=\"nvidia configuration as follows\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when trying to run code with mxnet-cu101 on an AWS ML.p2.xlarge instance, and needs to compile with use_cuda=1 to enable GPU usage."
    },
    {
        "Question_id":69938565.0,
        "Question_title":"How to REMOVE shortcuts from AWS Ground Truth labeler UI",
        "Question_body":"<p>I'm using Sagemaker Ground Truth for a custom labeling task. I want to remove the shift enter shortcut for submission. I want to remove it because I want to only show items in a sequence and have the labeler annotate them one at a time. Only when they are all done should they be able to submit. That has been built in some custom javascript but I don't want the user to just submit with the shortcut. Thanks<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1636696876047,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-sagemaker",
            "amazon-ground-truth"
        ],
        "Question_view_count":57.0,
        "Owner_creation_time":1432612127580,
        "Owner_last_access_time":1664079312283,
        "Owner_reputation":273.0,
        "Owner_up_votes":28.0,
        "Owner_down_votes":0.0,
        "Owner_views":14.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69938565",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to remove shortcuts from aws ground truth labeler ui; content:<p>i'm using  ground truth for a custom labeling task. i want to remove the shift enter shortcut for submission. i want to remove it because i want to only show items in a sequence and have the labeler annotate them one at a time. only when they are all done should they be able to submit. that has been built in some custom javascript but i don't want the user to just submit with the shortcut. thanks<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to remove the Shift+Enter shortcut from the AWS Ground Truth Labeler UI in order to have the labeler annotate items in a sequence before submitting."
    },
    {
        "Question_id":69218162.0,
        "Question_title":"Make custom kernels available to SageMaker Studio notebooks",
        "Question_body":"<p>On starting the SageMaker Studio server, I can only see a set of predefined kernels when\nI select kernel for any notebook.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/pGJIw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/pGJIw.png\" alt=\"Predefined Kernels\" \/><\/a><\/p>\n<p>I create conda environments and persist them between sessions by pointing <code>.condarc<\/code> to a custom miniconda directory stored on EFS.<\/p>\n<p>I want all notebooks to have access to environments stored in the custom miniconda directory. I can do that on the system terminal but can't seem to find a way to make the kernels available to notebooks.<\/p>\n<p>I am aware of <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/notebook-lifecycle-config.html\" rel=\"nofollow noreferrer\">Life Cycle Configuration<\/a> but that seems to be working only with notebooks instances rather than SageMaker Studio.<\/p>\n<p><strong>Desired outcomes<\/strong><\/p>\n<p>Ideally making custom kernels persistently available to notebooks but if that isn't feasible or requires custom docker image, I am happy with running a script manually every time I run the server.<\/p>\n<p><strong>What I have tried so far:<\/strong><\/p>\n<p>I ran the following which is a tweaked version of <a href=\"https:\/\/github.com\/aws-samples\/amazon-sagemaker-notebook-instance-lifecycle-config-samples\/blob\/master\/scripts\/persistent-conda-ebs\/on-start.sh\" rel=\"nofollow noreferrer\">start.sh<\/a> meant to be for Life Cycle Configuration.<\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>#!\/bin\/bash\n\nset -e\n\nsudo -u sagemaker-user -i &lt;&lt;'EOF'\nunset SUDO_UID\nWORKING_DIR=\/home\/sagemaker-user\/.SageMaker\/custom-miniconda\/\nsource \"$WORKING_DIR\/miniconda\/bin\/activate\"\nfor env in $WORKING_DIR\/miniconda\/envs\/*; do\n    BASENAME=$(basename \"$env\")\n    source activate \"$BASENAME\"\n    python -m ipykernel install --user --name \"$BASENAME\" --display-name \"$BASENAME\"\ndone\n\nEOF<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p>That didn't work and I couldn't access the kernels from the notebooks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1631856553007,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "conda",
            "amazon-sagemaker"
        ],
        "Question_view_count":1616.0,
        "Owner_creation_time":1398880184052,
        "Owner_last_access_time":1664004393232,
        "Owner_reputation":2245.0,
        "Owner_up_votes":740.0,
        "Owner_down_votes":11.0,
        "Owner_views":213.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69218162",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: make custom kernels available to  studio notebooks; content:<p>on starting the  studio server, i can only see a set of predefined kernels when\ni select kernel for any notebook.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/pgjiw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/pgjiw.png\" alt=\"predefined kernels\" \/><\/a><\/p>\n<p>i create conda environments and persist them between sessions by pointing <code>.condarc<\/code> to a custom miniconda directory stored on efs.<\/p>\n<p>i want all notebooks to have access to environments stored in the custom miniconda directory. i can do that on the system terminal but can't seem to find a way to make the kernels available to notebooks.<\/p>\n<p>i am aware of <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/notebook-lifecycle-config.html\" rel=\"nofollow noreferrer\">life cycle configuration<\/a> but that seems to be working only with notebooks instances rather than  studio.<\/p>\n<p><strong>desired outcomes<\/strong><\/p>\n<p>ideally making custom kernels persistently available to notebooks but if that isn't feasible or requires custom docker image, i am happy with running a script manually every time i run the server.<\/p>\n<p><strong>what i have tried so far:<\/strong><\/p>\n<p>i ran the following which is a tweaked version of <a href=\"https:\/\/github.com\/aws-samples\/amazon--notebook-instance-lifecycle-config-samples\/blob\/master\/scripts\/persistent-conda-ebs\/on-start.sh\" rel=\"nofollow noreferrer\">start.sh<\/a> meant to be for life cycle configuration.<\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>#!\/bin\/bash\n\nset -e\n\nsudo -u -user -i &lt;&lt;'eof'\nunset sudo_uid\nworking_dir=\/home\/-user\/.\/custom-miniconda\/\nsource \"$working_dir\/miniconda\/bin\/activate\"\nfor env in $working_dir\/miniconda\/envs\/*; do\n    basename=$(basename \"$env\")\n    source activate \"$basename\"\n    python -m ipykernel install --user --name \"$basename\" --display-name \"$basename\"\ndone\n\neof<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p>that didn't work and i couldn't access the kernels from the notebooks.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to make custom kernels available to studio notebooks, but has not been able to do so using the life cycle configuration or a tweaked version of the on-start.sh script."
    },
    {
        "Question_id":71645213.0,
        "Question_title":"AzureML to use geo-replication \/ secondary Blob Storage container for Datastore",
        "Question_body":"<p>For sake of safety I wish to use geo-replication \/ secondary Blob Storage container for a data source for AzureML Datastore. So I do the following:<\/p>\n<ol>\n<li>New Datastore<\/li>\n<li>Enter name + Azure Blob Storage + Enter manually<\/li>\n<li>For URL I paste &quot;Secondary Blob Service Endpoint&quot; value from &quot;Storage account endpoints&quot; and I add container name at the end, e.g. <a href=\"https:\/\/somedata-secondary.blob.core.windows.net\/container-name\" rel=\"nofollow noreferrer\">https:\/\/somedata-secondary.blob.core.windows.net\/container-name<\/a><\/li>\n<li>Select subscription ID<\/li>\n<li>I select the resource group in which somedata is hosted,<\/li>\n<li>I add account key taken from &quot;Access keys&quot; section, I tried also with SAS token<\/li>\n<li>After finalizing, the new datastore seem to appear in the list but it is impossible to Browse (preview), throwing the error &quot;Invalid host&quot;.<\/li>\n<\/ol>\n<p>What is the correct way of doing this?\nIs it possible at all to access this geo-replication \/ secondary Blob Storage as datastore?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1648459868830,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "azure-blob-storage",
            "azure-machine-learning-service",
            "geo-replication"
        ],
        "Question_view_count":77.0,
        "Owner_creation_time":1567151674136,
        "Owner_last_access_time":1663771775580,
        "Owner_reputation":304.0,
        "Owner_up_votes":221.0,
        "Owner_down_votes":1.0,
        "Owner_views":35.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Krak\u00f3w, Poland",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71645213",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  to use geo-replication \/ secondary blob storage container for datastore; content:<p>for sake of safety i wish to use geo-replication \/ secondary blob storage container for a data source for  datastore. so i do the following:<\/p>\n<ol>\n<li>new datastore<\/li>\n<li>enter name + azure blob storage + enter manually<\/li>\n<li>for url i paste &quot;secondary blob service endpoint&quot; value from &quot;storage account endpoints&quot; and i add container name at the end, e.g. <a href=\"https:\/\/somedata-secondary.blob.core.windows.net\/container-name\" rel=\"nofollow noreferrer\">https:\/\/somedata-secondary.blob.core.windows.net\/container-name<\/a><\/li>\n<li>select subscription id<\/li>\n<li>i select the resource group in which somedata is hosted,<\/li>\n<li>i add account key taken from &quot;access keys&quot; section, i tried also with sas token<\/li>\n<li>after finalizing, the new datastore seem to appear in the list but it is impossible to browse (preview), throwing the error &quot;invalid host&quot;.<\/li>\n<\/ol>\n<p>what is the correct way of doing this?\nis it possible at all to access this geo-replication \/ secondary blob storage as datastore?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is attempting to use geo-replication\/secondary blob storage as a data source for a datastore, but is having difficulty accessing it and is unsure of the correct way to do so."
    },
    {
        "Question_id":68644137.0,
        "Question_title":"Azure Machine Learning Studio Designer Error: code_expired",
        "Question_body":"<p>I am trying to register a data set via the Azure Machine Learning Studio designer but keep getting an error. Here is my code, used in a &quot;Execute Python Script&quot; module:<\/p>\n<pre><code>import pandas as pd\nfrom azureml.core.dataset import Dataset\nfrom azureml.core import Workspace\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    ws = Workspace.get(name = &lt;my_workspace_name&gt;, subscription_id = &lt;my_id&gt;, resource_group = &lt;my_RG&gt;)\n    ds = Dataset.from_pandas_dataframe(dataframe1)\n    ds.register(workspace = ws,\n                name = &quot;data set name&quot;,\n                description = &quot;example description&quot;,\n                create_new_version = True)\n    return dataframe1, \n<\/code><\/pre>\n<p>But I get the following error in the Workspace.get line:<\/p>\n<pre><code>Authentication Exception: Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired.\n<\/code><\/pre>\n<p>Since I am inside the workspace and in the designer, I do not usually need to do any kind of authentication (or even reference the workspace). Can anybody offer some direction? Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1628037272883,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "azure-machine-learning-studio",
            "azure-machine-learning-service"
        ],
        "Question_view_count":321.0,
        "Owner_creation_time":1371499229816,
        "Owner_last_access_time":1664024865427,
        "Owner_reputation":1111.0,
        "Owner_up_votes":124.0,
        "Owner_down_votes":2.0,
        "Owner_views":191.0,
        "Answer_body":"<p>when you're inside a &quot;Execute Python Script&quot; module or <code>PythonScriptStep<\/code>, the authentication for fetching the workspace is already done for you (unless you're trying to authenticate to different Azure ML workspace.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Run\nrun = Run.get_context()\n\nws = run.experiment.workspace\n<\/code><\/pre>\n<p>You should be able to use that <code>ws<\/code> object to register a Dataset.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1628038438487,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1628038626927,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68644137",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  studio designer error: code_expired; content:<p>i am trying to register a data set via the  studio designer but keep getting an error. here is my code, used in a &quot;execute python script&quot; module:<\/p>\n<pre><code>import pandas as pd\nfrom .core.dataset import dataset\nfrom .core import workspace\n\ndef _main(dataframe1 = none, dataframe2 = none):\n    ws = workspace.get(name = &lt;my_workspace_name&gt;, subscription_id = &lt;my_id&gt;, resource_group = &lt;my_rg&gt;)\n    ds = dataset.from_pandas_dataframe(dataframe1)\n    ds.register(workspace = ws,\n                name = &quot;data set name&quot;,\n                description = &quot;example description&quot;,\n                create_new_version = true)\n    return dataframe1, \n<\/code><\/pre>\n<p>but i get the following error in the workspace.get line:<\/p>\n<pre><code>authentication exception: unknown error occurred during authentication. error detail: unexpected polling state code_expired.\n<\/code><\/pre>\n<p>since i am inside the workspace and in the designer, i do not usually need to do any kind of authentication (or even reference the workspace). can anybody offer some direction? thanks!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to register a data set via the studio designer but is getting an error due to an unexpected polling state code_expired."
    },
    {
        "Question_id":72143195.0,
        "Question_title":"Running Neptune in Jupyter Notebook gives NameError that Neptune is not defined",
        "Question_body":"<pre><code># Create run in project (Neptune)\nrun = neptune.init(project='ssraghuvanshi1989\/GCI-01-Lung-CT-Segmentation-20220506')\n<\/code><\/pre>\n<hr \/>\n<pre><code>NameError                    Traceback (most recent call last)\nC:\\Users\\SAURAB~1\\AppData\\Local\\Temp\/ipykernel_27104\/3392926562.py in &lt;module&gt;\n      1 # Create run in project\n----&gt; 2 run = neptune.init(project='ssraghuvanshi1989\/GCI-01-Lung-CT-Segmentation-20220506')\n\nNameError: name 'neptune' is not defined\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1651847578783,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "google-colaboratory",
            "nameerror",
            "mlops",
            "neptune"
        ],
        "Question_view_count":67.0,
        "Owner_creation_time":1423107401472,
        "Owner_last_access_time":1653027951467,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1651848652763,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72143195",
        "Tool":"Neptune",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: running  in jupyter notebook gives nameerror that  is not defined; content:<pre><code># create run in project ()\nrun = .init(project='ssraghuvanshi1989\/gci-01-lung-ct-segmentation-20220506')\n<\/code><\/pre>\n<hr \/>\n<pre><code>nameerror                    traceback (most recent call last)\nc:\\users\\saurab~1\\appdata\\local\\temp\/ipykernel_27104\/3392926562.py in &lt;module&gt;\n      1 # create run in project\n----&gt; 2 run = .init(project='ssraghuvanshi1989\/gci-01-lung-ct-segmentation-20220506')\n\nnameerror: name '' is not defined\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving a NameError when running code in a Jupyter notebook."
    },
    {
        "Question_id":null,
        "Question_title":"Getting full run id",
        "Question_body":"<p>Is there a way to print out the full run id when using guild compare?<\/p>\n<p>I wanted to run through the results and then inspect the folder containing the output of the run in .guild, but the output of guild compare is the shortened run id so I can\u2019t directly find the folder.<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_creation_time":1600093581539,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":563.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/getting-full-run-id\/343",
        "Tool":"Guild AI",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":662,
                "name":"Garrett Smith",
                "username":"garrett",
                "avatar_template":"\/user_avatar\/my.guild.ai\/garrett\/{size}\/224_2.png",
                "created_at":"2020-09-15T14:28:07.892Z",
                "cooked":"<p>Use the <code>-c, --cols<\/code> option to include the run <code>id<\/code> attribute this way:<\/p>\n<pre><code class=\"lang-command\">guild compare -c .id\n<\/code><\/pre>\n<p>This appends the full ID to the table. The prefix <code>.<\/code> indicates the name is an a run attribute. If you wanted to indicate a scalar you\u2019d omit the prefix. If you wanted to indicate a flag you\u2019d use <code>=<\/code> as the prefix.<\/p>\n<p>See <a href=\"https:\/\/my.guild.ai\/t\/command-compare\/77#column-specs\">Column Specs<\/a> for more info.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2020-09-15T14:28:07.892Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":13,
                "readers_count":12,
                "score":2.6,
                "yours":false,
                "topic_id":343,
                "topic_slug":"getting-full-run-id",
                "display_username":"Garrett Smith",
                "primary_group_name":"guildai_staff",
                "flair_name":"guildai_staff",
                "flair_url":"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/834f7e381d7fc7c5757ec4c67ae087d5d4a25e6f.png",
                "flair_bg_color":"",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/my.guild.ai\/t\/command-compare\/77",
                        "internal":true,
                        "reflection":false,
                        "title":"Command: compare",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":669,
                "name":"",
                "username":"teracamo",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/ea666f\/{size}.png",
                "created_at":"2020-09-16T03:46:57.504Z",
                "cooked":"<p>I find <code>for i in {1..X};do guild open --marked --cmd \"echo\" ${i};done<\/code> to be more useful than <code>guild compare<\/code> in this case cause it gives you the full directory.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2020-09-16T04:47:25.522Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":13,
                "readers_count":12,
                "score":7.6,
                "yours":false,
                "topic_id":343,
                "topic_slug":"getting-full-run-id",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":41,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":675,
                "name":"Garrett Smith",
                "username":"garrett",
                "avatar_template":"\/user_avatar\/my.guild.ai\/garrett\/{size}\/224_2.png",
                "created_at":"2020-09-17T14:09:55.662Z",
                "cooked":"<p>Out of curiosity, what do you do with these run directories? Do they feed an automated process or are you using them manually to access run files?<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2020-09-17T14:09:55.662Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":12,
                "readers_count":11,
                "score":2.4,
                "yours":false,
                "topic_id":343,
                "topic_slug":"getting-full-run-id",
                "display_username":"Garrett Smith",
                "primary_group_name":"guildai_staff",
                "flair_name":"guildai_staff",
                "flair_url":"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/834f7e381d7fc7c5757ec4c67ae087d5d4a25e6f.png",
                "flair_bg_color":"",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "reply_to_user":{
                    "username":"teracamo",
                    "name":"",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/ea666f\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":679,
                "name":"",
                "username":"imani",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/i\/aeb1de\/{size}.png",
                "created_at":"2020-09-17T14:39:16.852Z",
                "cooked":"<p>I needed to access them manually in this case. I was running a set of experiments and after I started analyzing the results, I realized there were another set of metrics that I wanted to compute. Luckily I had saved the network weights using guild, so I iterated over each run, reloaded the weights, and then computed these additional metrics.<\/p>\n<p>If there is a nicer way to do this I would definitely like to know, but I didn\u2019t think this process was too painful to code up.<\/p>\n<p>If there was also way to save these new metrics to the run folders that would be great, I didn\u2019t look into whether that was possible.<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2020-09-17T14:39:16.852Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":12,
                "readers_count":11,
                "score":7.4,
                "yours":false,
                "topic_id":343,
                "topic_slug":"getting-full-run-id",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":36,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":688,
                "name":"Garrett Smith",
                "username":"garrett",
                "avatar_template":"\/user_avatar\/my.guild.ai\/garrett\/{size}\/224_2.png",
                "created_at":"2020-09-18T14:34:59.573Z",
                "cooked":"<p>You can use the <code>guild.ipy<\/code> module to iterate over runs to get their directory.<\/p>\n<pre><code class=\"lang-python\">from guild import ipy\n\nfor _, row in ipy.runs().iterrows():\n    run = row.run.value\n    print(\"%s: %s\" % (run.id, run.dir))\n<\/code><\/pre>\n<p>The <code>ipy<\/code> module is primarily intended for interactive use but it works just as well for scripting like this. You just need Pandas as it uses data frames for the interface.<\/p>\n<p>If you\u2019d prefer not to install Pandas, there\u2019s another API but it\u2019s not officially released for general use. I\u2019m happy to help you with that though - it\u2019s stable and will be released at some point.<\/p>",
                "post_number":6,
                "post_type":1,
                "updated_at":"2020-09-18T14:35:20.385Z",
                "reply_count":0,
                "reply_to_post_number":5,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":10,
                "readers_count":9,
                "score":2.0,
                "yours":false,
                "topic_id":343,
                "topic_slug":"getting-full-run-id",
                "display_username":"Garrett Smith",
                "primary_group_name":"guildai_staff",
                "flair_name":"guildai_staff",
                "flair_url":"https:\/\/global.discourse-cdn.com\/standard11\/uploads\/guild\/original\/1X\/834f7e381d7fc7c5757ec4c67ae087d5d4a25e6f.png",
                "flair_bg_color":"",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "reply_to_user":{
                    "username":"imani",
                    "name":"",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/i\/aeb1de\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: getting full run id; content:<p>is there a way to print out the full run id when using guild compare?<\/p>\n<p>i wanted to run through the results and then inspect the folder containing the output of the run in .guild, but the output of guild compare is the shortened run id so i can\u2019t directly find the folder.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to print out the full run ID when using Guild Compare, so they can inspect the folder containing the output of the run in .guild."
    },
    {
        "Question_id":72730199.0,
        "Question_title":"SageMaker: TypeError: Object of type Join is not JSON serializable",
        "Question_body":"<p>I'm trying to build a SM pipeline for a computer vision model.\nThe data is images stored in S3 bucket. I did the preprocessing using ScriptProcessor and now am trying to build the estimator.\nPreprocessing works alright. But the estimator part is giving me TypeError: Object of type Join is not JSON serializable: error.<\/p>\n<pre><code>from sagemaker.tensorflow import TensorFlow\n\n\noutput_config = preprocessing_job_description[&quot;ProcessingOutputConfig&quot;]\nfor output in output_config[&quot;Outputs&quot;]:\n    if output[&quot;OutputName&quot;] == &quot;train_data&quot;:\n        preprocessed_training_data = output[&quot;S3Output&quot;][&quot;S3Uri&quot;]\n    if output[&quot;OutputName&quot;] == &quot;valid_data&quot;:\n        preprocessed_test_data = output[&quot;S3Output&quot;][&quot;S3Uri&quot;]\n\ns3_train = &quot;s3:\/\/bucketname\/image_data\/train\/&quot;\ns3_val = &quot;s3:\/\/bucketname\/image_data\/val\/&quot;\n\n\ntf_estimator = TensorFlow(entry_point=&quot;train.py&quot;,\n                          sagemaker_session=sess,\n                          role=role,\n                          instance_count=1, \n                          instance_type=&quot;ml.m5.xlarge&quot;,\n                          # output_path = &quot;\/opt\/ml\/processing\/output&quot;,\n                          model_dir=&quot;s3:\/\/bucketname\/image_data\/output&quot;,\n                          py_version='py37',\n                          framework_version='2.4', \n                          hyperparameters={'epochs': epochs,\n                                           'learning_rate': learning_rate, \n                                           'train_batch_size': 64,\n                                          },\n                          metric_definitions=metrics_definitions,\n                          script_mode=True,\n                          max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 sec per minutes\n                         )\n\ntf_estimator.fit({&quot;train&quot;: preprocessed_training_data})\n<\/code><\/pre>\n<p>This gives me the following error:<\/p>\n<hr \/>\n<blockquote>\n<p>TypeError                                 Traceback (most recent call\nlast)  in \n36                          )\n37\n---&gt; 38 tf_estimator.fit({&quot;train&quot;: preprocessed_training_data})\n39 # tf_estimator.fit({&quot;train&quot;: s3_train})<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/workflow\/pipeline_context.py\nin wrapper(*args, **kwargs)\n207             return self_instance.sagemaker_session.context\n208\n--&gt; 209         return run_func(*args, **kwargs)\n210\n211     return wrapper<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/estimator.py in\nfit(self, inputs, wait, logs, job_name, experiment_config)\n976         self._prepare_for_training(job_name=job_name)\n977\n--&gt; 978         self.latest_training_job = _TrainingJob.start_new(self, inputs, experiment_config)\n979         self.jobs.append(self.latest_training_job)\n980         if wait:<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/estimator.py in\nstart_new(cls, estimator, inputs, experiment_config)    1806<br \/>\ntrain_args = cls._get_train_args(estimator, inputs, experiment_config)\n1807\n-&gt; 1808         estimator.sagemaker_session.train(**train_args)    1809     1810         return cls(estimator.sagemaker_session,\nestimator._current_job_name)<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in\ntrain(self, input_mode, input_config, role, job_name, output_config,\nresource_config, vpc_config, hyperparameters, stop_condition, tags,\nmetric_definitions, enable_network_isolation, image_uri,\nalgorithm_arn, encrypt_inter_container_traffic, use_spot_instances,\ncheckpoint_s3_uri, checkpoint_local_path, experiment_config,\ndebugger_rule_configs, debugger_hook_config,\ntensorboard_output_config, enable_sagemaker_metrics,\nprofiler_rule_configs, profiler_config, environment, retry_strategy)\n592             encrypt_inter_container_traffic=encrypt_inter_container_traffic,\n593             use_spot_instances=use_spot_instances,\n--&gt; 594             checkpoint_s3_uri=checkpoint_s3_uri,\n595             checkpoint_local_path=checkpoint_local_path,\n596             experiment_config=experiment_config,<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in\n_intercept_create_request(self, request, create, func_name)    4201         &quot;&quot;&quot;    4202         region = self.boto_session.region_name\n-&gt; 4203         sts_client = self.boto_session.client(    4204             &quot;sts&quot;, region_name=region, endpoint_url=sts_regional_endpoint(region)\n4205         )<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in\nsubmit(request)\n589             enable_network_isolation=enable_network_isolation,\n590             image_uri=image_uri,\n--&gt; 591             algorithm_arn=algorithm_arn,\n592             encrypt_inter_container_traffic=encrypt_inter_container_traffic,\n593             use_spot_instances=use_spot_instances,<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/<strong>init<\/strong>.py in dumps(obj, skipkeys,\nensure_ascii, check_circular, allow_nan, cls, indent, separators,\ndefault, sort_keys, **kw)\n236         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n237         separators=separators, default=default, sort_keys=sort_keys,\n--&gt; 238         **kw).encode(obj)\n239\n240<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in encode(self, o)\n199         chunks = self.iterencode(o, _one_shot=True)\n200         if not isinstance(chunks, (list, tuple)):\n--&gt; 201             chunks = list(chunks)\n202         return ''.join(chunks)\n203<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in _iterencode(o,\n_current_indent_level)\n429             yield from _iterencode_list(o, _current_indent_level)\n430         elif isinstance(o, dict):\n--&gt; 431             yield from _iterencode_dict(o, _current_indent_level)\n432         else:\n433             if markers is not None:<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in _iterencode_dict(dct,\n_current_indent_level)\n403                 else:\n404                     chunks = _iterencode(value, _current_indent_level)\n--&gt; 405                 yield from chunks\n406         if newline_indent is not None:\n407             _current_indent_level -= 1<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in _iterencode_dict(dct,\n_current_indent_level)\n403                 else:\n404                     chunks = _iterencode(value, _current_indent_level)\n--&gt; 405                 yield from chunks\n406         if newline_indent is not None:\n407             _current_indent_level -= 1<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in _iterencode(o,\n_current_indent_level)\n436                     raise ValueError(&quot;Circular reference detected&quot;)\n437                 markers[markerid] = o\n--&gt; 438             o = _default(o)\n439             yield from _iterencode(o, _current_indent_level)\n440             if markers is not None:<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in default(self, o)\n177\n178         &quot;&quot;&quot;\n--&gt; 179         raise TypeError(f'Object of type {o.<strong>class<\/strong>.<strong>name<\/strong>} '\n180                         f'is not JSON serializable')\n181<\/p>\n<p>TypeError: Object of type Join is not JSON serializable<\/p>\n<\/blockquote>\n<p>I have tried changing all the arguments I have given for the estimator. Sometimes enabling them and sometimes disabling them.\n--&gt; 594 checkpoint_s3_uri=checkpoint_s3_uri,\nIf this is the origin, I have tried giving it also.<\/p>\n<p>No idea where I'm messing up.\nI'm using<\/p>\n<pre><code>sagemaker 2.94.0\nPython3 Data Science kernel\nboto3 '1.24.8'\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1655987433777,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "tensorflow",
            "amazon-sagemaker"
        ],
        "Question_view_count":155.0,
        "Owner_creation_time":1655983338203,
        "Owner_last_access_time":1660714360396,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72730199",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: : typeerror: object of type join is not json serializable; content:<p>i'm trying to build a sm pipeline for a computer vision model.\nthe data is images stored in s3 bucket. i did the preprocessing using scriptprocessor and now am trying to build the estimator.\npreprocessing works alright. but the estimator part is giving me typeerror: object of type join is not json serializable: error.<\/p>\n<pre><code>from .tensorflow import tensorflow\n\n\noutput_config = preprocessing_job_description[&quot;processingoutputconfig&quot;]\nfor output in output_config[&quot;outputs&quot;]:\n    if output[&quot;outputname&quot;] == &quot;train_data&quot;:\n        preprocessed_training_data = output[&quot;s3output&quot;][&quot;s3uri&quot;]\n    if output[&quot;outputname&quot;] == &quot;valid_data&quot;:\n        preprocessed_test_data = output[&quot;s3output&quot;][&quot;s3uri&quot;]\n\ns3_train = &quot;s3:\/\/bucketname\/image_data\/train\/&quot;\ns3_val = &quot;s3:\/\/bucketname\/image_data\/val\/&quot;\n\n\ntf_estimator = tensorflow(entry_point=&quot;train.py&quot;,\n                          _session=sess,\n                          role=role,\n                          instance_count=1, \n                          instance_type=&quot;ml.m5.xlarge&quot;,\n                          # output_path = &quot;\/opt\/ml\/processing\/output&quot;,\n                          model_dir=&quot;s3:\/\/bucketname\/image_data\/output&quot;,\n                          py_version='py37',\n                          framework_version='2.4', \n                          hyperparameters={'epochs': epochs,\n                                           'learning_rate': learning_rate, \n                                           'train_batch_size': 64,\n                                          },\n                          metric_definitions=metrics_definitions,\n                          script_mode=true,\n                          max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 sec per minutes\n                         )\n\ntf_estimator.fit({&quot;train&quot;: preprocessed_training_data})\n<\/code><\/pre>\n<p>this gives me the following error:<\/p>\n<hr \/>\n<blockquote>\n<p>typeerror                                 traceback (most recent call\nlast)  in \n36                          )\n37\n---&gt; 38 tf_estimator.fit({&quot;train&quot;: preprocessed_training_data})\n39 # tf_estimator.fit({&quot;train&quot;: s3_train})<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/\/workflow\/pipeline_context.py\nin wrapper(*args, **kwargs)\n207             return self_instance._session.context\n208\n--&gt; 209         return run_func(*args, **kwargs)\n210\n211     return wrapper<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/\/estimator.py in\nfit(self, inputs, wait, logs, job_name, experiment_config)\n976         self._prepare_for_training(job_name=job_name)\n977\n--&gt; 978         self.latest_training_job = _trainingjob.start_new(self, inputs, experiment_config)\n979         self.jobs.append(self.latest_training_job)\n980         if wait:<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/\/estimator.py in\nstart_new(cls, estimator, inputs, experiment_config)    1806<br \/>\ntrain_args = cls._get_train_args(estimator, inputs, experiment_config)\n1807\n-&gt; 1808         estimator._session.train(**train_args)    1809     1810         return cls(estimator._session,\nestimator._current_job_name)<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/\/session.py in\ntrain(self, input_mode, input_config, role, job_name, output_config,\nresource_config, vpc_config, hyperparameters, stop_condition, tags,\nmetric_definitions, enable_network_isolation, image_uri,\nalgorithm_arn, encrypt_inter_container_traffic, use_spot_instances,\ncheckpoint_s3_uri, checkpoint_local_path, experiment_config,\ndebugger_rule_configs, debugger_hook_config,\ntensorboard_output_config, enable__metrics,\nprofiler_rule_configs, profiler_config, environment, retry_strategy)\n592             encrypt_inter_container_traffic=encrypt_inter_container_traffic,\n593             use_spot_instances=use_spot_instances,\n--&gt; 594             checkpoint_s3_uri=checkpoint_s3_uri,\n595             checkpoint_local_path=checkpoint_local_path,\n596             experiment_config=experiment_config,<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/\/session.py in\n_intercept_create_request(self, request, create, func_name)    4201         &quot;&quot;&quot;    4202         region = self.boto_session.region_name\n-&gt; 4203         sts_client = self.boto_session.client(    4204             &quot;sts&quot;, region_name=region, endpoint_url=sts_regional_endpoint(region)\n4205         )<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/site-packages\/\/session.py in\nsubmit(request)\n589             enable_network_isolation=enable_network_isolation,\n590             image_uri=image_uri,\n--&gt; 591             algorithm_arn=algorithm_arn,\n592             encrypt_inter_container_traffic=encrypt_inter_container_traffic,\n593             use_spot_instances=use_spot_instances,<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/<strong>init<\/strong>.py in dumps(obj, skipkeys,\nensure_ascii, check_circular, allow_nan, cls, indent, separators,\ndefault, sort_keys, **kw)\n236         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n237         separators=separators, default=default, sort_keys=sort_keys,\n--&gt; 238         **kw).encode(obj)\n239\n240<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in encode(self, o)\n199         chunks = self.iterencode(o, _one_shot=true)\n200         if not isinstance(chunks, (list, tuple)):\n--&gt; 201             chunks = list(chunks)\n202         return ''.join(chunks)\n203<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in _iterencode(o,\n_current_indent_level)\n429             yield from _iterencode_list(o, _current_indent_level)\n430         elif isinstance(o, dict):\n--&gt; 431             yield from _iterencode_dict(o, _current_indent_level)\n432         else:\n433             if markers is not none:<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in _iterencode_dict(dct,\n_current_indent_level)\n403                 else:\n404                     chunks = _iterencode(value, _current_indent_level)\n--&gt; 405                 yield from chunks\n406         if newline_indent is not none:\n407             _current_indent_level -= 1<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in _iterencode_dict(dct,\n_current_indent_level)\n403                 else:\n404                     chunks = _iterencode(value, _current_indent_level)\n--&gt; 405                 yield from chunks\n406         if newline_indent is not none:\n407             _current_indent_level -= 1<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in _iterencode(o,\n_current_indent_level)\n436                     raise valueerror(&quot;circular reference detected&quot;)\n437                 markers[markerid] = o\n--&gt; 438             o = _default(o)\n439             yield from _iterencode(o, _current_indent_level)\n440             if markers is not none:<\/p>\n<p>\/opt\/conda\/lib\/python3.7\/json\/encoder.py in default(self, o)\n177\n178         &quot;&quot;&quot;\n--&gt; 179         raise typeerror(f'object of type {o.<strong>class<\/strong>.<strong>name<\/strong>} '\n180                         f'is not json serializable')\n181<\/p>\n<p>typeerror: object of type join is not json serializable<\/p>\n<\/blockquote>\n<p>i have tried changing all the arguments i have given for the estimator. sometimes enabling them and sometimes disabling them.\n--&gt; 594 checkpoint_s3_uri=checkpoint_s3_uri,\nif this is the origin, i have tried giving it also.<\/p>\n<p>no idea where i'm messing up.\ni'm using<\/p>\n<pre><code> 2.94.0\npython3 data science kernel\nboto3 '1.24.8'\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving a TypeError when trying to build an estimator for a computer vision model, and is unsure of where they are making a mistake."
    },
    {
        "Question_id":68224550.0,
        "Question_title":"Is it possible to use ssm Session Manager to connect to a sagemaker notebook?",
        "Question_body":"<p>SageMaker Notebooks do not have an &quot;Official&quot; way for ssh connections, although it is possible to find instructions for it using ngrok.<\/p>\n<p>Is it possible to use session manager instead? Although the SageMaker Notebook looks like an ec2 the arn does not starts in the same way, it has <code>arn:aws:sagemaker<\/code> instead of <code>arn:aws:ec2<\/code>.<\/p>\n<p>I tried this via aws cli but I get <code>An error occurred (TargetNotConnected) when calling the StartSession operation:<\/code><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1625225941860,
        "Question_favorite_count":null,
        "Question_score":3.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker",
            "aws-session-manager"
        ],
        "Question_view_count":199.0,
        "Owner_creation_time":1449660293110,
        "Owner_last_access_time":1663964347052,
        "Owner_reputation":683.0,
        "Owner_up_votes":17.0,
        "Owner_down_votes":1.0,
        "Owner_views":27.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68224550",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is it possible to use ssm session manager to connect to a  notebook?; content:<p> notebooks do not have an &quot;official&quot; way for ssh connections, although it is possible to find instructions for it using ngrok.<\/p>\n<p>is it possible to use session manager instead? although the  notebook looks like an ec2 the arn does not starts in the same way, it has <code>arn:aws:<\/code> instead of <code>arn:aws:ec2<\/code>.<\/p>\n<p>i tried this via aws cli but i get <code>an error occurred (targetnotconnected) when calling the startsession operation:<\/code><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to use SSM Session Manager to connect to a notebook, as the ARN does not start with \"arn:aws:ec2\" and they receive an error when attempting to do so via the AWS CLI."
    },
    {
        "Question_id":73209864.0,
        "Question_title":"Azure Synapse: Possible to create\/deploy ONNX model to dedicated sql pool from Synapse Notebook?",
        "Question_body":"<p>The examples I see of installing trained ONNX models to Synapse dedicated sql pool (for use with the PREDICT functionality) all originate from Azure Machine Learning Studio. E.g. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-sql-pool-model-scoring-wizard\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-sql-pool-model-scoring-wizard<\/a><\/p>\n<p>Can this be done from a Synapse Notebook directly, never leaving the Synapse environment?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1659453001323,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "azure-synapse",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":79.0,
        "Owner_creation_time":1499405667427,
        "Owner_last_access_time":1663433476640,
        "Owner_reputation":393.0,
        "Owner_up_votes":22.0,
        "Owner_down_votes":0.0,
        "Owner_views":36.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73209864",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: azure synapse: possible to create\/deploy onnx model to dedicated sql pool from synapse notebook?; content:<p>the examples i see of installing trained onnx models to synapse dedicated sql pool (for use with the predict functionality) all originate from  studio. e.g. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-sql-pool-model-scoring-wizard\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-sql-pool-model-scoring-wizard<\/a><\/p>\n<p>can this be done from a synapse notebook directly, never leaving the synapse environment?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to create and deploy an ONNX model to a dedicated SQL pool from a Synapse notebook without leaving the Synapse environment."
    },
    {
        "Question_id":67552090.0,
        "Question_title":"Delete and recreate the registry for an azure machine learning workspace",
        "Question_body":"<p>Our azure machine learning workspace container registry has grown extremely large (4Tb) and has many obsolete entries. I would like to delete the registry and simply create a new one. We do not need any entries from the old one.<\/p>\n<p>If I delete the current registry, create a new one, how do I attach it to the workspace?  I dont want to create a new workspace.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1621122191180,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "azure-machine-learning-service"
        ],
        "Question_view_count":172.0,
        "Owner_creation_time":1565794118448,
        "Owner_last_access_time":1664072200672,
        "Owner_reputation":113.0,
        "Owner_up_votes":3.0,
        "Owner_down_votes":0.0,
        "Owner_views":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67552090",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: delete and recreate the registry for an  workspace; content:<p>our  workspace container registry has grown extremely large (4tb) and has many obsolete entries. i would like to delete the registry and simply create a new one. we do not need any entries from the old one.<\/p>\n<p>if i delete the current registry, create a new one, how do i attach it to the workspace?  i dont want to create a new workspace.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to delete their current workspace container registry and create a new one, but they would like to attach it to the same workspace without creating a new one."
    },
    {
        "Question_id":null,
        "Question_title":"Model Deployment Issues",
        "Question_body":"Hello,\n\n\nI've been trying to deploy a scikit-learn model (a super simple classification using the Iris data set) that I built and trained using the standard MLproject protocol. I have been trying to deploy in two different manners and have been getting errors both ways:\n\n\nServe the model using a local REST server\n\nTo serve the model, I have been using the following command:\nmlflow models serve -m mlruns\/0\/f7cad9db15134c2abaa6d2a8b208c505\/artifacts\/sk_models -h **.***.**.** -p 1234 --no-conda\nNOTE: The host flag is the correct IP, I just masked it for this post\n\nWhen I run this command, I get the following output:\n2019\/09\/03 14:36:16 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n2019\/09\/03 14:36:16 INFO mlflow.pyfunc.backend: === Running command 'gunicorn --timeout=60 -b **.***.**.**:1234 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\nbash: gunicorn: command not found\n\nI have ensured that gunicorn is in fact installed:\nsudo gunicorn --version\ngunicorn (version 19.9.0)\n\nIs this an issue that anyone else has run into?\n\n\nDeploy the model to Sagemaker\n\nTo deploy onto Sagemaker, I built the model using MLProject. The docker image that I have uploaded to ECR is the image I used to run the project and generate the model. When I attempt to deploy the model, I am using the following python script (the XXXX are personal info I removed for the post):\n\nimport mlflow.sagemaker as mfs\n\n\nrun_id = '0'\nexperiment_id = 'f7cad9db15134c2abaa6d2a8b208c505'\nregion = 'us-east-1'\naws_id = 'XXXXXXX'\narn = 'XXXXXXXXXX'\nimage_url = 'XXXXXXX\/mlflow-sklearn-test:latest'\napp_name = 'iris-dt-1'\nmodel_uri = 'mlruns\/%s\/%s\/artifacts\/sk_models' % (run_id, experiment_id)\n\n\nmfs.deploy(app_name=app_name, model_uri=model_uri, region_name=region, mode='create', execution_role_arn=arn, image_url=image_url)\n\n\nWhen I run the script, I get the following error:\n\u00a0\n2019\/09\/03 14:50:53 INFO mlflow.sagemaker: Creating new endpoint with name: iris-dt-1 ...\nTraceback (most recent call last):\n\u00a0 File \"sagemaker_deployment.py\", line 12, in <module>\n\u00a0 \u00a0 mfs.deploy(app_name=app_name, model_uri=model_uri, region_name=region, mode='create', execution_role_arn=arn, image_url=image_url)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/sagemaker\/__init__.py\", line 325, in deploy\n\u00a0 \u00a0 role=execution_role_arn, sage_client=sage_client)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/sagemaker\/__init__.py\", line 628, in _create_sagemaker_endpoint\n\u00a0 \u00a0 sage_client=sage_client)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/sagemaker\/__init__.py\", line 840, in _create_sagemaker_model\n\u00a0 \u00a0 model_response = sage_client.create_model(**create_model_args)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/botocore\/client.py\", line 357, in _api_call\n\u00a0 \u00a0 return self._make_api_call(operation_name, kwargs)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/botocore\/client.py\", line 661, in _make_api_call\n\u00a0 \u00a0 raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreateModel operation: ECR image \"XXXXXXX\/mlflow-sklearn-test:latest\" is invalid.\n\n\nHas anyone experienced this error before? I have tried googling the answer and the only answer I could find was to add the\u00a0:latest\u00a0tag to the image URI, but I have already done this and I still get the error.\n\n\n\n\nThank you so much!!",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1567508364000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":41.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/QPGFSApJ4Io",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[
            {
                "Answer_creation_time":"2019-09-04T00:48:20",
                "Answer_body":"Hey\u00a0Melanie,\u00a0\n\n\nFor (1) My only long-shot thought would be that maybe\u00a0its a python versioning issue, Could MLFlow be running on Python 3 and gunicorn be install on 2? Shouldn't impact bash, but it could be a problem. There's also a random suggestion to install gunicorn from source.\u00a0 Are you spinning that up in a virtual\u00a0environment just to control for all of the dependencies.\n\n\n\n\nFor (2) I think this is an issue we dealt with, two things to try:\nin ECR, when you go into the repository in the console, is \"latest\" the image tag that is listed? Are there any others? If not, I'd maybe try pushing a new image to the same repository with a new tag, and then reference that tag just to confirm.\nAlthough this doesn't explicitly state anything about permissions, there's a chance it's a sneaky IAM issue. In the CreateModel docs\u00a0(which mlflow is calling), it mentions that the user who is calling this endpoint must have permissions to assume the role to provide access to the artifacts or containers. This means the account that boto3 is attached to in python should have an sts:assumerole permission that assume a role with access to ECR (this is probably the right permission). I've attached the JSON example that you can give you could add to account to test the assume role permission.\u00a0\n\n\nLet me know if any of this helps!\n\n\n-Adam\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/36db1100-ba72-48f2-90b8-faa55c8e560b%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-09-13T19:05:15",
                "Answer_body":"Hi Melanie,\n\n\nWere you able to confirm that the ECR image URI you're referencing is listed in the ECR console? Did Adam's ECR suggestion help you resolve the issue?\n\n\nBest,\n\n\nCorey\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CAHbUTHtxn%3D382DaJMCgbn9gqOrQ8C-K8Re%2BJsg7XpiL92c0BDA%40mail.gmail.com."
            },
            {
                "Answer_creation_time":"2019-09-13T20:05:54",
                "Answer_body":"Sorry for the slow reply. It turns out the issues I was having was due to the ECR permissions in place at the enterprise I work at. With some help of the AWS team, I was able to get all of those permissions squared away and everything is now working."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: model deployment issues; content:hello,\n\n\ni've been trying to deploy a scikit-learn model (a super simple classification using the iris data set) that i built and trained using the standard mlproject protocol. i have been trying to deploy in two different manners and have been getting errors both ways:\n\n\nserve the model using a local rest server\n\nto serve the model, i have been using the following command:\n models serve -m mlruns\/0\/f7cad9db15134c2abaa6d2a8b208c505\/artifacts\/sk_models -h **.***.**.** -p 1234 --no-conda\nnote: the host flag is the correct ip, i just masked it for this post\n\nwhen i run this command, i get the following output:\n2019\/09\/03 14:36:16 info .models.cli: selected backend for flavor 'python_function'\n2019\/09\/03 14:36:16 info .pyfunc.backend: === running command 'gunicorn --timeout=60 -b **.***.**.**:1234 -w 1 ${gunicorn_cmd_args} -- .pyfunc.scoring_server.wsgi:app'\nbash: gunicorn: command not found\n\ni have ensured that gunicorn is in fact installed:\nsudo gunicorn --version\ngunicorn (version 19.9.0)\n\nis this an issue that anyone else has run into?\n\n\ndeploy the model to sagemaker\n\nto deploy onto sagemaker, i built the model using mlproject. the docker image that i have uploaded to ecr is the image i used to run the project and generate the model. when i attempt to deploy the model, i am using the following python script (the xxxx are personal info i removed for the post):\n\nimport .sagemaker as mfs\n\n\nrun_id = '0'\nexperiment_id = 'f7cad9db15134c2abaa6d2a8b208c505'\nregion = 'us-east-1'\naws_id = 'xxxxxxx'\narn = 'xxxxxxxxxx'\nimage_url = 'xxxxxxx\/-sklearn-test:latest'\napp_name = 'iris-dt-1'\nmodel_uri = 'mlruns\/%s\/%s\/artifacts\/sk_models' % (run_id, experiment_id)\n\n\nmfs.deploy(app_name=app_name, model_uri=model_uri, region_name=region, mode='create', execution_role_arn=arn, image_url=image_url)\n\n\nwhen i run the script, i get the following error:\n\u00a0\n2019\/09\/03 14:50:53 info .sagemaker: creating new endpoint with name: iris-dt-1 ...\ntraceback (most recent call last):\n\u00a0 file \"sagemaker_deployment.py\", line 12, in <module>\n\u00a0 \u00a0 mfs.deploy(app_name=app_name, model_uri=model_uri, region_name=region, mode='create', execution_role_arn=arn, image_url=image_url)\n\u00a0 file \"\/usr\/local\/lib\/python3.6\/site-packages\/\/sagemaker\/__init__.py\", line 325, in deploy\n\u00a0 \u00a0 role=execution_role_arn, sage_client=sage_client)\n\u00a0 file \"\/usr\/local\/lib\/python3.6\/site-packages\/\/sagemaker\/__init__.py\", line 628, in _create_sagemaker_endpoint\n\u00a0 \u00a0 sage_client=sage_client)\n\u00a0 file \"\/usr\/local\/lib\/python3.6\/site-packages\/\/sagemaker\/__init__.py\", line 840, in _create_sagemaker_model\n\u00a0 \u00a0 model_response = sage_client.create_model(**create_model_args)\n\u00a0 file \"\/usr\/local\/lib\/python3.6\/site-packages\/botocore\/client.py\", line 357, in _api_call\n\u00a0 \u00a0 return self._make_api_call(operation_name, kwargs)\n\u00a0 file \"\/usr\/local\/lib\/python3.6\/site-packages\/botocore\/client.py\", line 661, in _make_api_call\n\u00a0 \u00a0 raise error_class(parsed_response, operation_name)\nbotocore.exceptions.clienterror: an error occurred (validationexception) when calling the createmodel operation: ecr image \"xxxxxxx\/-sklearn-test:latest\" is invalid.\n\n\nhas anyone experienced this error before? i have tried googling the answer and the only answer i could find was to add the\u00a0:latest\u00a0tag to the image uri, but i have already done this and i still get the error.\n\n\n\n\nthank you so much!!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having issues deploying a scikit-learn model using a local rest server and deploying it to Sagemaker, receiving errors in both cases."
    },
    {
        "Question_id":null,
        "Question_title":"Fail to create Endpoints in SageMaker--JNI and NoClassDefFound error",
        "Question_body":"I was trying to deploy a model(logged as a Mleap model in Databricks and saved in a s3 bucket) to SageMaker, and got stuck at the Endpoint creation:\n\n\"The primary container for production variant [xxx] did not pass the ping health check. Please check CloudWatch logs for this endpoint.\"\n\nIn the log I found the following block repeating over and over again until some time later the creating Endpoint process just stopped and the status turned 'failed' in the SageMaker UI:\n\nError: A JNI error has occurred, please check your installation and try again\r\nException in thread \"main\" java.lang.NoClassDefFoundError: org\/eclipse\/jetty\/util\/thread\/ThreadPool\r\n#011at java.lang.Class.getDeclaredMethods0(Native Method)\r\n#011at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\r\n#011at java.lang.Class.privateGetMethodRecursive(Class.java:3048)\r\n#011at java.lang.Class.getMethod0(Class.java:3018)\r\n#011at java.lang.Class.getMethod(Class.java:1784)\r\n#011at sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544)\r\n#011at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526)\r\nCaused by: java.lang.ClassNotFoundException: org.eclipse.jetty.util.thread.ThreadPool\r\n#011at java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n#011at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n#011at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\r\n#011at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n#011... 7 more\r\nGot sigterm signal, exiting.\n\n\nI coded in Python in Databricks and as far as I could tell this is a Java error so I have no idea what went wrong, anyone has any experience deploying an 'outside' model to SageMaker? Any help or tips would be much appreciated!\n\nFYI: my whole s3 setup, ECR setup were in us-west-2(Oregon); the integration of AWS IAM role and Databricks Role are properly set up; in my s3, I could see the Databricks distributed filesystem in one bucket and the trained and pickled model in another; the docker image that is supposed to hold the model is successfully registered in ECR. I also tried to change the instance type under 'Production variants' in the Endpoint creation settings, I set it to the same instance type (ml.m5.large) as the one I used to initiate the Databricks runtime cluster but it did not seem to work.\n\nUpdate: I successfully trained, logged and deployed a sklearn model, but still have the same issue with spark ML model; for the container, I used a image built by mlflow:\n\nmlflow sagemaker build-and-push-container\n\n\nEdited by: ShumZZ on Sep 29, 2019 3:12 PM\n\nEdited by: ShumZZ on Oct 2, 2019 2:42 PM",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1569795079000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker"
        ],
        "Question_view_count":16.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUECV9A3Q2RK6pqVpSvhRpYw\/fail-to-create-endpoints-in-sage-maker-jni-and-no-class-def-found-error",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2019-10-03T23:06:21.000Z",
                "Answer_score":0,
                "Answer_body":"Hi ShumZZ,\n\nI'm assuming your model container is built through Mleap's Databrick runtime integration. From the code base (https:\/\/github.com\/combust\/mleap\/tree\/master\/mleap-databricks-runtime-fat), it seems that the underlying implementation is in Scala, which would require JNI bindings to interact with your Python code.\n\nHave you tried running your model container locally? If the error persists when in your local environment, I would suggest reaching out to the Mleap community for assistance. To run your container locally, please follow the commands in\nSageMaker documentation https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms-inference-code.html\n\nThank you very much for trying out Amazon SageMaker! Please let us know if you have additional questions.\n\nBest Regards,\nYijie",
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2019-10-03T20:30:13.000Z",
                "Answer_score":0,
                "Answer_body":"Hi Yijie,\nThanks so much for the reply! I followed your advice and saw indeed that the local test also failed with the same JNI error...\n\nYet I am a bit confused since I actually used Mlflow's CLI mlflow sagemaker build-and-push-container to build the container. I am quite new to all these concepts (this is actually the first time I've ever worked on an end-to-end ML project), so correct me if I am wrong, should I reach out to Mlflow community instead of Mleap? Or is it the case that under the hood the container is indeed built through Mleap's Databrick runtime integration? Any help\/ clarifications\/ advices would be much appreciated:)\n\nLinks that might be useful but I do not quite understand...\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/sagemaker\/cli.py\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/models\/docker_utils.py",
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2019-10-10T19:03:58.000Z",
                "Answer_score":0,
                "Answer_body":"After some discussion with the Mlflow community, we confirmed the bug, where Java dependencies are not correctly installed in the docker image that Mlflow uses by default. I posted a bug report (https:\/\/github.com\/mlflow\/mlflow\/issues\/1906) on Github and a temporary fix has been provided by @smurching (https:\/\/github.com\/mlflow\/mlflow\/pull\/1913).\n\nEdited by: ShumZZ on Oct 10, 2019 12:04 PM",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: fail to create endpoints in --jni and noclassdeffound error; content:i was trying to deploy a model(logged as a mleap model in databricks and saved in a s3 bucket) to , and got stuck at the endpoint creation:\n\n\"the primary container for production variant [xxx] did not pass the ping health check. please check cloudwatch logs for this endpoint.\"\n\nin the log i found the following block repeating over and over again until some time later the creating endpoint process just stopped and the status turned 'failed' in the  ui:\n\nerror: a jni error has occurred, please check your installation and try again\r\nexception in thread \"main\" java.lang.noclassdeffounderror: org\/eclipse\/jetty\/util\/thread\/threadpool\r\n#011at java.lang.class.getdeclaredmethods0(native method)\r\n#011at java.lang.class.privategetdeclaredmethods(class.java:2701)\r\n#011at java.lang.class.privategetmethodrecursive(class.java:3048)\r\n#011at java.lang.class.getmethod0(class.java:3018)\r\n#011at java.lang.class.getmethod(class.java:1784)\r\n#011at sun.launcher.launcherhelper.validatemainclass(launcherhelper.java:544)\r\n#011at sun.launcher.launcherhelper.checkandloadmain(launcherhelper.java:526)\r\ncaused by: java.lang.classnotfoundexception: org.eclipse.jetty.util.thread.threadpool\r\n#011at java.net.urlclassloader.findclass(urlclassloader.java:382)\r\n#011at java.lang.classloader.loadclass(classloader.java:424)\r\n#011at sun.misc.launcher$appclassloader.loadclass(launcher.java:349)\r\n#011at java.lang.classloader.loadclass(classloader.java:357)\r\n#011... 7 more\r\ngot sigterm signal, exiting.\n\n\ni coded in python in databricks and as far as i could tell this is a java error so i have no idea what went wrong, anyone has any experience deploying an 'outside' model to ? any help or tips would be much appreciated!\n\nfyi: my whole s3 setup, ecr setup were in us-west-2(oregon); the integration of aws iam role and databricks role are properly set up; in my s3, i could see the databricks distributed filesystem in one bucket and the trained and pickled model in another; the docker image that is supposed to hold the model is successfully registered in ecr. i also tried to change the instance type under 'production variants' in the endpoint creation settings, i set it to the same instance type (ml.m5.large) as the one i used to initiate the databricks runtime cluster but it did not seem to work.\n\nupdate: i successfully trained, logged and deployed a sklearn model, but still have the same issue with spark ml model; for the container, i used a image built by mlflow:\n\nmlflow  build-and-push-container\n\n\nedited by: shumzz on sep 29, 2019 3:12 pm\n\nedited by: shumzz on oct 2, 2019 2:42 pm",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty creating an endpoint for a model logged as a MLeap model in Databricks and saved in a S3 bucket, and is receiving a JNI error and NoClassDefFoundError. They have tried changing the instance type and using an MLFlow container, but have not been successful."
    },
    {
        "Question_id":73133746.0,
        "Question_title":"Fb-Prophet, Apache Spark in Colab and AWS SageMaker\/ Lambda",
        "Question_body":"<p>I am using <code>Google-Colab<\/code> for creating a model by using FbProphet and i am try to use Apache Spark in the <code>Google-Colab<\/code> itself. Now can i upload this <code>Google-colab<\/code> notebook in <code>aws Sagemaker\/Lambda<\/code> for free <code>(without charge for Apache Spark and only charge for AWS SageMaker)<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1658906440657,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "apache-spark",
            "google-colaboratory",
            "amazon-sagemaker",
            "facebook-prophet"
        ],
        "Question_view_count":51.0,
        "Owner_creation_time":1658906023852,
        "Owner_last_access_time":1663921457750,
        "Owner_reputation":152.0,
        "Owner_up_votes":15.0,
        "Owner_down_votes":1.0,
        "Owner_views":11.0,
        "Answer_body":"<p>In short, You can upload the notebook without any issue into SageMaker. Few things to keep in mind<\/p>\n<ol>\n<li>If you are using the pyspark library in colab and running spark locally,  you should be able to do the same by installing necessary pyspark libs in Sagemaker studio kernels. Here you will only pay for the underlying compute for the notebook instance. If you are experimenting then I would recommend you to use <a href=\"https:\/\/studiolab.sagemaker.aws\/\" rel=\"nofollow noreferrer\">https:\/\/studiolab.sagemaker.aws\/<\/a> to create a free account and try things out.<\/li>\n<li>If you had a separate spark cluster setup then you may need a similar setup in AWS using EMR so that you can connect to the cluster to execute the job.<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1658964743500,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":1660220920907,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73133746",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: fb-prophet, apache spark in colab and \/ lambda; content:<p>i am using <code>google-colab<\/code> for creating a model by using fbprophet and i am try to use apache spark in the <code>google-colab<\/code> itself. now can i upload this <code>google-colab<\/code> notebook in <code>\/lambda<\/code> for free <code>(without charge for apache spark and only charge for )<\/code>?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if they can upload their Google Colab notebook, which uses FB Prophet and Apache Spark, to \/lambda for free, without being charged for Apache Spark."
    },
    {
        "Question_id":null,
        "Question_title":"Shapash and MLFlow",
        "Question_body":"Dear all,\nI have a Model which is using shapash LIbray. Do I need any special precompilation to its input values, in order to serve it through MLFlow?",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1631381970000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":11.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/D4ttV9ONWRA",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: shapash and ; content:dear all,\ni have a model which is using shapash libray. do i need any special precompilation to its input values, in order to serve it through ?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if they need to do any special precompilation to the input values of their model using the Shapash library in order to serve it."
    },
    {
        "Question_id":71685588.0,
        "Question_title":"what is a optimal setting for a sagemaker batch job?",
        "Question_body":"<p>Based on AWS documentation, <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/batch-transform.html\" rel=\"nofollow noreferrer\"> docs<\/a>, I've set up a batch inference job. however, once we choose the instance type and instance count, bare minimum , does sagemaker choose optimal plan to process jobs, say if there are more than one files , and if resource are available, can those files in parallel?<\/p>\n<pre><code>from sagemaker.transformer import Transformer\n\ntr = Transformer(model_name='custom_model',instance_count=2, instance_type='ml.m4.xlarge')\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1648686714690,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-sagemaker"
        ],
        "Question_view_count":175.0,
        "Owner_creation_time":1590797441983,
        "Owner_last_access_time":1664049080543,
        "Owner_reputation":525.0,
        "Owner_up_votes":69.0,
        "Owner_down_votes":0.0,
        "Owner_views":98.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71685588",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: what is a optimal setting for a  batch job?; content:<p>based on aws documentation, <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/batch-transform.html\" rel=\"nofollow noreferrer\"> docs<\/a>, i've set up a batch inference job. however, once we choose the instance type and instance count, bare minimum , does  choose optimal plan to process jobs, say if there are more than one files , and if resource are available, can those files in parallel?<\/p>\n<pre><code>from .transformer import transformer\n\ntr = transformer(model_name='custom_model',instance_count=2, instance_type='ml.m4.xlarge')\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if there is an optimal setting for a batch job, based on AWS documentation, and if resources are available, if multiple files can be processed in parallel."
    },
    {
        "Question_id":null,
        "Question_title":"AzureML Scoring Script fails with ImportError: no known parent package",
        "Question_body":"On trying to deploy a Model as a Container, endpoint gets created, however, scoring script fails with an error:\n\nImportError: attempted relative import with no known parent package\n\n\n\n\n\nThis is because i'm referencing another module (packaged in the docker image using source_directory) with a relative path from scoring file.\n\nCan you help me in resolving this error?\n\nFiles\\modules structure (a simplified version):\n\nproject\n->src\n-> scoring.py\n-> module1.py\n-> common\n-> module2.py, etc\n-> init.py\n-> init.py\n-> configs\n-> conda_env.yml\n\nIn scoring.py,\nfrom .module1.py import SomeClass\n..\n..\n\nIn module1.py,\nfrom .common.module2.py importSC2\n...\n..\n\n\n\n\n\nAnd below is how an Inference config is initialized:\ninference_config = InferenceConfig(source_directory=\".\/\",\nruntime= \"python\",\nentry_script=\"src\/scoring.py\",\nconda_file=\"configs\/conda_env.yml\"\n)\n\n\n\n\n\nI could not pass entry_script as \"src.scoring\" as this fails the Validation and relative path to scoring file is expected",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_creation_time":1603969996160,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/144492\/azureml-scoring-script-fails-with-importerror-no-k.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-29T16:20:54.573Z",
                "Answer_score":0,
                "Answer_body":"@SunilSinghal-3380 Thanks for the question. When deploying your inference script, beyond the entry script (score.py), inferenceConfig also let you specify source directory that include the entry script as well as all other python code (packages as a subfolder in the source directory that has its own init.py, or plain python script files modules). The score.py script can directly import from them because the whole folder including score.py and all other folders will be available at the inference running environment. There is no need to save them as a \"model\".\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.inferenceconfig?view=azure-ml-py\n\nFull sample available at https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-to-cloud\/model-register-and-deploy.ipynb",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-11-02T10:44:15.697Z",
                "Answer_score":0,
                "Answer_body":"@SunilSinghal-3380 Thanks for the details. When you specify a source directory and a path(relative to the source_directory) to entry script, and if your deployment is failing, most likely the issue is with how you entry_script references other files in the source_directory. register-model-deploy-local-advanced.ipynb has an example of how to specify source directory and perform a local deployment for faster troubleshooting.\n\nHow to deploy using environments can be found here model-register-and-deploy.ipynb . InferenceConfig class accepts source_directory and entry_script parameters, where source_directory is a path to the folder that contains all files(score.py and any other additional files) to create the image.\nThis multi-model-register-and-deploy.ipynb has code snippets on how to create InferenceConfig with source_directory and entry_script.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-12T17:44:52.173Z",
                "Answer_score":0,
                "Answer_body":"Hi, I am having the same issue. Could you please direct me to the right resource from where I can get some insight to solve my issue. I have a trained model file which also includes some supported py module files. The tree is shown below:\n\nmodel --> conf --> hmcn.json\n--> data --> (some other required json files)\n--> dataset --> init.py\n--> classification_dataset.py\n--> collator.py\n--> data_preprocessor.py\n--> dataset.py\n--> model --> (some other .py module files)\n--> config.py\n--> HMCN\n--> util.py\n\nIn the above tree HMCN is the model file and as shown there are some python module files which are imported in the score.py (not included in this tree) script for inferencing. I was using the AZURE Web UI and registered the model by selecting the \"model\" directory so that in the artifacts tab the root item is shown as \"model\" and inside the model there are all the files shown in the tree are uploaded.\n\nNow I am trying to create an endpoint and deploy the model by using a \"score.py\" script for real-time inferencing. I did it with the WebUI by going to Endpoints --> Create deployment and in the Environment I selected score.py and choose PyTorch 1.9 curated environment but the during deployment the process fails and gives error that the module not found in the \"score.py\". The module that it is referring is in the \"config.py\" as shown in the model tree. I believe I need to set the path of the model tree so that the \"score.py\" can find the module. But I do now know how.\n\nYour help would be greatly appreciated. Thanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  scoring script fails with importerror: no known parent package; content:on trying to deploy a model as a container, endpoint gets created, however, scoring script fails with an error:\n\nimporterror: attempted relative import with no known parent package\n\n\n\n\n\nthis is because i'm referencing another module (packaged in the docker image using source_directory) with a relative path from scoring file.\n\ncan you help me in resolving this error?\n\nfiles\\modules structure (a simplified version):\n\nproject\n->src\n-> scoring.py\n-> module1.py\n-> common\n-> module2.py, etc\n-> init.py\n-> init.py\n-> configs\n-> conda_env.yml\n\nin scoring.py,\nfrom .module1.py import someclass\n..\n..\n\nin module1.py,\nfrom .common.module2.py importsc2\n...\n..\n\n\n\n\n\nand below is how an inference config is initialized:\ninference_config = inferenceconfig(source_directory=\".\/\",\nruntime= \"python\",\nentry_script=\"src\/scoring.py\",\nconda_file=\"configs\/conda_env.yml\"\n)\n\n\n\n\n\ni could not pass entry_script as \"src.scoring\" as this fails the validation and relative path to scoring file is expected",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is attempting to deploy a model as a container, but is receiving an error due to referencing another module with a relative path from the scoring file."
    },
    {
        "Question_id":66601526.0,
        "Question_title":"Azure ML Kubernetes - Private IP",
        "Question_body":"<p>I have an AKS cluster in a VNET\/Subnet. My AKS is linked to AzureML.<\/p>\n<p>I successfully deployed an Azure ML service to that AKS.<\/p>\n<p>However, I see that the azureml-fe service is responding to a public IP and not a private IP from my VNET\/Subnet.<\/p>\n<p>How can I make it so my AzureML inference service is exposed with a private IP?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1615558380740,
        "Question_favorite_count":1.0,
        "Question_score":1.0,
        "Question_tags":[
            "azure-aks",
            "azure-machine-learning-service"
        ],
        "Question_view_count":232.0,
        "Owner_creation_time":1274212839807,
        "Owner_last_access_time":1663341727192,
        "Owner_reputation":591.0,
        "Owner_up_votes":32.0,
        "Owner_down_votes":1.0,
        "Owner_views":75.0,
        "Answer_body":"<p>Maybe you need to use an internal load balancer, then it will use a private IP address. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-kubernetes?tabs=python#create-or-attach-an-aks-cluster-to-use-internal-load-balancer-with-private-ip\" rel=\"nofollow noreferrer\">Here<\/a> is the example code for Python:<\/p>\n<pre><code>from azureml.core.compute.aks import AksUpdateConfiguration\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n# When you create an AKS cluster, you can specify Internal Load Balancer to be created with provisioning_config object\nprovisioning_config = AksCompute.provisioning_configuration(load_balancer_type = 'InternalLoadBalancer')\n\n# when you attach an AKS cluster, you can update the cluster to use internal load balancer after attach\naks_target = AksCompute(ws,&quot;myaks&quot;)\n\n# Change to the name of the subnet that contains AKS\nsubnet_name = &quot;default&quot;\n# Update AKS configuration to use an internal load balancer\nupdate_config = AksUpdateConfiguration(None, &quot;InternalLoadBalancer&quot;, subnet_name)\naks_target.update(update_config)\n# Wait for the operation to complete\naks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1615790277368,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66601526",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  kubernetes - private ip; content:<p>i have an aks cluster in a vnet\/subnet. my aks is linked to .<\/p>\n<p>i successfully deployed an  service to that aks.<\/p>\n<p>however, i see that the -fe service is responding to a public ip and not a private ip from my vnet\/subnet.<\/p>\n<p>how can i make it so my  inference service is exposed with a private ip?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to deploy an Azure ML service to an AKS cluster in a VNet\/Subnet, but the inference service is responding to a public IP instead of a private IP from the VNet\/Subnet. They are looking for a way to make the inference service exposed with a private IP."
    },
    {
        "Question_id":60879944.0,
        "Question_title":"SageMaker - What IAM Permission to specify for ECR?",
        "Question_body":"<h1>Question<\/h1>\n\n<p>Is this the ECR IAM permission required for SageMaker to use the XGBoost of the <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/algos.html\" rel=\"nofollow noreferrer\">Amazon SageMaker built-in algorithms<\/a> in the <strong>us-west-1<\/strong> region?<\/p>\n\n<pre><code>\"Effect\": \"Allow\",\n\"Action\": [\n  \"ecr:GetAuthorizationToken\",\n  \"ecr:BatchCheckLayerAvailability\",\n  \"ecr:GetDownloadUrlForLayer\",\n  \"ecr:BatchGetImage\"\n],\n\"Resource\": [\n  \"arn:aws:ecr:us-west-1:632365934929:repository\/632365934929.dkr.ecr.us-west-1.amazonaws.com\/xgboost:1\"\n]\n<\/code><\/pre>\n\n<h1>Background<\/h1>\n\n<p>The AWS document <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sagemaker-roles.html#sagemaker-roles-createnotebookinstance-perms\" rel=\"nofollow noreferrer\">Amazon SageMaker Roles<\/a> tells to specify <strong>TrainingImage<\/strong> value of the <strong>CreateTrainingJob<\/strong> API.<\/p>\n\n<pre><code>Scope ecr permissions as follows:\n- Scope to the AlgorithmSpecification.TrainingImage value that you specify in a CreateTrainingJob request.\n- Scope to the PrimaryContainer.Image value that you specify in a CreateModel request:\n\n\n\"Effect\": \"Allow\",\n\"Action\": [\n  \"ecr:BatchCheckLayerAvailability\",\n  \"ecr:GetDownloadUrlForLayer\",\n  \"ecr:BatchGetImage\"\n],\n\"Resource\": [\n  \"arn:aws:ecr:::repository\/my-repo1\",\n  \"arn:aws:ecr:::repository\/my-repo2\",\n  \"arn:aws:ecr:::repository\/my-repo3\"\n]\n<\/code><\/pre>\n\n<p>The AWS SageMaker API document <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_AlgorithmSpecification.html#sagemaker-Type-AlgorithmSpecification-TrainingImage\" rel=\"nofollow noreferrer\">TrainingImage<\/a> tells to specify the algorithm <strong>docker image registry path<\/strong> as the value.<\/p>\n\n<blockquote>\n  <p><strong>TrainingImage<\/strong><br\/><br\/>\n  The <strong>registry path of the Docker image<\/strong> that contains the training\n  algorithm. For information about docker registry paths for built-in\n  algorithms, see Algorithms Provided by Amazon SageMaker: Common\n  Parameters. Amazon SageMaker supports both <strong>registry\/repository[:tag]<\/strong>\n  and registry\/repository[@digest] image path formats.<\/p>\n<\/blockquote>\n\n<p>The AWS document <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/sagemaker-algo-docker-registry-paths.html\" rel=\"nofollow noreferrer\">Common parameters for built-in algorithms<\/a> indicates the XGBoost registry path is <code>632365934929.dkr.ecr.us-west-1.amazonaws.com\/xgboost:1<\/code>.<\/p>\n\n<blockquote>\n  <p><br\/>\n  |Algorithm name|Training image and inference image registry path|<br\/>\n  |XGBoost       | <strong>ecr_path<\/strong>\/xgboost:<strong>tag<\/strong>|<br\/>\n  <br\/>\n  <strong>ecr_path<\/strong> (Algorithms: BlazingText, ..., Seq2Seq, and XGBoost (0.72)<br\/>\n  | us-west-1 | 632365934929.dkr.ecr.us-west-1.amazonaws.com |  <\/p>\n  \n  <p>For the Training Image and Inference Image Registry Path column, <strong>use the :1 version tag<\/strong> to ensure that you are using a stable version of the algorithm. You can reliably host a model trained using an image with the :1 tag on an inference image that has the :1 tag. <\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1585282753820,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-iam",
            "amazon-sagemaker"
        ],
        "Question_view_count":1170.0,
        "Owner_creation_time":1416648155470,
        "Owner_last_access_time":1664057583236,
        "Owner_reputation":14749.0,
        "Owner_up_votes":641.0,
        "Owner_down_votes":62.0,
        "Owner_views":968.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1585283190403,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60879944",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  - what iam permission to specify for ecr?; content:<h1>question<\/h1>\n\n<p>is this the ecr iam permission required for  to use the xgboost of the <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/algos.html\" rel=\"nofollow noreferrer\"> built-in algorithms<\/a> in the <strong>us-west-1<\/strong> region?<\/p>\n\n<pre><code>\"effect\": \"allow\",\n\"action\": [\n  \"ecr:getauthorizationtoken\",\n  \"ecr:batchchecklayeravailability\",\n  \"ecr:getdownloadurlforlayer\",\n  \"ecr:batchgetimage\"\n],\n\"resource\": [\n  \"arn:aws:ecr:us-west-1:632365934929:repository\/632365934929.dkr.ecr.us-west-1.amazonaws.com\/xgboost:1\"\n]\n<\/code><\/pre>\n\n<h1>background<\/h1>\n\n<p>the aws document <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/-roles.html#-roles-createnotebookinstance-perms\" rel=\"nofollow noreferrer\"> roles<\/a> tells to specify <strong>trainingimage<\/strong> value of the <strong>createtrainingjob<\/strong> api.<\/p>\n\n<pre><code>scope ecr permissions as follows:\n- scope to the algorithmspecification.trainingimage value that you specify in a createtrainingjob request.\n- scope to the primarycontainer.image value that you specify in a createmodel request:\n\n\n\"effect\": \"allow\",\n\"action\": [\n  \"ecr:batchchecklayeravailability\",\n  \"ecr:getdownloadurlforlayer\",\n  \"ecr:batchgetimage\"\n],\n\"resource\": [\n  \"arn:aws:ecr:::repository\/my-repo1\",\n  \"arn:aws:ecr:::repository\/my-repo2\",\n  \"arn:aws:ecr:::repository\/my-repo3\"\n]\n<\/code><\/pre>\n\n<p>the  api document <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/apireference\/api_algorithmspecification.html#-type-algorithmspecification-trainingimage\" rel=\"nofollow noreferrer\">trainingimage<\/a> tells to specify the algorithm <strong>docker image registry path<\/strong> as the value.<\/p>\n\n<blockquote>\n  <p><strong>trainingimage<\/strong><br\/><br\/>\n  the <strong>registry path of the docker image<\/strong> that contains the training\n  algorithm. for information about docker registry paths for built-in\n  algorithms, see algorithms provided by : common\n  parameters.  supports both <strong>registry\/repository[:tag]<\/strong>\n  and registry\/repository[@digest] image path formats.<\/p>\n<\/blockquote>\n\n<p>the aws document <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/-algo-docker-registry-paths.html\" rel=\"nofollow noreferrer\">common parameters for built-in algorithms<\/a> indicates the xgboost registry path is <code>632365934929.dkr.ecr.us-west-1.amazonaws.com\/xgboost:1<\/code>.<\/p>\n\n<blockquote>\n  <p><br\/>\n  |algorithm name|training image and inference image registry path|<br\/>\n  |xgboost       | <strong>ecr_path<\/strong>\/xgboost:<strong>tag<\/strong>|<br\/>\n  <br\/>\n  <strong>ecr_path<\/strong> (algorithms: blazingtext, ..., seq2seq, and xgboost (0.72)<br\/>\n  | us-west-1 | 632365934929.dkr.ecr.us-west-1.amazonaws.com |  <\/p>\n  \n  <p>for the training image and inference image registry path column, <strong>use the :1 version tag<\/strong> to ensure that you are using a stable version of the algorithm. you can reliably host a model trained using an image with the :1 tag on an inference image that has the :1 tag. <\/p>\n<\/blockquote>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to specify the ecr permission to allow \"ecr:getauthorizationtoken\", \"ecr:batchchecklayeravailability\", \"ecr:getdownloadurlforlayer\", and \"ecr:batchgetimage\" for the xgboost algorithm in the us-west-1 region, using the registry path of 632365934929.dkr.ecr.us-west-1.amazonaws.com\/xgboost:1 with the :1 version tag."
    },
    {
        "Question_id":71576580.0,
        "Question_title":"Unable to deploy locally trained Logistic Regression model on AWS Sagemaker",
        "Question_body":"<p>I have trained a Logistic Regression model on my local machine. Saved the model using Joblib and tried deploying it on Aws Sagemaker using &quot;Linear-Learner&quot; image.<\/p>\n<p>Facing issues while deployment as the deployment process keeps continuing and the Status is always as &quot;Creating&quot; and does not turn to &quot;InService&quot;.<\/p>\n<pre><code>endpoint_name = &quot;DEMO-LogisticEndpoint&quot; + strftime(&quot;%Y-%m-%d-%H-%M-%S&quot;, gmtime())\nprint(endpoint_name)\ncreate_endpoint_response = sm_client.create_endpoint(\n    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n)\nprint(create_endpoint_response[&quot;EndpointArn&quot;])\n\nresp = sm_client.describe_endpoint(EndpointName=endpoint_name)\nstatus = resp[&quot;EndpointStatus&quot;]\nprint(&quot;Status: &quot; + status)\n\nwhile status == &quot;Creating&quot;:\n    time.sleep(60)\n    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n    status = resp[&quot;EndpointStatus&quot;]\n    print(&quot;Status: &quot; + status)\n<\/code><\/pre>\n<p>The while loop keeps executing and the status never change.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1647970559340,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "machine-learning",
            "logistic-regression",
            "amazon-sagemaker"
        ],
        "Question_view_count":108.0,
        "Owner_creation_time":1647947360696,
        "Owner_last_access_time":1649861002596,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71576580",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: unable to deploy locally trained logistic regression model on ; content:<p>i have trained a logistic regression model on my local machine. saved the model using joblib and tried deploying it on  using &quot;linear-learner&quot; image.<\/p>\n<p>facing issues while deployment as the deployment process keeps continuing and the status is always as &quot;creating&quot; and does not turn to &quot;inservice&quot;.<\/p>\n<pre><code>endpoint_name = &quot;demo-logisticendpoint&quot; + strftime(&quot;%y-%m-%d-%h-%m-%s&quot;, gmtime())\nprint(endpoint_name)\ncreate_endpoint_response = sm_client.create_endpoint(\n    endpointname=endpoint_name, endpointconfigname=endpoint_config_name\n)\nprint(create_endpoint_response[&quot;endpointarn&quot;])\n\nresp = sm_client.describe_endpoint(endpointname=endpoint_name)\nstatus = resp[&quot;endpointstatus&quot;]\nprint(&quot;status: &quot; + status)\n\nwhile status == &quot;creating&quot;:\n    time.sleep(60)\n    resp = sm_client.describe_endpoint(endpointname=endpoint_name)\n    status = resp[&quot;endpointstatus&quot;]\n    print(&quot;status: &quot; + status)\n<\/code><\/pre>\n<p>the while loop keeps executing and the status never change.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty deploying a locally trained logistic regression model on using the \"linear-learner\" image, as the deployment process keeps continuing and the status remains \"creating\"."
    },
    {
        "Question_id":null,
        "Question_title":"Text-to-Speech seems to ignore SSML input",
        "Question_body":"Greetings, all! Since getting started with the TTS service, I have had good success with submitting JSON files that specify simple text input. I am using the instructions for PowerShell as described here:https:\/\/cloud.google.com\/text-to-speech\/docs\/quickstart-protocol#windowsWhen submitting JSON files that specify SSML input, however, it seems that some of the SSML elements are being ignored by the speech synthesizer. I'd like to use the <prosody> and <emphasis> elements, but the output isn't reflecting the values I specified. Here's an example:It doesn't seem to matter how I specify the rate and pitch attributes\u2014the output comes back with no alteration.Thank you for taking the time to read this. If you have information or suggestions, please reply with your ideas!",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1639729200000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":127.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Text-to-Speech-seems-to-ignore-SSML-input\/td-p\/179629\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-20T14:41:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"When submitting JSON files with SSML input, you can use the Prosody tag in the following format[1][2].\n\nExample:\n\n```\n\n<prosody rate=\"slow\" pitch=\"-2st\">Can you hear me now?<\/prosody>\n\n```\n\n[1] https:\/\/cloud.google.com\/text-to-speech\/docs\/ssml#prosody\n\n[2] https:\/\/www.w3.org\/TR\/speech-synthesis11\/#:~:text=3.2.4%20prosody%20Element"
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: text-to-speech seems to ignore ssml input; content:greetings, all! since getting started with the tts service, i have had good success with submitting json files that specify simple text input. i am using the instructions for powershell as described here:https:\/\/cloud.google.com\/text-to-speech\/docs\/quickstart-protocol#windowswhen submitting json files that specify ssml input, however, it seems that some of the ssml elements are being ignored by the speech synthesizer. i'd like to use the <prosody> and <emphasis> elements, but the output isn't reflecting the values i specified. here's an example:it doesn't seem to matter how i specify the rate and pitch attributes\u2014the output comes back with no alteration.thank you for taking the time to read this. if you have information or suggestions, please reply with your ideas!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty getting the text-to-speech service to recognize SSML input, and is looking for suggestions on how to get the <prosody> and <emphasis> elements to be reflected in the output."
    },
    {
        "Question_id":null,
        "Question_title":"SM Elastic Inference Accelerators are not available during inference",
        "Question_body":"Hi Team,\n\nGreetings!!\n\nWe are able to deploy on real-time endpoint with elastic inference accelerators. But SM Elastic Inference Accelerators are not available during inference, could you please have a look?\n\nNote:\n\nWe are bringing our own trained model using Pytorch = 1.10.2 on SM.\nWe don't find any errors in cloud watch logs.\nConverted our trained model to TorchScript and able to load that model as well during inference.\nTried both Torchscript's trace and script modes but no luck.\n\nCode\n\nfrom sagemaker.pytorch import PyTorchModel\n\nfrom sagemaker import get_execution_role\n\nendpoint_name = 'ner-bert'\n\npytorch = PyTorchModel(entry_point='deploy_ei.py', source_dir='code', model_data=model_data, role=get_execution_role(), framework_version='1.3.1', py_version='py3', sagemaker_session=sagemaker_session)\n\npredictor = pytorch.deploy(initial_instance_count=1, instance_type='ml.m5.large', accelerator_type='ml.eia2.xlarge', endpoint_name=endpoint_name)\n\nThanks, Vinayak",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1645620490604,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Machine Learning & AI",
            "Amazon Elastic Inference"
        ],
        "Question_view_count":37.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUi78wfQkWTuaxYOjA8jGZaw\/sm-elastic-inference-accelerators-are-not-available-during-inference",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: sm elastic inference accelerators are not available during inference; content:hi team,\n\ngreetings!!\n\nwe are able to deploy on real-time endpoint with elastic inference accelerators. but sm elastic inference accelerators are not available during inference, could you please have a look?\n\nnote:\n\nwe are bringing our own trained model using pytorch = 1.10.2 on sm.\nwe don't find any errors in cloud watch logs.\nconverted our trained model to torchscript and able to load that model as well during inference.\ntried both torchscript's trace and script modes but no luck.\n\ncode\n\nfrom .pytorch import pytorchmodel\n\nfrom  import get_execution_role\n\nendpoint_name = 'ner-bert'\n\npytorch = pytorchmodel(entry_point='deploy_ei.py', source_dir='code', model_data=model_data, role=get_execution_role(), framework_version='1.3.1', py_version='py3', _session=_session)\n\npredictor = pytorch.deploy(initial_instance_count=1, instance_type='ml.m5.large', accelerator_type='ml.eia2.xlarge', endpoint_name=endpoint_name)\n\nthanks, vinayak",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to deploy a trained model using PyTorch 1.10.2 on SM with Elastic Inference Accelerators during inference, despite converting the model to TorchScript and loading it during inference."
    },
    {
        "Question_id":65482767.0,
        "Question_title":"How to create a hyperparameter tuning step in SageMaker pipeline?",
        "Question_body":"<p>I am trying to use the latest SageMaker Python SDK (v2.23.0) to implement a SageMaker pipeline that includes a hyperparameter tuning job. However I didn't see anything in module sagemaker.workflow.steps or sagemaker.workflow.step_collections that I can use. There is a TrainingStep class but it's not for HPO.<\/p>\n<p>Is this not supported at this time?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1609182593660,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-sagemaker",
            "hyperparameters",
            "mlops"
        ],
        "Question_view_count":286.0,
        "Owner_creation_time":1389816586960,
        "Owner_last_access_time":1632325252590,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65482767",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to create a hyperparameter tuning step in  pipeline?; content:<p>i am trying to use the latest  python sdk (v2.23.0) to implement a  pipeline that includes a hyperparameter tuning job. however i didn't see anything in module .workflow.steps or .workflow.step_collections that i can use. there is a trainingstep class but it's not for hpo.<\/p>\n<p>is this not supported at this time?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to use the Python SDK to create a pipeline with a hyperparameter tuning job, but is unable to find the necessary module to do so. It appears that this is not supported at this time."
    },
    {
        "Question_id":null,
        "Question_title":"Wandb Project table value select algorithm",
        "Question_body":"<p>I have a wondering how to select value in project table.<br>\nWhat is algorithm in wandb project table to select values? In images, these values is not minimum in each models.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da.png\" data-download-href=\"\/uploads\/short-url\/bJn70ylkOmBrf45BJzAwLO3FLIe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png\" alt=\"image\" data-base62-sha1=\"bJn70ylkOmBrf45BJzAwLO3FLIe\" width=\"690\" height=\"99\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1035x148.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1380x198.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">2478\u00d7358 42.7 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1650599811340,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":328.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-project-table-value-select-algorithm\/2300",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":5470,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2022-04-26T11:38:15.026Z",
                "cooked":"<p>Hey Byeongjun, I am not sure I fully understand the question. Could you please elaborate?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-04-26T11:38:15.026Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2300,
                "topic_slug":"wandb-project-table-value-select-algorithm",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5512,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2022-04-29T14:12:11.733Z",
                "cooked":"<p>Hi Byeongjun,<\/p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.<\/p>\n<p>Best,<br>\nWeights &amp; Biases<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-04-29T14:12:11.733Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2300,
                "topic_slug":"wandb-project-table-value-select-algorithm",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6224,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-06-21T03:57:11.366Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":4,
                "post_type":3,
                "updated_at":"2022-06-21T03:57:11.366Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2300,
                "topic_slug":"wandb-project-table-value-select-algorithm",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  project table value select algorithm; content:<p>i have a wondering how to select value in project table.<br>\nwhat is algorithm in  project table to select values? in images, these values is not minimum in each models.<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/1x\/5238ecb4f4a97cf42692282562cfbd48f3bb95da.png\" data-download-href=\"\/uploads\/short-url\/bjn70ylkombrf45bjzawlo3flie.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png\" alt=\"image\" data-base62-sha1=\"bjn70ylkombrf45bjzawlo3flie\" width=\"690\" height=\"99\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1035x148.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1380x198.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">2478\u00d7358 42.7 kb<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is wondering how to select values in a project table, and what algorithm to use when the values are not minimum in each model."
    },
    {
        "Question_id":70363230.0,
        "Question_title":"How to create partitioned Athena table with Sagemaker Feature Store",
        "Question_body":"<p>I'm using Sagemaker Feature Store and trying to create an Offline Feature Store. During the process, Sagemaker creates an Athena table. However, I notice that this table is not partitioned, and when I create a query, it takes forever.<\/p>\n<p>How can I use Sagemaker Feature Store to create a Athena table with partition?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1639569109507,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-sagemaker",
            "feature-store",
            "aws-feature-store"
        ],
        "Question_view_count":69.0,
        "Owner_creation_time":1476704375776,
        "Owner_last_access_time":1659029181416,
        "Owner_reputation":109.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":21.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70363230",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to create partitioned athena table with  feature store; content:<p>i'm using  feature store and trying to create an offline feature store. during the process,  creates an athena table. however, i notice that this table is not partitioned, and when i create a query, it takes forever.<\/p>\n<p>how can i use  feature store to create a athena table with partition?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to create an offline feature store with Feature Store, but the Athena table created is not partitioned, causing queries to take a long time. They are looking for a way to use Feature Store to create an Athena table with partitions."
    },
    {
        "Question_id":64286191.0,
        "Question_title":"How to add keyboard shortcuts to AWS Ground Truth labeler UI?",
        "Question_body":"<p>I'm using AWS Sagemaker Ground Truth for a Custom Labeling Task that involves editing bounding boxes and their labels.  Ground Truth's UI has built-in keyboard shortcuts for doing things like choosing the label for a box, but it seems to lack shortcuts for other built-in UI elements like &quot;No adjustments needed&quot; or the &quot;Submit&quot; button.<\/p>\n<p>Is there a way to add such shortcuts?  I've looked at the crowd-html-elements for customizing the appearance of the page, but can't find anything in there about keyboard shortcuts.  It doesn't even look like crowd-button or crowd-icon-button support specifying a shortcut as an attribute.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1602271699933,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "amazon-sagemaker",
            "labeling"
        ],
        "Question_view_count":412.0,
        "Owner_creation_time":1289772110723,
        "Owner_last_access_time":1663029415383,
        "Owner_reputation":309.0,
        "Owner_up_votes":14.0,
        "Owner_down_votes":0.0,
        "Owner_views":40.0,
        "Answer_body":"<p>Could try something like:<\/p>\n<pre><code>document.addEventListener('keydown', function(event) {\n  if (event.shiftKey &amp;&amp; event.keyCode === 13) {\n    document.getElementsByTagName('crowd-bounding-box')[0].shadowRoot.getElementById('nothing-to-adjust').querySelector('label').click();\n  }\n});\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1605831050088,
        "Answer_score":3.0,
        "Owner_location":"Mt Kisco, NY",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64286191",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to add keyboard shortcuts to aws ground truth labeler ui?; content:<p>i'm using  ground truth for a custom labeling task that involves editing bounding boxes and their labels.  ground truth's ui has built-in keyboard shortcuts for doing things like choosing the label for a box, but it seems to lack shortcuts for other built-in ui elements like &quot;no adjustments needed&quot; or the &quot;submit&quot; button.<\/p>\n<p>is there a way to add such shortcuts?  i've looked at the crowd-html-elements for customizing the appearance of the page, but can't find anything in there about keyboard shortcuts.  it doesn't even look like crowd-button or crowd-icon-button support specifying a shortcut as an attribute.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to add keyboard shortcuts to the AWS Ground Truth Labeler UI for elements such as \"No Adjustments Needed\" and the \"Submit\" button."
    },
    {
        "Question_id":44245265.0,
        "Question_title":"Azure Machine Learning + R: Reading files",
        "Question_body":"<p>I am trying to run my R-code in the Azure Machine Learning environment, and I am running into a dead end trying to import data from the blob storage.<\/p>\n\n<p>Locally I can easily import a file like this:<\/p>\n\n<pre><code>data &lt;- read.delim(\"myfile.xls\", sep = \"\\t\", skip = 9)\n<\/code><\/pre>\n\n<p>When I am using Azure machine learning, just referring to file in the blob storage location, I get the error \"cannot open the connection\".<\/p>\n\n<pre><code>data &lt;- read.delim(\"https:\/\/knnstorage.blob.core.windows.net\/knn\/myfile.xls\", sep = \"\\t\", skip = 9)\n<\/code><\/pre>\n\n<p>I have additionally attempted to import the file using the \"Import Data\" option, but it only allows one to import csv files or excel-files with at the most one line to be skipped.<\/p>\n\n<p>In the future I will also need to import unstructured text into Azure Machine Learning. Is this really not possible using R?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_creation_time":1496069269853,
        "Question_favorite_count":0.0,
        "Question_score":3.0,
        "Question_tags":[
            "r",
            "import",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":359.0,
        "Owner_creation_time":1346939900920,
        "Owner_last_access_time":1663852618247,
        "Owner_reputation":2545.0,
        "Owner_up_votes":339.0,
        "Owner_down_votes":16.0,
        "Owner_views":381.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44245265",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  + r: reading files; content:<p>i am trying to run my r-code in the  environment, and i am running into a dead end trying to import data from the blob storage.<\/p>\n\n<p>locally i can easily import a file like this:<\/p>\n\n<pre><code>data &lt;- read.delim(\"myfile.xls\", sep = \"\\t\", skip = 9)\n<\/code><\/pre>\n\n<p>when i am using , just referring to file in the blob storage location, i get the error \"cannot open the connection\".<\/p>\n\n<pre><code>data &lt;- read.delim(\"https:\/\/knnstorage.blob.core.windows.net\/knn\/myfile.xls\", sep = \"\\t\", skip = 9)\n<\/code><\/pre>\n\n<p>i have additionally attempted to import the file using the \"import data\" option, but it only allows one to import csv files or excel-files with at the most one line to be skipped.<\/p>\n\n<p>in the future i will also need to import unstructured text into . is this really not possible using r?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to import data into an R environment and is facing issues when trying to import data from a blob storage location and is unable to open the connection. The user has also tried to import the file using the \"Import Data\" option, but it only allows for the import of CSV files or Excel files with at most one line to be skipped. The user is seeking a solution to import unstructured text into R."
    },
    {
        "Question_id":71459057.0,
        "Question_title":"'DecisionTreeRegressor' object has no attribute 'n_features_': 0",
        "Question_body":"<p>i had deployed my random Forest Regressor on AzureML.when i tried to request the scoring url i got the &quot;'DecisionTreeRegressor' object has no attribute 'n_features_': 0&quot;<a href=\"https:\/\/i.stack.imgur.com\/TJU5a.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/LVwEP.png\" rel=\"nofollow noreferrer\">My request code and error image<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1647191736773,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "azure-machine-learning-service"
        ],
        "Question_view_count":116.0,
        "Owner_creation_time":1647191405910,
        "Owner_last_access_time":1663482601360,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71459057",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: 'decisiontreeregressor' object has no attribute 'n_features_': 0; content:<p>i had deployed my random forest regressor on .when i tried to request the scoring url i got the &quot;'decisiontreeregressor' object has no attribute 'n_features_': 0&quot;<a href=\"https:\/\/i.stack.imgur.com\/tju5a.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/lvwep.png\" rel=\"nofollow noreferrer\">my request code and error image<\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user encountered an error when trying to request a scoring URL after deploying a random forest regressor, with the error message 'decisiontreeregressor' object has no attribute 'n_features_': 0."
    },
    {
        "Question_id":50085699.0,
        "Question_title":"Azure Machine Learning studio: Failed to parse parameter",
        "Question_body":"<p>I keep getting Error 002: Failed to parse parameter in the \"Score Matchbox Recommender\" box. <\/p>\n\n<p>I'm using Azure's default \"Recommender: Movie recommendation\" sample project. <\/p>\n\n<p>I've tried referring to an online video too, followed same steps but to no avail. Still getting error 002.<\/p>\n\n<p><a href=\"https:\/\/www.youtube.com\/watch?v=3cNd_YRAsdk\" rel=\"nofollow noreferrer\">https:\/\/www.youtube.com\/watch?v=3cNd_YRAsdk<\/a><\/p>\n\n<p>Full error code below.<\/p>\n\n<blockquote>\n  <p>requestId = 8ce5b273ae124cd5a5d872e5a509fe45 errorComponent=Module. taskStatusCode=400. {\"Exception\":{\"ErrorId\":\"ParameterParsing\",\"ErrorCode\":\"0002\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 0002: Failed to parse parameter\"}}Error: Error 0002: Failed to parse parameter Process exited with error code -2<\/p>\n<\/blockquote>\n\n<p>Does anyone have any idea what's wrong?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_creation_time":1524998626470,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "data-science",
            "azure-machine-learning-studio",
            "azure-machine-learning-workbench"
        ],
        "Question_view_count":153.0,
        "Owner_creation_time":1514724330472,
        "Owner_last_access_time":1663734614036,
        "Owner_reputation":3.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1526050454763,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50085699",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  studio: failed to parse parameter; content:<p>i keep getting error 002: failed to parse parameter in the \"score matchbox recommender\" box. <\/p>\n\n<p>i'm using azure's default \"recommender: movie recommendation\" sample project. <\/p>\n\n<p>i've tried referring to an online video too, followed same steps but to no avail. still getting error 002.<\/p>\n\n<p><a href=\"https:\/\/www.youtube.com\/watch?v=3cnd_yrasdk\" rel=\"nofollow noreferrer\">https:\/\/www.youtube.com\/watch?v=3cnd_yrasdk<\/a><\/p>\n\n<p>full error code below.<\/p>\n\n<blockquote>\n  <p>requestid = 8ce5b273ae124cd5a5d872e5a509fe45 errorcomponent=module. taskstatuscode=400. {\"exception\":{\"errorid\":\"parameterparsing\",\"errorcode\":\"0002\",\"exceptiontype\":\"moduleexception\",\"message\":\"error 0002: failed to parse parameter\"}}error: error 0002: failed to parse parameter process exited with error code -2<\/p>\n<\/blockquote>\n\n<p>does anyone have any idea what's wrong?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error code 002: failed to parse parameter when using the \"score matchbox recommender\" box in Azure's default \"recommender: movie recommendation\" sample project, despite following the same steps as an online video."
    },
    {
        "Question_id":50209284.0,
        "Question_title":"How to use the trained model developed in AZURE ML",
        "Question_body":"<p>I trained a model in AZURE ML. Now i want to use that model in my ios app to predict the output\u00a0.<\/p>\n\n<p>How to download the model from AZURE and use it my swift code.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1525678856837,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":516.0,
        "Owner_creation_time":1510206999776,
        "Owner_last_access_time":1630651881372,
        "Owner_reputation":81.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":41.0,
        "Answer_body":"<p>As far as I know, the model could run in <strong>Azure Machine Learning Studio<\/strong>.It seems that you are unable to download it, the model could do nothing outside of Azure ML. <\/p>\n\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/41236871\/how-to-download-the-trained-models-from-azure-machine-studio\">Here<\/a> is a similar post for you to refer, I have also tried @Ahmet's \nmethod, but result is like @mrjrdnthms says.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1525849618928,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1558224843256,
        "Answer_last_edit_time":1525850503192,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50209284",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to use the trained model developed in ; content:<p>i trained a model in . now i want to use that model in my ios app to predict the output\u00a0.<\/p>\n\n<p>how to download the model from azure and use it my swift code.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to know how to download the trained model from Azure ML and use it in their iOS app with Swift code."
    },
    {
        "Question_id":63698011.0,
        "Question_title":"AWS Notebook Instance is working but Lambda is not accepting the input",
        "Question_body":"<p>I developed an ANN tool by using pycharm\/tensorflow on my own computer. I uploaded the h5 and json files to Amazon Sagemaker by creating a Notebook Instance. I was finally able to successfully create an endpoint and make it work. The following code in Notebook Instance -Jupyter works:<\/p>\n<pre><code>import json\nimport boto3\nimport numpy as np\nimport io\nimport sagemaker\nfrom sagemaker.tensorflow.model import TensorFlowModel\nclient = boto3.client('runtime.sagemaker')\ndata = np.random.randn(1,6).tolist()\nendpoint_name = 'sagemaker-tensorflow-**********'\nresponse = client.invoke_endpoint(EndpointName=endpoint_name, Body=json.dumps(data))\nresponse_body = response['Body']\nprint(response_body.read())\n<\/code><\/pre>\n<p>However, the problem occurs when I created a lambda function and call the endpoint from there. The input should be a row of 6 features -that is a 1-by-6 vector. I enter the following input into lambda {&quot;data&quot;:&quot;1,1,1,1,1,1&quot;} and it gives me the following error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;\/var\/task\/lambda_function.py&quot;, line 20, in lambda_handler\n    Body=payload)\n  File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 316, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 635, in _make_api_call\n    raise error_class(parsed_response, operation_name)\n<\/code><\/pre>\n<p>I think the problem is that the input needs to be 1-by-6 instead of 6-by-1 and I don't know how to do that.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1599015165303,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "tensorflow",
            "aws-lambda",
            "amazon-sagemaker"
        ],
        "Question_view_count":51.0,
        "Owner_creation_time":1369539919747,
        "Owner_last_access_time":1663810191950,
        "Owner_reputation":311.0,
        "Owner_up_votes":6.0,
        "Owner_down_votes":0.0,
        "Owner_views":35.0,
        "Answer_body":"<p>I assume the content type you specified is <code>text\/csv<\/code>, so try out:<\/p>\n<pre><code>{&quot;data&quot;: [&quot;1,1,1,1,1,1&quot;]}\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1599633575463,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63698011",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: aws notebook instance is working but lambda is not accepting the input; content:<p>i developed an ann tool by using pycharm\/tensorflow on my own computer. i uploaded the h5 and json files to  by creating a notebook instance. i was finally able to successfully create an endpoint and make it work. the following code in notebook instance -jupyter works:<\/p>\n<pre><code>import json\nimport boto3\nimport numpy as np\nimport io\nimport \nfrom .tensorflow.model import tensorflowmodel\nclient = boto3.client('runtime.')\ndata = np.random.randn(1,6).tolist()\nendpoint_name = '-tensorflow-**********'\nresponse = client.invoke_endpoint(endpointname=endpoint_name, body=json.dumps(data))\nresponse_body = response['body']\nprint(response_body.read())\n<\/code><\/pre>\n<p>however, the problem occurs when i created a lambda function and call the endpoint from there. the input should be a row of 6 features -that is a 1-by-6 vector. i enter the following input into lambda {&quot;data&quot;:&quot;1,1,1,1,1,1&quot;} and it gives me the following error:<\/p>\n<pre><code>traceback (most recent call last):\n  file &quot;\/var\/task\/lambda_function.py&quot;, line 20, in lambda_handler\n    body=payload)\n  file &quot;\/var\/runtime\/botocore\/client.py&quot;, line 316, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  file &quot;\/var\/runtime\/botocore\/client.py&quot;, line 635, in _make_api_call\n    raise error_class(parsed_response, operation_name)\n<\/code><\/pre>\n<p>i think the problem is that the input needs to be 1-by-6 instead of 6-by-1 and i don't know how to do that.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty getting their Lambda function to accept an input of a 1-by-6 vector for their ANN tool, which works in their notebook instance."
    },
    {
        "Question_id":null,
        "Question_title":"S3 remote permissions and integrity best practices",
        "Question_body":"<p>Does anyone have recommendations about best practices for S3 remote set-up?<\/p>\n<p>I\u2019m specifically interested if there are thoughts around permissions and integrity of data in S3. To enable S3, remotes users would be granted read &amp; write permissions. As long as users use the dvc tooling it appears the data should relatively save. However, granting permissions would allow direct access outside of dvc tooling. This seems to open the possibility of a scenario where the data history could be corrupted.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1553787278231,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":1562.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/s3-remote-permissions-and-integrity-best-practices\/165",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":350,
                "name":"Ruslan Kuprieiev",
                "username":"kupruser",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/e95f7d\/{size}.png",
                "created_at":"2019-03-28T21:04:30.222Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/meby\">@meby<\/a>!<\/p>\n<p>Great question! All data history is stored in your git repo. Dvc remote only stores the data itself, which is stored under checksum names, so unless you are directly uploading a file with incorrect checksum(which shouldn\u2019t happen with dvc, since it checks that cache files are not corrupted before uploading them) you should be fine. To help mitigate the risk, you might want to create separate creds for each team member specifically to use them with dvc s3 remote. Also, using different buckets on s3 for different dvc projects is also a good idea when combined with per-project-per-team-member creds. And, of course, backups might be a good idea as well <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> If you are using dvc pipelines too, then you should be able to reproduce all other data from your source data in single <code>dvc repro<\/code> command, so that adds an additional level of assurance even if you do lose your data <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>\n<p>Thanks,<br>\nRuslan<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2019-03-28T21:04:30.222Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":16,
                "reads":16,
                "readers_count":15,
                "score":83.2,
                "yours":false,
                "topic_id":165,
                "topic_slug":"s3-remote-permissions-and-integrity-best-practices",
                "display_username":"Ruslan Kuprieiev",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":3,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":351,
                "name":"Matt Eby",
                "username":"meby",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/90ced4\/{size}.png",
                "created_at":"2019-03-29T16:38:22.822Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/kupruser\">@kupruser<\/a>,<\/p>\n<p>Thanks for the quick reply. I like the suggestion per project and per team creds.<\/p>\n<p>I also like the ability to reproduce from source data if intermediates are lost. One of my main concerns of course is not losing the source data and also ensuring that we don\u2019t lose the final generated artifacts that would be deployed to production. One thing we\u2019re evaluating is whether we can configure DVC &amp; S3 so that we can store those in S3 or if we should rely on external archiving where a majority of users would be granted only read access.<\/p>\n<p>With S3, I believe we could turn on versioning at the bucket level and not grant <code>s3:DeleteObject<\/code> permissions. This would ensure users could create and update objects but never delete and we\u2019d have a version history for all updates if we needed to roll back.<\/p>\n<p>The DVC <a href=\"https:\/\/dvc.org\/doc\/commands-reference\/remote-add#options\" rel=\"nofollow noopener\">docs for S3<\/a> list <code>s3:DeleteObject<\/code> as a required permission. Is this necessary for \u201cevery day\u201d workflows?<\/p>\n<p>Specifically, I\u2019m trying to understand how this relates to my mental model of git history. Once a specific commit hash is in the repo it is there forever unless you\u2019re rewriting the history which is not an \u201cevery day\u201d workflow.<\/p>\n<p>Thanks,<br>\nMatt<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2019-03-29T16:38:22.822Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":18,
                "reads":15,
                "readers_count":14,
                "score":98.0,
                "yours":false,
                "topic_id":165,
                "topic_slug":"s3-remote-permissions-and-integrity-best-practices",
                "display_username":"Matt Eby",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/dvc.org\/doc\/commands-reference\/remote-add#options",
                        "internal":false,
                        "reflection":false,
                        "title":"Get Started | Machine Learning Version Control System",
                        "clicks":78
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":63,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":355,
                "name":"Ruslan Kuprieiev",
                "username":"kupruser",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/e95f7d\/{size}.png",
                "created_at":"2019-03-31T11:15:19.766Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/meby\">@meby<\/a>  !<\/p>\n<p>s3:DeleteObject is not required, unless you are using <code>dvc gc<\/code> (garbage collector), so your proposed way of not granting s3:DeleteObject would definitely work for day-to-day workflow <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>\n<p>Thanks,<br>\nRuslan<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2019-03-31T11:15:19.766Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":4,
                "reads":13,
                "readers_count":12,
                "score":22.6,
                "yours":false,
                "topic_id":165,
                "topic_slug":"s3-remote-permissions-and-integrity-best-practices",
                "display_username":"Ruslan Kuprieiev",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"meby",
                    "name":"Matt Eby",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/90ced4\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":3,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: s3 remote permissions and integrity best practices; content:<p>does anyone have recommendations about best practices for s3 remote set-up?<\/p>\n<p>i\u2019m specifically interested if there are thoughts around permissions and integrity of data in s3. to enable s3, remotes users would be granted read &amp; write permissions. as long as users use the  tooling it appears the data should relatively save. however, granting permissions would allow direct access outside of  tooling. this seems to open the possibility of a scenario where the data history could be corrupted.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for best practices for setting up S3 remotes, specifically regarding permissions and data integrity. They are concerned that granting permissions could lead to data history being corrupted if users access the data outside of the tooling."
    },
    {
        "Question_id":null,
        "Question_title":"Deploy GPU enbaled in a studio notebook locally",
        "Question_body":"Hello there, team. I'm attempting to deploy a model locally in my ML studio notebook, which has GPU compute power. But when I try to run my model, I get an error.\n\nFound no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from azure ml\n\nI'm using this\n\n env = Environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/new_cuda_dep.yml' ) #environment  using\n inference_config = InferenceConfig(entry_script=\"score.py\", environment=env , source_directory='.' ,)",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1632702738960,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/566714\/deploy-gpu-enbaled-in-a-studio-notebook-locally.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-29T04:12:36.79Z",
                "Answer_score":0,
                "Answer_body":"@NabeelRaza-8986 Thanks for the question. Since the AzureML SDK for local deployment uses the existing docker client we'll have to make sure that this client picks up the nvidia container runtime to make the GPUs available to it. Usually we would use the gpus --all flag when creating a new docker container.\n\nMake sure you install the nvidia container runtime.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: deploy gpu enbaled in a studio notebook locally; content:hello there, team. i'm attempting to deploy a model locally in my ml studio notebook, which has gpu compute power. but when i try to run my model, i get an error.\n\nfound no nvidia driver on your system. please check that you have an nvidia gpu and installed a driver from \n\ni'm using this\n\n env = environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/new_cuda_dep.yml' ) #environment  using\n inference_config = inferenceconfig(entry_script=\"score.py\", environment=env , source_directory='.' ,)",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is attempting to deploy a model locally in their ML Studio notebook with GPU compute power, but is receiving an error indicating that no NVIDIA driver is installed on their system."
    },
    {
        "Question_id":65044700.0,
        "Question_title":"Proper way to make a request to a model, deployed via Azure ML Designer",
        "Question_body":"<p>I am trying to make the POST request to the Azure ML Designer endpoint (model, I have deployed).\nHere is my code:<\/p>\n<pre><code>import requests\n\nscoring_uri = 'http:some-url\/score'\nkey = 'someKey'\n\nheaders = {'Content-Type': 'application\/json'}\nheaders['Authorization'] = f'Bearer {key}'\n\nresponse = requests.get('https:\/\/www.okino.ua\/media\/var\/news\/2019\/12\/04\/Quentin_Tarantino.jpg')\n\ninput_data = &quot;{\\&quot;data\\&quot;: [&quot; + str(response.content) + &quot;]}&quot;\nresp = requests.post(scoring_uri, data=response.content, headers=headers)\nprint(resp.text)\n<\/code><\/pre>\n<p>And I receive and error:<\/p>\n<pre><code>{&quot;error&quot;: {&quot;code&quot;: 400, &quot;message&quot;: &quot;Input Data Error. Input data are inconsistent with schema.\\nSchema: {'WebServiceInput0': {'columnAttributes': [{'name': 'image', 'type': 'Bytes', 'isFeature': True, 'elementType': {'typeName': 'bytes', 'isNullable': False}, 'properties': {'mime_type': 'image\/png', 'image_ref': 'image_info'}}, {'name': 'id', 'type': 'Numeri\\nData: b'\\\\xff\\\\xd8\\\\xff\\\\xe0\\\\x00\\\\x10JFIF\\\\x00\\\\x01\\\\x01\\\\x01\\\\x01,\\\\x01,\\\\x00\\\\x00\\\\xff\\\\xfe\\\\x00[Copyright Shutterstock 2019;82139424;3600;2400;1563865756;Tue, 23 Jul 2019 07:09:16 GMT;0\\\\xff\\\\xed\\\\x04\\\\x16Photoshop 3.0\\\\x008BIM\\\\x04\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x03\\\\xf9\\\\x1c\\\\x02\\\\x05\\\\x00\\\\n103\\nTraceback (most recent call last):\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/site-packages\/azureml\/designer\/serving\/dagengine\/processor.py\\&quot;, line 18, in run\\n    webservice_input, global_parameters = self.pre_process(raw_data)\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/site-packages\/azureml\/designer\/serving\/dagengine\/processor.py\\&quot;, line 45, in pre_process\\n    json_data = json.loads(raw_data)\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/json\/__init__.py\\&quot;, line 349, in loads\\n    s = s.decode(detect_encoding(s), 'surrogatepass')\\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\\n&quot;, &quot;details&quot;: &quot;&quot;}}\n\n<\/code><\/pre>\n<p>Is anyone aware of how I should pass image data to the exposed by Azure ML endpoint?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1606517768417,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "azure",
            "computer-vision",
            "classification",
            "azure-machine-learning-service"
        ],
        "Question_view_count":264.0,
        "Owner_creation_time":1565038435856,
        "Owner_last_access_time":1606639837552,
        "Owner_reputation":23.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1606785467360,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65044700",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: proper way to make a request to a model, deployed via  designer; content:<p>i am trying to make the post request to the  designer endpoint (model, i have deployed).\nhere is my code:<\/p>\n<pre><code>import requests\n\nscoring_uri = 'http:some-url\/score'\nkey = 'somekey'\n\nheaders = {'content-type': 'application\/json'}\nheaders['authorization'] = f'bearer {key}'\n\nresponse = requests.get('https:\/\/www.okino.ua\/media\/var\/news\/2019\/12\/04\/quentin_tarantino.jpg')\n\ninput_data = &quot;{\\&quot;data\\&quot;: [&quot; + str(response.content) + &quot;]}&quot;\nresp = requests.post(scoring_uri, data=response.content, headers=headers)\nprint(resp.text)\n<\/code><\/pre>\n<p>and i receive and error:<\/p>\n<pre><code>{&quot;error&quot;: {&quot;code&quot;: 400, &quot;message&quot;: &quot;input data error. input data are inconsistent with schema.\\nschema: {'webserviceinput0': {'columnattributes': [{'name': 'image', 'type': 'bytes', 'isfeature': true, 'elementtype': {'typename': 'bytes', 'isnullable': false}, 'properties': {'mime_type': 'image\/png', 'image_ref': 'image_info'}}, {'name': 'id', 'type': 'numeri\\ndata: b'\\\\xff\\\\xd8\\\\xff\\\\xe0\\\\x00\\\\x10jfif\\\\x00\\\\x01\\\\x01\\\\x01\\\\x01,\\\\x01,\\\\x00\\\\x00\\\\xff\\\\xfe\\\\x00[copyright shutterstock 2019;82139424;3600;2400;1563865756;tue, 23 jul 2019 07:09:16 gmt;0\\\\xff\\\\xed\\\\x04\\\\x16photoshop 3.0\\\\x008bim\\\\x04\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x03\\\\xf9\\\\x1c\\\\x02\\\\x05\\\\x00\\\\n103\\ntraceback (most recent call last):\\n  file \\&quot;\/-envs\/_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/site-packages\/\/designer\/serving\/dagengine\/processor.py\\&quot;, line 18, in run\\n    webservice_input, global_parameters = self.pre_process(raw_data)\\n  file \\&quot;\/-envs\/_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/site-packages\/\/designer\/serving\/dagengine\/processor.py\\&quot;, line 45, in pre_process\\n    json_data = json.loads(raw_data)\\n  file \\&quot;\/-envs\/_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/json\/__init__.py\\&quot;, line 349, in loads\\n    s = s.decode(detect_encoding(s), 'surrogatepass')\\nunicodedecodeerror: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\\n&quot;, &quot;details&quot;: &quot;&quot;}}\n\n<\/code><\/pre>\n<p>is anyone aware of how i should pass image data to the exposed by  endpoint?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when trying to make a post request to an Azure ML Designer endpoint with an image and is looking for advice on how to properly pass image data to the endpoint."
    },
    {
        "Question_id":null,
        "Question_title":"[Potential Bugs] Issues with `wandb sync` after running `wandb artifact cache cleanup 10GB`",
        "Question_body":"<p>Hi,<\/p>\n<p>I am using the offline mode to train models and sync the wandb logs\/artifacts later using <code>wandb sync<\/code> command. As the number of artifact files get larger, I used <code>wandb artifact cache cleanup 10GB<\/code> to clean up some disk space. However, after running this command, I can no longer to <code>wandb sync<\/code> to upload the logs to the wandb online server.<\/p>\n<p>I got the following error when using <code>wandb sync<\/code> after running <code>wandb artifact cache cleanup 10GB<\/code>. There are many artifacts in this run, some of them might be deleted via the <code>cache cleanup<\/code> command. However, the logs (learning curves etc.) are all there,  but the following error prevents the logs being sync to the cloud server. Is there a way to still upload the logs?<\/p>\n<pre><code class=\"lang-auto\">FileNotFoundError, [Errno 2] No such file or directory: '\/home\/user\/.cache\/wandb\/artifacts\/obj\/md5\/93\/a2248a657e599da7c97f43d292b1c'\nwandb: ERROR Uploading artifact file failed. Artifact won't be committed.<\/code><\/pre>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_creation_time":1642569357992,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":345.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/potential-bugs-issues-with-wandb-sync-after-running-wandb-artifact-cache-cleanup-10gb\/1784",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":4236,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2022-01-19T11:56:10.835Z",
                "cooked":"<p>Hey Tao, which wandb version are you using?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-01-19T11:56:10.835Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":9,
                "readers_count":8,
                "score":1.8,
                "yours":false,
                "topic_id":1784,
                "topic_slug":"potential-bugs-issues-with-wandb-sync-after-running-wandb-artifact-cache-cleanup-10gb",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4238,
                "name":"Tao Chen",
                "username":"taochen",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/a698b9\/{size}.png",
                "created_at":"2022-01-19T14:51:58.262Z",
                "cooked":"<p>Hi, I am using <code>0.12.9<\/code>. Thanks!<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-01-19T14:51:58.262Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":9,
                "readers_count":8,
                "score":6.8,
                "yours":false,
                "topic_id":1784,
                "topic_slug":"potential-bugs-issues-with-wandb-sync-after-running-wandb-artifact-cache-cleanup-10gb",
                "display_username":"Tao Chen",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":742,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4404,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2022-02-01T22:19:33.665Z",
                "cooked":"<p>Hey Tao, sorry about the delay on this. Could you try syncing to new run id: <code>wandb sync [PATH] --id new_run_id<\/code> ? Generate the new run id via <code>wandb.util.generate_id()<\/code><\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-02-01T22:19:33.665Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":8,
                "readers_count":7,
                "score":1.6,
                "yours":false,
                "topic_id":1784,
                "topic_slug":"potential-bugs-issues-with-wandb-sync-after-running-wandb-artifact-cache-cleanup-10gb",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4421,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2022-02-04T15:58:51.255Z",
                "cooked":"<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2022-02-04T15:58:51.255Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":7,
                "readers_count":6,
                "score":1.4,
                "yours":false,
                "topic_id":1784,
                "topic_slug":"potential-bugs-issues-with-wandb-sync-after-running-wandb-artifact-cache-cleanup-10gb",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5095,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-04-02T22:19:41.343Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":6,
                "post_type":3,
                "updated_at":"2022-04-02T22:19:41.343Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":6,
                "readers_count":5,
                "score":6.2,
                "yours":false,
                "topic_id":1784,
                "topic_slug":"potential-bugs-issues-with-wandb-sync-after-running-wandb-artifact-cache-cleanup-10gb",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: [potential bugs] issues with ` sync` after running ` artifact cache cleanup 10gb`; content:<p>hi,<\/p>\n<p>i am using the offline mode to train models and sync the  logs\/artifacts later using <code> sync<\/code> command. as the number of artifact files get larger, i used <code> artifact cache cleanup 10gb<\/code> to clean up some disk space. however, after running this command, i can no longer to <code> sync<\/code> to upload the logs to the  online server.<\/p>\n<p>i got the following error when using <code> sync<\/code> after running <code> artifact cache cleanup 10gb<\/code>. there are many artifacts in this run, some of them might be deleted via the <code>cache cleanup<\/code> command. however, the logs (learning curves etc.) are all there,  but the following error prevents the logs being sync to the cloud server. is there a way to still upload the logs?<\/p>\n<pre><code class=\"lang-auto\">filenotfounderror, [errno 2] no such file or directory: '\/home\/user\/.cache\/\/artifacts\/obj\/md5\/93\/a2248a657e599da7c97f43d292b1c'\n: error uploading artifact file failed. artifact won't be committed.<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to sync logs to the online server after running the artifact cache cleanup 10gb command, resulting in a FileNotFoundError."
    },
    {
        "Question_id":73415182.0,
        "Question_title":"When do I use a glue job or a Sagemaker Processing job for an etl?",
        "Question_body":"<p>I am currently struggling to decide on what situations in which a glue job is preferable over a sagemaker processing job and vice versa? Some advice on this topic would be greatly appreciated.<\/p>\n<p>I can do the same on both, so why should I bother with the difference?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1660903988283,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "amazon-web-services",
            "aws-glue",
            "amazon-sagemaker"
        ],
        "Question_view_count":34.0,
        "Owner_creation_time":1644981356940,
        "Owner_last_access_time":1663945577550,
        "Owner_reputation":53.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":"<ul>\n<li>if you want to use a specific EC2 instance, use SageMaker<\/li>\n<li>Pricing: SageMaker is pro-rated per-second while Glue has minimum charge amount (1min or 10min depending on versions). You should measure how much would a workload cost you on each platform<\/li>\n<li>customization: in SageMaker Processing you can customize the execution environment, as you provide a Docker image (you could run more than Spark\/Python, such as C++ or R)<\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1660951371720,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73415182",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: when do i use a glue job or a  processing job for an etl?; content:<p>i am currently struggling to decide on what situations in which a glue job is preferable over a  processing job and vice versa? some advice on this topic would be greatly appreciated.<\/p>\n<p>i can do the same on both, so why should i bother with the difference?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is struggling to decide when to use a Glue job or a Processing job for an ETL, and is wondering why they should bother with the difference if they can do the same on both."
    },
    {
        "Question_id":66923216.0,
        "Question_title":"Change Disk Type Azure ML",
        "Question_body":"<p>I have azure ml , I created compute for learning.\nCost for instance is 2-5usd with my use. But cost for p10(premium SSD) Disk 17usd.<\/p>\n<p>I don't know how change it because its not appear in azure Disk and in ML studio i cant find option for manage storage type for compute.<\/p>\n<p>Some one know how change it ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1617385541497,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-service"
        ],
        "Question_view_count":150.0,
        "Owner_creation_time":1561015783552,
        "Owner_last_access_time":1664083277456,
        "Owner_reputation":97.0,
        "Owner_up_votes":167.0,
        "Owner_down_votes":0.0,
        "Owner_views":15.0,
        "Answer_body":"<p>There is no possible way to change the compute disk type if you use the Azure ML compute cluster and compute instance. Only when you use the extra computer, you can manage the separate resources such as the disk, network, and so on. For example, you attach a VM as the target computer to the Azure ML. Then when you create the VM you can set the disk type with HDD.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1617778657403,
        "Answer_score":2.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66923216",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: change disk type ; content:<p>i have  , i created compute for learning.\ncost for instance is 2-5usd with my use. but cost for p10(premium ssd) disk 17usd.<\/p>\n<p>i don't know how change it because its not appear in azure disk and in ml studio i cant find option for manage storage type for compute.<\/p>\n<p>some one know how change it ?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking to change the disk type of their Azure ML instance from the current type to a Premium SSD, but is unable to find the option to do so in either Azure Disk or ML Studio."
    },
    {
        "Question_id":null,
        "Question_title":"How is scoring done in azure ml?",
        "Question_body":"Suppose I have 50 features in my dataset, but after feature engineering(one hot encoding or tf-idf) I get 200 feature colums. The model is trained on these 200 features and is deployed and now we have a rest endpoint for the model. Now the customer will hit the endpoint with 50 features but the model is expecting 200 columns. Where will the conversion of 50 to 200 features takes place?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1649152330267,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/800586\/how-is-scoring-done-in-azure-ml.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-05T20:26:45.297Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. It seems you're wondering how to consume the model after feature engineering. The simple answer is that you'll need to apply the same transformations on your testing dataset. The schema of the input dataset should match the schema of the data used to train the model.\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how is scoring done in ?; content:suppose i have 50 features in my dataset, but after feature engineering(one hot encoding or tf-idf) i get 200 feature colums. the model is trained on these 200 features and is deployed and now we have a rest endpoint for the model. now the customer will hit the endpoint with 50 features but the model is expecting 200 columns. where will the conversion of 50 to 200 features takes place?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking how scoring is done in Azure ML when the customer is providing fewer features than the model is expecting."
    },
    {
        "Question_id":73224036.0,
        "Question_title":"Google cloud vertex AI workbench notebook stuck on \"starting\"",
        "Question_body":"<p>I'm running a Jupyter Notebook on the Vertex AI workbench and getting the error below. It loads for an hour or two, then reverts back to a stopped state. It's a managed notebook, so I can't <code>ssh<\/code> to the notebook to recover my code, which is all I want to do since there's a lot of work there I haven't backed up (I didn't expect a big Cloud service to randomly fail like this...) Any ideas on how to get this back up and running? I am happy to delete this and start a new instance onc I recover the code on this.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Cardr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Cardr.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5.0,
        "Question_creation_time":1659540977210,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "google-cloud-platform",
            "jupyter-notebook",
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":275.0,
        "Owner_creation_time":1564327169643,
        "Owner_last_access_time":1662223953267,
        "Owner_reputation":123.0,
        "Owner_up_votes":10.0,
        "Owner_down_votes":0.0,
        "Owner_views":76.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Cambridge, MA, USA",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73224036",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: google cloud  workbench notebook stuck on \"starting\"; content:<p>i'm running a jupyter notebook on the  workbench and getting the error below. it loads for an hour or two, then reverts back to a stopped state. it's a managed notebook, so i can't <code>ssh<\/code> to the notebook to recover my code, which is all i want to do since there's a lot of work there i haven't backed up (i didn't expect a big cloud service to randomly fail like this...) any ideas on how to get this back up and running? i am happy to delete this and start a new instance onc i recover the code on this.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/cardr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/cardr.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty with their Google Cloud Workbench Notebook, which has been stuck in a \"starting\" state for an hour or two and cannot be recovered through SSH. They need help recovering their code, as they have not backed it up yet."
    },
    {
        "Question_id":70973526.0,
        "Question_title":"sagemaker-sklearn-container 1.0 requires pandas==0.25.*, but you have pandas 1.3.5 which is incompatible",
        "Question_body":"<p><strong>ERROR:<\/strong> pip's dependency resolver does not currently take into account all the packages that are installed. This behavior is the source of the following dependency conflicts.<\/p>\n<p><code>sagemaker-sklearn-container 1.0 requires pandas==0.25.*,<\/code> but you have <code>pandas 1.3.5<\/code> which is incompatible.<\/p>\n<p>I am running my notebook locally under python virtual machine , and I have <code>pandas 0.25.3<\/code> version but when I am training the model on sagemaker , it shows an error that amazon scikitlearn container <code>1.0 using 0.25.*<\/code> but I have <code>1.3.5<\/code>,<\/p>\n<p>I don't understand how can I solve it , though locally I have <code>0.25.3<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1643900263570,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "pandas",
            "scikit-learn",
            "dependencies",
            "amazon-sagemaker"
        ],
        "Question_view_count":191.0,
        "Owner_creation_time":1643899849347,
        "Owner_last_access_time":1663682953803,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1644905942447,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70973526",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: -sklearn-container 1.0 requires pandas==0.25.*, but you have pandas 1.3.5 which is incompatible; content:<p><strong>error:<\/strong> pip's dependency resolver does not currently take into account all the packages that are installed. this behavior is the source of the following dependency conflicts.<\/p>\n<p><code>-sklearn-container 1.0 requires pandas==0.25.*,<\/code> but you have <code>pandas 1.3.5<\/code> which is incompatible.<\/p>\n<p>i am running my notebook locally under python virtual machine , and i have <code>pandas 0.25.3<\/code> version but when i am training the model on  , it shows an error that amazon scikitlearn container <code>1.0 using 0.25.*<\/code> but i have <code>1.3.5<\/code>,<\/p>\n<p>i don't understand how can i solve it , though locally i have <code>0.25.3<\/code><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing a conflict between the version of pandas they have installed (1.3.5) and the version required by sklearn-container 1.0 (0.25.*)."
    },
    {
        "Question_id":null,
        "Question_title":"Prevent boto3.client('sagemaker').create_auto_ml_job() from deploying endpoint",
        "Question_body":"When I invoke the .create_auto_ml_job() method both with and without the optional ModelDeployConfig kwarg, the autopilot job deploys an endpoint using the best model. Is there a way to prevent the .create_auto_ml_job() method from behaving this way? I do not wish to deploy the best model to an endpoint, and do not wish to have to delete this endpoint.",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1669662766261,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Serverless",
            "Amazon SageMaker",
            "Machine Learning & AI"
        ],
        "Question_view_count":18.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUGEnbfLBgQJKrbdKfizHkEw\/prevent-boto-3-client-sagemaker-create-auto-ml-job-from-deploying-endpoint",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Serverless",
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: prevent boto3.client('').create_auto_ml_job() from deploying endpoint; content:when i invoke the .create_auto_ml_job() method both with and without the optional modeldeployconfig kwarg, the autopilot job deploys an endpoint using the best model. is there a way to prevent the .create_auto_ml_job() method from behaving this way? i do not wish to deploy the best model to an endpoint, and do not wish to have to delete this endpoint.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if there is a way to prevent the .create_auto_ml_job() method from deploying an endpoint with the best model, as they do not wish to deploy the best model to an endpoint."
    },
    {
        "Question_id":64653042.0,
        "Question_title":"Control tracked version of external dependency",
        "Question_body":"<p>I am trying to set up a DVC repository for machine learning data with different tagged versions of the dataset. I do this with something like:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ cd \/raid\/ml_data  # folder on a data drive\n$ git init\n$ dvc init\n$ [add data]\n$ [commit to dvc, git]\n$ git tag -a 1.0.0\n$ [add or change data]\n$ [commit to dvc, git]\n$ git tag -a 1.1.0\n<\/code><\/pre>\n<p>I have multiple projects that each need to reference some version of this dataset. The problem is I can't figure out how to set up those projects to reference a specific version. I'm able to track the <code>HEAD<\/code> of the repo with something like:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ cd ~\/my_proj  # different drive than the remote\n$ mkdir data\n$ git init\n$ dvc init\n$ dvc remote add -d local \/raid\/ml_data  # add the remote on my data drive\n$ dvc cache dir \/raid\/ml_data\/.dvc\/cache  # tell DVC to use the remote cache\n$ dvc checkout\n$ dvc run --external -d \/raid\/ml_data -o data\/ cp -r \/raid\/ml_data data\n<\/code><\/pre>\n<p>This gets me the latest version of the dataset, symlinked into my <code>data<\/code> folder, but what if I want some projects to use the <code>1.0.0<\/code> version and some to use the <code>1.1.0<\/code> version, or another version? Or for that matter, if I update the dataset to <code>2.0.0<\/code> but don't want my existing projects to necessarily track <code>HEAD<\/code> and instead keep the version with which they were set up?<\/p>\n<p>It's important to me to not create a ton of local copies of my dataset as the <code>\/home<\/code> drive is much smaller than the <code>\/raid<\/code> drive and some of these datasets are huge.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1604349754297,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "version-control",
            "dvc"
        ],
        "Question_view_count":139.0,
        "Owner_creation_time":1370629593700,
        "Owner_last_access_time":1663178436648,
        "Owner_reputation":11685.0,
        "Owner_up_votes":2855.0,
        "Owner_down_votes":47.0,
        "Owner_views":1329.0,
        "Answer_body":"<p>I think you are looking for the <a href=\"https:\/\/dvc.org\/doc\/start\/data-access\" rel=\"nofollow noreferrer\">data access<\/a> set of commands.<\/p>\n<p>In your particular case, <code>dvc import<\/code> makes sense:<\/p>\n<pre><code>$ dvc import \/raid\/ml_data data\n<\/code><\/pre>\n<p>if you want to get the most recent version (HEAD). Then you will be able to update it with the <code>dvc update<\/code> command (if 2.0.0 is released, for example).<\/p>\n<pre><code>$ dvc import \/raid\/ml_data data --rev 1.0.0\n<\/code><\/pre>\n<p>if you'd like to &quot;fix&quot; it to the specific version.<\/p>\n<h3>Avoiding copies<\/h3>\n<p>Make sure also, that <code>symlinks<\/code> are set for the second project, as described in the <a href=\"https:\/\/dvc.org\/doc\/user-guide\/large-dataset-optimization\" rel=\"nofollow noreferrer\">Large Dataset Optimization<\/a>:<\/p>\n<pre><code>$ dvc config cache.type reflink,hardlink,symlink,copy\n<\/code><\/pre>\n<p>(there are config modifiers <code>--global<\/code>, <code>--local<\/code>, <code>--system<\/code> to set this setting for everyone at once, or just for one project, etc)<\/p>\n<p>Check the details instruction <a href=\"https:\/\/dvc.org\/doc\/user-guide\/large-dataset-optimization#configuring-dvc-cache-file-link-type\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<hr \/>\n<p>Overall, it's a great setup, and looks like you got pretty much everything right. Please, don't hesitate to follow up and\/or create other questions here- we'll help you with this.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1604351561432,
        "Answer_score":1.0,
        "Owner_location":"Colorado Springs, CO",
        "Question_last_edit_time":1604361023336,
        "Answer_last_edit_time":1604362563343,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64653042",
        "Tool":"DVC",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: control tracked version of external dependency; content:<p>i am trying to set up a  repository for machine learning data with different tagged versions of the dataset. i do this with something like:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ cd \/raid\/ml_data  # folder on a data drive\n$ git init\n$  init\n$ [add data]\n$ [commit to , git]\n$ git tag -a 1.0.0\n$ [add or change data]\n$ [commit to , git]\n$ git tag -a 1.1.0\n<\/code><\/pre>\n<p>i have multiple projects that each need to reference some version of this dataset. the problem is i can't figure out how to set up those projects to reference a specific version. i'm able to track the <code>head<\/code> of the repo with something like:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ cd ~\/my_proj  # different drive than the remote\n$ mkdir data\n$ git init\n$  init\n$  remote add -d local \/raid\/ml_data  # add the remote on my data drive\n$  cache dir \/raid\/ml_data\/.\/cache  # tell  to use the remote cache\n$  checkout\n$  run --external -d \/raid\/ml_data -o data\/ cp -r \/raid\/ml_data data\n<\/code><\/pre>\n<p>this gets me the latest version of the dataset, symlinked into my <code>data<\/code> folder, but what if i want some projects to use the <code>1.0.0<\/code> version and some to use the <code>1.1.0<\/code> version, or another version? or for that matter, if i update the dataset to <code>2.0.0<\/code> but don't want my existing projects to necessarily track <code>head<\/code> and instead keep the version with which they were set up?<\/p>\n<p>it's important to me to not create a ton of local copies of my dataset as the <code>\/home<\/code> drive is much smaller than the <code>\/raid<\/code> drive and some of these datasets are huge.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to set up a repository for machine learning data with different tagged versions of the dataset, and is looking for a way to set up projects to reference a specific version without creating a ton of local copies."
    },
    {
        "Question_id":null,
        "Question_title":"Idle shutdown for user-managed notebook (vertex-AI)",
        "Question_body":"There are two types of notebooks in Vertex-AI1) managed notebook: https:\/\/cloud.google.com\/vertex-ai\/docs\/workbench\/managed\/introduction2) user-managed notebook: https:\/\/cloud.google.com\/vertex-ai\/docs\/workbench\/user-managed\/introductionI see that the former has a useful function called \"idle shutdown\" that help manage costs: managed notebooks instances shut down after being idle for a specific time period by default.Why we didn't make it available for user-managed notebook as well? Thanks",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1654153800000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":188.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Idle-shutdown-for-user-managed-notebook-vertex-AI\/td-p\/428171\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-02T22:36:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"Thanks for the feedback here. We are aware of the request and this is further to prioritize this work. Happy to get back when we have a concrete plan for this feature."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: idle shutdown for user-managed notebook (vertex-ai); content:there are two types of notebooks in vertex-ai1) managed notebook: https:\/\/cloud.google.com\/vertex-ai\/docs\/workbench\/managed\/introduction2) user-managed notebook: https:\/\/cloud.google.com\/vertex-ai\/docs\/workbench\/user-managed\/introductioni see that the former has a useful function called \"idle shutdown\" that help manage costs: managed notebooks instances shut down after being idle for a specific time period by default.why we didn't make it available for user-managed notebook as well? thanks",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking why the idle shutdown feature is not available for user-managed notebooks in Vertex-AI, as it is available for managed notebooks."
    },
    {
        "Question_id":null,
        "Question_title":"mlflow for beginners",
        "Question_body":"Hello everyone, I would like to use MLflow but I don't know how to register on the platform. Also, I would like to know if there are any step-by-step instructions on how to use this tool (for example, Run an MLflow project).\n\n\nthanks in advance,\n\n\n--\n\nOlga Ximena Giraldo Pasmin\nOrcid ID: orcid.org\/0000-0003-2978-8922\nTwiter: @olgaxgiraldo\nSkype:olgaximenagiraldo\nWebsite: http:\/\/oxgiraldo.wordpress.com",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1667821452000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":9.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/px-W1aq-dE8",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  for beginners; content:hello everyone, i would like to use  but i don't know how to register on the platform. also, i would like to know if there are any step-by-step instructions on how to use this tool (for example, run an  project).\n\n\nthanks in advance,\n\n\n--\n\nolga ximena giraldo pasmin\norcid id: orcid.org\/0000-0003-2978-8922\ntwiter: @olgaxgiraldo\nskype:olgaximenagiraldo\nwebsite: http:\/\/oxgiraldo.wordpress.com",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to know how to register on the platform and if there are any step-by-step instructions on how to use the tool."
    },
    {
        "Question_id":null,
        "Question_title":"How can I access a FileDataset without filling local disk?",
        "Question_body":"Hello!\n\nI'm setting up a pipeline for machine learning. Reading the docs I understood that when I pass my FileDataset as_mount it is mounted, similar to mounting an external drive. However, three hours into my training, my pipeline crashed, out of storage. It seems that as_mount actually is downloading per file, rather than the entire Dataset, but still uses local disk space. Is this correct? If so, how can I train on a FileDataset that is too large for any of the available compute options?\n\nDavid",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1628529752433,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/506820\/how-can-i-access-a-filedataset-without-filling-loc.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-10T12:31:26.553Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. When you mount, only the data files used by your script are loaded at the time of processing. When you download, all files referenced by the dataset will be downloaded to the compute target. If your data size exceeds the compute disk size, we recommend mounting (which reads only a subset of the data). Based on your post, you may need to use a larger compute instance to handle your workload. Please review mount vs download documentation. Hope this helps.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how can i access a filedataset without filling local disk?; content:hello!\n\ni'm setting up a pipeline for machine learning. reading the docs i understood that when i pass my filedataset as_mount it is mounted, similar to mounting an external drive. however, three hours into my training, my pipeline crashed, out of storage. it seems that as_mount actually is downloading per file, rather than the entire dataset, but still uses local disk space. is this correct? if so, how can i train on a filedataset that is too large for any of the available compute options?\n\ndavid",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to set up a machine learning pipeline and is wondering if there is a way to access a filedataset without filling up their local disk, as their pipeline crashed due to lack of storage."
    },
    {
        "Question_id":28590690.0,
        "Question_title":"Azure ML App - Complete Experince - Train automatically and Consume",
        "Question_body":"<p>I played a bit around with Azure ML studio. So as I understand the process goes like this:<\/p>\n\n<p>a) Create training experiment. Train it with data. <\/p>\n\n<p>b) Create Scoring experiment. This will include the trained model from the training experiment. Expose this as a service to be consumed over REST.<\/p>\n\n<p>Maybe a stupid question but what is the recommended way to get the complete experience like the one i get when I use an app like <a href=\"https:\/\/datamarket.azure.com\/dataset\/amla\/mba\" rel=\"nofollow\">https:\/\/datamarket.azure.com\/dataset\/amla\/mba<\/a> (Frequently Bought Together API built with Azure Machine Learning). <\/p>\n\n<p>I mean the following:<\/p>\n\n<p>a) Expose 2 or more services - one to train the model and the other to consume (test) the trained model. <\/p>\n\n<p>b) User periodically sends training data to train the model <\/p>\n\n<p>c) The trained model\/models now gets saved available for consumption<\/p>\n\n<p>d) User is now able to send a dataframe to get the predicted results.<\/p>\n\n<p>Is there an additional wrapper that needs to be built?<\/p>\n\n<p>If there is a link documenting this please point me to the same. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1424282724780,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":769.0,
        "Owner_creation_time":1424282355667,
        "Owner_last_access_time":1467981882012,
        "Owner_reputation":33.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":4.0,
        "Answer_body":"<p>The Azure ML retraining API is designed to handle the workflow you describe:<\/p>\n\n<p><a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-retrain-models-programmatically\/\" rel=\"nofollow\">http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-retrain-models-programmatically\/<\/a><\/p>\n\n<p>Hope this helps,<\/p>\n\n<p>Roope - Microsoft Azure ML Team<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1425426748316,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":1424286272932,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/28590690",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  app - complete experince - train automatically and consume; content:<p>i played a bit around with  studio. so as i understand the process goes like this:<\/p>\n\n<p>a) create training experiment. train it with data. <\/p>\n\n<p>b) create scoring experiment. this will include the trained model from the training experiment. expose this as a service to be consumed over rest.<\/p>\n\n<p>maybe a stupid question but what is the recommended way to get the complete experience like the one i get when i use an app like <a href=\"https:\/\/datamarket.azure.com\/dataset\/amla\/mba\" rel=\"nofollow\">https:\/\/datamarket.azure.com\/dataset\/amla\/mba<\/a> (frequently bought together api built with ). <\/p>\n\n<p>i mean the following:<\/p>\n\n<p>a) expose 2 or more services - one to train the model and the other to consume (test) the trained model. <\/p>\n\n<p>b) user periodically sends training data to train the model <\/p>\n\n<p>c) the trained model\/models now gets saved available for consumption<\/p>\n\n<p>d) user is now able to send a dataframe to get the predicted results.<\/p>\n\n<p>is there an additional wrapper that needs to be built?<\/p>\n\n<p>if there is a link documenting this please point me to the same. <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to automatically train and consume an Azure ML app, and wants to know if there is an additional wrapper that needs to be built."
    },
    {
        "Question_id":null,
        "Question_title":"MLflow 1.21.0 released!",
        "Question_body":"We are happy to announce the availability of\u00a0MLflow\u00a01.21.0!\n\n\n\nMLflow 1.21.0 includes several major features and improvements:\n\nFeatures:\n\n[UI] Add a diff-only toggle to the runs table for filtering out columns with constant values (#4862,\u00a0@marijncv)\n[UI] Add a duration column to the runs table (#4840,\u00a0@marijncv)\n[UI] Display the default column sorting order in the runs table (#4847,\u00a0@marijncv)\n[UI] Add\u00a0start_time\u00a0and\u00a0duration\u00a0information to exported runs CSV (#4851,\u00a0@marijncv)\n[UI] Add lifecycle stage information to the run page (#4848,\u00a0@marijncv)\n[UI] Collapse run page sections by default for space efficiency, limit artifact previews to 50MB (#4917,\u00a0@dbczumar)\n[Tracking] Introduce autologging capabilities for PaddlePaddle model training (#4751,\u00a0@jinminhao)\n[Tracking] Add an optional tags field to the CreateExperiment API (#4788,\u00a0@dbczumar;\u00a0#4795,\u00a0@apurva-koti)\n[Tracking] Add support for deleting artifacts from SFTP stores via the\u00a0mlflow gc\u00a0CLI (#4670,\u00a0@afaul)\n[Tracking] Support AzureDefaultCredential for authenticating with Azure artifact storage backends (#4002,\u00a0@marijncv)\n[Models] Upgrade the fastai model flavor to support fastai V2 (>=2.4.1) (#4715,\u00a0@jinzhang21)\n[Models] Introduce an\u00a0mlflow.prophet\u00a0model flavor for Prophet time series models (#4773,\u00a0@BenWilson2)\n[Models] Introduce a CLI for publishing MLflow Models to the SageMaker Model Registry (#4669,\u00a0@jinnig)\n[Models] Print a warning when inferred model dependencies are not available on PyPI (#4891,\u00a0@dbczumar)\n[Models, Projects] Add\u00a0MLFLOW_CONDA_CREATE_ENV_CMD\u00a0for customizing Conda environment creation (#4746,\u00a0@giacomov)\n\nBug fixes and documentation updates:\n\n[UI] Fix an issue where column selections made in the runs table were persisted across experiments (#4926,\u00a0@sunishsheth2009)\n[UI] Fix an issue where the text\u00a0null\u00a0was displayed in the runs table column ordering dropdown (#4924,\u00a0@harupy)\n[UI] Fix a bug causing the metric plot view to display NaN values upon click (#4858,\u00a0@arpitjasa-db)\n[Tracking] Fix a model load failure for paths containing spaces or special characters on UNIX systems (#4890,\u00a0@BenWilson2)\n[Tracking] Correct a migration issue that impacted usage of MLflow Tracking with SQL Server (#4880,\u00a0@marijncv)\n[Tracking] Spark datasource autologging tags now respect the maximum allowable size for MLflow Tracking (#4809,\u00a0@dbczumar)\n[Model Registry] Add previously-missing certificate sources for Model Registry REST API requests (#4731,\u00a0@ericgosno91)\n[Model Registry] Throw an exception when users supply invalid Model Registry URIs for Databricks (#4877,\u00a0@yunpark93)\n[Scoring] Fix a schema enforcement error that incorrectly cast date-like strings to datetime objects (#4902,\u00a0@wentinghu)\n[Docs] Expand the documentation for the MLflow Skinny Client (#4113,\u00a0@eedeleon)\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1635184341000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":19.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/CSKBY9hL2bo",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-25T17:57:35",
                "Answer_body":"Version 1.21.0 of the MLflow R package has not yet been released. It will be available on CRAN within the next week.\n\ue5d3"
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  1.21.0 released!; content:we are happy to announce the availability of\u00a0\u00a01.21.0!\n\n\n\n 1.21.0 includes several major features and improvements:\n\nfeatures:\n\n[ui] add a diff-only toggle to the runs table for filtering out columns with constant values (#4862,\u00a0@marijncv)\n[ui] add a duration column to the runs table (#4840,\u00a0@marijncv)\n[ui] display the default column sorting order in the runs table (#4847,\u00a0@marijncv)\n[ui] add\u00a0start_time\u00a0and\u00a0duration\u00a0information to exported runs csv (#4851,\u00a0@marijncv)\n[ui] add lifecycle stage information to the run page (#4848,\u00a0@marijncv)\n[ui] collapse run page sections by default for space efficiency, limit artifact previews to 50mb (#4917,\u00a0@dbczumar)\n[tracking] introduce autologging capabilities for paddlepaddle model training (#4751,\u00a0@jinminhao)\n[tracking] add an optional tags field to the createexperiment api (#4788,\u00a0@dbczumar;\u00a0#4795,\u00a0@apurva-koti)\n[tracking] add support for deleting artifacts from sftp stores via the\u00a0 gc\u00a0cli (#4670,\u00a0@afaul)\n[tracking] support azuredefaultcredential for authenticating with azure artifact storage backends (#4002,\u00a0@marijncv)\n[models] upgrade the fastai model flavor to support fastai v2 (>=2.4.1) (#4715,\u00a0@jinzhang21)\n[models] introduce an\u00a0.prophet\u00a0model flavor for prophet time series models (#4773,\u00a0@benwilson2)\n[models] introduce a cli for publishing  models to the sagemaker model registry (#4669,\u00a0@jinnig)\n[models] print a warning when inferred model dependencies are not available on pypi (#4891,\u00a0@dbczumar)\n[models, projects] add\u00a0_conda_create_env_cmd\u00a0for customizing conda environment creation (#4746,\u00a0@giacomov)\n\nbug fixes and documentation updates:\n\n[ui] fix an issue where column selections made in the runs table were persisted across experiments (#4926,\u00a0@sunishsheth2009)\n[ui] fix an issue where the text\u00a0null\u00a0was displayed in the runs table column ordering dropdown (#4924,\u00a0@harupy)\n[ui] fix a bug causing the metric plot view to display nan values upon click (#4858,\u00a0@arpitjasa-db)\n[tracking] fix a model load failure for paths containing spaces or special characters on unix systems (#4890,\u00a0@benwilson2)\n[tracking] correct a migration issue that impacted usage of  tracking with sql server (#4880,\u00a0@marijncv)\n[tracking] spark datasource autologging tags now respect the maximum allowable size for  tracking (#4809,\u00a0@dbczumar)\n[model registry] add previously-missing certificate sources for model registry rest api requests (#4731,\u00a0@ericgosno91)\n[model registry] throw an exception when users supply invalid model registry uris for databricks (#4877,\u00a0@yunpark93)\n[scoring] fix a schema enforcement error that incorrectly cast date-like strings to datetime objects (#4902,\u00a0@wentinghu)\n[docs] expand the documentation for the  skinny client (#4113,\u00a0@eedeleon)\nfor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0.org.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user can expect 1.21.0 to include several major features and improvements, such as UI updates, autologging capabilities, model registry support, and bug fixes."
    },
    {
        "Question_id":61377643.0,
        "Question_title":"Tracking SageMaker Estimator with MLFlow",
        "Question_body":"<p>I'm working on a version tracking system for a ML project and want to use MLflow to do so. My project uses AWS Sagemaker's DeepAR for forecast.<\/p>\n\n<p>What I want to do is very simple. I'm trying do log the Sagemaker DeepAR model (Sagemaker Estimator) with MLFlow. As it doesn't have a \"log_model\" funcion in it's \"mlflow.sagemaker\" module, I tried to use the \"mlflow.pyfunc\" module to do the log. Unfortunatelly it didn't worked. How can I log the Sagemaker model and get the cloudpickle and yaml files generated by MLFlow?<\/p>\n\n<p>My code for now:<\/p>\n\n<p><code>mlflow.pyfunc.log_model(model)<\/code><\/p>\n\n<p>Where model is a sagemaker.estimator.Estimator object and the error I get from the code is<\/p>\n\n<p><code>mlflow.exceptions.MlflowException: Either `loader_module` or `python_model` must be specified. A `loader_module` should be a python module. A `python_model` should be a subclass of PythonModel<\/code><\/p>\n\n<p>I know AWS Sagemaker logs my models, but it is really important to my project to do the log with MLFlow too.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1587603987047,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "amazon-sagemaker",
            "mlflow"
        ],
        "Question_view_count":437.0,
        "Owner_creation_time":1548023586667,
        "Owner_last_access_time":1663509557783,
        "Owner_reputation":111.0,
        "Owner_up_votes":22.0,
        "Owner_down_votes":0.0,
        "Owner_views":41.0,
        "Answer_body":"<p>You cannot use pyfunc to store Any type object.<\/p>\n\n<p>You should either specify one of loader_module as shown in the example below or you must write the wrapper that implements PythonModel interface and provides logic to deserialize your model from  previously-stored artifacts as described here \n <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#example-saving-an-xgboost-model-in-mlflow-format\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/models.html#example-saving-an-xgboost-model-in-mlflow-format<\/a><\/p>\n\n<p>example with loader:<\/p>\n\n<pre><code>    model_uri = 'model.pkl'\n\n    with open(model_uri, 'wb') as f:\n        pickle.dump(model, f)\n\n    mlflow.log_artifact(model_uri, 'model')\n\n    mlflow.pyfunc.log_model(\n        'model', loader_module='mlflow.sklearn', data_path='model.pkl', code_path=['src'], conda_env='environment.yml'\n    )\n<\/code><\/pre>\n\n<p>I think PythonModel is the better way for you because of mlflow doesn't have a built-in loader for SageMaker DeepAR model.<\/p>\n\n<p>Nonetheless, You must have the knowledge how to restore SageMaker model from artifacts, because I am not sure that is possible at all, cuz of some built-in SageMaker algorithms are blackboxes.<\/p>\n\n<p>You can also may be interested in container that allow you to run any MLFlow projects inside Sagemaker: <a href=\"https:\/\/github.com\/odahu\/sagemaker-mlflow-container\" rel=\"nofollow noreferrer\">https:\/\/github.com\/odahu\/sagemaker-mlflow-container<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1587720289803,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":1587605439876,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61377643",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: tracking  estimator with mlflow; content:<p>i'm working on a version tracking system for a ml project and want to use mlflow to do so. my project uses 's deepar for forecast.<\/p>\n\n<p>what i want to do is very simple. i'm trying do log the  deepar model ( estimator) with mlflow. as it doesn't have a \"log_model\" funcion in it's \"mlflow.\" module, i tried to use the \"mlflow.pyfunc\" module to do the log. unfortunatelly it didn't worked. how can i log the  model and get the cloudpickle and yaml files generated by mlflow?<\/p>\n\n<p>my code for now:<\/p>\n\n<p><code>mlflow.pyfunc.log_model(model)<\/code><\/p>\n\n<p>where model is a .estimator.estimator object and the error i get from the code is<\/p>\n\n<p><code>mlflow.exceptions.mlflowexception: either `loader_module` or `python_model` must be specified. a `loader_module` should be a python module. a `python_model` should be a subclass of pythonmodel<\/code><\/p>\n\n<p>i know  logs my models, but it is really important to my project to do the log with mlflow too.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to log a DeepAR estimator model with MLflow, but is receiving an error when using the MLflow.pyfunc.log_model() function."
    },
    {
        "Question_id":null,
        "Question_title":"Azure Machine Learning with on premise SQL Server",
        "Question_body":"Hi is there a way for Azure Machine Learning to be able to perform analytics using data from an on premise SQL Server?\n\nOnly found the below article which is for Azure Machine Learning Studio (classic):\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\n\nThanks.",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1592874857830,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38894\/azure-machine-learning-with-on-premise-sql-server-1.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-23T08:17:48.573Z",
                "Answer_score":1,
                "Answer_body":"@conrad Here is the link to connect with the Azure SQL server.\nhttps:\/\/stackoverflow.com\/questions\/61806350\/database-communication-link-error-occurded-on-azure-ml-service-used-azure-sql-s\/61950481#61950481",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-06-25T18:27:33.377Z",
                "Answer_score":0,
                "Answer_body":"Light Servi\u00e7os de Eletricidade",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  with on premise sql server; content:hi is there a way for  to be able to perform analytics using data from an on premise sql server?\n\nonly found the below article which is for  studio (classic):\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\n\nthanks.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to perform analytics using data from an on premise SQL Server and has found an article for Azure Machine Learning Studio (classic) that may be helpful."
    },
    {
        "Question_id":null,
        "Question_title":"Is there a way to have the logs from a polyaxon run viewable via the cloud UI?",
        "Question_body":"From slack\n\nIs there some way we could save the output logs to have them be accessible?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1649327817000,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[

        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1470",
        "Tool":"Polyaxon",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T10:37:50Z",
                "Answer_score":1,
                "Answer_body":"That's not possible I am afraid. Logs, as well as other artifacts, are only viewable via the gateway deployed with the agent.\n\nIn order to provide such option, Polyaxon will have to have access to the artifacts store, but I do not think that we want to provide such functionality at the moment since logs also can include sensitive information."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":-1.0,
        "Question_original_content_preprocessed_text":"title: is there a way to have the logs from a  run viewable via the cloud ui?; content:from slack\n\nis there some way we could save the output logs to have them be accessible?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if there is a way to view logs from a run via the cloud UI, and if there is a way to save the output logs to make them accessible."
    },
    {
        "Question_id":53962146.0,
        "Question_title":"Configure Training job using Ground Truth and BlazingText in Amazon Sagemaker",
        "Question_body":"<p>I'm trying to configure a Training-Job with BlazingText algorithm in Amazon Sagemaker using its console. I have an manifest file as follows:<\/p>\n\n<pre><code>{\"source\":\"Text1\",\"GroundtruthTryVideo\":2,\"GroundtruthTryVideo-metadata\": \n{\"confidence\":0.66,\"job-name\":\"labeling-job\/groundtruthtryvideo\",\"class-name\":\"TrackingToProspecting\",\"human-annotated\":\"yes\",\"creation-date\":\"2018-12-27T00:37:23.894062\",\"type\":\"groundtruth\/text-classification\"}}\n{\"source\":\"Text2\",\"GroundtruthTryVideo\":1,\"GroundtruthTryVideo-metadata\": \n{\"confidence\":0.66,\"job-name\":\"labeling-job\/groundtruthtryvideo\",\"class-name\":\"FirstDateProspecting\",\"human-annotated\":\"yes\",\"creation-date\":\"2018-12-27T00:37:23.894043\",\"type\":\"groundtruth\/text-classification\"}}\n{\"source\":\"Text3\",\"GroundtruthTryVideo\":1,\"GroundtruthTryVideo-metadata\": \n{\"confidence\":0.9,\"job-name\":\"labeling-job\/groundtruthtryvideo\",\"class-name\":\"FirstDateProspecting\",\"human-annotated\":\"yes\",\"creation-date\":\"2018-12-27T00:38:26.377216\",\"type\":\"groundtruth\/text-classification\"}}\n<\/code><\/pre>\n\n<p>When I try to create the trainingjob using this manifest, I get Always troubles with the result, my configurations are:<\/p>\n\n<p>Algorithm source: <\/p>\n\n<p>Amazon SageMaker built-in algorithm (BlazingText)<\/p>\n\n<p>Channels: <\/p>\n\n<ul>\n<li>S3 data type: ManifestFile<\/li>\n<li>S3 data distribution type: FullyReplicated<\/li>\n<li>S3 location: Path to ManifestFile (In S3 Bucket)<\/li>\n<\/ul>\n\n<p>I've tried to use <code>augmentedManifestFile<\/code> and <code>Pipe<\/code> as input mode instead of <code>ManifestFile<\/code> and <code>File<\/code> input but I have the same result, I can't complete the training job successfully.<\/p>\n\n<p>Could anybody help me in configuring correctly the console? Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_creation_time":1546017939947,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-sagemaker"
        ],
        "Question_view_count":724.0,
        "Owner_creation_time":1546016759727,
        "Owner_last_access_time":1548895678928,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1546045197776,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53962146",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: configure training job using ground truth and blazingtext in ; content:<p>i'm trying to configure a training-job with blazingtext algorithm in  using its console. i have an manifest file as follows:<\/p>\n\n<pre><code>{\"source\":\"text1\",\"groundtruthtryvideo\":2,\"groundtruthtryvideo-metadata\": \n{\"confidence\":0.66,\"job-name\":\"labeling-job\/groundtruthtryvideo\",\"class-name\":\"trackingtoprospecting\",\"human-annotated\":\"yes\",\"creation-date\":\"2018-12-27t00:37:23.894062\",\"type\":\"groundtruth\/text-classification\"}}\n{\"source\":\"text2\",\"groundtruthtryvideo\":1,\"groundtruthtryvideo-metadata\": \n{\"confidence\":0.66,\"job-name\":\"labeling-job\/groundtruthtryvideo\",\"class-name\":\"firstdateprospecting\",\"human-annotated\":\"yes\",\"creation-date\":\"2018-12-27t00:37:23.894043\",\"type\":\"groundtruth\/text-classification\"}}\n{\"source\":\"text3\",\"groundtruthtryvideo\":1,\"groundtruthtryvideo-metadata\": \n{\"confidence\":0.9,\"job-name\":\"labeling-job\/groundtruthtryvideo\",\"class-name\":\"firstdateprospecting\",\"human-annotated\":\"yes\",\"creation-date\":\"2018-12-27t00:38:26.377216\",\"type\":\"groundtruth\/text-classification\"}}\n<\/code><\/pre>\n\n<p>when i try to create the trainingjob using this manifest, i get always troubles with the result, my configurations are:<\/p>\n\n<p>algorithm source: <\/p>\n\n<p> built-in algorithm (blazingtext)<\/p>\n\n<p>channels: <\/p>\n\n<ul>\n<li>s3 data type: manifestfile<\/li>\n<li>s3 data distribution type: fullyreplicated<\/li>\n<li>s3 location: path to manifestfile (in s3 bucket)<\/li>\n<\/ul>\n\n<p>i've tried to use <code>augmentedmanifestfile<\/code> and <code>pipe<\/code> as input mode instead of <code>manifestfile<\/code> and <code>file<\/code> input but i have the same result, i can't complete the training job successfully.<\/p>\n\n<p>could anybody help me in configuring correctly the console? thanks.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to configure a training job using BlazingText algorithm and a manifest file, but is having trouble completing the job successfully."
    },
    {
        "Question_id":70754016.0,
        "Question_title":"Creating a Vertex AI Workbench with a Non Organization Account and problems with constraints\/compute.vmExternalIpAccess",
        "Question_body":"<p>I'm trying to create a Vertex AI Workbench on GCP, but every time I try I get the following error:<\/p>\n<p><em>&lt;Workbench Name&gt; Constraint constraints\/compute.vmExternalIpAccess violated for project &lt;Project ID&gt;. Add instance &lt;Workbench ID&gt; to the constraint to use external IP with it.<\/em><\/p>\n<p>I went to the Organization Policies page to edit the constraint: <em>constraints\/compute.vmExternalIpAccess<\/em> and saw that is denied for all (which is odd because in the <a href=\"https:\/\/cloud.google.com\/resource-manager\/docs\/organization-policy\/org-policy-constraints\" rel=\"nofollow noreferrer\">constraints documentation<\/a> it says that is should be enabled for all by default). Now, the problem is that when I go to edit the constraint, it says that it requires this set of permissions:<\/p>\n<ul>\n<li><em>orgpolicy.policies.create<\/em><\/li>\n<li><em>orgpolicy.policies.delete<\/em><\/li>\n<li><em>orgpolicy.policies.update<\/em><\/li>\n<li><em>orgpolicy.policy.get<\/em><\/li>\n<\/ul>\n<p>which are all part of the role: <em>roles\/orgpolicy.policyAdmin<\/em> that can only be granted at an organization level, and well, I have a Non Organization Account.<\/p>\n<p>Am I missing something?<\/p>\n<p>Thank for your time!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_creation_time":1642501704547,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "google-cloud-platform",
            "workbench",
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":333.0,
        "Owner_creation_time":1353379904267,
        "Owner_last_access_time":1653505313252,
        "Owner_reputation":215.0,
        "Owner_up_votes":15.0,
        "Owner_down_votes":0.0,
        "Owner_views":30.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70754016",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: creating a  workbench with a non organization account and problems with constraints\/compute.vmexternalipaccess; content:<p>i'm trying to create a  workbench on gcp, but every time i try i get the following error:<\/p>\n<p><em>&lt;workbench name&gt; constraint constraints\/compute.vmexternalipaccess violated for project &lt;project id&gt;. add instance &lt;workbench id&gt; to the constraint to use external ip with it.<\/em><\/p>\n<p>i went to the organization policies page to edit the constraint: <em>constraints\/compute.vmexternalipaccess<\/em> and saw that is denied for all (which is odd because in the <a href=\"https:\/\/cloud.google.com\/resource-manager\/docs\/organization-policy\/org-policy-constraints\" rel=\"nofollow noreferrer\">constraints documentation<\/a> it says that is should be enabled for all by default). now, the problem is that when i go to edit the constraint, it says that it requires this set of permissions:<\/p>\n<ul>\n<li><em>orgpolicy.policies.create<\/em><\/li>\n<li><em>orgpolicy.policies.delete<\/em><\/li>\n<li><em>orgpolicy.policies.update<\/em><\/li>\n<li><em>orgpolicy.policy.get<\/em><\/li>\n<\/ul>\n<p>which are all part of the role: <em>roles\/orgpolicy.policyadmin<\/em> that can only be granted at an organization level, and well, i have a non organization account.<\/p>\n<p>am i missing something?<\/p>\n<p>thank for your time!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to create a workbench on GCP but is receiving an error due to a constraint that is denied for all, and they do not have the permissions to edit the constraint as they have a non organization account."
    },
    {
        "Question_id":null,
        "Question_title":"Debugging the Execute Python Scripts model in Azure\u2013ML: Where can I find the print statements?",
        "Question_body":"Hi,\n\nI am using Azure Machine Learning \u2013 Designer (drag-n-drop) \u2013\u00a0to train an ML model. While doing so, I require to execute some Python code & hence decided to use the Execute Python Script module available.\n\nWhile writing the script, I added print statements because it would allow for easier debugging. However, I have had no luck in finding a file where the print statements are stored.\n\nI have tried the following solution. On failure of the script, this method (opening 70_driver_log.txt and searching for messages) only shows me the error returned by the Python Interpreter, but it doesn't show me any print statements at all. For example:\n\nSimilarly, on success, no print statements are displayed.\n\nAdditionally, logs > azureml > stdoutlogs .txt is completely empty.\n\nWhat clue am I missing? Any help is appreciated!",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1621349529943,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/399653\/debugging-the-execute-python-scripts-model-in-azur.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: debugging the execute python scripts model in azure\u2013ml: where can i find the print statements?; content:hi,\n\ni am using  \u2013 designer (drag-n-drop) \u2013\u00a0to train an ml model. while doing so, i require to execute some python code & hence decided to use the execute python script module available.\n\nwhile writing the script, i added print statements because it would allow for easier debugging. however, i have had no luck in finding a file where the print statements are stored.\n\ni have tried the following solution. on failure of the script, this method (opening 70_driver_log.txt and searching for messages) only shows me the error returned by the python interpreter, but it doesn't show me any print statements at all. for example:\n\nsimilarly, on success, no print statements are displayed.\n\nadditionally, logs >  > stdoutlogs .txt is completely empty.\n\nwhat clue am i missing? any help is appreciated!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to debug an Azure ML model by using print statements, but is unable to find the file where the print statements are stored."
    },
    {
        "Question_id":72365934.0,
        "Question_title":"Running mlflow ui in AWS Sagemaker",
        "Question_body":"<p>I want to run mlflow UI in sagemaker but it simply does not work, When it outputs the http address going to it results in a &quot;this site cannot be reached&quot;<\/p>\n<p>Here is the code:<\/p>\n<pre><code>def mlflow_test(server_uri, experiment_name):\n    mlflow.set_tracking_uri(server_uri)\n    mlflow.set_experiment(experiment_name)\n    with mlflow.start_run():\n        params = {\n            &quot;n-estimators&quot;: 100,\n            &quot;min-samples-leaf&quot;: 10,\n            &quot;features&quot;: 'feature_test'\n        }\n        mlflow.log_params(params)\n        mlflow.log_metric('foo', 5)\n        mlflow.end_run()\n<\/code><\/pre>\n<p>running that code will return:<\/p>\n<pre><code>[2022-05-24 15:48:44 +0000] [27820] [INFO] Starting gunicorn 20.1.0\n[2022-05-24 15:48:44 +0000] [27820] [INFO] Listening at: http:\/\/127.0.0.1:5000 (27820)\n[2022-05-24 15:48:44 +0000] [27820] [INFO] Using worker: sync\n[2022-05-24 15:48:44 +0000] [27823] [INFO] Booting worker with pid: 27823\n<\/code><\/pre>\n<p>Going to the <a href=\"http:\/\/127.0.0.1:5000\" rel=\"nofollow noreferrer\">http:\/\/127.0.0.1:5000<\/a> link won't work. Anyone know how to get mlflow ui running in sagemaker? There's not much info on this that's at an easy to understand level. I just want to log my metrics and params in sagemaker and view them using the mlflow ui<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1653407649377,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "amazon-sagemaker",
            "mlflow"
        ],
        "Question_view_count":93.0,
        "Owner_creation_time":1615994492347,
        "Owner_last_access_time":1657796021116,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":12.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72365934",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: running mlflow ui in ; content:<p>i want to run mlflow ui in  but it simply does not work, when it outputs the http address going to it results in a &quot;this site cannot be reached&quot;<\/p>\n<p>here is the code:<\/p>\n<pre><code>def mlflow_test(server_uri, experiment_name):\n    mlflow.set_tracking_uri(server_uri)\n    mlflow.set_experiment(experiment_name)\n    with mlflow.start_run():\n        params = {\n            &quot;n-estimators&quot;: 100,\n            &quot;min-samples-leaf&quot;: 10,\n            &quot;features&quot;: 'feature_test'\n        }\n        mlflow.log_params(params)\n        mlflow.log_metric('foo', 5)\n        mlflow.end_run()\n<\/code><\/pre>\n<p>running that code will return:<\/p>\n<pre><code>[2022-05-24 15:48:44 +0000] [27820] [info] starting gunicorn 20.1.0\n[2022-05-24 15:48:44 +0000] [27820] [info] listening at: http:\/\/127.0.0.1:5000 (27820)\n[2022-05-24 15:48:44 +0000] [27820] [info] using worker: sync\n[2022-05-24 15:48:44 +0000] [27823] [info] booting worker with pid: 27823\n<\/code><\/pre>\n<p>going to the <a href=\"http:\/\/127.0.0.1:5000\" rel=\"nofollow noreferrer\">http:\/\/127.0.0.1:5000<\/a> link won't work. anyone know how to get mlflow ui running in ? there's not much info on this that's at an easy to understand level. i just want to log my metrics and params in  and view them using the mlflow ui<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to run the MLflow UI in but is unable to access it, as the link provided results in a \"this site cannot be reached\" error."
    },
    {
        "Question_id":70968460.0,
        "Question_title":"ModelUploadOp step failing with custom prediction container",
        "Question_body":"<p>I am currenlty trying to deploy a Vertex pipeline to achieve the following:<\/p>\n<ol>\n<li><p>Train a custom model (from a custom training python package) and dump model artifacts (trained model and data preprocessor that will be sed at prediction time). This is step is working fine as I can see new resources being created in the storage bucket.<\/p>\n<\/li>\n<li><p>Create a model resource via <code>ModelUploadOp<\/code>. This step fails for some reason when specifying <code>serving_container_environment_variables<\/code> and <code>serving_container_ports<\/code> with the error message in the <strong>errors<\/strong> section below. This is somewhat surprising as they are both needed by the prediction container and environment variables are passed as a dict as specified in the documentation.<br \/>\nThis step works just fine using <code>gcloud<\/code> commands:<\/p>\n<\/li>\n<\/ol>\n<pre class=\"lang-sh prettyprint-override\"><code>gcloud ai models upload \\\n    --region us-west1 \\\n    --display-name session_model_latest \\\n    --container-image-uri gcr.io\/and-reporting\/pred:latest \\\n    --container-env-vars=&quot;MODEL_BUCKET=ml_session_model&quot; \\\n    --container-health-route=\/\/health \\\n    --container-predict-route=\/\/predict \\\n    --container-ports=5000\n<\/code><\/pre>\n<ol start=\"3\">\n<li>Create an endpoint.<\/li>\n<li>Deploy the model to the endpoint.<\/li>\n<\/ol>\n<p>There is clearly something that I am getting wrong with Vertex, the components <a href=\"https:\/\/google-cloud-pipeline-components.readthedocs.io\/en\/google-cloud-pipeline-components-0.2.2\/index.html\" rel=\"nofollow noreferrer\">documentation<\/a> doesn't help much in this case.<\/p>\n<h2>Pipeline<\/h2>\n<pre class=\"lang-py prettyprint-override\"><code>from datetime import datetime\n\nimport kfp\nfrom google.cloud import aiplatform\nfrom google_cloud_pipeline_components import aiplatform as gcc_aip\nfrom kfp.v2 import compiler\n\nPIPELINE_ROOT = &quot;gs:\/\/ml_model_bucket\/pipeline_root&quot;\n\n\n@kfp.dsl.pipeline(name=&quot;session-train-deploy&quot;, pipeline_root=PIPELINE_ROOT)\ndef pipeline():\n    training_op = gcc_aip.CustomPythonPackageTrainingJobRunOp(\n        project=&quot;my-project&quot;,\n        location=&quot;us-west1&quot;,\n        display_name=&quot;train_session_model&quot;,\n        model_display_name=&quot;session_model&quot;,\n        service_account=&quot;name@my-project.iam.gserviceaccount.com&quot;,\n        environment_variables={&quot;MODEL_BUCKET&quot;: &quot;ml_session_model&quot;},\n        python_module_name=&quot;trainer.train&quot;,\n        staging_bucket=&quot;gs:\/\/ml_model_bucket\/&quot;,\n        base_output_dir=&quot;gs:\/\/ml_model_bucket\/&quot;,\n        args=[\n            &quot;--gcs-data-path&quot;,\n            &quot;gs:\/\/ml_model_data\/2019-Oct_short.csv&quot;,\n            &quot;--gcs-model-path&quot;,\n            &quot;gs:\/\/ml_model_bucket\/model\/model.joblib&quot;,\n            &quot;--gcs-preproc-path&quot;,\n            &quot;gs:\/\/ml_model_bucket\/model\/preproc.pkl&quot;,\n        ],\n        container_uri=&quot;us-docker.pkg.dev\/vertex-ai\/training\/scikit-learn-cpu.0-23:latest&quot;,\n        python_package_gcs_uri=&quot;gs:\/\/ml_model_bucket\/trainer-0.0.1.tar.gz&quot;,\n        model_serving_container_image_uri=&quot;gcr.io\/my-project\/pred&quot;,\n        model_serving_container_predict_route=&quot;\/predict&quot;,\n        model_serving_container_health_route=&quot;\/health&quot;,\n        model_serving_container_ports=[5000],\n        model_serving_container_environment_variables={\n            &quot;MODEL_BUCKET&quot;: &quot;ml_model_bucket\/model&quot;\n        },\n    )\n\n    model_upload_op = gcc_aip.ModelUploadOp(\n        project=&quot;and-reporting&quot;,\n        location=&quot;us-west1&quot;,\n        display_name=&quot;session_model&quot;,\n        serving_container_image_uri=&quot;gcr.io\/my-project\/pred:latest&quot;,\n        # When passing the following 2 arguments this step fails...\n        serving_container_environment_variables={&quot;MODEL_BUCKET&quot;: &quot;ml_model_bucket\/model&quot;},\n        serving_container_ports=[5000],\n        serving_container_predict_route=&quot;\/predict&quot;,\n        serving_container_health_route=&quot;\/health&quot;,\n    )\n    model_upload_op.after(training_op)\n\n    endpoint_create_op = gcc_aip.EndpointCreateOp(\n        project=&quot;my-project&quot;,\n        location=&quot;us-west1&quot;,\n        display_name=&quot;pipeline_endpoint&quot;,\n    )\n\n    model_deploy_op = gcc_aip.ModelDeployOp(\n        model=model_upload_op.outputs[&quot;model&quot;],\n        endpoint=endpoint_create_op.outputs[&quot;endpoint&quot;],\n        deployed_model_display_name=&quot;session_model&quot;,\n        traffic_split={&quot;0&quot;: 100},\n        service_account=&quot;name@my-project.iam.gserviceaccount.com&quot;,\n    )\n    model_deploy_op.after(endpoint_create_op)\n\n\nif __name__ == &quot;__main__&quot;:\n    ts = datetime.now().strftime(&quot;%Y%m%d%H%M%S&quot;)\n    compiler.Compiler().compile(pipeline, &quot;custom_train_pipeline.json&quot;)\n    pipeline_job = aiplatform.PipelineJob(\n        display_name=&quot;session_train_and_deploy&quot;,\n        template_path=&quot;custom_train_pipeline.json&quot;,\n        job_id=f&quot;session-custom-pipeline-{ts}&quot;,\n        enable_caching=True,\n    )\n    pipeline_job.submit()\n\n<\/code><\/pre>\n<h3>Errors and notes<\/h3>\n<ol>\n<li>When specifying <code>serving_container_environment_variables<\/code> and <code>serving_container_ports<\/code> the step fails with the following error:<\/li>\n<\/ol>\n<pre><code>{'code': 400, 'message': 'Invalid JSON payload received. Unknown name &quot;MODEL_BUCKET&quot; at \\'model.container_spec.env[0]\\': Cannot find field.\\nInvalid value at \\'model.container_spec.ports[0]\\' (type.googleapis.com\/google.cloud.aiplatform.v1.Port), 5000', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com\/google.rpc.BadRequest', 'fieldViolations': [{'field': 'model.container_spec.env[0]', 'description': 'Invalid JSON payload received. Unknown name &quot;MODEL_BUCKET&quot; at \\'model.container_spec.env[0]\\': Cannot find field.'}, {'field': 'model.container_spec.ports[0]', 'description': &quot;Invalid value at 'model.container_spec.ports[0]' (type.googleapis.com\/google.cloud.aiplatform.v1.Port), 5000&quot;}]}]}\n<\/code><\/pre>\n<p>When commenting out <code>serving_container_environment_variables<\/code> and <code>serving_container_ports<\/code>  the model resource gets created but deploying it manually to the endpoint results into a failed deployment with no output logs.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1643879294320,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "google-cloud-ml",
            "kubeflow-pipelines",
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":273.0,
        "Owner_creation_time":1512301540763,
        "Owner_last_access_time":1663934781440,
        "Owner_reputation":1427.0,
        "Owner_up_votes":93.0,
        "Owner_down_votes":16.0,
        "Owner_views":113.0,
        "Answer_body":"<p>After some time researching the problem I've stumbled upon <a href=\"https:\/\/github.com\/kubeflow\/pipelines\/issues\/6848\" rel=\"nofollow noreferrer\">this<\/a> Github issue. The problem was originated by a mismatch between <a href=\"https:\/\/google-cloud-pipeline-components.readthedocs.io\/en\/google-cloud-pipeline-components-0.2.2\/index.html\" rel=\"nofollow noreferrer\"><code>google_cloud_pipeline_components<\/code><\/a> and <a href=\"https:\/\/kubernetes.io\/docs\/reference\/generated\/kubernetes-api\/v1.19\/#envvar-v1-core\" rel=\"nofollow noreferrer\"><code>kubernetes_api<\/code><\/a> docs. In this case, <code>serving_container_environment_variables<\/code> is typed as an <code>Optional[dict[str, str]]<\/code> whereas it should have been typed as a <code>Optional[list[dict[str, str]]]<\/code>. A similar mismatch can be found for <code>serving_container_ports<\/code> argument as well. Passing arguments following kubernetes documentation did the trick:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>model_upload_op = gcc_aip.ModelUploadOp(\n    project=&quot;my-project&quot;,\n    location=&quot;us-west1&quot;,\n    display_name=&quot;session_model&quot;,\n    serving_container_image_uri=&quot;gcr.io\/my-project\/pred:latest&quot;,\n    serving_container_environment_variables=[\n        {&quot;name&quot;: &quot;MODEL_BUCKET&quot;, &quot;value&quot;: &quot;ml_session_model&quot;}\n    ],\n    serving_container_ports=[{&quot;containerPort&quot;: 5000}],\n    serving_container_predict_route=&quot;\/predict&quot;,\n    serving_container_health_route=&quot;\/health&quot;,\n)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1643965835692,
        "Answer_score":1.0,
        "Owner_location":"Milan, Italy",
        "Question_last_edit_time":1644239389000,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70968460",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: modeluploadop step failing with custom prediction container; content:<p>i am currenlty trying to deploy a vertex pipeline to achieve the following:<\/p>\n<ol>\n<li><p>train a custom model (from a custom training python package) and dump model artifacts (trained model and data preprocessor that will be sed at prediction time). this is step is working fine as i can see new resources being created in the storage bucket.<\/p>\n<\/li>\n<li><p>create a model resource via <code>modeluploadop<\/code>. this step fails for some reason when specifying <code>serving_container_environment_variables<\/code> and <code>serving_container_ports<\/code> with the error message in the <strong>errors<\/strong> section below. this is somewhat surprising as they are both needed by the prediction container and environment variables are passed as a dict as specified in the documentation.<br \/>\nthis step works just fine using <code>gcloud<\/code> commands:<\/p>\n<\/li>\n<\/ol>\n<pre class=\"lang-sh prettyprint-override\"><code>gcloud ai models upload \\\n    --region us-west1 \\\n    --display-name session_model_latest \\\n    --container-image-uri gcr.io\/and-reporting\/pred:latest \\\n    --container-env-vars=&quot;model_bucket=ml_session_model&quot; \\\n    --container-health-route=\/\/health \\\n    --container-predict-route=\/\/predict \\\n    --container-ports=5000\n<\/code><\/pre>\n<ol start=\"3\">\n<li>create an endpoint.<\/li>\n<li>deploy the model to the endpoint.<\/li>\n<\/ol>\n<p>there is clearly something that i am getting wrong with vertex, the components <a href=\"https:\/\/google-cloud-pipeline-components.readthedocs.io\/en\/google-cloud-pipeline-components-0.2.2\/index.html\" rel=\"nofollow noreferrer\">documentation<\/a> doesn't help much in this case.<\/p>\n<h2>pipeline<\/h2>\n<pre class=\"lang-py prettyprint-override\"><code>from datetime import datetime\n\nimport kfp\nfrom google.cloud import aiplatform\nfrom google_cloud_pipeline_components import aiplatform as gcc_aip\nfrom kfp.v2 import compiler\n\npipeline_root = &quot;gs:\/\/ml_model_bucket\/pipeline_root&quot;\n\n\n@kfp.dsl.pipeline(name=&quot;session-train-deploy&quot;, pipeline_root=pipeline_root)\ndef pipeline():\n    training_op = gcc_aip.custompythonpackagetrainingjobrunop(\n        project=&quot;my-project&quot;,\n        location=&quot;us-west1&quot;,\n        display_name=&quot;train_session_model&quot;,\n        model_display_name=&quot;session_model&quot;,\n        service_account=&quot;name@my-project.iam.gserviceaccount.com&quot;,\n        environment_variables={&quot;model_bucket&quot;: &quot;ml_session_model&quot;},\n        python_module_name=&quot;trainer.train&quot;,\n        staging_bucket=&quot;gs:\/\/ml_model_bucket\/&quot;,\n        base_output_dir=&quot;gs:\/\/ml_model_bucket\/&quot;,\n        args=[\n            &quot;--gcs-data-path&quot;,\n            &quot;gs:\/\/ml_model_data\/2019-oct_short.csv&quot;,\n            &quot;--gcs-model-path&quot;,\n            &quot;gs:\/\/ml_model_bucket\/model\/model.joblib&quot;,\n            &quot;--gcs-preproc-path&quot;,\n            &quot;gs:\/\/ml_model_bucket\/model\/preproc.pkl&quot;,\n        ],\n        container_uri=&quot;us-docker.pkg.dev\/vertex-ai\/training\/scikit-learn-cpu.0-23:latest&quot;,\n        python_package_gcs_uri=&quot;gs:\/\/ml_model_bucket\/trainer-0.0.1.tar.gz&quot;,\n        model_serving_container_image_uri=&quot;gcr.io\/my-project\/pred&quot;,\n        model_serving_container_predict_route=&quot;\/predict&quot;,\n        model_serving_container_health_route=&quot;\/health&quot;,\n        model_serving_container_ports=[5000],\n        model_serving_container_environment_variables={\n            &quot;model_bucket&quot;: &quot;ml_model_bucket\/model&quot;\n        },\n    )\n\n    model_upload_op = gcc_aip.modeluploadop(\n        project=&quot;and-reporting&quot;,\n        location=&quot;us-west1&quot;,\n        display_name=&quot;session_model&quot;,\n        serving_container_image_uri=&quot;gcr.io\/my-project\/pred:latest&quot;,\n        # when passing the following 2 arguments this step fails...\n        serving_container_environment_variables={&quot;model_bucket&quot;: &quot;ml_model_bucket\/model&quot;},\n        serving_container_ports=[5000],\n        serving_container_predict_route=&quot;\/predict&quot;,\n        serving_container_health_route=&quot;\/health&quot;,\n    )\n    model_upload_op.after(training_op)\n\n    endpoint_create_op = gcc_aip.endpointcreateop(\n        project=&quot;my-project&quot;,\n        location=&quot;us-west1&quot;,\n        display_name=&quot;pipeline_endpoint&quot;,\n    )\n\n    model_deploy_op = gcc_aip.modeldeployop(\n        model=model_upload_op.outputs[&quot;model&quot;],\n        endpoint=endpoint_create_op.outputs[&quot;endpoint&quot;],\n        deployed_model_display_name=&quot;session_model&quot;,\n        traffic_split={&quot;0&quot;: 100},\n        service_account=&quot;name@my-project.iam.gserviceaccount.com&quot;,\n    )\n    model_deploy_op.after(endpoint_create_op)\n\n\nif __name__ == &quot;__main__&quot;:\n    ts = datetime.now().strftime(&quot;%y%m%d%h%m%s&quot;)\n    compiler.compiler().compile(pipeline, &quot;custom_train_pipeline.json&quot;)\n    pipeline_job = aiplatform.pipelinejob(\n        display_name=&quot;session_train_and_deploy&quot;,\n        template_path=&quot;custom_train_pipeline.json&quot;,\n        job_id=f&quot;session-custom-pipeline-{ts}&quot;,\n        enable_caching=true,\n    )\n    pipeline_job.submit()\n\n<\/code><\/pre>\n<h3>errors and notes<\/h3>\n<ol>\n<li>when specifying <code>serving_container_environment_variables<\/code> and <code>serving_container_ports<\/code> the step fails with the following error:<\/li>\n<\/ol>\n<pre><code>{'code': 400, 'message': 'invalid json payload received. unknown name &quot;model_bucket&quot; at \\'model.container_spec.env[0]\\': cannot find field.\\ninvalid value at \\'model.container_spec.ports[0]\\' (type.googleapis.com\/google.cloud.aiplatform.v1.port), 5000', 'status': 'invalid_argument', 'details': [{'@type': 'type.googleapis.com\/google.rpc.badrequest', 'fieldviolations': [{'field': 'model.container_spec.env[0]', 'description': 'invalid json payload received. unknown name &quot;model_bucket&quot; at \\'model.container_spec.env[0]\\': cannot find field.'}, {'field': 'model.container_spec.ports[0]', 'description': &quot;invalid value at 'model.container_spec.ports[0]' (type.googleapis.com\/google.cloud.aiplatform.v1.port), 5000&quot;}]}]}\n<\/code><\/pre>\n<p>when commenting out <code>serving_container_environment_variables<\/code> and <code>serving_container_ports<\/code>  the model resource gets created but deploying it manually to the endpoint results into a failed deployment with no output logs.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having issues with the modeluploadop step failing when specifying serving_container_environment_variables and serving_container_ports, and when commenting them out the model resource is created but the deployment fails with no output logs."
    },
    {
        "Question_id":66656120.0,
        "Question_title":"SageMaker TF 2.3 distributed training",
        "Question_body":"<p>Using SageMaker v2.29.2 and Tensorflow v2.3.2 I'm trying to implement distributed training as explained in the following blogpost:<\/p>\n<p><a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-parallel-customize-training-script-tf.html#model-parallel-customize-training-script-tf-23\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/model-parallel-customize-training-script-tf.html#model-parallel-customize-training-script-tf-23<\/a><\/p>\n<p>However I'm having difficulties importing the smdistributed script.<\/p>\n<p>Here is my code:<\/p>\n<pre><code>import tensorflow as tf\nimport smdistributed.modelparallel.tensorflow as smp\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;temp.py&quot;, line 2, in &lt;module&gt;\n    import smdistributed.modelparallel.tensorflow as smp\nModuleNotFoundError: No module named 'smdistributed'\n<\/code><\/pre>\n<p>What am I missing?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1615901050403,
        "Question_favorite_count":1.0,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "tensorflow",
            "amazon-sagemaker"
        ],
        "Question_view_count":383.0,
        "Owner_creation_time":1324808381143,
        "Owner_last_access_time":1663842092260,
        "Owner_reputation":9050.0,
        "Owner_up_votes":1458.0,
        "Owner_down_votes":21.0,
        "Owner_views":1750.0,
        "Answer_body":"<p>smdistributed is only available on the SageMaker containers. It is supported for specific TensorFlow versions and you must add:<\/p>\n<pre><code>distribution={'smdistributed': {\n            'dataparallel': {\n                'enabled': True\n            }\n        }}\n<\/code><\/pre>\n<p>On the estimator code in order to enable it<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1623834809928,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1615921589292,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66656120",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  tf 2.3 distributed training; content:<p>using  v2.29.2 and tensorflow v2.3.2 i'm trying to implement distributed training as explained in the following blogpost:<\/p>\n<p><a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/model-parallel-customize-training-script-tf.html#model-parallel-customize-training-script-tf-23\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/\/latest\/dg\/model-parallel-customize-training-script-tf.html#model-parallel-customize-training-script-tf-23<\/a><\/p>\n<p>however i'm having difficulties importing the smdistributed script.<\/p>\n<p>here is my code:<\/p>\n<pre><code>import tensorflow as tf\nimport smdistributed.modelparallel.tensorflow as smp\n<\/code><\/pre>\n<p>error:<\/p>\n<pre><code>traceback (most recent call last):\n  file &quot;temp.py&quot;, line 2, in &lt;module&gt;\n    import smdistributed.modelparallel.tensorflow as smp\nmodulenotfounderror: no module named 'smdistributed'\n<\/code><\/pre>\n<p>what am i missing?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to implement distributed training using TensorFlow v2.3.2, but is having difficulty importing the smdistributed script and is receiving a ModuleNotFoundError."
    },
    {
        "Question_id":null,
        "Question_title":"Can you give me an example of a draw with Infer.net",
        "Question_body":"On the web\u201c https:\/\/docs.microsoft.com\/en-au\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net \u201dFor Infer.net Probability programming example of. In this example, there are only wins or losses, no draws. Can you give me an example of a draw, which can be used in the machine learning of E-sports Bo 2 or football, thank you",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1593357487593,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40647\/can-you-give-me-an-example-of-a-draw-with-infernet.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-29T12:48:42.093Z",
                "Answer_score":1,
                "Answer_body":"The Chess Analysis example in the Infer.NET documentation includes draws.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: can you give me an example of a draw with infer.net; content:on the web\u201c https:\/\/docs.microsoft.com\/en-au\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net \u201dfor infer.net probability programming example of. in this example, there are only wins or losses, no draws. can you give me an example of a draw, which can be used in the machine learning of e-sports bo 2 or football, thank you",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for an example of a draw with Infer.Net, specifically one that can be used in the machine learning of e-sports or football."
    },
    {
        "Question_id":69859398.0,
        "Question_title":"Azure ML Studio Designer - Is it possible to copy pipeline or pipeline drafts from one workspace to another?",
        "Question_body":"<p>Is it possible to export or copy Pipelines created in Azure ML Studio <em>Designer<\/em> from one Workspace to another, using the UI, python sdk, and\/or azure CLI?  If so, how?<\/p>\n<p>EDIT:  My Designer does not appear to have the 'Export To Code' option that DeepDave-MT shows below.  How do I enable this ability?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/xhpCf.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/xhpCf.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1636147488900,
        "Question_favorite_count":null,
        "Question_score":3.0,
        "Question_tags":[
            "azure-machine-learning-studio",
            "azureml-python-sdk",
            "azuremlsdk"
        ],
        "Question_view_count":267.0,
        "Owner_creation_time":1340833876128,
        "Owner_last_access_time":1663795160110,
        "Owner_reputation":751.0,
        "Owner_up_votes":68.0,
        "Owner_down_votes":5.0,
        "Owner_views":73.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1636474855252,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69859398",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  studio designer - is it possible to copy pipeline or pipeline drafts from one workspace to another?; content:<p>is it possible to export or copy pipelines created in  studio <em>designer<\/em> from one workspace to another, using the ui, python sdk, and\/or azure cli?  if so, how?<\/p>\n<p>edit:  my designer does not appear to have the 'export to code' option that deepdave-mt shows below.  how do i enable this ability?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/xhpcf.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/xhpcf.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to know if it is possible to export or copy pipelines created in Azure ML Studio Designer from one workspace to another, using the UI, Python SDK, and\/or Azure CLI, and how to enable the 'export to code' option."
    },
    {
        "Question_id":null,
        "Question_title":"Cannot open a terminal in compute instances",
        "Question_body":"I am trying to complete the learning exercises in the Microsoft Learning module \"Explore and analyze data with Python\" with a trial subscription to Azure. In any compute instances that I start, I cannot connect to the terminal and get the error \"Invalid terminal: Unable connect to terminal, please close the tab and restart your current compute and retry Trace ID : 5b4a5ee5-c5cf-4f66-b054-71a81417bdbc \". I have tried restarting the instance, in addition to deleting the VM and starting a new instance but still encounter the same error which happens in both Edge and Chrome browsers. Is there something that I am missing in connecting to the terminal in these notebooks?",
        "Question_answer_count":3,
        "Question_comment_count":4.0,
        "Question_creation_time":1615232316253,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/304418\/cannot-open-a-terminal-in-compute-instances.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-09T10:39:16.61Z",
                "Answer_score":0,
                "Answer_body":"@GeoffreyMoxley-0007 Thanks for the question. Can you please add more details about the VM(type, size) that you are trying. We are able to create the terminal without any error.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-16T18:12:31.17Z",
                "Answer_score":0,
                "Answer_body":"I'm having the same issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-30T18:36:06.157Z",
                "Answer_score":0,
                "Answer_body":"I'm having the same issue. I've started & stopped my compute instance several times as well as created a new compute instance from scratch.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: cannot open a terminal in compute instances; content:i am trying to complete the learning exercises in the microsoft learning module \"explore and analyze data with python\" with a trial subscription to azure. in any compute instances that i start, i cannot connect to the terminal and get the error \"invalid terminal: unable connect to terminal, please close the tab and restart your current compute and retry trace id : 5b4a5ee5-c5cf-4f66-b054-71a81417bdbc \". i have tried restarting the instance, in addition to deleting the vm and starting a new instance but still encounter the same error which happens in both edge and chrome browsers. is there something that i am missing in connecting to the terminal in these notebooks?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to open a terminal in compute instances and is receiving an error when trying to connect. They have tried restarting the instance and deleting the VM, but still encounter the same error."
    },
    {
        "Question_id":70429857.0,
        "Question_title":"seems like GPU is not working in AWS Sagemaker Studio Lab",
        "Question_body":"<p>I've selected compute type as GPU, and opened my project.<\/p>\n<p>but checking the local devices, it doesn't look like any GPU is deployed.<\/p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()\n<\/code><\/pre>\n<p>outputs:<\/p>\n<pre><code>[name: &quot;\/device:CPU:0&quot;\n device_type: &quot;CPU&quot;\n memory_limit: 268435456\n locality {\n }\n incarnation: 13079107644747151451]\n<\/code><\/pre>\n<p>How can I enable GPU usage in AWS Sagemaker?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1640051584293,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "tensorflow",
            "gpu",
            "amazon-sagemaker"
        ],
        "Question_view_count":459.0,
        "Owner_creation_time":1640051180483,
        "Owner_last_access_time":1663300671900,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70429857",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: seems like gpu is not working in  studio lab; content:<p>i've selected compute type as gpu, and opened my project.<\/p>\n<p>but checking the local devices, it doesn't look like any gpu is deployed.<\/p>\n<pre><code>import tensorflow as tf\nfrom tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()\n<\/code><\/pre>\n<p>outputs:<\/p>\n<pre><code>[name: &quot;\/device:cpu:0&quot;\n device_type: &quot;cpu&quot;\n memory_limit: 268435456\n locality {\n }\n incarnation: 13079107644747151451]\n<\/code><\/pre>\n<p>how can i enable gpu usage in ?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having trouble getting their GPU to work in AWS Studio Lab, as it doesn't appear to be deployed when they run a script to list local devices."
    },
    {
        "Question_id":51430151.0,
        "Question_title":"Create AWS sagemaker endpoint and delete the same using AWS lambda",
        "Question_body":"<p>Is there a way to create sagemaker endpoint using AWS lambda ?<\/p>\n\n<p>The maximum timeout limit for lambda is 300 seconds while my existing model takes 5-6 mins to host ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1532027138877,
        "Question_favorite_count":1.0,
        "Question_score":3.0,
        "Question_tags":[
            "amazon-web-services",
            "aws-lambda",
            "amazon-sagemaker"
        ],
        "Question_view_count":1559.0,
        "Owner_creation_time":1532026905327,
        "Owner_last_access_time":1532763060590,
        "Owner_reputation":31.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Navi Mumbai, Maharashtra, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51430151",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: create  endpoint and delete the same using aws lambda; content:<p>is there a way to create  endpoint using aws lambda ?<\/p>\n\n<p>the maximum timeout limit for lambda is 300 seconds while my existing model takes 5-6 mins to host ?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if they can create an endpoint using AWS Lambda, and if the maximum timeout limit of 300 seconds is sufficient for their existing model which takes 5-6 minutes to host."
    },
    {
        "Question_id":71033276.0,
        "Question_title":"Vertex AI forecasting AutoML giving different answers for same input data",
        "Question_body":"<p>I trained Vertex AI forecasting AutoML model one with target column as String and other numeric input features as String then I trained another AutoML model with target column as float and other input features as Integer.<\/p>\n<p>The predictions are different for both the models. The data is same only the datatypes\/schema changed.<\/p>\n<p>Google <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/datasets\/data-types-tabular#forecasting\" rel=\"nofollow noreferrer\">documentation<\/a> says:<\/p>\n<blockquote>\n<p>When you train a model with a feature with a numeric transformation,\nVertex AI applies the following data transformations to the feature,\nand uses any that provide signal for training:<\/p>\n<ul>\n<li>The value converted to float32.<\/li>\n<\/ul>\n<\/blockquote>\n<p>So both the data should be same even after transformation.\nWhy would results be different? Is it possible?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1644320416577,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "google-cloud-platform",
            "forecasting",
            "google-cloud-automl",
            "automl",
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":197.0,
        "Owner_creation_time":1450288149287,
        "Owner_last_access_time":1661168365350,
        "Owner_reputation":500.0,
        "Owner_up_votes":14.0,
        "Owner_down_votes":0.0,
        "Owner_views":72.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1644580300387,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71033276",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  forecasting automl giving different answers for same input data; content:<p>i trained  forecasting automl model one with target column as string and other numeric input features as string then i trained another automl model with target column as float and other input features as integer.<\/p>\n<p>the predictions are different for both the models. the data is same only the datatypes\/schema changed.<\/p>\n<p>google <a href=\"https:\/\/cloud.google.com\/vertex-ai\/docs\/datasets\/data-types-tabular#forecasting\" rel=\"nofollow noreferrer\">documentation<\/a> says:<\/p>\n<blockquote>\n<p>when you train a model with a feature with a numeric transformation,\n applies the following data transformations to the feature,\nand uses any that provide signal for training:<\/p>\n<ul>\n<li>the value converted to float32.<\/li>\n<\/ul>\n<\/blockquote>\n<p>so both the data should be same even after transformation.\nwhy would results be different? is it possible?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user trained two forecasting automl models with different data types and found that the predictions were different, despite the data being the same."
    },
    {
        "Question_id":56513409.0,
        "Question_title":"Connecting sagemaker using java sdk",
        "Question_body":"<p>Can anyone tell me how to connect to sagemaker using aws java sdk and invoke a endpoint which is arleady created using jupyter notebook?<\/p>\n\n<p>Link -<a href=\"https:\/\/docs.aws.amazon.com\/AWSJavaSDK\/latest\/javadoc\/com\/amazonaws\/services\/sagemaker\/AmazonSageMaker.html#createNotebookInstance-com.amazonaws.services.sagemaker.model.CreateNotebookInstanceRequest-\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/AWSJavaSDK\/latest\/javadoc\/com\/amazonaws\/services\/sagemaker\/AmazonSageMaker.html#createNotebookInstance-com.amazonaws.services.sagemaker.model.CreateNotebookInstanceRequest-<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1560072156127,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-sagemaker"
        ],
        "Question_view_count":1112.0,
        "Owner_creation_time":1539596007860,
        "Owner_last_access_time":1663854904627,
        "Owner_reputation":33.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":39.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56513409",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: connecting  using java sdk; content:<p>can anyone tell me how to connect to  using aws java sdk and invoke a endpoint which is arleady created using jupyter notebook?<\/p>\n\n<p>link -<a href=\"https:\/\/docs.aws.amazon.com\/awsjavasdk\/latest\/javadoc\/com\/amazonaws\/services\/\/amazon.html#createnotebookinstance-com.amazonaws.services..model.createnotebookinstancerequest-\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/awsjavasdk\/latest\/javadoc\/com\/amazonaws\/services\/\/amazon.html#createnotebookinstance-com.amazonaws.services..model.createnotebookinstancerequest-<\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking how to connect to using AWS Java SDK and invoke an endpoint created using Jupyter Notebook."
    },
    {
        "Question_id":null,
        "Question_title":"Lighting: Checkpoints silently fail to save",
        "Question_body":"<p>Every couple of hours I silently get this error during training then checkpoints silently fail to save from then on. I\u2019ve now lost &gt;30 hrs of training because of this weird issue. Does anyone know what\u2019s causing this and how to fix it?<\/p>\n<p>for future searchers:<br>\n<code>NVMLError_OperatingSystem: The operating system has blocked the request.<\/code><\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/40594953988cd414c66052042a88418ba4eda5a4.jpeg\" data-download-href=\"\/uploads\/short-url\/9bfQUuHL4Ek3Qjo5EjzA1z8ucRK.jpeg?dl=1\" title=\"IMG_0367\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40594953988cd414c66052042a88418ba4eda5a4_2_690x497.jpeg\" alt=\"IMG_0367\" data-base62-sha1=\"9bfQUuHL4Ek3Qjo5EjzA1z8ucRK\" width=\"690\" height=\"497\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40594953988cd414c66052042a88418ba4eda5a4_2_690x497.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40594953988cd414c66052042a88418ba4eda5a4_2_1035x745.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/40594953988cd414c66052042a88418ba4eda5a4.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/40594953988cd414c66052042a88418ba4eda5a4_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">IMG_0367<\/span><span class=\"informations\">1284\u00d7925 205 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_creation_time":1662073802656,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":52.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/lighting-checkpoints-silently-fail-to-save\/3048",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":7254,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-09-07T15:25:10.995Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/zaptrem\">@zaptrem<\/a> thank you for reporting this. We will need a bit more context here on your setup both hardware and environments. Is this a WSL terminal? there might be some issues with NVML and WSL.<br>\nAlso wanted to clarify, did it not log anything from epoch 1876 to 2392? would you be interested in running the experiments in offline mode and write the data to your disk and sync to W&amp;B afterwards?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-09-07T15:25:10.995Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":5.6,
                "yours":false,
                "topic_id":3048,
                "topic_slug":"lighting-checkpoints-silently-fail-to-save",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7318,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-09-12T17:36:47.447Z",
                "cooked":"<p>Hey <a class=\"mention\" href=\"\/u\/zaptrem\">@zaptrem<\/a> I wanted to follow up with you regarding this issue, could you provide some more information asked above to help debug this? Please let me know if I can be of further assistance or if your issue has been resolved.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-09-12T17:36:47.447Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":5.6,
                "yours":false,
                "topic_id":3048,
                "topic_slug":"lighting-checkpoints-silently-fail-to-save",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"thanos-wandb",
                    "name":"Thanos Vitsas",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7402,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-09-16T11:39:46.460Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/zaptrem\">@zaptrem<\/a> as we haven\u2019t heard back from you, we are going to close the ticket for now. Please feel free to message us here if the issue hasn\u2019t been resolved for you, and we will be happy to keep investigating!<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-09-16T11:39:46.460Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":3048,
                "topic_slug":"lighting-checkpoints-silently-fail-to-save",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"thanos-wandb",
                    "name":"Thanos Vitsas",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":8129,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-11-15T11:40:13.660Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":5,
                "post_type":3,
                "updated_at":"2022-11-15T11:40:13.660Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":3048,
                "topic_slug":"lighting-checkpoints-silently-fail-to-save",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: lighting: checkpoints silently fail to save; content:<p>every couple of hours i silently get this error during training then checkpoints silently fail to save from then on. i\u2019ve now lost &gt;30 hrs of training because of this weird issue. does anyone know what\u2019s causing this and how to fix it?<\/p>\n<p>for future searchers:<br>\n<code>nvmlerror_operatingsystem: the operating system has blocked the request.<\/code><\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/1x\/40594953988cd414c66052042a88418ba4eda5a4.jpeg\" data-download-href=\"\/uploads\/short-url\/9bfquuhl4ek3qjo5ejza1z8ucrk.jpeg?dl=1\" title=\"img_0367\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/40594953988cd414c66052042a88418ba4eda5a4_2_690x497.jpeg\" alt=\"img_0367\" data-base62-sha1=\"9bfquuhl4ek3qjo5ejza1z8ucrk\" width=\"690\" height=\"497\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/40594953988cd414c66052042a88418ba4eda5a4_2_690x497.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/40594953988cd414c66052042a88418ba4eda5a4_2_1035x745.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/1x\/40594953988cd414c66052042a88418ba4eda5a4.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/40594953988cd414c66052042a88418ba4eda5a4_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">img_0367<\/span><span class=\"informations\">1284\u00d7925 205 kb<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an issue where checkpoints silently fail to save every couple of hours and has lost more than 30 hours of training due to this issue. The error code is \"nvmlerror_operatingsystem: the operating system has blocked the request.\""
    },
    {
        "Question_id":64655227.0,
        "Question_title":"How to build and install dlib for python without GUI support?",
        "Question_body":"<h3>Background:<\/h3>\n<p>I'm running a \u200d<code>jupyter\u200d<\/code> notebook on an AWS <code>sagemaker<\/code> ec2 instance (Which uses Fedora Linux) and one of my requirements is <code>dlib<\/code>.\nHowever, <code>dlib<\/code> (by default) uses <code>xorg's x11<\/code> libs for GUI support, and these are not installed on the <code>sagemaker<\/code> instance. I do not need the GUI support, and <code>sagemaker<\/code> does not support yum installs, so I'm trying to build it without them.<\/p>\n<p>I've cloned <code>dlib<\/code>'s github repo and have attempted to build with <code>python setup.py<\/code>, where it throws x11 errors. I've read through the website and it says that <a href=\"http:\/\/dlib.net\/compile.html\" rel=\"nofollow noreferrer\">you can define the <code>DLIB_NO_GUI_SUPPORT<\/code> preprocessor directive to compile without GUI support<\/a>. Sounds great! I read through the setup.py file and see that I can add that by running <code>python setup.py x DLIB_NO_GUI_SUPPORT<\/code> where <code>x<\/code> is one of [<code>--no<\/code>, <code>--set<\/code>, <code>--compiler-flags<\/code>, and <code>-G<\/code>].\nI don't know which one, so I try them all:<\/p>\n<ul>\n<li><code>python setup.py --no DLIB_NO_GUI_SUPPORT<\/code><\/li>\n<li><code>python setup.py --set DLIB_NO_GUI_SUPPORT<\/code><\/li>\n<li><code>python setup.py --compiler-flags DLIB_NO_GUI_SUPPORT<\/code><\/li>\n<li><code>python setup.py -G DLIB_NO_GUI_SUPPORT<\/code><\/li>\n<\/ul>\n<p>None of them worked.<\/p>\n<h3>Question:<\/h3>\n<p>What is the correct syntax for setting the <code>DLIB_NO_GUI_SUPPORT<\/code> preprocessor directive for <code>dlib<\/code> using <code>setup.py<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1604363957200,
        "Question_favorite_count":null,
        "Question_score":4.0,
        "Question_tags":[
            "python",
            "setup.py",
            "amazon-sagemaker",
            "dlib"
        ],
        "Question_view_count":365.0,
        "Owner_creation_time":1504661789123,
        "Owner_last_access_time":1654611055688,
        "Owner_reputation":41.0,
        "Owner_up_votes":2.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"KY, United States",
        "Question_last_edit_time":1604439687207,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64655227",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to build and install dlib for python without gui support?; content:<h3>background:<\/h3>\n<p>i'm running a \u200d<code>jupyter\u200d<\/code> notebook on an aws <code><\/code> ec2 instance (which uses fedora linux) and one of my requirements is <code>dlib<\/code>.\nhowever, <code>dlib<\/code> (by default) uses <code>xorg's x11<\/code> libs for gui support, and these are not installed on the <code><\/code> instance. i do not need the gui support, and <code><\/code> does not support yum installs, so i'm trying to build it without them.<\/p>\n<p>i've cloned <code>dlib<\/code>'s github repo and have attempted to build with <code>python setup.py<\/code>, where it throws x11 errors. i've read through the website and it says that <a href=\"http:\/\/dlib.net\/compile.html\" rel=\"nofollow noreferrer\">you can define the <code>dlib_no_gui_support<\/code> preprocessor directive to compile without gui support<\/a>. sounds great! i read through the setup.py file and see that i can add that by running <code>python setup.py x dlib_no_gui_support<\/code> where <code>x<\/code> is one of [<code>--no<\/code>, <code>--set<\/code>, <code>--compiler-flags<\/code>, and <code>-g<\/code>].\ni don't know which one, so i try them all:<\/p>\n<ul>\n<li><code>python setup.py --no dlib_no_gui_support<\/code><\/li>\n<li><code>python setup.py --set dlib_no_gui_support<\/code><\/li>\n<li><code>python setup.py --compiler-flags dlib_no_gui_support<\/code><\/li>\n<li><code>python setup.py -g dlib_no_gui_support<\/code><\/li>\n<\/ul>\n<p>none of them worked.<\/p>\n<h3>question:<\/h3>\n<p>what is the correct syntax for setting the <code>dlib_no_gui_support<\/code> preprocessor directive for <code>dlib<\/code> using <code>setup.py<\/code>?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to build and install dlib for python without gui support on an AWS EC2 instance, and is attempting to use the preprocessor directive dlib_no_gui_support with setup.py, but is unsure of the correct syntax."
    },
    {
        "Question_id":30396392.0,
        "Question_title":"Azure Machine Learning Prediction - Input and Outputs",
        "Question_body":"<p>I am attempting to follow this <a href=\"http:\/\/www.toptal.com\/machine-learning\/predicting-gas-prices-using-azure-machine-learning-studio\" rel=\"nofollow\">tutorial<\/a> however I was attempting to predict MPG for a set of cars rather than oil prices and have the following set up:<\/p>\n\n<ol>\n<li>MPG Sample dataset<\/li>\n<li>Remove missing values, project everything (weight, displacement, cylinders, etc) except model name<\/li>\n<li>Split 75 to train model, 25 to score model<\/li>\n<li>Train model on MPG column with neural network<\/li>\n<li>Score model which is fed by Train Model and Split<\/li>\n<li>Score model is fed to Evaluate model<\/li>\n<\/ol>\n\n<p>This all seems to run fine and without issue, so I create a scoring experiment and then publish it as a web service, however when I attempt to input values it is asking for an MPG input. My understanding is that this would be the predicted value, so it seems somewhat opposite to have to enter this as a value, or am I just understanding a basic tenet of machine learning? <\/p>\n\n<p>In short: Ideally I would like to be able to enter everything but the MPG and get a prediction on what the MPG is for a given set of value.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1432296670560,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure",
            "machine-learning",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":1527.0,
        "Owner_creation_time":1352816892227,
        "Owner_last_access_time":1662863190947,
        "Owner_reputation":2054.0,
        "Owner_up_votes":1029.0,
        "Owner_down_votes":99.0,
        "Owner_views":260.0,
        "Answer_body":"<p>You could also add project columns to exclude label as part of scoring experiment and connect web service output port to the output of project columns<\/p>",
        "Answer_comment_count":8.0,
        "Answer_creation_time":1432778316968,
        "Answer_score":2.0,
        "Owner_location":"United States",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30396392",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  prediction - input and outputs; content:<p>i am attempting to follow this <a href=\"http:\/\/www.toptal.com\/machine-learning\/predicting-gas-prices-using-azure-machine-learning-studio\" rel=\"nofollow\">tutorial<\/a> however i was attempting to predict mpg for a set of cars rather than oil prices and have the following set up:<\/p>\n\n<ol>\n<li>mpg sample dataset<\/li>\n<li>remove missing values, project everything (weight, displacement, cylinders, etc) except model name<\/li>\n<li>split 75 to train model, 25 to score model<\/li>\n<li>train model on mpg column with neural network<\/li>\n<li>score model which is fed by train model and split<\/li>\n<li>score model is fed to evaluate model<\/li>\n<\/ol>\n\n<p>this all seems to run fine and without issue, so i create a scoring experiment and then publish it as a web service, however when i attempt to input values it is asking for an mpg input. my understanding is that this would be the predicted value, so it seems somewhat opposite to have to enter this as a value, or am i just understanding a basic tenet of machine learning? <\/p>\n\n<p>in short: ideally i would like to be able to enter everything but the mpg and get a prediction on what the mpg is for a given set of value.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is attempting to use a tutorial to predict MPG for a set of cars, but is having difficulty understanding why they need to input an MPG value when publishing the web service. They would like to be able to enter all values except MPG and get a prediction."
    },
    {
        "Question_id":63469762.0,
        "Question_title":"Weights&Biases Sweep Keras K-Fold Validation",
        "Question_body":"<p>I'm using Weights&amp;Biases Cloud-based sweeps with Keras.\nSo first i create a new Sweep within a W&amp;B Project with a config like following:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>description: LSTM Model\nmethod: random\nmetric:\n  goal: maximize\n  name: val_accuracy\nname: LSTM-Sweep\nparameters:\n  batch_size:\n    distribution: int_uniform\n    max: 128\n    min: 32\n  epochs:\n    distribution: constant\n    value: 200\n  node_size1:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  node_size2:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  node_size3:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  node_size4:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  node_size5:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  num_layers:\n    distribution: categorical\n    values:\n    - 1\n    - 2\n    - 3\n  optimizer:\n    distribution: categorical\n    values:\n    - Adam\n    - Adamax\n    - Adagrad\n  path:\n    distribution: constant\n    value: &quot;.\/path\/to\/data\/&quot;\nprogram: sweep.py\nproject: SLR\n<\/code><\/pre>\n<p>My <code>sweep.py<\/code> file looks something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># imports\ninit = wandb.init(project=&quot;my-project&quot;, reinit=True)\nconfig = wandb.config\n\ndef main():\n    skfold = StratifiedKFold(n_splits=5, \n    shuffle=True, random_state=7)\n    cvscores = []\n    group_id = wandb.util.generate_id()\n    X,y = # load data\n    i = 0\n    for train, test in skfold.split(X,y):\n        i=i+1\n        run = wandb.init(group=group_id, reinit=True, name=group_id+&quot;#&quot;+str(i))\n        model = # build model\n        model.fit([...], WandBCallback())\n        cvscores.append([...])\n        wandb.join()\n\nif __name__ == &quot;__main__&quot;:\n    main()\n<\/code><\/pre>\n<p>Starting this with the <code>wandb agent<\/code> command within the folder of <code>sweep.py<\/code>.<\/p>\n<p>What i experienced with this setup is, that with the first wandb.init() call a new run is initialized. Okay, i could just remove that. But when calling wandb.init() for the second time it seems to lose track of the sweep it is running in. Online an empty run is listed in the sweep (because of the first wandb.init() call), all other runs are listed inside the project, but not in the sweep.<\/p>\n<p>My goal is to have a run for each fold of the k-Fold cross-validation. At least i thought this would be the right way of doing this.\nIs there a different approach to combine sweeps with keras k-fold cross validation?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1597757510213,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "keras",
            "k-fold",
            "wandb"
        ],
        "Question_view_count":1043.0,
        "Owner_creation_time":1486549300030,
        "Owner_last_access_time":1620240688720,
        "Owner_reputation":45.0,
        "Owner_up_votes":4.0,
        "Owner_down_votes":0.0,
        "Owner_views":13.0,
        "Answer_body":"<p>We put together an example of how to accomplish k-fold cross validation:<\/p>\n<p><a href=\"https:\/\/github.com\/wandb\/examples\/tree\/master\/examples\/wandb-sweeps\/sweeps-cross-validation\" rel=\"nofollow noreferrer\">https:\/\/github.com\/wandb\/examples\/tree\/master\/examples\/wandb-sweeps\/sweeps-cross-validation<\/a><\/p>\n<p>The solution requires some contortions for the wandb library to spawn multiple jobs on behalf of a launched sweep job.<\/p>\n<p>The basic idea is:<\/p>\n<ul>\n<li>The agent requests a new set of parameters from the cloud hosted parameter server.  This is the run called <code>sweep_run<\/code> in the main function.<\/li>\n<li>Send information about what the folds should process over a multiprocessing queue to waiting processes<\/li>\n<li>Each spawned process logs to their own run, organized with group and job_type to enable auto-grouping in the UI<\/li>\n<li>When the process is finished, it sends the primary metric over a queue to the parent sweep run<\/li>\n<li>The sweep run reads metrics from the child runs and logs it to the sweep run so that the sweep can use that result to impact future parameter choices and\/or hyperband early termination optimizations<\/li>\n<\/ul>\n<p>Example visualizations of the sweep and k-fold grouping can be seen here:<\/p>\n<ul>\n<li>Sweep: <a href=\"https:\/\/app.wandb.ai\/jeffr\/examples-sweeps-cross-validation\/sweeps\/vp0fsvku\" rel=\"nofollow noreferrer\">https:\/\/app.wandb.ai\/jeffr\/examples-sweeps-cross-validation\/sweeps\/vp0fsvku<\/a><\/li>\n<li>K-fold Grouping: <a href=\"https:\/\/app.wandb.ai\/jeffr\/examples-sweeps-cross-validation\/groups\/vp0fsvku\" rel=\"nofollow noreferrer\">https:\/\/app.wandb.ai\/jeffr\/examples-sweeps-cross-validation\/groups\/vp0fsvku<\/a><\/li>\n<\/ul>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1598032113043,
        "Answer_score":6.0,
        "Owner_location":"Germany",
        "Question_last_edit_time":1661849871016,
        "Answer_last_edit_time":1599772735680,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63469762",
        "Tool":"Weights & Biases",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: weights&biases sweep keras k-fold validation; content:<p>i'm using weights&amp;biases cloud-based sweeps with keras.\nso first i create a new sweep within a w&amp;b project with a config like following:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>description: lstm model\nmethod: random\nmetric:\n  goal: maximize\n  name: val_accuracy\nname: lstm-sweep\nparameters:\n  batch_size:\n    distribution: int_uniform\n    max: 128\n    min: 32\n  epochs:\n    distribution: constant\n    value: 200\n  node_size1:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  node_size2:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  node_size3:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  node_size4:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  node_size5:\n    distribution: categorical\n    values:\n    - 64\n    - 128\n    - 256\n  num_layers:\n    distribution: categorical\n    values:\n    - 1\n    - 2\n    - 3\n  optimizer:\n    distribution: categorical\n    values:\n    - adam\n    - adamax\n    - adagrad\n  path:\n    distribution: constant\n    value: &quot;.\/path\/to\/data\/&quot;\nprogram: sweep.py\nproject: slr\n<\/code><\/pre>\n<p>my <code>sweep.py<\/code> file looks something like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># imports\ninit = .init(project=&quot;my-project&quot;, reinit=true)\nconfig = .config\n\ndef main():\n    skfold = stratifiedkfold(n_splits=5, \n    shuffle=true, random_state=7)\n    cvscores = []\n    group_id = .util.generate_id()\n    x,y = # load data\n    i = 0\n    for train, test in skfold.split(x,y):\n        i=i+1\n        run = .init(group=group_id, reinit=true, name=group_id+&quot;#&quot;+str(i))\n        model = # build model\n        model.fit([...], callback())\n        cvscores.append([...])\n        .join()\n\nif __name__ == &quot;__main__&quot;:\n    main()\n<\/code><\/pre>\n<p>starting this with the <code> agent<\/code> command within the folder of <code>sweep.py<\/code>.<\/p>\n<p>what i experienced with this setup is, that with the first .init() call a new run is initialized. okay, i could just remove that. but when calling .init() for the second time it seems to lose track of the sweep it is running in. online an empty run is listed in the sweep (because of the first .init() call), all other runs are listed inside the project, but not in the sweep.<\/p>\n<p>my goal is to have a run for each fold of the k-fold cross-validation. at least i thought this would be the right way of doing this.\nis there a different approach to combine sweeps with keras k-fold cross validation?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is using Weights & Biases cloud-based sweeps with Keras to run a k-fold cross-validation, but is having difficulty tracking the runs within the sweep."
    },
    {
        "Question_id":null,
        "Question_title":"MLFlow Get Run information in R API and NGINX issue",
        "Question_body":"Hi all,\n\n\nGreat work on mlflow, we have been using it to run many experiments.\n\n\nI am trying to get a list of runs for a specific experiment. I am hosting mlflow in a container running on an EC2 instance in AWS.\u00a0\n\n\n\nI am using the R API.\n\n\n# set tracking URI\nmlflow_set_tracking_uri(ML_FLOW_TRACKING_URI)\n\n\n# init MLflow client object\nclient <- mlflow:::mlflow_client(ML_FLOW_TRACKING_URI)\n\n\n# extract experimment information\nd_exp <- mlflow:::mlflow_client_get_experiment(client, EXPERIMENT_ID)\n\n\n\nNow when I use this on experiments with few runs (<30) I get back the data in a named list with the data being stores in d_exp$runs\n\n\nHowever, for experiments with many runs I receive a cURL error as follow:\n\n\nError in curl::curl_fetch_memory(url, handle = handle) :\u00a0\n\u00a0 Timeout was reached: Operation timed out after 1003 milliseconds with 0 bytes received\n\n\nHas anyone had a similar\u00a0problem and happened to fix it? Or is this an issue with the API?\n\n\nNGINX Issue\n\n\nAlso another issue I have is sending requests to mlflow when I secure it with SSL certs using nGINX (with authentication) as a reverse proxy.\n\n\nIs there an example implementation on how to get this setup and working? I saw that there is a HostCreds class in the source code, but how do I initialise this?\n\n\nCurrent fix has been to whitelist the IP address, however this is obviously not a long-term solution.\n\n\nCheers,\n--\n\nVivek Katial\nData Scientist\n\nLevel 1, 155 Karangahape Road, Auckland Central,\u00a01010\nvivek....@quantiful.co.nz | \u00a00210435892\nwww.quantiful.co.nz",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1541534149000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":31.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/6nWaATd4uTw",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[
            {
                "Answer_creation_time":"2018-11-08T13:13:45",
                "Answer_body":"It looks like the default timeout in the R API is 1 second (per\u00a0this code). This seems relatively aggressive, especially for a remote server. I think you can change this timeout by using\n\n\noptions(\"mlflow.rest.timeout\" = 60)\n\n\nto set it to 60 seconds, for example.\n\n\nRegarding the TLS stuff, let me add Tomas -- I know he was working on improving the R client support for authenticating against remote servers.\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CABGg2YG0C8uPjWmg6G2B2rU3AZeJpM%2B-i5QGc4XfA7y1o_1NuQ%40mail.gmail.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  get run information in r api and nginx issue; content:hi all,\n\n\ngreat work on , we have been using it to run many experiments.\n\n\ni am trying to get a list of runs for a specific experiment. i am hosting  in a container running on an ec2 instance in aws.\u00a0\n\n\n\ni am using the r api.\n\n\n# set tracking uri\n_set_tracking_uri(ml_flow_tracking_uri)\n\n\n# init  client object\nclient <- :::_client(ml_flow_tracking_uri)\n\n\n# extract experimment information\nd_exp <- :::_client_get_experiment(client, experiment_id)\n\n\n\nnow when i use this on experiments with few runs (<30) i get back the data in a named list with the data being stores in d_exp$runs\n\n\nhowever, for experiments with many runs i receive a curl error as follow:\n\n\nerror in curl::curl_fetch_memory(url, handle = handle) :\u00a0\n\u00a0 timeout was reached: operation timed out after 1003 milliseconds with 0 bytes received\n\n\nhas anyone had a similar\u00a0problem and happened to fix it? or is this an issue with the api?\n\n\nnginx issue\n\n\nalso another issue i have is sending requests to  when i secure it with ssl certs using nginx (with authentication) as a reverse proxy.\n\n\nis there an example implementation on how to get this setup and working? i saw that there is a hostcreds class in the source code, but how do i initialise this?\n\n\ncurrent fix has been to whitelist the ip address, however this is obviously not a long-term solution.\n\n\ncheers,\n--\n\nvivek katial\ndata scientist\n\nlevel 1, 155 karangahape road, auckland central,\u00a01010\nvivek....@quantiful.co.nz | \u00a00210435892\nwww.quantiful.co.nz",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to get a list of runs for a specific experiment using the R API, but is running into a timeout error when the experiment has many runs. They are also having an issue with sending requests to  when secured with SSL certs using nginx, and are looking for an example implementation and how to initialise the hostcreds class."
    },
    {
        "Question_id":null,
        "Question_title":"How to move all the ai models (service endpoints) from one compute cluster to another cluster in azure without any effects",
        "Question_body":"I have machine learning models which is deployed in Azure aks in 'x' Cluster , Now i want to move this models and its endpoint in another cluster which is 'y' within same workspace and subscription ,So how to do this without any changes to its rest endpoint as this endpoints are in production use already.\n\nalso if this is not possible then can i upgrade my x cluster with newer version without affecting my endpoints",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1636704232043,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-kubernetes-service",
            "azure-container-instances",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/624851\/how-to-move-all-the-ai-models-service-endpoints-fr.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-12T11:50:38.363Z",
                "Answer_score":1,
                "Answer_body":"@VishalSuryavanshi-3563 Thanks for the question. Here is link to the blog for New managed online endpoints features in Azure ML: Autoscaling, Debugging, MLflow and more.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to move all the ai models (service endpoints) from one compute cluster to another cluster in azure without any effects; content:i have machine learning models which is deployed in azure aks in 'x' cluster , now i want to move this models and its endpoint in another cluster which is 'y' within same workspace and subscription ,so how to do this without any changes to its rest endpoint as this endpoints are in production use already.\n\nalso if this is not possible then can i upgrade my x cluster with newer version without affecting my endpoints",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to know how to move all of their AI models and service endpoints from one Azure compute cluster to another without any effects, or if that is not possible, how to upgrade their current cluster without affecting their endpoints."
    },
    {
        "Question_id":null,
        "Question_title":"Date\/Datetime flags in YAML file are not recognized",
        "Question_body":"<p>I have set up a YAML file with the flags for my single operation. When I run the guild run command, all flags get imported except for date and datetime flags. Will I have to write them as strings and parse them into dates myself on my main script?<\/p>\n<p>Contents of my YAML file:<\/p>\n<pre><code>N_LEADS: 30\nWINDOW_RANGE: [-395, -1]\nLAST_EOM_TRAIN: 2019-12-31\nLEAD_RANGE: [-60, -50]\nN_ESTIMATORS: 2\nEOM_PRED_BENCH: 2021-07-31 00:00:00\nAS_OF_PRED_BENCH: 2021-06-01 00:00:00\n<\/code><\/pre>\n<p>What shows up when running the guild run command:<\/p>\n<pre><code>You are about to run main\n  LEAD_RANGE: -60 -50\n  N_ESTIMATORS: 2\n  N_LEADS: 30\n  WINDOW_RANGE: -395 -1\n<\/code><\/pre>\n<p>Thank you for your help!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1642615429696,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":107.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/date-datetime-flags-in-yaml-file-are-not-recognized\/798",
        "Tool":"Guild AI",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: date\/datetime flags in yaml file are not recognized; content:<p>i have set up a yaml file with the flags for my single operation. when i run the guild run command, all flags get imported except for date and datetime flags. will i have to write them as strings and parse them into dates myself on my main script?<\/p>\n<p>contents of my yaml file:<\/p>\n<pre><code>n_leads: 30\nwindow_range: [-395, -1]\nlast_eom_train: 2019-12-31\nlead_range: [-60, -50]\nn_estimators: 2\neom_pred_bench: 2021-07-31 00:00:00\nas_of_pred_bench: 2021-06-01 00:00:00\n<\/code><\/pre>\n<p>what shows up when running the guild run command:<\/p>\n<pre><code>you are about to run main\n  lead_range: -60 -50\n  n_estimators: 2\n  n_leads: 30\n  window_range: -395 -1\n<\/code><\/pre>\n<p>thank you for your help!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty getting their date and datetime flags recognized in their yaml file when running the guild run command, and is wondering if they will have to parse the flags into dates themselves in their main script."
    },
    {
        "Question_id":null,
        "Question_title":"Azure On-Demand ML cluster from a search in the data catalog",
        "Question_body":"I'm trying to implement a self-service solution in Azure so users can run a Jupyter or PySpark notebook on-Demand\/automatically with the dataset they found a search in the Azure Data Catalog. I visualize, once the user finds the data in a search, there will be a link that will take him\/her to a Notebook and the dataset can be used for analysis. Any suggestion would be very much appreciated!",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_creation_time":1619209726297,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-data-catalog"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/369952\/azure-on-demand-ml-cluster-from-a-search-in-the-da.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-26T10:22:10.247Z",
                "Answer_score":0,
                "Answer_body":"@JairoMelo-1657 Thanks for the question.Azure Purview can find, understand, and consume data sources. Please follow the Azure Purview documentation: https:\/\/docs.microsoft.com\/en-us\/azure\/purview\/\n\nand We have Azure Open Datasets where you can download a Notebook for AML, Databricks or Synapse that explores the data: Azure Open Datasets Catalog | Microsoft Azure. What are open datasets? Curated public datasets - Azure Open Datasets | Microsoft Docs.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-28T11:51:31.093Z",
                "Answer_score":1,
                "Answer_body":"Thank you very much for your response. I'll look into Azure Purview. Best! J.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: azure on-demand ml cluster from a search in the data catalog; content:i'm trying to implement a self-service solution in azure so users can run a jupyter or pyspark notebook on-demand\/automatically with the dataset they found a search in the azure data catalog. i visualize, once the user finds the data in a search, there will be a link that will take him\/her to a notebook and the dataset can be used for analysis. any suggestion would be very much appreciated!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a self-service solution in Azure to allow them to run a Jupyter or PySpark notebook on-demand with the dataset they found in a search in the Azure Data Catalog."
    },
    {
        "Question_id":null,
        "Question_title":"Deployment failed - InternalServerError",
        "Question_body":"Hello,\n\nI just created a free Azure account. I want to create an an Azure Machine Learning workspace (create a resource), but it seems that the the deployment fails. I receive the following error:\n\n\"code\": \"InternalServerError\",\n\"message\": \"Received 400 from a service request\"\n\nWhat should I do?",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1630015001840,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/529757\/deployment-failed-internalservererror.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-27T08:22:12.05Z",
                "Answer_score":0,
                "Answer_body":"@ArminNajarpourForoushani-0656 Which region did you try to create this resource? Usually, such errors could occur due to some intermittent issues.\nIf this is a free account without any usage the creation of workspace should be successful. I would request to try the same with a different region maybe eastus and check if it is successful.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: deployment failed - internalservererror; content:hello,\n\ni just created a free azure account. i want to create an an  workspace (create a resource), but it seems that the the deployment fails. i receive the following error:\n\n\"code\": \"internalservererror\",\n\"message\": \"received 400 from a service request\"\n\nwhat should i do?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user created a free Azure account and attempted to create a workspace, but the deployment failed with an \"InternalServerError\" and a \"400 from a service request\" error."
    },
    {
        "Question_id":63915711.0,
        "Question_title":"What's the largest allowed image size for SageMaker GroundTruth Labelling Job?",
        "Question_body":"<p>We have images of single size 400 MB to 800 MB.<\/p>\n<p>Not sure if SageMaker GroundTruth can handle it.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1600243584947,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":110.0,
        "Owner_creation_time":1392607100776,
        "Owner_last_access_time":1664069299612,
        "Owner_reputation":133.0,
        "Owner_up_votes":304.0,
        "Owner_down_votes":0.0,
        "Owner_views":29.0,
        "Answer_body":"<p><a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/input-data-limits.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/input-data-limits.html<\/a><\/p>\n<p>In case someone is also looking for the answer of this one.<\/p>\n<p>In short:<\/p>\n<blockquote>\n<p>40 MB<\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1605061301483,
        "Answer_score":0.0,
        "Owner_location":"Sydney NSW, Australia",
        "Question_last_edit_time":1600243926987,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63915711",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: what's the largest allowed image size for  groundtruth labelling job?; content:<p>we have images of single size 400 mb to 800 mb.<\/p>\n<p>not sure if  groundtruth can handle it.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unsure if GroundTruth can handle images of size 400 MB to 800 MB."
    },
    {
        "Question_id":60650556.0,
        "Question_title":"From the cluster, cannot download a Python Wheel from the storage account",
        "Question_body":"<p>1) We upload a python wheel to the storage account associated with the workspace successfully.\n2) In the second step we submit an experiment which runs in the cluster and needs to download and run the package from step 1.<\/p>\n\n<p>The experiment is able to download the package and run when the storage account is not associated with any VNet. However, when we associate the storage account in Vnets the experiment hangs and eventually fails. This storage account is in two Vnet\u2019s, a, and b. The cluster is also in the Vnet, a.<\/p>\n\n<p>I don\u2019t know why the cluster cannot download the wheel package when the storage account is in a Vnet. It is our policy to have storage accounts in Vnet\u2019s.<\/p>\n\n<p>It there something else we are missing? I also checked the container registry setting and its set to \u2018allow from everywhere\u2019 (we are using std SKU).<\/p>\n\n<p>Let me know if any further information is required. Thanks.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1584003413540,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning-studio",
            "azure-machine-learning-service",
            "azure-machine-learning-workbench"
        ],
        "Question_view_count":81.0,
        "Owner_creation_time":1296641515120,
        "Owner_last_access_time":1660898089060,
        "Owner_reputation":389.0,
        "Owner_up_votes":10.0,
        "Owner_down_votes":0.0,
        "Owner_views":137.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60650556",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: from the cluster, cannot download a python wheel from the storage account; content:<p>1) we upload a python wheel to the storage account associated with the workspace successfully.\n2) in the second step we submit an experiment which runs in the cluster and needs to download and run the package from step 1.<\/p>\n\n<p>the experiment is able to download the package and run when the storage account is not associated with any vnet. however, when we associate the storage account in vnets the experiment hangs and eventually fails. this storage account is in two vnet\u2019s, a, and b. the cluster is also in the vnet, a.<\/p>\n\n<p>i don\u2019t know why the cluster cannot download the wheel package when the storage account is in a vnet. it is our policy to have storage accounts in vnet\u2019s.<\/p>\n\n<p>it there something else we are missing? i also checked the container registry setting and its set to \u2018allow from everywhere\u2019 (we are using std sku).<\/p>\n\n<p>let me know if any further information is required. thanks.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to download a python wheel from the storage account associated with the workspace when the storage account is in a VNet, despite the container registry settings being set to 'allow from everywhere'."
    },
    {
        "Question_id":null,
        "Question_title":"Force Bayesian sweep to run certain variable tests",
        "Question_body":"<p>Hi!<br>\nI want to run a bayesian HP sweep with 5-fold CV. In other words I want the bayesian sweep to decide upon a configuration, run 5 runs with that configuration and log each run. The easiest way to do this would be to have a variable in the sweep, called e.g. fold_id which simply can take the values 1,2,3,4,5 and force the agent to always test all the fold_ids per configuration.<\/p>\n<p>Is there any way to make this possible? I.e force the sweep agent to always test a variable, even though running a bayesian sweep. In a way it would be like running a grid sweep over a bayesian sweep.<\/p>\n<p>One way I\u2019ve thought of is by making all parameters nested inside the fold_id variable but it still won\u2019t probably do what I\u2019m after.<\/p>\n<p>I\u2019ve seen the k-fold CV example code, but it\u2019s quite advanced and does not seem to work when running on CUDA and my understanding of multiprocessing is limited.<\/p>\n<p>Thank you!<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_creation_time":1662970178525,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":47.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/force-bayesian-sweep-to-run-certain-variable-tests\/3098",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "id":7311,
                "name":"Styrbj\u00f6rn K\u00e4ll",
                "username":"kallstyrbjorn",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/a4c791\/{size}.png",
                "created_at":"2022-09-12T08:13:20.687Z",
                "cooked":"<p>Another way I\u2019ve though of is the following:<\/p>\n<p>Use this pseudo trainer function (called by wandb.agent):<\/p>\n<pre><code class=\"lang-auto\">def trainer(config=None):\n    # Initialize a new run with the sweep configuration\n    wandb.init(config=config)\n\n# Store the config parameters\n    sweepconfig = wandb.config\n\n# Load the raw data and split into k-folds\n    data = pd.read_csv(...)\n    folds = Make_KFolds().Split(...)\n\n# Store the sweep run's name\n    name = wandb.run.name\n    \n    sweep_metric = []\n    for fold_id in range(1,  k_folds+1, 1):\n        # init new run to store performance of this fold\n        wandb.init(config=sweepconfig, name=f\"{name+'-'+str(fold_id)}\", group=name)\n        wandb.config.update({'fold_id': fold_id})\n        # Run the training function which logs metrics to the fold's run\n        metric = RunTrainingEpochs(...)\n        sweep_metric.append(metric)\n\n\n# Exit loop, resume the sweep run and log the avg sweep metric as the average performance\n    wandb.init(config=sweepconfig, name = name, resume=True)\n    wandb.log({'Avg metric': sum(sweep_metric)\/ k_folds})\n<\/code><\/pre>\n<p>But this does not work. In my opinion this should basically do the same as the kfold-CV example code. The sweep agent seems to be limited to one run per trainer call. Even though it initializes new runs, the previous run is continuously overwritten by the next wandb.init call.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-09-12T08:13:20.687Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":1.2,
                "yours":false,
                "topic_id":3098,
                "topic_slug":"force-bayesian-sweep-to-run-certain-variable-tests",
                "display_username":"Styrbj\u00f6rn K\u00e4ll",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1789,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7379,
                "name":"Leslie",
                "username":"lesliewandb",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/lesliewandb\/{size}\/369_2.png",
                "created_at":"2022-09-15T16:51:08.921Z",
                "cooked":"<p>You can create a nested sweep where each fold could be a list and then you can then iterate over those values.  Make sure that the run name changes per run so that way the runs don\u2019t overwrite one another.<\/p>\n<p>Here\u2019s an example config of a nested sweep:<\/p>\n<pre><code class=\"lang-auto\">command:\n  - ${env}\n  - python3\n  - ${program}\n  - ${args}\nmethod: random\nparameters:\n  MULTI_STAGE_TRAINING:\n    value:\n      DEPTH_SCALE:\n        - 100\n        - 100\n      HEAD:\n        - OBJECT_DETECTION\n      NETWORK:\n        - net_a\n        - net_b\n        - net_c\n      NUM_EPOCHS_IN_EACH_STAGE:\n        - 0\n        - 1\n        - 2\n        - 3\n      NUM_STAGES:\n        - 0\n        - 1\n        - 2\n        - 3\n        - 4\n        - 5\n        - 6\n        - 7\n        - 8\n        - 9\n      OPTIMIZER_PARAMS_PER_STAGE:\n        lr:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n        momentum:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n        weight_decay:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n  epochs:\n    value: 10\nprogram: script.py\n<\/code><\/pre>\n<p>And here\u2019s a script that is able to run it:<\/p>\n<pre><code class=\"lang-auto\">import wandb\n\u200b\ndef create_sweep(\n    sweep_config:dict,\n    update:bool,\n    project:str,\n    entity:str):\n    \n    parameters_dict = {'MULTI_STAGE_TRAINING':\n                   {'value':\n                    {'NUM_STAGES':list(range(10)),\n                     'OPTIMIZER_PARAMS_PER_STAGE':\n                     {'lr':list(range(10)),'momentum': list(range(10)),'weight_decay':list(range(10))},\n                     'NUM_EPOCHS_IN_EACH_STAGE':list(range(4)),\n                     'NETWORK':['net_a','net_b','net_c'],\n                     'HEAD':['OBJECT_DETECTION'],\n                     'DEPTH_SCALE': [100,100]\n                     }\n                    }\n                   }\n    sweep_config['parameters'] = parameters_dict\n    \n    parameters_dict.update({\n    'epochs': {\n        'value': 10}\n    })\n    return wandb.sweep(sweep_config,entity=entity,project=project)\n\u200b\nif __name__ == '__main__':\n\u200b\n    SWEEP_CONFIG = {\n    'method': 'random',\n    'program':'script.py',\n    'command':['${env}', 'python3', '${program}','${args}']\n    }\n    ENTITY = 'demonstrations'\n    PROJECT = 'sweep_gm'\n    UPDATE = True\n\u200b\n    sweep = create_sweep(\n        sweep_config=SWEEP_CONFIG,\n        entity=ENTITY,\n        project=PROJECT,\n        update=UPDATE)\n<\/code><\/pre>\n<p>Let me know if you need any further help with this!<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-09-15T16:51:08.921Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":3098,
                "topic_slug":"force-bayesian-sweep-to-run-certain-variable-tests",
                "display_username":"Leslie",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":453,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":true
            },
            {
                "id":7504,
                "name":"Leslie",
                "username":"lesliewandb",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/lesliewandb\/{size}\/369_2.png",
                "created_at":"2022-09-20T19:28:47.638Z",
                "cooked":"<p>Do you need any help here still?<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-09-20T19:28:47.638Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":3098,
                "topic_slug":"force-bayesian-sweep-to-run-certain-variable-tests",
                "display_username":"Leslie",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":453,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7555,
                "name":"Leslie",
                "username":"lesliewandb",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/lesliewandb\/{size}\/369_2.png",
                "created_at":"2022-09-26T15:11:44.764Z",
                "cooked":"<p>Hi Styrbj\u00f6rn, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2022-09-26T15:11:44.764Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":3098,
                "topic_slug":"force-bayesian-sweep-to-run-certain-variable-tests",
                "display_username":"Leslie",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":453,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":8121,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-11-14T16:52:02.624Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":6,
                "post_type":3,
                "updated_at":"2022-11-14T16:52:02.624Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":3098,
                "topic_slug":"force-bayesian-sweep-to-run-certain-variable-tests",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: force bayesian sweep to run certain variable tests; content:<p>hi!<br>\ni want to run a bayesian hp sweep with 5-fold cv. in other words i want the bayesian sweep to decide upon a configuration, run 5 runs with that configuration and log each run. the easiest way to do this would be to have a variable in the sweep, called e.g. fold_id which simply can take the values 1,2,3,4,5 and force the agent to always test all the fold_ids per configuration.<\/p>\n<p>is there any way to make this possible? i.e force the sweep agent to always test a variable, even though running a bayesian sweep. in a way it would be like running a grid sweep over a bayesian sweep.<\/p>\n<p>one way i\u2019ve thought of is by making all parameters nested inside the fold_id variable but it still won\u2019t probably do what i\u2019m after.<\/p>\n<p>i\u2019ve seen the k-fold cv example code, but it\u2019s quite advanced and does not seem to work when running on cuda and my understanding of multiprocessing is limited.<\/p>\n<p>thank you!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to force a Bayesian HP sweep to run certain variable tests, such as a 5-fold CV, and is wondering if there is a way to do this without using advanced code or multiprocessing."
    },
    {
        "Question_id":null,
        "Question_title":"AzureMLCompute job failed",
        "Question_body":"I have created a simple pipeline in Azure ML studio.\nThe pipeline contains only one module \"Import Data\" which is set up as follows:\n\n][2]\n\nThis is a very small dataset that can be found here: https:\/\/archive.ics.uci.edu\/ml\/datasets\/adult\n\nThe validation passed and I can see the sample data.\n\nI have tried to run this pipeline twice and both runs:\n1. Took very long time - over 30 minutes\n2. Failed with the message \"AzureMLCompute job failed. InternalError: Server encountered an internal error. Please try again after some time\"\n\n\n\n\nWhen I look at the error logs of the module I see the following:\n\nJob failed, job RunId is cff2da53-1726-4092-9887-c7cb3c57dd81. Error: {\"Error\":{\"Code\":\"ServiceError\",\"Severity\":null,\"Message\":\"AzureMLCompute job failed.\\nInternalError: Server encountered an internal error. Please try again after some time\",\"MessageFormat\":null,\"MessageParameters\":null,\"ReferenceCode\":null,\"DetailsUri\":null,\"Target\":null,\"Details\":[],\"InnerError\":null,\"DebugInfo\":null,\"AdditionalInfo\":null},\"Correlation\":{\"operation\":\"be4e18a418e8ad6b924b509d8a353404\",\"request\":\"124bf413bb074f22\"},\"Environment\":\"eastus\",\"Location\":\"eastus\",\"Time\":\"2022-03-12T10:25:01.2364098+00:00\",\"ComponentName\":\"globaljobdispatcher\"}\n\nI am using the following compute:\n\nEven though this is marked as an internal server error, since I tried more than once - I think something is wrong with one of my settings.\n\nWould appreciate help with this.\n\nThanks.\n\n[2]: \/answers\/storage\/attachments\/182456-image.png",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1647081369547,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/769672\/azuremlcompute-job-failed-1.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T06:03:52.29Z",
                "Answer_score":0,
                "Answer_body":"@BelgiAmir-3027 I tried import data module and it seems to work fine while using the URI. I think in your case the link is incorrect, The URI download link is enabled on https.\n\nhttps:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/adult\/adult.data\n\nWith the above link, the module ran successfully and the data is available to view.\n\n@AngelicaGarrido-1922 @RahulKhanna-2541 Are you using the same dataset in your jobs? You can also report internal errors through Azure ml portal ml.azure.com using the smiley icon on the top right corner. This reports the issue directly to the product group to lookup the error based on the run details.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: compute job failed; content:i have created a simple pipeline in  studio.\nthe pipeline contains only one module \"import data\" which is set up as follows:\n\n][2]\n\nthis is a very small dataset that can be found here: https:\/\/archive.ics.uci.edu\/ml\/datasets\/adult\n\nthe validation passed and i can see the sample data.\n\ni have tried to run this pipeline twice and both runs:\n1. took very long time - over 30 minutes\n2. failed with the message \"compute job failed. internalerror: server encountered an internal error. please try again after some time\"\n\n\n\n\nwhen i look at the error logs of the module i see the following:\n\njob failed, job runid is cff2da53-1726-4092-9887-c7cb3c57dd81. error: {\"error\":{\"code\":\"serviceerror\",\"severity\":null,\"message\":\"compute job failed.\\ninternalerror: server encountered an internal error. please try again after some time\",\"messageformat\":null,\"messageparameters\":null,\"referencecode\":null,\"detailsuri\":null,\"target\":null,\"details\":[],\"innererror\":null,\"debuginfo\":null,\"additionalinfo\":null},\"correlation\":{\"operation\":\"be4e18a418e8ad6b924b509d8a353404\",\"request\":\"124bf413bb074f22\"},\"environment\":\"eastus\",\"location\":\"eastus\",\"time\":\"2022-03-12t10:25:01.2364098+00:00\",\"componentname\":\"globaljobdispatcher\"}\n\ni am using the following compute:\n\neven though this is marked as an internal server error, since i tried more than once - i think something is wrong with one of my settings.\n\nwould appreciate help with this.\n\nthanks.\n\n[2]: \/answers\/storage\/attachments\/182456-image.png",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an internal server error when attempting to run a compute job in Azure ML Studio, and has tried more than once."
    },
    {
        "Question_id":71222258.0,
        "Question_title":"Error in AWS SageMaker Ground Truth labeled job creation",
        "Question_body":"<p>I'm using AWS SageMaker Ground Truth for labeling images. I have uploaded the data into s3 bucket, create the IAM role to access 'S3,SageMaker,Groundtruth, and IAM'. When I am trying to create labeling job, it give me this error:<\/p>\n<blockquote>\n<p>NetworkingError: Network Failure - The S3 bucket 'sm-gt-s3-enron' you entered in Input dataset location cannot be reached. Either the bucket does not exist, or you do not have permission to access it. If the bucket does not exist, update Input dataset location with a new S3 URI. If the bucket exists, give the IAM entity you are using to create this labeling job permission to read and write to this S3 bucket, and try your request again.<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1645536752887,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker",
            "amazon-ground-truth"
        ],
        "Question_view_count":225.0,
        "Owner_creation_time":1436595102336,
        "Owner_last_access_time":1650532390720,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1645599167900,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71222258",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: error in  ground truth labeled job creation; content:<p>i'm using  ground truth for labeling images. i have uploaded the data into s3 bucket, create the iam role to access 's3,,groundtruth, and iam'. when i am trying to create labeling job, it give me this error:<\/p>\n<blockquote>\n<p>networkingerror: network failure - the s3 bucket 'sm-gt-s3-enron' you entered in input dataset location cannot be reached. either the bucket does not exist, or you do not have permission to access it. if the bucket does not exist, update input dataset location with a new s3 uri. if the bucket exists, give the iam entity you are using to create this labeling job permission to read and write to this s3 bucket, and try your request again.<\/p>\n<\/blockquote>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is encountering an error while creating a ground truth labeled job for images. The error message states that there is a network failure with the S3 bucket \"sm-gt-s3-enron\" and either the bucket doesn't exist or the user doesn't have permission to access it."
    },
    {
        "Question_id":null,
        "Question_title":"Cannot save Spark Pipeline model as pyfunc",
        "Question_body":"I have a Spark Pipeline model saved using mlflow.spark.save_model().Then load it back as a Pyfunc model (mlflow.pyfunc.load_pyfunc). But it is not getting saved on my local machine using the mlflow.pyfunc.save_model command. Why not able to save using mlflow.pyfunc.save_model () ?",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1582551638000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":11.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/IRaESID1o5g",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: cannot save spark pipeline model as pyfunc; content:i have a spark pipeline model saved using .spark.save_model().then load it back as a pyfunc model (.pyfunc.load_pyfunc). but it is not getting saved on my local machine using the .pyfunc.save_model command. why not able to save using .pyfunc.save_model () ?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to save a spark pipeline model as a pyfunc model using the .pyfunc.save_model command."
    },
    {
        "Question_id":null,
        "Question_title":"Group Categorical Values in Azure ML Designer",
        "Question_body":"Hello,\nis there any possibility to do the same in Azure ML Studio designer as it is able in Azure ML Studio? I need to group categorical values, but in Azure ML Studio designer there option for Group Data into Bins. When I am trying to do it by chosing custom edges, it does not seem to work with data column which is categorical.\n\nEDIT\nI have rating 1-5, and I would like to make it in from 1-2-3-4-5 to 1-5. When creating bins I only can get categorized as 1 and 2.",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1615818855177,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/315002\/group-categorical-values-in-azure-ml-designer.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-05T07:34:31.703Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nWe are sorry that have not heard from you. Azure ML Designer officially supports Group data into Bins with custom edge. I have highlighted the essential part below.\n\nAdd the Group Data Into Bins module to your pipeline in the designer. You can find this module in the category Data Transformation.\n\n\n\n\nConnect the dataset that has numerical data to bin. Quantization can be applied only to columns that contain numeric data.\n\nIf the dataset contains non-numeric columns, use the Select Columns in Dataset module to select a subset of columns to work with.\n\nSpecify the binning mode. The binning mode determines other parameters, so be sure to select the Binning mode option first. The following types of binning are supported:\n\nQuantiles: The quantile method assigns values to bins based on percentile ranks. This method is also known as equal height binning.\n\nEqual Width: With this option, you must specify the total number of bins. The values from the data column are placed in the bins such that each bin has the same interval between starting and ending values. As a result, some bins might have more values if data is clumped around a certain point.\n\nCustom Edges: You can specify the values that begin each bin. The edge value is always the lower boundary of the bin.\n\nFor example, assume you want to group values into two bins. One will have values greater than 0, and one will have values less than or equal to 0. In this case, for bin edges, you enter 0 in Comma-separated list of bin edges. The output of the module will be 1 and 2, indicating the bin index for each row value. Note that the comma-separated value list must be in an ascending order, such as 1, 3, 5, 7.\n\nNote\n\nEntropy MDL mode is defined in Studio (classic) and there's no corresponding open source package which can be leveraged to support in Designer yet.\n\nIf you're using the Quantiles and Equal Width binning modes, use the Number of bins option to specify how many bins, or quantiles, you want to create.\n\n\n\n\nFor Columns to bin, use the column selector to choose the columns that have the values you want to bin. Columns must be a numeric data type.\n\nThe same binning rule is applied to all applicable columns that you choose. If you need to bin some columns by using a different method, use a separate instance of the Group Data into Bins module for each set of columns.\n\nWarning\n\nIf you choose a column that's not an allowed type, a runtime error is generated. The module returns an error as soon as it finds any column of a disallowed type. If you get an error, review all selected columns. The error does not list all invalid columns.\n\nFor Output mode, indicate how you want to output the quantized values:\n\nAppend: Creates a new column with the binned values, and appends that to the input table.\n\nInplace: Replaces the original values with the new values in the dataset.\n\nResultOnly: Returns just the result columns.\n\nIf you select the Quantiles binning mode, use the Quantile normalization option to determine how values are normalized before sorting into quantiles. Note that normalizing values transforms the values but doesn't affect the final number of bins.\n\n\n\n\n\nThe following normalization types are supported:\n\nPercent: Values are normalized within the range [0,100].\n\nPQuantile: Values are normalized within the range [0,1].\n\nQuantileIndex: Values are normalized within the range [1,number of bins].\n\nIf you choose the Custom Edges option, enter a comma-separated list of numbers to use as bin edges in the Comma-separated list of bin edges text box.\n\n\n\n\nThe values mark the point that divides bins. For example, if you enter one bin edge value, two bins will be generated. If you enter two bin edge values, three bins will be generated.\n\nThe values must be sorted in the order that the bins are created, from lowest to highest.\n\nSelect the Tag columns as categorical option to indicate that the quantized columns should be handled as categorical variables.\n\n\n\n\nSubmit the pipeline.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: group categorical values in  designer; content:hello,\nis there any possibility to do the same in  studio designer as it is able in  studio? i need to group categorical values, but in  studio designer there option for group data into bins. when i am trying to do it by chosing custom edges, it does not seem to work with data column which is categorical.\n\nedit\ni have rating 1-5, and i would like to make it in from 1-2-3-4-5 to 1-5. when creating bins i only can get categorized as 1 and 2.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to group categorical values in Azure ML Designer, similar to the way it can be done in Azure ML Studio. They need to group a rating of 1-5 into 1-5, but when creating bins they can only get categorized as 1 and 2."
    },
    {
        "Question_id":60832279.0,
        "Question_title":"Influx DB as a source for MLS as a direct connection",
        "Question_body":"<p>Can we use InfluxDB as a data source for Azure ML Serv, in the form of a direct connection.  If not, what are the proposed alternatives to setup this connection?\n(Put differently, Is it possible for M LServ to connect to an InfluxDB next to some API to fetch data from. Or do we have to put all data in a SQL database?)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1585057386130,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning-service"
        ],
        "Question_view_count":105.0,
        "Owner_creation_time":1585057281607,
        "Owner_last_access_time":1614093458423,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60832279",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: influx db as a source for mls as a direct connection; content:<p>can we use influxdb as a data source for  serv, in the form of a direct connection.  if not, what are the proposed alternatives to setup this connection?\n(put differently, is it possible for m lserv to connect to an influxdb next to some api to fetch data from. or do we have to put all data in a sql database?)<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to use InfluxDB as a data source for Azure ML Service in the form of a direct connection, and if not, what alternatives are available to set up this connection."
    },
    {
        "Question_id":63456236.0,
        "Question_title":"Video classification with AWS Lambda websocket and Sagemaker",
        "Question_body":"<p>I'm trying to do webcam video classification with AWS Sagemaker. I currently have a proof-of-concept pipeline that works, which looks like:<\/p>\n<ol>\n<li>Front-end gets frame of video<\/li>\n<li>Sends in websocket to AWS API Gateway<\/li>\n<li>Uses a Lambda proxy to send the image to Sagemaker, which classifies the image and returns a prediction<\/li>\n<\/ol>\n<p>This works for images. I'm trying to move to multiple frames - i.e. video. AWS has a limit of 32kb in each websocket message, so I can't concatenate frames, each of which is ~30kb. So I have to send each frame separately. What is the simplest way to insert some concept of &quot;connected messages&quot; into this pipeline? Do I have to use a database (e.g. Dynamo DB) or is there any concept of preserving information across websocket messages \/ Lambda function calls?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1597687181720,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-web-services",
            "websocket",
            "aws-lambda",
            "aws-api-gateway",
            "amazon-sagemaker"
        ],
        "Question_view_count":100.0,
        "Owner_creation_time":1476426309390,
        "Owner_last_access_time":1657275499976,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Adelaide SA, Australia",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63456236",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: video classification with aws lambda websocket and ; content:<p>i'm trying to do webcam video classification with . i currently have a proof-of-concept pipeline that works, which looks like:<\/p>\n<ol>\n<li>front-end gets frame of video<\/li>\n<li>sends in websocket to aws api gateway<\/li>\n<li>uses a lambda proxy to send the image to , which classifies the image and returns a prediction<\/li>\n<\/ol>\n<p>this works for images. i'm trying to move to multiple frames - i.e. video. aws has a limit of 32kb in each websocket message, so i can't concatenate frames, each of which is ~30kb. so i have to send each frame separately. what is the simplest way to insert some concept of &quot;connected messages&quot; into this pipeline? do i have to use a database (e.g. dynamo db) or is there any concept of preserving information across websocket messages \/ lambda function calls?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to do video classification with AWS Lambda Websocket and is looking for a way to send multiple frames of video without exceeding the 32kb limit of each websocket message. They are wondering if they need to use a database or if there is a way to preserve information across websocket messages and Lambda function calls."
    },
    {
        "Question_id":null,
        "Question_title":"What is the limit of ProductSet per location",
        "Question_body":"When using Google Vision's Product Search API, does anyone have an idea the maximum number of ProductSets allowed in a location(region)?This documentation shares limits on reference images per ProductSet, but it says nothing about ProductSets per location",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1667481660000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":30.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-is-the-limit-of-ProductSet-per-location\/td-p\/485590\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-04T11:53:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"Hi, iola,\n\nIn your Google Cloud Project, type \u201cCloud Vision API\u201d in the search bar.\nOn the left, click \u201cEnabled APIs and services\u201d > Quotas.\n\nIn the Quota column it is listed the different types of actions, accompanied by their limit in the Limit column.\n\nPlease tell me if this information is useful."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: what is the limit of productset per location; content:when using google vision's product search api, does anyone have an idea the maximum number of productsets allowed in a location(region)?this documentation shares limits on reference images per productset, but it says nothing about productsets per location",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking about the maximum number of productsets allowed in a location when using Google Vision's Product Search API."
    },
    {
        "Question_id":69141138.0,
        "Question_title":"How do I parse in the arguments to my Python file when running the Sagemaker pipeline's ProcessingStep?",
        "Question_body":"<p>I read from this <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/workflows\/pipelines\/sagemaker.workflow.pipelines.html#sagemaker.workflow.steps.ProcessingStep\" rel=\"nofollow noreferrer\">documentation<\/a> that the ProcessingStep can accept job arguments.<\/p>\n<p>I currently have a python script contaning a function to be executed via ProcessingStep that requires arguments to be parsed in. I am not sure how I can extract the arguments from the 'Job arguments' such that I can call the function in the python script with the arguments.<\/p>\n<p>Here is an example of code snippet from my python script:<\/p>\n<pre><code>def params(input_params):\n    details = {&quot;database&quot;: input_params[0],\n         &quot;table&quot;: input_params[1], \n         &quot;catalog&quot;: input_params[2], \n         &quot;earliestday&quot;: int(input_params[3]), \n         &quot;latestday&quot;: int(input_params[4]),\n         &quot;s3bucket&quot;: input_params[5], \n         &quot;bucketpath&quot;: input_params[6]}\n    return details\n\noutput_params = params(input_params) #this is where I'm not sure how I can extract the argument from the job arguments in the ProcessingStep to call my function here\n<\/code><\/pre>\n<p>Here's how my processingstep code looks like:<\/p>\n<pre><code>step_params = ProcessingStep(\n    name=&quot;StateParams&quot;,\n    processor=sklearn_processor, \n    outputs = [processing_output],\n    job_arguments = [&quot;ABC&quot;, &quot;SESSION_123&quot;, &quot;AwsDataCatalog&quot;, &quot;5&quot;, &quot;7&quot;, &quot;mybucket&quot;, &quot;bucket2\/tmp\/athena_sagemaker&quot;],   #This is the job argument I input which I hope will be parsed into my python file function\n    code = &quot;params.py&quot;,\n)\n<\/code><\/pre>\n<p>Would greatly appreciate if any of you can advice me on how I can go about using the job arguments in the ProcessingStep to successfully call the function in the python script, thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1631347445253,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":551.0,
        "Owner_creation_time":1623222646127,
        "Owner_last_access_time":1662641889288,
        "Owner_reputation":23.0,
        "Owner_up_votes":12.0,
        "Owner_down_votes":0.0,
        "Owner_views":8.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69141138",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how do i parse in the arguments to my python file when running the  pipeline's processingstep?; content:<p>i read from this <a href=\"https:\/\/.readthedocs.io\/en\/stable\/workflows\/pipelines\/.workflow.pipelines.html#.workflow.steps.processingstep\" rel=\"nofollow noreferrer\">documentation<\/a> that the processingstep can accept job arguments.<\/p>\n<p>i currently have a python script contaning a function to be executed via processingstep that requires arguments to be parsed in. i am not sure how i can extract the arguments from the 'job arguments' such that i can call the function in the python script with the arguments.<\/p>\n<p>here is an example of code snippet from my python script:<\/p>\n<pre><code>def params(input_params):\n    details = {&quot;database&quot;: input_params[0],\n         &quot;table&quot;: input_params[1], \n         &quot;catalog&quot;: input_params[2], \n         &quot;earliestday&quot;: int(input_params[3]), \n         &quot;latestday&quot;: int(input_params[4]),\n         &quot;s3bucket&quot;: input_params[5], \n         &quot;bucketpath&quot;: input_params[6]}\n    return details\n\noutput_params = params(input_params) #this is where i'm not sure how i can extract the argument from the job arguments in the processingstep to call my function here\n<\/code><\/pre>\n<p>here's how my processingstep code looks like:<\/p>\n<pre><code>step_params = processingstep(\n    name=&quot;stateparams&quot;,\n    processor=sklearn_processor, \n    outputs = [processing_output],\n    job_arguments = [&quot;abc&quot;, &quot;session_123&quot;, &quot;awsdatacatalog&quot;, &quot;5&quot;, &quot;7&quot;, &quot;mybucket&quot;, &quot;bucket2\/tmp\/athena_&quot;],   #this is the job argument i input which i hope will be parsed into my python file function\n    code = &quot;params.py&quot;,\n)\n<\/code><\/pre>\n<p>would greatly appreciate if any of you can advice me on how i can go about using the job arguments in the processingstep to successfully call the function in the python script, thanks!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to extract the job arguments from the processingstep and parse them into the python script to call the function with the arguments."
    },
    {
        "Question_id":null,
        "Question_title":"[Feature Request] Serverless Inference with VPC Config",
        "Question_body":"I would like to use a Sagemaker Model with a custom VPC Configuration, which is currently not possible with Serverless Inference. Is this feature planned? More generally: Is there a roadmap somewhere for Serverless Inference?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1643639169189,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "Amazon SageMaker"
        ],
        "Question_view_count":181.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU0JnCsfMHRrSUosWjOiOM9g\/feature-request-serverless-inference-with-vpc-config",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-11T17:55:31.963Z",
                "Answer_score":0,
                "Answer_body":"SageMaker Serverless Inference is currently in preview and VPC support is not available but as the feature you are asking for is an important one and is on the roadmap( unfortunately I cannot share the exact details of the timelines here)",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: [feature request] serverless inference with vpc config; content:i would like to use a  model with a custom vpc configuration, which is currently not possible with serverless inference. is this feature planned? more generally: is there a roadmap somewhere for serverless inference?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to use a model with a custom VPC configuration with serverless inference, and is asking if this feature is planned and if there is a roadmap for serverless inference."
    },
    {
        "Question_id":null,
        "Question_title":"Custom Argument pass to Docker Container Azure ML inference",
        "Question_body":"Hello Team,\n\nI'm trying to pass the arguments to Azure ML docker. I have created an environment like this.\n\n env = Environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/conda_dependencies.yml' )\n\n\n\nAm I passing the arguments correct?\n\n DOCKER_ARGUMENTS = [\"--shm-size\",\"32G\"]  # increase shared memory\n env.docker.arguments = DOCKER_ARGUMENTS\n\n\n\n\nThe main goal of this project is to deploy a model on the AKS inference cluster. I have successfully deployed the model. When I try to get predictions from the model I got this error\n\nIt is possible that data loaders workers are out of shared memory. Please try to raise your shared memory limit\n\nHow can I do that if that's not the correct way to pass arguments?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1632856020243,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569816\/custom-argument-pass-to-docker-container-azure-ml.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-29T06:31:54.6Z",
                "Answer_score":0,
                "Answer_body":"@khubaibRaza-8970 To pass the argument for increasing the default \"shm_size\" you would have to use the DockerConfiguration object. Here is a sample to achieve this:\n\n from azureml.core import Environment\n from azureml.core import ScriptRunConfig\n from azureml.core.runconfig import DockerConfiguration\n    \n    \n # Specify VM and Python environment:\n my_env = Environment.from_conda_specification(name='my-test-env', file_path=PATH_TO_YAML_FILE)\n my_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.2-cudnn7-ubuntu18.04'\n    \n docker_config = DockerConfiguration(use_docker=True,shm_size='32g')\n    \n # Finally, use the environment in the ScriptRunConfig:\n src = ScriptRunConfig(source_directory=DEPLOY_CONTAINER_FOLDER_PATH,\n                       script=SCRIPT_FILE_TO_EXECUTE,\n                       arguments=EXECUTE_ARGUMENTS,\n                       compute_target=compute_target,\n                       environment=my_env,\n                       docker_runtime_config=docker_config)\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: custom argument pass to docker container  inference; content:hello team,\n\ni'm trying to pass the arguments to  docker. i have created an environment like this.\n\n env = environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/conda_dependencies.yml' )\n\n\n\nam i passing the arguments correct?\n\n docker_arguments = [\"--shm-size\",\"32g\"]  # increase shared memory\n env.docker.arguments = docker_arguments\n\n\n\n\nthe main goal of this project is to deploy a model on the aks inference cluster. i have successfully deployed the model. when i try to get predictions from the model i got this error\n\nit is possible that data loaders workers are out of shared memory. please try to raise your shared memory limit\n\nhow can i do that if that's not the correct way to pass arguments?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to pass arguments to an Azure ML Docker container and is having difficulty getting predictions from the model due to an error suggesting that data loaders workers are out of shared memory. They are asking how to raise the shared memory limit if their current method of passing arguments is not correct."
    },
    {
        "Question_id":null,
        "Question_title":"Error while hyperparameter search",
        "Question_body":"<p>When I try wandb.sweep, it gives following error:  wandb.errors.CommError: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.<\/p>\n<p>Following this, is my sweep config<br>\n{\u2018method\u2019: \u2018random\u2019,<br>\n\u2018metric\u2019: {\u2018goal\u2019: \u2018minimize\u2019, \u2018name\u2019: \u2018loss\u2019},<br>\n\u2018parameters\u2019: {\u2018batch_size\u2019: {\u2018distribution\u2019: \u2018q_log_uniform_values\u2019,<br>\n\u2018max\u2019: 256,<br>\n\u2018min\u2019: 32,<br>\n\u2018q\u2019: 8},<br>\n\u2018epochs\u2019: {\u2018value\u2019: 10},<br>\n\u2018fc_layer_size\u2019: {\u2018values\u2019: [16, 32, 64]},<br>\n\u2018learning_rate\u2019: {\u2018distribution\u2019: \u2018uniform\u2019,<br>\n\u2018max\u2019: 0.1,<br>\n\u2018min\u2019: 0},<br>\n\u2018optimizer\u2019: {\u2018values\u2019: [\u2018adam\u2019, \u2018sgd\u2019]},<br>\n\u2018training_snr\u2019: {\u2018values\u2019: [0.3981071705534972,<br>\n0.44668359215096315,<br>\n0.5011872336272722,<br>\n0.5623413251903491,<br>\n0.6309573444801932,<br>\n0.7079457843841379,<br>\n0.7943282347242815,<br>\n0.8912509381337456,<br>\n1.0,<br>\n1.1220184543019633,<br>\n1.2589254117941673,<br>\n1.4125375446227544,<br>\n1.5848931924611136,<br>\n1.7782794100389228,<br>\n1.9952623149688795,<br>\n2.2387211385683394,<br>\n2.51188643150958,<br>\n2.8183829312644537,<br>\n3.1622776601683795,<br>\n3.548133892335755,<br>\n3.9810717055349722,<br>\n4.466835921509632,<br>\n5.011872336272722,<br>\n5.623413251903491,<br>\n6.309573444801933,<br>\n7.079457843841379,<br>\n7.943282347242816,<br>\n8.912509381337454,<br>\n10.0]}}}<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_creation_time":1657819842704,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":92.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/error-while-hyperparameter-search\/2751",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":6501,
                "name":"Mohammad Bakir",
                "username":"mohammadbakir",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/a9a28c\/{size}.png",
                "created_at":"2022-07-15T19:30:39.279Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/raikar_sumanth\">@raikar_sumanth<\/a> ,<br>\nCould you share the <code>debug.log<\/code> and <code>debug-internal.log<\/code> files associated with one of the runs which displays this error? It would be very helpful in order to gain more visibility into this error and understand why you are seeing CommErrors here.<\/p>\n<p>Thanks<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-07-15T19:35:10.281Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":4,
                "readers_count":3,
                "score":10.8,
                "yours":false,
                "topic_id":2751,
                "topic_slug":"error-while-hyperparameter-search",
                "display_username":"Mohammad Bakir",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1458,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6510,
                "name":"Sumanth Raikar",
                "username":"raikar_sumanth",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/58956e\/{size}.png",
                "created_at":"2022-07-16T06:40:28.428Z",
                "cooked":"<p>There was no run, it gets stuck at wandb.sweep(sweep_config). if I disable the training_snr parameter from the sweep config , it works perfectly.<br>\nthe training_snr parameter is given at the forward pass in pytorch like this<br>\nfor epoch in range(config.epochs):<br>\navg_loss = train_epoch(network,loader,optimizer,training_snr)<br>\nwandb.log({\u201closs\u201d:avg_loss, \u201cepoch\u201d:epoch,\u201ctraining_snr\u201d:config.training_snr})<\/p>\n<p>Can you suggest any changes?<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-07-16T06:40:28.428Z",
                "reply_count":0,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":2751,
                "topic_slug":"error-while-hyperparameter-search",
                "display_username":"Sumanth Raikar",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"mohammadbakir",
                    "name":"Mohammad Bakir",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/a9a28c\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1634,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6574,
                "name":"Mohammad Bakir",
                "username":"mohammadbakir",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/a9a28c\/{size}.png",
                "created_at":"2022-07-21T03:52:45.679Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/raikar_sumanth\">@raikar_sumanth<\/a> ,<\/p>\n<p>Your sweep dictionary configuration is setup correctly and I was able to use it for a an experiment and didn\u2019t run into the same error. To better assist you can you please provide the following:<\/p>\n<ul>\n<li>wandb version<\/li>\n<li>Full traceback of error<\/li>\n<li>Description\/Summary of the experiment you are running and which integration ,if any,  you are using<\/li>\n<li>Example colab of your code to attempt to reproduce your specific error<\/li>\n<\/ul>\n<p>Thank-you.<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-07-21T03:52:45.679Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":2751,
                "topic_slug":"error-while-hyperparameter-search",
                "display_username":"Mohammad Bakir",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1458,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6638,
                "name":"Mohammad Bakir",
                "username":"mohammadbakir",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/a9a28c\/{size}.png",
                "created_at":"2022-07-26T21:22:23.547Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/raikar_sumanth\">@raikar_sumanth<\/a> ,<\/p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2022-07-26T21:22:23.547Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2751,
                "topic_slug":"error-while-hyperparameter-search",
                "display_username":"Mohammad Bakir",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1458,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7547,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-09-24T21:22:29.900Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":6,
                "post_type":3,
                "updated_at":"2022-09-24T21:22:29.900Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2751,
                "topic_slug":"error-while-hyperparameter-search",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: error while hyperparameter search; content:<p>when i try .sweep, it gives following error:  .errors.commerror: 400 bad request: the browser (or proxy) sent a request that this server could not understand.<\/p>\n<p>following this, is my sweep config<br>\n{\u2018method\u2019: \u2018random\u2019,<br>\n\u2018metric\u2019: {\u2018goal\u2019: \u2018minimize\u2019, \u2018name\u2019: \u2018loss\u2019},<br>\n\u2018parameters\u2019: {\u2018batch_size\u2019: {\u2018distribution\u2019: \u2018q_log_uniform_values\u2019,<br>\n\u2018max\u2019: 256,<br>\n\u2018min\u2019: 32,<br>\n\u2018q\u2019: 8},<br>\n\u2018epochs\u2019: {\u2018value\u2019: 10},<br>\n\u2018fc_layer_size\u2019: {\u2018values\u2019: [16, 32, 64]},<br>\n\u2018learning_rate\u2019: {\u2018distribution\u2019: \u2018uniform\u2019,<br>\n\u2018max\u2019: 0.1,<br>\n\u2018min\u2019: 0},<br>\n\u2018optimizer\u2019: {\u2018values\u2019: [\u2018adam\u2019, \u2018sgd\u2019]},<br>\n\u2018training_snr\u2019: {\u2018values\u2019: [0.3981071705534972,<br>\n0.44668359215096315,<br>\n0.5011872336272722,<br>\n0.5623413251903491,<br>\n0.6309573444801932,<br>\n0.7079457843841379,<br>\n0.7943282347242815,<br>\n0.8912509381337456,<br>\n1.0,<br>\n1.1220184543019633,<br>\n1.2589254117941673,<br>\n1.4125375446227544,<br>\n1.5848931924611136,<br>\n1.7782794100389228,<br>\n1.9952623149688795,<br>\n2.2387211385683394,<br>\n2.51188643150958,<br>\n2.8183829312644537,<br>\n3.1622776601683795,<br>\n3.548133892335755,<br>\n3.9810717055349722,<br>\n4.466835921509632,<br>\n5.011872336272722,<br>\n5.623413251903491,<br>\n6.309573444801933,<br>\n7.079457843841379,<br>\n7.943282347242816,<br>\n8.912509381337454,<br>\n10.0]}}}<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving a 400 bad request error when attempting to run a hyperparameter search with the given configuration."
    },
    {
        "Question_id":45051055.0,
        "Question_title":"Read multiple CSV files in Azure ML Python Script",
        "Question_body":"<p>I have 4 csv files that are inputs to the python script in azure ML, but the widget has only 2 inputs for dataframes and the third for a zip file. I tried to put the csv files in a zipped folder and connect it to the third input for the script but that also did not work :\n<a href=\"https:\/\/i.stack.imgur.com\/FkxRE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FkxRE.png\" alt=\"Image of workspace\"><\/a><\/p>\n\n<p>I would like to know how to read multiple csv files in the python script.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_creation_time":1499844354733,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "csv",
            "azure",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":944.0,
        "Owner_creation_time":1470376815796,
        "Owner_last_access_time":1660941481503,
        "Owner_reputation":596.0,
        "Owner_up_votes":72.0,
        "Owner_down_votes":3.0,
        "Owner_views":57.0,
        "Answer_body":"<p>Here's some more detail on the approach others have outlined above. Try replacing the code currently in the \"Execute Python Script\" module with the following:<\/p>\n\n<pre><code>import pandas as pd\nimport os\ndef azureml_main(dataframe1=None, dataframe2=None):\n    print(os.listdir('.'))\n    return(pd.DataFrame([]))\n<\/code><\/pre>\n\n<p>After running the experiment, click on the module. There should be a \"View output log\" link now in the right-hand bar. I get something like the following:<\/p>\n\n<pre><code>[Information]         Started in [C:\\temp]\n[Information]         Running in [C:\\temp]\n[Information]         Executing 4af67c05ba02417a980f6a16e84e61dc with inputs [] and generating outputs ['.maml.oport1']\n[Information]         Extracting Script Bundle.zip to .\\Script Bundle\n[Information]         File Name                                             Modified             Size\n[Information]         temp.csv                                       2016-05-06 13:16:56           52\n[Information]         [ READING ] 0:00:00\n[Information]         ['4af67c05ba02417a980f6a16e84e61dc.py', 'Script Bundle', 'Script Bundle.zip']\n<\/code><\/pre>\n\n<p>This tells me that the contents of my zip file have been extracted to the <code>C:\\temp\\Script Bundle<\/code> folder. In my case the zip file contained just one CSV file, <code>temp.csv<\/code>: your output would probably have four files. You may also have zipped a folder containing your four files, in which case the filepath would be one layer deeper. You can use the <code>os.listdir()<\/code> to explore your directory structure further if necessary.<\/p>\n\n<p>Once you think you know the full filepaths for your CSV files, edit your Execute Python Script module's code to load them, e.g.:<\/p>\n\n<pre><code>import pandas as pd\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    df = pd.read_csv('C:\/temp\/Script Bundle\/temp.csv')\n    # ...load other files and merge into a single dataframe...\n    return(df)\n<\/code><\/pre>\n\n<p>Hope that helps!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1500412322168,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":1499850837700,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45051055",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: read multiple csv files in  python script; content:<p>i have 4 csv files that are inputs to the python script in , but the widget has only 2 inputs for dataframes and the third for a zip file. i tried to put the csv files in a zipped folder and connect it to the third input for the script but that also did not work :\n<a href=\"https:\/\/i.stack.imgur.com\/fkxre.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fkxre.png\" alt=\"image of workspace\"><\/a><\/p>\n\n<p>i would like to know how to read multiple csv files in the python script.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to read multiple CSV files in an Azure ML Python script, as the widget only allows for two inputs for dataframes and one for a zip file."
    },
    {
        "Question_id":71385524.0,
        "Question_title":"Sagemaker training job Fatal error: cannot open file 'train': No such file or directory",
        "Question_body":"<p>I am trying work on bring your own model. I have R code. when i try to run the job its failing.<\/p>\n<p><strong>Training Image:<\/strong><\/p>\n<pre><code>FROM r-base:3.6.3\n\nMAINTAINER Amazon SageMaker Examples &lt;amazon-sagemaker-examples@amazon.com&gt;\n\nRUN apt-get -y update &amp;&amp; apt-get install -y --no-install-recommends \\\n    wget \\\n    r-base \\\n    r-base-dev \\\n    apt-transport-https \\\n    ca-certificates \\\n    python3 python3-dev pip\n\nENV AWS_DEFAULT_REGION=&quot;us-east-2&quot;\nRUN R -e &quot;install.packages('reticulate', dependencies = TRUE, warning = function(w) stop(w))&quot;\nRUN R -e &quot;install.packages('readr', dependencies = TRUE, warning = function(w) stop(w))&quot;\nRUN R -e &quot;install.packages('dplyr', dependencies = TRUE, warning = function(w) stop(w))&quot;\n\nRUN pip install --quiet --no-cache-dir \\\n    'boto3&gt;1.0&lt;2.0' \\\n    'sagemaker&gt;2.0&lt;3.0'    \n\nENTRYPOINT [&quot;\/usr\/bin\/Rscript&quot;]\n<\/code><\/pre>\n<p><strong>Source code:<\/strong><\/p>\n<pre><code>rcode\n    \u2514\u2500\u2500 train.R\n    \u2514\u2500\u2500 train.tar.gz\n<\/code><\/pre>\n<p>Build<\/p>\n<pre><code>- aws s3 cp $CODEBUILD_SRC_DIR\/rcode\/ s3:\/\/${self:custom.deploymentBucket}\/${self:service}\/code\/training --recursive\n<\/code><\/pre>\n<p><strong>Serverless.com yaml<\/strong><\/p>\n<pre><code>           SagemakerRCodeTrainingStep:\n            Type: Task\n            Resource: ${self:custom.sageMakerTrainingJob}\n            Parameters:\n              TrainingJobName.$: &quot;$.sageMakerTrainingJobName&quot;\n              DebugHookConfig:\n                S3OutputPath: &quot;s3:\/\/${self:custom.deploymentBucket}\/${self:service}\/models\/rmodel&quot;\n              AlgorithmSpecification:\n                TrainingImage: ${self:custom.sagemakerRExecutionContainerURI}\n                TrainingInputMode: &quot;File&quot;\n              OutputDataConfig:\n                S3OutputPath: &quot;s3:\/\/${self:custom.deploymentBucket}\/${self:service}\/models\/rmodel&quot;\n              StoppingCondition:\n                MaxRuntimeInSeconds: ${self:custom.maxRuntime}\n              ResourceConfig:\n                InstanceCount: 1\n                InstanceType: &quot;ml.m5.xlarge&quot;\n                VolumeSizeInGB: 30\n              RoleArn: ${self:custom.stateMachineRoleARN}\n              InputDataConfig:\n                - DataSource:\n                    S3DataSource:\n                      S3DataType: &quot;S3Prefix&quot;\n                      S3Uri: &quot;s3:\/\/${self:custom.datasetsFilePath}\/data\/processed\/train&quot;\n                      S3DataDistributionType: &quot;FullyReplicated&quot;\n                  ChannelName: &quot;train&quot;\n              HyperParameters:\n                sagemaker_submit_directory: &quot;s3:\/\/${self:custom.deploymentBucket}\/${self:service}\/code\/training\/train.tar.gz&quot;\n                sagemaker_program: &quot;train.R&quot;\n                sagemaker_enable_cloudwatch_metrics: &quot;false&quot;\n                sagemaker_container_log_level: &quot;20&quot;\n                sagemaker_job_name: &quot;sagemaker-r-learn-2022-02-28-09-56-33-234&quot;\n                sagemaker_region: ${self:provider.region}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1646676784137,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "r",
            "amazon-sagemaker",
            "serverless.com"
        ],
        "Question_view_count":369.0,
        "Owner_creation_time":1285763771347,
        "Owner_last_access_time":1658319981990,
        "Owner_reputation":6958.0,
        "Owner_up_votes":123.0,
        "Owner_down_votes":1.0,
        "Owner_views":787.0,
        "Answer_body":"<p>I am not sure which <code>TrainingImage<\/code> you are using and all the files in your container.\nThat being said, I suspect you are using a custom container.<\/p>\n<p>SageMaker Training Jobs look for a <code>train<\/code> file and run your container as <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms-training-algo-dockerfile.html\" rel=\"nofollow noreferrer\">follows<\/a>:<\/p>\n<pre><code>docker run image train\n<\/code><\/pre>\n<p>You can change this behavior by setting the <code>ENTRYPOINT<\/code> in your Dockerfile. Please see this example <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/r_examples\/r_byo_r_algo_hpo\/Dockerfile#L47\" rel=\"nofollow noreferrer\">Dockerfile<\/a> from the <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/tree\/main\/r_examples\/r_byo_r_algo_hpo\" rel=\"nofollow noreferrer\">r_byo_r_algo_hpo<\/a> example.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1646690790176,
        "Answer_score":1.0,
        "Owner_location":"Bangalore, India",
        "Question_last_edit_time":1646720798767,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71385524",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  training job fatal error: cannot open file 'train': no such file or directory; content:<p>i am trying work on bring your own model. i have r code. when i try to run the job its failing.<\/p>\n<p><strong>training image:<\/strong><\/p>\n<pre><code>from r-base:3.6.3\n\nmaintainer  examples &lt;amazon--examples@amazon.com&gt;\n\nrun apt-get -y update &amp;&amp; apt-get install -y --no-install-recommends \\\n    wget \\\n    r-base \\\n    r-base-dev \\\n    apt-transport-https \\\n    ca-certificates \\\n    python3 python3-dev pip\n\nenv aws_default_region=&quot;us-east-2&quot;\nrun r -e &quot;install.packages('reticulate', dependencies = true, warning = function(w) stop(w))&quot;\nrun r -e &quot;install.packages('readr', dependencies = true, warning = function(w) stop(w))&quot;\nrun r -e &quot;install.packages('dplyr', dependencies = true, warning = function(w) stop(w))&quot;\n\nrun pip install --quiet --no-cache-dir \\\n    'boto3&gt;1.0&lt;2.0' \\\n    '&gt;2.0&lt;3.0'    \n\nentrypoint [&quot;\/usr\/bin\/rscript&quot;]\n<\/code><\/pre>\n<p><strong>source code:<\/strong><\/p>\n<pre><code>rcode\n    \u2514\u2500\u2500 train.r\n    \u2514\u2500\u2500 train.tar.gz\n<\/code><\/pre>\n<p>build<\/p>\n<pre><code>- aws s3 cp $codebuild_src_dir\/rcode\/ s3:\/\/${self:custom.deploymentbucket}\/${self:service}\/code\/training --recursive\n<\/code><\/pre>\n<p><strong>serverless.com yaml<\/strong><\/p>\n<pre><code>           rcodetrainingstep:\n            type: task\n            resource: ${self:custom.trainingjob}\n            parameters:\n              trainingjobname.$: &quot;$.trainingjobname&quot;\n              debughookconfig:\n                s3outputpath: &quot;s3:\/\/${self:custom.deploymentbucket}\/${self:service}\/models\/rmodel&quot;\n              algorithmspecification:\n                trainingimage: ${self:custom.rexecutioncontaineruri}\n                traininginputmode: &quot;file&quot;\n              outputdataconfig:\n                s3outputpath: &quot;s3:\/\/${self:custom.deploymentbucket}\/${self:service}\/models\/rmodel&quot;\n              stoppingcondition:\n                maxruntimeinseconds: ${self:custom.maxruntime}\n              resourceconfig:\n                instancecount: 1\n                instancetype: &quot;ml.m5.xlarge&quot;\n                volumesizeingb: 30\n              rolearn: ${self:custom.statemachinerolearn}\n              inputdataconfig:\n                - datasource:\n                    s3datasource:\n                      s3datatype: &quot;s3prefix&quot;\n                      s3uri: &quot;s3:\/\/${self:custom.datasetsfilepath}\/data\/processed\/train&quot;\n                      s3datadistributiontype: &quot;fullyreplicated&quot;\n                  channelname: &quot;train&quot;\n              hyperparameters:\n                _submit_directory: &quot;s3:\/\/${self:custom.deploymentbucket}\/${self:service}\/code\/training\/train.tar.gz&quot;\n                _program: &quot;train.r&quot;\n                _enable_cloudwatch_metrics: &quot;false&quot;\n                _container_log_level: &quot;20&quot;\n                _job_name: &quot;-r-learn-2022-02-28-09-56-33-234&quot;\n                _region: ${self:provider.region}\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing a fatal error when trying to run a training job, as the file 'train' cannot be found."
    },
    {
        "Question_id":59500449.0,
        "Question_title":"AWS SageMaker EndPoint returns 415",
        "Question_body":"<p>I have trained a multiclass classification model on the wine quality dataset and I have deployed the model.\nAfter deploying the model I got EndPoint URL like:<\/p>\n\n<p><a href=\"https:\/\/runtime.sagemaker.region.amazonaws.com\/endpoints\/experiment\/invocations\" rel=\"nofollow noreferrer\">https:\/\/runtime.sagemaker.region.amazonaws.com\/endpoints\/experiment\/invocations<\/a><\/p>\n\n<p>And I am invoking the URL after passing AWS credentials and body like:<\/p>\n\n<p><code>{\n  \"instances\": [7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4]\n}<\/code><\/p>\n\n<p>But I am getting below error:<\/p>\n\n<p><code>{\n    \"ErrorCode\": \"CLIENT_ERROR_FROM_MODEL\",\n    \"LogStreamArn\": \"\",\n    \"OriginalMessage\": \"'application\/json' is an unsupported content type.\",\n    \"OriginalStatusCode\": 415\n}<\/code><\/p>\n\n<p>I tried looking for the trace logs in the cloud watch but no traces there as well. Anyone could guide me on this?<\/p>\n\n<p>I have trained a model using Sage Maker Studion.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1577447820647,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker",
            "awsdeploy"
        ],
        "Question_view_count":795.0,
        "Owner_creation_time":1402558101252,
        "Owner_last_access_time":1664028594572,
        "Owner_reputation":962.0,
        "Owner_up_votes":116.0,
        "Owner_down_votes":239.0,
        "Owner_views":283.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Hyderabad, Telangana, India",
        "Question_last_edit_time":1577450782780,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59500449",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  endpoint returns 415; content:<p>i have trained a multiclass classification model on the wine quality dataset and i have deployed the model.\nafter deploying the model i got endpoint url like:<\/p>\n\n<p><a href=\"https:\/\/runtime..region.amazonaws.com\/endpoints\/experiment\/invocations\" rel=\"nofollow noreferrer\">https:\/\/runtime..region.amazonaws.com\/endpoints\/experiment\/invocations<\/a><\/p>\n\n<p>and i am invoking the url after passing aws credentials and body like:<\/p>\n\n<p><code>{\n  \"instances\": [7.4,0.7,0,1.9,0.076,11,34,0.9978,3.51,0.56,9.4]\n}<\/code><\/p>\n\n<p>but i am getting below error:<\/p>\n\n<p><code>{\n    \"errorcode\": \"client_error_from_model\",\n    \"logstreamarn\": \"\",\n    \"originalmessage\": \"'application\/json' is an unsupported content type.\",\n    \"originalstatuscode\": 415\n}<\/code><\/p>\n\n<p>i tried looking for the trace logs in the cloud watch but no traces there as well. anyone could guide me on this?<\/p>\n\n<p>i have trained a model using sage maker studion.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving a 415 error when attempting to invoke an endpoint URL after passing AWS credentials and a body, and is unable to find trace logs in Cloud Watch."
    },
    {
        "Question_id":null,
        "Question_title":"Parameterlike dependencies",
        "Question_body":"<p>Hi,<br>\nI have a question about the following scenario:<br>\nLet data1 and data2 be two data folders, script.py a script and the command to run the script like: <code>python  script.py --datadir .\/df<\/code> where df is equal to data1 or data2.<br>\nWhat is a good way to setup the stage now? I thought about these options:<\/p>\n<ol>\n<li>one stage + make datadir a parameter -&gt; dvc will not update after changes in data1\/data2<\/li>\n<li>one stage + just one data folder -&gt; I have to checkout the right data all the time (for example tests) and maybe another script needs both folders at the same time.<\/li>\n<li>two stages, one for each datafolder -&gt; I would have to add extra argument \u201cstage\u201d to  script.py to load the right parameters.<\/li>\n<\/ol>\n<p>Is there a better way to do this?<\/p>\n<p>Thanks for your great work by the way : )<\/p>",
        "Question_answer_count":12,
        "Question_comment_count":null,
        "Question_creation_time":1606585276131,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":null,
        "Question_view_count":692.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/parameterlike-dependencies\/565",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":1254,
                "name":"Dmitry",
                "username":"dmitry",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/dmitry\/{size}\/7_2.png",
                "created_at":"2020-11-28T18:18:50.853Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/xyz\">@xyz<\/a><br>\nI\u2019d appreciate it if you could clarify the question a bit - what is the motivation to have two stages?<\/p>\n<ol>\n<li>Do you need two \u201cparallel\u201d stages in the pipeline or a sequence of the stages?<\/li>\n<li>Will you need two sets of parameters for each of the two runs?<\/li>\n<\/ol>\n<p>PS: More advanced pipeline parameterization functionality is coming in DVC 2.0 in a month or so. Now it is available only in test mode: <a href=\"https:\/\/github.com\/iterative\/dvc\/wiki\/Parametrization\">https:\/\/github.com\/iterative\/dvc\/wiki\/Parametrization<\/a><br>\nThe initial feature request: <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/3633\">https:\/\/github.com\/iterative\/dvc\/issues\/3633<\/a><\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2020-11-28T18:18:50.853Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":2,
                "reads":11,
                "readers_count":10,
                "score":32.2,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"Dmitry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/github.com\/iterative\/dvc\/wiki\/Parametrization",
                        "internal":false,
                        "reflection":false,
                        "title":"Parametrization \u00b7 iterative\/dvc Wiki \u00b7 GitHub",
                        "clicks":11
                    },
                    {
                        "url":"https:\/\/github.com\/iterative\/dvc\/issues\/3633",
                        "internal":false,
                        "reflection":false,
                        "title":"Pipeline variables from params file \u00b7 Issue #3633 \u00b7 iterative\/dvc \u00b7 GitHub",
                        "clicks":2
                    }
                ],
                "read":true,
                "user_title":"Regular",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":2,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1255,
                "name":"",
                "username":"xyz",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/b5a626\/{size}.png",
                "created_at":"2020-11-28T19:41:37.085Z",
                "cooked":"<p>Thank you for your fast reply. So the original motivation was to have a simple and fast way to test the script. I have a normal stage which is part of a pipeline and a test stage for the script. The test stage has its own small dataset and passes \u201cshort running\u201d parameters to the script.<\/p>\n<p>Then I wanted to introduce parameters  to the normal stage, but this would break the test stage. I think the answers to your questions are: rather parallel and yes.<br>\nI think I will look into the new parameterization api.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2020-11-28T19:41:37.085Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":11,
                "readers_count":10,
                "score":7.2,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"dmitry",
                    "name":"Dmitry",
                    "avatar_template":"\/user_avatar\/discuss.dvc.org\/dmitry\/{size}\/7_2.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":173,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1256,
                "name":"Dmitry",
                "username":"dmitry",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/dmitry\/{size}\/7_2.png",
                "created_at":"2020-11-28T19:49:29.967Z",
                "cooked":"<aside class=\"quote no-group\" data-username=\"xyz\" data-post=\"3\" data-topic=\"565\">\n<div class=\"title\">\n<div class=\"quote-controls\"><\/div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/b5a626\/40.png\" class=\"avatar\"> xyz:<\/div>\n<blockquote>\n<p>The test stage has its own small dataset and passes \u201cshort running\u201d parameters to the script.<\/p>\n<\/blockquote>\n<\/aside>\n<p>The new functionality should help you with that. Please let me know if it does not - we will try to make it work.<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2020-11-28T19:49:29.967Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":1,
                "incoming_link_count":1,
                "reads":12,
                "readers_count":11,
                "score":7.4,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"Dmitry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Regular",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":2,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1257,
                "name":"",
                "username":"xyz",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/b5a626\/{size}.png",
                "created_at":"2020-11-29T16:19:16.469Z",
                "cooked":"<p>Hello again ; ),<br>\nI tried the new parametrization tool and have a question now. My (simplified) dvc.yaml looks like this:<\/p>\n<pre><code class=\"lang-auto\">stages:\n  Submission:\n    foreach: ${submission}\n    do:\n      cmd: &gt;-\n        python submit.py ... \n      deps:\n      - ${item.datapath}\n      - submit.py\n      - ${item.model}\n      outs:\n      - ${item.outdir}:\n          cache: false\n<\/code><\/pre>\n<p>I have just one stage now and submission is either <code>test<\/code> or <code>normal<\/code>. It looks like dvc is still caching the outdir.  Is it correct that no caching is not supported yet? Will it be?<\/p>\n<p>Best wishes<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2020-11-29T16:19:16.469Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":12,
                "readers_count":11,
                "score":2.4,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/discuss.dvc.org\/t\/dvc-yaml-deps-outs-section-accessible-from-code\/577\/2",
                        "internal":true,
                        "reflection":true,
                        "title":"Dvc.yaml: `deps` & `outs` section accessible from code?",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":173,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1258,
                "name":"Dmitry",
                "username":"dmitry",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/dmitry\/{size}\/7_2.png",
                "created_at":"2020-11-29T20:45:19.110Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/xyz\">@xyz<\/a>!<\/p>\n<p>Could you please clarify what do you mean by caching? Don\u2019t you want to have this file in your cache and storage?<\/p>\n<p><code>cache: false<\/code> in the outputs means the output is not tracked by DVC and should be committed to Git. It was mostly created to small files that you\u2019d prefer to commit. It feels like your goal is a bit different. I\u2019d appreciate your clarification.<\/p>",
                "post_number":6,
                "post_type":1,
                "updated_at":"2020-11-29T20:45:19.110Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":11,
                "readers_count":10,
                "score":2.2,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"Dmitry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Regular",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":2,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1259,
                "name":"",
                "username":"xyz",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/b5a626\/{size}.png",
                "created_at":"2020-11-29T21:52:32.918Z",
                "cooked":"<p><code>datapath<\/code> is a folder with 7GB and script.py produces a folder <code>outdir<\/code> with 7GB. I want that dvc tracks the hashsum\/s of <code>outdir<\/code> but not the files themselves . Like the -O option in <code>dvc run<\/code> as far as I understand. But it seems that the files are copied to the .cache as it constantly grows by several GB.<\/p>",
                "post_number":7,
                "post_type":1,
                "updated_at":"2020-11-29T21:52:32.918Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":12,
                "readers_count":11,
                "score":12.4,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":173,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1260,
                "name":"Dmitry",
                "username":"dmitry",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/dmitry\/{size}\/7_2.png",
                "created_at":"2020-11-29T22:28:44.304Z",
                "cooked":"<p>Thank you. Now I understand your use case better.<\/p>\n<p>In your yaml file you clearly say <code>cache: false<\/code> - it should <strong>not<\/strong> go to the cache dir. Have you checked if that is the result of these stages and not the downstream ones? You can check that by trying to find datafiles in <code>.dvc\/cache\/<\/code> by the md5 from <code>dvc.lock<\/code>.<\/p>\n<p><img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/thinking.png?v=9\" title=\":thinking:\" class=\"emoji\" alt=\":thinking:\"> It might be just a bug in new pipelines or in run-cache. <a class=\"mention\" href=\"\/u\/skshetry\">@skshetry<\/a> &amp; <a class=\"mention\" href=\"\/u\/kupruser\">@kupruser<\/a> I\u2019d appreciate it if you guys could take a look.<\/p>",
                "post_number":8,
                "post_type":1,
                "updated_at":"2020-11-29T22:28:44.304Z",
                "reply_count":0,
                "reply_to_post_number":7,
                "quote_count":0,
                "incoming_link_count":11,
                "reads":12,
                "readers_count":11,
                "score":57.4,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"Dmitry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Regular",
                "title_is_group":false,
                "reply_to_user":{
                    "username":"xyz",
                    "name":"",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/b5a626\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":2,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1261,
                "name":"",
                "username":"skshetry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/eb8c5e\/{size}.png",
                "created_at":"2020-11-30T03:34:38.223Z",
                "cooked":"<p><code>cache: false<\/code> is a bit misleading, as it still tries to cache the results for the run-cache.<br>\nIt will only prevent pushing those artifacts right now.  There\u2019s <code>--no-run-cache<\/code> option that<br>\nwill skip using run-cache, but it still tries to save the run-cache.<\/p>\n<aside class=\"onebox githubissue\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/4428\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com\/iterative\/dvc<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewBox=\"0 0 14 16\" aria-hidden=\"true\"><path d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/4428\" target=\"_blank\" rel=\"noopener nofollow ugc\">DVC Repro incorrectly saving directory to cache<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-08-19\" data-time=\"21:15:01\" data-timezone=\"UTC\">09:15PM - 19 Aug 20 UTC<\/span>\n      <\/div>\n\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/digitalillusions\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"digitalillusions\" src=\"https:\/\/avatars2.githubusercontent.com\/u\/13047446?v=4\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          digitalillusions\n        <\/a>\n      <\/div>\n    <\/div>\n  <\/div>\n<\/div>\n\n<div class=\"github-row\">\n  <p class=\"github-content\">Bug Report\nAs the title states. I run dvc repro extract for my extract pipeline stage. This takes two pretty large zip...<\/p>\n<\/div>\n\n<div class=\"labels\">\n    <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">feature request<\/span>\n    <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">p2-medium<\/span>\n<\/div>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n",
                "post_number":9,
                "post_type":1,
                "updated_at":"2020-11-30T03:34:38.223Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":10,
                "readers_count":9,
                "score":7.0,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/github.com\/iterative\/dvc\/issues\/4428",
                        "internal":false,
                        "reflection":false,
                        "title":"DVC Repro incorrectly saving directory to cache \u00b7 Issue #4428 \u00b7 iterative\/dvc \u00b7 GitHub",
                        "clicks":3
                    },
                    {
                        "url":"https:\/\/github.com\/digitalillusions",
                        "internal":false,
                        "reflection":false,
                        "title":"digitalillusions (Stefan Jeske) \u00b7 GitHub",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":147,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1269,
                "name":"",
                "username":"xyz",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/b5a626\/{size}.png",
                "created_at":"2020-12-04T16:43:28.651Z",
                "cooked":"<p>Thank you for your answer as well. This explains lots of the behavior, but I\u2019m still confused. I always thought it worked like this:<\/p>\n<ul>\n<li>\n<code>dvc run -o file ...<\/code>: git like versioning of <code>file<\/code> (I would call this strong versioning). <code>file<\/code> can be restored from archive\/.cache<\/li>\n<li>\n<code>dvc run -O file ...<\/code>: I would call this weak versioning. If the pipeline is deterministic, <code>file<\/code> can get restored by running the pipeline again. Changes are detected by storing hashsums. Typical tradeoff between memory and time.<\/li>\n<\/ul>\n<p>Did this change in 1.0?<\/p>\n<p>I ran <code>dvc run -n test  -O hello.txt --no-run-cache  \"echo hello &gt; hello.txt\"<\/code>. Is it correct that the corresponding stage in the <code>dvc.yaml<\/code> doesn\u2019t change at all? Will this limit the memory usage now?<\/p>\n<pre><code class=\"lang-auto\">  test:\n    cmd: echo hello &gt; hello.txt\n    outs:\n    - hello.txt:\n        cache: false\n<\/code><\/pre>\n<p>I have to say, that it never crossed my mind that this option (<code>-O<\/code>) is for small git versioned files.<\/p>",
                "post_number":10,
                "post_type":1,
                "updated_at":"2020-12-04T16:43:28.651Z",
                "reply_count":0,
                "reply_to_post_number":9,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":8,
                "readers_count":7,
                "score":1.6,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"skshetry",
                    "name":"",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/eb8c5e\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":173,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1280,
                "name":"Pawe\u0142",
                "username":"Paffciu",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/d07c76\/{size}.png",
                "created_at":"2020-12-09T08:31:50.451Z",
                "cooked":"<p><a class=\"mention\" href=\"\/u\/xyz\">@xyz<\/a><\/p>\n<blockquote>\n<p>Changes are detected by storing hashsums. Typical tradeoff between memory and time.<\/p>\n<\/blockquote>\n<p>This did not change in 1.0. Checksum are now stored in <code>dvc.lock<\/code>. Regretfully, as its mentioned in the issue posted by <a class=\"mention\" href=\"\/u\/skshetry\">@skshetry<\/a> dvc still tries to make use of <code>run cache<\/code>, feature introduced in 1.0.<br>\nCan I ask you to comment there that you have issues with that too? It seems like a bug to me. I already wrote a comment there.<\/p>",
                "post_number":11,
                "post_type":1,
                "updated_at":"2020-12-09T08:31:50.451Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":8,
                "readers_count":7,
                "score":6.6,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"Pawe\u0142",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":79,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1294,
                "name":"",
                "username":"xyz",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/b5a626\/{size}.png",
                "created_at":"2020-12-11T17:33:44.776Z",
                "cooked":"<p>Hi,<br>\nwith my last answer I just wanted to tell what I think how things should work. Just to clarify: The checksums are calculated and saved correctly. Basically all I want is to limit the disk space for stages that are deterministic and produce big data folders. ( I know that I can use the garbage collection command. ) Do you want me to make a comment in the mentioned issue?<br>\nThanks again <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/grinning.png?v=9\" title=\":grinning:\" class=\"emoji\" alt=\":grinning:\"><\/p>",
                "post_number":12,
                "post_type":1,
                "updated_at":"2020-12-11T17:38:47.400Z",
                "reply_count":0,
                "reply_to_post_number":11,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":8,
                "readers_count":7,
                "score":1.6,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":2,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"Paffciu",
                    "name":"Pawe\u0142",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/d07c76\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":173,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1296,
                "name":"Pawe\u0142",
                "username":"Paffciu",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/d07c76\/{size}.png",
                "created_at":"2020-12-12T09:15:10.765Z",
                "cooked":"<p><a class=\"mention\" href=\"\/u\/xyz\">@xyz<\/a> sure! Usually we discuss validity, their importance and how severe they are and if we know particular use cases its much easier to estimate.<\/p>",
                "post_number":13,
                "post_type":1,
                "updated_at":"2020-12-12T09:15:10.765Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":8,
                "readers_count":7,
                "score":1.6,
                "yours":false,
                "topic_id":565,
                "topic_slug":"parameterlike-dependencies",
                "display_username":"Pawe\u0142",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":79,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: parameterlike dependencies; content:<p>hi,<br>\ni have a question about the following scenario:<br>\nlet data1 and data2 be two data folders, script.py a script and the command to run the script like: <code>python  script.py --datadir .\/df<\/code> where df is equal to data1 or data2.<br>\nwhat is a good way to setup the stage now? i thought about these options:<\/p>\n<ol>\n<li>one stage + make datadir a parameter -&gt;  will not update after changes in data1\/data2<\/li>\n<li>one stage + just one data folder -&gt; i have to checkout the right data all the time (for example tests) and maybe another script needs both folders at the same time.<\/li>\n<li>two stages, one for each datafolder -&gt; i would have to add extra argument \u201cstage\u201d to  script.py to load the right parameters.<\/li>\n<\/ol>\n<p>is there a better way to do this?<\/p>\n<p>thanks for your great work by the way : )<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking for advice on how to best set up a scenario where they have two data folders, a script, and a command to run the script with a parameter that can be either data1 or data2."
    },
    {
        "Question_id":59873804.0,
        "Question_title":"Error 0085 while executing python script in Azure Web service but not in ML Experiment",
        "Question_body":"<p>My workflow is running perfect on Experimentation, but after deployed to web service, I receive this error while post.<\/p>\n\n<p>Python Code:<\/p>\n\n<pre><code># -*- coding: utf-8 -*-\n\n#import sys\nimport pickle\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree \n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    print('input dataframe1 ',dataframe1)\n    decision_tree_pkl_predictive_maint = r'.\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl'\n\n    #sys.path.insert(0,\".\\Script Bundle\")\n    #model = pickle.load(open(\".\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl\", 'rb'))\n\n    modle_file = open(decision_tree_pkl_predictive_maint,\"rb\")\n    model = pickle.load(modle_file)\n\n    #return the mode of prediciton\n    result = model.predict(dataframe1)\n    print(result)\n    result_df = pd.DataFrame({'prediction_class':result})\n    return result_df,\n<\/code><\/pre>\n\n<p>ERROR:<\/p>\n\n<p>Execute Python Script RRS : Error 0085: The following error occurred during script evaluation, please view the output log for more information: ---------- Start of error message from Python interpreter ---------- Caught exception while executing function: Traceback (most recent call last): File \"\\server\\InvokePy.py\", line 120, in executeScript outframe = mod.azureml_main(*inframes) File \"\\temp-1036260731852293620.py\", line 46, in azureml_main modle_file = open(decision_tree_pkl_predictive_maint,\"rb\") FileNotFoundError: [Errno 2] No such file or directory: '.\\Script Bundle\\decision_tree_pkl_predictive_maint.pkl' ---------- End of error message from Python interpreter ----------<\/p>\n\n<p>Please, Advice.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1579766106190,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure",
            "machine-learning",
            "azure-web-app-service",
            "azure-machine-learning-studio",
            "azure-machine-learning-service"
        ],
        "Question_view_count":215.0,
        "Owner_creation_time":1554724240183,
        "Owner_last_access_time":1664041243347,
        "Owner_reputation":29.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":16.0,
        "Answer_body":"<p>The issue has to do with your file path. Ensure that you have included the correct path.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1580091525612,
        "Answer_score":0.0,
        "Owner_location":"Bangalore, Karnataka, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59873804",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: error 0085 while executing python script in azure web service but not in ml experiment; content:<p>my workflow is running perfect on experimentation, but after deployed to web service, i receive this error while post.<\/p>\n\n<p>python code:<\/p>\n\n<pre><code># -*- coding: utf-8 -*-\n\n#import sys\nimport pickle\nimport pandas as pd\nfrom sklearn.tree import decisiontreeclassifier\nfrom sklearn import tree \n\ndef _main(dataframe1 = none, dataframe2 = none):\n    print('input dataframe1 ',dataframe1)\n    decision_tree_pkl_predictive_maint = r'.\\script bundle\\decision_tree_pkl_predictive_maint.pkl'\n\n    #sys.path.insert(0,\".\\script bundle\")\n    #model = pickle.load(open(\".\\script bundle\\decision_tree_pkl_predictive_maint.pkl\", 'rb'))\n\n    modle_file = open(decision_tree_pkl_predictive_maint,\"rb\")\n    model = pickle.load(modle_file)\n\n    #return the mode of prediciton\n    result = model.predict(dataframe1)\n    print(result)\n    result_df = pd.dataframe({'prediction_class':result})\n    return result_df,\n<\/code><\/pre>\n\n<p>error:<\/p>\n\n<p>execute python script rrs : error 0085: the following error occurred during script evaluation, please view the output log for more information: ---------- start of error message from python interpreter ---------- caught exception while executing function: traceback (most recent call last): file \"\\server\\invokepy.py\", line 120, in executescript outframe = mod._main(*inframes) file \"\\temp-1036260731852293620.py\", line 46, in _main modle_file = open(decision_tree_pkl_predictive_maint,\"rb\") filenotfounderror: [errno 2] no such file or directory: '.\\script bundle\\decision_tree_pkl_predictive_maint.pkl' ---------- end of error message from python interpreter ----------<\/p>\n\n<p>please, advice.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error 0085 while executing a python script in Azure Web Service, but not in ML Experiment. The error is due to a missing file in the script bundle."
    },
    {
        "Question_id":68718719.0,
        "Question_title":"How can I retrive the model.pkl in the experiment in Databricks",
        "Question_body":"<p>I want to retrieve the pickle off my trained model, which I know is in the run file inside my experiments in Databricks.<\/p>\n<p>It seems that the <code>mlflow.pyfunc.load_model<\/code> can only do the <code>predict<\/code> method.<\/p>\n<p>There is an option to directly access the pickle?<\/p>\n<p>I also tried to use the path in the run using the <code>pickle.load(path)<\/code> (example of path: dbfs:\/databricks\/mlflow-tracking\/20526156406\/92f3ec23bf614c9d934dd0195\/artifacts\/model\/model.pkl).<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1628544411170,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "azure",
            "databricks",
            "datastore",
            "mlflow"
        ],
        "Question_view_count":3081.0,
        "Owner_creation_time":1522076554448,
        "Owner_last_access_time":1663901377960,
        "Owner_reputation":96.0,
        "Owner_up_votes":10.0,
        "Owner_down_votes":0.0,
        "Owner_views":31.0,
        "Answer_body":"<p>I recently found the solution which can be done by the following two approaches:<\/p>\n<ol>\n<li>Use the customized predict function at the moment of saving the model (check <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#model-customization\" rel=\"nofollow noreferrer\">databricks<\/a> documentation for more details).<\/li>\n<\/ol>\n<p>example give by Databricks<\/p>\n<pre><code>class AddN(mlflow.pyfunc.PythonModel):\n\n    def __init__(self, n):\n        self.n = n\n\n    def predict(self, context, model_input):\n        return model_input.apply(lambda column: column + self.n)\n# Construct and save the model\nmodel_path = &quot;add_n_model&quot;\nadd5_model = AddN(n=5)\nmlflow.pyfunc.save_model(path=model_path, python_model=add5_model)\n\n# Load the model in `python_function` format\nloaded_model = mlflow.pyfunc.load_model(model_path)\n<\/code><\/pre>\n<ol start=\"2\">\n<li>Load the model artefacts as we are downloading the artefact:<\/li>\n<\/ol>\n<pre><code>from mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\n\ntmp_path = client.download_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path='model\/model.pkl')\n\nf = open(tmp_path,'rb')\n\nmodel = pickle.load(f)\n\nf.close()\n\n \n\nclient.list_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path=&quot;&quot;)\n\nclient.list_artifacts(run_id=&quot;0c7946c81fb64952bc8ccb3c7c66bca3&quot;, path=&quot;model&quot;)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1629748421287,
        "Answer_score":1.0,
        "Owner_location":"S\u00e3o Paulo, State of S\u00e3o Paulo, Brazil",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":1643054905512,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68718719",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how can i retrive the model.pkl in the experiment in databricks; content:<p>i want to retrieve the pickle off my trained model, which i know is in the run file inside my experiments in databricks.<\/p>\n<p>it seems that the <code>.pyfunc.load_model<\/code> can only do the <code>predict<\/code> method.<\/p>\n<p>there is an option to directly access the pickle?<\/p>\n<p>i also tried to use the path in the run using the <code>pickle.load(path)<\/code> (example of path: dbfs:\/databricks\/-tracking\/20526156406\/92f3ec23bf614c9d934dd0195\/artifacts\/model\/model.pkl).<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to retrieve the pickle of their trained model from the run file inside their experiments in Databricks, and is wondering if there is an option to directly access the pickle or if they can use the path in the run to do so."
    },
    {
        "Question_id":65322286.0,
        "Question_title":"AWS Sagemaker inference endpoint doesn't scale in with autoscaling",
        "Question_body":"<p>I have an AWS Sagemaker inference endpoint with autoscaling enabled with SageMakerVariantInvocationsPerInstance target metric. When I send a lot of requests to the endpoint the number of instances correctly scales out to the maximum instance count. But after I stop sending the requests the number of instances doesn't scale in to 1, minimum instance count. I waited for many hours. Is there a reason for this behaviour?<\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1608117787513,
        "Question_favorite_count":1.0,
        "Question_score":2.0,
        "Question_tags":[
            "autoscaling",
            "amazon-sagemaker",
            "aws-auto-scaling"
        ],
        "Question_view_count":1028.0,
        "Owner_creation_time":1382978984190,
        "Owner_last_access_time":1664012645480,
        "Owner_reputation":1311.0,
        "Owner_up_votes":149.0,
        "Owner_down_votes":0.0,
        "Owner_views":49.0,
        "Answer_body":"<p>AutoScaling requires a cloudwatch alarm to trigger to scale in.  Sagemaker doesn't push 0 value metrics when there's no activity (it just doesn't push anything).  This leads to the alarm being put into insufficient data and not triggering the autoscaling scale in action when your workload suddenly ends.<\/p>\n<p>Workarounds are either:<\/p>\n<ol>\n<li>Have a step scaling policy using the cloudwatch metric math FILL() function for your scale in.  This way you can tell CloudWatch &quot;if there's no data, pretend this was the metric value when evaluating the alarm.  This is only possible with step scaling since target tracking creates the alarms for you (and AutoScaling will periodically recreate them, so if you make manual changes they'll get deleted)<\/li>\n<li>Have scheduled scaling set the size back down to 1 every evening<\/li>\n<li>Make sure traffic continues at a low level for some times<\/li>\n<\/ol>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1608300540056,
        "Answer_score":5.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65322286",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  inference endpoint doesn't scale in with autoscaling; content:<p>i have an  inference endpoint with autoscaling enabled with variantinvocationsperinstance target metric. when i send a lot of requests to the endpoint the number of instances correctly scales out to the maximum instance count. but after i stop sending the requests the number of instances doesn't scale in to 1, minimum instance count. i waited for many hours. is there a reason for this behaviour?<\/p>\n<p>thanks<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user has an inference endpoint with autoscaling enabled, but the number of instances does not scale in to the minimum instance count after the requests stop."
    },
    {
        "Question_id":71454995.0,
        "Question_title":"Getting the error \"str' object has no attribute 'decode\" when trying to use custom weights for image classification",
        "Question_body":"<p>I am trying to develop a simple image classification model in Azure ML notebooks. ResNet50 model was trained and the custom weights from the model is being used in the following code for image classification. The custom weights are saved in a folder called Model.<\/p>\n<pre><code>import os\nworking_directory = os.getcwd()\nmodel_directory = working_directory + &quot;\/Model\/model.h5&quot; \n<\/code><\/pre>\n<p>The above code is being used for accessing the saved model.<\/p>\n<pre><code>def classifyingImages(image_list):\n    value = 0\n\n    for image in image_list:\n        image_resized = cv2.resize(image, (img_height, img_width))\n        image = np.expand_dims(image_resized, axis=0)\n\n        \n        model = load_model(model_directory)\n        #classifying the image\n        prediction = model.predict(image)\n        output_class = class_names[np.argmax(prediction)]\n\n        #getting the image name\n        image_name = img_name_list[value]\n        print(image_name)\n\n        if(np.argmax(prediction)==0):\n            print(&quot;check negative&quot;)\n            # cv2.imwrite((negative_path+&quot;\/&quot;+image_name), image)\n        else:\n            print(&quot;check positive&quot;)\n            # cv2.imwrite((path_positive+&quot;\/&quot;+image_name), image)\n\n        value = value +1\n\n\n    return value\n\nclassifyingImages(image_list)\n<\/code><\/pre>\n<p>The code added above is the image classification code<\/p>\n<p>The <code>image_list<\/code> contains the test images which saved in the blob storage.<\/p>\n<p>After running the classification function i get the error <code>str' object has no attribute 'decode<\/code> and as a solution i tried to change the h5py lib version using below code. But still it gives me the same error. It would be great if i could a solution for this issue. Thank you in advance.\n<code>!pip install h5py==2.10.0<\/code><\/p>\n<p>The stack trace<\/p>\n<pre><code>AttributeError                            Traceback (most recent call last)\n&lt;ipython-input-96-6e38a2f74291&gt; in &lt;module&gt;\n     42     return value\n     43 \n---&gt; 44 classifyingImages(image_list)\n\n&lt;ipython-input-96-6e38a2f74291&gt; in classifyingImages(image_list)\n     20         print(image.dtype)\n     21 \n---&gt; 22         model = load_model(model_directory)\n     23 \n     24         #classifying the image\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/saving\/save.py in load_model(filepath, custom_objects, compile)\n    144   if (h5py is not None and (\n    145       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n--&gt; 146     return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\n    147 \n    148   if isinstance(filepath, six.string_types):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/saving\/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)\n    164     if model_config is None:\n    165       raise ValueError('No model found in config file.')\n--&gt; 166     model_config = json.loads(model_config.decode('utf-8'))\n    167     model = model_config_lib.model_from_config(model_config,\n    168                                                custom_objects=custom_objects)\n\nAttributeError: 'str' object has no attribute 'decode'\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":9.0,
        "Question_creation_time":1647159554620,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "tensorflow",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":68.0,
        "Owner_creation_time":1556718046720,
        "Owner_last_access_time":1662885742376,
        "Owner_reputation":25.0,
        "Owner_up_votes":14.0,
        "Owner_down_votes":0.0,
        "Owner_views":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"1040\/3 Athurugiriya Road, Malabe, Sri Lanka",
        "Question_last_edit_time":1647162639363,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71454995",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: getting the error \"str' object has no attribute 'decode\" when trying to use custom weights for image classification; content:<p>i am trying to develop a simple image classification model in  notebooks. resnet50 model was trained and the custom weights from the model is being used in the following code for image classification. the custom weights are saved in a folder called model.<\/p>\n<pre><code>import os\nworking_directory = os.getcwd()\nmodel_directory = working_directory + &quot;\/model\/model.h5&quot; \n<\/code><\/pre>\n<p>the above code is being used for accessing the saved model.<\/p>\n<pre><code>def classifyingimages(image_list):\n    value = 0\n\n    for image in image_list:\n        image_resized = cv2.resize(image, (img_height, img_width))\n        image = np.expand_dims(image_resized, axis=0)\n\n        \n        model = load_model(model_directory)\n        #classifying the image\n        prediction = model.predict(image)\n        output_class = class_names[np.argmax(prediction)]\n\n        #getting the image name\n        image_name = img_name_list[value]\n        print(image_name)\n\n        if(np.argmax(prediction)==0):\n            print(&quot;check negative&quot;)\n            # cv2.imwrite((negative_path+&quot;\/&quot;+image_name), image)\n        else:\n            print(&quot;check positive&quot;)\n            # cv2.imwrite((path_positive+&quot;\/&quot;+image_name), image)\n\n        value = value +1\n\n\n    return value\n\nclassifyingimages(image_list)\n<\/code><\/pre>\n<p>the code added above is the image classification code<\/p>\n<p>the <code>image_list<\/code> contains the test images which saved in the blob storage.<\/p>\n<p>after running the classification function i get the error <code>str' object has no attribute 'decode<\/code> and as a solution i tried to change the h5py lib version using below code. but still it gives me the same error. it would be great if i could a solution for this issue. thank you in advance.\n<code>!pip install h5py==2.10.0<\/code><\/p>\n<p>the stack trace<\/p>\n<pre><code>attributeerror                            traceback (most recent call last)\n&lt;ipython-input-96-6e38a2f74291&gt; in &lt;module&gt;\n     42     return value\n     43 \n---&gt; 44 classifyingimages(image_list)\n\n&lt;ipython-input-96-6e38a2f74291&gt; in classifyingimages(image_list)\n     20         print(image.dtype)\n     21 \n---&gt; 22         model = load_model(model_directory)\n     23 \n     24         #classifying the image\n\n\/anaconda\/envs\/_py36\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/saving\/save.py in load_model(filepath, custom_objects, compile)\n    144   if (h5py is not none and (\n    145       isinstance(filepath, h5py.file) or h5py.is_hdf5(filepath))):\n--&gt; 146     return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\n    147 \n    148   if isinstance(filepath, six.string_types):\n\n\/anaconda\/envs\/_py36\/lib\/python3.6\/site-packages\/tensorflow_core\/python\/keras\/saving\/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)\n    164     if model_config is none:\n    165       raise valueerror('no model found in config file.')\n--&gt; 166     model_config = json.loads(model_config.decode('utf-8'))\n    167     model = model_config_lib.model_from_config(model_config,\n    168                                                custom_objects=custom_objects)\n\nattributeerror: 'str' object has no attribute 'decode'\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is getting the error \"str' object has no attribute 'decode\" when trying to use custom weights for image classification, and has attempted to change the h5py lib version but is still getting the same error."
    },
    {
        "Question_id":null,
        "Question_title":"where to find the equation for the line after making Azure ML linear regression model, 2 slopes and 1 y intercept",
        "Question_body":"Hi, I've made a model and it's predicting prices of cars. hooray! I cannot find the the equation for Azure's Regression Linear model anywhere. I made this model using Designer GUI. For example, in R, the coefficients are returned by running summary(mymodel)\n= y-intercept + (slope miles) + (slope year)\n= 21022.96 + (-0.0249*98500) + (-6.5668*2016)\nsomething like this equation for a line is what I'm looking for in Azure.\n\nwhat I've tried:\n1. If it was only 1 feature, I could solve for an equation using (y2-y1) \/ (miles2-miles1) to find slope and the solve to y intercept. But this model uses miles and year as variables.",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_creation_time":1626236136657,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/474924\/where-to-find-the-equation-for-the-line-after-maki.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-14T15:44:15.03Z",
                "Answer_score":0,
                "Answer_body":"@@MikeRichardson-3493 Thanks, We currently do not have coefficients for regression models, but we will forward this with our data science team to check on this. We are working on an interface to surface models that compose ensembles, model weights and more. While not as involved of an interface, some of this information is available today within the model details tags sections:.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-07-14T21:43:48.24Z",
                "Answer_score":1,
                "Answer_body":"ok, thanks. If I understand correctly, I could make this model an ensemble model containing two algorithms, that each use one factor\/feature variable, and then this would allow me to add weights at each model. And the calculation of the equation can be made if it's linear regression on one feature. I will look forward to trying this. Thanks for the insight.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: where to find the equation for the line after making  linear regression model, 2 slopes and 1 y intercept; content:hi, i've made a model and it's predicting prices of cars. hooray! i cannot find the the equation for azure's regression linear model anywhere. i made this model using designer gui. for example, in r, the coefficients are returned by running summary(mymodel)\n= y-intercept + (slope miles) + (slope year)\n= 21022.96 + (-0.0249*98500) + (-6.5668*2016)\nsomething like this equation for a line is what i'm looking for in azure.\n\nwhat i've tried:\n1. if it was only 1 feature, i could solve for an equation using (y2-y1) \/ (miles2-miles1) to find slope and the solve to y intercept. but this model uses miles and year as variables.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for an equation for the line after making an Azure ML linear regression model with two slopes and one y-intercept, and has tried solving for the slope and y-intercept using the difference between two points."
    },
    {
        "Question_id":71256030.0,
        "Question_title":"Random cut forest anomaly detection on multi variant without time series data",
        "Question_body":"<p>I went through various article\/blog on aws sagemaker unsupervised ml algo called random cut forest, i saw all the examples are based on time series data, i have a doubt, is random cut forest detects anomaly only on time series data or can it detect anomaly from data sample with multi variant none time series data also?\nMy use case to detect based on detecting anomaly based on sudden increase in specific event for eg<\/p>\n<pre><code>event1,event2,event3,device\n100,1,1,device1\n1,100,100,device2\n1,1,1,device3\n<\/code><\/pre>\n<p>In this case, anomaly detection algo should predict anomaly for device1 and device2<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1645724169663,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "random-forest",
            "amazon-sagemaker",
            "anomaly-detection"
        ],
        "Question_view_count":115.0,
        "Owner_creation_time":1587528475872,
        "Owner_last_access_time":1654106451800,
        "Owner_reputation":131.0,
        "Owner_up_votes":9.0,
        "Owner_down_votes":0.0,
        "Owner_views":27.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1645724669963,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71256030",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: random cut forest anomaly detection on multi variant without time series data; content:<p>i went through various article\/blog on  unsupervised ml algo called random cut forest, i saw all the examples are based on time series data, i have a doubt, is random cut forest detects anomaly only on time series data or can it detect anomaly from data sample with multi variant none time series data also?\nmy use case to detect based on detecting anomaly based on sudden increase in specific event for eg<\/p>\n<pre><code>event1,event2,event3,device\n100,1,1,device1\n1,100,100,device2\n1,1,1,device3\n<\/code><\/pre>\n<p>in this case, anomaly detection algo should predict anomaly for device1 and device2<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if Random Cut Forest anomaly detection can be used on multi-variant data without time series data, and if it can detect anomalies based on sudden increases in specific events."
    },
    {
        "Question_id":null,
        "Question_title":"Excessive Memory use when deploying PipelineModel using the pre-build Scikit container in Sagemaker",
        "Question_body":"I am using the pre-build Scikit container in Sagemaker to deploy an endpoint based on a model that contains a 59.4 MB model.tar.gz file. The following line was used to deploy the endpoint:\n\nsm_model.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\", endpoint_name=endpoint_name)\n\nHowever, the after the endpoint was created, it fails to allocate memory to works. These error messages and warnings keep showing in the logs:\n\n[Errno 12] Cannot allocate memory [WARNING] Worker with pid 242 was terminated due to signal 9\n\nAs far as I know, the xlarge instance has 16 GB of memory. The endpoint memory usage is at 60% while it still fails to allocate memory to workers. May I ask if anyone has any insight on why this is happening and how to solve this issue without using an instance that has more memory?",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1663945337107,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Machine Learning & AI",
            "Containers"
        ],
        "Question_view_count":17.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU2hdNVBreSFyX1iSPDRPMXw\/excessive-memory-use-when-deploying-pipeline-model-using-the-pre-build-scikit-container-in-sagemaker",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI",
            "Containers"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: excessive memory use when deploying pipelinemodel using the pre-build scikit container in ; content:i am using the pre-build scikit container in  to deploy an endpoint based on a model that contains a 59.4 mb model.tar.gz file. the following line was used to deploy the endpoint:\n\nsm_model.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\", endpoint_name=endpoint_name)\n\nhowever, the after the endpoint was created, it fails to allocate memory to works. these error messages and warnings keep showing in the logs:\n\n[errno 12] cannot allocate memory [warning] worker with pid 242 was terminated due to signal 9\n\nas far as i know, the xlarge instance has 16 gb of memory. the endpoint memory usage is at 60% while it still fails to allocate memory to workers. may i ask if anyone has any insight on why this is happening and how to solve this issue without using an instance that has more memory?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing excessive memory use when deploying a pipelinemodel using the pre-build scikit container, despite the instance type having 16GB of memory."
    },
    {
        "Question_id":null,
        "Question_title":"ClientError: An error occurred (UnknownOperationException) when calling the CreateHyperParameterTuningJob operation: The requested operation is not supported in the called region.",
        "Question_body":"Hi Dears,\n\nI am building ML model using DeepAR Algorithm.\n\nI faced this error while i reached to this point : Error :\n\nClientError: An error occurred (UnknownOperationException) when calling the CreateHyperParameterTuningJob operation: The requested operation is not supported in the called region.\n\nCode: from sagemaker.tuner import ( IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner, ) from sagemaker import image_uris\n\ncontainer = image_uris.retrieve(region= 'af-south-1', framework=\"forecasting-deepar\")\n\ndeepar = sagemaker.estimator.Estimator( container, role, instance_count=1, instance_type=\"ml.m5.2xlarge\", use_spot_instances=True, # use spot instances max_run=1800, # max training time in seconds max_wait=1800, # seconds to wait for spot instance output_path=\"s3:\/\/{}\/{}\".format(bucket, output_path), sagemaker_session=sess, ) freq = \"D\" context_length = 300\n\ndeepar.set_hyperparameters( time_freq=freq, context_length=str(context_length), prediction_length=str(prediction_length) )\n\nCan you please help in solving the error? I have to do that in af-south-1 region.\n\nThanks Basem\n\nhyperparameter_ranges = { \"mini_batch_size\": IntegerParameter(100, 400), \"epochs\": IntegerParameter(200, 400), \"num_cells\": IntegerParameter(30, 100), \"likelihood\": CategoricalParameter([\"negative-binomial\", \"student-T\"]), \"learning_rate\": ContinuousParameter(0.0001, 0.1), }\n\nobjective_metric_name = \"test:RMSE\"\n\ntuner = HyperparameterTuner( deepar, objective_metric_name, hyperparameter_ranges, max_jobs=10, strategy=\"Bayesian\", objective_type=\"Minimize\", max_parallel_jobs=10, early_stopping_type=\"Auto\", )\n\ns3_input_train = sagemaker.inputs.TrainingInput( s3_data=\"s3:\/\/{}\/{}\/train\/\".format(bucket, prefix), content_type=\"json\" ) s3_input_test = sagemaker.inputs.TrainingInput( s3_data=\"s3:\/\/{}\/{}\/test\/\".format(bucket, prefix), content_type=\"json\" )\n\ntuner.fit({\"train\": s3_input_train, \"test\": s3_input_test}, include_cls_metadata=False) tuner.wait()",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1652655830031,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "AWS Command Line Interface",
            "Machine Learning & AI",
            "Spot Instances"
        ],
        "Question_view_count":135.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUkAwy2tG8QreIWmLTGIUAqg\/client-error-an-error-occurred-unknown-operation-exception-when-calling-the-create-hyper-parameter-tuning-job-operation-the-requested-operation-is-not-supported-in-the-called-region",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI",
            "Management & Governance",
            "Compute"
        ],
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-20T16:09:16.983Z",
                "Answer_score":0,
                "Answer_body":"The error message indicates that CreateHyperParameterTuningJob operation is not supported in the region you're currently using. If possible, try the notebook in a region that supports HPO jobs.",
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: clienterror: an error occurred (unknownoperationexception) when calling the createhyperparametertuningjob operation: the requested operation is not supported in the called region.; content:hi dears,\n\ni am building ml model using deepar algorithm.\n\ni faced this error while i reached to this point : error :\n\nclienterror: an error occurred (unknownoperationexception) when calling the createhyperparametertuningjob operation: the requested operation is not supported in the called region.\n\ncode: from .tuner import ( integerparameter, categoricalparameter, continuousparameter, hyperparametertuner, ) from  import image_uris\n\ncontainer = image_uris.retrieve(region= 'af-south-1', framework=\"forecasting-deepar\")\n\ndeepar = .estimator.estimator( container, role, instance_count=1, instance_type=\"ml.m5.2xlarge\", use_spot_instances=true, # use spot instances max_run=1800, # max training time in seconds max_wait=1800, # seconds to wait for spot instance output_path=\"s3:\/\/{}\/{}\".format(bucket, output_path), _session=sess, ) freq = \"d\" context_length = 300\n\ndeepar.set_hyperparameters( time_freq=freq, context_length=str(context_length), prediction_length=str(prediction_length) )\n\ncan you please help in solving the error? i have to do that in af-south-1 region.\n\nthanks basem\n\nhyperparameter_ranges = { \"mini_batch_size\": integerparameter(100, 400), \"epochs\": integerparameter(200, 400), \"num_cells\": integerparameter(30, 100), \"likelihood\": categoricalparameter([\"negative-binomial\", \"student-t\"]), \"learning_rate\": continuousparameter(0.0001, 0.1), }\n\nobjective_metric_name = \"test:rmse\"\n\ntuner = hyperparametertuner( deepar, objective_metric_name, hyperparameter_ranges, max_jobs=10, strategy=\"bayesian\", objective_type=\"minimize\", max_parallel_jobs=10, early_stopping_type=\"auto\", )\n\ns3_input_train = .inputs.traininginput( s3_data=\"s3:\/\/{}\/{}\/train\/\".format(bucket, prefix), content_type=\"json\" ) s3_input_test = .inputs.traininginput( s3_data=\"s3:\/\/{}\/{}\/test\/\".format(bucket, prefix), content_type=\"json\" )\n\ntuner.fit({\"train\": s3_input_train, \"test\": s3_input_test}, include_cls_metadata=false) tuner.wait()",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when attempting to create a hyperparameter tuning job in the af-south-1 region, and is asking for help in solving the issue."
    },
    {
        "Question_id":52294404.0,
        "Question_title":"R Server on Azure",
        "Question_body":"<p>I need to execute R code as webservice, so i tried MLS and it works ok. \nThe problem is that the packages are too old, and i need functions that are not implemented on old packages. \nI asked microsoft support about it, and they have no data up upgrade it, and the new packages require a upgrade of it.<\/p>\n\n<p>How can i do that using other resources, like webapi instead of MLS?\nAll solutions i found requires R installed on machine, wich is a problem for create an azure webapp, function, or api.\nI need an endpoint for forecast on-demand.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_creation_time":1536752847560,
        "Question_favorite_count":0.0,
        "Question_score":2.0,
        "Question_tags":[
            "r",
            "azure-web-app-service",
            "azure-functions",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":327.0,
        "Owner_creation_time":1515518171123,
        "Owner_last_access_time":1657119408507,
        "Owner_reputation":1108.0,
        "Owner_up_votes":33.0,
        "Owner_down_votes":2.0,
        "Owner_views":183.0,
        "Answer_body":"<p>I found one way to execute R on Azure functions.\nthe solutions is copy R-Portable in\n<a href=\"https:\/\/sourceforge.net\/projects\/rportable\/\" rel=\"nofollow noreferrer\">https:\/\/sourceforge.net\/projects\/rportable\/<\/a>\nunzip it using powershell and create a process on function code. In my case i used the code:<\/p>\n\n<pre><code>System.Diagnostics.Process process = new System.Diagnostics.Process();\n            process.StartInfo.WorkingDirectory = @\"D:\\home\\site\\tools\\R-Portable\\App\\R-Portable\\bin\\\";\n            process.StartInfo.FileName = @\"D:\\home\\site\\tools\\R-Portable\\App\\R-Portable\\bin\\Rscript.exe\";\n            process.StartInfo.Arguments = \"-e \\\"print('Hello world')\\\"\";\n            process.StartInfo.UseShellExecute = false;\n            process.StartInfo.RedirectStandardOutput = true;\n            process.StartInfo.RedirectStandardError = true;\n            process.Start();\n            string outputt = process.StandardOutput.ReadToEnd();\n            string err = process.StandardError.ReadToEnd();\n            process.WaitForExit();\n<\/code><\/pre>\n\n<p>On your script you can access csv files or write, and after on function read and return that file.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1537264424307,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52294404",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: r server on azure; content:<p>i need to execute r code as webservice, so i tried mls and it works ok. \nthe problem is that the packages are too old, and i need functions that are not implemented on old packages. \ni asked microsoft support about it, and they have no data up upgrade it, and the new packages require a upgrade of it.<\/p>\n\n<p>how can i do that using other resources, like webapi instead of mls?\nall solutions i found requires r installed on machine, wich is a problem for create an azure webapp, function, or api.\ni need an endpoint for forecast on-demand.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to execute R code as a webservice, but the packages are too old and they need functions that are not implemented. Microsoft support has no data to upgrade it, and the user is looking for other resources like webapi instead of mls, but all solutions require R installed on a machine, which is a problem for creating an Azure webapp, function, or API."
    },
    {
        "Question_id":66425213.0,
        "Question_title":"AWS Sagemaker Jupyter Notebook Stopped Printing",
        "Question_body":"<p>I have a Jupyter Notebook instance through AWS Sagemaker. My script runs two models, performing up to 48 jobs at once (this shouldn't be an issue for the instance size I selected). There are also lines on the script that print a short description of where it's at:<\/p>\n<pre><code>...    \nprint(&quot;Loading training data&quot;)\n...\nprint(&quot;Training model: Random Forest&quot;)\n...\nprint(&quot;Training model: K-Nearest Neighbors&quot;)\n...\n(etc.)\n<\/code><\/pre>\n<p>At one point, the number of tasks the instance was working declined and were eventually replaced with tasks that all began running around the same time, and have been running every since. I assume this means the random forest model has completed training, and the KNN one initiated training. However, it appears as though the notebook has stopped printing results.<\/p>\n<p>My question is, what am I experiencing? Did I do something that ceased the script printing? Will the script continue to run after the second model is done training, or will the script crash?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1614613595967,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "amazon-web-services",
            "jupyter-notebook",
            "amazon-sagemaker"
        ],
        "Question_view_count":172.0,
        "Owner_creation_time":1610727691040,
        "Owner_last_access_time":1644592822340,
        "Owner_reputation":77.0,
        "Owner_up_votes":79.0,
        "Owner_down_votes":0.0,
        "Owner_views":13.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66425213",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  jupyter notebook stopped printing; content:<p>i have a jupyter notebook instance through . my script runs two models, performing up to 48 jobs at once (this shouldn't be an issue for the instance size i selected). there are also lines on the script that print a short description of where it's at:<\/p>\n<pre><code>...    \nprint(&quot;loading training data&quot;)\n...\nprint(&quot;training model: random forest&quot;)\n...\nprint(&quot;training model: k-nearest neighbors&quot;)\n...\n(etc.)\n<\/code><\/pre>\n<p>at one point, the number of tasks the instance was working declined and were eventually replaced with tasks that all began running around the same time, and have been running every since. i assume this means the random forest model has completed training, and the knn one initiated training. however, it appears as though the notebook has stopped printing results.<\/p>\n<p>my question is, what am i experiencing? did i do something that ceased the script printing? will the script continue to run after the second model is done training, or will the script crash?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing a situation where their Jupyter Notebook instance has stopped printing results and they are unsure if they did something to cause this or if the script will continue to run after the second model is done training."
    },
    {
        "Question_id":69347001.0,
        "Question_title":"Sagemaker endpoint invalid when create_monitoring_schedule is called on the endpoint",
        "Question_body":"<p>I am following this github <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/tree\/master\/sagemaker_model_monitor\" rel=\"nofollow noreferrer\">repo<\/a>, adopting it to a text classification problem that is built on distil bert. So given a sting of text, the model should return a label and a (probability) score.\nOutput from the model:<\/p>\n<pre><code>sentiment_input = {&quot;inputs&quot;: &quot;I love using the new Inference DLC.&quot;}\n\n# sentiment_input= &quot;I love using the new Inference DLC.&quot;\n\nresponse = predictor.predict(data=sentiment_input)\nprint(response)\n<\/code><\/pre>\n<p>Output:<\/p>\n<blockquote>\n<p>[{'label': 'LABEL_80', 'score': 0.008507220074534416}]<\/p>\n<\/blockquote>\n<p>When I run the following<\/p>\n<pre><code># Create an enpointInput\nendpointInput = EndpointInput(\n    endpoint_name=predictor.endpoint_name,\n    probability_attribute=&quot;score&quot;,\n    inference_attribute=&quot;label&quot;,\n#     probability_threshold_attribute=0.5,\n    destination=&quot;\/opt\/ml\/processing\/input_data&quot;,\n)\n\n# Create the monitoring schedule to execute every hour.\nfrom sagemaker.model_monitor import CronExpressionGenerator\n\nresponse = clinc_intent0911.create_monitoring_schedule(\n    monitor_schedule_name=clincintent_monitor_schedule_name,\n    endpoint_input=endpointInput,\n    output_s3_uri=baseline_results_uri,\n    problem_type=&quot;MulticlassClassification&quot;,\n    ground_truth_input=ground_truth_upload_path,\n    constraints=baseline_job.suggested_constraints(),\n    schedule_cron_expression=CronExpressionGenerator.hourly(),\n    enable_cloudwatch_metrics=True,\n)\n<\/code><\/pre>\n<p>I get the following error:<\/p>\n<pre><code>---------------------------------------------------------------------------\nClientError                               Traceback (most recent call last)\n&lt;ipython-input-269-72e7049246fb&gt; in &lt;module&gt;\n     10     constraints=baseline_job.suggested_constraints(),\n     11     schedule_cron_expression=CronExpressionGenerator.hourly(),\n---&gt; 12     enable_cloudwatch_metrics=True,\n     13 )\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/sagemaker\/model_monitor\/model_monitoring.py in create_monitoring_schedule(self, endpoint_input, ground_truth_input, problem_type, record_preprocessor_script, post_analytics_processor_script, output_s3_uri, constraints, monitor_schedule_name, schedule_cron_expression, enable_cloudwatch_metrics)\n   2615             network_config=self.network_config,\n   2616         )\n-&gt; 2617         self.sagemaker_session.sagemaker_client.create_model_quality_job_definition(**request_dict)\n   2618 \n   2619         # create schedule\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/botocore\/client.py in _api_call(self, *args, **kwargs)\n    355                     &quot;%s() only accepts keyword arguments.&quot; % py_operation_name)\n    356             # The &quot;self&quot; in this scope is referring to the BaseClient.\n--&gt; 357             return self._make_api_call(operation_name, kwargs)\n    358 \n    359         _api_call.__name__ = str(py_operation_name)\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/botocore\/client.py in _make_api_call(self, operation_name, api_params)\n    674             error_code = parsed_response.get(&quot;Error&quot;, {}).get(&quot;Code&quot;)\n    675             error_class = self.exceptions.from_code(error_code)\n--&gt; 676             raise error_class(parsed_response, operation_name)\n    677         else:\n    678             return parsed_response\n\nClientError: An error occurred (ValidationException) when calling the CreateModelQualityJobDefinition operation: Endpoint 'clinc-intent-analysis-0911' does not exist or is not valid\n<\/code><\/pre>\n<p>At this point my sagemaker endpoint is live and unable to debug it is not valid.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1632747359567,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":106.0,
        "Owner_creation_time":1545311054088,
        "Owner_last_access_time":1663916183127,
        "Owner_reputation":170.0,
        "Owner_up_votes":113.0,
        "Owner_down_votes":2.0,
        "Owner_views":33.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69347001",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  endpoint invalid when create_monitoring_schedule is called on the endpoint; content:<p>i am following this github <a href=\"https:\/\/github.com\/aws\/amazon--examples\/tree\/master\/_model_monitor\" rel=\"nofollow noreferrer\">repo<\/a>, adopting it to a text classification problem that is built on distil bert. so given a sting of text, the model should return a label and a (probability) score.\noutput from the model:<\/p>\n<pre><code>sentiment_input = {&quot;inputs&quot;: &quot;i love using the new inference dlc.&quot;}\n\n# sentiment_input= &quot;i love using the new inference dlc.&quot;\n\nresponse = predictor.predict(data=sentiment_input)\nprint(response)\n<\/code><\/pre>\n<p>output:<\/p>\n<blockquote>\n<p>[{'label': 'label_80', 'score': 0.008507220074534416}]<\/p>\n<\/blockquote>\n<p>when i run the following<\/p>\n<pre><code># create an enpointinput\nendpointinput = endpointinput(\n    endpoint_name=predictor.endpoint_name,\n    probability_attribute=&quot;score&quot;,\n    inference_attribute=&quot;label&quot;,\n#     probability_threshold_attribute=0.5,\n    destination=&quot;\/opt\/ml\/processing\/input_data&quot;,\n)\n\n# create the monitoring schedule to execute every hour.\nfrom .model_monitor import cronexpressiongenerator\n\nresponse = clinc_intent0911.create_monitoring_schedule(\n    monitor_schedule_name=clincintent_monitor_schedule_name,\n    endpoint_input=endpointinput,\n    output_s3_uri=baseline_results_uri,\n    problem_type=&quot;multiclassclassification&quot;,\n    ground_truth_input=ground_truth_upload_path,\n    constraints=baseline_job.suggested_constraints(),\n    schedule_cron_expression=cronexpressiongenerator.hourly(),\n    enable_cloudwatch_metrics=true,\n)\n<\/code><\/pre>\n<p>i get the following error:<\/p>\n<pre><code>---------------------------------------------------------------------------\nclienterror                               traceback (most recent call last)\n&lt;ipython-input-269-72e7049246fb&gt; in &lt;module&gt;\n     10     constraints=baseline_job.suggested_constraints(),\n     11     schedule_cron_expression=cronexpressiongenerator.hourly(),\n---&gt; 12     enable_cloudwatch_metrics=true,\n     13 )\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/\/model_monitor\/model_monitoring.py in create_monitoring_schedule(self, endpoint_input, ground_truth_input, problem_type, record_preprocessor_script, post_analytics_processor_script, output_s3_uri, constraints, monitor_schedule_name, schedule_cron_expression, enable_cloudwatch_metrics)\n   2615             network_config=self.network_config,\n   2616         )\n-&gt; 2617         self._session._client.create_model_quality_job_definition(**request_dict)\n   2618 \n   2619         # create schedule\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/botocore\/client.py in _api_call(self, *args, **kwargs)\n    355                     &quot;%s() only accepts keyword arguments.&quot; % py_operation_name)\n    356             # the &quot;self&quot; in this scope is referring to the baseclient.\n--&gt; 357             return self._make_api_call(operation_name, kwargs)\n    358 \n    359         _api_call.__name__ = str(py_operation_name)\n\n\/opt\/conda\/lib\/python3.6\/site-packages\/botocore\/client.py in _make_api_call(self, operation_name, api_params)\n    674             error_code = parsed_response.get(&quot;error&quot;, {}).get(&quot;code&quot;)\n    675             error_class = self.exceptions.from_code(error_code)\n--&gt; 676             raise error_class(parsed_response, operation_name)\n    677         else:\n    678             return parsed_response\n\nclienterror: an error occurred (validationexception) when calling the createmodelqualityjobdefinition operation: endpoint 'clinc-intent-analysis-0911' does not exist or is not valid\n<\/code><\/pre>\n<p>at this point my  endpoint is live and unable to debug it is not valid.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving a validation exception when calling the create_monitoring_schedule operation, indicating that the endpoint is invalid or does not exist."
    },
    {
        "Question_id":61977905.0,
        "Question_title":"Azure ML Web Service - Slow response time",
        "Question_body":"<p>I have developed a Machine learning model (Random Forest classification model) in Azure Machine Learning Studio &amp; deployed the same to Azure Container Instance (ACI) as a web service.<\/p>\n\n<p>I then test the performance of the Webservice from within a notebook running in Azure ML studio with a 4 core, 8 GB ram back-end Azure compute. Using the <code>%%timeit<\/code> magic command in Jupyter notebook, I get an average speed of around 1.2 seconds\/loop (for running inference on 1000 data points).<\/p>\n\n<p>However, when I test the same webservice outside of Azure, in my local machine, the performance drops to ~5 seconds\/loop (more than 4 times slower)<\/p>\n\n<p>I am fairly new to web service deployment, so I am really not sure how to go about troubleshooting this (and could not find any helpful info on googling either).\nDo let me know if there are any specific configuration or environment details required to answer this (I have mostly just followed the azure documentation for deployment,e.g. the tutorial <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance\" rel=\"nofollow noreferrer\">here<\/a>) <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1590264116550,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":328.0,
        "Owner_creation_time":1433054608167,
        "Owner_last_access_time":1627885075520,
        "Owner_reputation":1409.0,
        "Owner_up_votes":5.0,
        "Owner_down_votes":0.0,
        "Owner_views":70.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61977905",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  web service - slow response time; content:<p>i have developed a machine learning model (random forest classification model) in  studio &amp; deployed the same to azure container instance (aci) as a web service.<\/p>\n\n<p>i then test the performance of the webservice from within a notebook running in  studio with a 4 core, 8 gb ram back-end azure compute. using the <code>%%timeit<\/code> magic command in jupyter notebook, i get an average speed of around 1.2 seconds\/loop (for running inference on 1000 data points).<\/p>\n\n<p>however, when i test the same webservice outside of azure, in my local machine, the performance drops to ~5 seconds\/loop (more than 4 times slower)<\/p>\n\n<p>i am fairly new to web service deployment, so i am really not sure how to go about troubleshooting this (and could not find any helpful info on googling either).\ndo let me know if there are any specific configuration or environment details required to answer this (i have mostly just followed the azure documentation for deployment,e.g. the tutorial <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance\" rel=\"nofollow noreferrer\">here<\/a>) <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user has deployed a machine learning model to Azure Container Instance as a web service and tested the performance of the web service from within Azure ML Studio, but when tested outside of Azure, the performance drops significantly."
    },
    {
        "Question_id":null,
        "Question_title":"Azure ML: User errors were found in at least one of the child runs",
        "Question_body":"Hi, I am trying to perform hyperparameter tuning, but I keep getting the error in my Question Title. I am new to Azure, and I am not sure if it is some error in my script. Could someone advise please?",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_creation_time":1630835455217,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/540302\/azure-ml-user-errors-were-found-in-at-least-one-of-1.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: : user errors were found in at least one of the child runs; content:hi, i am trying to perform hyperparameter tuning, but i keep getting the error in my question title. i am new to azure, and i am not sure if it is some error in my script. could someone advise please?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to perform hyperparameter tuning in Azure ML, but is receiving an error. They are new to Azure and need assistance to identify and resolve the issue."
    },
    {
        "Question_id":null,
        "Question_title":"How to draw many images with a bar",
        "Question_body":"<p>I can only draw image with [wandb.Image(Numpy.array()),] like this<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab\/3961\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/b48aa9bfc94603e638f56ff8452ed88b900f00db.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab\/3961\" target=\"_blank\" rel=\"noopener nofollow ugc\" title=\"11:54AM - 20 November 2020\">AIcrowd Forum \u2013 20 Nov 20<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:600\/325;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/e05a631c976b165047261523c356b3fa7e5eab41.gif\" class=\"thumbnail animated\" width=\"600\" height=\"325\"><\/div>\n\n<h3><a href=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab\/3961\" target=\"_blank\" rel=\"noopener nofollow ugc\">MaskRCNN integrated with WandB and DIRECT SUBMIT FROM COLAB!<\/a><\/h3>\n\n  <p>Hi everyone!    @rohitmidha23 and me have been following this challenge for quite a while. We have written a starter notebook using MaskRCNN. We further integrate MaskRCNN with WandB which really helps to keep track of the various experiments that...<\/p>\n\n  <p>\n    <span class=\"label1\">Reading time: 1 mins \ud83d\udd51<\/span>\n      <span class=\"label2\">Likes: 17 \u2764<\/span>\n  <\/p>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n<p>\nBut how can I draw many images with a bar like this<br>\n<a href=\"https:\/\/sooftware.io\/static\/fd6ffa741fe53de299a57e6a8852f68d\/f312c\/wandb_image.webp\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https:\/\/sooftware.io\/static\/fd6ffa741fe53de299a57e6a8852f68d\/f312c\/wandb_image.webp<\/a><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1652175740664,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":91.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-to-draw-many-images-with-a-bar\/2391",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "id":5643,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2022-05-11T08:41:46.823Z",
                "cooked":"<p>Hey <a class=\"mention\" href=\"\/u\/langelo\">@langelo<\/a>, by bar do you mean the step slider?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-05-11T08:41:46.823Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":2391,
                "topic_slug":"how-to-draw-many-images-with-a-bar",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5678,
                "name":"LAngelo",
                "username":"langelo",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/l\/22d042\/{size}.png",
                "created_at":"2022-05-13T09:03:54.120Z",
                "cooked":"<p>Oh\uff0cyes! I got it ,the step slider.<br>\nIt\u2019s on the left top of my panel. Thanks!<br>\n<img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/7477d027660f227b355c1b7090095a0ca0e72264.png\" alt=\"FireShot Capture 043 - warm-sea-50 - deepfillv2_512x512_dv5_0pv8_1 \u2013 Weights &amp; Biases_ - 192.168.23.40\" data-base62-sha1=\"gCk5gzKgcCCqUAxrDVgTMn9CtF2\" width=\"274\" height=\"249\"><\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-05-13T09:03:54.120Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2391,
                "topic_slug":"how-to-draw-many-images-with-a-bar",
                "display_username":"LAngelo",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1425,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":true
            },
            {
                "id":6443,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-07-12T09:04:26.645Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":4,
                "post_type":3,
                "updated_at":"2022-07-12T09:04:26.645Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2391,
                "topic_slug":"how-to-draw-many-images-with-a-bar",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to draw many images with a bar; content:<p>i can only draw image with [.image(numpy.array()),] like this<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with--and-direct-submit-from-colab\/3961\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/1x\/b48aa9bfc94603e638f56ff8452ed88b900f00db.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with--and-direct-submit-from-colab\/3961\" target=\"_blank\" rel=\"noopener nofollow ugc\" title=\"11:54am - 20 november 2020\">aicrowd forum \u2013 20 nov 20<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:600\/325;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/1x\/e05a631c976b165047261523c356b3fa7e5eab41.gif\" class=\"thumbnail animated\" width=\"600\" height=\"325\"><\/div>\n\n<h3><a href=\"https:\/\/discourse.aicrowd.com\/t\/maskrcnn-integrated-with--and-direct-submit-from-colab\/3961\" target=\"_blank\" rel=\"noopener nofollow ugc\">maskrcnn integrated with  and direct submit from colab!<\/a><\/h3>\n\n  <p>hi everyone!    @rohitmidha23 and me have been following this challenge for quite a while. we have written a starter notebook using maskrcnn. we further integrate maskrcnn with  which really helps to keep track of the various experiments that...<\/p>\n\n  <p>\n    <span class=\"label1\">reading time: 1 mins \ud83d\udd51<\/span>\n      <span class=\"label2\">likes: 17 \u2764<\/span>\n  <\/p>\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n<p>\nbut how can i draw many images with a bar like this<br>\n<a href=\"https:\/\/sooftware.io\/static\/fd6ffa741fe53de299a57e6a8852f68d\/f312c\/_image.webp\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https:\/\/sooftware.io\/static\/fd6ffa741fe53de299a57e6a8852f68d\/f312c\/_image.webp<\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to draw multiple images with a bar, similar to the example provided."
    },
    {
        "Question_id":73592771.0,
        "Question_title":"python script that runs inside a docker image, doesn't use the usual PYTHONPATH",
        "Question_body":"<p>I'm creating a docker image using the following Dockerfile:<\/p>\n<pre><code>FROM python:3.7\nRUN apt-get update &amp;&amp; pip install sagemaker boto3 numpy sagemaker-training\n\n# Copies the training code inside the container\nCOPY cv.py \/opt\/ml\/code\/train.py\nCOPY scikit_learn_iris.py \/opt\/ml\/code\/scikit_learn_iris.py\n\n# Defines train.py as script entrypoint\nENV SAGEMAKER_PROGRAM train.py\n\n# Install custom packages specified in requirements.txts\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\n\nENV PYTHONPATH &quot;\/usr\/local\/lib\/python3.7\/site-packages&quot;\n<\/code><\/pre>\n<p>In the requirements file, I have added <code>lightgbm<\/code> library and it installs it successfully inside the docker image. When sagemaker runs starts to run <code>scikit_learn_iris.py<\/code> cause it can't import <code>lightgbm<\/code>: <code>ModuleNotFoundError: No module named 'lightgbm'<\/code>. I'm printing the sys path and PYTHONPATH at the start of <code>scikit_learn_iris.py<\/code> script and it shows the following results :<\/p>\n<pre><code>sys.path = ['\/opt\/ml\/code', '\/opt\/ml\/code', '\/miniconda3\/bin', '\/miniconda3\/lib\/python37.zip', '\/miniconda3\/lib\/python3.7', '\/miniconda3\/lib\/python3.7\/lib-dynload', '\/miniconda3\/lib\/python3.7\/site-packages']\n\nPYTHONPATH = ['\/opt\/ml\/code', '\/miniconda3\/bin', '\/miniconda3\/lib\/python37.zip', '\/miniconda3\/lib\/python3.7', '\/miniconda3\/lib\/python3.7\/lib-dynload', '\/miniconda3\/lib\/python3.7\/site-packages']\n<\/code><\/pre>\n<p>why the script is using <code>\/miniconda3\/...<\/code> to find the libraries? Even tough I'm setting <code>PYTHONPATH<\/code> env variable in the Dockerfile? How do I make it understand to look in the correct path?! This path <code>\/miniconda3\/<\/code> doesn't even exists in the docker image when I checked (using <code>docker run -it IMAGE_NAME bash<\/code>)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1662213332087,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "docker",
            "pip",
            "amazon-sagemaker"
        ],
        "Question_view_count":42.0,
        "Owner_creation_time":1401983938270,
        "Owner_last_access_time":1663927059848,
        "Owner_reputation":5014.0,
        "Owner_up_votes":499.0,
        "Owner_down_votes":1.0,
        "Owner_views":244.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73592771",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: python script that runs inside a docker image, doesn't use the usual pythonpath; content:<p>i'm creating a docker image using the following dockerfile:<\/p>\n<pre><code>from python:3.7\nrun apt-get update &amp;&amp; pip install  boto3 numpy -training\n\n# copies the training code inside the container\ncopy cv.py \/opt\/ml\/code\/train.py\ncopy scikit_learn_iris.py \/opt\/ml\/code\/scikit_learn_iris.py\n\n# defines train.py as script entrypoint\nenv _program train.py\n\n# install custom packages specified in requirements.txts\ncopy requirements.txt requirements.txt\nrun pip install -r requirements.txt\n\nenv pythonpath &quot;\/usr\/local\/lib\/python3.7\/site-packages&quot;\n<\/code><\/pre>\n<p>in the requirements file, i have added <code>lightgbm<\/code> library and it installs it successfully inside the docker image. when  runs starts to run <code>scikit_learn_iris.py<\/code> cause it can't import <code>lightgbm<\/code>: <code>modulenotfounderror: no module named 'lightgbm'<\/code>. i'm printing the sys path and pythonpath at the start of <code>scikit_learn_iris.py<\/code> script and it shows the following results :<\/p>\n<pre><code>sys.path = ['\/opt\/ml\/code', '\/opt\/ml\/code', '\/miniconda3\/bin', '\/miniconda3\/lib\/python37.zip', '\/miniconda3\/lib\/python3.7', '\/miniconda3\/lib\/python3.7\/lib-dynload', '\/miniconda3\/lib\/python3.7\/site-packages']\n\npythonpath = ['\/opt\/ml\/code', '\/miniconda3\/bin', '\/miniconda3\/lib\/python37.zip', '\/miniconda3\/lib\/python3.7', '\/miniconda3\/lib\/python3.7\/lib-dynload', '\/miniconda3\/lib\/python3.7\/site-packages']\n<\/code><\/pre>\n<p>why the script is using <code>\/miniconda3\/...<\/code> to find the libraries? even tough i'm setting <code>pythonpath<\/code> env variable in the dockerfile? how do i make it understand to look in the correct path?! this path <code>\/miniconda3\/<\/code> doesn't even exists in the docker image when i checked (using <code>docker run -it image_name bash<\/code>)<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty getting their python script to recognize the lightgbm library installed in the docker image, as the script is using a different pythonpath than the one set in the dockerfile."
    },
    {
        "Question_id":56076313.0,
        "Question_title":"Label encoding in Azure Machine Learning Studio",
        "Question_body":"<p>I'm trying to find the equivalent of the sklearn <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html\" rel=\"nofollow noreferrer\">LabelEncoder<\/a> or the <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder\" rel=\"nofollow noreferrer\">OrdinalEncoder<\/a> in Azure ML Studio. I understand the Convert to Indicator Values module performs One-hot encoding but I can't find anything that would do label encoding. <\/p>\n\n<p>What I have is a column with six unique string values and what I need is to represent that data with integers from 0 to 6.<\/p>\n\n<p>Right now, I'm using the Execute Python Script module to do it but I was wondering if there's a built-in module to do it.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1557486034313,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":786.0,
        "Owner_creation_time":1450260166772,
        "Owner_last_access_time":1663955203356,
        "Owner_reputation":1587.0,
        "Owner_up_votes":123.0,
        "Owner_down_votes":8.0,
        "Owner_views":540.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56076313",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: label encoding in  studio; content:<p>i'm trying to find the equivalent of the sklearn <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.labelencoder.html\" rel=\"nofollow noreferrer\">labelencoder<\/a> or the <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.ordinalencoder.html#sklearn.preprocessing.ordinalencoder\" rel=\"nofollow noreferrer\">ordinalencoder<\/a> in  studio. i understand the convert to indicator values module performs one-hot encoding but i can't find anything that would do label encoding. <\/p>\n\n<p>what i have is a column with six unique string values and what i need is to represent that data with integers from 0 to 6.<\/p>\n\n<p>right now, i'm using the execute python script module to do it but i was wondering if there's a built-in module to do it.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to find the equivalent of the sklearn labelencoder or ordinalencoder in Azure ML Studio to represent a column of six unique string values with integers from 0 to 6."
    },
    {
        "Question_id":73411852.0,
        "Question_title":"Issue with data lake mounting in custom RStudio application Azure ML",
        "Question_body":"<ol>\n<li>previously while creating a compute instance  we were able to see RStudio application by default and we were able to mount\/access the data lake from RStudio.<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/J17ne.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/J17ne.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3l8Q4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3l8Q4.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"2\">\n<li>In current situation we are not able to access RStudio application by default.<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/nx5GL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/nx5GL.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"3\">\n<li>with the help of below link we are able to create custom RStudio application<\/li>\n<\/ol>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/flQyy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/flQyy.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>4.In custom RStudio we are not able to mount\/access the data lake.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2dWL9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2dWL9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Is there way to mount\/access the data lake in custom RStudio app<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1660883431000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "r",
            "azure",
            "installation",
            "azure-machine-learning-studio",
            "rstudio-server"
        ],
        "Question_view_count":71.0,
        "Owner_creation_time":1655285218328,
        "Owner_last_access_time":1663848796827,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Pune",
        "Question_last_edit_time":1661269087767,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73411852",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: issue with data lake mounting in custom rstudio application ; content:<ol>\n<li>previously while creating a compute instance  we were able to see rstudio application by default and we were able to mount\/access the data lake from rstudio.<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/j17ne.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/j17ne.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3l8q4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3l8q4.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"2\">\n<li>in current situation we are not able to access rstudio application by default.<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/nx5gl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/nx5gl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"3\">\n<li>with the help of below link we are able to create custom rstudio application<\/li>\n<\/ol>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/flqyy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/flqyy.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>4.in custom rstudio we are not able to mount\/access the data lake.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2dwl9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2dwl9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>is there way to mount\/access the data lake in custom rstudio app<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to mount\/access the data lake in the custom rstudio application created in Azure ML, despite being able to do so in the default rstudio application."
    },
    {
        "Question_id":68619132.0,
        "Question_title":"Log (and then apply) Spark MLlib model from R to MLflow",
        "Question_body":"<p>I'm using Spark MLlib functions (through the <em>sparklyr<\/em> package) to train a model but now seem unable to save the model in <em>MLflow<\/em> for future use.<\/p>\n<pre><code>iris_tbl &lt;- sparklyr::copy_to(sc, iris, &quot;iris_spark&quot;)\nmdl_mllib &lt;- iris_tbl %&gt;% sparklyr::ml_linear_regression(formula = Sepal_Width ~ Sepal_Length)\nmlflow::mlflow_log_model(mdl_mllib, &quot;artifact_path_where_saved&quot;)\nError in UseMethod(&quot;mlflow_save_model&quot;) : \n  no applicable method for 'mlflow_save_model' applied to an object of class &quot;c('ml_model_linear_regression', 'ml_model_regression', 'ml_model_prediction', 'ml_model')&quot;\n\npackageVersion(&quot;mlflow&quot;)\n[1] \u20181.17.0\u2019\n<\/code><\/pre>\n<p>What is a simple way to save this model in <em>mlflow<\/em> for later use <strong>on a Spark DataFrame<\/strong> such as:<\/p>\n<p><code>mlflow::mlflow_load_model(model_uri = &quot;models:\/mdl_mllib_project01\/Staging&quot;)<\/code><\/p>\n<p>For context, I'm using Azure Databricks as the ecosystem.<\/p>\n<h3>Other places I've looked for answers<\/h3>\n<ul>\n<li>These links don't seem to directly solve my problem (<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#id28;\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/models.html#id28;<\/a> <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.spark.html#mlflow.spark.log_model\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.spark.html#mlflow.spark.log_model<\/a>), although maybe it's that I need to make a &quot;pipeline&quot; or that this works for Python but not yet for R?<\/li>\n<li>This question seems relevant but offers abstract answers rather than details (<a href=\"https:\/\/stackoverflow.com\/questions\/40533582\/how-to-serve-a-spark-mllib-model\">How to serve a Spark MLlib model?<\/a>).<\/li>\n<\/ul>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_creation_time":1627896006663,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "apache-spark-mllib",
            "sparklyr",
            "mlflow"
        ],
        "Question_view_count":107.0,
        "Owner_creation_time":1619023423856,
        "Owner_last_access_time":1663688995296,
        "Owner_reputation":33.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68619132",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: log (and then apply) spark mllib model from r to ; content:<p>i'm using spark mllib functions (through the <em>sparklyr<\/em> package) to train a model but now seem unable to save the model in <em><\/em> for future use.<\/p>\n<pre><code>iris_tbl &lt;- sparklyr::copy_to(sc, iris, &quot;iris_spark&quot;)\nmdl_mllib &lt;- iris_tbl %&gt;% sparklyr::ml_linear_regression(formula = sepal_width ~ sepal_length)\n::_log_model(mdl_mllib, &quot;artifact_path_where_saved&quot;)\nerror in usemethod(&quot;_save_model&quot;) : \n  no applicable method for '_save_model' applied to an object of class &quot;c('ml_model_linear_regression', 'ml_model_regression', 'ml_model_prediction', 'ml_model')&quot;\n\npackageversion(&quot;&quot;)\n[1] \u20181.17.0\u2019\n<\/code><\/pre>\n<p>what is a simple way to save this model in <em><\/em> for later use <strong>on a spark dataframe<\/strong> such as:<\/p>\n<p><code>::_load_model(model_uri = &quot;models:\/mdl_mllib_project01\/staging&quot;)<\/code><\/p>\n<p>for context, i'm using azure databricks as the ecosystem.<\/p>\n<h3>other places i've looked for answers<\/h3>\n<ul>\n<li>these links don't seem to directly solve my problem (<a href=\"https:\/\/www..org\/docs\/latest\/models.html#id28;\" rel=\"nofollow noreferrer\">https:\/\/www..org\/docs\/latest\/models.html#id28;<\/a> <a href=\"https:\/\/www..org\/docs\/latest\/python_api\/.spark.html#.spark.log_model\" rel=\"nofollow noreferrer\">https:\/\/www..org\/docs\/latest\/python_api\/.spark.html#.spark.log_model<\/a>), although maybe it's that i need to make a &quot;pipeline&quot; or that this works for python but not yet for r?<\/li>\n<li>this question seems relevant but offers abstract answers rather than details (<a href=\"https:\/\/stackoverflow.com\/questions\/40533582\/how-to-serve-a-spark-mllib-model\">how to serve a spark mllib model?<\/a>).<\/li>\n<\/ul>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to save a Spark MLlib model trained through the sparklyr package and is looking for a simple way to save the model for later use on a Spark dataframe."
    },
    {
        "Question_id":null,
        "Question_title":"how to log error\/messages in while running a sagemaker batch transform job?",
        "Question_body":"i'm using a hugging face model and a container to create a batch transform job in sagemaker. i have a custom inference code and in the output_fn function i'm returning json_dumps(prediction). I'm using print(prediction) to see, if i can see it in the cloudwatch logs to find out type and what prediction is. how can log these messages . Also, the inference output i get is in the form below., i'm not sure why is it not a json object in each line instead it has square brackets. I want to use the filter to match the input and output in the batch job. I'm not sure how the output should look like , because i'm trying to associate input with output by using dataprocessing config as below. but i get an error. the documenation has example of csv not json. what should the output look like so that i can associate the input with output when they both are in json format.\n\n  \"DataProcessing\": {\n        \"JoinSource\": \"Input\"\n    },\n\n[ output text 1 ]\n[output text 2 ]\n\n# Serialize the prediction result into the desired response content type\ndef output_fn(prediction, accept=JSON_CONTENT_TYPE):\n    logger.info(\"Serializing the generated output.\")\n    if accept == JSON_CONTENT_TYPE:\n        output = json.dumps(prediction)\n        return output, accept\n    raise Exception(\"Requested unsupported ContentType in Accept: {}\".format(accept))",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1653699481978,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker"
        ],
        "Question_view_count":58.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUNirOT1cMSfig9ANtgmZMpg\/how-to-log-error-messages-in-while-running-a-sagemaker-batch-transform-job",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to log error\/messages in while running a  batch transform job?; content:i'm using a hugging face model and a container to create a batch transform job in . i have a custom inference code and in the output_fn function i'm returning json_dumps(prediction). i'm using print(prediction) to see, if i can see it in the cloudwatch logs to find out type and what prediction is. how can log these messages . also, the inference output i get is in the form below., i'm not sure why is it not a json object in each line instead it has square brackets. i want to use the filter to match the input and output in the batch job. i'm not sure how the output should look like , because i'm trying to associate input with output by using dataprocessing config as below. but i get an error. the documenation has example of csv not json. what should the output look like so that i can associate the input with output when they both are in json format.\n\n  \"dataprocessing\": {\n        \"joinsource\": \"input\"\n    },\n\n[ output text 1 ]\n[output text 2 ]\n\n# serialize the prediction result into the desired response content type\ndef output_fn(prediction, accept=json_content_type):\n    logger.info(\"serializing the generated output.\")\n    if accept == json_content_type:\n        output = json.dumps(prediction)\n        return output, accept\n    raise exception(\"requested unsupported contenttype in accept: {}\".format(accept))",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to use the output_fn function to serialize the prediction result into the desired response content type, and use print(prediction) to log messages in Cloudwatch logs. The output should be in JSON format in order to associate the input and output in the batch job."
    },
    {
        "Question_id":null,
        "Question_title":"Machine learning job stuck on queued and then cancelled",
        "Question_body":"I have a job which I set to run last night, only to find out it was queued for over 2 hours and eventually cancelled (not by me).\n\nThis morning, my machine learning run is again, stuck on queued.\n\nIs there any way to fix this?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1614676942043,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/294828\/machine-learnin-job-stuck-on-queued-and-then-cance.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-02T13:46:00.057Z",
                "Answer_score":0,
                "Answer_body":"@CarterBouley-1225 Usually a failed job or a run is available from the Experiments tab on azure ML portal ml.azure.com, Do you see these runs or the logs related to these runs on this tab to provide more details of the errors?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: machine learning job stuck on queued and then cancelled; content:i have a job which i set to run last night, only to find out it was queued for over 2 hours and eventually cancelled (not by me).\n\nthis morning, my machine learning run is again, stuck on queued.\n\nis there any way to fix this?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user's machine learning job is stuck on queued and then cancelled, and they are wondering if there is any way to fix this."
    },
    {
        "Question_id":61382605.0,
        "Question_title":"Azure ML SDK in Python, Azure ML models to integrate in Notebook",
        "Question_body":"<p>We are setting up Azure ML SDK in Python. When we are creating models using Azure ML SDK in Python notebook We have to manually write the code to use feature of Azure ML and Scikit learn-- But if we model in ML studio we will do all that easily by drag and drop. Required solution is Can we build a model in Azure ML Studio and use the model in Azure ML SDK (Python Notebook). No more manual coding for Model creation will be involved. Please suggest.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1587630287673,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning-studio",
            "azure-machine-learning-service"
        ],
        "Question_view_count":127.0,
        "Owner_creation_time":1578649477907,
        "Owner_last_access_time":1590997946847,
        "Owner_reputation":41.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61382605",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  sdk in python,  models to integrate in notebook; content:<p>we are setting up  sdk in python. when we are creating models using  sdk in python notebook we have to manually write the code to use feature of  and scikit learn-- but if we model in ml studio we will do all that easily by drag and drop. required solution is can we build a model in  studio and use the model in  sdk (python notebook). no more manual coding for model creation will be involved. please suggest.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to build a model in Azure ML Studio and use it in an Azure ML SDK (Python notebook) without manually coding for model creation."
    },
    {
        "Question_id":65135398.0,
        "Question_title":"azure ml metrics using log or parent.log()?",
        "Question_body":"<p>At the moment I am using log to track ml experiment metrics in azure. An Example of the output.<\/p>\n<pre><code>Run 1  mse=0.3\nRun 2  mse=0.2\nrun 3  mse=0.1\n<\/code><\/pre>\n<p>However, I want one mse value that summarises the entire pipeline would  parent_run.log allow me to do this?<\/p>\n<p>Research material used\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-track-designer-experiments\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-track-designer-experiments<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1607035939897,
        "Question_favorite_count":null,
        "Question_score":3.0,
        "Question_tags":[
            "azure-machine-learning-studio",
            "azure-machine-learning-service"
        ],
        "Question_view_count":532.0,
        "Owner_creation_time":1579013256568,
        "Owner_last_access_time":1663763227623,
        "Owner_reputation":129.0,
        "Owner_up_votes":7.0,
        "Owner_down_votes":0.0,
        "Owner_views":17.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65135398",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  metrics using log or parent.log()?; content:<p>at the moment i am using log to track ml experiment metrics in azure. an example of the output.<\/p>\n<pre><code>run 1  mse=0.3\nrun 2  mse=0.2\nrun 3  mse=0.1\n<\/code><\/pre>\n<p>however, i want one mse value that summarises the entire pipeline would  parent_run.log allow me to do this?<\/p>\n<p>research material used\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-track-designer-experiments\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-track-designer-experiments<\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is currently using log to track ML experiment metrics in Azure, but is looking to use parent_run.log to summarize the entire pipeline."
    },
    {
        "Question_id":60934522.0,
        "Question_title":"Sagemaker Error for HyperParameterTuning job",
        "Question_body":"<p>I checked the aws forums and here at SO and I can't find a solution to this error or an explanation to what it is.<\/p>\n\n<p>The full error is:<\/p>\n\n<pre><code>UnexpectedStatusException: Error for HyperParameterTuning job sagemaker-xgboost-200330-1544: Failed. Reason: No objective metrics found after running 5 training jobs. Please ensure that the custom algorithm is emitting the objective metric as defined by the regular expression provided.\n\n<\/code><\/pre>\n\n<p>and it is respective to the following code:<\/p>\n\n<pre><code>xgbt = sagemaker.estimator.Estimator(container, #name of training container\n                                    role, # IAM role to use\n                                    train_instance_count = 1, # number of instances yo use for training\n                                    train_instance_type = 'ml.m4.xlarge', #type of virtual machine to use\n                                    output_path = 's3:\/\/{}\/{}\/output'.format(session.default_bucket(),\n                                                                            prefix),\n                                    sagemaker_session = session) #current sagemaker session\n\n\nxgbt.set_hyperparameters(\n    max_depth = 5,\n    eta = 0.1,\n    eval_metric='auc',\n    objective='binary:logistic',\n    early_stopping_rounds=500,\n    rate_drop=0.1,\n    colsample_bytree=0.8,\n    subsample=0.75,\n    min_child_weight=0,\n    num_round = 500)\n\n\nxgbt.fit({'train': s3_input_train})\n\n<\/code><\/pre>\n\n<p>and then the hyperparameter tuning is where it croaks:<\/p>\n\n<pre><code>from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n\nxgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgbt, # The estimator object to use as the basis for the training jobs.\n                                               objective_metric_name = 'validation:auc', # The metric used to compare trained models.\n                                               objective_type = 'Maximize', # Whether we wish to minimize or maximize the metric.\n                                               max_jobs = 20, # The total number of models to train\n                                               max_parallel_jobs = 3, # The number of models to train in parallel\n                                               hyperparameter_ranges = {\n                                                    'max_depth': IntegerParameter(3, 12),\n                                                    'eta'      : ContinuousParameter(0.01, 0.5),\n                                                    'min_child_weight': IntegerParameter(2, 8),\n                                                    'subsample': ContinuousParameter(0.5, 0.9),\n                                                    'gamma': ContinuousParameter(0, 10),\n                                               })\n\nxgb_hyperparameter_tuner.fit({'train': s3_input_train})\n\nxgb_hyperparameter_tuner.wait()\n\n<\/code><\/pre>\n\n<p>I think I have the metrics correctly defined so I don't know what it wants from me.<\/p>\n\n<p>Thank you so much for checking this out.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_creation_time":1585583945573,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python-3.x",
            "xgboost",
            "amazon-sagemaker"
        ],
        "Question_view_count":1313.0,
        "Owner_creation_time":1517932507092,
        "Owner_last_access_time":1648741816032,
        "Owner_reputation":331.0,
        "Owner_up_votes":14.0,
        "Owner_down_votes":0.0,
        "Owner_views":73.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60934522",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  error for hyperparametertuning job; content:<p>i checked the aws forums and here at so and i can't find a solution to this error or an explanation to what it is.<\/p>\n\n<p>the full error is:<\/p>\n\n<pre><code>unexpectedstatusexception: error for hyperparametertuning job -xgboost-200330-1544: failed. reason: no objective metrics found after running 5 training jobs. please ensure that the custom algorithm is emitting the objective metric as defined by the regular expression provided.\n\n<\/code><\/pre>\n\n<p>and it is respective to the following code:<\/p>\n\n<pre><code>xgbt = .estimator.estimator(container, #name of training container\n                                    role, # iam role to use\n                                    train_instance_count = 1, # number of instances yo use for training\n                                    train_instance_type = 'ml.m4.xlarge', #type of virtual machine to use\n                                    output_path = 's3:\/\/{}\/{}\/output'.format(session.default_bucket(),\n                                                                            prefix),\n                                    _session = session) #current  session\n\n\nxgbt.set_hyperparameters(\n    max_depth = 5,\n    eta = 0.1,\n    eval_metric='auc',\n    objective='binary:logistic',\n    early_stopping_rounds=500,\n    rate_drop=0.1,\n    colsample_bytree=0.8,\n    subsample=0.75,\n    min_child_weight=0,\n    num_round = 500)\n\n\nxgbt.fit({'train': s3_input_train})\n\n<\/code><\/pre>\n\n<p>and then the hyperparameter tuning is where it croaks:<\/p>\n\n<pre><code>from .tuner import integerparameter, continuousparameter, hyperparametertuner\n\nxgb_hyperparameter_tuner = hyperparametertuner(estimator = xgbt, # the estimator object to use as the basis for the training jobs.\n                                               objective_metric_name = 'validation:auc', # the metric used to compare trained models.\n                                               objective_type = 'maximize', # whether we wish to minimize or maximize the metric.\n                                               max_jobs = 20, # the total number of models to train\n                                               max_parallel_jobs = 3, # the number of models to train in parallel\n                                               hyperparameter_ranges = {\n                                                    'max_depth': integerparameter(3, 12),\n                                                    'eta'      : continuousparameter(0.01, 0.5),\n                                                    'min_child_weight': integerparameter(2, 8),\n                                                    'subsample': continuousparameter(0.5, 0.9),\n                                                    'gamma': continuousparameter(0, 10),\n                                               })\n\nxgb_hyperparameter_tuner.fit({'train': s3_input_train})\n\nxgb_hyperparameter_tuner.wait()\n\n<\/code><\/pre>\n\n<p>i think i have the metrics correctly defined so i don't know what it wants from me.<\/p>\n\n<p>thank you so much for checking this out.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an unexpected status exception error for a hyperparameter tuning job, and is unable to find a solution or explanation for the error."
    },
    {
        "Question_id":null,
        "Question_title":"How can i access azure ml pipeline parameters from a python script running in designer?",
        "Question_body":"I would like to perform some data transformations using the Python script module in Designer for which i would need to access some pipeline parameters. How can i get those values?\n\nWhat would be the equivalent for an R script?",
        "Question_answer_count":1,
        "Question_comment_count":4.0,
        "Question_creation_time":1620522230407,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/387875\/how-can-i-access-azure-ml-pipeline-parameters-from.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-18T04:06:56.287Z",
                "Answer_score":0,
                "Answer_body":"@javier-8889 Thanks, Currently passing a pipeline parameter to the script of Execute Python\/R Module is not supported. We have a new feature custom module which is in private preview. you can write your own module and use in Designer. If it's a common case, it might be better to use custom module.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how can i access  pipeline parameters from a python script running in designer?; content:i would like to perform some data transformations using the python script module in designer for which i would need to access some pipeline parameters. how can i get those values?\n\nwhat would be the equivalent for an r script?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to access Azure ML pipeline parameters from a Python script running in Designer, as well as the equivalent for an R script."
    },
    {
        "Question_id":70879512.0,
        "Question_title":"How to automatically start and stop a compute instance to execute Azure Machine Learning pipelines",
        "Question_body":"<p>I've been following <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-setup-schedule-for-a-published-pipeline.ipynb\" rel=\"nofollow noreferrer\">this notebook<\/a> to schedule the execution of some code every hour. It makes a schedule and creates the pipelines. The problem is that if the computer instance is not running, the pipeline is just queued and waiting for it to run.<\/p>\n<p>Is there a way to automatically run a compute instance when a pipeline is triggered within Azure Machine Learning, as well as stop them when the pipeline is completed?<\/p>\n<p>I need to do it within the AzureML Studio platform because that is the only thing external Data Scientists have access to. I can't use clusters because some of their behaviors cause issues with the code.<\/p>\n<p>I can schedule an instance to become active approximately at the same time as the schedule, but I want to do it in the code, so the scripts can run when they are up, as well as shut down the instance when the pipeline run is over.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1643290738653,
        "Question_favorite_count":1.0,
        "Question_score":2.0,
        "Question_tags":[
            "azure",
            "azure-devops",
            "azure-machine-learning-studio",
            "azure-machine-learning-service"
        ],
        "Question_view_count":820.0,
        "Owner_creation_time":1643289775790,
        "Owner_last_access_time":1663845469316,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Berlin, Germany",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70879512",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to automatically start and stop a compute instance to execute  pipelines; content:<p>i've been following <a href=\"https:\/\/github.com\/azure\/machinelearningnotebooks\/blob\/master\/how-to-use-\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-setup-schedule-for-a-published-pipeline.ipynb\" rel=\"nofollow noreferrer\">this notebook<\/a> to schedule the execution of some code every hour. it makes a schedule and creates the pipelines. the problem is that if the computer instance is not running, the pipeline is just queued and waiting for it to run.<\/p>\n<p>is there a way to automatically run a compute instance when a pipeline is triggered within , as well as stop them when the pipeline is completed?<\/p>\n<p>i need to do it within the  studio platform because that is the only thing external data scientists have access to. i can't use clusters because some of their behaviors cause issues with the code.<\/p>\n<p>i can schedule an instance to become active approximately at the same time as the schedule, but i want to do it in the code, so the scripts can run when they are up, as well as shut down the instance when the pipeline run is over.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to automatically start and stop a compute instance to execute pipelines within the Azure Machine Learning Studio platform, as well as shut down the instance when the pipeline run is over."
    },
    {
        "Question_id":52948351.0,
        "Question_title":"Restore a specific checkpoint for deploying with Sagemaker and TensorFlow",
        "Question_body":"<p>I'm using SageMaker for training some custom TF model I realized. During training I naturally evaluate the model multiple times in order to understand when the NN actually starts overfitting. After training I'd like to restore the model that works best (i.e. which presents minimum validation loss) and deploy it on an endpoint. However, if I use the classic Tensorflow.attach() the model that is restored corresponds with the one stored in output\/model.tar.gz, which, if I got it correctly, would be the one corresponding with the last training iteration (thus it may overfits). <\/p>\n\n<p>Is there a way for specifying to SageMaker which checkpoint restoring without necessarily retraining the model with early stopping? Even forcing SM to save in model.tar.gz the model that presents minimum validation loss and not the last one would work for me, unfortunately I didn't find any immediate way to do so...<\/p>\n\n<p>Thank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1540295396750,
        "Question_favorite_count":null,
        "Question_score":3.0,
        "Question_tags":[
            "python",
            "tensorflow",
            "amazon-sagemaker"
        ],
        "Question_view_count":975.0,
        "Owner_creation_time":1540294590876,
        "Owner_last_access_time":1545155743207,
        "Owner_reputation":31.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"London, Regno Unito",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52948351",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: restore a specific checkpoint for deploying with  and tensorflow; content:<p>i'm using  for training some custom tf model i realized. during training i naturally evaluate the model multiple times in order to understand when the nn actually starts overfitting. after training i'd like to restore the model that works best (i.e. which presents minimum validation loss) and deploy it on an endpoint. however, if i use the classic tensorflow.attach() the model that is restored corresponds with the one stored in output\/model.tar.gz, which, if i got it correctly, would be the one corresponding with the last training iteration (thus it may overfits). <\/p>\n\n<p>is there a way for specifying to  which checkpoint restoring without necessarily retraining the model with early stopping? even forcing sm to save in model.tar.gz the model that presents minimum validation loss and not the last one would work for me, unfortunately i didn't find any immediate way to do so...<\/p>\n\n<p>thank you!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to restore a specific checkpoint for deploying with SageMaker and TensorFlow, without having to retrain the model with early stopping."
    },
    {
        "Question_id":66348183.0,
        "Question_title":"Azure DevOps release pipelines \"Conflict of operation error \" while running one job on microsoft-hosted agent",
        "Question_body":"<p>I am trying to implement an Azure DevOps Release pipeline to Deploy a machine learning model on Azure ML. I'm using 6 tasks:<\/p>\n<ul>\n<li>Use python version<\/li>\n<li>Azure CLI : <code>az extension add -n azure-cli-ml<\/code><\/li>\n<li>Azure CLI : <code>az ml model deploy -g &lt;RG&gt; -w &lt;WS&gt; -n &lt;SN&gt; -f ..\/metadata\/model.json --dc aciDeploymentConfig.yml --ic inferenceConfig.yml --overwrite<\/code><\/li>\n<li>Bash Task : pip install requirments.<\/li>\n<li>Azure CLI : Run some integration tests.<\/li>\n<li>Publish Test Results.<\/li>\n<\/ul>\n<p>My pipeline fails on the deployment task, with the error: <br>\n<code>Conflict of operation, another operation on same entity is already running in workspace mlops-wrksp.<\/code><br>\n<code>Script failed with exit code: 1<\/code>\n<br>\nNo other pipeline is running, I'm using the Microsoft-hosted agent.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_creation_time":1614159396837,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure",
            "azure-devops",
            "azure-pipelines",
            "azure-pipelines-release-pipeline",
            "azure-machine-learning-service"
        ],
        "Question_view_count":409.0,
        "Owner_creation_time":1581516516116,
        "Owner_last_access_time":1645484908603,
        "Owner_reputation":36.0,
        "Owner_up_votes":5.0,
        "Owner_down_votes":0.0,
        "Owner_views":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Morocco",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66348183",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: azure devops release pipelines \"conflict of operation error \" while running one job on microsoft-hosted agent; content:<p>i am trying to implement an azure devops release pipeline to deploy a machine learning model on . i'm using 6 tasks:<\/p>\n<ul>\n<li>use python version<\/li>\n<li>azure cli : <code>az extension add -n azure-cli-ml<\/code><\/li>\n<li>azure cli : <code>az ml model deploy -g &lt;rg&gt; -w &lt;ws&gt; -n &lt;sn&gt; -f ..\/metadata\/model.json --dc acideploymentconfig.yml --ic inferenceconfig.yml --overwrite<\/code><\/li>\n<li>bash task : pip install requirments.<\/li>\n<li>azure cli : run some integration tests.<\/li>\n<li>publish test results.<\/li>\n<\/ul>\n<p>my pipeline fails on the deployment task, with the error: <br>\n<code>conflict of operation, another operation on same entity is already running in workspace mlops-wrksp.<\/code><br>\n<code>script failed with exit code: 1<\/code>\n<br>\nno other pipeline is running, i'm using the microsoft-hosted agent.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is encountering an error when deploying a machine learning model in an Azure DevOps release pipeline with a Microsoft-hosted agent. The error message says that there is a conflict of operation and another operation is already running in the workspace. The pipeline is failing at the deployment task and the script is returning an exit code of 1."
    },
    {
        "Question_id":72663159.0,
        "Question_title":"AWS Quicksight - question about creating a calculated field using if else and custom aggregation",
        "Question_body":"<p>I have a data that looks like this<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>Date<\/th>\n<th>Name<\/th>\n<th>SurveyID<\/th>\n<th>Score<\/th>\n<th>Error<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>2022-02-17<\/td>\n<td>Jack<\/td>\n<td>10<\/td>\n<td>95<\/td>\n<td>Name<\/td>\n<\/tr>\n<tr>\n<td>2022-02-17<\/td>\n<td>Jack<\/td>\n<td>10<\/td>\n<td>95<\/td>\n<td>Address<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>Tom<\/td>\n<td>9<\/td>\n<td>100<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>Carl<\/td>\n<td>8<\/td>\n<td>93<\/td>\n<td>Zip<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>Carl<\/td>\n<td>8<\/td>\n<td>93<\/td>\n<td>Email<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>Dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>Zip<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>Dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>Email<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>Dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>Name<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>Dan<\/td>\n<td>6<\/td>\n<td>90<\/td>\n<td>Phone<\/td>\n<\/tr>\n<tr>\n<td>2022-02-14<\/td>\n<td>Tom<\/td>\n<td>5<\/td>\n<td>98<\/td>\n<td>Gender<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>I wanted to have a segmentation data using the avg. score per individual.<\/p>\n<pre><code>Segment\nA:  98%-100%\nB:  95%-97%\nC:  90%-94%\nD:  80%-89%\nE:  0% -79%\n<\/code><\/pre>\n<p>I did an if else formula which is this:<\/p>\n<pre><code>ifelse(Score} &gt;= 98,'A',ifelse({Score} &gt;= 95,'B',ifelse({Score} &gt;= 90,'C',ifelse({Score} &gt;= 80,'D','E'))))\n<\/code><\/pre>\n<p>This is now the output of what I did:<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>Date<\/th>\n<th>Name<\/th>\n<th>SurveyID<\/th>\n<th>Score<\/th>\n<th>Error<\/th>\n<th>Segement<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>2022-02-17<\/td>\n<td>Jack<\/td>\n<td>10<\/td>\n<td>95<\/td>\n<td>Name<\/td>\n<td>B<\/td>\n<\/tr>\n<tr>\n<td>2022-02-17<\/td>\n<td>Jack<\/td>\n<td>10<\/td>\n<td>95<\/td>\n<td>Address<\/td>\n<td>B<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>Tom<\/td>\n<td>9<\/td>\n<td>100<\/td>\n<td><\/td>\n<td>A<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>Carl<\/td>\n<td>8<\/td>\n<td>93<\/td>\n<td>Zip<\/td>\n<td>C<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>Carl<\/td>\n<td>8<\/td>\n<td>93<\/td>\n<td>Email<\/td>\n<td>C<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>Dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>Zip<\/td>\n<td>E<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>Dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>Email<\/td>\n<td>E<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>Dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>Name<\/td>\n<td>E<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>Dan<\/td>\n<td>6<\/td>\n<td>90<\/td>\n<td>Phone<\/td>\n<td>C<\/td>\n<\/tr>\n<tr>\n<td>2022-02-14<\/td>\n<td>Tom<\/td>\n<td>5<\/td>\n<td>98<\/td>\n<td>Gender<\/td>\n<td>A<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>I realized that the calculation I did only applies for the score. I was expecting an output like this:<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>Name<\/th>\n<th>Average Score<\/th>\n<th>Total Survey<\/th>\n<th>Segement<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>Jack<\/td>\n<td>95<\/td>\n<td>1<\/td>\n<td>B<\/td>\n<\/tr>\n<tr>\n<td>Tom<\/td>\n<td>99<\/td>\n<td>2<\/td>\n<td>A<\/td>\n<\/tr>\n<tr>\n<td>Carl<\/td>\n<td>93<\/td>\n<td>1<\/td>\n<td>C<\/td>\n<\/tr>\n<tr>\n<td>Dan<\/td>\n<td>81<\/td>\n<td>2<\/td>\n<td>D<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>I have tried to create another calculated field for Average Score which is:<\/p>\n<pre><code>avgOver({Score}, [Name], PRE_AGG)\n<\/code><\/pre>\n<p>I believe I am missing a distinct count of survey IDs in that formula, that I do not know where to place. As for segmentation calculation, I cannot on my life figure that part out without getting aggregation errors on Quicksight. Please help, thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1655488605330,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-s3",
            "aws-lambda",
            "amazon-sagemaker",
            "amazon-quicksight"
        ],
        "Question_view_count":105.0,
        "Owner_creation_time":1646242327867,
        "Owner_last_access_time":1663697296087,
        "Owner_reputation":27.0,
        "Owner_up_votes":2.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":"<p>Got the answer from Quicksight Community. Pasting it here.<\/p>\n<p>For segmentation, you can use the calculated field which you created for average score .<\/p>\n<pre><code>avg_score = avgOver(Score,[Name],PRE_AGG)\n<\/code><\/pre>\n<p>Segment<\/p>\n<pre><code>ifelse\n(\n    {avg_score}&gt;= 98,'A',\n    {avg_score}&gt;= 95,'B',\n    {avg_score}&gt;= 90,'C',\n    {avg_score}&gt;= 80,'D',\n    'E'\n)\n<\/code><\/pre>\n<p>The survey id can be used to get the distinct count per individual.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1655843015852,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72663159",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: aws quicksight - question about creating a calculated field using if else and custom aggregation; content:<p>i have a data that looks like this<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>date<\/th>\n<th>name<\/th>\n<th>surveyid<\/th>\n<th>score<\/th>\n<th>error<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>2022-02-17<\/td>\n<td>jack<\/td>\n<td>10<\/td>\n<td>95<\/td>\n<td>name<\/td>\n<\/tr>\n<tr>\n<td>2022-02-17<\/td>\n<td>jack<\/td>\n<td>10<\/td>\n<td>95<\/td>\n<td>address<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>tom<\/td>\n<td>9<\/td>\n<td>100<\/td>\n<td><\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>carl<\/td>\n<td>8<\/td>\n<td>93<\/td>\n<td>zip<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>carl<\/td>\n<td>8<\/td>\n<td>93<\/td>\n<td>email<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>zip<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>email<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>name<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>dan<\/td>\n<td>6<\/td>\n<td>90<\/td>\n<td>phone<\/td>\n<\/tr>\n<tr>\n<td>2022-02-14<\/td>\n<td>tom<\/td>\n<td>5<\/td>\n<td>98<\/td>\n<td>gender<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>i wanted to have a segmentation data using the avg. score per individual.<\/p>\n<pre><code>segment\na:  98%-100%\nb:  95%-97%\nc:  90%-94%\nd:  80%-89%\ne:  0% -79%\n<\/code><\/pre>\n<p>i did an if else formula which is this:<\/p>\n<pre><code>ifelse(score} &gt;= 98,'a',ifelse({score} &gt;= 95,'b',ifelse({score} &gt;= 90,'c',ifelse({score} &gt;= 80,'d','e'))))\n<\/code><\/pre>\n<p>this is now the output of what i did:<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>date<\/th>\n<th>name<\/th>\n<th>surveyid<\/th>\n<th>score<\/th>\n<th>error<\/th>\n<th>segement<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>2022-02-17<\/td>\n<td>jack<\/td>\n<td>10<\/td>\n<td>95<\/td>\n<td>name<\/td>\n<td>b<\/td>\n<\/tr>\n<tr>\n<td>2022-02-17<\/td>\n<td>jack<\/td>\n<td>10<\/td>\n<td>95<\/td>\n<td>address<\/td>\n<td>b<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>tom<\/td>\n<td>9<\/td>\n<td>100<\/td>\n<td><\/td>\n<td>a<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>carl<\/td>\n<td>8<\/td>\n<td>93<\/td>\n<td>zip<\/td>\n<td>c<\/td>\n<\/tr>\n<tr>\n<td>2022-02-16<\/td>\n<td>carl<\/td>\n<td>8<\/td>\n<td>93<\/td>\n<td>email<\/td>\n<td>c<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>zip<\/td>\n<td>e<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>email<\/td>\n<td>e<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>dan<\/td>\n<td>7<\/td>\n<td>72<\/td>\n<td>name<\/td>\n<td>e<\/td>\n<\/tr>\n<tr>\n<td>2022-02-15<\/td>\n<td>dan<\/td>\n<td>6<\/td>\n<td>90<\/td>\n<td>phone<\/td>\n<td>c<\/td>\n<\/tr>\n<tr>\n<td>2022-02-14<\/td>\n<td>tom<\/td>\n<td>5<\/td>\n<td>98<\/td>\n<td>gender<\/td>\n<td>a<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>i realized that the calculation i did only applies for the score. i was expecting an output like this:<\/p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>name<\/th>\n<th>average score<\/th>\n<th>total survey<\/th>\n<th>segement<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>jack<\/td>\n<td>95<\/td>\n<td>1<\/td>\n<td>b<\/td>\n<\/tr>\n<tr>\n<td>tom<\/td>\n<td>99<\/td>\n<td>2<\/td>\n<td>a<\/td>\n<\/tr>\n<tr>\n<td>carl<\/td>\n<td>93<\/td>\n<td>1<\/td>\n<td>c<\/td>\n<\/tr>\n<tr>\n<td>dan<\/td>\n<td>81<\/td>\n<td>2<\/td>\n<td>d<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>i have tried to create another calculated field for average score which is:<\/p>\n<pre><code>avgover({score}, [name], pre_agg)\n<\/code><\/pre>\n<p>i believe i am missing a distinct count of survey ids in that formula, that i do not know where to place. as for segmentation calculation, i cannot on my life figure that part out without getting aggregation errors on quicksight. please help, thank you.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to create a calculated field using if else and custom aggregation to segment data based on average score per individual, but is having difficulty with the segmentation calculation and including a distinct count of survey ids in the formula."
    },
    {
        "Question_id":41245211.0,
        "Question_title":"Azure ML LibraryExecutionError",
        "Question_body":"<p>I get the following error when trying to retrieve the data from Azure Machine Learning<\/p>\n\n<pre><code>Error: LibraryExecutionError\nTarget: Score Model (AFx Library)\nMessage: table: The data set being scored must contain all features used during training, missing feature(s): 'NA'.\n<\/code><\/pre>\n\n<p>If I include NA within the values that get sent to Azure I get the following message <\/p>\n\n<pre><code>Parsing of input vector failed. Verify the input vector has the correct number of columns and data types\n<\/code><\/pre>\n\n<p>Has anyone got any idea's on how to fix this issue?<\/p>\n\n<p>James<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1482245841440,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "c#",
            "azure",
            "machine-learning",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":187.0,
        "Owner_creation_time":1337118001492,
        "Owner_last_access_time":1642766080987,
        "Owner_reputation":97.0,
        "Owner_up_votes":33.0,
        "Owner_down_votes":0.0,
        "Owner_views":30.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Neath, Wales",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41245211",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  libraryexecutionerror; content:<p>i get the following error when trying to retrieve the data from <\/p>\n\n<pre><code>error: libraryexecutionerror\ntarget: score model (afx library)\nmessage: table: the data set being scored must contain all features used during training, missing feature(s): 'na'.\n<\/code><\/pre>\n\n<p>if i include na within the values that get sent to azure i get the following message <\/p>\n\n<pre><code>parsing of input vector failed. verify the input vector has the correct number of columns and data types\n<\/code><\/pre>\n\n<p>has anyone got any idea's on how to fix this issue?<\/p>\n\n<p>james<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when trying to retrieve data from Azure ML, and when they include 'na' within the values sent to Azure, they receive a message about the input vector."
    },
    {
        "Question_id":71909360.0,
        "Question_title":"Reading multiple csv files in AWS Sagemaker from a location in Amazon S3 Bucket",
        "Question_body":"<p>I have multiple csv files in a location in S3. The name of those files is in a date format. Example: 2021_09_30_Output.csv<\/p>\n<p>I need to understand how I can read all the files in this folder while selecting only the dates that I require. An example would be reading only the files from September. ie: &quot;2022_09_*.csv&quot; which would read only the files from that month<\/p>\n<p>Would appreciate the help. Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1650270357780,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "pandas",
            "amazon-web-services",
            "for-loop",
            "amazon-s3",
            "amazon-sagemaker"
        ],
        "Question_view_count":407.0,
        "Owner_creation_time":1607598608387,
        "Owner_last_access_time":1658981623800,
        "Owner_reputation":15.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71909360",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: reading multiple csv files in  from a location in amazon s3 bucket; content:<p>i have multiple csv files in a location in s3. the name of those files is in a date format. example: 2021_09_30_output.csv<\/p>\n<p>i need to understand how i can read all the files in this folder while selecting only the dates that i require. an example would be reading only the files from september. ie: &quot;2022_09_*.csv&quot; which would read only the files from that month<\/p>\n<p>would appreciate the help. thanks<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs help understanding how to read multiple csv files from a location in an Amazon S3 bucket, selecting only the files from a specific month (e.g. September) based on the date format of the file names."
    },
    {
        "Question_id":70599300.0,
        "Question_title":"Is it possible to pass MetricName as an Execution Input in AWS Step Functions for Sagemaker HyperParameter Optimization Job?",
        "Question_body":"<p>I have the following snippet from the step function workflow I'm currently working on (the context for this specific snippet can be found <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_CreateHyperParameterTuningJob.html\" rel=\"nofollow noreferrer\">here<\/a>).<\/p>\n<pre><code>&quot;HyperParameterTuningJobObjective&quot;: {\n        &quot;Type.$&quot;: &quot;$$.Execution.Input['ObjectiveHPOType']&quot;,\n        &quot;MetricName.$&quot;: &quot;States.Format('Validation:{}', $$.Execution.Input['EvalMetric'])&quot;\n      }\n<\/code><\/pre>\n<p>Context:\nThe step function I'm currently working on, receives from one of the execution inputs, the parameters <code>EvalMetric<\/code> and <code>ObjectiveHPOType<\/code>, which determines the name of the hyperparameter to be used, such as MCC, AUC, Accuracy, etc. This is to handle the step function in a generic and reusable way to be able to choose the metric to perform the HPO.<\/p>\n<p>However, doing so throws me the following error:<\/p>\n<pre><code>{\n  &quot;resourceType&quot;: &quot;sagemaker&quot;,\n  &quot;resource&quot;: &quot;createHyperParameterTuningJob.sync&quot;,\n  &quot;error&quot;: &quot;SageMaker.AmazonSageMakerException&quot;,\n  &quot;cause&quot;: &quot;A metric is required for this hyperparameter tuning job objective. Provide a metric in the metric definitions. (Service: AmazonSageMaker; Status Code: 400; Error Code:     ValidationException; Request ID: XXXX; Proxy: null)&quot;\n}\n<\/code><\/pre>\n<p>I suspect that the inner parameters such us <code>Type<\/code>and <code>MetricName<\/code>aren't quite supported to use JSONPath with the <code>.$<\/code> operand. That would explain that the machine doesn't recognize &quot;MetricName.$&quot; as &quot;MetricName&quot; parameter.<\/p>\n<p>Any help would be really welcomed! I've been stuck with this bug for days.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1641415024770,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker",
            "aws-step-functions"
        ],
        "Question_view_count":117.0,
        "Owner_creation_time":1641407737756,
        "Owner_last_access_time":1663940163540,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Santiago, Chile",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70599300",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is it possible to pass metricname as an execution input in aws step functions for  hyperparameter optimization job?; content:<p>i have the following snippet from the step function workflow i'm currently working on (the context for this specific snippet can be found <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/apireference\/api_createhyperparametertuningjob.html\" rel=\"nofollow noreferrer\">here<\/a>).<\/p>\n<pre><code>&quot;hyperparametertuningjobobjective&quot;: {\n        &quot;type.$&quot;: &quot;$$.execution.input['objectivehpotype']&quot;,\n        &quot;metricname.$&quot;: &quot;states.format('validation:{}', $$.execution.input['evalmetric'])&quot;\n      }\n<\/code><\/pre>\n<p>context:\nthe step function i'm currently working on, receives from one of the execution inputs, the parameters <code>evalmetric<\/code> and <code>objectivehpotype<\/code>, which determines the name of the hyperparameter to be used, such as mcc, auc, accuracy, etc. this is to handle the step function in a generic and reusable way to be able to choose the metric to perform the hpo.<\/p>\n<p>however, doing so throws me the following error:<\/p>\n<pre><code>{\n  &quot;resourcetype&quot;: &quot;&quot;,\n  &quot;resource&quot;: &quot;createhyperparametertuningjob.sync&quot;,\n  &quot;error&quot;: &quot;.amazonexception&quot;,\n  &quot;cause&quot;: &quot;a metric is required for this hyperparameter tuning job objective. provide a metric in the metric definitions. (service: amazon; status code: 400; error code:     validationexception; request id: xxxx; proxy: null)&quot;\n}\n<\/code><\/pre>\n<p>i suspect that the inner parameters such us <code>type<\/code>and <code>metricname<\/code>aren't quite supported to use jsonpath with the <code>.$<\/code> operand. that would explain that the machine doesn't recognize &quot;metricname.$&quot; as &quot;metricname&quot; parameter.<\/p>\n<p>any help would be really welcomed! i've been stuck with this bug for days.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to pass metricname as an execution input in an AWS Step Function for hyperparameter optimization job, but is receiving an error that suggests that the inner parameters such as type and metricname are not supported to use JSONPath with the .$ operand."
    },
    {
        "Question_id":null,
        "Question_title":"Wandb for Huggingface Trainer saves only first model",
        "Question_body":"<p>I am finetuning multiple models using for loop as follows.<\/p>\n<pre><code class=\"lang-auto\">for file in os.listdir(args.data_dir):\n    finetune(args, file)\n<\/code><\/pre>\n<p>BUT <code>wandb<\/code> shows logs only for the first file in <code>data_dir<\/code> although it is training and saving models for other files. It feels very strange behavior.<\/p>\n<pre><code class=\"lang-auto\">wandb: Synced bertweet-base-finetuned-file1: https:\/\/wandb.ai\/***\/huggingface\/runs\/***\n<\/code><\/pre>\n<p>This is a small snippet of <strong>finetuning<\/strong> code with Huggingface:<\/p>\n<pre><code class=\"lang-auto\">def finetune(args, file):\n    training_args = TrainingArguments(\n        output_dir=f'{model_name}-finetuned-{file}',\n        overwrite_output_dir=True,\n        evaluation_strategy='no',\n        num_train_epochs=args.epochs,\n        learning_rate=args.lr,\n        weight_decay=args.decay,\n        per_device_train_batch_size=args.batch_size,\n        per_device_eval_batch_size=args.batch_size,\n        fp16=True, # mixed-precision training to boost speed\n        save_strategy='no',\n        seed=args.seed,\n        dataloader_num_workers=4,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_dataset['train'],\n        eval_dataset=None,\n        data_collator=data_collator,\n    )\n    trainer.train()\n    trainer.save_model()\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1650439111790,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":123.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wandb-for-huggingface-trainer-saves-only-first-model\/2270",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "id":5388,
                "name":"Anmol Mann",
                "username":"anmolmann",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/c37758\/{size}.png",
                "created_at":"2022-04-20T19:56:12.331Z",
                "cooked":"<p><a class=\"mention\" href=\"\/u\/kgarg8\">@kgarg8<\/a> , you\u2019ve set <code>save_strategy<\/code> to NO in your code to avoid saving anything. This would only save the final model once training is done with <code>trainer.save_model()<\/code> . You can update it to <code>save_strategy=\"epoch\"<\/code> and it will save the model with every epoch.<\/p>\n<p>Or, in order <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/huggingface#turn-on-model-versioning\">to log models<\/a>, you could also set the env var <code>WANDB_LOG_MODEL<\/code> as <a href=\"https:\/\/docs.wandb.ai\/guides\/integrations\/huggingface#additional-w-and-b-settings\">specified in our docs here<\/a>. Once you set this env var, any Trainer you initialize from now on will upload models to your W&amp;B project. Note that your model will be saved to W&amp;B Artifacts as <code>run-{run_name}<\/code> .<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-04-20T19:56:12.331Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":2,
                "reads":4,
                "readers_count":3,
                "score":15.8,
                "yours":false,
                "topic_id":2270,
                "topic_slug":"wandb-for-huggingface-trainer-saves-only-first-model",
                "display_username":"Anmol Mann",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/docs.wandb.ai\/guides\/integrations\/huggingface#additional-w-and-b-settings",
                        "internal":false,
                        "reflection":false,
                        "clicks":0
                    },
                    {
                        "url":"https:\/\/docs.wandb.ai\/guides\/integrations\/huggingface#turn-on-model-versioning",
                        "internal":false,
                        "reflection":false,
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":419,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5415,
                "name":"Krishna Garg",
                "username":"kgarg8",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/f4b2a3\/{size}.png",
                "created_at":"2022-04-21T14:50:51.674Z",
                "cooked":"<p><code>wandb.init(reinit=True)<\/code> and <code>run.finish()<\/code> helped me to log the models <strong>separately<\/strong> on wandb website.<\/p>\n<p>The working code looks like below:<\/p>\n<pre><code class=\"lang-auto\">\nfor file in os.listdir(args.data_dir):\n    finetune(args, file)\n\nimport wandb\ndef finetune(args, file):\n    run = wandb.init(reinit=True)\n    ...\n    run.finish()\n<\/code><\/pre>\n<p>Reference: <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/launch#how-do-i-launch-multiple-runs-from-one-script\" class=\"inline-onebox\">Launch Experiments with wandb.init - Documentation<\/a><\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-04-21T14:50:51.674Z",
                "reply_count":0,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":13,
                "reads":4,
                "readers_count":3,
                "score":110.8,
                "yours":false,
                "topic_id":2270,
                "topic_slug":"wandb-for-huggingface-trainer-saves-only-first-model",
                "display_username":"Krishna Garg",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/docs.wandb.ai\/guides\/track\/launch#how-do-i-launch-multiple-runs-from-one-script",
                        "internal":false,
                        "reflection":false,
                        "title":"Launch Experiments with wandb.init - Documentation",
                        "clicks":2
                    }
                ],
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"anmolmann",
                    "name":"Anmol Mann",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/c37758\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1347,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":true
            },
            {
                "id":6222,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-06-20T14:51:40.355Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":4,
                "post_type":3,
                "updated_at":"2022-06-20T14:51:40.355Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2270,
                "topic_slug":"wandb-for-huggingface-trainer-saves-only-first-model",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  for huggingface trainer saves only first model; content:<p>i am finetuning multiple models using for loop as follows.<\/p>\n<pre><code class=\"lang-auto\">for file in os.listdir(args.data_dir):\n    finetune(args, file)\n<\/code><\/pre>\n<p>but <code><\/code> shows logs only for the first file in <code>data_dir<\/code> although it is training and saving models for other files. it feels very strange behavior.<\/p>\n<pre><code class=\"lang-auto\">: synced bertweet-base-finetuned-file1: https:\/\/.ai\/***\/huggingface\/runs\/***\n<\/code><\/pre>\n<p>this is a small snippet of <strong>finetuning<\/strong> code with huggingface:<\/p>\n<pre><code class=\"lang-auto\">def finetune(args, file):\n    training_args = trainingarguments(\n        output_dir=f'{model_name}-finetuned-{file}',\n        overwrite_output_dir=true,\n        evaluation_strategy='no',\n        num_train_epochs=args.epochs,\n        learning_rate=args.lr,\n        weight_decay=args.decay,\n        per_device_train_batch_size=args.batch_size,\n        per_device_eval_batch_size=args.batch_size,\n        fp16=true, # mixed-precision training to boost speed\n        save_strategy='no',\n        seed=args.seed,\n        dataloader_num_workers=4,\n    )\n\n    trainer = trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_dataset['train'],\n        eval_dataset=none,\n        data_collator=data_collator,\n    )\n    trainer.train()\n    trainer.save_model()\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an issue where the Huggingface trainer is only saving the first model when finetuning multiple models in a loop."
    },
    {
        "Question_id":66820884.0,
        "Question_title":"Access large BDF and EDF files stored on S3 from Sagemaker by URL and read them with mne library",
        "Question_body":"<p>I have a bucket on <a href=\"https:\/\/aws.amazon.com\/s3\/\" rel=\"nofollow noreferrer\"><strong>S3<\/strong><\/a> and a <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/gs-console.html\" rel=\"nofollow noreferrer\"><strong>SageMaker<\/strong><\/a> notebook. I try to get access to rather large <em>BDF<\/em> and <em>EDF<\/em> files (1-2 GB), stored on the <strong>S3<\/strong> bucket, without uploading them to <strong>SageMaker<\/strong> volume.\nI also need to access these files by URL as the <em>EDF<\/em> processing function <a href=\"https:\/\/mne.tools\/stable\/generated\/mne.io.read_raw_edf.html\" rel=\"nofollow noreferrer\"><code>mne.io.read_raw_edf<\/code><\/a> receives the absolute path to a file as an input.<\/p>\n<p>The <strong>S3<\/strong> bucket is in the same region as the <strong>Sagemaker Notebook Instance<\/strong>. The IAM role associated with the notebook instance is given permission to access the <strong>S3<\/strong> bucket.<\/p>\n<p>First, I tried to use the approach from <a href=\"https:\/\/stackoverflow.com\/questions\/48264656\/load-s3-data-into-aws-sagemaker-notebook\">this question<\/a>, that describes how to read <code>.csv<\/code> files. Although in my case it worked well with <code>.csv<\/code> files, it failed with <code>.edf<\/code> ones.<\/p>\n<pre><code>import pandas as pd\nfrom sagemaker import get_execution_role\n\nrole = get_execution_role()\n\nbucket='my-bucket'\nkey = 'train.edf'\ndata_location = 's3:\/\/{}\/{}'.format(bucket, key)\n\nmne.io.read_raw_edf(data_location)\n<\/code><\/pre>\n<p>When I execute this code, I receive the following error:<\/p>\n<pre><code>FileNotFoundError: [Errno 2] No such file or directory: '\/home\/ec2-user\/SageMaker\/s3:\/my-bucket\/train.edf'\n<\/code><\/pre>\n<p>Here I face a path stacking that was not done by me. I don't quite understand why <code>pd.read_csv<\/code> read paths normally, unlike <code>mne.io.read_raw_edf<\/code>, which seems to stack the local path and the server one.<\/p>\n<p>Then I found <a href=\"https:\/\/stackoverflow.com\/a\/34698521\/6936382\">an answer<\/a> to a very similar question but faced a very similar problem with the stacked paths.<\/p>\n<pre><code>import boto3\n\nbucket_location = boto3.client('s3').get_bucket_location(Bucket=bucket)\nobject_url = &quot;https:\/\/s3-{0}.amazonaws.com\/{1}\/{2}&quot;.format(\n    bucket_location['LocationConstraint'],\n    bucket,\n    key)\nobject_url\n<\/code><\/pre>\n<pre><code>'https:\/\/s3-us-west-2.amazonaws.com\/my-bucket\/train.edf'\n<\/code><\/pre>\n<p>Here we can see that the path is stored normally.<\/p>\n<pre><code>mne.io.read_raw_edf(object_url)\n<\/code><\/pre>\n<p>When I execute this code, I receive the following error:<\/p>\n<pre><code>FileNotFoundError: [Errno 2] No such file or directory: '\/home\/ec2-user\/SageMaker\/https:\/s3-us-west-2.amazonaws.com\/my-bucket\/train.edf'\n<\/code><\/pre>\n<p><code>mne.io.read_raw_edf<\/code> performs the weird stacking again.<\/p>\n<p>At last, I tried to follow the approach described in <a href=\"https:\/\/towardsdatascience.com\/working-with-amazon-s3-buckets-with-boto3-785252ea22e0\" rel=\"nofollow noreferrer\">this article<\/a>.<\/p>\n<pre><code>s3 = boto3.client(&quot;s3&quot;, \n                  region_name='us-west-2', \n                  aws_access_key_id='access_key_id', \n                  aws_secret_access_key='secret_access_key')\n\nshare_url = s3.generate_presigned_url(ClientMethod=&quot;get_object&quot;, \n                                      ExpiresIn=3600,\n                                      Params={&quot;Bucket&quot;: bucket, &quot;Key&quot;: key})\nshare_url\n<\/code><\/pre>\n<pre><code>'https:\/\/my-bucket.s3.amazonaws.com\/train.edf?AWSAccessKeyId=access_key_id&amp;Signature=signature&amp;Expires=1616777253'\n<\/code><\/pre>\n<p>The path seems to be normal again.<\/p>\n<pre><code>mne.io.read_raw_edf(share_url)\n<\/code><\/pre>\n<pre><code>NotImplementedError: Only EDF files are supported by read_raw_edf, got edf?awsaccesskeyid=access_key_id&amp;\nsignature=signature&amp;expires=1616777253\n<\/code><\/pre>\n<p>But here I got another weird <code>mne.io.read_raw_edf<\/code> behavior. No more stacking but the path was cropped.<\/p>\n<p>I assume that it could be <code>mne.io.read_raw_edf<\/code> problem itself, but I have never faced anything like this outside <strong>Amazon<\/strong> products.<\/p>\n<p>Does it make sense to get access to the <em>BDF<\/em> and <em>EDF<\/em> files by URLs or is it better to upload the files to the <strong>SageMaker<\/strong> volume? I apologize if this question seems naive. I've already spent a couple of days solving this problem, but I need to sort it out as soon as possible as <strong>Amazon<\/strong> takes money for every hour when the notebook is active.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1616776533403,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "amazon-s3",
            "amazon-sagemaker",
            "mne-python"
        ],
        "Question_view_count":189.0,
        "Owner_creation_time":1475832095700,
        "Owner_last_access_time":1639047960100,
        "Owner_reputation":57.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Moscow, Russia",
        "Question_last_edit_time":1616847212310,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66820884",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: access large bdf and edf files stored on s3 from  by url and read them with mne library; content:<p>i have a bucket on <a href=\"https:\/\/aws.amazon.com\/s3\/\" rel=\"nofollow noreferrer\"><strong>s3<\/strong><\/a> and a <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/gs-console.html\" rel=\"nofollow noreferrer\"><strong><\/strong><\/a> notebook. i try to get access to rather large <em>bdf<\/em> and <em>edf<\/em> files (1-2 gb), stored on the <strong>s3<\/strong> bucket, without uploading them to <strong><\/strong> volume.\ni also need to access these files by url as the <em>edf<\/em> processing function <a href=\"https:\/\/mne.tools\/stable\/generated\/mne.io.read_raw_edf.html\" rel=\"nofollow noreferrer\"><code>mne.io.read_raw_edf<\/code><\/a> receives the absolute path to a file as an input.<\/p>\n<p>the <strong>s3<\/strong> bucket is in the same region as the <strong> notebook instance<\/strong>. the iam role associated with the notebook instance is given permission to access the <strong>s3<\/strong> bucket.<\/p>\n<p>first, i tried to use the approach from <a href=\"https:\/\/stackoverflow.com\/questions\/48264656\/load-s3-data-into-aws--notebook\">this question<\/a>, that describes how to read <code>.csv<\/code> files. although in my case it worked well with <code>.csv<\/code> files, it failed with <code>.edf<\/code> ones.<\/p>\n<pre><code>import pandas as pd\nfrom  import get_execution_role\n\nrole = get_execution_role()\n\nbucket='my-bucket'\nkey = 'train.edf'\ndata_location = 's3:\/\/{}\/{}'.format(bucket, key)\n\nmne.io.read_raw_edf(data_location)\n<\/code><\/pre>\n<p>when i execute this code, i receive the following error:<\/p>\n<pre><code>filenotfounderror: [errno 2] no such file or directory: '\/home\/ec2-user\/\/s3:\/my-bucket\/train.edf'\n<\/code><\/pre>\n<p>here i face a path stacking that was not done by me. i don't quite understand why <code>pd.read_csv<\/code> read paths normally, unlike <code>mne.io.read_raw_edf<\/code>, which seems to stack the local path and the server one.<\/p>\n<p>then i found <a href=\"https:\/\/stackoverflow.com\/a\/34698521\/6936382\">an answer<\/a> to a very similar question but faced a very similar problem with the stacked paths.<\/p>\n<pre><code>import boto3\n\nbucket_location = boto3.client('s3').get_bucket_location(bucket=bucket)\nobject_url = &quot;https:\/\/s3-{0}.amazonaws.com\/{1}\/{2}&quot;.format(\n    bucket_location['locationconstraint'],\n    bucket,\n    key)\nobject_url\n<\/code><\/pre>\n<pre><code>'https:\/\/s3-us-west-2.amazonaws.com\/my-bucket\/train.edf'\n<\/code><\/pre>\n<p>here we can see that the path is stored normally.<\/p>\n<pre><code>mne.io.read_raw_edf(object_url)\n<\/code><\/pre>\n<p>when i execute this code, i receive the following error:<\/p>\n<pre><code>filenotfounderror: [errno 2] no such file or directory: '\/home\/ec2-user\/\/https:\/s3-us-west-2.amazonaws.com\/my-bucket\/train.edf'\n<\/code><\/pre>\n<p><code>mne.io.read_raw_edf<\/code> performs the weird stacking again.<\/p>\n<p>at last, i tried to follow the approach described in <a href=\"https:\/\/towardsdatascience.com\/working-with-amazon-s3-buckets-with-boto3-785252ea22e0\" rel=\"nofollow noreferrer\">this article<\/a>.<\/p>\n<pre><code>s3 = boto3.client(&quot;s3&quot;, \n                  region_name='us-west-2', \n                  aws_access_key_id='access_key_id', \n                  aws_secret_access_key='secret_access_key')\n\nshare_url = s3.generate_presigned_url(clientmethod=&quot;get_object&quot;, \n                                      expiresin=3600,\n                                      params={&quot;bucket&quot;: bucket, &quot;key&quot;: key})\nshare_url\n<\/code><\/pre>\n<pre><code>'https:\/\/my-bucket.s3.amazonaws.com\/train.edf?awsaccesskeyid=access_key_id&amp;signature=signature&amp;expires=1616777253'\n<\/code><\/pre>\n<p>the path seems to be normal again.<\/p>\n<pre><code>mne.io.read_raw_edf(share_url)\n<\/code><\/pre>\n<pre><code>notimplementederror: only edf files are supported by read_raw_edf, got edf?awsaccesskeyid=access_key_id&amp;\nsignature=signature&amp;expires=1616777253\n<\/code><\/pre>\n<p>but here i got another weird <code>mne.io.read_raw_edf<\/code> behavior. no more stacking but the path was cropped.<\/p>\n<p>i assume that it could be <code>mne.io.read_raw_edf<\/code> problem itself, but i have never faced anything like this outside <strong>amazon<\/strong> products.<\/p>\n<p>does it make sense to get access to the <em>bdf<\/em> and <em>edf<\/em> files by urls or is it better to upload the files to the <strong><\/strong> volume? i apologize if this question seems naive. i've already spent a couple of days solving this problem, but i need to sort it out as soon as possible as <strong>amazon<\/strong> takes money for every hour when the notebook is active.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to access large bdf and edf files stored on s3 from a notebook instance and read them with mne library, but is facing issues with path stacking and cropping."
    },
    {
        "Question_id":59573982.0,
        "Question_title":"Distributing DCGAN with horovod on Sagemaker",
        "Question_body":"<p>I am trying to distribute my workload to multiple GPUs with AWS Sagemaker. I am using a custom algorithm  for a DCGAN with tensorflow 2.0. The code thus far works perfect on a single GPU. I decided to implement the same code but with horovod distribution across multiple GPUs to reduce run time. The code, when changed from the original to horovod, seems to work the same, and the training time is roughly the same. However, when I print out hvd.size() I am only getting a  size of 1, regardless of the multiple GPU's present. Tensorflow recognizes all the present GPU's; Horovod, no.<\/p>\n\n<p>I've tried running my code on both Sagemaker and on an EC2 instance in a docker container, and in both environments the same issue persists.<\/p>\n\n<p>Here is the a link to my github repo:<\/p>\n\n<p><a href=\"https:\/\/github.com\/nogya3z\/sagemaker_dcgan_tf2.0\/tree\/distributed-gpu-dcgan\/container\" rel=\"nofollow noreferrer\">Here<\/a><\/p>\n\n<p>I've also tried using a different neural network entirely from the horovod repository, updated to tf2.0:<\/p>\n\n<p><a href=\"https:\/\/github.com\/horovod\/horovod\/blob\/master\/examples\/tensorflow2_mnist.py\" rel=\"nofollow noreferrer\">hvdmnist<\/a><\/p>\n\n<p>At this point I am only trying to get the GPU's within one instance to be utilized, and am not trying utilize multiple instances.<\/p>\n\n<p>I think I might be missing a dependency of some sort in the docker image, either that or there is some sort of prerequisite command for me to run. I don't really know.<\/p>\n\n<p>Thanks.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_creation_time":1578031986280,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "tensorflow",
            "amazon-sagemaker",
            "horovod"
        ],
        "Question_view_count":117.0,
        "Owner_creation_time":1578029446807,
        "Owner_last_access_time":1583911147070,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"New York, NY, USA",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59573982",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: distributing dcgan with horovod on ; content:<p>i am trying to distribute my workload to multiple gpus with . i am using a custom algorithm  for a dcgan with tensorflow 2.0. the code thus far works perfect on a single gpu. i decided to implement the same code but with horovod distribution across multiple gpus to reduce run time. the code, when changed from the original to horovod, seems to work the same, and the training time is roughly the same. however, when i print out hvd.size() i am only getting a  size of 1, regardless of the multiple gpu's present. tensorflow recognizes all the present gpu's; horovod, no.<\/p>\n\n<p>i've tried running my code on both  and on an ec2 instance in a docker container, and in both environments the same issue persists.<\/p>\n\n<p>here is the a link to my github repo:<\/p>\n\n<p><a href=\"https:\/\/github.com\/nogya3z\/_dcgan_tf2.0\/tree\/distributed-gpu-dcgan\/container\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n\n<p>i've also tried using a different neural network entirely from the horovod repository, updated to tf2.0:<\/p>\n\n<p><a href=\"https:\/\/github.com\/horovod\/horovod\/blob\/master\/examples\/tensorflow2_mnist.py\" rel=\"nofollow noreferrer\">hvdmnist<\/a><\/p>\n\n<p>at this point i am only trying to get the gpu's within one instance to be utilized, and am not trying utilize multiple instances.<\/p>\n\n<p>i think i might be missing a dependency of some sort in the docker image, either that or there is some sort of prerequisite command for me to run. i don't really know.<\/p>\n\n<p>thanks.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to distribute their workload to multiple GPUs with Horovod for a DCGAN with TensorFlow 2.0, but is only getting a size of 1 when printing hvd.size() regardless of the multiple GPUs present."
    },
    {
        "Question_id":null,
        "Question_title":"Azure ml notebooks sharing and compute selection.",
        "Question_body":"What kind of collaboration do we need among the data scientists or developers who need to share these notebooks? What kind of compute does these notebooks require? Is it all single node?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1591956129183,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/35432\/azure-ml-notebooks-sharing-and-compute-selection.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-12T11:43:28.857Z",
                "Answer_score":0,
                "Answer_body":"@azureml056-5112 Please follow the below for managing compute instances. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#managing-a-compute-instance All data scientists or developers need is access to the AzureML Workspace and they will have access to a shared file share where everyone\u2019s notebooks can be accessed.\n\n\n\n\nAll notebook require a Compute Instance(CI). CI is a managed VM that exists in AzureML.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  notebooks sharing and compute selection.; content:what kind of collaboration do we need among the data scientists or developers who need to share these notebooks? what kind of compute does these notebooks require? is it all single node?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to consider collaboration among data scientists and developers who need to share Azure ML notebooks, as well as the type of compute required for the notebooks, which may be single node or multiple nodes."
    },
    {
        "Question_id":61980244.0,
        "Question_title":"How to fix Artifacts not showing in MLflow UI",
        "Question_body":"<p>I'd used MLflow and logged parameters using the function below (from pydataberlin).<\/p>\n<pre><code>def train(alpha=0.5, l1_ratio=0.5):\n    # train a model with given parameters\n    warnings.filterwarnings(&quot;ignore&quot;)\n    np.random.seed(40)\n\n    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n    data_path = &quot;data\/wine-quality.csv&quot;\n    train_x, train_y, test_x, test_y = load_data(data_path)\n\n    # Useful for multiple runs (only doing one run in this sample notebook)    \n    with mlflow.start_run():\n        # Execute ElasticNet\n        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n        lr.fit(train_x, train_y)\n\n        # Evaluate Metrics\n        predicted_qualities = lr.predict(test_x)\n        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n        # Print out metrics\n        print(&quot;Elasticnet model (alpha=%f, l1_ratio=%f):&quot; % (alpha, l1_ratio))\n        print(&quot;  RMSE: %s&quot; % rmse)\n        print(&quot;  MAE: %s&quot; % mae)\n        print(&quot;  R2: %s&quot; % r2)\n\n        # Log parameter, metrics, and model to MLflow\n        mlflow.log_param(key=&quot;alpha&quot;, value=alpha)\n        mlflow.log_param(key=&quot;l1_ratio&quot;, value=l1_ratio)\n        mlflow.log_metric(key=&quot;rmse&quot;, value=rmse)\n        mlflow.log_metrics({&quot;mae&quot;: mae, &quot;r2&quot;: r2})\n        mlflow.log_artifact(data_path)\n        print(&quot;Save to: {}&quot;.format(mlflow.get_artifact_uri()))\n        \n        mlflow.sklearn.log_model(lr, &quot;model&quot;)\n<\/code><\/pre>\n<p>Once I run <code>train()<\/code> with its parameters, in UI I cannot see Artifacts, but I can see models and its parameters and Metric.<\/p>\n<p>In artifact tab it's written <code>No Artifacts Recorded Use the log artifact APIs to store file outputs from MLflow runs.<\/code> But in finder in models folders all Artifacts existe with models Pickle.<\/p>\n<p>help<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0.0,
        "Question_creation_time":1590280271933,
        "Question_favorite_count":0.0,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "artifacts",
            "mlflow"
        ],
        "Question_view_count":8044.0,
        "Owner_creation_time":1500490643012,
        "Owner_last_access_time":1663284031840,
        "Owner_reputation":722.0,
        "Owner_up_votes":703.0,
        "Owner_down_votes":8.0,
        "Owner_views":290.0,
        "Answer_body":"<p>Had a similar issue. In my case, I solved it by running <code>mlflow ui<\/code> inside the <code>mlruns<\/code> directory of your experiment.<\/p>\n<p>See the full discussion on Github <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/3030\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n<p>Hope it helps!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1593697638320,
        "Answer_score":4.0,
        "Owner_location":"France",
        "Question_last_edit_time":1656334439607,
        "Answer_last_edit_time":1593982070672,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61980244",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to fix artifacts not showing in  ui; content:<p>i'd used  and logged parameters using the function below (from pydataberlin).<\/p>\n<pre><code>def train(alpha=0.5, l1_ratio=0.5):\n    # train a model with given parameters\n    warnings.filterwarnings(&quot;ignore&quot;)\n    np.random.seed(40)\n\n    # read the wine-quality csv file (make sure you're running this from the root of !)\n    data_path = &quot;data\/wine-quality.csv&quot;\n    train_x, train_y, test_x, test_y = load_data(data_path)\n\n    # useful for multiple runs (only doing one run in this sample notebook)    \n    with .start_run():\n        # execute elasticnet\n        lr = elasticnet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n        lr.fit(train_x, train_y)\n\n        # evaluate metrics\n        predicted_qualities = lr.predict(test_x)\n        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n        # print out metrics\n        print(&quot;elasticnet model (alpha=%f, l1_ratio=%f):&quot; % (alpha, l1_ratio))\n        print(&quot;  rmse: %s&quot; % rmse)\n        print(&quot;  mae: %s&quot; % mae)\n        print(&quot;  r2: %s&quot; % r2)\n\n        # log parameter, metrics, and model to \n        .log_param(key=&quot;alpha&quot;, value=alpha)\n        .log_param(key=&quot;l1_ratio&quot;, value=l1_ratio)\n        .log_metric(key=&quot;rmse&quot;, value=rmse)\n        .log_metrics({&quot;mae&quot;: mae, &quot;r2&quot;: r2})\n        .log_artifact(data_path)\n        print(&quot;save to: {}&quot;.format(.get_artifact_uri()))\n        \n        .sklearn.log_model(lr, &quot;model&quot;)\n<\/code><\/pre>\n<p>once i run <code>train()<\/code> with its parameters, in ui i cannot see artifacts, but i can see models and its parameters and metric.<\/p>\n<p>in artifact tab it's written <code>no artifacts recorded use the log artifact apis to store file outputs from  runs.<\/code> but in finder in models folders all artifacts existe with models pickle.<\/p>\n<p>help<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to use the log artifact APIs to store file outputs from  runs in order to view the artifacts in the UI."
    },
    {
        "Question_id":71777914.0,
        "Question_title":"Change AWS SageMaker LogGroup Prefix?",
        "Question_body":"<p>We have applications for multiple tenants on our AWS account and would like to distinguish between them in different IAM roles. In most places this is already possible by limiting resource access based on naming patterns.<\/p>\n<p>For CloudWatch log groups of SageMaker training jobs however I have not seen a working solution yet. The tenants can choose the job name arbitrarily, and hence the only part of the LogGroup name that is available for pattern matching would be the prefix before the job name. This prefix however seems to be fixed to <code>\/aws\/sagemaker\/TrainingJobs<\/code>.<\/p>\n<p>Is there a way to change or extend this prefix in order to make such limiting possible? Say, for example <code>\/aws\/sagemaker\/TrainingJobs\/&lt;product&gt;-&lt;stage&gt;-&lt;component&gt;\/&lt;training-job-name&gt;-...<\/code> so that a resource limitation like <code>\/aws\/sagemaker\/TrainingJobs\/&lt;product&gt;-*<\/code> becomes possible?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1649316153020,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker",
            "amazon-cloudwatchlogs"
        ],
        "Question_view_count":48.0,
        "Owner_creation_time":1257535237563,
        "Owner_last_access_time":1663941276656,
        "Owner_reputation":1904.0,
        "Owner_up_votes":58.0,
        "Owner_down_votes":9.0,
        "Owner_views":321.0,
        "Answer_body":"<p>I think it is not possible to change the log streams names for any of the SageMaker services.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1651281451296,
        "Answer_score":0.0,
        "Owner_location":"Germany",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71777914",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: change  loggroup prefix?; content:<p>we have applications for multiple tenants on our aws account and would like to distinguish between them in different iam roles. in most places this is already possible by limiting resource access based on naming patterns.<\/p>\n<p>for cloudwatch log groups of  training jobs however i have not seen a working solution yet. the tenants can choose the job name arbitrarily, and hence the only part of the loggroup name that is available for pattern matching would be the prefix before the job name. this prefix however seems to be fixed to <code>\/aws\/\/trainingjobs<\/code>.<\/p>\n<p>is there a way to change or extend this prefix in order to make such limiting possible? say, for example <code>\/aws\/\/trainingjobs\/&lt;product&gt;-&lt;stage&gt;-&lt;component&gt;\/&lt;training-job-name&gt;-...<\/code> so that a resource limitation like <code>\/aws\/\/trainingjobs\/&lt;product&gt;-*<\/code> becomes possible?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if there is a way to change the Cloudwatch loggroup prefix in order to make resource limitation based on naming patterns possible."
    },
    {
        "Question_id":60056978.0,
        "Question_title":"AzureML: Unable to unpickle LightGBM model",
        "Question_body":"<p>I am trying to run an Azure ML pipeline. This pipeline trains a model, saves it a pickle file and then tries to unpickle it in the next step. When trying to unpickle it, I am facing the below issue in any random run:<\/p>\n\n<blockquote>\n  <p>Traceback (most recent call last):\n    File \"batch_scoring.py\", line 199, in \n      clf = joblib.load(open(model_path, 'rb'))\n    File \"\/azureml-envs\/azureml_347514cea2002d6bd71b42aceb1e4eeb\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py\", line 595, in load\n      obj = _unpickle(fobj)\n    File \"\/azureml-envs\/azureml_347514cea2002d6bd71b42aceb1e4eeb\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py\", line 529, in _unpickle\n      obj = unpickler.load()\n    File \"\/azureml-envs\/azureml_347514cea2002d6bd71b42aceb1e4eeb\/lib\/python3.6\/pickle.py\", line 1048, in load\n      raise EOFError\n  EOFError<\/p>\n<\/blockquote>\n\n<p>Has anyone faced this issue before?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5.0,
        "Question_creation_time":1580817662377,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning-service"
        ],
        "Question_view_count":319.0,
        "Owner_creation_time":1577025845723,
        "Owner_last_access_time":1582794024303,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":10.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60056978",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: : unable to unpickle lightgbm model; content:<p>i am trying to run an  pipeline. this pipeline trains a model, saves it a pickle file and then tries to unpickle it in the next step. when trying to unpickle it, i am facing the below issue in any random run:<\/p>\n\n<blockquote>\n  <p>traceback (most recent call last):\n    file \"batch_scoring.py\", line 199, in \n      clf = joblib.load(open(model_path, 'rb'))\n    file \"\/-envs\/_347514cea2002d6bd71b42aceb1e4eeb\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py\", line 595, in load\n      obj = _unpickle(fobj)\n    file \"\/-envs\/_347514cea2002d6bd71b42aceb1e4eeb\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py\", line 529, in _unpickle\n      obj = unpickler.load()\n    file \"\/-envs\/_347514cea2002d6bd71b42aceb1e4eeb\/lib\/python3.6\/pickle.py\", line 1048, in load\n      raise eoferror\n  eoferror<\/p>\n<\/blockquote>\n\n<p>has anyone faced this issue before?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to unpickle a lightgbm model when running an Azure ML pipeline, and is receiving an EOFError."
    },
    {
        "Question_id":70738638.0,
        "Question_title":"sagemaker.image_uris.retrieve: FileNotFoundError: [Errno 2] No such file or directory: '\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packa",
        "Question_body":"<p>I have an issue while getting xgboost image URI. It is a function for generating ECR image URIs for pre-built SageMaker Docker images.<\/p>\n<p>My code:<\/p>\n<p><code>region = sagemaker.Session().boto_region_name container=sagemaker.image_uris.retrieve(&quot;xgboost&quot;, region, &quot;1.2-1&quot;) <\/code><\/p>\n<p>Output:FileNotFoundError: [Errno 2] No such file or directory: '\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/image_uri_config\/xgboost.json'<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1642409290550,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "boto3",
            "amazon-sagemaker",
            "docker-image"
        ],
        "Question_view_count":392.0,
        "Owner_creation_time":1568734503088,
        "Owner_last_access_time":1663922598072,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70738638",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: .image_uris.retrieve: filenotfounderror: [errno 2] no such file or directory: '\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packa; content:<p>i have an issue while getting xgboost image uri. it is a function for generating ecr image uris for pre-built  docker images.<\/p>\n<p>my code:<\/p>\n<p><code>region = .session().boto_region_name container=.image_uris.retrieve(&quot;xgboost&quot;, region, &quot;1.2-1&quot;) <\/code><\/p>\n<p>output:filenotfounderror: [errno 2] no such file or directory: '\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/\/image_uri_config\/xgboost.json'<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an issue while attempting to retrieve an xgboost image uri using the .image_uris.retrieve function, resulting in a FileNotFoundError."
    },
    {
        "Question_id":null,
        "Question_title":"Handling imbalance dataset without altering the original dataset",
        "Question_body":"<p>Hi,<\/p>\n<p>i tried several methods to handle imbalanced datasets<\/p>\n<p>i used a simple single neuron ANN as a logistic regression model and a churn dataset<\/p>\n<p>under- and oversampling worked well (especially SMOTE) but to get deeper understanding i wonder if there are even simpler ways to do than altering the original dataset?<\/p>\n<p>my questions (sorry, too many of them):<\/p>\n<ol>\n<li>\n<p>is changing the threshold value after training a model a usual and proper\/professional way to handle imbalance dataset classification problem?<\/p>\n<ul>\n<li>if so, how to do it? just run over the trained model and test data modifying threshold and calculating f1?<br>\nis the best threshold where F1 score is the highest?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>is it a good idea to try to find a model with best AUC score using wandb sweeps and then find the best threshold value of that model maximizing the F1 score?<\/p>\n<\/li>\n<li>\n<p>what if i train a model with a threshold value other than 0.5<\/p>\n<ul>\n<li>doing wandb sweeps finding the best AUC or f1 score?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>applying class weights will help to improve recall but in return precision will decrease<\/p>\n<ul>\n<li>how to make it right? how to maximize F1 score?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>does it improve my model if i add one or more hidden layers to it?<\/p>\n<\/li>\n<\/ol>\n<p>thank you!<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1638702267373,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":219.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/handling-imbalance-dataset-without-altering-the-original-dataset\/1472",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":3660,
                "name":"Tamas Csakanyosi",
                "username":"teamtom",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/e8c25b\/{size}.png",
                "created_at":"2021-12-07T20:57:47.005Z",
                "cooked":"<p>can you help me?  <a class=\"mention\" href=\"\/u\/bhutanisanyam1\">@bhutanisanyam1<\/a><\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-12-07T20:57:47.005Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":1.2,
                "yours":false,
                "topic_id":1472,
                "topic_slug":"handling-imbalance-dataset-without-altering-the-original-dataset",
                "display_username":"Tamas Csakanyosi",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":474,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":3668,
                "name":"Scott Condron",
                "username":"_scott",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/_scott\/{size}\/95_2.png",
                "created_at":"2021-12-08T11:29:35.517Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/teamtom\">@teamtom<\/a><\/p>\n<p>These are all good questions and I wouldn\u2019t say there\u2019s concrete answers that apply in all cases.<\/p>\n<p>For tuning the output of your model, choosing a threshold value is generally a tradeoff between False Positives versus False Negatives. It\u2019s a consideration you\u2019ll want to make depending on the task. If getting the highest F1 is all you care about, then tuning your threshold to achieve this is ok. The only extra consideration here is to be sure to not tune to a test set, because that\u2019s considered bad practise.<\/p>\n<p>I would say for questions 1-4, they\u2019re all pretty similar and the answer is generally that it depends how you want your system to behave.<\/p>\n<p>For question 5, for questions like these where you\u2019re considering your model architecture, I would say you are better off using off the shelf architectures and understanding how they work by reading the papers that introduced them. The <a href=\"https:\/\/github.com\/rwightman\/pytorch-image-models\">Timm library<\/a> is a good resource to find image architectures and papers. Generally, more model capacity is a good thing, but deeper models can cause issues like vanishing gradients so there are approaches to overcome these like skip connections etc. For those reasons, it can often be a good idea to choose off-the-shelf architectures that\u2019ll fit on your machine.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-12-08T11:29:35.517Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":1472,
                "topic_slug":"handling-imbalance-dataset-without-altering-the-original-dataset",
                "display_username":"Scott Condron",
                "primary_group_name":"team",
                "flair_name":"team",
                "flair_url":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/27bab8f920bcd41717e467ec0a2929adc33869e5.png",
                "flair_bg_color":"ffffff",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/github.com\/rwightman\/pytorch-image-models",
                        "internal":false,
                        "reflection":false,
                        "title":"GitHub - rwightman\/pytorch-image-models: PyTorch image models, scripts, pretrained weights -- ResNet, ResNeXT, EfficientNet, EfficientNetV2, NFNet, Vision Transformer, MixNet, MobileNet-V3\/V2, RegNet, DPN, CSPNet, and more",
                        "clicks":2
                    }
                ],
                "read":true,
                "user_title":"Community Team",
                "title_is_group":true,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":85,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5362,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-04-20T18:02:06.969Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":4,
                "post_type":3,
                "updated_at":"2022-04-20T18:02:06.969Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":1472,
                "topic_slug":"handling-imbalance-dataset-without-altering-the-original-dataset",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: handling imbalance dataset without altering the original dataset; content:<p>hi,<\/p>\n<p>i tried several methods to handle imbalanced datasets<\/p>\n<p>i used a simple single neuron ann as a logistic regression model and a churn dataset<\/p>\n<p>under- and oversampling worked well (especially smote) but to get deeper understanding i wonder if there are even simpler ways to do than altering the original dataset?<\/p>\n<p>my questions (sorry, too many of them):<\/p>\n<ol>\n<li>\n<p>is changing the threshold value after training a model a usual and proper\/professional way to handle imbalance dataset classification problem?<\/p>\n<ul>\n<li>if so, how to do it? just run over the trained model and test data modifying threshold and calculating f1?<br>\nis the best threshold where f1 score is the highest?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>is it a good idea to try to find a model with best auc score using  sweeps and then find the best threshold value of that model maximizing the f1 score?<\/p>\n<\/li>\n<li>\n<p>what if i train a model with a threshold value other than 0.5<\/p>\n<ul>\n<li>doing  sweeps finding the best auc or f1 score?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>applying class weights will help to improve recall but in return precision will decrease<\/p>\n<ul>\n<li>how to make it right? how to maximize f1 score?<\/li>\n<\/ul>\n<\/li>\n<li>\n<p>does it improve my model if i add one or more hidden layers to it?<\/p>\n<\/li>\n<\/ol>\n<p>thank you!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking about ways to handle an imbalanced dataset without altering the original dataset, such as changing the threshold value after training a model, finding a model with the best AUC score, training a model with a threshold value other than 0.5, applying class weights, and adding one or more hidden layers."
    },
    {
        "Question_id":null,
        "Question_title":"Ground truth labeling job - unable to submit annotations",
        "Question_body":"Hi,\nI've been experiencing this issue when I tried to submit a response on the worker portal. The browser kept popping up a message saying \"something went wrong\" and instructed me to refresh. However, nothing changed after refreshing. Does anyone know what might be causing this? Thanks!",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1559512661000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker"
        ],
        "Question_view_count":93.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUOw2BnRGWTVmLfC-zcNN-RA\/ground-truth-labeling-job-unable-to-submit-annotations",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2019-06-22T18:44:40.000Z",
                "Answer_score":0,
                "Answer_body":"The issue turned out to be that I used a template from Mturk and some of the crowd-form attributes were not compatible with sage maker",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: ground truth labeling job - unable to submit annotations; content:hi,\ni've been experiencing this issue when i tried to submit a response on the worker portal. the browser kept popping up a message saying \"something went wrong\" and instructed me to refresh. however, nothing changed after refreshing. does anyone know what might be causing this? thanks!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty submitting annotations for a ground truth labeling job, and the browser keeps displaying a message saying \"something went wrong\" when they try to submit a response."
    },
    {
        "Question_id":null,
        "Question_title":"AzureMLCompute job failed: container registry failed unexpectedly: container setup task failed",
        "Question_body":"Hi,\n\nCould you please help me with running python script in azureml environment? I created the workspace and azure container registry and pushed docker image to the container. This is the example of dockerfile:\n\n FROM python:3.7\n    \n RUN pip install --upgrade pip\n    \n RUN pip install virtualenv\n    \n ENV VIRTUAL_ENV=\/venv\n    \n RUN virtualenv venv -p python3\n    \n ENV PATH=\"VIRTUAL_ENV\/bin:$PATH\"\n    \n WORKDIR \/app\n    \n ADD . \/app\n    \n ENV PYTHON_PACKAGES=\"\\\n      numpy \\\n  pandas \\\n  seaborn \\\n  matplotlib \\\n  sklearn \\\n  scipy \\\n  imbalanced-learn \\\n  xgboost \\\n  joblib \\\n \" \n    \n RUN pip install --no-cache-dir $PYTHON_PACKAGES\n    \n ENTRYPOINT [\"python3\",\"train.py\"]\n\n\n\nWhen I run the experiment I get this error:\n\n\"Message\": \"AzureMLCompute job failed.\\nJobContainerConfigFailed: Container configuration failed unexpectedly\\n\\tJobContainerConfigFailed: Container configuration failed unexpectedly\\n\\terr: container setup task failed: exit status 1\\n\\tReason: container setup task failed: exit status 1\\n\\tInfo: Failed to prepare an environment for the job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\"\n\n\n\n\nI do not understand what this error mean.\n\nThank you!",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_creation_time":1610999729247,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-container-instances"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/235234\/azuremlcompute-job-failed-container-registry-faile.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-20T10:39:50.733Z",
                "Answer_score":0,
                "Answer_body":"@MomirBeljic-9741 Thanks for the question. Could you please try the following solution given below.\nSolution:\nUpdated storage account key with below command.\nChange storage account access keys - Azure Machine Learning | Microsoft Docs\n\n\n\n\naz ml workspace sync-keys -w myworkspace -g myresourcegroup\n\nThis message occurs when the AML storage account restricts access to specific VNETs and the Compute Cluster isn\u2019t in that VNET.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: compute job failed: container registry failed unexpectedly: container setup task failed; content:hi,\n\ncould you please help me with running python script in  environment? i created the workspace and azure container registry and pushed docker image to the container. this is the example of dockerfile:\n\n from python:3.7\n    \n run pip install --upgrade pip\n    \n run pip install virtualenv\n    \n env virtual_env=\/venv\n    \n run virtualenv venv -p python3\n    \n env path=\"virtual_env\/bin:$path\"\n    \n workdir \/app\n    \n add . \/app\n    \n env python_packages=\"\\\n      numpy \\\n  pandas \\\n  seaborn \\\n  matplotlib \\\n  sklearn \\\n  scipy \\\n  imbalanced-learn \\\n  xgboost \\\n  joblib \\\n \" \n    \n run pip install --no-cache-dir $python_packages\n    \n entrypoint [\"python3\",\"train.py\"]\n\n\n\nwhen i run the experiment i get this error:\n\n\"message\": \"compute job failed.\\njobcontainerconfigfailed: container configuration failed unexpectedly\\n\\tjobcontainerconfigfailed: container configuration failed unexpectedly\\n\\terr: container setup task failed: exit status 1\\n\\treason: container setup task failed: exit status 1\\n\\tinfo: failed to prepare an environment for the job execution: job environment preparation failed on 10.0.0.5 with err exit status 1.\"\n\n\n\n\ni do not understand what this error mean.\n\nthank you!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having trouble running a python script in an environment and is receiving an error message about a compute job failing and a container setup task failing."
    },
    {
        "Question_id":72831360.0,
        "Question_title":"Use dataset registed in on pipelines in AML",
        "Question_body":"<p>I was following the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk\" rel=\"nofollow noreferrer\">SDK v2 Python tutorial<\/a> in order to create a pipeline job with my own assets. I notice that in this tutorial they let you use a csv file that can be downloaded but Im trying to use a registered dataset that I already registered by my own. The problem that I facing is that I dont know where I need to specify the dataset.<\/p>\n<p>The funny part is that at the beginning they create this dataset like this:<\/p>\n<pre><code>credit_data = ml_client.data.create_or_update(credit_data)\nprint(\n    f&quot;Dataset with name {credit_data.name} was registered to workspace, the dataset version is {credit_data.version}&quot;\n)\n<\/code><\/pre>\n<p>But the only part where they refer to this dataset is on the last part where they # the line:<\/p>\n<pre><code>registered_model_name = &quot;credit_defaults_model&quot;\n\n# Let's instantiate the pipeline with the parameters of our choice\npipeline = credit_defaults_pipeline(\n    # pipeline_job_data_input=credit_data,\n    pipeline_job_data_input=Input(type=&quot;uri_file&quot;, path=web_path),\n    pipeline_job_test_train_ratio=0.2,\n    pipeline_job_learning_rate=0.25,\n    pipeline_job_registered_model_name=registered_model_name,\n)\n<\/code><\/pre>\n<p>For me this means that I can use this data like this (a already registered dataset), the problem is that I don't know where I need to do the changes (I know that in the data_prep.py and in the code below but I don\u00b4t know where else) and I don't know how to set this:<\/p>\n<pre><code>%%writefile {data_prep_src_dir}\/data_prep.py\n...\n\ndef main():\n    &quot;&quot;&quot;Main function of the script.&quot;&quot;&quot;\n\n    # input and output arguments\n    parser = argparse.ArgumentParser()\n    parser.add_argument(&quot;--data&quot;, type=str, help=&quot;path to input data&quot;) # &lt;=== Here, but I don\u00b4t know how\n    parser.add_argument(&quot;--test_train_ratio&quot;, type=float, required=False, default=0.25)\n    parser.add_argument(&quot;--train_data&quot;, type=str, help=&quot;path to train data&quot;)\n    parser.add_argument(&quot;--test_data&quot;, type=str, help=&quot;path to test data&quot;)\n    args = parser.parse_args()\n\n...\n<\/code><\/pre>\n<p>Does anyone have experience working as registered datasets?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1656688618547,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-studio",
            "azure-machine-learning-service",
            "azure-sdk-python",
            "azureml-python-sdk"
        ],
        "Question_view_count":85.0,
        "Owner_creation_time":1636569000947,
        "Owner_last_access_time":1661898017243,
        "Owner_reputation":9.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":"<blockquote>\n<p>parser.add_argument(&quot;--data&quot;, type=str, help=&quot;path to input data&quot;) # &lt;=== Here, but I don\u00b4t know how<\/p>\n<\/blockquote>\n<p>To get the path to input data, according to <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/how-to-train-with-datasets.md\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n<ul>\n<li><p>You can get <code>--input-data<\/code> by ID which you can access in your training script.<\/p>\n<\/li>\n<li><p>Use it as <code>argument<\/code> on <code>mounted_input_path<\/code><\/p>\n<\/li>\n<\/ul>\n<p>For example, try the following three code snippets taken from the <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/how-to-train-with-datasets.md\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n<p><strong>Access dataset in training script:<\/strong><\/p>\n<pre><code>parser = argparse.ArgumentParser()\nparser.add_argument(&quot;--input-data&quot;, type=str)\nargs = parser.parse_args()\n\nrun = Run.get_context()\nws = run.experiment.workspace\n\n# get the input dataset by ID\ndataset = Dataset.get_by_id(ws, id=args.input_data)\n<\/code><\/pre>\n<p><strong>Configure the training run:<\/strong><\/p>\n<pre><code>src = ScriptRunConfig(source_directory=script_folder,\n                      script='train_titanic.py',\n                      # pass dataset as an input with friendly name 'titanic'\n                      arguments=['--input-data', titanic_ds.as_named_input('titanic')],\n                      compute_target=compute_target,\n                      environment=myenv)\n<\/code><\/pre>\n<p><strong>Pass <code>mounted_input_path<\/code> as argument:<\/strong><\/p>\n<pre><code>mounted_input_path = sys.argv[1]\nmounted_output_path = sys.argv[2]\n\nprint(&quot;Argument 1: %s&quot; % mounted_input_path)\nprint(&quot;Argument 2: %s&quot; % mounted_output_path)\n<\/code><\/pre>\n<p>References: <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/v1\/how-to-create-register-datasets.md\" rel=\"nofollow noreferrer\">How to create register dataset<\/a> and <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/scriptrun-with-data-input-output\/how-to-use-scriptrun.ipynb\" rel=\"nofollow noreferrer\">How to use configure a training run with data input and output<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1657082550892,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1657482591390,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72831360",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: use dataset registed in on pipelines in aml; content:<p>i was following the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk\" rel=\"nofollow noreferrer\">sdk v2 python tutorial<\/a> in order to create a pipeline job with my own assets. i notice that in this tutorial they let you use a csv file that can be downloaded but im trying to use a registered dataset that i already registered by my own. the problem that i facing is that i dont know where i need to specify the dataset.<\/p>\n<p>the funny part is that at the beginning they create this dataset like this:<\/p>\n<pre><code>credit_data = ml_client.data.create_or_update(credit_data)\nprint(\n    f&quot;dataset with name {credit_data.name} was registered to workspace, the dataset version is {credit_data.version}&quot;\n)\n<\/code><\/pre>\n<p>but the only part where they refer to this dataset is on the last part where they # the line:<\/p>\n<pre><code>registered_model_name = &quot;credit_defaults_model&quot;\n\n# let's instantiate the pipeline with the parameters of our choice\npipeline = credit_defaults_pipeline(\n    # pipeline_job_data_input=credit_data,\n    pipeline_job_data_input=input(type=&quot;uri_file&quot;, path=web_path),\n    pipeline_job_test_train_ratio=0.2,\n    pipeline_job_learning_rate=0.25,\n    pipeline_job_registered_model_name=registered_model_name,\n)\n<\/code><\/pre>\n<p>for me this means that i can use this data like this (a already registered dataset), the problem is that i don't know where i need to do the changes (i know that in the data_prep.py and in the code below but i don\u00b4t know where else) and i don't know how to set this:<\/p>\n<pre><code>%%writefile {data_prep_src_dir}\/data_prep.py\n...\n\ndef main():\n    &quot;&quot;&quot;main function of the script.&quot;&quot;&quot;\n\n    # input and output arguments\n    parser = argparse.argumentparser()\n    parser.add_argument(&quot;--data&quot;, type=str, help=&quot;path to input data&quot;) # &lt;=== here, but i don\u00b4t know how\n    parser.add_argument(&quot;--test_train_ratio&quot;, type=float, required=false, default=0.25)\n    parser.add_argument(&quot;--train_data&quot;, type=str, help=&quot;path to train data&quot;)\n    parser.add_argument(&quot;--test_data&quot;, type=str, help=&quot;path to test data&quot;)\n    args = parser.parse_args()\n\n...\n<\/code><\/pre>\n<p>does anyone have experience working as registered datasets?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to use a registered dataset in a pipeline job, but is unsure of how to specify the dataset and where to make the changes."
    },
    {
        "Question_id":null,
        "Question_title":"Make user admin for trial",
        "Question_body":"<p>Hi!<\/p>\n<p>I\u2019m trialing wanb for my company to see if its something we\u2019re interested in using.  My account is a \u201cmember\u201d account even though i\u2019m the one who created the Team.  I\u2019d like to invite other team members to my team but because my user isn\u2019t \u201cadmin\u201d status I cannot.  How can I get my team members added to the wand team I created?<\/p>\n<p>Thank you,<br>\nBlake<\/p>",
        "Question_answer_count":6,
        "Question_comment_count":null,
        "Question_creation_time":1633048801825,
        "Question_favorite_count":null,
        "Question_score":6.0,
        "Question_tags":null,
        "Question_view_count":283.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/make-user-admin-for-trial\/826",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2069,
                "name":"Sanyam Bhutani",
                "username":"bhutanisanyam1",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/bhutanisanyam1\/{size}\/18_2.png",
                "created_at":"2021-10-01T04:54:48.739Z",
                "cooked":"<p>Hi Blake,<\/p>\n<p>Welcome to our forums and Thanks for flagging this! I\u2019ll request the team to look into this and help you out ASAP. I\u2019ll reply as soon as I hear back (Slack appears to be down today so it might take a little longer <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> )<\/p>\n<p>In the meantime, please feel free to send any feedback\/questions our way about W&amp;B or beyond.<\/p>\n<p>Thanks,<br>\nSanyam<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-10-01T04:54:48.739Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":17,
                "readers_count":16,
                "score":18.4,
                "yours":false,
                "topic_id":826,
                "topic_slug":"make-user-admin-for-trial",
                "display_username":"Sanyam Bhutani",
                "primary_group_name":"team",
                "flair_name":"team",
                "flair_url":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/27bab8f920bcd41717e467ec0a2929adc33869e5.png",
                "flair_bg_color":"ffffff",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Community Team",
                "title_is_group":true,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":5,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2211,
                "name":"Blake Carpenter",
                "username":"openblake",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/o\/e68b1a\/{size}.png",
                "created_at":"2021-10-06T21:18:15.380Z",
                "cooked":"<p>Hello!<br>\nI was wondering if there has been any update on this?  We are trialing different services and will be making a decision shortly, so it would be helpful for me to show this to my team.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-10-06T21:18:15.380Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":12,
                "readers_count":11,
                "score":52.4,
                "yours":false,
                "topic_id":826,
                "topic_slug":"make-user-admin-for-trial",
                "display_username":"Blake Carpenter",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":493,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2218,
                "name":"Sanyam Bhutani",
                "username":"bhutanisanyam1",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/bhutanisanyam1\/{size}\/18_2.png",
                "created_at":"2021-10-07T12:56:40.044Z",
                "cooked":"<p>Hey <a class=\"mention\" href=\"\/u\/openblake\">@openblake<\/a>,<\/p>\n<p>Apologies for the small delay and Thanks for giving this a bump and checking!<\/p>\n<p>I\u2019ve re-requested the team to look into it, we\u2019ll have someone help you out today.<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2021-10-07T12:56:40.044Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":12,
                "readers_count":11,
                "score":2.4,
                "yours":false,
                "topic_id":826,
                "topic_slug":"make-user-admin-for-trial",
                "display_username":"Sanyam Bhutani",
                "primary_group_name":"team",
                "flair_name":"team",
                "flair_url":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/27bab8f920bcd41717e467ec0a2929adc33869e5.png",
                "flair_bg_color":"ffffff",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Community Team",
                "title_is_group":true,
                "reply_to_user":{
                    "username":"openblake",
                    "name":"Blake Carpenter",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/o\/e68b1a\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":5,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2224,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2021-10-07T15:59:28.359Z",
                "cooked":"<p>Hey Blake, can you tell me your organization name and your username?<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2021-10-07T15:59:28.359Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":11,
                "readers_count":10,
                "score":52.2,
                "yours":false,
                "topic_id":826,
                "topic_slug":"make-user-admin-for-trial",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2225,
                "name":"Blake Carpenter",
                "username":"openblake",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/o\/e68b1a\/{size}.png",
                "created_at":"2021-10-07T16:32:32.850Z",
                "cooked":"<p>openblakeis my username and my organization is OpenSpace<\/p>",
                "post_number":6,
                "post_type":1,
                "updated_at":"2021-10-07T16:32:32.850Z",
                "reply_count":1,
                "reply_to_post_number":5,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":11,
                "readers_count":10,
                "score":52.2,
                "yours":false,
                "topic_id":826,
                "topic_slug":"make-user-admin-for-trial",
                "display_username":"Blake Carpenter",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"armanharutyunyan",
                    "name":"Arman Harutyunyan",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":493,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2347,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2021-10-12T12:17:56.521Z",
                "cooked":"<p>You are now an admin of the team, Blake. Let me know if there are any issues<\/p>",
                "post_number":7,
                "post_type":1,
                "updated_at":"2021-10-12T12:17:56.521Z",
                "reply_count":0,
                "reply_to_post_number":6,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":46.2,
                "yours":false,
                "topic_id":826,
                "topic_slug":"make-user-admin-for-trial",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "reply_to_user":{
                    "username":"openblake",
                    "name":"Blake Carpenter",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/o\/e68b1a\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: make user admin for trial; content:<p>hi!<\/p>\n<p>i\u2019m trialing wanb for my company to see if its something we\u2019re interested in using.  my account is a \u201cmember\u201d account even though i\u2019m the one who created the team.  i\u2019d like to invite other team members to my team but because my user isn\u2019t \u201cadmin\u201d status i cannot.  how can i get my team members added to the wand team i created?<\/p>\n<p>thank you,<br>\nblake<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trialing Wanb for their company and would like to invite other team members to their team, but they cannot because their user is not an admin. They are asking how they can get their team members added to the Wand team they created."
    },
    {
        "Question_id":null,
        "Question_title":"SDK v1 or V2",
        "Question_body":"We are planing for next gen of product. Will V2 provide way more changes than V1?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1661977244390,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989368\/sdk-v1-or-v2.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-31T21:32:40.817Z",
                "Answer_score":0,
                "Answer_body":"Hello @nam-4027\n\nThanks for using Microsoft Q&A. I will recommend you keeping in V1 at this moment.\n\nSDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews.\n\nhttps:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: sdk v1 or v2; content:we are planing for next gen of product. will v2 provide way more changes than v1?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if version 2 of the SDK will provide more changes than version 1 for the next generation of the product."
    },
    {
        "Question_id":71195699.0,
        "Question_title":"wandb [SSL: WRONG_VERSION_NUMBER] error only thrown in Pycharm using python 3.8",
        "Question_body":"<p>I log the metrics of the training results on the wandb online server. This was working without any problems, till the beginning of this week. Since then i am suddenly unable to connect to the wandb online server and loggin the metrics isn't working anymore. I on Windows 10 using PyCharm with python version 3.8.<\/p>\n<p>The following exception is thrown:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connectionpool.py&quot;, line 696, in urlopen\n    self._prepare_proxy(conn)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connectionpool.py&quot;, line 964, in _prepare_proxy\n    conn.connect()\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connection.py&quot;, line 364, in connect\n    conn = self._connect_tls_proxy(hostname, conn)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connection.py&quot;, line 501, in _connect_tls_proxy\n    socket = ssl_wrap_socket(\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\util\\ssl_.py&quot;, line 453, in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\util\\ssl_.py&quot;, line 495, in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\ssl.py&quot;, line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\ssl.py&quot;, line 1040, in _create\n    self.do_handshake()\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\ssl.py&quot;, line 1309, in do_handshake\n    self._sslobj.do_handshake()\nssl.SSLError: [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1131)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\adapters.py&quot;, line 439, in send\n    resp = conn.urlopen(\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connectionpool.py&quot;, line 755, in urlopen\n    retries = retries.increment(\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\util\\retry.py&quot;, line 574, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: \/graphql (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1131)')))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\wandb\\sdk\\lib\\retry.py&quot;, line 102, in __call__\n    result = self._call_fn(*args, **kwargs)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\wandb\\sdk\\internal\\internal_api.py&quot;, line 132, in execute\n    return self.client.execute(*args, **kwargs)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\gql\\client.py&quot;, line 52, in execute\n    result = self._get_result(document, *args, **kwargs)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\gql\\client.py&quot;, line 60, in _get_result\n    return self.transport.execute(document, *args, **kwargs)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\gql\\transport\\requests.py&quot;, line 38, in execute\n    request = requests.post(self.url, **post_args)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\api.py&quot;, line 117, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\api.py&quot;, line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\sessions.py&quot;, line 542, in request\n    resp = self.send(prep, **send_kwargs)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\sessions.py&quot;, line 655, in send\n    r = adapter.send(request, **kwargs)\n  File &quot;C:\\Users\\Miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\adapters.py&quot;, line 514, in send\n    raise SSLError(e, request=request)\nrequests.exceptions.SSLError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: \/graphql (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1131)')))\nwandb: Network error (SSLError), entering retry loop.\nwandb: W&amp;B API key is configured (use `wandb login --relogin` to force relogin)\nwandb: Network error (SSLError), entering retry loop.\n<\/code><\/pre>\n<p>Strange thing is, if i execute the run configuration used in pycharm as a command from it's built in terminal it works fine. Since the same virtual environment is used on the built in terminal i don't understand why this exceptions is thrown if using the run configuration in Pycharm. What am i missing here?<\/p>\n<p>Any help would be appreciated.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_creation_time":1645369500377,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "python-3.x",
            "ssl",
            "pycharm",
            "wandb"
        ],
        "Question_view_count":259.0,
        "Owner_creation_time":1644055951303,
        "Owner_last_access_time":1651943996327,
        "Owner_reputation":41.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71195699",
        "Tool":"Weights & Biases",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  [ssl: wrong_version_number] error only thrown in pycharm using python 3.8; content:<p>i log the metrics of the training results on the  online server. this was working without any problems, till the beginning of this week. since then i am suddenly unable to connect to the  online server and loggin the metrics isn't working anymore. i on windows 10 using pycharm with python version 3.8.<\/p>\n<p>the following exception is thrown:<\/p>\n<pre><code>traceback (most recent call last):\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connectionpool.py&quot;, line 696, in urlopen\n    self._prepare_proxy(conn)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connectionpool.py&quot;, line 964, in _prepare_proxy\n    conn.connect()\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connection.py&quot;, line 364, in connect\n    conn = self._connect_tls_proxy(hostname, conn)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connection.py&quot;, line 501, in _connect_tls_proxy\n    socket = ssl_wrap_socket(\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\util\\ssl_.py&quot;, line 453, in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\util\\ssl_.py&quot;, line 495, in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\ssl.py&quot;, line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\ssl.py&quot;, line 1040, in _create\n    self.do_handshake()\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\ssl.py&quot;, line 1309, in do_handshake\n    self._sslobj.do_handshake()\nssl.sslerror: [ssl: wrong_version_number] wrong version number (_ssl.c:1131)\n\nduring handling of the above exception, another exception occurred:\n\ntraceback (most recent call last):\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\adapters.py&quot;, line 439, in send\n    resp = conn.urlopen(\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\connectionpool.py&quot;, line 755, in urlopen\n    retries = retries.increment(\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\urllib3\\util\\retry.py&quot;, line 574, in increment\n    raise maxretryerror(_pool, url, error or responseerror(cause))\nurllib3.exceptions.maxretryerror: httpsconnectionpool(host='api..ai', port=443): max retries exceeded with url: \/graphql (caused by sslerror(sslerror(1, '[ssl: wrong_version_number] wrong version number (_ssl.c:1131)')))\n\nduring handling of the above exception, another exception occurred:\n\ntraceback (most recent call last):\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\\\sdk\\lib\\retry.py&quot;, line 102, in __call__\n    result = self._call_fn(*args, **kwargs)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\\\sdk\\internal\\internal_api.py&quot;, line 132, in execute\n    return self.client.execute(*args, **kwargs)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\\\vendor\\gql-0.2.0\\gql\\client.py&quot;, line 52, in execute\n    result = self._get_result(document, *args, **kwargs)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\\\vendor\\gql-0.2.0\\gql\\client.py&quot;, line 60, in _get_result\n    return self.transport.execute(document, *args, **kwargs)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\\\vendor\\gql-0.2.0\\gql\\transport\\requests.py&quot;, line 38, in execute\n    request = requests.post(self.url, **post_args)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\api.py&quot;, line 117, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\api.py&quot;, line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\sessions.py&quot;, line 542, in request\n    resp = self.send(prep, **send_kwargs)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\sessions.py&quot;, line 655, in send\n    r = adapter.send(request, **kwargs)\n  file &quot;c:\\users\\miniconda3\\envs\\smartvision\\lib\\site-packages\\requests\\adapters.py&quot;, line 514, in send\n    raise sslerror(e, request=request)\nrequests.exceptions.sslerror: httpsconnectionpool(host='api..ai', port=443): max retries exceeded with url: \/graphql (caused by sslerror(sslerror(1, '[ssl: wrong_version_number] wrong version number (_ssl.c:1131)')))\n: network error (sslerror), entering retry loop.\n: w&amp;b api key is configured (use ` login --relogin` to force relogin)\n: network error (sslerror), entering retry loop.\n<\/code><\/pre>\n<p>strange thing is, if i execute the run configuration used in pycharm as a command from it's built in terminal it works fine. since the same virtual environment is used on the built in terminal i don't understand why this exceptions is thrown if using the run configuration in pycharm. what am i missing here?<\/p>\n<p>any help would be appreciated.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an SSL error when attempting to log metrics to an online server using PyCharm with Python 3.8, but the same command works fine when executed from the built-in terminal."
    },
    {
        "Question_id":57819173.0,
        "Question_title":"SageMaker AWS Binary Text Classification",
        "Question_body":"<p>Can AWS SageMaker handle binary classification using TFidf vectorized text as prediction base?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1567761634067,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "nlp",
            "amazon-sagemaker"
        ],
        "Question_view_count":109.0,
        "Owner_creation_time":1339151552347,
        "Owner_last_access_time":1663811742392,
        "Owner_reputation":1125.0,
        "Owner_up_votes":490.0,
        "Owner_down_votes":77.0,
        "Owner_views":319.0,
        "Answer_body":"<p>You would have to use inference pipeline for your use case. What that means is that you will need to use a pre-processing step to featurize your text into tfidf and then feed into Sagemaker classification. Here's a <a href=\"https:\/\/stackoverflow.com\/questions\/57767899\/how-to-create-a-pipeline-in-sagemaker-with-pytorch\">SO answer<\/a> with more details around this.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1567815655550,
        "Answer_score":1.0,
        "Owner_location":"Amsterdam, Netherlands",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57819173",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  aws binary text classification; content:<p>can  handle binary classification using tfidf vectorized text as prediction base?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if AWS can handle binary classification using TF-IDF vectorized text as the prediction base."
    },
    {
        "Question_id":71747545.0,
        "Question_title":"Commands in the Azure ML yml files",
        "Question_body":"<p>When reading the examples from Microsoft on azure ML CLI v2, they use the symbols:\n&quot;|&quot;, &quot;&gt;&quot;, etc., in their yml files.<\/p>\n<p>What do they mean, and where can I find explanations of possible syntax for the Azure CLI v2 engine?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1649142429250,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "yaml",
            "command-line-interface",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":100.0,
        "Owner_creation_time":1620049475608,
        "Owner_last_access_time":1663926087860,
        "Owner_reputation":3.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":8.0,
        "Answer_body":"<p>| - This pipe symbol in YAML document is used for <em><strong>&quot;Multiple line statements&quot;<\/strong><\/em><\/p>\n<pre><code>description: |\n  # Azure Machine Learning &quot;hello world&quot; job\n\n  This is a &quot;hello world&quot; job running in the cloud via Azure Machine Learning!\n\n  ## Description\n\n  Markdown is supported in the studio for job descriptions! You can edit the description there or via CLI.\n<\/code><\/pre>\n<p>in the above example, we need to write some multiple line description. So, we need to use &quot;|&quot; symbol<\/p>\n<p>&quot;&gt;&quot; - This symbol is used to save some content directly to a specific location document.<\/p>\n<pre><code>command: echo &quot;hello world&quot; &gt; .\/outputs\/helloworld.txt\n<\/code><\/pre>\n<p>In this above command, we need to post <strong>&quot;hello world&quot;<\/strong> to <em><strong>&quot;helloworld.txt&quot;<\/strong><\/em><\/p>\n<p>Check the below link for complete documentation regarding YAML files.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-job-command\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-job-command<\/a><\/p>\n<p>All these symbols are the YAML job commands which are used to accomplish a specific task through CLI.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1649231701843,
        "Answer_score":0.0,
        "Owner_location":"Denmark",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71747545",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: commands in the  yml files; content:<p>when reading the examples from microsoft on  cli v2, they use the symbols:\n&quot;|&quot;, &quot;&gt;&quot;, etc., in their yml files.<\/p>\n<p>what do they mean, and where can i find explanations of possible syntax for the azure cli v2 engine?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for an explanation of the symbols used in Azure ML CLI v2 YML files and an overview of the possible syntax for the engine."
    },
    {
        "Question_id":null,
        "Question_title":"DVC and AWS EFS",
        "Question_body":"<p>Hi. Can DVC work with an Amazon Web Services EFS volume? I looked at the list of supported storage types and did not see EFS, but figured I\u2019d ask here to be sure because my boss is asking me to be sure <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1646678462276,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":172.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-and-aws-efs\/1103",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2482,
                "name":"Pawe\u0142",
                "username":"Paffciu",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/d07c76\/{size}.png",
                "created_at":"2022-03-07T18:47:58.056Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/cesc\">@cesc<\/a><br>\nIsn\u2019t EFS a drive that you mount to your EC2 machine? If so, you could probably use it as a <code>local<\/code> remote type.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-03-07T18:47:58.056Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":1103,
                "topic_slug":"dvc-and-aws-efs",
                "display_username":"Pawe\u0142",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":79,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2496,
                "name":"",
                "username":"cesc",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/c\/5f8ce5\/{size}.png",
                "created_at":"2022-03-08T13:31:42.607Z",
                "cooked":"<p>That makes a lot of sense. Thanks!<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-03-08T13:31:42.607Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":1103,
                "topic_slug":"dvc-and-aws-efs",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":414,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  and aws efs; content:<p>hi. can  work with an amazon web services efs volume? i looked at the list of supported storage types and did not see efs, but figured i\u2019d ask here to be sure because my boss is asking me to be sure <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> thanks!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if they can work with an Amazon Web Services EFS volume, as it was not listed in the supported storage types."
    },
    {
        "Question_id":57782670.0,
        "Question_title":"mlflow log_model need to capture runId to use in mlflow models serve",
        "Question_body":"<p>runId generated in log_model call needs to be accessed in mlflow models serve<\/p>\n\n<p>I am trying to run mlflow bare minimum to deploy custom models<\/p>\n\n<p>1st step taken : I save the model using log_model\nobservation: the artifacts are duly saved in mlruns<\/p>\n\n<p>2nd step taken: i am able to serve using mlflow models serve -m runs:\nobservation: the server is started at 5000<\/p>\n\n<p>3rd step taken: i am able to run a curl invocation to predict\nobservation: prediction returned<\/p>\n\n<p>Question : How do i get the runId generated in Step1 to be passed to Step2\nie does the log_model<\/p>\n\n<p>Please advise the recommended workflow for the above use case (whether tracking\/mlflow server) need to be used etc..<\/p>\n\n<pre><code>mlflow.pyfunc.log_model(artifact_path=\"artifacts\", python_model=add5_model)\n<\/code><\/pre>\n\n<p>Question: how to access the runId returned by the above log_model to call in mlflow models serve -m runs<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1567578637513,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "mlflow"
        ],
        "Question_view_count":566.0,
        "Owner_creation_time":1456961602136,
        "Owner_last_access_time":1592975718443,
        "Owner_reputation":9.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1567584313430,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57782670",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  log_model need to capture runid to use in  models serve; content:<p>runid generated in log_model call needs to be accessed in  models serve<\/p>\n\n<p>i am trying to run  bare minimum to deploy custom models<\/p>\n\n<p>1st step taken : i save the model using log_model\nobservation: the artifacts are duly saved in mlruns<\/p>\n\n<p>2nd step taken: i am able to serve using  models serve -m runs:\nobservation: the server is started at 5000<\/p>\n\n<p>3rd step taken: i am able to run a curl invocation to predict\nobservation: prediction returned<\/p>\n\n<p>question : how do i get the runid generated in step1 to be passed to step2\nie does the log_model<\/p>\n\n<p>please advise the recommended workflow for the above use case (whether tracking\/ server) need to be used etc..<\/p>\n\n<pre><code>.pyfunc.log_model(artifact_path=\"artifacts\", python_model=add5_model)\n<\/code><\/pre>\n\n<p>question: how to access the runid returned by the above log_model to call in  models serve -m runs<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is using the log_model method from the `mlflow.pyfunc` module to save a model in the artifact repository, but they want to access the run ID generated by the log_model call in order to use it with the `mlflow models serve` command. They are trying to understand the recommended workflow for this use case and how to access the run ID."
    },
    {
        "Question_id":null,
        "Question_title":"Triton on Vertex AI does not support multiple models?",
        "Question_body":"Currently, I want to deploy a Triton server to Vertex AI endpoint. However I received this error message.\"failed to start Vertex AI service: Invalid argument - Expect the model repository contains only a single model if default model is not specified\"Is this mean that the Triton server deploy only support one model? It is different from what I have read in this document about concurrent model executionhttps:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/using-nvidia-triton",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1661411700000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":107.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Triton-on-Vertex-AI-does-not-support-multiple-models\/td-p\/459822\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-07T13:44:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"The error message suggest that you haven't selected a default model."
            },
            {
                "Answer_creation_time":"2022-10-17T07:18:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"Hi, I have the same issue and I couldn't find how to set a default model. Could you please link a guide about it or explain how to do that? Thanks"
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: triton on  does not support multiple models?; content:currently, i want to deploy a triton server to  endpoint. however i received this error message.\"failed to start  service: invalid argument - expect the model repository contains only a single model if default model is not specified\"is this mean that the triton server deploy only support one model? it is different from what i have read in this document about concurrent model executionhttps:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/using-nvidia-triton",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if Triton on does not support multiple models, as they received an error message when trying to deploy a Triton server. The documentation they read suggests that concurrent model execution is supported, so they are unsure if this is the case."
    },
    {
        "Question_id":null,
        "Question_title":"Cannot Create Batch Inference ParallelRunStep Pipeline",
        "Question_body":"Firstly, here is my entry script,\ndeploy model code,\n\n\n\n\n\n\n\nMy run keeps failing with the same errors\n\n\n\n\n\nI'm not sure if the entry script is failing to read the model or whether I have some authorisation issues.\nI have made so many attempts by adding datasets used in config file with SAS tokens from the respective containers, I even have\nowner authority access from containers and blob data reader etc, but nothing seems to work. Even when I register the model,\nI don't seem to have an AZURE_MODEL_DIR enviroment variable. Any advice would be much welcome",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1639579721297,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-batch"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/664931\/cannot-create-batch-inference-parallelrunstep-pipe.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-03T18:21:01.383Z",
                "Answer_score":0,
                "Answer_body":"@ShayneWilliams-5714\n\nHello,\n\nHope your issue has been resolved and sorry we have not hear back from you. I will link some guidance below for reference and please let us know if you are still blocked by this.\n\nIf you received auth issue but you think you have input the correct SAS, please check if you have the correct CORS setting.\n\nBatch Inference repo: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/README.md\n\nTroubleshooting guidance: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-parallel-run-step\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: cannot create batch inference parallelrunstep pipeline; content:firstly, here is my entry script,\ndeploy model code,\n\n\n\n\n\n\n\nmy run keeps failing with the same errors\n\n\n\n\n\ni'm not sure if the entry script is failing to read the model or whether i have some authorisation issues.\ni have made so many attempts by adding datasets used in config file with sas tokens from the respective containers, i even have\nowner authority access from containers and blob data reader etc, but nothing seems to work. even when i register the model,\ni don't seem to have an azure_model_dir enviroment variable. any advice would be much welcome",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty creating a batch inference parallelrunstep pipeline, and is unsure if the entry script is failing to read the model or if there are authorization issues. They have tried adding datasets with SAS tokens and have owner authority access, but nothing has worked."
    },
    {
        "Question_id":null,
        "Question_title":"Add alias to artifacts linked to a registered model\/collection",
        "Question_body":"<p>I can update the aliases of an artifact that is not linked to a registered model in the following manner:<\/p>\n<pre><code class=\"lang-auto\">    api = wandb.Api()\n    artifact = api.artifact('entity\/project\/artifact:v1')\n\n    # Add an alias\n    artifact.aliases.append('test')\n\n    # Persist all artifact modifications\n    artifact.save()\n<\/code><\/pre>\n<p>However, I  cannot update an artifact linked to a registered model\/collection.<\/p>\n<pre><code class=\"lang-auto\">    api = wandb.Api()\n    artifact = api.artifact('entity\/project\/collection:v1')\n\n    # Add an alias\n    artifact.aliases.append('test')\n\n    # Persist all artifact modifications\n    artifact.save()\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code class=\"lang-auto\">File \"\/usr\/local\/lib\/python3.8\/dist-packages\/requests\/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https:\/\/api.wandb.ai\/graphql\n<\/code><\/pre>\n<p>The only way to do it is by using the UI and manually adding an alias.<br>\nIs there a way to programmatically update the alias of an artifact in a collection\/registered model?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1665454587885,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":58.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-alias-to-artifacts-linked-to-a-registered-model-collection\/3237",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":7732,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-10-13T23:25:30.281Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/ahmeds\">@ahmeds<\/a> thank you for writing in, great to hear you\u2019re using the model registry! The API to interact with the registered models is still in progress, and more features will be available in future releases. The current supported commands can be found in <a href=\"https:\/\/docs.wandb.ai\/guides\/models\/walkthrough\">this<\/a> reference doc and the companion Colab.<\/p>\n<p>However, updating the aliases may be done by using the artifact and linking it back to the same. Please see below a code snippet:<\/p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nart = api.artifact('entity\/project\/artifact:v1', type='model')\nart.link('entity\/project\/artifact', aliases=['test'])\n<\/code><\/pre>\n<p>Would this work for you?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-10-13T23:25:30.281Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":4,
                "readers_count":3,
                "score":10.8,
                "yours":false,
                "topic_id":3237,
                "topic_slug":"add-alias-to-artifacts-linked-to-a-registered-model-collection",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/docs.wandb.ai\/guides\/models\/walkthrough",
                        "internal":false,
                        "reflection":false,
                        "title":"Model Management Walkthrough - Documentation",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7809,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-10-19T10:25:50.738Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/ahmeds\">@ahmeds<\/a> just checking in with you to see if you tried the above code and if it worked for you? thanks<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-10-19T10:25:50.738Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":5.6,
                "yours":false,
                "topic_id":3237,
                "topic_slug":"add-alias-to-artifacts-linked-to-a-registered-model-collection",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"thanos-wandb",
                    "name":"Thanos Vitsas",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7872,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-10-24T13:01:11.986Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/ahmeds\">@ahmeds<\/a> since we haven\u2019t heard back from you, I will close this ticket for now. If you still experience this issue, please let us know and we will keep investigating!<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-10-24T13:01:11.986Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":3237,
                "topic_slug":"add-alias-to-artifacts-linked-to-a-registered-model-collection",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"thanos-wandb",
                    "name":"Thanos Vitsas",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: add alias to artifacts linked to a registered model\/collection; content:<p>i can update the aliases of an artifact that is not linked to a registered model in the following manner:<\/p>\n<pre><code class=\"lang-auto\">    api = .api()\n    artifact = api.artifact('entity\/project\/artifact:v1')\n\n    # add an alias\n    artifact.aliases.append('test')\n\n    # persist all artifact modifications\n    artifact.save()\n<\/code><\/pre>\n<p>however, i  cannot update an artifact linked to a registered model\/collection.<\/p>\n<pre><code class=\"lang-auto\">    api = .api()\n    artifact = api.artifact('entity\/project\/collection:v1')\n\n    # add an alias\n    artifact.aliases.append('test')\n\n    # persist all artifact modifications\n    artifact.save()\n<\/code><\/pre>\n<p>error:<\/p>\n<pre><code class=\"lang-auto\">file \"\/usr\/local\/lib\/python3.8\/dist-packages\/requests\/models.py\", line 1021, in raise_for_status\n    raise httperror(http_error_msg, response=self)\nrequests.exceptions.httperror: 400 client error: bad request for url: https:\/\/api..ai\/graphql\n<\/code><\/pre>\n<p>the only way to do it is by using the ui and manually adding an alias.<br>\nis there a way to programmatically update the alias of an artifact in a collection\/registered model?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user cannot update the alias of an artifact linked to a registered model\/collection programmatically, and must use the UI to manually add an alias."
    },
    {
        "Question_id":71751564.0,
        "Question_title":"Register model version via MLflow Python API while carrying over input\/output schemas",
        "Question_body":"<p>I am trying to use the mlflow Python API to register models to an mlflow server's model registry. And in fact this does work:<\/p>\n<pre><code>model_version = client.create_model_version(\n    source=run.info.artifact_uri,\n    name='my_model',\n    run_id=run.info.run_id)    \n<\/code><\/pre>\n<p>Meaning the newly registered model version appears in the server's web UI.<\/p>\n<p>However, the input and output schemas that have been logged with the respective run are not carried over to the new model version (i.e. in the UI, the &quot;Schema&quot; tab under &quot;Registered Models &gt; my_model &gt; Version 2&quot; is empty). When I instead register the new model version via the web UI, the input and output schemas do appear there.<\/p>\n<p>How can I get mlflow to carry over the schemas even when using the Python API?<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1649160797570,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "mlflow",
            "mlops"
        ],
        "Question_view_count":118.0,
        "Owner_creation_time":1585647823903,
        "Owner_last_access_time":1663871963323,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Bochum, Germany",
        "Question_last_edit_time":1649416242088,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71751564",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: register model version via  python api while carrying over input\/output schemas; content:<p>i am trying to use the  python api to register models to an  server's model registry. and in fact this does work:<\/p>\n<pre><code>model_version = client.create_model_version(\n    source=run.info.artifact_uri,\n    name='my_model',\n    run_id=run.info.run_id)    \n<\/code><\/pre>\n<p>meaning the newly registered model version appears in the server's web ui.<\/p>\n<p>however, the input and output schemas that have been logged with the respective run are not carried over to the new model version (i.e. in the ui, the &quot;schema&quot; tab under &quot;registered models &gt; my_model &gt; version 2&quot; is empty). when i instead register the new model version via the web ui, the input and output schemas do appear there.<\/p>\n<p>how can i get  to carry over the schemas even when using the python api?<\/p>\n<p>thanks!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to use the Python API to register models to a server's model registry, but the input and output schemas are not being carried over. They are looking for a way to get the schemas to carry over when using the Python API."
    },
    {
        "Question_id":62305176.0,
        "Question_title":"Slow running of code in AWS for the first time",
        "Question_body":"<p>I am running my code on SageMaker, which runs my code slowly for the first time, but runs much faster the second time around. I guess there's something getting stored in the cache. Few days back, it was running with the same speed all the time. What could be a possible solution for this? <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>count_hea = 0\ncount_pleth = 0\nfor subfile in sorted(os.listdir('physionet.org\/files\/mimic3wdb-matched\/1.0\/p00')):\n    count_hea = 0\n    if subfile.startswith('p'):\n        for subsubfile in sorted(os.listdir(os.path.join('physionet.org\/files\/mimic3wdb-matched\/1.0\/p00\/' , subfile))):\n            if subsubfile.startswith('p') and count_hea == 0 and not subsubfile[:-4].endswith('n'):\n                try:            \n                    i = i + 1\n                    print(subsubfile)\n                    count_hea = count_hea + 1\n                    strip = subsubfile[:-4]\n                    record = wfdb.rdrecord('physionet.org\/files\/mimic3wdb-matched\/1.0\/p00\/' + subfile + '\/' + strip, channel_names = ['PLETH'], return_res = 16)\n                    r = record.__dict__\n                    print(r['sig_name'])\n                    if r['sig_name'] != None:\n                        if r['sig_name'][0] == 'PLETH':\n                            count_pleth = count_pleth + 1\n                            print(count_pleth)  \n                except Exception:\n                    pass\nprint(count_pleth)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1591796711163,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "caching",
            "amazon-sagemaker"
        ],
        "Question_view_count":942.0,
        "Owner_creation_time":1591590460687,
        "Owner_last_access_time":1607696037083,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1591811735903,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62305176",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: slow running of code in aws for the first time; content:<p>i am running my code on , which runs my code slowly for the first time, but runs much faster the second time around. i guess there's something getting stored in the cache. few days back, it was running with the same speed all the time. what could be a possible solution for this? <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>count_hea = 0\ncount_pleth = 0\nfor subfile in sorted(os.listdir('physionet.org\/files\/mimic3wdb-matched\/1.0\/p00')):\n    count_hea = 0\n    if subfile.startswith('p'):\n        for subsubfile in sorted(os.listdir(os.path.join('physionet.org\/files\/mimic3wdb-matched\/1.0\/p00\/' , subfile))):\n            if subsubfile.startswith('p') and count_hea == 0 and not subsubfile[:-4].endswith('n'):\n                try:            \n                    i = i + 1\n                    print(subsubfile)\n                    count_hea = count_hea + 1\n                    strip = subsubfile[:-4]\n                    record = wfdb.rdrecord('physionet.org\/files\/mimic3wdb-matched\/1.0\/p00\/' + subfile + '\/' + strip, channel_names = ['pleth'], return_res = 16)\n                    r = record.__dict__\n                    print(r['sig_name'])\n                    if r['sig_name'] != none:\n                        if r['sig_name'][0] == 'pleth':\n                            count_pleth = count_pleth + 1\n                            print(count_pleth)  \n                except exception:\n                    pass\nprint(count_pleth)\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing slow running of code in AWS for the first time, but it runs much faster the second time around. Possible solutions could include caching the code or optimizing the code for faster performance."
    },
    {
        "Question_id":62330719.0,
        "Question_title":"Write millions of files to S3 during post-processing with AWS Sagemaker",
        "Question_body":"<p>I am having trouble with data post-processing in AWS Sagemaker, where I need to split one large  text file with predictions (~2-10 GB) into millions of small files (one file per user ~3-10KB).<\/p>\n<p>Both the source and target files are stored in S3. The output files will be served to end-users using AWS API Gateway + AWS Lambda.<\/p>\n<p><strong>Jupyter notebook:<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import boto3\nfrom sagemaker import get_execution_role\nfrom sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput, NetworkConfig\n\n\nrole = get_execution_role()\ninstance_type = 'ml.m4.4xlarge'\necr_image_full_name = '0123456789.dkr.ecr.eu-central.amazonaws.com\/maslick-sagemaker-processing-image:latest'\n    \ninput_file = 'input.csv'\ninput_object = 's3:\/\/my-awesome-dataset\/input.csv'\noutput_object = 's3:\/\/my-awesome-results'\n    \nnetwork_config = NetworkConfig(enable_network_isolation=False,\n                               subnets=[&quot;subnet-12345&quot;, &quot;subnet-67890&quot;],\n                               security_group_ids=[&quot;sg-0123456789&quot;])\n    \nscript_processor = ScriptProcessor(role=role,\n                                   image_uri=ecr_image_full_name,\n                                   command=['python3'],\n                                   instance_count=1,\n                                   instance_type=instance_type)\n\ninput = ProcessingInput(source=input_object, destination='\/opt\/ml\/processing\/input')\noutput = ProcessingOutput(source='\/opt\/ml\/processing\/output', destination=output_object)\n    \nscript_processor.run(code='callable.py', inputs=[input], outputs=[output], arguments=[input_file])\n<\/code><\/pre>\n<p><strong>Dockerfile:<\/strong><\/p>\n<pre><code>FROM python:3.7-slim-buster\nRUN pip3 install pandas==0.25.3\nENV PYTHONUNBUFFERED=TRUE\n<\/code><\/pre>\n<p>Inside <code>callable.py<\/code> I preprocess the input file and put the result in <code>\/opt\/ml\/processing\/output<\/code>, e.g.:<\/p>\n<blockquote>\n<p><em>\/opt\/ml\/processing\/output\/93faa_654321010000007_latest.json<\/em><\/p>\n<\/blockquote>\n<p>The resulting file will be saved to S3 by ScriptProcessor:<\/p>\n<blockquote>\n<p><em>s3:\/\/my-awesome-results\/93faa_654321010000007_latest.json<\/em><\/p>\n<\/blockquote>\n<p>The input file is just a | delimited csv file, e.g.<\/p>\n<pre><code>654321010000007|1288858|AB|1\n654321010000008|1266069|AB|2\n654321010000009|0956486|AB|3\n654321010000010|1295930|AB|4\n654321010000011|0594956|AB|5\n654321010000012|1231767|AB|6\n654321010000013|1273878|CD|7\n654321010000014|1295236|AB|8\n654321010000015|1255404|AB|9\n<\/code><\/pre>\n<p>The resulting file would look like this (so basically callable.py will just iterate over each line and convert it to a json string):<\/p>\n<pre><code>{&quot;id&quot;: 654321010000007, &quot;article&quot;: 1288858, &quot;type&quot;: &quot;AB&quot;, &quot;rank&quot;: 1}\n<\/code><\/pre>\n<p><strong>callable.py<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import hashlib\nimport json\nimport sys\nfrom collections import defaultdict\nfrom concurrent.futures.process import ProcessPoolExecutor\nfrom pathlib import Path\nimport pandas as pd\n\n\ndef saveFilesMultiProcesses(items):\n    with ProcessPoolExecutor() as executor:\n        for item in items:\n            executor.submit(saveFile, item)\n\n\ndef readCsv(input_file):\n    colnames = ['id', 'article', 'type', 'rank']\n    df = pd.read_csv('\/opt\/ml\/processing\/input\/{}'.format(input_file), sep='|', names=colnames)\n    return df\n\n\ndef processCsv(df):\n    dicts = []\n    for row in df.itertuples():\n        dict = defaultdict(lambda: defaultdict(list))\n        dict[&quot;id&quot;] = row.id\n        dict[&quot;article&quot;] = row.article\n        dict[&quot;type&quot;] = row.type\n        dict[&quot;rank&quot;] = row.rank\n        dicts.append(dict)\n\n    return dicts\n\n\ndef saveFile(item):\n    hashed_prefix = hashlib.md5(str(item['id']).encode('utf-8')).hexdigest()\n    short = hashed_prefix[:5]\n\n    file_name = short + &quot;_&quot; + str(item['id']) + &quot;_latest.json&quot;\n    outfile = Path('\/opt\/ml\/processing\/output', file_name)\n    with open(outfile, 'w') as json_file:\n        json.dump(item, json_file)\n\n\nif __name__ == '__main__':\n    input_file = sys.argv[1]\n    df = readCsv(input_file)\n    list_of_dicts = processCsv(df)\n    saveFilesMultiProcesses(list_of_dicts)\n    print(&quot;Done. Wait until all files are saved to S3&quot;)\n<\/code><\/pre>\n<p>I've been able to process a small dataset (32MB, 13540 records). When I try 1.2 million records (2.2 GB), ScriptProcessor successfully processes the input file and saves the output files to <code>\/opt\/ml\/processing\/output<\/code>, however it fails to put them in S3 with the following error:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>---------------------------------------------------------------------------\nUnexpectedStatusException                 Traceback (most recent call last)\n&lt;ipython-input-66-48dccaef0bee&gt; in &lt;module&gt;()\n----&gt; 1 script_processor.run(code='callable.py', inputs=[input], outputs=[output], arguments=[input_file])\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/processing.py in run(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config)\n    402         self.jobs.append(self.latest_job)\n    403         if wait:\n--&gt; 404             self.latest_job.wait(logs=logs)\n    405 \n    406     def _get_user_code_name(self, code):\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/processing.py in wait(self, logs)\n    726         &quot;&quot;&quot;\n    727         if logs:\n--&gt; 728             self.sagemaker_session.logs_for_processing_job(self.job_name, wait=True)\n    729         else:\n    730             self.sagemaker_session.wait_for_processing_job(self.job_name)\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/session.py in logs_for_processing_job(self, job_name, wait, poll)\n   3132 \n   3133         if wait:\n-&gt; 3134             self._check_job_status(job_name, description, &quot;ProcessingJobStatus&quot;)\n   3135             if dot:\n   3136                 print()\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker\/session.py in _check_job_status(self, job, desc, status_key_name)\n   2636                 ),\n   2637                 allowed_statuses=[&quot;Completed&quot;, &quot;Stopped&quot;],\n-&gt; 2638                 actual_status=status,\n   2639             )\n   2640 \n\nUnexpectedStatusException: Error for Processing job maslick-sagemaker-processing-image-2020-06-11-15-42-34-593: Failed. Reason: InternalServerError: We encountered an internal error.  Please try again.\n\n<\/code><\/pre>\n<p>In the Sagemaker <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/api\/training\/processing.html?highlight=scriptprocessor#sagemaker.processing.ScriptProcessor\" rel=\"nofollow noreferrer\">documentation<\/a> it's written that the <code>Processor<\/code> class (and it's child class ScriptProcessor) is meant for data pre-processing, post-processing, feature engineering, data validation, and model evaluation. Apparently it's not meant for handling millions of files (put to S3).<\/p>\n<p>Any ideas?\nThanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1591898709927,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-s3",
            "etl",
            "amazon-sagemaker"
        ],
        "Question_view_count":639.0,
        "Owner_creation_time":1384530039387,
        "Owner_last_access_time":1664020852630,
        "Owner_reputation":2470.0,
        "Owner_up_votes":910.0,
        "Owner_down_votes":11.0,
        "Owner_views":285.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Ljubljana, Slovenia",
        "Question_last_edit_time":1592979174520,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62330719",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: write millions of files to s3 during post-processing with ; content:<p>i am having trouble with data post-processing in , where i need to split one large  text file with predictions (~2-10 gb) into millions of small files (one file per user ~3-10kb).<\/p>\n<p>both the source and target files are stored in s3. the output files will be served to end-users using aws api gateway + aws lambda.<\/p>\n<p><strong>jupyter notebook:<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import boto3\nfrom  import get_execution_role\nfrom .processing import scriptprocessor, processinginput, processingoutput, networkconfig\n\n\nrole = get_execution_role()\ninstance_type = 'ml.m4.4xlarge'\necr_image_full_name = '0123456789.dkr.ecr.eu-central.amazonaws.com\/maslick--processing-image:latest'\n    \ninput_file = 'input.csv'\ninput_object = 's3:\/\/my-awesome-dataset\/input.csv'\noutput_object = 's3:\/\/my-awesome-results'\n    \nnetwork_config = networkconfig(enable_network_isolation=false,\n                               subnets=[&quot;subnet-12345&quot;, &quot;subnet-67890&quot;],\n                               security_group_ids=[&quot;sg-0123456789&quot;])\n    \nscript_processor = scriptprocessor(role=role,\n                                   image_uri=ecr_image_full_name,\n                                   command=['python3'],\n                                   instance_count=1,\n                                   instance_type=instance_type)\n\ninput = processinginput(source=input_object, destination='\/opt\/ml\/processing\/input')\noutput = processingoutput(source='\/opt\/ml\/processing\/output', destination=output_object)\n    \nscript_processor.run(code='callable.py', inputs=[input], outputs=[output], arguments=[input_file])\n<\/code><\/pre>\n<p><strong>dockerfile:<\/strong><\/p>\n<pre><code>from python:3.7-slim-buster\nrun pip3 install pandas==0.25.3\nenv pythonunbuffered=true\n<\/code><\/pre>\n<p>inside <code>callable.py<\/code> i preprocess the input file and put the result in <code>\/opt\/ml\/processing\/output<\/code>, e.g.:<\/p>\n<blockquote>\n<p><em>\/opt\/ml\/processing\/output\/93faa_654321010000007_latest.json<\/em><\/p>\n<\/blockquote>\n<p>the resulting file will be saved to s3 by scriptprocessor:<\/p>\n<blockquote>\n<p><em>s3:\/\/my-awesome-results\/93faa_654321010000007_latest.json<\/em><\/p>\n<\/blockquote>\n<p>the input file is just a | delimited csv file, e.g.<\/p>\n<pre><code>654321010000007|1288858|ab|1\n654321010000008|1266069|ab|2\n654321010000009|0956486|ab|3\n654321010000010|1295930|ab|4\n654321010000011|0594956|ab|5\n654321010000012|1231767|ab|6\n654321010000013|1273878|cd|7\n654321010000014|1295236|ab|8\n654321010000015|1255404|ab|9\n<\/code><\/pre>\n<p>the resulting file would look like this (so basically callable.py will just iterate over each line and convert it to a json string):<\/p>\n<pre><code>{&quot;id&quot;: 654321010000007, &quot;article&quot;: 1288858, &quot;type&quot;: &quot;ab&quot;, &quot;rank&quot;: 1}\n<\/code><\/pre>\n<p><strong>callable.py<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import hashlib\nimport json\nimport sys\nfrom collections import defaultdict\nfrom concurrent.futures.process import processpoolexecutor\nfrom pathlib import path\nimport pandas as pd\n\n\ndef savefilesmultiprocesses(items):\n    with processpoolexecutor() as executor:\n        for item in items:\n            executor.submit(savefile, item)\n\n\ndef readcsv(input_file):\n    colnames = ['id', 'article', 'type', 'rank']\n    df = pd.read_csv('\/opt\/ml\/processing\/input\/{}'.format(input_file), sep='|', names=colnames)\n    return df\n\n\ndef processcsv(df):\n    dicts = []\n    for row in df.itertuples():\n        dict = defaultdict(lambda: defaultdict(list))\n        dict[&quot;id&quot;] = row.id\n        dict[&quot;article&quot;] = row.article\n        dict[&quot;type&quot;] = row.type\n        dict[&quot;rank&quot;] = row.rank\n        dicts.append(dict)\n\n    return dicts\n\n\ndef savefile(item):\n    hashed_prefix = hashlib.md5(str(item['id']).encode('utf-8')).hexdigest()\n    short = hashed_prefix[:5]\n\n    file_name = short + &quot;_&quot; + str(item['id']) + &quot;_latest.json&quot;\n    outfile = path('\/opt\/ml\/processing\/output', file_name)\n    with open(outfile, 'w') as json_file:\n        json.dump(item, json_file)\n\n\nif __name__ == '__main__':\n    input_file = sys.argv[1]\n    df = readcsv(input_file)\n    list_of_dicts = processcsv(df)\n    savefilesmultiprocesses(list_of_dicts)\n    print(&quot;done. wait until all files are saved to s3&quot;)\n<\/code><\/pre>\n<p>i've been able to process a small dataset (32mb, 13540 records). when i try 1.2 million records (2.2 gb), scriptprocessor successfully processes the input file and saves the output files to <code>\/opt\/ml\/processing\/output<\/code>, however it fails to put them in s3 with the following error:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>---------------------------------------------------------------------------\nunexpectedstatusexception                 traceback (most recent call last)\n&lt;ipython-input-66-48dccaef0bee&gt; in &lt;module&gt;()\n----&gt; 1 script_processor.run(code='callable.py', inputs=[input], outputs=[output], arguments=[input_file])\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/\/processing.py in run(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config)\n    402         self.jobs.append(self.latest_job)\n    403         if wait:\n--&gt; 404             self.latest_job.wait(logs=logs)\n    405 \n    406     def _get_user_code_name(self, code):\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/\/processing.py in wait(self, logs)\n    726         &quot;&quot;&quot;\n    727         if logs:\n--&gt; 728             self._session.logs_for_processing_job(self.job_name, wait=true)\n    729         else:\n    730             self._session.wait_for_processing_job(self.job_name)\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/\/session.py in logs_for_processing_job(self, job_name, wait, poll)\n   3132 \n   3133         if wait:\n-&gt; 3134             self._check_job_status(job_name, description, &quot;processingjobstatus&quot;)\n   3135             if dot:\n   3136                 print()\n\n~\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/\/session.py in _check_job_status(self, job, desc, status_key_name)\n   2636                 ),\n   2637                 allowed_statuses=[&quot;completed&quot;, &quot;stopped&quot;],\n-&gt; 2638                 actual_status=status,\n   2639             )\n   2640 \n\nunexpectedstatusexception: error for processing job maslick--processing-image-2020-06-11-15-42-34-593: failed. reason: internalservererror: we encountered an internal error.  please try again.\n\n<\/code><\/pre>\n<p>in the  <a href=\"https:\/\/.readthedocs.io\/en\/stable\/api\/training\/processing.html?highlight=scriptprocessor#.processing.scriptprocessor\" rel=\"nofollow noreferrer\">documentation<\/a> it's written that the <code>processor<\/code> class (and it's child class scriptprocessor) is meant for data pre-processing, post-processing, feature engineering, data validation, and model evaluation. apparently it's not meant for handling millions of files (put to s3).<\/p>\n<p>any ideas?\nthanks in advance.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having trouble post-processing a large text file with predictions into millions of small files and writing them to S3 using ScriptProcessor."
    },
    {
        "Question_id":null,
        "Question_title":"How to get model references logged by a specific run?",
        "Question_body":"We are trying to save a model using log_model_ref and add a name to it, i.e. best_auc. Then we want to be able to retrieve this model from the latest run.\nHowever, if we use RunClient.client.runs_v1.get_runs_artifacts_lineage this returns all the artifacts ever generated for that project. And if we use RunClient.get_artifacts_tree, we do have more control about which run we are looking at, but we lose the name information we set when using log_model_ref?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1649410139000,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "area\/client",
            "area\/registry"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1485",
        "Tool":"Polyaxon",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-08T09:30:38Z",
                "Answer_score":1,
                "Answer_body":"To get the logged model refs:\n\nfrom polyaxon.client import RunClient\n\nrun_client = RunClient(project=\"PROJECT_NAME\", run_uuid=\"RUN_UUID\")\n\n# Query the lineage information\nlineages = run_client.get_artifacts_lineage(query=\"kind: model\").results\n\n# Download the lineage assets\nfor lineage in lineages:\n    run_client.download_artifact_for_lineage(lineage=lineage)\n\nYou can restrict the ref to specific lineage by filtering further by name:\n\nlineages = run_client.get_artifacts_lineage(query=\"kind: model, name: best_auc\").results"
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":-1.0,
        "Question_original_content_preprocessed_text":"title: how to get model references logged by a specific run?; content:we are trying to save a model using log_model_ref and add a name to it, i.e. best_auc. then we want to be able to retrieve this model from the latest run.\nhowever, if we use runclient.client.runs_v1.get_runs_artifacts_lineage this returns all the artifacts ever generated for that project. and if we use runclient.get_artifacts_tree, we do have more control about which run we are looking at, but we lose the name information we set when using log_model_ref?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to save a model using log_model_ref and add a name to it, and then retrieve it from the latest run. They have tried using runclient.client.runs_v1.get_runs_artifacts_lineage, but this returns all the artifacts ever generated for that project. They have also tried using runclient.get_artifacts_tree, but this loses the name information set when using log_model_ref."
    },
    {
        "Question_id":null,
        "Question_title":"Unable to import prophet",
        "Question_body":"I am attempting to run Prophet (fbprophet) in an Azure Notebook. I have installed prophet using the terminal window and it is listed as an installed package (prophet (0.1.1.post1)).\n\nWhen I attempt to import the Prophet module using either of the following commands in a Notebook cell I receive the error message; \"ModuleNotFoundError: No module named 'prophet'\"\n\n from fbprophet import Prophet\n or\n from prophet import Prophet\n\nCould someone please assist...thank you.",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1650846070067,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/824199\/unable-to-import-prophet.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-25T10:22:14.557Z",
                "Answer_score":0,
                "Answer_body":"@GrahamBenson-6517 Please try installing the package using the notebook cells instead of terminal window since you are running different kernels for the notebook session.\nPlease try the following from the cell and try to import the package.\n\n %pip install Prophet\n\n\n\nWorked in my notebook as seen below.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: unable to import prophet; content:i am attempting to run prophet (fbprophet) in an azure notebook. i have installed prophet using the terminal window and it is listed as an installed package (prophet (0.1.1.post1)).\n\nwhen i attempt to import the prophet module using either of the following commands in a notebook cell i receive the error message; \"modulenotfounderror: no module named 'prophet'\"\n\n from fbprophet import prophet\n or\n from prophet import prophet\n\ncould someone please assist...thank you.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to import the prophet module in an Azure notebook, despite having installed it, and is asking for assistance."
    },
    {
        "Question_id":60334889.0,
        "Question_title":"\"No Kernel!\" error Azure ML compute JupyterLab",
        "Question_body":"<p>When using the JupyterLab found within the azure ML compute instance, every now and then, I run into an issue where it will say that network connection is lost. <\/p>\n\n<p>I have confirmed that the computer is still running.\nthe notebook itself can be edited and saved, so the computer\/VM is definitely running\nOf course, the internet is fully functional<\/p>\n\n<p>On the top right corner <em>next to the now blank circle<\/em> it will say \"No Kernel!\"<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0.0,
        "Question_creation_time":1582274394260,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-studio",
            "azure-machine-learning-service",
            "azure-machine-learning-workbench"
        ],
        "Question_view_count":1026.0,
        "Owner_creation_time":1442334437952,
        "Owner_last_access_time":1664002198907,
        "Owner_reputation":2272.0,
        "Owner_up_votes":1340.0,
        "Owner_down_votes":67.0,
        "Owner_views":516.0,
        "Answer_body":"<p>We can't repro the issue, can you help gives us more details? One possibility is that the kernel has bugs and hangs (could be due to extensions, widgets installed) or the resources on the machine are exhausted and kernel dies. What VM type are you using? If it's a small VM you may ran out of resources.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1582323157643,
        "Answer_score":1.0,
        "Owner_location":"Bangalore, Karnataka, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60334889",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: \"no kernel!\" error  compute jupyterlab; content:<p>when using the jupyterlab found within the  compute instance, every now and then, i run into an issue where it will say that network connection is lost. <\/p>\n\n<p>i have confirmed that the computer is still running.\nthe notebook itself can be edited and saved, so the computer\/vm is definitely running\nof course, the internet is fully functional<\/p>\n\n<p>on the top right corner <em>next to the now blank circle<\/em> it will say \"no kernel!\"<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an issue where the Azure ML Compute JupyterLab instance will display a \"no kernel!\" error, despite the computer\/VM still running and the internet being fully functional."
    },
    {
        "Question_id":71136057.0,
        "Question_title":"Identifying user from AWS Sagemaker Studio generated EFS storage",
        "Question_body":"<p>When a sagemaker studio domain is created. An EFS storage is associated with the domain. As the assigned users log into Sagemaker studio, a corresponding home directory is created.<\/p>\n<p>Using a separate EC2 instance, I mounted the EFS storage that was created to try to see whether is it possible to look at each of the individual home domains. I noticed that each of these home directories are shown in terms of numbers (e.g 200000, 200005). Is there a specific rule on how this folders are named? Is it possible to trace the folders back to a particular user or whether this is done by design?<\/p>\n<p>(currently doing exploration on my personal aws account)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1644982177253,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker",
            "amazon-efs"
        ],
        "Question_view_count":302.0,
        "Owner_creation_time":1644981356940,
        "Owner_last_access_time":1663945577550,
        "Owner_reputation":53.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":"<p>Yes, if you <a href=\"https:\/\/docs.aws.amazon.com\/cli\/latest\/reference\/sagemaker\/list-user-profiles.html\" rel=\"nofollow noreferrer\">list<\/a> and <a href=\"https:\/\/docs.aws.amazon.com\/cli\/latest\/reference\/sagemaker\/describe-user-profile.html\" rel=\"nofollow noreferrer\">describe<\/a> the domain users, you'll get back the user's <code>HomeEfsFileSystemUid<\/code> value.<br \/>\nHere's a CLI example:<\/p>\n<pre><code>aws sagemaker describe-user-profile --domain-id d-lcn1vbt47yku --user-profile-name default-1588670743757\n{\n    ...\n    &quot;UserProfileName&quot;: &quot;default-1588670743757&quot;,\n    &quot;HomeEfsFileSystemUid&quot;: &quot;200005&quot;,\n    ...\n}\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1645133944567,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71136057",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: identifying user from  studio generated efs storage; content:<p>when a  studio domain is created. an efs storage is associated with the domain. as the assigned users log into  studio, a corresponding home directory is created.<\/p>\n<p>using a separate ec2 instance, i mounted the efs storage that was created to try to see whether is it possible to look at each of the individual home domains. i noticed that each of these home directories are shown in terms of numbers (e.g 200000, 200005). is there a specific rule on how this folders are named? is it possible to trace the folders back to a particular user or whether this is done by design?<\/p>\n<p>(currently doing exploration on my personal aws account)<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to identify which home directories correspond to which users in an EFS storage associated with a Studio domain, and is wondering if there is a specific rule for how the folders are named and if it is possible to trace them back to a particular user."
    },
    {
        "Question_id":63179080.0,
        "Question_title":"When I upload data into an Sagemaker Notebook instance, in which directory does the data live and how do I access it?",
        "Question_body":"<p>You can add files to a Sagemaker notebook instance by using the &quot;upload&quot; button.  When you do this, to which directory are the files uploaded, and how can I view this in the command line?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1596133200537,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":3454.0,
        "Owner_creation_time":1446748214680,
        "Owner_last_access_time":1660244026583,
        "Owner_reputation":306.0,
        "Owner_up_votes":78.0,
        "Owner_down_votes":2.0,
        "Owner_views":44.0,
        "Answer_body":"<p>SageMaker Notebooks home is on <code>\/home\/ec2-user\/SageMaker<\/code><\/p>\n<ul>\n<li>Everything you send to <code>\/home\/ec2-user\/SageMaker<\/code> will be visible in\nthe Jupyter home page<\/li>\n<li>Everything you upload in the Jupyter home page\nwill be visible in the terminal via <code>ls \/home\/ec2-user\/SageMaker<\/code><\/li>\n<li>The content of <code>\/home\/ec2-user\/SageMaker<\/code> is persisted in a storage volume called the &quot;ML Storage Volume&quot;, that is charged additionally to the\ninstance compute pricing and defaults at 5GB. It can be up to 16TB in\nsize. Content saved there stays persisted even when you switch off\nthe notebook instance. On the other hand, anything you save anywhere\nelse will be lost when you switch off the instance<\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1596146845343,
        "Answer_score":5.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63179080",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: when i upload data into an  notebook instance, in which directory does the data live and how do i access it?; content:<p>you can add files to a  notebook instance by using the &quot;upload&quot; button.  when you do this, to which directory are the files uploaded, and how can i view this in the command line?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user can upload files to a notebook instance using the \"upload\" button, and can view the directory in the command line."
    },
    {
        "Question_id":null,
        "Question_title":"Azure Machine Learning Exit Code 143",
        "Question_body":"Hi There,\nI am running a very simple pipeline that contains a dataset and a SQL transformation task. When i run the two tasks i get an error : 2021\/09\/07 17:49:47 Wrapper cmd failed with err: exit status 143 which i can't seem to find anywhere. I am running a compute VM DS1.\nany direction?\nThanks,",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1631037752020,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/543071\/azure-machine-learning-exit-code-143.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-07T18:40:59.28Z",
                "Answer_score":1,
                "Answer_body":"Incase anyone is wondering, you must increase the compute with more memory to avoid this...",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  exit code 143; content:hi there,\ni am running a very simple pipeline that contains a dataset and a sql transformation task. when i run the two tasks i get an error : 2021\/09\/07 17:49:47 wrapper cmd failed with err: exit status 143 which i can't seem to find anywhere. i am running a compute vm ds1.\nany direction?\nthanks,",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is running a pipeline with a dataset and a SQL transformation task, but is receiving an error with exit status 143 which they cannot find any information about."
    },
    {
        "Question_id":73646137.0,
        "Question_title":"AWS - SageMaker Serverless Inference with SageMaker Neo",
        "Question_body":"<p>I am planning to use SageMaker Serverless Inference in conjunction with SageMaker Neo to deploy my model for serverless, low latency inference. However, documentation is not clear whether it is possible to do so.<\/p>\n<p>According to Instance Types for Neo <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/neo-supported-cloud.html\" rel=\"nofollow noreferrer\">here<\/a>, I can use e.g. <code>ml_m4<\/code> instance. However, OutputConfig for Neo Compiler <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/APIReference\/API_OutputConfig.html\" rel=\"nofollow noreferrer\">here<\/a> specifies that TargetDevice can be <code>lambda<\/code>. Serverless Inference <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/serverless-endpoints.html\" rel=\"nofollow noreferrer\">docs<\/a> specify that &quot;Serverless Inference integrates with AWS Lambda to offer you high availability...&quot;, so I assume that underlying instances are of the same (or compatible) type with AWS Lambda.<\/p>\n<ol>\n<li>Have you used such combination? Does it work?<\/li>\n<li>Which instance type should I compile for with Neo?<\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1662626681740,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":23.0,
        "Owner_creation_time":1520689858167,
        "Owner_last_access_time":1664010033703,
        "Owner_reputation":1040.0,
        "Owner_up_votes":135.0,
        "Owner_down_votes":9.0,
        "Owner_views":149.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73646137",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: aws -  serverless inference with  neo; content:<p>i am planning to use  serverless inference in conjunction with  neo to deploy my model for serverless, low latency inference. however, documentation is not clear whether it is possible to do so.<\/p>\n<p>according to instance types for neo <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/neo-supported-cloud.html\" rel=\"nofollow noreferrer\">here<\/a>, i can use e.g. <code>ml_m4<\/code> instance. however, outputconfig for neo compiler <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/apireference\/api_outputconfig.html\" rel=\"nofollow noreferrer\">here<\/a> specifies that targetdevice can be <code>lambda<\/code>. serverless inference <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/serverless-endpoints.html\" rel=\"nofollow noreferrer\">docs<\/a> specify that &quot;serverless inference integrates with aws lambda to offer you high availability...&quot;, so i assume that underlying instances are of the same (or compatible) type with aws lambda.<\/p>\n<ol>\n<li>have you used such combination? does it work?<\/li>\n<li>which instance type should i compile for with neo?<\/li>\n<\/ol>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to use serverless inference with NEO and which instance type should be used for compilation."
    },
    {
        "Question_id":64158911.0,
        "Question_title":"Load Python Pickle File from S3 Bucket to Sagemaker Notebook",
        "Question_body":"<p>I have attempted the code on the many posts on how to load a pickle file (1.9GB) from an S3 bucket, but none seem to work for our notebook instance on AWS Sagemaker.  Notebook size is 50GB.<\/p>\n<p>Some of the methods attempted:<\/p>\n<p>Method 1<\/p>\n<pre><code>import io\nimport boto3\n\nclient = boto3.client('s3')\nbytes_buffer = io.BytesIO()\nclient.download_fileobj(Bucket=my_bucket, Key=my_key_path, Fileobj=bytes_buffer)\n\nbytes_io.seek(0) \nbyte_value = pickle.load(bytes_io)\n<\/code><\/pre>\n<p>This gives:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rMmJx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rMmJx.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Method 2: This actually gets me something back with no error:<\/p>\n<pre><code>client = boto3.client('s3')\nbytes_buffer = io.BytesIO()\nclient.download_fileobj(Bucket=my_bucket, Key=my_key_path, Fileobj=bytes_buffer)\nbyte_value = bytes_buffer.getvalue()\nimport sys\nsys.getsizeof(byte_value)\/(1024**3)\n<\/code><\/pre>\n<p>this returns: 1.93<\/p>\n<p>but how do I convert the byte_value into the pickled object?\nI tried this:<\/p>\n<pre><code>pickled_data = pickle.loads(byte_value)\n<\/code><\/pre>\n<p>But the kernel &quot;crashed&quot; - went idle and I lost all variables.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1601567432000,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "amazon-s3",
            "boto3",
            "amazon-sagemaker"
        ],
        "Question_view_count":2485.0,
        "Owner_creation_time":1338137210000,
        "Owner_last_access_time":1661852953916,
        "Owner_reputation":1937.0,
        "Owner_up_votes":249.0,
        "Owner_down_votes":0.0,
        "Owner_views":221.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64158911",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: load python pickle file from s3 bucket to  notebook; content:<p>i have attempted the code on the many posts on how to load a pickle file (1.9gb) from an s3 bucket, but none seem to work for our notebook instance on .  notebook size is 50gb.<\/p>\n<p>some of the methods attempted:<\/p>\n<p>method 1<\/p>\n<pre><code>import io\nimport boto3\n\nclient = boto3.client('s3')\nbytes_buffer = io.bytesio()\nclient.download_fileobj(bucket=my_bucket, key=my_key_path, fileobj=bytes_buffer)\n\nbytes_io.seek(0) \nbyte_value = pickle.load(bytes_io)\n<\/code><\/pre>\n<p>this gives:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rmmjx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rmmjx.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>method 2: this actually gets me something back with no error:<\/p>\n<pre><code>client = boto3.client('s3')\nbytes_buffer = io.bytesio()\nclient.download_fileobj(bucket=my_bucket, key=my_key_path, fileobj=bytes_buffer)\nbyte_value = bytes_buffer.getvalue()\nimport sys\nsys.getsizeof(byte_value)\/(1024**3)\n<\/code><\/pre>\n<p>this returns: 1.93<\/p>\n<p>but how do i convert the byte_value into the pickled object?\ni tried this:<\/p>\n<pre><code>pickled_data = pickle.loads(byte_value)\n<\/code><\/pre>\n<p>but the kernel &quot;crashed&quot; - went idle and i lost all variables.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to load a 1.9GB Python Pickle file from an S3 bucket into a notebook instance on Azure, but the methods they tried do not work. The first method throws an error, while the second method converts the byte value into a Pickled object, but the kernel crashes when they tried to convert it."
    },
    {
        "Question_id":69538469.0,
        "Question_title":"Is there a way to pass arguments to our own docker container in sagemaker?",
        "Question_body":"<p>I am trying to train my model using Bring your own container technique in sagemaker. My model training runs correctly without any issues locally. But my docker image takes env-file as an input that could change at different runs. But in sagemaker when passing the ECR image, I don't know how to pass this env-file. So instead, inside the <code>train<\/code> script, which is called by the sagemaker, I added <code>export KEY=value<\/code> statements to create my variables. Even that did not expose my variables. Another way I tried it was by executing <code>RUN source file.env<\/code> while building my image. Even this approach did not work out as I got an error <code>\/bin\/sh: 1: source: not found<\/code>.<\/p>\n<p>I could try <code>ENV<\/code> while building my image and that would probably work but this approach won't be flexible as my variables could change at different runs. Is there any way to pass docker run arguments from a sagemaker estimator or notebook? I checked out the documentation but I couldn't find anything.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1634032422110,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "docker",
            "amazon-sagemaker",
            "env-file"
        ],
        "Question_view_count":292.0,
        "Owner_creation_time":1633433905427,
        "Owner_last_access_time":1663334017808,
        "Owner_reputation":43.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":5.0,
        "Answer_body":"<p>I've been passing environment variables along with the Docker image URL when creating the Training job using the SageMaker Python SDK. Documentation of the <code>train<\/code> method states that:<\/p>\n<pre><code>environment (dict[str, str]) : Environment variables to be set for\n            use during training job (default: ``None``): \n<\/code><\/pre>\n<p>For reference, the <a href=\"https:\/\/github.com\/aws\/sagemaker-python-sdk\/blob\/5bc3ccf\/src\/sagemaker\/session.py#L569\" rel=\"nofollow noreferrer\">SDK source<\/a>.<\/p>\n<p>Because the SDK is a wrapper on top of <a href=\"https:\/\/pypi.org\/project\/boto3\/\" rel=\"nofollow noreferrer\">Boto3<\/a>, I'm pretty sure that the same can be implemented with Boto3 alone, and that there is an equivalent for every other <a href=\"https:\/\/aws.amazon.com\/developer\/tools\/#SDKs\" rel=\"nofollow noreferrer\">Amazon Services SDK<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1662661497360,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69538469",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is there a way to pass arguments to our own docker container in ?; content:<p>i am trying to train my model using bring your own container technique in . my model training runs correctly without any issues locally. but my docker image takes env-file as an input that could change at different runs. but in  when passing the ecr image, i don't know how to pass this env-file. so instead, inside the <code>train<\/code> script, which is called by the , i added <code>export key=value<\/code> statements to create my variables. even that did not expose my variables. another way i tried it was by executing <code>run source file.env<\/code> while building my image. even this approach did not work out as i got an error <code>\/bin\/sh: 1: source: not found<\/code>.<\/p>\n<p>i could try <code>env<\/code> while building my image and that would probably work but this approach won't be flexible as my variables could change at different runs. is there any way to pass docker run arguments from a  estimator or notebook? i checked out the documentation but i couldn't find anything.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to pass arguments to their own docker container in order to train a model, but is having difficulty finding a way to do so."
    },
    {
        "Question_id":71919389.0,
        "Question_title":"Azureml TabularDataset to_pandas_dataframe() returns InvalidEncoding error",
        "Question_body":"<p>When I run:<\/p>\n<pre><code>datasetTabular = Dataset.get_by_name(ws, &quot;&lt;Redacted&gt;&quot;)\ndatasetTabular.to_pandas_dataframe()\n<\/code><\/pre>\n<p>The following error is returned.  What can I do to get past this?<\/p>\n<pre><code>ExecutionError                            Traceback (most recent call last) File C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\dataset_error_handling.py:101, in _try_execute(action, operation, dataset_info, **kwargs)\n    100     else:\n--&gt; 101         return action()\n    102 except Exception as e:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\tabular_dataset.py:169, in TabularDataset.to_pandas_dataframe.&lt;locals&gt;.&lt;lambda&gt;()\n    168 dataflow = get_dataflow_for_execution(self._dataflow, 'to_pandas_dataframe', 'TabularDataset')\n--&gt; 169 df = _try_execute(lambda: dataflow.to_pandas_dataframe(on_error=on_error,\n    170                                                        out_of_range_datetime=out_of_range_datetime),\n    171                   'to_pandas_dataframe',\n    172                   None if self.id is None else {'id': self.id, 'name': self.name, 'version': self.version})\n    173 fine_grain_timestamp = self._properties.get(_DATASET_PROP_TIMESTAMP_FINE, None)\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\_loggerfactory.py:213, in track.&lt;locals&gt;.monitor.&lt;locals&gt;.wrapper(*args, **kwargs)\n    212 try:\n--&gt; 213     return func(*args, **kwargs)\n    214 except Exception as e:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\dataflow.py:697, in Dataflow.to_pandas_dataframe(self, extended_types, nulls_as_nan, on_error, out_of_range_datetime)\n    696 with tracer.start_as_current_span('Dataflow.to_pandas_dataframe', trace.get_current_span()) as span:\n--&gt; 697     return get_dataframe_reader().to_pandas_dataframe(self,\n    698                                                       extended_types,\n    699                                                       nulls_as_nan,\n    700                                                       on_error,\n    701                                                       out_of_range_datetime,\n    702                                                       to_dprep_span_context(span.get_context()))\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\_dataframereader.py:386, in _DataFrameReader.to_pandas_dataframe(self, dataflow, extended_types, nulls_as_nan, on_error, out_of_range_datetime, span_context)\n    384     if have_pyarrow() and not extended_types and not inconsistent_schema:\n    385         # if arrow is supported, and we didn't get inconsistent schema, and extended typed were not asked for - fallback to feather\n--&gt; 386         return clex_feather_to_pandas()\n    387 except _InconsistentSchemaError as e:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\_dataframereader.py:298, in\n_DataFrameReader.to_pandas_dataframe.&lt;locals&gt;.clex_feather_to_pandas()\n    297 activity_data = dataflow_to_execute._dataflow_to_anonymous_activity_data(dataflow_to_execute)\n--&gt; 298 dataflow._engine_api.execute_anonymous_activity(\n    299     ExecuteAnonymousActivityMessageArguments(anonymous_activity=activity_data, span_context=span_context))\n    301 try:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\_aml_helper.py:38, in update_aml_env_vars.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(op_code, message, cancellation_token)\n     37     engine_api_func().update_environment_variable(changed)\n---&gt; 38 return send_message_func(op_code, message, cancellation_token)\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\engineapi\\api.py:160, in EngineAPI.execute_anonymous_activity(self, message_args, cancellation_token)\n    158 @update_aml_env_vars(get_engine_api)\n    159 def execute_anonymous_activity(self, message_args: typedefinitions.ExecuteAnonymousActivityMessageArguments, cancellation_token: CancellationToken = None) -&gt; None:\n--&gt; 160     response = self._message_channel.send_message('Engine.ExecuteActivity', message_args, cancellation_token)\n    161     return response\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\engineapi\\engine.py:291, in MultiThreadMessageChannel.send_message(self, op_code, message, cancellation_token)\n    290     cancel_on_error()\n--&gt; 291     raise_engine_error(response['error'])\n    292 else:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\dataprep\\api\\errorhandlers.py:10, in raise_engine_error(error_response)\n      9 if 'ScriptExecution' in error_code:\n---&gt; 10     raise ExecutionError(error_response)\n     11 if 'Validation' in error_code:\n\nExecutionError:  Error Code: ScriptExecution.StreamAccess.Validation Validation Error Code: InvalidEncoding Validation Target: TextFile Failed Step: 78059bb0-278f-4c7f-9c21-01a0cccf7b96 Error Message: ScriptExecutionException was caused by StreamAccessException.   StreamAccessException was caused by ValidationException.\n    Unable to read file using Unicode (UTF-8). Attempted read range 0:777. Lines read in the range 0. Decoding error: Unable to translate bytes [8B] at index 1 from specified code page to Unicode.\n      Unable to translate bytes [8B] at index 1 from specified code page to Unicode. | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c\n\nDuring handling of the above exception, another exception occurred:\n\nUserErrorException                        Traceback (most recent call last) Input In [34], in &lt;module&gt;\n      1 # preview the first 3 rows of the dataset\n      2 #datasetTabular.take(3)\n----&gt; 3 datasetTabular.take(3).to_pandas_dataframe()\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\_loggerfactory.py:132, in track.&lt;locals&gt;.monitor.&lt;locals&gt;.wrapper(*args, **kwargs)\n    130 with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n    131     try:\n--&gt; 132         return func(*args, **kwargs)\n    133     except Exception as e:\n    134         if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\tabular_dataset.py:169, in TabularDataset.to_pandas_dataframe(self, on_error, out_of_range_datetime)\n    158 &quot;&quot;&quot;Load all records from the dataset into a pandas DataFrame.\n    159 \n    160 :param on_error: How to handle any error values in the dataset, such as those produced by an error while    (...)\n    166 :rtype: pandas.DataFrame\n    167 &quot;&quot;&quot;\n    168 dataflow = get_dataflow_for_execution(self._dataflow, 'to_pandas_dataframe', 'TabularDataset')\n--&gt; 169 df = _try_execute(lambda: dataflow.to_pandas_dataframe(on_error=on_error,\n    170                                                        out_of_range_datetime=out_of_range_datetime),\n    171                   'to_pandas_dataframe',\n    172                   None if self.id is None else {'id': self.id, 'name': self.name, 'version': self.version})\n    173 fine_grain_timestamp = self._properties.get(_DATASET_PROP_TIMESTAMP_FINE, None)\n    175 if fine_grain_timestamp is not None and df.empty is False:\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\dataset_error_handling.py:104, in _try_execute(action, operation, dataset_info, **kwargs)\n    102 except Exception as e:\n    103     message, is_dprep_exception = _construct_message_and_check_exception_type(e, dataset_info, operation)\n--&gt; 104     _dataprep_error_handler(e, message, is_dprep_exception)\n\nFile C:\\ProgramData\\Anaconda3_2\\envs\\amlds\\lib\\site-packages\\azureml\\data\\dataset_error_handling.py:154, in _dataprep_error_handler(e, message, is_dprep_exception)\n    152     for item in user_exception_list:\n    153         if _contains(item, getattr(e, 'error_code', 'Unexpected')):\n--&gt; 154             raise UserErrorException(message, inner_exception=e)\n    156 raise AzureMLException(message, inner_exception=e)\n\nUserErrorException: UserErrorException:     Message: Execution failed with error message: ScriptExecutionException was caused by StreamAccessException.   StreamAccessException was caused by ValidationException.\n    Unable to read file using Unicode (UTF-8). Attempted read range 0:777. Lines read in the range 0. Decoding error: [REDACTED]\n      Failed due to inner exception of type: DecoderFallbackException | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c ErrorCode: ScriptExecution.StreamAccess.Validation  InnerException  Error Code: ScriptExecution.StreamAccess.Validation Validation Error Code: InvalidEncoding Validation Target: TextFile Failed Step: 78059bb0-278f-4c7f-9c21-01a0cccf7b96 Error Message: ScriptExecutionException was caused by StreamAccessException.   StreamAccessException was caused by ValidationException.\n    Unable to read file using Unicode (UTF-8). Attempted read range 0:777. Lines read in the range 0. Decoding error: Unable to translate bytes [8B] at index 1 from specified code page to Unicode.\n      Unable to translate bytes [8B] at index 1 from specified code page to Unicode. | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c  ErrorResponse  {\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Execution failed with error message: ScriptExecutionException was caused by StreamAccessException.\\r\\n  StreamAccessException was caused by ValidationException.\\r\\n    Unable to read file using Unicode (UTF-8). Attempted read range 0:777. Lines read in the range 0. Decoding error: [REDACTED]\\r\\n      Failed due to inner exception of type: DecoderFallbackException\\r\\n| session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c ErrorCode: ScriptExecution.StreamAccess.Validation&quot;\n    } }\n\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_creation_time":1650339397280,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning-service",
            "azureml-python-sdk"
        ],
        "Question_view_count":335.0,
        "Owner_creation_time":1650337408350,
        "Owner_last_access_time":1653101508432,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1650489525383,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71919389",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  tabulardataset to_pandas_dataframe() returns invalidencoding error; content:<p>when i run:<\/p>\n<pre><code>datasettabular = dataset.get_by_name(ws, &quot;&lt;redacted&gt;&quot;)\ndatasettabular.to_pandas_dataframe()\n<\/code><\/pre>\n<p>the following error is returned.  what can i do to get past this?<\/p>\n<pre><code>executionerror                            traceback (most recent call last) file c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\data\\dataset_error_handling.py:101, in _try_execute(action, operation, dataset_info, **kwargs)\n    100     else:\n--&gt; 101         return action()\n    102 except exception as e:\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\data\\tabular_dataset.py:169, in tabulardataset.to_pandas_dataframe.&lt;locals&gt;.&lt;lambda&gt;()\n    168 dataflow = get_dataflow_for_execution(self._dataflow, 'to_pandas_dataframe', 'tabulardataset')\n--&gt; 169 df = _try_execute(lambda: dataflow.to_pandas_dataframe(on_error=on_error,\n    170                                                        out_of_range_datetime=out_of_range_datetime),\n    171                   'to_pandas_dataframe',\n    172                   none if self.id is none else {'id': self.id, 'name': self.name, 'version': self.version})\n    173 fine_grain_timestamp = self._properties.get(_dataset_prop_timestamp_fine, none)\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\dataprep\\api\\_loggerfactory.py:213, in track.&lt;locals&gt;.monitor.&lt;locals&gt;.wrapper(*args, **kwargs)\n    212 try:\n--&gt; 213     return func(*args, **kwargs)\n    214 except exception as e:\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\dataprep\\api\\dataflow.py:697, in dataflow.to_pandas_dataframe(self, extended_types, nulls_as_nan, on_error, out_of_range_datetime)\n    696 with tracer.start_as_current_span('dataflow.to_pandas_dataframe', trace.get_current_span()) as span:\n--&gt; 697     return get_dataframe_reader().to_pandas_dataframe(self,\n    698                                                       extended_types,\n    699                                                       nulls_as_nan,\n    700                                                       on_error,\n    701                                                       out_of_range_datetime,\n    702                                                       to_dprep_span_context(span.get_context()))\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\dataprep\\api\\_dataframereader.py:386, in _dataframereader.to_pandas_dataframe(self, dataflow, extended_types, nulls_as_nan, on_error, out_of_range_datetime, span_context)\n    384     if have_pyarrow() and not extended_types and not inconsistent_schema:\n    385         # if arrow is supported, and we didn't get inconsistent schema, and extended typed were not asked for - fallback to feather\n--&gt; 386         return clex_feather_to_pandas()\n    387 except _inconsistentschemaerror as e:\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\dataprep\\api\\_dataframereader.py:298, in\n_dataframereader.to_pandas_dataframe.&lt;locals&gt;.clex_feather_to_pandas()\n    297 activity_data = dataflow_to_execute._dataflow_to_anonymous_activity_data(dataflow_to_execute)\n--&gt; 298 dataflow._engine_api.execute_anonymous_activity(\n    299     executeanonymousactivitymessagearguments(anonymous_activity=activity_data, span_context=span_context))\n    301 try:\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\dataprep\\api\\_aml_helper.py:38, in update_aml_env_vars.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(op_code, message, cancellation_token)\n     37     engine_api_func().update_environment_variable(changed)\n---&gt; 38 return send_message_func(op_code, message, cancellation_token)\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\dataprep\\api\\engineapi\\api.py:160, in engineapi.execute_anonymous_activity(self, message_args, cancellation_token)\n    158 @update_aml_env_vars(get_engine_api)\n    159 def execute_anonymous_activity(self, message_args: typedefinitions.executeanonymousactivitymessagearguments, cancellation_token: cancellationtoken = none) -&gt; none:\n--&gt; 160     response = self._message_channel.send_message('engine.executeactivity', message_args, cancellation_token)\n    161     return response\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\dataprep\\api\\engineapi\\engine.py:291, in multithreadmessagechannel.send_message(self, op_code, message, cancellation_token)\n    290     cancel_on_error()\n--&gt; 291     raise_engine_error(response['error'])\n    292 else:\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\dataprep\\api\\errorhandlers.py:10, in raise_engine_error(error_response)\n      9 if 'scriptexecution' in error_code:\n---&gt; 10     raise executionerror(error_response)\n     11 if 'validation' in error_code:\n\nexecutionerror:  error code: scriptexecution.streamaccess.validation validation error code: invalidencoding validation target: textfile failed step: 78059bb0-278f-4c7f-9c21-01a0cccf7b96 error message: scriptexecutionexception was caused by streamaccessexception.   streamaccessexception was caused by validationexception.\n    unable to read file using unicode (utf-8). attempted read range 0:777. lines read in the range 0. decoding error: unable to translate bytes [8b] at index 1 from specified code page to unicode.\n      unable to translate bytes [8b] at index 1 from specified code page to unicode. | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c\n\nduring handling of the above exception, another exception occurred:\n\nusererrorexception                        traceback (most recent call last) input in [34], in &lt;module&gt;\n      1 # preview the first 3 rows of the dataset\n      2 #datasettabular.take(3)\n----&gt; 3 datasettabular.take(3).to_pandas_dataframe()\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\data\\_loggerfactory.py:132, in track.&lt;locals&gt;.monitor.&lt;locals&gt;.wrapper(*args, **kwargs)\n    130 with _loggerfactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n    131     try:\n--&gt; 132         return func(*args, **kwargs)\n    133     except exception as e:\n    134         if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\data\\tabular_dataset.py:169, in tabulardataset.to_pandas_dataframe(self, on_error, out_of_range_datetime)\n    158 &quot;&quot;&quot;load all records from the dataset into a pandas dataframe.\n    159 \n    160 :param on_error: how to handle any error values in the dataset, such as those produced by an error while    (...)\n    166 :rtype: pandas.dataframe\n    167 &quot;&quot;&quot;\n    168 dataflow = get_dataflow_for_execution(self._dataflow, 'to_pandas_dataframe', 'tabulardataset')\n--&gt; 169 df = _try_execute(lambda: dataflow.to_pandas_dataframe(on_error=on_error,\n    170                                                        out_of_range_datetime=out_of_range_datetime),\n    171                   'to_pandas_dataframe',\n    172                   none if self.id is none else {'id': self.id, 'name': self.name, 'version': self.version})\n    173 fine_grain_timestamp = self._properties.get(_dataset_prop_timestamp_fine, none)\n    175 if fine_grain_timestamp is not none and df.empty is false:\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\data\\dataset_error_handling.py:104, in _try_execute(action, operation, dataset_info, **kwargs)\n    102 except exception as e:\n    103     message, is_dprep_exception = _construct_message_and_check_exception_type(e, dataset_info, operation)\n--&gt; 104     _dataprep_error_handler(e, message, is_dprep_exception)\n\nfile c:\\programdata\\anaconda3_2\\envs\\amlds\\lib\\site-packages\\\\data\\dataset_error_handling.py:154, in _dataprep_error_handler(e, message, is_dprep_exception)\n    152     for item in user_exception_list:\n    153         if _contains(item, getattr(e, 'error_code', 'unexpected')):\n--&gt; 154             raise usererrorexception(message, inner_exception=e)\n    156 raise exception(message, inner_exception=e)\n\nusererrorexception: usererrorexception:     message: execution failed with error message: scriptexecutionexception was caused by streamaccessexception.   streamaccessexception was caused by validationexception.\n    unable to read file using unicode (utf-8). attempted read range 0:777. lines read in the range 0. decoding error: [redacted]\n      failed due to inner exception of type: decoderfallbackexception | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c errorcode: scriptexecution.streamaccess.validation  innerexception  error code: scriptexecution.streamaccess.validation validation error code: invalidencoding validation target: textfile failed step: 78059bb0-278f-4c7f-9c21-01a0cccf7b96 error message: scriptexecutionexception was caused by streamaccessexception.   streamaccessexception was caused by validationexception.\n    unable to read file using unicode (utf-8). attempted read range 0:777. lines read in the range 0. decoding error: unable to translate bytes [8b] at index 1 from specified code page to unicode.\n      unable to translate bytes [8b] at index 1 from specified code page to unicode. | session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c  errorresponse  {\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;usererror&quot;,\n        &quot;message&quot;: &quot;execution failed with error message: scriptexecutionexception was caused by streamaccessexception.\\r\\n  streamaccessexception was caused by validationexception.\\r\\n    unable to read file using unicode (utf-8). attempted read range 0:777. lines read in the range 0. decoding error: [redacted]\\r\\n      failed due to inner exception of type: decoderfallbackexception\\r\\n| session_id=295acf7e-4af9-42f1-b04a-79f3c5a0f98c errorcode: scriptexecution.streamaccess.validation&quot;\n    } }\n\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an invalidencoding error when attempting to convert a tabulardataset to a pandas dataframe."
    },
    {
        "Question_id":58019308.0,
        "Question_title":"ScriptRunConfig with datastore reference on AML",
        "Question_body":"<p>When trying to run a ScriptRunConfig, using :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>src = ScriptRunConfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', ds.as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>\n\n<p>It doesn't work and breaks with this when I submit the job : <\/p>\n\n<pre><code>... lots of things... and then\nTypeError: Object of type 'DataReference' is not JSON serializable\n<\/code><\/pre>\n\n<p>However if I run it with the Estimator, it works. One of the differences is the fact that with a <code>ScriptRunConfig<\/code> we're using a list for parameters and the other is a dictionary.<\/p>\n\n<p>Thanks for any pointers!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1568929720367,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "azure-machine-learning-service"
        ],
        "Question_view_count":1541.0,
        "Owner_creation_time":1538275960603,
        "Owner_last_access_time":1658458641830,
        "Owner_reputation":381.0,
        "Owner_up_votes":75.0,
        "Owner_down_votes":2.0,
        "Owner_views":50.0,
        "Answer_body":"<p>Being able to use <code>DataReference<\/code> in <code>ScriptRunConfig<\/code> is a bit more involved than doing just <code>ds.as_mount()<\/code>. You will need to convert it into a string in <code>arguments<\/code> and then update the <code>RunConfiguration<\/code>'s <code>data_references<\/code> section with the <code>DataReferenceConfiguration<\/code> created from <code>ds<\/code>. Please <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-remote-vm\/train-on-remote-vm.ipynb\" rel=\"nofollow noreferrer\">see here<\/a> for an example notebook on how to do that.<\/p>\n<p>If you are just reading from the input location and not doing any writes to it, please check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-register-datasets\" rel=\"nofollow noreferrer\"><code>Dataset<\/code><\/a>. It allows you to do exactly what you are doing without doing anything extra. <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/train-with-datasets.ipynb\" rel=\"nofollow noreferrer\">Here is an example notebook<\/a> that shows this in action.<\/p>\n<p>Below is a short version of the notebook<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Dataset\n\n# more imports and code\n\nds = Datastore(workspace, 'mydatastore')\ndataset = Dataset.File.from_files(path=(ds, 'path\/to\/input-data\/within-datastore'))\n\nsrc = ScriptRunConfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', dataset.as_named_input('input').as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1568945686667,
        "Answer_score":4.0,
        "Owner_location":"Montreal, QC, Canada",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":1595974462436,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58019308",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: scriptrunconfig with datastore reference on aml; content:<p>when trying to run a scriptrunconfig, using :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>src = scriptrunconfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', ds.as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>\n\n<p>it doesn't work and breaks with this when i submit the job : <\/p>\n\n<pre><code>... lots of things... and then\ntypeerror: object of type 'datareference' is not json serializable\n<\/code><\/pre>\n\n<p>however if i run it with the estimator, it works. one of the differences is the fact that with a <code>scriptrunconfig<\/code> we're using a list for parameters and the other is a dictionary.<\/p>\n\n<p>thanks for any pointers!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an error when trying to run a scriptrunconfig using a datastore reference, but it works when using an estimator."
    },
    {
        "Question_id":71410791.0,
        "Question_title":"How can I build a multi model endpoint for ensemble modeling with using my own model containers?",
        "Question_body":"<p>I'm trying to deploy a multi model endpoint on Amazon Sagemaker, and am working with my own model containers which I created using <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/tree\/main\/advanced_functionality\/scikit_bring_your_own\" rel=\"nofollow noreferrer\">scikit_bring_your_own<\/a> example. I can train and create endpoint for each of them separately but for example when I try to collect mlp and cart together in multi model endpoint, I get an error which says &quot;The cart,mlp for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint&quot;. When I check CloudWatch logs I cannot see anything unusual. <strong>Should I change the container structure for multi model endpoints ?<\/strong><\/p>\n<pre><code>from time import gmtime, strftime\nimport os\nimport boto3\nimport time\nimport re\nimport sagemaker\n\nmodel_name = &quot;efe-test-model-ensemble-modeling-&quot; + strftime(&quot;%Y-%m-%d-%H-%M-%S&quot;, gmtime())\n\ncart_hosting_container = {\n    &quot;Image&quot;: &quot;097916623002.dkr.ecr.eu-central-1.amazonaws.com\/snop-mm-cart:latest&quot;,\n    &quot;ContainerHostname&quot;: &quot;cart&quot;,\n    &quot;ModelDataUrl&quot;: &quot;s3:\/\/sagemaker-eu-central-1-097916623002\/output\/snop-mm-cart-2022-03-09-12-47-04-881\/output\/model.tar.gz&quot;,\n}\n\nmlp_hosting_container = {\n    &quot;Image&quot;: &quot;097916623002.dkr.ecr.eu-central-1.amazonaws.com\/snop-mm-mlp:latest&quot;,\n    &quot;ContainerHostname&quot;: &quot;mlp&quot;,\n    &quot;ModelDataUrl&quot;: &quot;s3:\/\/sagemaker-eu-central-1-097916623002\/output\/snop-mm-mlp-2022-03-09-12-52-09-267\/output\/model.tar.gz&quot;,\n}\n\nrole = sagemaker.get_execution_role()\nsm = boto3.client(&quot;sagemaker&quot;)\n\ninferenceExecutionConfig = {&quot;Mode&quot;: &quot;Direct&quot;}\n\ncreate_model_response = sm.create_model(\n    ModelName=model_name,\n    InferenceExecutionConfig=inferenceExecutionConfig,\n    ExecutionRoleArn=role,\n    Containers=[cart_hosting_container, mlp_hosting_container],\n)\n\nendpoint_config_name = &quot;TEST-config-ensemble-modelling-&quot; + strftime(\n    &quot;%Y-%m-%d-%H-%M-%S&quot;, gmtime()\n)\nprint(endpoint_config_name)\ncreate_endpoint_config_response = sm.create_endpoint_config(\n    EndpointConfigName=endpoint_config_name,\n    ProductionVariants=[\n        {\n            &quot;InstanceType&quot;: &quot;ml.m5.large&quot;,\n            &quot;InitialInstanceCount&quot;: 1,\n            &quot;InitialVariantWeight&quot;: 1,\n            &quot;ModelName&quot;: model_name,\n            &quot;VariantName&quot;: &quot;AllTraffic&quot;,\n        }\n    ],\n)\n\nprint(&quot;Endpoint Config Arn: &quot; + create_endpoint_config_response[&quot;EndpointConfigArn&quot;])\n\n%%time\nimport time\n\nendpoint_name = &quot;TEST-endpoint-ensemble-modelling-&quot; + strftime(&quot;%Y-%m-%d-%H-%M-%S&quot;, gmtime())\nprint(endpoint_name)\ncreate_endpoint_response = sm.create_endpoint(\n    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n)\nprint(create_endpoint_response[&quot;EndpointArn&quot;])\n\nresp = sm.describe_endpoint(EndpointName=endpoint_name)\nstatus = resp[&quot;EndpointStatus&quot;]\nprint(&quot;Status: &quot; + status)\n\nwhile status == &quot;Creating&quot;:\n    time.sleep(60)\n    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n    status = resp[&quot;EndpointStatus&quot;]\n    print(&quot;Status: &quot; + status)\n\nprint(&quot;Arn: &quot; + resp[&quot;EndpointArn&quot;])\nprint(&quot;Status: &quot; + status)\n<\/code><\/pre>\n<p>It creates two folders in CloudWatch<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wCNOC.png\" rel=\"nofollow noreferrer\">log groups<\/a><\/p>\n<p>mlp is:\n<a href=\"https:\/\/i.stack.imgur.com\/O7qeA.png\" rel=\"nofollow noreferrer\">mlp log<\/a><\/p>\n<p>cart is:\n<a href=\"https:\/\/i.stack.imgur.com\/XhiDC.png\" rel=\"nofollow noreferrer\">cart log<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1646835413127,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "machine-learning",
            "amazon-sagemaker"
        ],
        "Question_view_count":87.0,
        "Owner_creation_time":1645732047140,
        "Owner_last_access_time":1654867064967,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71410791",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how can i build a multi model endpoint for ensemble modeling with using my own model containers?; content:<p>i'm trying to deploy a multi model endpoint on , and am working with my own model containers which i created using <a href=\"https:\/\/github.com\/aws\/amazon--examples\/tree\/main\/advanced_functionality\/scikit_bring_your_own\" rel=\"nofollow noreferrer\">scikit_bring_your_own<\/a> example. i can train and create endpoint for each of them separately but for example when i try to collect mlp and cart together in multi model endpoint, i get an error which says &quot;the cart,mlp for production variant alltraffic did not pass the ping health check. please check cloudwatch logs for this endpoint&quot;. when i check cloudwatch logs i cannot see anything unusual. <strong>should i change the container structure for multi model endpoints ?<\/strong><\/p>\n<pre><code>from time import gmtime, strftime\nimport os\nimport boto3\nimport time\nimport re\nimport \n\nmodel_name = &quot;efe-test-model-ensemble-modeling-&quot; + strftime(&quot;%y-%m-%d-%h-%m-%s&quot;, gmtime())\n\ncart_hosting_container = {\n    &quot;image&quot;: &quot;097916623002.dkr.ecr.eu-central-1.amazonaws.com\/snop-mm-cart:latest&quot;,\n    &quot;containerhostname&quot;: &quot;cart&quot;,\n    &quot;modeldataurl&quot;: &quot;s3:\/\/-eu-central-1-097916623002\/output\/snop-mm-cart-2022-03-09-12-47-04-881\/output\/model.tar.gz&quot;,\n}\n\nmlp_hosting_container = {\n    &quot;image&quot;: &quot;097916623002.dkr.ecr.eu-central-1.amazonaws.com\/snop-mm-mlp:latest&quot;,\n    &quot;containerhostname&quot;: &quot;mlp&quot;,\n    &quot;modeldataurl&quot;: &quot;s3:\/\/-eu-central-1-097916623002\/output\/snop-mm-mlp-2022-03-09-12-52-09-267\/output\/model.tar.gz&quot;,\n}\n\nrole = .get_execution_role()\nsm = boto3.client(&quot;&quot;)\n\ninferenceexecutionconfig = {&quot;mode&quot;: &quot;direct&quot;}\n\ncreate_model_response = sm.create_model(\n    modelname=model_name,\n    inferenceexecutionconfig=inferenceexecutionconfig,\n    executionrolearn=role,\n    containers=[cart_hosting_container, mlp_hosting_container],\n)\n\nendpoint_config_name = &quot;test-config-ensemble-modelling-&quot; + strftime(\n    &quot;%y-%m-%d-%h-%m-%s&quot;, gmtime()\n)\nprint(endpoint_config_name)\ncreate_endpoint_config_response = sm.create_endpoint_config(\n    endpointconfigname=endpoint_config_name,\n    productionvariants=[\n        {\n            &quot;instancetype&quot;: &quot;ml.m5.large&quot;,\n            &quot;initialinstancecount&quot;: 1,\n            &quot;initialvariantweight&quot;: 1,\n            &quot;modelname&quot;: model_name,\n            &quot;variantname&quot;: &quot;alltraffic&quot;,\n        }\n    ],\n)\n\nprint(&quot;endpoint config arn: &quot; + create_endpoint_config_response[&quot;endpointconfigarn&quot;])\n\n%%time\nimport time\n\nendpoint_name = &quot;test-endpoint-ensemble-modelling-&quot; + strftime(&quot;%y-%m-%d-%h-%m-%s&quot;, gmtime())\nprint(endpoint_name)\ncreate_endpoint_response = sm.create_endpoint(\n    endpointname=endpoint_name, endpointconfigname=endpoint_config_name\n)\nprint(create_endpoint_response[&quot;endpointarn&quot;])\n\nresp = sm.describe_endpoint(endpointname=endpoint_name)\nstatus = resp[&quot;endpointstatus&quot;]\nprint(&quot;status: &quot; + status)\n\nwhile status == &quot;creating&quot;:\n    time.sleep(60)\n    resp = sm.describe_endpoint(endpointname=endpoint_name)\n    status = resp[&quot;endpointstatus&quot;]\n    print(&quot;status: &quot; + status)\n\nprint(&quot;arn: &quot; + resp[&quot;endpointarn&quot;])\nprint(&quot;status: &quot; + status)\n<\/code><\/pre>\n<p>it creates two folders in cloudwatch<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wcnoc.png\" rel=\"nofollow noreferrer\">log groups<\/a><\/p>\n<p>mlp is:\n<a href=\"https:\/\/i.stack.imgur.com\/o7qea.png\" rel=\"nofollow noreferrer\">mlp log<\/a><\/p>\n<p>cart is:\n<a href=\"https:\/\/i.stack.imgur.com\/xhidc.png\" rel=\"nofollow noreferrer\">cart log<\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user should check if the container structure needs to be changed in order to successfully deploy a multi model endpoint with their own model containers."
    },
    {
        "Question_id":70248817.0,
        "Question_title":"Shared input in Sagemaker inference pipeline models",
        "Question_body":"<p>I'm deploying a SageMaker inference pipeline composed of two PyTorch models (<code>model_1<\/code> and <code>model_2<\/code>), and I am wondering if it's possible to pass the same input to both the models composing the pipeline.<\/p>\n<p>What I have in mind would work more or less as follows<\/p>\n<ol>\n<li><p>Invoke the endpoint sending a binary encoded payload (namely <code>payload_ser<\/code>), for example:<\/p>\n<pre><code>client.invoke_endpoint(EndpointName=ENDPOINT,\n                       ContentType='application\/x-npy',\n                       Body=payload_ser)\n<\/code><\/pre>\n<\/li>\n<li><p>The first model parses the payload with <code>inut_fn<\/code> function, runs the predictor on it, and returns the output of the predictor. As a simplified example:<\/p>\n<pre><code>def input_fn(request_body, request_content_type):\n    if request_content_type == &quot;application\/x-npy&quot;:\n        input = some_function_to_parse_input(request_body)\n    return input\n\ndef predict_fn(input_object, predictor):\n    outputs = predictor(input_object)\n    return outputs\n\ndef output_fn(predictions, response_content_type):\n    return json.dumps(predictions)\n<\/code><\/pre>\n<\/li>\n<li><p>The second model gets as payload both the original payload (<code>payload_ser<\/code>) and the output of the previous model (predictions). Possibly, the <code>input_fn<\/code> function would be used to parse the output of model_1 (as in the &quot;standard case&quot;), but I'd need some way to also make the original payload available to model_2.  In this way, model_2 will use both the original payload and the output of model_1 to make the final prediction and return it to whoever invoked the endpoint.<\/p>\n<\/li>\n<\/ol>\n<p>Any idea if this is achievable?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1638808672663,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":210.0,
        "Owner_creation_time":1508881117760,
        "Owner_last_access_time":1663930396547,
        "Owner_reputation":157.0,
        "Owner_up_votes":20.0,
        "Owner_down_votes":0.0,
        "Owner_views":25.0,
        "Answer_body":"<p>Sounds like you need an inference DAG. Amazon SageMaker Inference pipelines currently supports only a chain of handlers, where the output of handler N is the input for handler N+1.<\/p>\n<p>You could change model1's predict_fn() to return both (input_object, outputs), and output_fn(). output_fn() will receive these two objects as the predictions, and will handle serializing both as json. model2's input_fn() will need to know how to parse this pair input.<\/p>\n<p>Consider implementing this as a generic pipeline handling mechanism that adds the input to the model's output. This way you could reuse it for all models and pipelines.<\/p>\n<p>You could allow the model to be deployed as a standalone model, and as a part of a pipeline, and apply the relevant input\/output handling behavior that will be triggered by the presence of an environment variable (<code>Environment<\/code> dict), which you can specify when <a href=\"https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/sagemaker.html#SageMaker.Client.create_model\" rel=\"nofollow noreferrer\">creating<\/a> the inference pipelines model.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1638812806036,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70248817",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: shared input in  inference pipeline models; content:<p>i'm deploying a  inference pipeline composed of two pytorch models (<code>model_1<\/code> and <code>model_2<\/code>), and i am wondering if it's possible to pass the same input to both the models composing the pipeline.<\/p>\n<p>what i have in mind would work more or less as follows<\/p>\n<ol>\n<li><p>invoke the endpoint sending a binary encoded payload (namely <code>payload_ser<\/code>), for example:<\/p>\n<pre><code>client.invoke_endpoint(endpointname=endpoint,\n                       contenttype='application\/x-npy',\n                       body=payload_ser)\n<\/code><\/pre>\n<\/li>\n<li><p>the first model parses the payload with <code>inut_fn<\/code> function, runs the predictor on it, and returns the output of the predictor. as a simplified example:<\/p>\n<pre><code>def input_fn(request_body, request_content_type):\n    if request_content_type == &quot;application\/x-npy&quot;:\n        input = some_function_to_parse_input(request_body)\n    return input\n\ndef predict_fn(input_object, predictor):\n    outputs = predictor(input_object)\n    return outputs\n\ndef output_fn(predictions, response_content_type):\n    return json.dumps(predictions)\n<\/code><\/pre>\n<\/li>\n<li><p>the second model gets as payload both the original payload (<code>payload_ser<\/code>) and the output of the previous model (predictions). possibly, the <code>input_fn<\/code> function would be used to parse the output of model_1 (as in the &quot;standard case&quot;), but i'd need some way to also make the original payload available to model_2.  in this way, model_2 will use both the original payload and the output of model_1 to make the final prediction and return it to whoever invoked the endpoint.<\/p>\n<\/li>\n<\/ol>\n<p>any idea if this is achievable?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to pass the same input to two PyTorch models in an inference pipeline, and if there is a way to make the original payload available to the second model."
    },
    {
        "Question_id":56229207.0,
        "Question_title":"Export MXNet model to ONNX with _contrib_MultiBoxPrior Error",
        "Question_body":"<p>I created an object detection model in AWS SageMaker, based on SSD\/ResNet50 and in MXNet. \nNow I would like to optimize it in TensorRT, for which I need to export to ONNX as a first step.<\/p>\n\n<p>Looking for any recommendation on converting _contrib_MultiBoxPrior to a supported symbol didn't yield any result for me.<\/p>\n\n<p>Basic code<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>input_shape = (1, 3, 512, 512)\nconverted_model_path = onnx_mxnet.export_model(sym_file, params_file, [input_shape], np.float32, onnx_file)\n<\/code><\/pre>\n\n<p>The exact error message is<\/p>\n\n<p>\"AttributeError: No conversion function registered for op type _contrib_MultiBoxPrior yet.\"<\/p>\n\n<p>What is the recommended way to solve this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1558393535063,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "mxnet",
            "amazon-sagemaker",
            "tensorrt",
            "onnx"
        ],
        "Question_view_count":334.0,
        "Owner_creation_time":1407926464176,
        "Owner_last_access_time":1662140645003,
        "Owner_reputation":61.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":7.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"San Francisco, CA, USA",
        "Question_last_edit_time":1558501429996,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56229207",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: export mxnet model to onnx with _contrib_multiboxprior error; content:<p>i created an object detection model in , based on ssd\/resnet50 and in mxnet. \nnow i would like to optimize it in tensorrt, for which i need to export to onnx as a first step.<\/p>\n\n<p>looking for any recommendation on converting _contrib_multiboxprior to a supported symbol didn't yield any result for me.<\/p>\n\n<p>basic code<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>input_shape = (1, 3, 512, 512)\nconverted_model_path = onnx_mxnet.export_model(sym_file, params_file, [input_shape], np.float32, onnx_file)\n<\/code><\/pre>\n\n<p>the exact error message is<\/p>\n\n<p>\"attributeerror: no conversion function registered for op type _contrib_multiboxprior yet.\"<\/p>\n\n<p>what is the recommended way to solve this error?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a recommendation on how to convert a _contrib_multiboxprior symbol to a supported symbol in order to export an MXNet model to ONNX."
    },
    {
        "Question_id":42324035.0,
        "Question_title":"How to select Scored Probabilities from azure prediction model",
        "Question_body":"<p>I have a model in AzureML that scores incoming values from a csv.<\/p>\n\n<p>The flow is ...->(Score Model using one-class SVM)->(Normalize Data)->(Convert to CSV)->(Convert to Dataset)->(Web Service Output)<\/p>\n\n<p>When the experiment is run I can download the csv from the (Convert to CSV) module output and it will contain Scored Probabilities column.<\/p>\n\n<p>But when I'm using a streaming job I don't know how to access the Scored Probabilities column using Query SQL. How do I do it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1487482693377,
        "Question_favorite_count":1.0,
        "Question_score":1.0,
        "Question_tags":[
            "azure",
            "azure-stream-analytics",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":576.0,
        "Owner_creation_time":1300047702248,
        "Owner_last_access_time":1563817416587,
        "Owner_reputation":586.0,
        "Owner_up_votes":33.0,
        "Owner_down_votes":3.0,
        "Owner_views":108.0,
        "Answer_body":"<p>You can access the response using the amlresult.[Scored Probabilities] notation, where amlresult is an alias for the return value from your AzureML call.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1488576068267,
        "Answer_score":2.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42324035",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to select scored probabilities from azure prediction model; content:<p>i have a model in  that scores incoming values from a csv.<\/p>\n\n<p>the flow is ...->(score model using one-class svm)->(normalize data)->(convert to csv)->(convert to dataset)->(web service output)<\/p>\n\n<p>when the experiment is run i can download the csv from the (convert to csv) module output and it will contain scored probabilities column.<\/p>\n\n<p>but when i'm using a streaming job i don't know how to access the scored probabilities column using query sql. how do i do it?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to access the scored probabilities column from a streaming job using query SQL, but is unsure how to do so."
    },
    {
        "Question_id":72663743.0,
        "Question_title":"Azure ML Python SDK Unable to get MSI token using identity secret",
        "Question_body":"<p>I've been using the Azure ML Python SDK to create pipelines for weeks now, but all of the sudden I started getting this error when trying to get the default datastore<\/p>\n<pre><code>ws = Workspace.from_config()\ndef_blob_store = ws.get_default_datastore()\n<\/code><\/pre>\n<blockquote>\n<p>Traceback (most recent call last):   File &quot;lstm_evaluate_pipeline.py&quot;,\nline 14, in \ndef_blob_store = ws.get_default_datastore()   File &quot;\/opt\/anaconda3\/envs\/azure_ml\/lib\/python3.8\/site-packages\/azureml\/core\/workspace.py&quot;,\nline 1154, in get_default_datastore\nreturn _DatastoreClient.get_default(self)   File &quot;\/opt\/anaconda3\/envs\/azure_ml\/lib\/python3.8\/site-packages\/azureml\/data\/datastore_client.py&quot;,\nline 699, in get_default\nreturn _DatastoreClient._get_default(workspace)   File &quot;\/opt\/anaconda3\/envs\/azure_ml\/lib\/python3.8\/site-packages\/azureml\/data\/_exception_handler.py&quot;,\nline 19, in decorated\nraise UserErrorException(str(e)) azureml.exceptions._azureml_exception.UserErrorException:\nUserErrorException:   Message: (UserError) Unable to get MSI token\nusing identity secret. The application associated with this managed\nidentity  InnerException None     ErrorResponse  {\n&quot;error&quot;: {\n&quot;code&quot;: &quot;UserError&quot;,\n&quot;message&quot;: &quot;(UserError) Unable to get MSI token using identity secret. The application associated with this managed identity&quot;\n} }<\/p>\n<\/blockquote>\n<p>How can I fix this? I'm running this on MacOS Monterey in a conda environment using Python 3.8. The sdk version is 1.42.0<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1655492453573,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "azure",
            "azure-machine-learning-service",
            "azureml-python-sdk"
        ],
        "Question_view_count":52.0,
        "Owner_creation_time":1399515882223,
        "Owner_last_access_time":1664060417212,
        "Owner_reputation":3015.0,
        "Owner_up_votes":821.0,
        "Owner_down_votes":0.0,
        "Owner_views":203.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Chicago",
        "Question_last_edit_time":1655495184432,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72663743",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  python sdk unable to get msi token using identity secret; content:<p>i've been using the  python sdk to create pipelines for weeks now, but all of the sudden i started getting this error when trying to get the default datastore<\/p>\n<pre><code>ws = workspace.from_config()\ndef_blob_store = ws.get_default_datastore()\n<\/code><\/pre>\n<blockquote>\n<p>traceback (most recent call last):   file &quot;lstm_evaluate_pipeline.py&quot;,\nline 14, in \ndef_blob_store = ws.get_default_datastore()   file &quot;\/opt\/anaconda3\/envs\/azure_ml\/lib\/python3.8\/site-packages\/\/core\/workspace.py&quot;,\nline 1154, in get_default_datastore\nreturn _datastoreclient.get_default(self)   file &quot;\/opt\/anaconda3\/envs\/azure_ml\/lib\/python3.8\/site-packages\/\/data\/datastore_client.py&quot;,\nline 699, in get_default\nreturn _datastoreclient._get_default(workspace)   file &quot;\/opt\/anaconda3\/envs\/azure_ml\/lib\/python3.8\/site-packages\/\/data\/_exception_handler.py&quot;,\nline 19, in decorated\nraise usererrorexception(str(e)) .exceptions.__exception.usererrorexception:\nusererrorexception:   message: (usererror) unable to get msi token\nusing identity secret. the application associated with this managed\nidentity  innerexception none     errorresponse  {\n&quot;error&quot;: {\n&quot;code&quot;: &quot;usererror&quot;,\n&quot;message&quot;: &quot;(usererror) unable to get msi token using identity secret. the application associated with this managed identity&quot;\n} }<\/p>\n<\/blockquote>\n<p>how can i fix this? i'm running this on macos monterey in a conda environment using python 3.8. the sdk version is 1.42.0<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when trying to get the default datastore using the Azure ML Python SDK, which is unable to get an MSI token using the identity secret."
    },
    {
        "Question_id":59078589.0,
        "Question_title":"SageMaker notebook connected to EMR import custom Python module",
        "Question_body":"<p>I looked through similar questions but none of them solved my problem.\nI have a SageMaker notebook instance, opened a SparkMagic Pyspark notebook connected to a AWS EMR cluster. I have a SageMaker repo connected to this notebook as well called dsci-Python<\/p>\n\n<p>Directory looks like:<\/p>\n\n<pre><code>\/home\/ec2-user\/SageMaker\/dsci-Python\n\/home\/ec2-user\/SageMaker\/dsci-Python\/pyspark_mle\/datalake_data_object\/SomeClass\n\/home\/ec2-user\/SageMaker\/dsci-Python\/Pyspark_playground.ipynb\n<\/code><\/pre>\n\n<p>There are <code>__init__.py<\/code> under both pyspark_mle and datalake_data_object directory and I have no problem importing them in other environments<\/p>\n\n<p>when I'm running this code in Pyspark_playground.ipynb:<\/p>\n\n<pre><code>from pyspark_mle.datalake_data_object.SomeClass.SomeClass import Something\n<\/code><\/pre>\n\n<p>I got No module named 'pyspark_mle'<\/p>\n\n<p>I think this is an environment path thing.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1574889575783,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "amazon-emr",
            "amazon-sagemaker"
        ],
        "Question_view_count":924.0,
        "Owner_creation_time":1501398593483,
        "Owner_last_access_time":1584045557220,
        "Owner_reputation":875.0,
        "Owner_up_votes":17.0,
        "Owner_down_votes":0.0,
        "Owner_views":58.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59078589",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  notebook connected to emr import custom python module; content:<p>i looked through similar questions but none of them solved my problem.\ni have a  notebook instance, opened a sparkmagic pyspark notebook connected to a aws emr cluster. i have a  repo connected to this notebook as well called dsci-python<\/p>\n\n<p>directory looks like:<\/p>\n\n<pre><code>\/home\/ec2-user\/\/dsci-python\n\/home\/ec2-user\/\/dsci-python\/pyspark_mle\/datalake_data_object\/someclass\n\/home\/ec2-user\/\/dsci-python\/pyspark_playground.ipynb\n<\/code><\/pre>\n\n<p>there are <code>__init__.py<\/code> under both pyspark_mle and datalake_data_object directory and i have no problem importing them in other environments<\/p>\n\n<p>when i'm running this code in pyspark_playground.ipynb:<\/p>\n\n<pre><code>from pyspark_mle.datalake_data_object.someclass.someclass import something\n<\/code><\/pre>\n\n<p>i got no module named 'pyspark_mle'<\/p>\n\n<p>i think this is an environment path thing.  <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty importing a custom Python module into a notebook instance connected to an EMR cluster."
    },
    {
        "Question_id":72554404.0,
        "Question_title":"Access MLflow Artifacts in Model Registry Using Python",
        "Question_body":"<p>I am looking to access the artifacts of a model registered to the Model Registry in Databricks. However, I want to be able to do this outside of Databricks, using a Python script.<\/p>\n<p>Specifically, I want to be able to access the <code>feature_spec.yml<\/code> shown in the directory structure below,<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/7lSav.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7lSav.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I came across this article in the Microsoft docs, but it is not quite clear,\n<br>\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/access-hosted-tracking-server\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/access-hosted-tracking-server<\/a><\/p>\n<p>Note that I will probably only have the name of the Model and the Version that I want to access. How can I do this using Python?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1654745124130,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "databricks",
            "mlflow"
        ],
        "Question_view_count":203.0,
        "Owner_creation_time":1521856385820,
        "Owner_last_access_time":1664037995903,
        "Owner_reputation":820.0,
        "Owner_up_votes":389.0,
        "Owner_down_votes":1.0,
        "Owner_views":165.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Sri Lanka",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72554404",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: access  artifacts in model registry using python; content:<p>i am looking to access the artifacts of a model registered to the model registry in databricks. however, i want to be able to do this outside of databricks, using a python script.<\/p>\n<p>specifically, i want to be able to access the <code>feature_spec.yml<\/code> shown in the directory structure below,<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/7lsav.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7lsav.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>i came across this article in the microsoft docs, but it is not quite clear,\n<br>\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/\/access-hosted-tracking-server\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/\/access-hosted-tracking-server<\/a><\/p>\n<p>note that i will probably only have the name of the model and the version that i want to access. how can i do this using python?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to access the artifacts of a model registered in Databricks Model Registry using a python script and wants to access the `feature_spec.yml` file. They came across a Microsoft article but found it unclear. The user wants to know how to access the model with only the name of the model and its version using python."
    },
    {
        "Question_id":null,
        "Question_title":"DVC push to SSH remote ERROR: No such file",
        "Question_body":"<p>I do the Getting started guide.<br>\nWhen it is time to add a remote, instead of proposed S3 storage, I use an SSH remote that I add using the following command:<\/p>\n<pre><code>dvc remote add -d storage ssh:\/\/ws\/hddb\/data\/dvc-tutorial\n<\/code><\/pre>\n<p>where ws is a hostname of a workstation with the SSH access enabled, and <code>hddb\/data\/dvc-tutorial<\/code> is the path to the directory in which I would like to keep the data. I actually execute this command being on the workstation through SSH (I can recursively ssh to this workstation when I am already ssh\u2019ed to it).<\/p>\n<p>Then I have to execute the following command to use passphrase-protected SSH keys:<\/p>\n<pre><code>dvc remote modify --local storage password my-lovely-passphrase\n<\/code><\/pre>\n<p>When I do <code>dvc push<\/code> to transfer <code>data\/data.xml<\/code> from the Getting started guide, it fails when the following error:<\/p>\n<pre><code class=\"lang-auto\">\u279c dvc push                                             \nERROR: failed to transfer 'md5: 22a1a2931c8370d3aeedd7183606fd7f' - [Errno 2] No such file or directory: No such file\nERROR: failed to push data to the cloud - 1 files failed to upload\n<\/code><\/pre>\n<p>What should I do to make an SSH remote work? Thank you!<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_creation_time":1654677490086,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":150.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-push-to-ssh-remote-error-no-such-file\/1203",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2685,
                "name":"",
                "username":"dtrifiro",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/278dde\/{size}.png",
                "created_at":"2022-06-08T09:17:20.147Z",
                "cooked":"<p>Hey there,<br>\nit may be due to the username (and possibly port, if it\u2019s not 22) missing from the ssh remote url. I\u2019d try again with:<\/p>\n<p>dvc remote add -d storage ssh:\/\/username@ws\/hddb\/data\/dvc-tutorial<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-06-08T09:17:20.147Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":6.0,
                "yours":false,
                "topic_id":1203,
                "topic_slug":"dvc-push-to-ssh-remote-error-no-such-file",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":396,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2686,
                "name":"Dmitry Kabanov",
                "username":"dmitry-kabanov",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/bcef8e\/{size}.png",
                "created_at":"2022-06-08T09:26:37.698Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/dtrifiro\">@dtrifiro<\/a>. I\u2019ve just tried it with username added but it still gives the same error<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-06-08T09:26:37.698Z",
                "reply_count":0,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":1203,
                "topic_slug":"dvc-push-to-ssh-remote-error-no-such-file",
                "display_username":"Dmitry Kabanov",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"dtrifiro",
                    "name":"",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/278dde\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":452,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2687,
                "name":"",
                "username":"dtrifiro",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/278dde\/{size}.png",
                "created_at":"2022-06-08T09:28:36.269Z",
                "cooked":"<p>Are you able to login using <code>ssh username@ws<\/code>? Does the path exist on the workstation and does the user you\u2019re connecting as have the permissions to read\/write to the given path?<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-06-08T09:28:36.269Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":6.0,
                "yours":false,
                "topic_id":1203,
                "topic_slug":"dvc-push-to-ssh-remote-error-no-such-file",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":396,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2688,
                "name":"Dmitry Kabanov",
                "username":"dmitry-kabanov",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/bcef8e\/{size}.png",
                "created_at":"2022-06-08T09:38:40.105Z",
                "cooked":"<p>Ooops, yeah, the problem was with the write permissions of the users for the directory path <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nThe error message was a bit misleading in that sense.<br>\nDear <a class=\"mention\" href=\"\/u\/dtrifiro\">@dtrifiro<\/a> thank you very much!<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2022-06-08T09:38:40.105Z",
                "reply_count":0,
                "reply_to_post_number":4,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":0.8,
                "yours":false,
                "topic_id":1203,
                "topic_slug":"dvc-push-to-ssh-remote-error-no-such-file",
                "display_username":"Dmitry Kabanov",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"dtrifiro",
                    "name":"",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/278dde\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":452,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2689,
                "name":"",
                "username":"dtrifiro",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/278dde\/{size}.png",
                "created_at":"2022-06-08T09:41:02.870Z",
                "cooked":"<p>I agree, the message is a bit misleading. If you want, you could open up an issue on github so that we can keep track of that.<\/p>\n<p>Happy to hear that everything is working <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/partying_face.png?v=12\" title=\":partying_face:\" class=\"emoji\" alt=\":partying_face:\" loading=\"lazy\" width=\"20\" height=\"20\"><\/p>",
                "post_number":6,
                "post_type":1,
                "updated_at":"2022-06-08T09:41:02.870Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":15.8,
                "yours":false,
                "topic_id":1203,
                "topic_slug":"dvc-push-to-ssh-remote-error-no-such-file",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":396,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  push to ssh remote error: no such file; content:<p>i do the getting started guide.<br>\nwhen it is time to add a remote, instead of proposed s3 storage, i use an ssh remote that i add using the following command:<\/p>\n<pre><code> remote add -d storage ssh:\/\/ws\/hddb\/data\/-tutorial\n<\/code><\/pre>\n<p>where ws is a hostname of a workstation with the ssh access enabled, and <code>hddb\/data\/-tutorial<\/code> is the path to the directory in which i would like to keep the data. i actually execute this command being on the workstation through ssh (i can recursively ssh to this workstation when i am already ssh\u2019ed to it).<\/p>\n<p>then i have to execute the following command to use passphrase-protected ssh keys:<\/p>\n<pre><code> remote modify --local storage password my-lovely-passphrase\n<\/code><\/pre>\n<p>when i do <code> push<\/code> to transfer <code>data\/data.xml<\/code> from the getting started guide, it fails when the following error:<\/p>\n<pre><code class=\"lang-auto\">\u279c  push                                             \nerror: failed to transfer 'md5: 22a1a2931c8370d3aeedd7183606fd7f' - [errno 2] no such file or directory: no such file\nerror: failed to push data to the cloud - 1 files failed to upload\n<\/code><\/pre>\n<p>what should i do to make an ssh remote work? thank you!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty pushing data to an SSH remote, receiving an error that there is no such file or directory."
    },
    {
        "Question_id":63156236.0,
        "Question_title":"Error while Uploading Model Explainations using Azure-Interpret ExplanationClient",
        "Question_body":"<p>We are trying to use Azure Machine Learning to interpret a model by using Azure ML Interpretability libraries namely <strong>azureml-interpret<\/strong>  and <strong>azureml-sdk[explain]<\/strong>.\nOur model is RandomForestRegressor from sklearn.ensemble.<\/p>\n<pre><code>import lightgbm\nfrom interpret.ext.blackbox import PFIExplainer\n#from interpret.ext.glassbox import DecisionTreeExplainableModel\nfrom azureml.contrib.interpret.explanation.explanation_client import ExplanationClient\nmodel = train_model(X_train_df,y_train_df)\n\nexplainer = PFIExplainer(model, features = feature_names)\n\nglobal_explanation = explainer.explain_global(X_test_df[0:50],true_labels=y_test_df[0:50])\n\nexplain_client = ExplanationClient.from_run(run)\nexplain_client.upload_model_explanation(global_explanation)\n<\/code><\/pre>\n<p>We are getting the following error<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;training\/train.py&quot;, line 83, in &lt;module&gt;\n    explain_client.upload_model_explanation(global_explanation)\n  File &quot;\/azureml-envs\/azureml_d5d57a45ca9af991b8408524822c201f\/lib\/python3.6\/site-packages\/azureml\/interpret\/_internal\/explanation_client.py&quot;, line 793, in upload_model_explanation\n    asset_type=History.ASSET_TYPE\nTypeError: create_asset() got an unexpected keyword argument 'asset_type'\n<\/code><\/pre>\n<p>We have tried -\nTabularExplainer, MimicExplainer(with DecisionTreeExplainableModel) but all of them result in the same error.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1596033917473,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-service"
        ],
        "Question_view_count":166.0,
        "Owner_creation_time":1596025714283,
        "Owner_last_access_time":1603393210436,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":7.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Atlanta, GA, USA",
        "Question_last_edit_time":1596041654128,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63156236",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: error while uploading model explainations using azure-interpret explanationclient; content:<p>we are trying to use  to interpret a model by using  interpretability libraries namely <strong>-interpret<\/strong>  and <strong>-sdk[explain]<\/strong>.\nour model is randomforestregressor from sklearn.ensemble.<\/p>\n<pre><code>import lightgbm\nfrom interpret.ext.blackbox import pfiexplainer\n#from interpret.ext.glassbox import decisiontreeexplainablemodel\nfrom .contrib.interpret.explanation.explanation_client import explanationclient\nmodel = train_model(x_train_df,y_train_df)\n\nexplainer = pfiexplainer(model, features = feature_names)\n\nglobal_explanation = explainer.explain_global(x_test_df[0:50],true_labels=y_test_df[0:50])\n\nexplain_client = explanationclient.from_run(run)\nexplain_client.upload_model_explanation(global_explanation)\n<\/code><\/pre>\n<p>we are getting the following error<\/p>\n<pre><code>traceback (most recent call last):\n  file &quot;training\/train.py&quot;, line 83, in &lt;module&gt;\n    explain_client.upload_model_explanation(global_explanation)\n  file &quot;\/-envs\/_d5d57a45ca9af991b8408524822c201f\/lib\/python3.6\/site-packages\/\/interpret\/_internal\/explanation_client.py&quot;, line 793, in upload_model_explanation\n    asset_type=history.asset_type\ntypeerror: create_asset() got an unexpected keyword argument 'asset_type'\n<\/code><\/pre>\n<p>we have tried -\ntabularexplainer, mimicexplainer(with decisiontreeexplainablemodel) but all of them result in the same error.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error while attempting to upload model explanations using the Azure-Interpret ExplanationClient library with a RandomForestRegressor from sklearn.ensemble."
    },
    {
        "Question_id":66657850.0,
        "Question_title":"Boto3 \/ MLflow model logging via temporary AWS credentials",
        "Question_body":"<p>We are building an ML tracking service using MLflow as a backend. One issue we've run into is that in order to log models via MLflow's python API\u200b, the user needs to have AWS credentials configured on their machine. Since our service is outward-facing, we can't really let users have the access key for our S3 bucket. Is there a mechanism for authenticating a boto3 client used by MLflow via some temporary AWS credentials? We can generate a signed URL with write permissions to the bucket, but it's unclear how we would then pass it onto the boto3 client \/ MLflow python api. Or can we do something with environment variables? In any case, if someone knows of a good way to do this - I'd greatly appreciate the help.\nBest,\nSP<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1615906925970,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "boto3",
            "credentials",
            "mlflow"
        ],
        "Question_view_count":264.0,
        "Owner_creation_time":1509135548107,
        "Owner_last_access_time":1656423989088,
        "Owner_reputation":53.0,
        "Owner_up_votes":6.0,
        "Owner_down_votes":0.0,
        "Owner_views":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66657850",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: boto3 \/  model logging via temporary aws credentials; content:<p>we are building an ml tracking service using  as a backend. one issue we've run into is that in order to log models via 's python api\u200b, the user needs to have aws credentials configured on their machine. since our service is outward-facing, we can't really let users have the access key for our s3 bucket. is there a mechanism for authenticating a boto3 client used by  via some temporary aws credentials? we can generate a signed url with write permissions to the bucket, but it's unclear how we would then pass it onto the boto3 client \/  python api. or can we do something with environment variables? in any case, if someone knows of a good way to do this - i'd greatly appreciate the help.\nbest,\nsp<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs a way to authenticate a boto3 client used by model logging via temporary AWS credentials, as they cannot provide the access key for the S3 bucket."
    },
    {
        "Question_id":72982916.0,
        "Question_title":"How to set the number of cosmoDB item processed in micro-batch in Spark Structured streaming?",
        "Question_body":"<p>Basically, I'm using spark structured streaming to read sensor data (24 sensors with frequency 1s) from cosmo, doing some manip and calling a MLFlow classification model.<\/p>\n<p>Thus, I need a batch of 24 input items (or a modulo of 24).<\/p>\n<p>My code look like this so far :<\/p>\n<pre><code>  &quot;spark.cosmos.accountEndpoint&quot; : cosmosEndpoint,\n  &quot;spark.cosmos.accountKey&quot; : cosmosMasterKey,\n  &quot;spark.cosmos.database&quot; : cosmosDatabaseName,\n  &quot;spark.cosmos.container&quot; : cosmosContainerName,\n  &quot;spark.cosmos.upsert&quot; : &quot;true&quot;\n}\n\n# Configure Catalog Api to be used\nspark.conf.set(&quot;spark.sql.catalog.cosmosCatalog&quot;, &quot;com.azure.cosmos.spark.CosmosCatalog&quot;)\nspark.conf.set(&quot;spark.sql.catalog.cosmosCatalog.spark.cosmos.accountEndpoint&quot;, cosmosEndpoint)\nspark.conf.set(&quot;spark.sql.catalog.cosmosCatalog.spark.cosmos.accountKey&quot;, cosmosMasterKey)\n\n# Initiate Cosmos Connection Config Object\nchangeFeedCfg = {\n  &quot;spark.cosmos.accountEndpoint&quot;: cosmosEndpoint,\n  &quot;spark.cosmos.accountKey&quot;: cosmosMasterKey,\n  &quot;spark.cosmos.database&quot;: cosmosDatabaseName,\n  &quot;spark.cosmos.container&quot;: cosmosContainerName,\n  &quot;spark.cosmos.read.partitioning.strategy&quot;: &quot;Default&quot;,\n  &quot;spark.cosmos.read.inferSchema.enabled&quot; : &quot;false&quot;,\n  &quot;spark.cosmos.changeFeed.startFrom&quot; : &quot;Now&quot;,\n  &quot;spark.cosmos.changeFeed.mode&quot; : &quot;Incremental&quot;,\n  &quot;spark.cosmos.changeFeed.ItemCountPerTriggerHint&quot; : 24,\n}\n\n# Load model as a PysparkUDF\nloaded_model = mlflow.pyfunc.spark_udf(spark, model_uri='runs:\/*********\/model', result_type='double')\nliteral_eval_udf = udf(ast.literal_eval, MapType(StringType(), StringType()))\n\nfixedStream = spark.readStream.format(&quot;cosmos.oltp.changeFeed&quot;).options(**changeFeedCfg).load()\n\nfixedStream = fixedStream.select('_rawBody').withColumn('temp', regexp_replace('_rawBody', ',&quot;_rid&quot;.*', '}')).drop('_rawBody')\nfixedStream = fixedStream.withColumn(&quot;temp&quot;, map_values(literal_eval_udf(col(&quot;temp&quot;))))\nkeys = ['datetime', 'machine', 'id', 'factor', 'value', 'Sensor']\nfor k in range(len(keys)):\n    fixedStream = fixedStream.withColumn(keys[k], fixedStream.temp[k])\nfixedStream = fixedStream.select('factor','machine','Sensor','value')\n\ndef foreach_batch_function(df, epoch_id):\n    df = df.groupBy('factor','machine').pivot(&quot;Sensor&quot;).agg(first(&quot;value&quot;))\n    columns = list(df)\n    df = df.withColumn('predictions', loaded_model(*columns)).collect()\n    df.write.option(&quot;mergeSchema&quot;,&quot;true&quot;).format(&quot;delta&quot;).option(&quot;header&quot;, &quot;true&quot;).mode(&quot;append&quot;).saveAsTable(&quot;poc_industry.test_stream&quot;)\n    \nfixedStream.writeStream.foreachBatch(foreach_batch_function).start()\n<\/code><\/pre>\n<p>I have tried using with the read stream:<\/p>\n<ul>\n<li>ItemCountPerTriggerHint,<\/li>\n<li>limit<\/li>\n<li>maxItemCount<\/li>\n<\/ul>\n<p>I also tried slowing down the write with the trigger(processingTime='x seconds') option.<\/p>\n<p>It runs without error, But none of it seems to have an effect on the batchDF size, indeed numInputRows seems to be varying randomly between (3 and 100).<\/p>\n<p>As anyone achieve something like this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1657811951507,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "pyspark",
            "azure-databricks",
            "spark-structured-streaming",
            "azure-cosmosdb-sqlapi",
            "mlflow"
        ],
        "Question_view_count":37.0,
        "Owner_creation_time":1517574702710,
        "Owner_last_access_time":1663964321916,
        "Owner_reputation":31.0,
        "Owner_up_votes":31.0,
        "Owner_down_votes":0.0,
        "Owner_views":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72982916",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to set the number of cosmodb item processed in micro-batch in spark structured streaming?; content:<p>basically, i'm using spark structured streaming to read sensor data (24 sensors with frequency 1s) from cosmo, doing some manip and calling a  classification model.<\/p>\n<p>thus, i need a batch of 24 input items (or a modulo of 24).<\/p>\n<p>my code look like this so far :<\/p>\n<pre><code>  &quot;spark.cosmos.accountendpoint&quot; : cosmosendpoint,\n  &quot;spark.cosmos.accountkey&quot; : cosmosmasterkey,\n  &quot;spark.cosmos.database&quot; : cosmosdatabasename,\n  &quot;spark.cosmos.container&quot; : cosmoscontainername,\n  &quot;spark.cosmos.upsert&quot; : &quot;true&quot;\n}\n\n# configure catalog api to be used\nspark.conf.set(&quot;spark.sql.catalog.cosmoscatalog&quot;, &quot;com.azure.cosmos.spark.cosmoscatalog&quot;)\nspark.conf.set(&quot;spark.sql.catalog.cosmoscatalog.spark.cosmos.accountendpoint&quot;, cosmosendpoint)\nspark.conf.set(&quot;spark.sql.catalog.cosmoscatalog.spark.cosmos.accountkey&quot;, cosmosmasterkey)\n\n# initiate cosmos connection config object\nchangefeedcfg = {\n  &quot;spark.cosmos.accountendpoint&quot;: cosmosendpoint,\n  &quot;spark.cosmos.accountkey&quot;: cosmosmasterkey,\n  &quot;spark.cosmos.database&quot;: cosmosdatabasename,\n  &quot;spark.cosmos.container&quot;: cosmoscontainername,\n  &quot;spark.cosmos.read.partitioning.strategy&quot;: &quot;default&quot;,\n  &quot;spark.cosmos.read.inferschema.enabled&quot; : &quot;false&quot;,\n  &quot;spark.cosmos.changefeed.startfrom&quot; : &quot;now&quot;,\n  &quot;spark.cosmos.changefeed.mode&quot; : &quot;incremental&quot;,\n  &quot;spark.cosmos.changefeed.itemcountpertriggerhint&quot; : 24,\n}\n\n# load model as a pysparkudf\nloaded_model = .pyfunc.spark_udf(spark, model_uri='runs:\/*********\/model', result_type='double')\nliteral_eval_udf = udf(ast.literal_eval, maptype(stringtype(), stringtype()))\n\nfixedstream = spark.readstream.format(&quot;cosmos.oltp.changefeed&quot;).options(**changefeedcfg).load()\n\nfixedstream = fixedstream.select('_rawbody').withcolumn('temp', regexp_replace('_rawbody', ',&quot;_rid&quot;.*', '}')).drop('_rawbody')\nfixedstream = fixedstream.withcolumn(&quot;temp&quot;, map_values(literal_eval_udf(col(&quot;temp&quot;))))\nkeys = ['datetime', 'machine', 'id', 'factor', 'value', 'sensor']\nfor k in range(len(keys)):\n    fixedstream = fixedstream.withcolumn(keys[k], fixedstream.temp[k])\nfixedstream = fixedstream.select('factor','machine','sensor','value')\n\ndef foreach_batch_function(df, epoch_id):\n    df = df.groupby('factor','machine').pivot(&quot;sensor&quot;).agg(first(&quot;value&quot;))\n    columns = list(df)\n    df = df.withcolumn('predictions', loaded_model(*columns)).collect()\n    df.write.option(&quot;mergeschema&quot;,&quot;true&quot;).format(&quot;delta&quot;).option(&quot;header&quot;, &quot;true&quot;).mode(&quot;append&quot;).saveastable(&quot;poc_industry.test_stream&quot;)\n    \nfixedstream.writestream.foreachbatch(foreach_batch_function).start()\n<\/code><\/pre>\n<p>i have tried using with the read stream:<\/p>\n<ul>\n<li>itemcountpertriggerhint,<\/li>\n<li>limit<\/li>\n<li>maxitemcount<\/li>\n<\/ul>\n<p>i also tried slowing down the write with the trigger(processingtime='x seconds') option.<\/p>\n<p>it runs without error, but none of it seems to have an effect on the batchdf size, indeed numinputrows seems to be varying randomly between (3 and 100).<\/p>\n<p>as anyone achieve something like this?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to set the number of CosmoDB items processed in a micro-batch in Spark Structured Streaming, and has tried various options such as itemcountpertriggerhint, limit, and maxitemcount, but none of them seem to have an effect."
    },
    {
        "Question_id":null,
        "Question_title":"Confusion matrix not generating \"Custom chart\" entry",
        "Question_body":"<p>I\u2019m using the following code (based on <code>wandb.plot.confusion_matrix<\/code> because I accumulate my own confusion matrix per step using <code>tf.math.confusion_matrix<\/code>) to log a confusion matrix:<\/p>\n<pre><code class=\"lang-auto\"> data = []\n for i in range(n_classes):\n     for j in range(n_classes):\n         data.append([class_names[i], class_names[j], value[i, j]])\n\n fields = {\n     \"Actual\": \"Actual\",\n     \"Predicted\": \"Predicted\",\n     \"nPredictions\": \"nPredictions\",\n }\n return wandb.plot_table(\n     \"wandb\/confusion_matrix\/v1\",\n     wandb.Table(columns=[\"Actual\", \"Predicted\", \"nPredictions\"], data=data),\n     fields,\n     {\"title\": title},\n )\n<\/code><\/pre>\n<p>On one run I did get the custom chart, but the \u201cActual\u201d labels (on the Y-axis) were horribly laid out so I tweaked the code to generate different labels and now I don\u2019t see the custom chart. I tried to create my own custom chart cloning the settings from the other confusion matrix, but the \u201cOK\u201d button is grayed out.<\/p>\n<p>Are there some extra checks somewhere that decide whether or not to generate a confusion matrix report?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d5db4d0f7e4bcecf7a79828175f915f107ddd53b.png\" data-download-href=\"\/uploads\/short-url\/uvRybQw5OBb0uSf32Wb66ffRbFV.png?dl=1\" title=\"Screen Shot 2022-09-25 at 4.30.45 pm\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/d\/d5db4d0f7e4bcecf7a79828175f915f107ddd53b.png\" alt=\"Screen Shot 2022-09-25 at 4.30.45 pm\" data-base62-sha1=\"uvRybQw5OBb0uSf32Wb66ffRbFV\" width=\"183\" height=\"500\" data-dominant-color=\"272727\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-09-25 at 4.30.45 pm<\/span><span class=\"informations\">268\u00d7732 9.57 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d.jpeg\" data-download-href=\"\/uploads\/short-url\/12g1yYFJCC60Ln7oWdZARFbh57v.jpeg?dl=1\" title=\"Screen Shot 2022-09-25 at 4.34.29 pm\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_690x333.jpeg\" alt=\"Screen Shot 2022-09-25 at 4.34.29 pm\" data-base62-sha1=\"12g1yYFJCC60Ln7oWdZARFbh57v\" width=\"690\" height=\"333\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_690x333.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_1035x499.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/2X\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_1380x666.jpeg 2x\" data-dominant-color=\"252525\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Screen Shot 2022-09-25 at 4.34.29 pm<\/span><span class=\"informations\">2934\u00d71418 140 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_creation_time":1664087892866,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":248.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/confusion-matrix-not-generating-custom-chart-entry\/3181",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":7597,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-09-29T09:24:10.923Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/tbirch\">@tbirch<\/a>, thank you for reporting this, and sorry for the delay in this response. I am following up with you here after our discussion in the Support chat.<\/p>\n<p>I have looked into the wandb-summary.json and the summary metrics between the two Runs. It appears that the variables conf_mat_table and conf_mat_norm_table were not logged in the case where the confusion matrix isn\u2019t generated. The Vega spec and the code snippet above are correct, but the button is greyed out because it can\u2019t query the data. I am wondering if you had overwritten the Run, or did this experiment run a single time?<\/p>\n<p>The artifacts seem to be properly logged in both cases and you can get them to your Workspace using a Weave expression such as:<br>\nproject(\u201centity\u201d, \u201cproject-name_\u201d).artifact(\u201crun-runid-conf_mat_norm_table\u201d).membershipForAlias(\u201cv19\u201d).artifactVersion.file(\u201cconf_mat_norm_table.table.json\u201d)<\/p>\n<p>Would you be interested in the option to download the data, generate the chart externally and then log it to this Run?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-09-29T09:28:37.821Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":2,
                "readers_count":1,
                "score":10.4,
                "yours":false,
                "topic_id":3181,
                "topic_slug":"confusion-matrix-not-generating-custom-chart-entry",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":2,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7599,
                "name":"Tom Birch",
                "username":"tbirch",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/b77776\/{size}.png",
                "created_at":"2022-09-29T10:25:10.202Z",
                "cooked":"<p>I\u2019d like to just know the correct code to log a \u201cwandb\/confusion_matrix\/v1\u201d given a NxN matrix of values and N labels. I don\u2019t care about the data for these runs, I was just doing them to test confusion matrix.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-09-29T10:25:10.202Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":5.4,
                "yours":false,
                "topic_id":3181,
                "topic_slug":"confusion-matrix-not-generating-custom-chart-entry",
                "display_username":"Tom Birch",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"thanos-wandb",
                    "name":"Thanos Vitsas",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1643,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7710,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-10-11T22:09:47.739Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/tbirch\">@tbirch<\/a> apologies for the late reply here, <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/wandb-log\/Log_a_Confusion_Matrix_with_W%26B.ipynb#scrollTo=6NZJwm8OE7Qw\" rel=\"noopener nofollow ugc\">this<\/a> is a working Colab that demonstrates how to log confusion matrices from your code. A minimal code example would be something like the following:<\/p>\n<pre><code class=\"lang-auto\">        vals = np.random.uniform(size=(10, 5))\n        probs = np.exp(vals)\/np.sum(np.exp(vals), keepdims=True, axis=1)\n        y_true = np.random.randint(0, 5, size=(10))\n        labels = [\"Cat\", \"Dog\", \"Bird\", \"Fish\", \"Horse\"]\n        wandb.log({'confusion_matrix': wandb.plot.confusion_matrix(probs, y_true=y_true, class_names=labels)})\n<\/code><\/pre>\n<p>Please let me know if that would help, or if you still have issues or further questions about this.<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-10-11T22:09:47.739Z",
                "reply_count":1,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":5.2,
                "yours":false,
                "topic_id":3181,
                "topic_slug":"confusion-matrix-not-generating-custom-chart-entry",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/wandb-log\/Log_a_Confusion_Matrix_with_W%26B.ipynb#scrollTo=6NZJwm8OE7Qw",
                        "internal":false,
                        "reflection":false,
                        "title":"Google Colab",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"tbirch",
                    "name":"Tom Birch",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/b77776\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7763,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-10-17T10:35:14.328Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/tbirch\">@tbirch<\/a> I wanted to follow up on this request, did the above Colab solve this? and would there be any further questions to help you with? thanks!<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2022-10-17T10:35:14.328Z",
                "reply_count":0,
                "reply_to_post_number":4,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":3181,
                "topic_slug":"confusion-matrix-not-generating-custom-chart-entry",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"thanos-wandb",
                    "name":"Thanos Vitsas",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7824,
                "name":"Thanos Vitsas",
                "username":"thanos-wandb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/4af34b\/{size}.png",
                "created_at":"2022-10-20T12:53:03.724Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/tbirch\">@tbirch<\/a> since we haven\u2019t heard back from you, I am going to close this ticket for now. If you still experience any issues, please let us know and we will keep investigating.<\/p>",
                "post_number":6,
                "post_type":1,
                "updated_at":"2022-10-20T12:53:03.724Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":3181,
                "topic_slug":"confusion-matrix-not-generating-custom-chart-entry",
                "display_username":"Thanos Vitsas",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1732,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: confusion matrix not generating \"custom chart\" entry; content:<p>i\u2019m using the following code (based on <code>.plot.confusion_matrix<\/code> because i accumulate my own confusion matrix per step using <code>tf.math.confusion_matrix<\/code>) to log a confusion matrix:<\/p>\n<pre><code class=\"lang-auto\"> data = []\n for i in range(n_classes):\n     for j in range(n_classes):\n         data.append([class_names[i], class_names[j], value[i, j]])\n\n fields = {\n     \"actual\": \"actual\",\n     \"predicted\": \"predicted\",\n     \"npredictions\": \"npredictions\",\n }\n return .plot_table(\n     \"\/confusion_matrix\/v1\",\n     .table(columns=[\"actual\", \"predicted\", \"npredictions\"], data=data),\n     fields,\n     {\"title\": title},\n )\n<\/code><\/pre>\n<p>on one run i did get the custom chart, but the \u201cactual\u201d labels (on the y-axis) were horribly laid out so i tweaked the code to generate different labels and now i don\u2019t see the custom chart. i tried to create my own custom chart cloning the settings from the other confusion matrix, but the \u201cok\u201d button is grayed out.<\/p>\n<p>are there some extra checks somewhere that decide whether or not to generate a confusion matrix report?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/2x\/d\/d5db4d0f7e4bcecf7a79828175f915f107ddd53b.png\" data-download-href=\"\/uploads\/short-url\/uvrybqw5obb0usf32wb66ffrbfv.png?dl=1\" title=\"screen shot 2022-09-25 at 4.30.45 pm\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/2x\/d\/d5db4d0f7e4bcecf7a79828175f915f107ddd53b.png\" alt=\"screen shot 2022-09-25 at 4.30.45 pm\" data-base62-sha1=\"uvrybqw5obb0usf32wb66ffrbfv\" width=\"183\" height=\"500\" data-dominant-color=\"272727\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">screen shot 2022-09-25 at 4.30.45 pm<\/span><span class=\"informations\">268\u00d7732 9.57 kb<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/2x\/0\/074387bfc030623568325ce892dc4c2921eb1d2d.jpeg\" data-download-href=\"\/uploads\/short-url\/12g1yyfjcc60ln7owdzarfbh57v.jpeg?dl=1\" title=\"screen shot 2022-09-25 at 4.34.29 pm\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/2x\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_690x333.jpeg\" alt=\"screen shot 2022-09-25 at 4.34.29 pm\" data-base62-sha1=\"12g1yyfjcc60ln7owdzarfbh57v\" width=\"690\" height=\"333\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/2x\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_690x333.jpeg, https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/2x\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_1035x499.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/2x\/0\/074387bfc030623568325ce892dc4c2921eb1d2d_2_1380x666.jpeg 2x\" data-dominant-color=\"252525\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">screen shot 2022-09-25 at 4.34.29 pm<\/span><span class=\"informations\">2934\u00d71418 140 kb<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty generating a \"custom chart\" entry for a confusion matrix and is unable to create their own custom chart due to the \"ok\" button being grayed out."
    },
    {
        "Question_id":69766663.0,
        "Question_title":"Sagemaker Studio trial component chart not showing",
        "Question_body":"<p>I am wondering why I am unable to show the loss and accuracy curve in Sagemaker Studio, Trial components chart.<\/p>\n<p>I am using tensorflow's keras API for training.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from sagemaker.tensorflow import TensorFlow\n\n\nestimator = TensorFlow(\n    entry_point=&quot;sm_entrypoint.sh&quot;,\n    source_dir=&quot;.&quot;,\n    role=role,\n    instance_count=1,\n    instance_type=&quot;ml.m5.4xlarge&quot;,\n    framework_version=&quot;2.4&quot;,\n    py_version=&quot;py37&quot;,\n    metric_definitions=[\n            {'Name':'train:loss', 'Regex':'loss: ([0-9.]+'},\n            {'Name':'val:loss', 'Regex':'val_loss: ([0-9.]+'},\n            {'Name':'train:accuracy', 'Regex':'accuracy: ([0-9.]+'},\n            {'Name':'val:accuracy', 'Regex':'val_accuracy: ([0-9.]+'}\n        ],\n    enable_sagemaker_metrics=True\n)\n \n\nestimator.fit(\n    inputs=&quot;s3:\/\/xxx&quot;,\n    experiment_config={\n        &quot;ExperimentName&quot;: &quot;urbansounds-20211027&quot;,\n        &quot;TrialName&quot;: &quot;tf-classical-NN-20211027&quot;,\n        &quot;TrialComponentDisplayName&quot;: &quot;Train&quot;\n    }\n)\n<\/code><\/pre>\n<p>Regex is enabled, and appears to be logging them correctly. Since under the metrics tab, it shows 12 counts for each metric, corresponding to 12 epochs cycle which I specified.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/G0Q4t.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/G0Q4t.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>However, the chart is empty. The x-axis is in time here, but it is also empty when I switched to epoch.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/7Q4x8.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7Q4x8.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1635500199747,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-sagemaker"
        ],
        "Question_view_count":127.0,
        "Owner_creation_time":1436933338692,
        "Owner_last_access_time":1663827546670,
        "Owner_reputation":1962.0,
        "Owner_up_votes":497.0,
        "Owner_down_votes":7.0,
        "Owner_views":168.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69766663",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  studio trial component chart not showing; content:<p>i am wondering why i am unable to show the loss and accuracy curve in  studio, trial components chart.<\/p>\n<p>i am using tensorflow's keras api for training.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from .tensorflow import tensorflow\n\n\nestimator = tensorflow(\n    entry_point=&quot;sm_entrypoint.sh&quot;,\n    source_dir=&quot;.&quot;,\n    role=role,\n    instance_count=1,\n    instance_type=&quot;ml.m5.4xlarge&quot;,\n    framework_version=&quot;2.4&quot;,\n    py_version=&quot;py37&quot;,\n    metric_definitions=[\n            {'name':'train:loss', 'regex':'loss: ([0-9.]+'},\n            {'name':'val:loss', 'regex':'val_loss: ([0-9.]+'},\n            {'name':'train:accuracy', 'regex':'accuracy: ([0-9.]+'},\n            {'name':'val:accuracy', 'regex':'val_accuracy: ([0-9.]+'}\n        ],\n    enable__metrics=true\n)\n \n\nestimator.fit(\n    inputs=&quot;s3:\/\/xxx&quot;,\n    experiment_config={\n        &quot;experimentname&quot;: &quot;urbansounds-20211027&quot;,\n        &quot;trialname&quot;: &quot;tf-classical-nn-20211027&quot;,\n        &quot;trialcomponentdisplayname&quot;: &quot;train&quot;\n    }\n)\n<\/code><\/pre>\n<p>regex is enabled, and appears to be logging them correctly. since under the metrics tab, it shows 12 counts for each metric, corresponding to 12 epochs cycle which i specified.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/g0q4t.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/g0q4t.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>however, the chart is empty. the x-axis is in time here, but it is also empty when i switched to epoch.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/7q4x8.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7q4x8.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to show the loss and accuracy curve in studio, trial components chart, despite regex being enabled and the metrics tab showing 12 counts for each metric. The chart is empty when the x-axis is in time or epoch."
    },
    {
        "Question_id":null,
        "Question_title":"passing a numpy array to predict_fn when making inference for xgboost model",
        "Question_body":"I have a model that's trained locally and deployed to SageMaker to make inferences \/ invoke endpoint. When I try to make predictions, I get the following exception.\n\nraise ValueError('Input numpy.ndarray must be 2 dimensional')\nValueError: Input numpy.ndarray must be 2 dimensional\n    \n\n\nMy model is a xgboost model with some pre-processing (variable encoding) and hyper-parameter tuning. Here's what model object looks like:\n\nXGBRegressor(colsample_bytree=xxx, gamma=xxx,\n             learning_rate=xxx, max_depth=x, n_estimators=xxx,\n             subsample=xxx)\n\n\nMy test data is a string of float values which is turned into an array as the data must be passed as numpy array.\n\ntestdata = [........., 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2000, 200, 85, 412412, 123, 41, 552, 50000, 512, 0.1, 10.0, 2.0, 0.05]\n\n\nI have tried to reshape the numpy array from 1d to 2d, however, that doesn't work as the number of features between test data and trained model do not match.\n\nMy question is how do I pass a numpy array same as the length of # of features in trained model? I am able to make predictions by passing test data as a list locally.\n\nMore info on inference script here: https:\/\/github.com\/aws-samples\/amazon-sagemaker-local-mode\/blob\/main\/xgboost_script_mode_local_training_and_serving\/code\/inference.py\n\nTraceback (most recent call last):\nFile \"\/miniconda3\/lib\/python3.6\/site-packages\/sagemaker_containers\/_functions.py\", line 93, in wrapper\nreturn fn(*args, **kwargs)\nFile \"\/opt\/ml\/code\/inference.py\", line 75, in predict_fn\nprediction = model.predict(input_data)\nFile \"\/miniconda3\/lib\/python3.6\/site-packages\/xgboost\/sklearn.py\", line 448, in predict\ntest_dmatrix = DMatrix(data, missing=self.missing, nthread=self.n_jobs)\nFile \"\/miniconda3\/lib\/python3.6\/site-packages\/xgboost\/core.py\", line 404, in __init__\nself._init_from_npy2d(data, missing, nthread)\nFile \"\/miniconda3\/lib\/python3.6\/site-packages\/xgboost\/core.py\", line 474, in _init_from_npy2d\nraise ValueError('Input numpy.ndarray must be 2 dimensional')\nValueError: Input numpy.ndarray must be 2 dimensional",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1638724249630,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Machine Learning & AI"
        ],
        "Question_view_count":421.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU-0wEAMBoQaK4s-Bsbp0qHA\/passing-a-numpy-array-to-predict-fn-when-making-inference-for-xgboost-model",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-06T21:17:24.244Z",
                "Answer_score":0,
                "Answer_body":"Try converting your list to a numpy 2d array like so:\n\na = np.array([1, 2, 3])\n\nand replace [1, 2, 3] with your list.",
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-10T09:23:39.023Z",
                "Answer_score":0,
                "Answer_body":"XGBoost, similar to scikit-learn, expects X as 2D data (n_samples, n_features). In order to predict one sample, you need to reshape your list or feature vector to a 2D array.\n\nimport numpy as np\n\nlst = [1, 2, 3]\nlst_reshaped = np.array(lst).reshape((1,-1))\nclf.predict(lst_reshaped)",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: passing a numpy array to predict_fn when making inference for xgboost model; content:i have a model that's trained locally and deployed to  to make inferences \/ invoke endpoint. when i try to make predictions, i get the following exception.\n\nraise valueerror('input numpy.ndarray must be 2 dimensional')\nvalueerror: input numpy.ndarray must be 2 dimensional\n    \n\n\nmy model is a xgboost model with some pre-processing (variable encoding) and hyper-parameter tuning. here's what model object looks like:\n\nxgbregressor(colsample_bytree=xxx, gamma=xxx,\n             learning_rate=xxx, max_depth=x, n_estimators=xxx,\n             subsample=xxx)\n\n\nmy test data is a string of float values which is turned into an array as the data must be passed as numpy array.\n\ntestdata = [........., 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2000, 200, 85, 412412, 123, 41, 552, 50000, 512, 0.1, 10.0, 2.0, 0.05]\n\n\ni have tried to reshape the numpy array from 1d to 2d, however, that doesn't work as the number of features between test data and trained model do not match.\n\nmy question is how do i pass a numpy array same as the length of # of features in trained model? i am able to make predictions by passing test data as a list locally.\n\nmore info on inference script here: https:\/\/github.com\/aws-samples\/amazon--local-mode\/blob\/main\/xgboost_script_mode_local_training_and_serving\/code\/inference.py\n\ntraceback (most recent call last):\nfile \"\/miniconda3\/lib\/python3.6\/site-packages\/_containers\/_functions.py\", line 93, in wrapper\nreturn fn(*args, **kwargs)\nfile \"\/opt\/ml\/code\/inference.py\", line 75, in predict_fn\nprediction = model.predict(input_data)\nfile \"\/miniconda3\/lib\/python3.6\/site-packages\/xgboost\/sklearn.py\", line 448, in predict\ntest_dmatrix = dmatrix(data, missing=self.missing, nthread=self.n_jobs)\nfile \"\/miniconda3\/lib\/python3.6\/site-packages\/xgboost\/core.py\", line 404, in __init__\nself._init_from_npy2d(data, missing, nthread)\nfile \"\/miniconda3\/lib\/python3.6\/site-packages\/xgboost\/core.py\", line 474, in _init_from_npy2d\nraise valueerror('input numpy.ndarray must be 2 dimensional')\nvalueerror: input numpy.ndarray must be 2 dimensional",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to pass a 1-dimensional numpy array to the predict_fn when making inference for their xgboost model, but is receiving an error that the input numpy.ndarray must be 2 dimensional."
    },
    {
        "Question_id":null,
        "Question_title":"How to import CSV file as a dataset for Azure machine learning",
        "Question_body":"I need to import CSV files as a dataset for my Azure machine learning experiment but I will get an error in execution, kindly provide me with the correct steps.\nThe aim of the experiment is to generate a demand forecast in MS D365 F&O based on the historical data provided in the CSV files.",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_creation_time":1615376822993,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/307727\/how-to-import-csv-file-as-a-dataset-for-azure-mach.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-11T07:27:22.347Z",
                "Answer_score":1,
                "Answer_body":"Hi @AbdelrahmanMorsy-9613\nThank you for posting in Q & A.\n\nAzure ML Studio Classic import data\nImport your training data into Azure Machine Learning Studio (classic) from various data sources\n\nAzure ML Designer import data\nImport data into Azure Machine Learning designer\n\n\n\n\nPlease don\u2019t forget to Accept the answer and up-vote wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-11T17:58:47.43Z",
                "Answer_score":0,
                "Answer_body":"The Azure AI gallery is a great resource to view sample experiments. Here's a forecasting model for Dynamics 365 example. Regarding the error, please follow-up on this thread. Thanks!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to import csv file as a dataset for ; content:i need to import csv files as a dataset for my  experiment but i will get an error in execution, kindly provide me with the correct steps.\nthe aim of the experiment is to generate a demand forecast in ms d365 f&o based on the historical data provided in the csv files.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to import CSV files as a dataset for their experiment in order to generate a demand forecast in MS D365 F&O based on the historical data provided."
    },
    {
        "Question_id":41010551.0,
        "Question_title":"predicting the possibility of Active members becoming Inactive?",
        "Question_body":"<p>I have a database of members, some are active and some are inactive. <\/p>\n\n<p>I want to predict the possibility of Active members becoming Inactive?<\/p>\n\n<p>Should I run the AML on the inactive members (no splitting) and when I publish the model i pass in the active members?<\/p>\n\n<p>I have tried many AML datasets before however usually you will have a column that contains the values you want to predict (Active-Inactive) (True-False) (Red-Black-White) but i never tried having only one value to trina your model with.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1481090961200,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "machine-learning",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":83.0,
        "Owner_creation_time":1481090553287,
        "Owner_last_access_time":1580718354212,
        "Owner_reputation":15.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":4.0,
        "Answer_body":"<p>you will need to train your model with both active and inactive members.  I would split your dataset so there are examples of active and inactive members in both your training and your test set.  <\/p>\n\n<p>Let's discuss why we split the data.  Remember that with supervised learning, you need data with labeled examples.  For example, let\u2019s say I want to predict how much a house will cost based on its square footage and zip code.  To train my model, I need a dataset of existing houses with their square footage, zip codes, and prices, like this:<\/p>\n\n<p>SquareFootage ZipCode Price <br\/>\n2000          48075   200,000 <br\/>\n3000 48075 300,000 <br\/>\n4000 48075 400,000 <br\/>\n5000 48075 500,000 <br\/><\/p>\n\n<p>In this example, square footage and zip code are my features (things that influence the thing you want to predict) and price is my label (the thing that you want to predict).  I could train a model on some data like the above, and then use the trained model to predict prices, given only a square footage and zip code.  <\/p>\n\n<p>So, the reason I split the data is to provide most of the data to train the model (it will process the data to figure out correlations between the features and labels in the \u201ctrain model\u201d module), but we want to hold back some of that labeled data to test the model that we built.  Then, we can compare the price value that the trained model generates against the actual labeled price value in the test dataset (in the \u201cscore model\u201d module) to see how well the model is performing.  (We can\u2019t use the same data for both...the model is built using the training data, so it will perform pretty accurately with that; we hold back unused data to test.)  <\/p>\n\n<p>So, for your example, I would try a random split so there are examples of both active and inactive members (that is your label - inactive or active) and you will also need to provide relevant features that influence activity.  <\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1481093602247,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1481093503168,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41010551",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: predicting the possibility of active members becoming inactive?; content:<p>i have a database of members, some are active and some are inactive. <\/p>\n\n<p>i want to predict the possibility of active members becoming inactive?<\/p>\n\n<p>should i run the aml on the inactive members (no splitting) and when i publish the model i pass in the active members?<\/p>\n\n<p>i have tried many aml datasets before however usually you will have a column that contains the values you want to predict (active-inactive) (true-false) (red-black-white) but i never tried having only one value to trina your model with.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to predict the possibility of active members becoming inactive and is wondering if they should run the AML on the inactive members without splitting and pass in the active members when publishing the model. They have tried many AML datasets before, but never with only one value to train the model with."
    },
    {
        "Question_id":69117885.0,
        "Question_title":"Sending http request Google Vertex AI end point",
        "Question_body":"<p>I've just deployed an ML model on Google vertex AI, it can make predictions using vertex AI web interface. But is it possible to send a request from a browser, for example, to this deployed model. Something like<\/p>\n<pre><code>http:\/\/myapp.cloud.google.com\/input=&quot;features of an example&quot; \n<\/code><\/pre>\n<p>and get the prediction as output.\nThanks<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1631189210517,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":929.0,
        "Owner_creation_time":1377724133300,
        "Owner_last_access_time":1664050723383,
        "Owner_reputation":349.0,
        "Owner_up_votes":12.0,
        "Owner_down_votes":0.0,
        "Owner_views":47.0,
        "Answer_body":"<p>Yes, you can send using endpoint URL as.<\/p>\n<pre><code>https:\/\/us-central1-aiplatform.googleapis.com\/v1beta1\/projects\/&lt;PROJECT_ID&gt;\/locations\/us-central1\/endpoints\/&lt;ENDPOINT_ID&gt;:predict\n<\/code><\/pre>\n<p>Data should be given as in POST parameter.<\/p>\n<pre><code>{\n  &quot;instances&quot;: \n    [1.4838871833555929,\n 1.8659883497083019,\n 2.234620276849616,\n 1.0187816540094903,\n -2.530890710602246,\n -1.6046416850441676,\n -0.4651483719733302,\n -0.4952254087173721,\n 0.774676376873553]\n}\n<\/code><\/pre>\n<p>URL should be Region Based.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1631252937240,
        "Answer_score":4.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":1631432417907,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69117885",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: sending http request google  end point; content:<p>i've just deployed an ml model on google , it can make predictions using  web interface. but is it possible to send a request from a browser, for example, to this deployed model. something like<\/p>\n<pre><code>http:\/\/myapp.cloud.google.com\/input=&quot;features of an example&quot; \n<\/code><\/pre>\n<p>and get the prediction as output.\nthanks<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to send an HTTP request to a deployed ML model on Google and receive a prediction as output."
    },
    {
        "Question_id":null,
        "Question_title":"No such file or directory: '\/opt\/ml\/input\/data\/test\/revenue_train.csv' Sagemaker [SM_CHANNEL_TRAIN]",
        "Question_body":"I am trying to deploy my RandomForestClassifier on Amazon Sagemaker using Python SDK. I have been following this example https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/main\/sagemaker-script-mode\/sagemaker-script-mode.ipynb but keep getting an error that the train file was not found. I think the file were not uploaded to the correct channel. When I run the script as follows it works fine.\n\n! python script_rf.py --model-dir .\/ \\\n                   --train .\/ \\\n                   --test .\/ \\\n\n\nThis is my script code:\n\n# inference functions ---------------\ndef model_fn(model_dir):\n    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n    return clf\n\nif __name__ =='__main__':\n\n    print('extracting arguments')\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--max_depth', type=int, default=2)\n    parser.add_argument('--n_estimators', type=int, default=100)\n    parser.add_argument('--random_state', type=int, default=0)\n    \n\n    # Data, model, and output directories\n    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n    parser.add_argument('--train-file', type=str, default='revenue_train.csv')\n    parser.add_argument('--test-file', type=str, default='revenue_test.csv')\n    \n    args, _ = parser.parse_known_args()\n    \n    print('reading data')\n    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n    \n    if len(train_df) == 0:\n        raise ValueError(('There are no files in {}.\\n').format(args.train, \"train\"))\n\n    print('building training and testing datasets')\n    attributes = ['available_minutes_100','ampido_slots_amount','ampido_slots_amount_100','ampido_slots_amount_200','ampido_slots_amount_300','min_dist_loc','count_event','min_dist_phouses','count_phouses','min_dist_stops','count_stops','min_dist_tickets','count_tickets','min_dist_google','min_dist_psa','count_psa']\n    X_train = train_df[attributes]\n    X_test = test_df[attributes]\n    y_train = train_df['target']\n    y_test = test_df['target']\n    \n    # train\n    print('training model')\n    model = RandomForestClassifier(\n        max_depth =args.max_depth, n_estimators = args.n_estimators)\n    \n    model.fit(X_train, y_train)\n     \n    # persist model\n    path = os.path.join(args.model_dir, \"model_rf.joblib\")\n    joblib.dump(model, path)\n    print('model persisted at ' + path)\n    \n    # print accuracy and confusion matrix \n    print('validating model')\n    y_pred=model.predict(X_test) \n    print('Confusion Matrix:')\n    result = confusion_matrix(y_test, y_pred)\n    print(result)\n    print('Accuracy:')\n    result2 = accuracy_score(y_test, y_pred)\n    print(result2)\n\n\nthe error is raised in the train_df line of the script (FileNotFoundError: [Errno 2] No such file or directory: '\/opt\/ml\/input\/data\/test\/revenue_train.csv').\n\nI tried specifying the input parameters:\n\n# change channel input dirs \ninputs = {\n    \"train\": \"ampido-exports\/production\/revenue_train\",\n    \"test\": \"ampido-exports\/production\/revenue_test\",\n}\nfrom sagemaker.sklearn.estimator import SKLearn\nenable_local_mode_training = False\n\n\nhyperparameters = {\"max_depth\": 2, 'random_state':0, \"n_estimators\": 100}\n\nif enable_local_mode_training:\n    train_instance_type = \"local\"\n    inputs = {\"train\": trainpath, \"test\": testpath}\n\nelse:\n    train_instance_type = \"ml.c5.xlarge\"\n    inputs = {\"train\": trainpath, \"test\": testpath}\n\nestimator_parameters = {\n    \"entry_point\": \"script_rf.py\",\n    \"framework_version\": \"1.0-1\",\n    \"py_version\": \"py3\",\n    \"instance_type\": train_instance_type,\n    \"instance_count\": 1,\n    \"hyperparameters\": hyperparameters,\n    \"role\": role,\n    \"base_job_name\": \"randomforestclassifier-model\",\n    'channel_input_dirs' : inputs\n}\n\nestimator = SKLearn(**estimator_parameters)\nestimator.fit(inputs)\n\n\nbut i still get the error FileNotFoundError: [Errno 2] No such file or directory: '\/opt\/ml\/input\/data\/test\/revenue_train.csv",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1661681019239,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Machine Learning & AI",
            "Amazon SageMaker Model Training",
            "Amazon SageMaker Model Building",
            "Amazon SageMaker Deployment"
        ],
        "Question_view_count":54.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUBY-fIUMuRDqwBmObCn8GqQ\/no-such-file-or-directory-opt-ml-input-data-test-revenue-train-csv-sagemaker-sm-channel-train",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-29T07:18:21.655Z",
                "Answer_score":1,
                "Answer_body":"Your code has a typo that results in the issue, maybe caused by copy-pasting. Note that instead of a training path you're passing a test path location as the default to args.train:\n\n    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n                           ^^^^^                                                ^^^^\n    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n\n\nLater, when you try to access the training file from the test location, the file is obviously not there:\n\nNo such file or directory: '\/opt\/ml\/input\/data\/test\/revenue_train.csv\n                                               ^^^^         ^^^^^\n\n\nChanging the default argument for the args.train to SM_CHANNEL_TRAIN should resolve the issue,",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: no such file or directory: '\/opt\/ml\/input\/data\/test\/revenue_train.csv'  [sm_channel_train]; content:i am trying to deploy my randomforestclassifier on  using python sdk. i have been following this example https:\/\/github.com\/aws\/amazon--examples\/blob\/main\/-script-mode\/-script-mode.ipynb but keep getting an error that the train file was not found. i think the file were not uploaded to the correct channel. when i run the script as follows it works fine.\n\n! python script_rf.py --model-dir .\/ \\\n                   --train .\/ \\\n                   --test .\/ \\\n\n\nthis is my script code:\n\n# inference functions ---------------\ndef model_fn(model_dir):\n    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n    return clf\n\nif __name__ =='__main__':\n\n    print('extracting arguments')\n    parser = argparse.argumentparser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument('--max_depth', type=int, default=2)\n    parser.add_argument('--n_estimators', type=int, default=100)\n    parser.add_argument('--random_state', type=int, default=0)\n    \n\n    # data, model, and output directories\n    parser.add_argument('--model-dir', type=str, default=os.environ.get('sm_model_dir'))\n    parser.add_argument('--train', type=str, default=os.environ.get('sm_channel_test'))\n    parser.add_argument('--test', type=str, default=os.environ.get('sm_channel_test'))\n    parser.add_argument('--train-file', type=str, default='revenue_train.csv')\n    parser.add_argument('--test-file', type=str, default='revenue_test.csv')\n    \n    args, _ = parser.parse_known_args()\n    \n    print('reading data')\n    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n    \n    if len(train_df) == 0:\n        raise valueerror(('there are no files in {}.\\n').format(args.train, \"train\"))\n\n    print('building training and testing datasets')\n    attributes = ['available_minutes_100','ampido_slots_amount','ampido_slots_amount_100','ampido_slots_amount_200','ampido_slots_amount_300','min_dist_loc','count_event','min_dist_phouses','count_phouses','min_dist_stops','count_stops','min_dist_tickets','count_tickets','min_dist_google','min_dist_psa','count_psa']\n    x_train = train_df[attributes]\n    x_test = test_df[attributes]\n    y_train = train_df['target']\n    y_test = test_df['target']\n    \n    # train\n    print('training model')\n    model = randomforestclassifier(\n        max_depth =args.max_depth, n_estimators = args.n_estimators)\n    \n    model.fit(x_train, y_train)\n     \n    # persist model\n    path = os.path.join(args.model_dir, \"model_rf.joblib\")\n    joblib.dump(model, path)\n    print('model persisted at ' + path)\n    \n    # print accuracy and confusion matrix \n    print('validating model')\n    y_pred=model.predict(x_test) \n    print('confusion matrix:')\n    result = confusion_matrix(y_test, y_pred)\n    print(result)\n    print('accuracy:')\n    result2 = accuracy_score(y_test, y_pred)\n    print(result2)\n\n\nthe error is raised in the train_df line of the script (filenotfounderror: [errno 2] no such file or directory: '\/opt\/ml\/input\/data\/test\/revenue_train.csv').\n\ni tried specifying the input parameters:\n\n# change channel input dirs \ninputs = {\n    \"train\": \"ampido-exports\/production\/revenue_train\",\n    \"test\": \"ampido-exports\/production\/revenue_test\",\n}\nfrom .sklearn.estimator import sklearn\nenable_local_mode_training = false\n\n\nhyperparameters = {\"max_depth\": 2, 'random_state':0, \"n_estimators\": 100}\n\nif enable_local_mode_training:\n    train_instance_type = \"local\"\n    inputs = {\"train\": trainpath, \"test\": testpath}\n\nelse:\n    train_instance_type = \"ml.c5.xlarge\"\n    inputs = {\"train\": trainpath, \"test\": testpath}\n\nestimator_parameters = {\n    \"entry_point\": \"script_rf.py\",\n    \"framework_version\": \"1.0-1\",\n    \"py_version\": \"py3\",\n    \"instance_type\": train_instance_type,\n    \"instance_count\": 1,\n    \"hyperparameters\": hyperparameters,\n    \"role\": role,\n    \"base_job_name\": \"randomforestclassifier-model\",\n    'channel_input_dirs' : inputs\n}\n\nestimator = sklearn(**estimator_parameters)\nestimator.fit(inputs)\n\n\nbut i still get the error filenotfounderror: [errno 2] no such file or directory: '\/opt\/ml\/input\/data\/test\/revenue_train.csv",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error that the train file was not found, likely due to it not being uploaded to the correct channel, and has attempted to specify the input parameters but is still receiving the same error."
    },
    {
        "Question_id":null,
        "Question_title":"\"Failure reason Image size 12704675783 is greater than supported size 10737418240\" when creating serverless endpoint in SageMaker.",
        "Question_body":"How to reproduce the error: We want to run Python Inference in SageMaker. Because our model is pre-trained out side the SageMaker and has some special logic, so we need to create customer image. We see the document https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/prebuilt-containers-extend.html#prebuilt-containers-extend-tutorial We use the 763104351884.dkr.ecr.us-east-1.amazonaws.com\/pytorch-inference:1.11.0-gpu-py38-cu113-ubuntu20.04-sagemaker to be the base image. We wrote a dockerfile and use \"docker build\" to create a new image. Also, use \"docker push\" to push new image to Amazon ECR. We pushed it to 935877503070.dkr.ecr.us-east-1.amazonaws.com\/pytorch-inference:testaisage Then, we follow the document: https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/serverless-endpoints-create.html Then, we went to SageMaker console https:\/\/us-east-1.console.aws.amazon.com\/sagemaker\/home?region=us-east-1#\/models We created model. We input the \"935877503070.dkr.ecr.us-east-1.amazonaws.com\/pytorch-inference:testaisage\" of our new image to \"Location of inference code image\". Then, we create Endpoint configuration. Then, we create Endpoint. But the Endpoint shows \"Failure reason Image size 12704675783 is greater than supported size 10737418240\".",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1657243407002,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Serverless",
            "Amazon SageMaker",
            "Machine Learning & AI",
            "Containers"
        ],
        "Question_view_count":220.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU90699ONgQD2t2HUKzm9AUA\/failure-reason-image-size-12704675783-is-greater-than-supported-size-10737418240-when-creating-serverless-endpoint-in-sage-maker",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Serverless",
            "Machine Learning & AI",
            "Containers"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-08T09:20:53.961Z",
                "Answer_score":1,
                "Answer_body":"As you're seeing in the error message, SageMaker Serverless Inference imposes a limit of 10GiB (10737418240 bytes) on your deployed container size - which helps deliver quality of service for considerations like cold-start time. From a quick look I didn't see this mentioned in the SageMaker serverless docs, but as mentioned in the launch blog post, SageMaker Serverless is backed by AWS Lambda and the AWS Lambda quotas page lists the limit.\n\nSo to solve the issue (and still use SageMaker Serverless Inference), you'll need to look at optimizing that container image size by removing any unnecessary bloat (need to find almost 2GiB from the number you posted).\n\nSome suggestions on that:\n\nAre you currently building your actual model in to the image itself? The typical pattern on SageMaker is to host a model.tar.gz tarball on S3, which gets downloaded and extracted into your container at runtime. For large language models and similar, this can be a big size saving (although of course, optimizing overall S3+image size can still help give you the best start-up times). The contents of this file are flexible so you could offload multiple artifacts.\nI saw you're using the standard PyTorch DLC as a base... Are you replacing the entire serving stack, or slotting your custom logic into the one the DLC provides? The stack already provided in the PyTorch container already provides (see docs here) customization to model loading via model_fn, input de-serialization via input_fn, output serialization via output_fn, and actual prediction via predict_fn. The APIs between these user-defined functions are very flexible (for example can return pretty much whatever you like from model_fn, so long as predict_fn knows how to use it) - so I find in practice that it can support even complex requirements like custom request formats, pipelining multiple models together, advanced pre-processing, etc. I've seen some customers go straight to building custom serving stacks (and installing their dependencies alongside the existing e.g. TorchServe in the image) before realising that the pre-built could already support what they needed. Again, this inference.py script would live in your model.tar.gz.\nGeneral non-SageMaker-specific container image optimization guidelines would still apply: Like for e.g. you might see the AWS DLCs clearing apt caches in the same RUN command as performing apt installs. If you find yourself really struggling with the size of the base AWS DLC you could look in to building from scratch \/ another base, and installing everything you need... But of course, would need to do the due diligence to check you're including everything you need & it's optimized well.",
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-07-08T09:18:11.681Z",
                "Answer_score":0,
                "Answer_body":"You need a smaller container image. Also, take into consideration that at the moment SageMaker serverless endpoints do not support GPU acceleration (see https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/serverless-endpoints.html#serverless-endpoints-how-it-works-exclusions).",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: \"failure reason image size 12704675783 is greater than supported size 10737418240\" when creating serverless endpoint in .; content:how to reproduce the error: we want to run python inference in . because our model is pre-trained out side the  and has some special logic, so we need to create customer image. we see the document https:\/\/docs.aws.amazon.com\/\/latest\/dg\/prebuilt-containers-extend.html#prebuilt-containers-extend-tutorial we use the 763104351884.dkr.ecr.us-east-1.amazonaws.com\/pytorch-inference:1.11.0-gpu-py38-cu113-ubuntu20.04- to be the base image. we wrote a dockerfile and use \"docker build\" to create a new image. also, use \"docker push\" to push new image to amazon ecr. we pushed it to 935877503070.dkr.ecr.us-east-1.amazonaws.com\/pytorch-inference:testaisage then, we follow the document: https:\/\/docs.aws.amazon.com\/\/latest\/dg\/serverless-endpoints-create.html then, we went to  console https:\/\/us-east-1.console.aws.amazon.com\/\/home?region=us-east-1#\/models we created model. we input the \"935877503070.dkr.ecr.us-east-1.amazonaws.com\/pytorch-inference:testaisage\" of our new image to \"location of inference code image\". then, we create endpoint configuration. then, we create endpoint. but the endpoint shows \"failure reason image size 12704675783 is greater than supported size 10737418240\".",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user encountered an error when creating a serverless endpoint in AWS due to the size of the image being greater than the supported size."
    },
    {
        "Question_id":67495547.0,
        "Question_title":"wandb logging PermissionError and OSError",
        "Question_body":"<p>Description:<\/p>\n<ul>\n<li><p>When running experiments using <code>Weights and Biases<\/code> (wandb), I\noccasionally get a <code>PermissionError<\/code> for Python's <code>logging<\/code> library\nand <code>OSError<\/code> for accessing the TLS CA cert.<\/p>\n<\/li>\n<li><p>I had the following stacktrace, repeated many times with different\ntypes of &quot;message&quot;. I can't discern the order of operations, but I'm\nguessing the cert can't be accessed and that causes the script to\ncrash, but I don't know why it only happens sometimes.<\/p>\n<\/li>\n<li><p>If it is relevant, I ran the experiments on an Ubuntu server, authenticated via Kerberos.<\/p>\n<\/li>\n<\/ul>\n<p>What I've tried:<\/p>\n<ul>\n<li>I have manually checked the CA cert, and more than half the time I can successfully run experiments. As such I don't think it's the same as <a href=\"https:\/\/stackoverflow.com\/questions\/49100986\/certbot-could-not-find-a-suitable-tls-ca-certificate-bundle-archlinux\">this<\/a> or <a href=\"https:\/\/stackoverflow.com\/questions\/46119901\/python-requests-cant-find-a-folder-with-a-certificate-when-converted-to-exe\">this<\/a>.<\/li>\n<\/ul>\n<p>Stacktrace<\/p>\n<pre><code>Message: 'handle_request: stop_status'                                                                                                                                      [854\/1967]Arguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/logging\/__init__.py&quot;, line 1085, in emit\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/logging\/__init__.py&quot;, line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/threading.py&quot;, line 890, in _bootstrap\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/threading.py&quot;, line 932, in _bootstrap_inner\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py&quot;, line 54, in run\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_util.py&quot;, line 95, in _run\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal.py&quot;, line 280, in _process\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py&quot;, line 175, in send\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/sender.py&quot;, line 183, in send_request\nMessage: 'send_request: stop_status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/apis\/normalize.py&quot;, line 24, in wrapper\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py&quot;, line 681, in check_stop_requested\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/lib\/retry.py&quot;, line 102, in __call__\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/sdk\/internal\/internal_api.py&quot;, line 127, in execute\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py&quot;, line 52, in execute\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/client.py&quot;, line 60, in _get_result\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/wandb\/vendor\/gql-0.2.0\/gql\/transport\/requests.py&quot;, line 38, in execute\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/api.py&quot;, line 119, in post\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/api.py&quot;, line 61, in request\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/sessions.py&quot;, line 530, in request\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/sessions.py&quot;, line 643, in send\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/adapters.py&quot;, line 416, in send\n  File &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/adapters.py&quot;, line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: \/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_creation_time":1620775947520,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python-requests",
            "ssl-certificate",
            "kerberos",
            "wandb"
        ],
        "Question_view_count":468.0,
        "Owner_creation_time":1519031032163,
        "Owner_last_access_time":1663673544740,
        "Owner_reputation":496.0,
        "Owner_up_votes":47.0,
        "Owner_down_votes":5.0,
        "Owner_views":16.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67495547",
        "Tool":"Weights & Biases",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  logging permissionerror and oserror; content:<p>description:<\/p>\n<ul>\n<li><p>when running experiments using <code><\/code> (), i\noccasionally get a <code>permissionerror<\/code> for python's <code>logging<\/code> library\nand <code>oserror<\/code> for accessing the tls ca cert.<\/p>\n<\/li>\n<li><p>i had the following stacktrace, repeated many times with different\ntypes of &quot;message&quot;. i can't discern the order of operations, but i'm\nguessing the cert can't be accessed and that causes the script to\ncrash, but i don't know why it only happens sometimes.<\/p>\n<\/li>\n<li><p>if it is relevant, i ran the experiments on an ubuntu server, authenticated via kerberos.<\/p>\n<\/li>\n<\/ul>\n<p>what i've tried:<\/p>\n<ul>\n<li>i have manually checked the ca cert, and more than half the time i can successfully run experiments. as such i don't think it's the same as <a href=\"https:\/\/stackoverflow.com\/questions\/49100986\/certbot-could-not-find-a-suitable-tls-ca-certificate-bundle-archlinux\">this<\/a> or <a href=\"https:\/\/stackoverflow.com\/questions\/46119901\/python-requests-cant-find-a-folder-with-a-certificate-when-converted-to-exe\">this<\/a>.<\/li>\n<\/ul>\n<p>stacktrace<\/p>\n<pre><code>message: 'handle_request: stop_status'                                                                                                                                      [854\/1967]arguments: ()\n--- logging error ---\ntraceback (most recent call last):\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/logging\/__init__.py&quot;, line 1085, in emit\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/logging\/__init__.py&quot;, line 1065, in flush\npermissionerror: [errno 13] permission denied\ncall stack:\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/threading.py&quot;, line 890, in _bootstrap\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/threading.py&quot;, line 932, in _bootstrap_inner\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/sdk\/internal\/internal_util.py&quot;, line 54, in run\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/sdk\/internal\/internal_util.py&quot;, line 95, in _run\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/sdk\/internal\/internal.py&quot;, line 280, in _process\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/sdk\/internal\/sender.py&quot;, line 175, in send\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/sdk\/internal\/sender.py&quot;, line 183, in send_request\nmessage: 'send_request: stop_status'\narguments: ()\n--- logging error ---\ntraceback (most recent call last):\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/apis\/normalize.py&quot;, line 24, in wrapper\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/sdk\/internal\/internal_api.py&quot;, line 681, in check_stop_requested\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/sdk\/lib\/retry.py&quot;, line 102, in __call__\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/sdk\/internal\/internal_api.py&quot;, line 127, in execute\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/vendor\/gql-0.2.0\/gql\/client.py&quot;, line 52, in execute\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/vendor\/gql-0.2.0\/gql\/client.py&quot;, line 60, in _get_result\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/\/vendor\/gql-0.2.0\/gql\/transport\/requests.py&quot;, line 38, in execute\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/api.py&quot;, line 119, in post\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/api.py&quot;, line 61, in request\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/sessions.py&quot;, line 530, in request\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/sessions.py&quot;, line 643, in send\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/adapters.py&quot;, line 416, in send\n  file &quot;\/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/requests\/adapters.py&quot;, line 227, in cert_verify\noserror: could not find a suitable tls ca certificate bundle, invalid path: \/home\/some_user\/miniconda3\/envs\/part_ii_dev-conda\/lib\/python3.8\/site-packages\/certifi\/cacert.pem\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing a PermissionError for Python's logging library and an OSError for accessing the TLS CA cert when running experiments using a certain code, and has tried manually checking the CA cert with mixed results."
    },
    {
        "Question_id":59826799.0,
        "Question_title":"Unable to download artifacts from FTP server using MLFLOW",
        "Question_body":"<p>I'm not able to load my sklearn model using <code>mlflow.sklearn.load_model<\/code>. Internally, <code>mlflow<\/code> uses the function <code>_download_artifact_from_uri<\/code> from the module <code>mlflow.tracking.artifact_utils<\/code>.<\/p>\n\n<p>If I try, to download an entire artifact folder I receive the following error message: <code>PermissionError: [Errno 13] Permission denied: '\/0'<\/code>. <\/p>\n\n<p>If I try to retrieve a single file from an artifact folder I do not get the error message, and I'm able to create a folder using the <code>os<\/code> module. <\/p>\n\n<p>The following is the converted jupyter notebook I've used.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import os\n\nimport mlflow\nfrom mlflow.tracking.artifact_utils import _download_artifact_from_uri\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.set_tracking_uri(\"file:mlruns\")\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>artifact_uri = 'ftp:\/\/user:pass@ftp\/0\/69a874f1f8a6474cae6bca5b3b5f9ffc\/artifacts'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>model_uri = 'ftp:\/\/user:pass@ftp\/0\/25f46678f1d44842910f185672ca852c\/artifacts\/linear model\/model\/MLmodel'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>_download_artifact_from_uri(artifact_uri, \".\/mlruns\")\n<\/code><\/pre>\n\n<pre><code>---------------------------------------------------------------------------\n\nPermissionError                           Traceback (most recent call last)\n\n&lt;ipython-input-14-834201128eef&gt; in &lt;module&gt;\n----&gt; 1 _download_artifact_from_uri(artifact_uri, \".\/mlruns\")\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/artifact_utils.py in _download_artifact_from_uri(artifact_uri, output_path)\n     73 \n     74     return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\n---&gt; 75         artifact_path=artifact_path, dst_path=output_path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_artifacts(self, artifact_path, dst_path)\n    135         # Check if the artifacts points to a directory\n    136         if self._is_directory(artifact_path):\n--&gt; 137             return download_artifact_dir(artifact_path)\n    138         else:\n    139             return download_file(artifact_path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    116                 for file_info in dir_content:\n    117                     if file_info.is_dir:\n--&gt; 118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n    120                         download_file(file_info.path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    116                 for file_info in dir_content:\n    117                     if file_info.is_dir:\n--&gt; 118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n    120                         download_file(file_info.path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n--&gt; 120                         download_file(file_info.path)\n    121             return local_dir\n    122         if not os.path.exists(dst_path):\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_file(fullpath)\n    101             local_file_path = os.path.join(dst_path, fullpath)\n    102             if not os.path.exists(local_dir_path):\n--&gt; 103                 os.makedirs(local_dir_path)\n    104             self._download_file(remote_file_path=fullpath, local_path=local_file_path)\n    105             return local_file_path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except FileExistsError:\n    213             # Defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except FileExistsError:\n    213             # Defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except FileExistsError:\n    213             # Defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except FileExistsError:\n    213             # Defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    219             return\n    220     try:\n--&gt; 221         mkdir(name, mode)\n    222     except OSError:\n    223         # Cannot rely on checking for EEXIST, since the operating system\n\n\nPermissionError: [Errno 13] Permission denied: '\/0'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>_download_artifact_from_uri(model_uri, \".\/mlruns\")\n<\/code><\/pre>\n\n<pre><code>'\/home\/jovyan\/notebooks\/mlruns\/MLmodel'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>os.mkdir(\"mlruns\/0\")\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1579535536323,
        "Question_favorite_count":1.0,
        "Question_score":4.0,
        "Question_tags":[
            "python",
            "scikit-learn",
            "mlflow"
        ],
        "Question_view_count":1099.0,
        "Owner_creation_time":1579535098392,
        "Owner_last_access_time":1645077386408,
        "Owner_reputation":41.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Copenhagen, Denmark",
        "Question_last_edit_time":1593685255692,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59826799",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: unable to download artifacts from ftp server using ; content:<p>i'm not able to load my sklearn model using <code>.sklearn.load_model<\/code>. internally, <code><\/code> uses the function <code>_download_artifact_from_uri<\/code> from the module <code>.tracking.artifact_utils<\/code>.<\/p>\n\n<p>if i try, to download an entire artifact folder i receive the following error message: <code>permissionerror: [errno 13] permission denied: '\/0'<\/code>. <\/p>\n\n<p>if i try to retrieve a single file from an artifact folder i do not get the error message, and i'm able to create a folder using the <code>os<\/code> module. <\/p>\n\n<p>the following is the converted jupyter notebook i've used.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import os\n\nimport \nfrom .tracking.artifact_utils import _download_artifact_from_uri\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>.set_tracking_uri(\"file:mlruns\")\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>artifact_uri = 'ftp:\/\/user:pass@ftp\/0\/69a874f1f8a6474cae6bca5b3b5f9ffc\/artifacts'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>model_uri = 'ftp:\/\/user:pass@ftp\/0\/25f46678f1d44842910f185672ca852c\/artifacts\/linear model\/model\/mlmodel'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>_download_artifact_from_uri(artifact_uri, \".\/mlruns\")\n<\/code><\/pre>\n\n<pre><code>---------------------------------------------------------------------------\n\npermissionerror                           traceback (most recent call last)\n\n&lt;ipython-input-14-834201128eef&gt; in &lt;module&gt;\n----&gt; 1 _download_artifact_from_uri(artifact_uri, \".\/mlruns\")\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/tracking\/artifact_utils.py in _download_artifact_from_uri(artifact_uri, output_path)\n     73 \n     74     return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\n---&gt; 75         artifact_path=artifact_path, dst_path=output_path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/store\/artifact\/artifact_repo.py in download_artifacts(self, artifact_path, dst_path)\n    135         # check if the artifacts points to a directory\n    136         if self._is_directory(artifact_path):\n--&gt; 137             return download_artifact_dir(artifact_path)\n    138         else:\n    139             return download_file(artifact_path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    116                 for file_info in dir_content:\n    117                     if file_info.is_dir:\n--&gt; 118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n    120                         download_file(file_info.path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    116                 for file_info in dir_content:\n    117                     if file_info.is_dir:\n--&gt; 118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n    120                         download_file(file_info.path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n--&gt; 120                         download_file(file_info.path)\n    121             return local_dir\n    122         if not os.path.exists(dst_path):\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/store\/artifact\/artifact_repo.py in download_file(fullpath)\n    101             local_file_path = os.path.join(dst_path, fullpath)\n    102             if not os.path.exists(local_dir_path):\n--&gt; 103                 os.makedirs(local_dir_path)\n    104             self._download_file(remote_file_path=fullpath, local_path=local_file_path)\n    105             return local_file_path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except fileexistserror:\n    213             # defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except fileexistserror:\n    213             # defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except fileexistserror:\n    213             # defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except fileexistserror:\n    213             # defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    219             return\n    220     try:\n--&gt; 221         mkdir(name, mode)\n    222     except oserror:\n    223         # cannot rely on checking for eexist, since the operating system\n\n\npermissionerror: [errno 13] permission denied: '\/0'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>_download_artifact_from_uri(model_uri, \".\/mlruns\")\n<\/code><\/pre>\n\n<pre><code>'\/home\/jovyan\/notebooks\/mlruns\/mlmodel'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>os.mkdir(\"mlruns\/0\")\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to download artifacts from an FTP server using the function `_download_artifact_from_uri` from the module `.tracking.artifact_utils`, resulting in a permission error when trying to download an entire artifact folder. However, they are able to create a folder using the `os` module."
    },
    {
        "Question_id":null,
        "Question_title":"Duplicating a project?",
        "Question_body":"<p>Hello,<\/p>\n<p>It would be super useful to be able to  duplicate a project, in order to have a \u2018benchmark\/control project\u2019 on top of which I can do experiments.<\/p>\n<p>Is this possible?<\/p>\n<p>Many thanks<br>\nHarry<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1660044236077,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":35.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/duplicating-a-project\/2866",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":6824,
                "name":"Mohammad Bakir",
                "username":"mohammadbakir",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/a9a28c\/{size}.png",
                "created_at":"2022-08-11T07:44:13.449Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/idk\">@idk<\/a>  cloning a project and using it as a template is not possible today. There is a feature request out for this that team is considering.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-08-11T07:44:13.449Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":2,
                "readers_count":1,
                "score":5.4,
                "yours":false,
                "topic_id":2866,
                "topic_slug":"duplicating-a-project",
                "display_username":"Mohammad Bakir",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1458,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7692,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-10-10T07:44:41.541Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":3,
                "post_type":3,
                "updated_at":"2022-10-10T07:44:41.541Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2866,
                "topic_slug":"duplicating-a-project",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: duplicating a project?; content:<p>hello,<\/p>\n<p>it would be super useful to be able to  duplicate a project, in order to have a \u2018benchmark\/control project\u2019 on top of which i can do experiments.<\/p>\n<p>is this possible?<\/p>\n<p>many thanks<br>\nharry<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to duplicate a project in order to have a benchmark\/control project to experiment on."
    },
    {
        "Question_id":49372161.0,
        "Question_title":"AWS SageMaker Very large Dataset",
        "Question_body":"<p>I have a csv file of 500GB and a mysql database of 1.5 TB of data and I want to run aws sagemaker classification and regression algorithm and random forest on it.<\/p>\n\n<p>Can aws sagemaker support it? can model be read and trained in batches or chunks? any example for it<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0.0,
        "Question_creation_time":1521492587020,
        "Question_favorite_count":3.0,
        "Question_score":6.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":7729.0,
        "Owner_creation_time":1363753277816,
        "Owner_last_access_time":1645657051623,
        "Owner_reputation":111.0,
        "Owner_up_votes":53.0,
        "Owner_down_votes":0.0,
        "Owner_views":76.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49372161",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  very large dataset; content:<p>i have a csv file of 500gb and a mysql database of 1.5 tb of data and i want to run  classification and regression algorithm and random forest on it.<\/p>\n\n<p>can  support it? can model be read and trained in batches or chunks? any example for it<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user has a very large dataset of 500GB in a CSV file and 1.5TB in a MySQL database, and wants to run classification, regression, and random forest algorithms on it. They are asking if the system can support it, and if the model can be read and trained in batches or chunks."
    },
    {
        "Question_id":null,
        "Question_title":"[ANNOUNCEMENT] CFP for Data + AI Conference",
        "Question_body":"MLflow users:\n\n\nWe accept CfP on MLflow for this conference: how you use it in production; use MLOps best practices; with popular ML frameworks for experiment tracking; integrations and extensions with MLflow; and the model registry\u00a0for discovering, sharing, and deploying models, etc.\u00a0\n\n\nShare your bright ideas with the larger data community on how MLflow helps you manage your model lifecycle.\n\n\nhttps:\/\/databricks.com\/dataaisummit\/north-america-2021\/call-for-presentations\n\n\n\nCheers\nJules\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nSr. Developer Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1612536907000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":11.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/SrwmTCHd4vw",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: [announcement] cfp for data + ai conference; content: users:\n\n\nwe accept cfp on  for this conference: how you use it in production; use mlops best practices; with popular ml frameworks for experiment tracking; integrations and extensions with ; and the model registry\u00a0for discovering, sharing, and deploying models, etc.\u00a0\n\n\nshare your bright ideas with the larger data community on how  helps you manage your model lifecycle.\n\n\nhttps:\/\/databricks.com\/dataaisummit\/north-america-2021\/call-for-presentations\n\n\n\ncheers\njules\n\n\n\n\n\u2013\u2013\n\nthe best ideas are simple\n\njules s. damji\n\nsr. developer advocate\n\ndatabricks, inc.\n\nju...@databricks.com\n\n(510) 304-7686",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is invited to submit a proposal for the Data + AI Conference, focusing on how they use data in production, MLOps best practices, popular ML frameworks, integrations and extensions, and the Model Registry for discovering, sharing, and deploying models."
    },
    {
        "Question_id":53213596.0,
        "Question_title":"How to execute python from conda environment by dvc run",
        "Question_body":"<p>I have an environment of conda configurated with python 3.6 and dvc is installed there, but when I try to execute dvc run with python, dvc call the python version of main installation of conda and not find the installed libraries.<\/p>\n\n<pre><code>$ conda activate py36\n$ python --version\nPython 3.6.6 :: Anaconda custom (64-bit)\n$ dvc run python --version\nRunning command:\n    python --version\nPython 3.7.0\nSaving information to 'Dvcfile'.\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":3.0,
        "Question_creation_time":1541699972677,
        "Question_favorite_count":1.0,
        "Question_score":6.0,
        "Question_tags":[
            "python",
            "anaconda",
            "conda",
            "dvc"
        ],
        "Question_view_count":351.0,
        "Owner_creation_time":1420765480790,
        "Owner_last_access_time":1663614206112,
        "Owner_reputation":340.0,
        "Owner_up_votes":477.0,
        "Owner_down_votes":2.0,
        "Owner_views":61.0,
        "Answer_body":"<p>The version 0.24.3 of dvc correct this problem.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1549414531500,
        "Answer_score":2.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53213596",
        "Tool":"DVC",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to execute python from conda environment by  run; content:<p>i have an environment of conda configurated with python 3.6 and  is installed there, but when i try to execute  run with python,  call the python version of main installation of conda and not find the installed libraries.<\/p>\n\n<pre><code>$ conda activate py36\n$ python --version\npython 3.6.6 :: anaconda custom (64-bit)\n$  run python --version\nrunning command:\n    python --version\npython 3.7.0\nsaving information to 'file'.\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty executing Python from their Conda environment, as the main installation of Conda is being called instead of the installed libraries."
    },
    {
        "Question_id":null,
        "Question_title":"Defer loading data when cloning repository?",
        "Question_body":"<p>We currently use a single repository for data science related projects (mainly due to limitations of GitHub private repositories). When cloning that repository, all Git LFS files are downloaded, which takes quite a while. Is there a way that using DVC would allow us to defer loading data from some of our data-science sub-projects until we are ready to work on the notebooks?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1526909062879,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":498.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/defer-loading-data-when-cloning-repository\/33",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":53,
                "name":"Dmitry",
                "username":"dmitry",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/dmitry\/{size}\/7_2.png",
                "created_at":"2018-05-22T18:19:42.766Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/brylie\">@brylie<\/a>!<\/p>\n<p>Yes, with DVC it is manageable.<\/p>\n<ol>\n<li>\n<code>dvc pull<\/code> and <code>dvc push<\/code> sync only on the latest data file version a current branch. So, if your project is separated by branches - it will work just fine.<\/li>\n<li>If you have all the projects in the same branch (like <code>master<\/code>) you can sync data files sebset by specifying DVC file: <code>dvc pull pmap_project.dvc<\/code>.<\/li>\n<\/ol>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2018-05-22T18:19:42.766Z",
                "reply_count":0,
                "reply_to_post_number":1,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":10,
                "readers_count":9,
                "score":2.0,
                "yours":false,
                "topic_id":33,
                "topic_slug":"defer-loading-data-when-cloning-repository",
                "display_username":"Dmitry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Regular",
                "title_is_group":false,
                "reply_to_user":{
                    "username":"brylie",
                    "name":"Brylie Christopher Oxley",
                    "avatar_template":"\/user_avatar\/discuss.dvc.org\/brylie\/{size}\/10_2.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":2,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":54,
                "name":"Brylie Christopher Oxley",
                "username":"brylie",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/brylie\/{size}\/10_2.png",
                "created_at":"2018-05-29T08:07:09.404Z",
                "cooked":"<p>Is there an approach that would work when <em>cloning<\/em> the repository?<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2018-05-29T08:07:09.404Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":11,
                "readers_count":10,
                "score":7.2,
                "yours":false,
                "topic_id":33,
                "topic_slug":"defer-loading-data-when-cloning-repository",
                "display_username":"Brylie Christopher Oxley",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":13,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":55,
                "name":"Ruslan Kuprieiev",
                "username":"kupruser",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/e95f7d\/{size}.png",
                "created_at":"2018-05-29T09:47:07.870Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/brylie\">@brylie<\/a>!<\/p>\n<p>When you clone your git repository that uses dvc inside, dvc doesn\u2019t download any data until you manually tell it to by running <code>dvc pull<\/code> command. So basically, cloning would look like:<\/p>\n<ol>\n<li>\n<code>git clone \/path\/to\/remote<\/code> - no different with and without dvc, downloads only code;<\/li>\n<li>\n<code>dvc pull<\/code> or <code>dvc pull mydata.dvc<\/code> - downloads data;<\/li>\n<\/ol>\n<p>Thanks,<br>\nRuslan<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2018-05-29T09:47:07.870Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":9,
                "readers_count":8,
                "score":46.8,
                "yours":false,
                "topic_id":33,
                "topic_slug":"defer-loading-data-when-cloning-repository",
                "display_username":"Ruslan Kuprieiev",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"brylie",
                    "name":"Brylie Christopher Oxley",
                    "avatar_template":"\/user_avatar\/discuss.dvc.org\/brylie\/{size}\/10_2.png"
                },
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":3,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: defer loading data when cloning repository?; content:<p>we currently use a single repository for data science related projects (mainly due to limitations of github private repositories). when cloning that repository, all git lfs files are downloaded, which takes quite a while. is there a way that using  would allow us to defer loading data from some of our data-science sub-projects until we are ready to work on the notebooks?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if there is a way to defer loading data from some of their data-science sub-projects when cloning a repository that contains Git LFS files."
    },
    {
        "Question_id":null,
        "Question_title":"Pytorch sweep help",
        "Question_body":"<p>Hi . I want to do a study in pytorch with wandb sweep. I want to try activation function optimization algorithm and lr value with various combinations. but I have no idea how to do this. I did it with keras but not in pytorch. can you help me<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_creation_time":1641211816566,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":142.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/pytorch-sweep-help\/1669",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":4031,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-01-03T22:06:54.243Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/yasarniyaz\">@yasarniyaz<\/a> ,<\/p>\n<p>We have an example Colab Notebook detailing how to run a sweep in PyTorch. You can access it <a href=\"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/pytorch\/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb\" rel=\"noopener nofollow ugc\">here<\/a>.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-01-03T22:06:54.243Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":6.0,
                "yours":false,
                "topic_id":1669,
                "topic_slug":"pytorch-sweep-help",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/colab.research.google.com\/github\/wandb\/examples\/blob\/master\/colabs\/pytorch\/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb",
                        "internal":false,
                        "reflection":false,
                        "title":"Google Colab",
                        "clicks":2
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4032,
                "name":"Yasar Niyazoglu",
                "username":"yasarniyaz",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/y\/53a042\/{size}.png",
                "created_at":"2022-01-03T22:19:41.346Z",
                "cooked":"<p>thank you my friend. I looked at this resource, but it doesn\u2019t show how to change my activation functions here, and frankly, this resource seems very confusing to me. do you have any other suggestions?<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-01-03T22:19:41.346Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":6.0,
                "yours":false,
                "topic_id":1669,
                "topic_slug":"pytorch-sweep-help",
                "display_username":"Yasar Niyazoglu",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"ramit_goolry",
                    "name":"Ramit Goolry",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":961,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4033,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-01-03T22:24:43.701Z",
                "cooked":"<p>I would say you would have to do some manipulation in your code to get this going. Something like:<\/p>\n<pre><code class=\"lang-auto\">if config.activation == 'relu':\n  self.activation = nn.ReLU\nelif config.activation == 'tanh':\n  self.activation = nn.tanh\n<\/code><\/pre>\n<p>in your <code>__init__<\/code> function. You can then use the <code>self.activation<\/code> object to set up your activations in your model based on the sweep config.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-01-03T22:24:43.701Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":1669,
                "topic_slug":"pytorch-sweep-help",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"yasarniyaz",
                    "name":"Yasar Niyazoglu",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/y\/53a042\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4719,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-03-04T22:24:46.283Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":5,
                "post_type":3,
                "updated_at":"2022-03-04T22:24:46.283Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":1669,
                "topic_slug":"pytorch-sweep-help",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: pytorch sweep help; content:<p>hi . i want to do a study in pytorch with  sweep. i want to try activation function optimization algorithm and lr value with various combinations. but i have no idea how to do this. i did it with keras but not in pytorch. can you help me<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for help with performing a study in PyTorch using a sweep to optimize activation functions and learning rate values."
    },
    {
        "Question_id":null,
        "Question_title":"Question: how to define custom Model in Designer",
        "Question_body":"In Azure ML Designer, I can't figure out how to define a custom Model. The builtin NN Regression module has many bugs (will open a separate issue for those), so I need to make my own custom model. The closest thing I've found so far is Create Python Model, but this has the following limitation:\n\nCan't parametrize model, so doesn't work with Tune Model Hyperparameters module\n\nIs there any way to design my own model, and is it possible to contribute this upstream for others to use?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1594757599337,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46909\/question-how-to-define-custom-model-in-designer.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-16T08:26:49.827Z",
                "Answer_score":0,
                "Answer_body":"@AdamStewart-2203 Yes, I think the current custom python model has a limitation while using it with Tune Model Hyperparameters. Our PG would like to discuss more about the contributions or inputs for this module, Could you please email us at AzCommunity[at]microsoft[dot]com so we can guide you accordingly.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":38.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: question: how to define custom model in designer; content:in  designer, i can't figure out how to define a custom model. the builtin nn regression module has many bugs (will open a separate issue for those), so i need to make my own custom model. the closest thing i've found so far is create python model, but this has the following limitation:\n\ncan't parametrize model, so doesn't work with tune model hyperparameters module\n\nis there any way to design my own model, and is it possible to contribute this upstream for others to use?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to define a custom model in Azure ML Designer and is wondering if it is possible to contribute this upstream for others to use."
    },
    {
        "Question_id":null,
        "Question_title":"list of folder names as input for ParallelRunStep-class",
        "Question_body":"In this example, all data files for the parallel run step are stored in one folder.\n\nI also want to create a parallel run step. The task for each of the several folders, in which the multiple data files are stored, is exactly identical.\n\nThe folders:\n\n\n\n\n\nThe content of each folder:\n\n\n\n\n\nHow should I define the ParallelRunStep-class so that the identical task for each folder (here 'a', 'b', 'c', 'd' and 'e') is executed in parallel?\nTwo folders should run simultaneously in parallel.\n\nMoreover, I would like to ask how to get only the stored folder names or folder paths from a given directory path of a blob storage container.",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1647256395817,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771015\/list-of-folder-names-as-input-for-parallelrunstep.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-21T10:25:43.237Z",
                "Answer_score":1,
                "Answer_body":"@@AlexanderPakakis-0994 Thanks, An Azure ML dataset is just metadata pointing to a path or collection of paths in an Azure storage account. You should first \"merge\" those datasets into a collection of adjacent folders (e.g. root\/dataset1\/, root\/dataset2\/, ...) and then run PRS against root\/**.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: list of folder names as input for parallelrunstep-class; content:in this example, all data files for the parallel run step are stored in one folder.\n\ni also want to create a parallel run step. the task for each of the several folders, in which the multiple data files are stored, is exactly identical.\n\nthe folders:\n\n\n\n\n\nthe content of each folder:\n\n\n\n\n\nhow should i define the parallelrunstep-class so that the identical task for each folder (here 'a', 'b', 'c', 'd' and 'e') is executed in parallel?\ntwo folders should run simultaneously in parallel.\n\nmoreover, i would like to ask how to get only the stored folder names or folder paths from a given directory path of a blob storage container.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to create a parallel run step to execute an identical task for each of several folders containing multiple data files, and wants to know how to define the parallelrunstep-class and get only the stored folder names or folder paths from a given directory path of a blob storage container."
    },
    {
        "Question_id":null,
        "Question_title":"mlflow model artifacts are not getting stored, while running the airflow dag. for that reason unable to fetch experiment details?",
        "Question_body":"import mlflow\n\nfrom mlflow.tracking import MlflowClient\nclient = MlflowClient()\n\n\" training the model and saving the model artificats\"\nmlflow.set_registry_uri('postgresql:\/\/postgres:postgres@localhost\/mlflow')\nmlflow.set_experiment('testing_mlflow_with_airflow')\nwith mlflow.start_run():\n# creating the training dataframe\n\u00a0 \u00a0 train_x = self.train_data[0]\n\u00a0 \u00a0 train_y = self.train_data[1]\n\n\u00a0 \u00a0 # training the given model\n\u00a0 \u00a0 model.fit(train_x, train_y)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\n\u00a0 \u00a0 mlflow.sklearn.log_model(model, \"model\")\n\n\n\n\" getting the experiment details by experiment name\"\nexperiment_id = client.get_experiment_by_name('testing_mlflow_with_airflow').experiment_id\nexperiment_results = mlflow.search_runs(experiment_ids=experiment_id)\n\n\n\nairflow code:\n\n\ntraining = BashOperator(\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 task_id = 'mlflow_training',\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 bash_command='python3 \/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models\/train_mlflow.py',\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 do_xcom_push=False\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0)\n\n\nairflow error :\n\n\n[2022-04-29, 13:01:08 UTC] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'python3 \/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models\/train_mlflow.py']\n[2022-04-29, 13:01:08 UTC] {subprocess.py:85} INFO - Output:\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - WARNING:root:Malformed experiment '2'. Detailed error Yaml file '\/tmp\/airflowtmpzjvuldm6\/mlruns\/2\/meta.yaml' does not exist.\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - Traceback (most recent call last):\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - \u00a0 File \"\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 262, in list_experiments\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - \u00a0 \u00a0 experiment = self._get_experiment(exp_id, view_type)\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - \u00a0 File \"\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 341, in _get_experiment\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - \u00a0 \u00a0 meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - \u00a0 File \"\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/utils\/file_utils.py\", line 179, in read_yaml\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - \u00a0 \u00a0 raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - mlflow.exceptions.MissingConfigException: Yaml file '\/tmp\/airflowtmpzjvuldm6\/mlruns\/2\/meta.yaml' does not exist.\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - priniting the testing data <class 'pandas.core.frame.DataFrame'>\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - priniting the testing data \u00a0 \u00a0fixed_acidity \u00a0volatile_acidity \u00a0citric_acid \u00a0... \u00a0sulphates \u00a0alcohol \u00a0quality\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a07.4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.70 \u00a0 \u00a0 \u00a0 \u00a0 0.00 \u00a0... \u00a0 \u00a0 \u00a0 0.56 \u00a0 \u00a0 \u00a09.4 \u00a0 \u00a0 \u00a0 \u00a05\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - 1 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a07.8 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.88 \u00a0 \u00a0 \u00a0 \u00a0 0.00 \u00a0... \u00a0 \u00a0 \u00a0 0.68 \u00a0 \u00a0 \u00a09.8 \u00a0 \u00a0 \u00a0 \u00a05\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - 2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a07.8 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.76 \u00a0 \u00a0 \u00a0 \u00a0 0.04 \u00a0... \u00a0 \u00a0 \u00a0 0.65 \u00a0 \u00a0 \u00a09.8 \u00a0 \u00a0 \u00a0 \u00a05\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - 3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 11.2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.28 \u00a0 \u00a0 \u00a0 \u00a0 0.56 \u00a0... \u00a0 \u00a0 \u00a0 0.58 \u00a0 \u00a0 \u00a09.8 \u00a0 \u00a0 \u00a0 \u00a06\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO -\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - [4 rows x 12 columns]\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - tracking uri ***ql:\/\/***:***@localhost\/mlflow\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - Traceback (most recent call last):\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - File \"\/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models\/train_mlflow.py\", line 44, in <module>\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - File \"\/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models\/mlflow_class.py\", line 88, in __init__\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - experiment_id = client.get_experiment_by_name('testing_mlflow_with_airflow').experiment_id\n[2022-04-29, 13:01:28 UTC] {subprocess.py:89} INFO - AttributeError: 'NoneType' object has no attribute 'experiment_id'\n[2022-04-29, 13:01:29 UTC] {subprocess.py:93} INFO - Command exited with return code 1\n[2022-04-29, 13:01:29 UTC] {taskinstance.py:1774} ERROR - Task failed with exception\n\nhow i can set a directory where all my experiment runs artifacts will be stored? where the mlflow artifacts are getting stored now? how i can find all runs details by the mlflow client as per the above code?\n\ni have tried with different approaches, None of them is worked\n\nsetting the tracking server as below\nmlflow.set_tracking_uri('postgresql:\/\/postgres:postgres@localhost\/mlflow')\nmlflow.set_tracking_uri('file:\/\/\/tmp\/mlruns')\n\nmlflow.set_tracking_uri('http:\/\/localhost:5000')\n\nmlflow.set_registry_uri('postgresql:\/\/postgres:postgres@localhost\/mlflow')\nmlflow.set_tracking_uri('\/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models')",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1651374349000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":198.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/C4gnXc4WN9A",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  model artifacts are not getting stored, while running the airflow dag. for that reason unable to fetch experiment details?; content:import \n\nfrom .tracking import client\nclient = client()\n\n\" training the model and saving the model artificats\"\n.set_registry_uri('postgresql:\/\/postgres:postgres@localhost\/')\n.set_experiment('testing__with_airflow')\nwith .start_run():\n# creating the training dataframe\n\u00a0 \u00a0 train_x = self.train_data[0]\n\u00a0 \u00a0 train_y = self.train_data[1]\n\n\u00a0 \u00a0 # training the given model\n\u00a0 \u00a0 model.fit(train_x, train_y)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\n\u00a0 \u00a0 .sklearn.log_model(model, \"model\")\n\n\n\n\" getting the experiment details by experiment name\"\nexperiment_id = client.get_experiment_by_name('testing__with_airflow').experiment_id\nexperiment_results = .search_runs(experiment_ids=experiment_id)\n\n\n\nairflow code:\n\n\ntraining = bashoperator(\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 task_id = '_training',\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 bash_command='python3 \/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models\/train_.py',\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 do_xcom_push=false\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0)\n\n\nairflow error :\n\n\n[2022-04-29, 13:01:08 utc] {subprocess.py:74} info - running command: ['bash', '-c', 'python3 \/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models\/train_.py']\n[2022-04-29, 13:01:08 utc] {subprocess.py:85} info - output:\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - warning:root:malformed experiment '2'. detailed error yaml file '\/tmp\/airflowtmpzjvuldm6\/mlruns\/2\/meta.yaml' does not exist.\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - traceback (most recent call last):\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - \u00a0 file \"\/usr\/local\/lib\/python3.8\/dist-packages\/\/store\/tracking\/file_store.py\", line 262, in list_experiments\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - \u00a0 \u00a0 experiment = self._get_experiment(exp_id, view_type)\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - \u00a0 file \"\/usr\/local\/lib\/python3.8\/dist-packages\/\/store\/tracking\/file_store.py\", line 341, in _get_experiment\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - \u00a0 \u00a0 meta = read_yaml(experiment_dir, filestore.meta_data_file_name)\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - \u00a0 file \"\/usr\/local\/lib\/python3.8\/dist-packages\/\/utils\/file_utils.py\", line 179, in read_yaml\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - \u00a0 \u00a0 raise missingconfigexception(\"yaml file '%s' does not exist.\" % file_path)\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - .exceptions.missingconfigexception: yaml file '\/tmp\/airflowtmpzjvuldm6\/mlruns\/2\/meta.yaml' does not exist.\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - priniting the testing data <class 'pandas.core.frame.dataframe'>\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - priniting the testing data \u00a0 \u00a0fixed_acidity \u00a0volatile_acidity \u00a0citric_acid \u00a0... \u00a0sulphates \u00a0alcohol \u00a0quality\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a07.4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.70 \u00a0 \u00a0 \u00a0 \u00a0 0.00 \u00a0... \u00a0 \u00a0 \u00a0 0.56 \u00a0 \u00a0 \u00a09.4 \u00a0 \u00a0 \u00a0 \u00a05\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - 1 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a07.8 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.88 \u00a0 \u00a0 \u00a0 \u00a0 0.00 \u00a0... \u00a0 \u00a0 \u00a0 0.68 \u00a0 \u00a0 \u00a09.8 \u00a0 \u00a0 \u00a0 \u00a05\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - 2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a07.8 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.76 \u00a0 \u00a0 \u00a0 \u00a0 0.04 \u00a0... \u00a0 \u00a0 \u00a0 0.65 \u00a0 \u00a0 \u00a09.8 \u00a0 \u00a0 \u00a0 \u00a05\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - 3 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 11.2 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a00.28 \u00a0 \u00a0 \u00a0 \u00a0 0.56 \u00a0... \u00a0 \u00a0 \u00a0 0.58 \u00a0 \u00a0 \u00a09.8 \u00a0 \u00a0 \u00a0 \u00a06\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info -\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - [4 rows x 12 columns]\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - tracking uri ***ql:\/\/***:***@localhost\/\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - traceback (most recent call last):\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - file \"\/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models\/train_.py\", line 44, in <module>\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - file \"\/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models\/_class.py\", line 88, in __init__\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - experiment_id = client.get_experiment_by_name('testing__with_airflow').experiment_id\n[2022-04-29, 13:01:28 utc] {subprocess.py:89} info - attributeerror: 'nonetype' object has no attribute 'experiment_id'\n[2022-04-29, 13:01:29 utc] {subprocess.py:93} info - command exited with return code 1\n[2022-04-29, 13:01:29 utc] {taskinstance.py:1774} error - task failed with exception\n\nhow i can set a directory where all my experiment runs artifacts will be stored? where the  artifacts are getting stored now? how i can find all runs details by the  client as per the above code?\n\ni have tried with different approaches, none of them is worked\n\nsetting the tracking server as below\n.set_tracking_uri('postgresql:\/\/postgres:postgres@localhost\/')\n.set_tracking_uri('file:\/\/\/tmp\/mlruns')\n\n.set_tracking_uri('http:\/\/localhost:5000')\n\n.set_registry_uri('postgresql:\/\/postgres:postgres@localhost\/')\n.set_tracking_uri('\/home\/vasanth\/airflow\/scripts\/mlproject\/src\/models')",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to store model artifacts while running the Airflow DAG, and is unable to fetch experiment details. They have tried different approaches to set the tracking server, but none of them have worked."
    },
    {
        "Question_id":null,
        "Question_title":"Information in tables disappearing",
        "Question_body":"<p>Hello!<\/p>\n<p>I have 39 runs in an experiment, all correctly finished with the corresponding tables per run correctly uploaded and available (when clicking on the specific run).<\/p>\n<p>I have 4 different tables, and combine the runs depending on the table ID (runs .summary[\u201ca\u201d], runs .summary[\u201cb\u201d], \u2026).<\/p>\n<p>2 of the combined tables are correctly outputted, but in 1 of the tables there is half the data available, and in the other a message of \u201cno rows to display\u201d is shown. If I re-upload the data of the \u201cno rows to display\u201d table, it is shown properly, but another table becomes empty, with the \u201cno rows to display\u201d message.<\/p>\n<p>Probably is due to the amount of rows can be processed at the same time? The total number of rows per run is 42, so 39x42 = 1638, which shouldn\u2019t be that much?<\/p>\n<p>Thank you!<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_creation_time":1649654781916,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":107.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/information-in-tables-disappearing\/2215",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":5187,
                "name":"Nathan Kuneman",
                "username":"nathank",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/n\/7ea924\/{size}.png",
                "created_at":"2022-04-12T13:43:39.133Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/agirbau\">@agirbau<\/a>,<br>\nWould you mind sharing a link to the workspace so I can see what is going on?<\/p>\n<p>If you would rather not share here you can email me at <a href=\"mailto:support@wandb.com\">support@wandb.com<\/a><\/p>\n<p>I don\u2019t think this should be an issue with the number of rows since we support up to 200k rows so I would be interested to see what is going on here.<\/p>\n<p>Thank you,<br>\nNate<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-04-12T13:43:39.133Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":2215,
                "topic_slug":"information-in-tables-disappearing",
                "display_username":"Nathan Kuneman",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1127,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5201,
                "name":"Andreu Girbau",
                "username":"agirbau",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/839c29\/{size}.png",
                "created_at":"2022-04-13T04:29:36.661Z",
                "cooked":"<p>Hello Nate,<\/p>\n<p>I will send you an email with the link. Thanks!<\/p>\n<p>Andreu<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-04-13T04:29:36.661Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":0.8,
                "yours":false,
                "topic_id":2215,
                "topic_slug":"information-in-tables-disappearing",
                "display_username":"Andreu Girbau",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1315,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5480,
                "name":"Nathan Kuneman",
                "username":"nathank",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/n\/7ea924\/{size}.png",
                "created_at":"2022-04-26T22:46:20.173Z",
                "cooked":"<p>Hi Andreu,<br>\nI apologize for the delay on this. Are the panels working how you would expect now or is this still an issue? I see that there is data in all of the panels now.<\/p>\n<p>If not, let me know and I will look into this further.<\/p>\n<p>Thank you,<br>\nNate<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-04-26T22:46:20.173Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":2215,
                "topic_slug":"information-in-tables-disappearing",
                "display_username":"Nathan Kuneman",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1127,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5537,
                "name":"Nathan Kuneman",
                "username":"nathank",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/n\/7ea924\/{size}.png",
                "created_at":"2022-05-02T13:23:10.438Z",
                "cooked":"<p>Hi Andreu, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2022-05-02T13:23:10.438Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":2215,
                "topic_slug":"information-in-tables-disappearing",
                "display_username":"Nathan Kuneman",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1127,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6145,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-06-12T04:29:47.510Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":6,
                "post_type":3,
                "updated_at":"2022-06-12T04:29:47.510Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2215,
                "topic_slug":"information-in-tables-disappearing",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: information in tables disappearing; content:<p>hello!<\/p>\n<p>i have 39 runs in an experiment, all correctly finished with the corresponding tables per run correctly uploaded and available (when clicking on the specific run).<\/p>\n<p>i have 4 different tables, and combine the runs depending on the table id (runs .summary[\u201ca\u201d], runs .summary[\u201cb\u201d], \u2026).<\/p>\n<p>2 of the combined tables are correctly outputted, but in 1 of the tables there is half the data available, and in the other a message of \u201cno rows to display\u201d is shown. if i re-upload the data of the \u201cno rows to display\u201d table, it is shown properly, but another table becomes empty, with the \u201cno rows to display\u201d message.<\/p>\n<p>probably is due to the amount of rows can be processed at the same time? the total number of rows per run is 42, so 39x42 = 1638, which shouldn\u2019t be that much?<\/p>\n<p>thank you!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an issue where information in tables is disappearing, and they believe it may be due to the amount of rows being processed at the same time."
    },
    {
        "Question_id":60344876.0,
        "Question_title":"Importing fbprophet on AWS SageMaker",
        "Question_body":"<p>I am trying to download fbprophet package on AWS SageMaker. On my local device, I was able to do that but couldn't accomplish the same on SageMaker. Thanks to this <a href=\"https:\/\/github.com\/dr-prodigy\/python-holidays\/issues\/277#issuecomment-580740723\" rel=\"nofollow noreferrer\">link<\/a> I updated the hdays.py file's line 16 from:<\/p>\n\n<pre><code>from holidays import WEEKEND, HolidayBase, easter, rd\n<\/code><\/pre>\n\n<p>to:<\/p>\n\n<pre><code>from holidays import WEEKEND, HolidayBase\nfrom dateutil.easter import easter\nfrom dateutil.relativedelta import relativedelta as rd\n<\/code><\/pre>\n\n<p>This solved the error on my local device. Anyone knows how I can download fbprophet on SageMaker or how I can update a downloaded package folder?<\/p>\n\n<p>When I run <code>!pip install fbprophet<\/code> on SageMaker, the following error pops up:<\/p>\n\n<pre><code>Collecting fbprophet\n  Using cached https:\/\/files.pythonhosted.org\/packages\/f7\/86\/4509e952f9724f084625e93e0bf8d8519b25c79029a0a916b0f996644c75\/fbprophet-0.6.tar.gz\nRequirement already satisfied: Cython&gt;=0.22 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.28.4)\nRequirement already satisfied: cmdstanpy==0.4 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.4.0)\nRequirement already satisfied: pystan&gt;=2.14 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (2.19.1.1)\nRequirement already satisfied: numpy&gt;=1.10.0 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (1.16.4)\nRequirement already satisfied: pandas&gt;=0.23.4 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.24.2)\nRequirement already satisfied: matplotlib&gt;=2.0.0 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (3.0.3)\nRequirement already satisfied: LunarCalendar&gt;=0.0.9 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.0.9)\nRequirement already satisfied: convertdate&gt;=2.1.2 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (2.2.0)\nRequirement already satisfied: holidays&gt;=0.9.5 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.10.1)\nRequirement already satisfied: setuptools-git&gt;=1.2 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (1.2)\nRequirement already satisfied: python-dateutil&gt;=2.8.0 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (2.8.1)\nRequirement already satisfied: pytz&gt;=2011k in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from pandas&gt;=0.23.4-&gt;fbprophet) (2018.4)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from matplotlib&gt;=2.0.0-&gt;fbprophet) (2.2.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from matplotlib&gt;=2.0.0-&gt;fbprophet) (1.0.1)\nRequirement already satisfied: cycler&gt;=0.10 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from matplotlib&gt;=2.0.0-&gt;fbprophet) (0.10.0)\nRequirement already satisfied: ephem&gt;=3.7.5.3 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from LunarCalendar&gt;=0.0.9-&gt;fbprophet) (3.7.7.0)\nRequirement already satisfied: pymeeus&lt;=1,&gt;=0.3.6 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from convertdate&gt;=2.1.2-&gt;fbprophet) (0.3.6)\nRequirement already satisfied: six in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from holidays&gt;=0.9.5-&gt;fbprophet) (1.11.0)\nRequirement already satisfied: setuptools in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib&gt;=2.0.0-&gt;fbprophet) (41.6.0)\nBuilding wheels for collected packages: fbprophet\n  Building wheel for fbprophet (setup.py) ... error\n  ERROR: Command errored out with exit status 1:\n   command: \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d \/tmp\/pip-wheel-vtdnatmm --python-tag cp36\n       cwd: \/tmp\/pip-install-n493kv2i\/fbprophet\/\n  Complete output (9 lines):\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build\/lib\n  creating build\/lib\/fbprophet\n  creating build\/lib\/fbprophet\/stan_model\n  INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_888a84912910fa0a45b9d614b75bb8a8 NOW.\n  error: command 'gcc' failed with exit status 1\n  ----------------------------------------\n  ERROR: Failed building wheel for fbprophet\n  Running setup.py clean for fbprophet\nFailed to build fbprophet\nInstalling collected packages: fbprophet\n    Running setup.py install for fbprophet ... error\n    ERROR: Command errored out with exit status 1:\n     command: \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record \/tmp\/pip-record-om94vf2a\/install-record.txt --single-version-externally-managed --compile\n         cwd: \/tmp\/pip-install-n493kv2i\/fbprophet\/\n    Complete output (9 lines):\n    running install\n    running build\n    running build_py\n    creating build\n    creating build\/lib\n    creating build\/lib\/fbprophet\n    creating build\/lib\/fbprophet\/stan_model\n    INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_888a84912910fa0a45b9d614b75bb8a8 NOW.\n    error: command 'gcc' failed with exit status 1\n    ----------------------------------------\nERROR: Command errored out with exit status 1: \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record \/tmp\/pip-record-om94vf2a\/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\nWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\n<\/code><\/pre>\n\n<p>Ps. I downloaded and imported pystan successfully.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1582312153763,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "amazon-sagemaker"
        ],
        "Question_view_count":642.0,
        "Owner_creation_time":1541972092476,
        "Owner_last_access_time":1664035936107,
        "Owner_reputation":731.0,
        "Owner_up_votes":65.0,
        "Owner_down_votes":0.0,
        "Owner_views":51.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Santa Clara, CA, USA",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60344876",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: importing fbprophet on ; content:<p>i am trying to download fbprophet package on . on my local device, i was able to do that but couldn't accomplish the same on . thanks to this <a href=\"https:\/\/github.com\/dr-prodigy\/python-holidays\/issues\/277#issuecomment-580740723\" rel=\"nofollow noreferrer\">link<\/a> i updated the hdays.py file's line 16 from:<\/p>\n\n<pre><code>from holidays import weekend, holidaybase, easter, rd\n<\/code><\/pre>\n\n<p>to:<\/p>\n\n<pre><code>from holidays import weekend, holidaybase\nfrom dateutil.easter import easter\nfrom dateutil.relativedelta import relativedelta as rd\n<\/code><\/pre>\n\n<p>this solved the error on my local device. anyone knows how i can download fbprophet on  or how i can update a downloaded package folder?<\/p>\n\n<p>when i run <code>!pip install fbprophet<\/code> on , the following error pops up:<\/p>\n\n<pre><code>collecting fbprophet\n  using cached https:\/\/files.pythonhosted.org\/packages\/f7\/86\/4509e952f9724f084625e93e0bf8d8519b25c79029a0a916b0f996644c75\/fbprophet-0.6.tar.gz\nrequirement already satisfied: cython&gt;=0.22 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.28.4)\nrequirement already satisfied: cmdstanpy==0.4 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.4.0)\nrequirement already satisfied: pystan&gt;=2.14 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (2.19.1.1)\nrequirement already satisfied: numpy&gt;=1.10.0 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (1.16.4)\nrequirement already satisfied: pandas&gt;=0.23.4 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.24.2)\nrequirement already satisfied: matplotlib&gt;=2.0.0 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (3.0.3)\nrequirement already satisfied: lunarcalendar&gt;=0.0.9 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.0.9)\nrequirement already satisfied: convertdate&gt;=2.1.2 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (2.2.0)\nrequirement already satisfied: holidays&gt;=0.9.5 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (0.10.1)\nrequirement already satisfied: setuptools-git&gt;=1.2 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (1.2)\nrequirement already satisfied: python-dateutil&gt;=2.8.0 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from fbprophet) (2.8.1)\nrequirement already satisfied: pytz&gt;=2011k in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from pandas&gt;=0.23.4-&gt;fbprophet) (2018.4)\nrequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from matplotlib&gt;=2.0.0-&gt;fbprophet) (2.2.0)\nrequirement already satisfied: kiwisolver&gt;=1.0.1 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from matplotlib&gt;=2.0.0-&gt;fbprophet) (1.0.1)\nrequirement already satisfied: cycler&gt;=0.10 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from matplotlib&gt;=2.0.0-&gt;fbprophet) (0.10.0)\nrequirement already satisfied: ephem&gt;=3.7.5.3 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from lunarcalendar&gt;=0.0.9-&gt;fbprophet) (3.7.7.0)\nrequirement already satisfied: pymeeus&lt;=1,&gt;=0.3.6 in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from convertdate&gt;=2.1.2-&gt;fbprophet) (0.3.6)\nrequirement already satisfied: six in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from holidays&gt;=0.9.5-&gt;fbprophet) (1.11.0)\nrequirement already satisfied: setuptools in \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/lib\/python3.6\/site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib&gt;=2.0.0-&gt;fbprophet) (41.6.0)\nbuilding wheels for collected packages: fbprophet\n  building wheel for fbprophet (setup.py) ... error\n  error: command errored out with exit status 1:\n   command: \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d \/tmp\/pip-wheel-vtdnatmm --python-tag cp36\n       cwd: \/tmp\/pip-install-n493kv2i\/fbprophet\/\n  complete output (9 lines):\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build\/lib\n  creating build\/lib\/fbprophet\n  creating build\/lib\/fbprophet\/stan_model\n  info:pystan:compiling the c++ code for model anon_model_888a84912910fa0a45b9d614b75bb8a8 now.\n  error: command 'gcc' failed with exit status 1\n  ----------------------------------------\n  error: failed building wheel for fbprophet\n  running setup.py clean for fbprophet\nfailed to build fbprophet\ninstalling collected packages: fbprophet\n    running setup.py install for fbprophet ... error\n    error: command errored out with exit status 1:\n     command: \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record \/tmp\/pip-record-om94vf2a\/install-record.txt --single-version-externally-managed --compile\n         cwd: \/tmp\/pip-install-n493kv2i\/fbprophet\/\n    complete output (9 lines):\n    running install\n    running build\n    running build_py\n    creating build\n    creating build\/lib\n    creating build\/lib\/fbprophet\n    creating build\/lib\/fbprophet\/stan_model\n    info:pystan:compiling the c++ code for model anon_model_888a84912910fa0a45b9d614b75bb8a8 now.\n    error: command 'gcc' failed with exit status 1\n    ----------------------------------------\nerror: command errored out with exit status 1: \/home\/ec2-user\/anaconda3\/envs\/tensorflow_p36\/bin\/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"'; __file__='\"'\"'\/tmp\/pip-install-n493kv2i\/fbprophet\/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record \/tmp\/pip-record-om94vf2a\/install-record.txt --single-version-externally-managed --compile check the logs for full command output.\nwarning: you are using pip version 19.3.1; however, version 20.0.2 is available.\nyou should consider upgrading via the 'pip install --upgrade pip' command.\n<\/code><\/pre>\n\n<p>ps. i downloaded and imported pystan successfully.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty downloading the fbprophet package on , and has updated the hdays.py file's line 16 to solve the error on their local device. They are still having difficulty downloading the package on and are receiving an error when running the pip install command."
    },
    {
        "Question_id":54433767.0,
        "Question_title":"how to add new R packages in azure machine learning for time series anomaly detection",
        "Question_body":"<p>I am trying to find out time series anomaly detection in which i need to install new R packages. In this i m following <a href=\"https:\/\/github.com\/business-science\/anomalize\" rel=\"nofollow noreferrer\">https:\/\/github.com\/business-science\/anomalize<\/a> site. In this i needed to install 2 packages: <code>tidyverse<\/code> and <code>anomalize<\/code>.<\/p>\n\n<ol>\n<li><p>can anyone help me on installing package mentioned above as I am getting <\/p>\n\n<blockquote>\n  <p>error \"package or namespace load failed for tidyverse\"<\/p>\n<\/blockquote><\/li>\n<li><p>Also while adding zip of <code>tidyverse<\/code> and <code>anomalize<\/code> do I need to add any other packages and dependencies in that as I am adding only those 2 packages thinking there r no other dependencies I needed for those 2?<\/p><\/li>\n<\/ol>\n\n<p>you can see in code that I created <code>R_Package.zip<\/code> and put <code>tidyverse.zip<\/code> and <code>anomalize.zip<\/code> in that that <\/p>\n\n<pre><code>dataset1 &lt;- maml.mapInputPort(1)\ndata.set &lt;- data.frame(installed.packages())\n#install.packages(\u201csrc\/R_Package\/tidyverse_1.2.1.zip\u201d, lib = \u201c.\u201d, \n                  repos = NULL, verbose = TRUE);\n#library(tidyverse, lib.loc=\u201d.\u201d, verbose=TRUE);\n\ninstall.packages(\"src\/tidyverse.zip\",lib=\".\",repos=NULL,verbose=TRUE)\nlibrary(R_package, lib.loc = \".\", verbose=TRUE);\n\ninstall.packages(\"src\/anomalize.zip\",lib=\".\",repos=NULL,verbose=TRUE)\nlibrary(R_package, lib.loc = \".\", verbose=TRUE);\n\n#success &lt;- library(\"tidyverse\", lib.loc = \".\", \n                    logical.return = TRUE, verbose = TRUE)\n#library(tidyverse)\n\n\nmaml.mapOutputPort(\"dataset1\");\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1548825762143,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "r",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":168.0,
        "Owner_creation_time":1492081349832,
        "Owner_last_access_time":1556108056507,
        "Owner_reputation":19.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":42.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1548834576212,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54433767",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to add new r packages in  for time series anomaly detection; content:<p>i am trying to find out time series anomaly detection in which i need to install new r packages. in this i m following <a href=\"https:\/\/github.com\/business-science\/anomalize\" rel=\"nofollow noreferrer\">https:\/\/github.com\/business-science\/anomalize<\/a> site. in this i needed to install 2 packages: <code>tidyverse<\/code> and <code>anomalize<\/code>.<\/p>\n\n<ol>\n<li><p>can anyone help me on installing package mentioned above as i am getting <\/p>\n\n<blockquote>\n  <p>error \"package or namespace load failed for tidyverse\"<\/p>\n<\/blockquote><\/li>\n<li><p>also while adding zip of <code>tidyverse<\/code> and <code>anomalize<\/code> do i need to add any other packages and dependencies in that as i am adding only those 2 packages thinking there r no other dependencies i needed for those 2?<\/p><\/li>\n<\/ol>\n\n<p>you can see in code that i created <code>r_package.zip<\/code> and put <code>tidyverse.zip<\/code> and <code>anomalize.zip<\/code> in that that <\/p>\n\n<pre><code>dataset1 &lt;- maml.mapinputport(1)\ndata.set &lt;- data.frame(installed.packages())\n#install.packages(\u201csrc\/r_package\/tidyverse_1.2.1.zip\u201d, lib = \u201c.\u201d, \n                  repos = null, verbose = true);\n#library(tidyverse, lib.loc=\u201d.\u201d, verbose=true);\n\ninstall.packages(\"src\/tidyverse.zip\",lib=\".\",repos=null,verbose=true)\nlibrary(r_package, lib.loc = \".\", verbose=true);\n\ninstall.packages(\"src\/anomalize.zip\",lib=\".\",repos=null,verbose=true)\nlibrary(r_package, lib.loc = \".\", verbose=true);\n\n#success &lt;- library(\"tidyverse\", lib.loc = \".\", \n                    logical.return = true, verbose = true)\n#library(tidyverse)\n\n\nmaml.mapoutputport(\"dataset1\");\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to install two R packages, tidyverse and anomalize, for time series anomaly detection and is encountering an error. They are also asking if any other packages or dependencies need to be installed."
    },
    {
        "Question_id":null,
        "Question_title":"R device result",
        "Question_body":"R device Loading variable to data frame not complete\nThis is my code\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,\nprobs=c(0, .25,.5, 0.75, 1) ) ) )\n\nSelect data.frame to be sent to the output Dataset port\nmaml.mapOutputPort(\"dataset1\");\n\n\n\n\nR device port (Loading variable ) show \"Loading variable port1...\"\n0% 25% 50% 75% 100%\n6319\/A16.ZDE1DWW70500009 0.270 0.5050 0.740 0.9000 1.06\n6319\/A17.ZDE1DWW70500009 0.300 0.3825 0.445 0.5825 0.89\n6319\/A18.ZDE1DWW70500009 0.470 0.4700 0.470 0.4700 0.47\n6320\/A01.ZDE1DWW70500009 0.330 0.3725 0.475 1.2675 1.99\n\nHow to import this in table format for analysis\n\nI try to use\ndata.set <- data.frame (\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,\nprobs=c(0, .25,.5, 0.75, 1) ) ) )\n)\n\nI get this table that has not first column ( ex. 6319\/A16.ZDE1DWW70500009)\n0. X25. X50. X75. X100.\n\n0.27 0.505 0.74 0.9 1.06\n0.3 0.3825 0.445 0.5825 0.89\n0.47 0.47 0.47 0.47 0.47\n0.33 0.3725 0.475 1.2675 1.99\n0.2 0.2675 0.33 0.3925 0.52\n\nPlease suggest me,\nI sorry for my english is not good.",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1611814116917,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/248487\/r-device-result.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: r device result; content:r device loading variable to data frame not complete\nthis is my code\ndo.call ( rbind, with( dataset1, tapply(shotonscreen2, interaction(lotnos=lotnos , productcode=productcode), quantile,\nprobs=c(0, .25,.5, 0.75, 1) ) ) )\n\nselect data.frame to be sent to the output dataset port\nmaml.mapoutputport(\"dataset1\");\n\n\n\n\nr device port (loading variable ) show \"loading variable port1...\"\n0% 25% 50% 75% 100%\n6319\/a16.zde1dww70500009 0.270 0.5050 0.740 0.9000 1.06\n6319\/a17.zde1dww70500009 0.300 0.3825 0.445 0.5825 0.89\n6319\/a18.zde1dww70500009 0.470 0.4700 0.470 0.4700 0.47\n6320\/a01.zde1dww70500009 0.330 0.3725 0.475 1.2675 1.99\n\nhow to import this in table format for analysis\n\ni try to use\ndata.set <- data.frame (\ndo.call ( rbind, with( dataset1, tapply(shotonscreen2, interaction(lotnos=lotnos , productcode=productcode), quantile,\nprobs=c(0, .25,.5, 0.75, 1) ) ) )\n)\n\ni get this table that has not first column ( ex. 6319\/a16.zde1dww70500009)\n0. x25. x50. x75. x100.\n\n0.27 0.505 0.74 0.9 1.06\n0.3 0.3825 0.445 0.5825 0.89\n0.47 0.47 0.47 0.47 0.47\n0.33 0.3725 0.475 1.2675 1.99\n0.2 0.2675 0.33 0.3925 0.52\n\nplease suggest me,\ni sorry for my english is not good.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty loading a variable to a data frame and importing it into a table format for analysis."
    },
    {
        "Question_id":null,
        "Question_title":"Getting an SSL error azureml",
        "Question_body":"I'm getting this error:\n\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1131)\n\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eastus.api.azureml.ms', port=443): Max retries exceeded with url: \/rp\/workspaces\/subscriptions\/. . .\n\n\n\n\nwhile trying to do anything with azureml sdk\n\n from azureml.core import Workspace\n    \n ws = Workspace.from_config()\n    \n for compute_name in ws.compute_targets:\n     compute = ws.compute_targets[compute_name]\n     print(compute.name, \":\", compute.type)\n\n\n\nHow would I go about fixing this and running any kind of operation with the azureml-sdk?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1656434118017,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/906759\/getting-an-ssl-error-azureml.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-29T14:24:25.777Z",
                "Answer_score":1,
                "Answer_body":"@AsimAryal-5631 Thanks for the question. Here is the sample notebook to run authentication in azure machine learning.\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/1f05157d24c8bd9866121b588e75dc95764ae898\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\n\nWe are able to execute successfully and get the compute name and type as shown below.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: getting an ssl error ; content:i'm getting this error:\n\nssl.sslcertverificationerror: [ssl: certificate_verify_failed] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1131)\n\nurllib3.exceptions.maxretryerror: httpsconnectionpool(host='eastus.api..ms', port=443): max retries exceeded with url: \/rp\/workspaces\/subscriptions\/. . .\n\n\n\n\nwhile trying to do anything with  sdk\n\n from .core import workspace\n    \n ws = workspace.from_config()\n    \n for compute_name in ws.compute_targets:\n     compute = ws.compute_targets[compute_name]\n     print(compute.name, \":\", compute.type)\n\n\n\nhow would i go about fixing this and running any kind of operation with the -sdk?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is getting an SSL error and max retry error while trying to do anything with the SDK, and is asking how to go about fixing this and running operations with the SDK."
    },
    {
        "Question_id":null,
        "Question_title":"can we run a jupyter notebook using scriptrunconfig on target compute cluster ?",
        "Question_body":"Hi,\n\nI understood that we can run a python script using scriptrunconfig.\n\nMy question is whether we can run jupyter notebook ?\nWhat other type of scripts can we run ?\n\nThank you.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1612203390137,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/254301\/can-we-run-a-jupyter-notebook-using-scriptrunconfi.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-01T21:46:21.163Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nFor Azure Machine Learning Service, you can create a notebook with designed Computer Instance: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-run-jupyter-notebooks\n\nThis guidance shows how to run your Jupyter notebooks directly in your workspace in Azure Machine Learning studio. While you can launch Jupyter or JupyterLab, you can also edit and run your notebooks without leaving the workspace.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: can we run a jupyter notebook using scriptrunconfig on target compute cluster ?; content:hi,\n\ni understood that we can run a python script using scriptrunconfig.\n\nmy question is whether we can run jupyter notebook ?\nwhat other type of scripts can we run ?\n\nthank you.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if they can run a Jupyter notebook using scriptrunconfig on a target compute cluster, and what other types of scripts can be run."
    },
    {
        "Question_id":62623166.0,
        "Question_title":"Azure ML Error: TimeSeriesImputer object has no attribute '_known_df'",
        "Question_body":"<p>Running <a href=\"http:\/\/%20https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-orange-juice-sales\/auto-ml-forecasting-orange-juice-sales.ipynb\" rel=\"nofollow noreferrer\">this orange juice sales notebook<\/a> I get the below error with the <code>.forecast()<\/code> method.<\/p>\n<h3>code<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code># The featurized data, aligned to y, will also be returned.\n# This contains the assumptions that were made in the forecast\n# and helps align the forecast to the original data\ny_predictions, X_trans = fitted_model.forecast(X_test)\n<\/code><\/pre>\n<h3>Error (<a href=\"https:\/\/gist.github.com\/swanderz\/201819978b6719bbed1826a02bb2fb47\" rel=\"nofollow noreferrer\">full stacktrace<\/a>):<\/h3>\n<pre><code>**AttributeError: 'TimeSeriesImputer' object has no attribute '_known_df'**\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1593350881953,
        "Question_favorite_count":1.0,
        "Question_score":1.0,
        "Question_tags":[
            "time-series",
            "azure-machine-learning-studio",
            "forecast",
            "azure-machine-learning-service"
        ],
        "Question_view_count":256.0,
        "Owner_creation_time":1444548825376,
        "Owner_last_access_time":1641987792040,
        "Owner_reputation":303.0,
        "Owner_up_votes":105.0,
        "Owner_down_votes":7.0,
        "Owner_views":60.0,
        "Answer_body":"<p>This is commonly fixed by upgrading to the latest SDK. You can do this by running <code>pip install --upgrade azureml-sdk[explain,automl]<\/code>.<\/p>\n<p>Thanks,\nSabina<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1593542625630,
        "Answer_score":2.0,
        "Owner_location":null,
        "Question_last_edit_time":1594142196016,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62623166",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  error: timeseriesimputer object has no attribute '_known_df'; content:<p>running <a href=\"http:\/\/%20https:\/\/github.com\/azure\/machinelearningnotebooks\/blob\/master\/how-to-use-\/automated-machine-learning\/forecasting-orange-juice-sales\/auto-ml-forecasting-orange-juice-sales.ipynb\" rel=\"nofollow noreferrer\">this orange juice sales notebook<\/a> i get the below error with the <code>.forecast()<\/code> method.<\/p>\n<h3>code<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code># the featurized data, aligned to y, will also be returned.\n# this contains the assumptions that were made in the forecast\n# and helps align the forecast to the original data\ny_predictions, x_trans = fitted_model.forecast(x_test)\n<\/code><\/pre>\n<h3>error (<a href=\"https:\/\/gist.github.com\/swanderz\/201819978b6719bbed1826a02bb2fb47\" rel=\"nofollow noreferrer\">full stacktrace<\/a>):<\/h3>\n<pre><code>**attributeerror: 'timeseriesimputer' object has no attribute '_known_df'**\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an AttributeError when running a notebook for forecasting orange juice sales, indicating that the 'TimeSeriesImputer' object has no attribute '_known_df'."
    },
    {
        "Question_id":null,
        "Question_title":"Need help for compute engine pricing",
        "Question_body":"GPU: nvidia-a100-80gb has no pricing but  nvidia-tesla-a100 has",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1662441060000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":36.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Need-help-for-compute-engine-pricing\/td-p\/463295\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-06T05:11:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"GPU:\u00a0nvidia-a100-80gb has no pricing but\u00a0\u00a0nvidia-tesla-a100 has"
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: need help for compute engine pricing; content:gpu: nvidia-a100-80gb has no pricing but  nvidia-tesla-a100 has",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs help understanding the pricing for the Nvidia A100 80GB GPU, as it does not appear to be listed, but the Nvidia Tesla A100 does have pricing."
    },
    {
        "Question_id":64282238.0,
        "Question_title":"What is the difference of xgboost and sagemaker.xgboost",
        "Question_body":"<p>Question is really clear. Nowadays im learning AWS world, and this question is eating my head up. What is the difference of <code>import xgboost<\/code> and <code>import sagemaker.xgboost<\/code>.<\/p>\n<p>On SageMaker i can work with normal XGBoost library, and i know i can select different EC2 types with <code>sagemaker.xgboost<\/code>. But except this, what is the difference?\nAre there any big difference?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1602254525880,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "amazon-ec2",
            "scikit-learn",
            "amazon-sagemaker"
        ],
        "Question_view_count":313.0,
        "Owner_creation_time":1587688322720,
        "Owner_last_access_time":1661976002296,
        "Owner_reputation":63.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"\u0130zmir, T\u00fcrkiye",
        "Question_last_edit_time":1602291754620,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64282238",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: what is the difference of xgboost and .xgboost; content:<p>question is really clear. nowadays im learning aws world, and this question is eating my head up. what is the difference of <code>import xgboost<\/code> and <code>import .xgboost<\/code>.<\/p>\n<p>on  i can work with normal xgboost library, and i know i can select different ec2 types with <code>.xgboost<\/code>. but except this, what is the difference?\nare there any big difference?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking what the difference is between importing the xgboost library and importing the .xgboost library, and if there are any major differences between the two."
    },
    {
        "Question_id":70929123.0,
        "Question_title":"AzureMLCompute job failed with `FailedLoginToImageRegistry`",
        "Question_body":"<p>I've been trying to send a train job through azure ml python sdk with:<\/p>\n<pre><code>from azureml.core import Workspace, Experiment, ScriptRunConfig \n\nif __name__ == &quot;__main__&quot;:\n    ws = Workspace.from_config()\n    experiment = Experiment(workspace=ws, name='ConstructionTopicsModel')\n\n    config = ScriptRunConfig(source_directory='.\/',\n                         script='src\/azureml\/train.py',\n                         arguments=None,\n                         compute_target='ComputeTargetName',\n                         )\n\n    env = ws.environments['test-env']\n    config.run_config.environment = env\n    run = experiment.submit(config)\n    \n    run.wait_for_completion(show_output=True)\n\n    aml_url = run.get_portal_url()\n    print(aml_url)\n<\/code><\/pre>\n<p>But I was getting the <code>ServiceError<\/code> message:<\/p>\n<pre><code>AzureMLCompute job failed. FailedLoginToImageRegistry: Unable to login to docker image repo\nReason: Failed to login to the docker registry\nerror: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nserviceURL: 7ac86b04d6564d36aa80ae2ad090582c.azurecr.io\nReason: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n<\/code><\/pre>\n<p>I also tried using the azure cli without success, same error message<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1643645330913,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning-service",
            "azureml-python-sdk",
            "azuremlsdk"
        ],
        "Question_view_count":202.0,
        "Owner_creation_time":1589293508567,
        "Owner_last_access_time":1663681781072,
        "Owner_reputation":833.0,
        "Owner_up_votes":9.0,
        "Owner_down_votes":9.0,
        "Owner_views":55.0,
        "Answer_body":"<p>The only way I've found so far to make this work, was to run it on a terminal of the compute-target itself. That's how the docker error goes away. Trying to run the experiment from a terminal of a different compute instance raises the exception.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1643645330912,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70929123",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: compute job failed with `failedlogintoimageregistry`; content:<p>i've been trying to send a train job through  python sdk with:<\/p>\n<pre><code>from .core import workspace, experiment, scriptrunconfig \n\nif __name__ == &quot;__main__&quot;:\n    ws = workspace.from_config()\n    experiment = experiment(workspace=ws, name='constructiontopicsmodel')\n\n    config = scriptrunconfig(source_directory='.\/',\n                         script='src\/\/train.py',\n                         arguments=none,\n                         compute_target='computetargetname',\n                         )\n\n    env = ws.environments['test-env']\n    config.run_config.environment = env\n    run = experiment.submit(config)\n    \n    run.wait_for_completion(show_output=true)\n\n    aml_url = run.get_portal_url()\n    print(aml_url)\n<\/code><\/pre>\n<p>but i was getting the <code>serviceerror<\/code> message:<\/p>\n<pre><code>compute job failed. failedlogintoimageregistry: unable to login to docker image repo\nreason: failed to login to the docker registry\nerror: warning! using --password via the cli is insecure. use --password-stdin. error saving credentials: error storing credentials - err: exit status 1, out: `cannot autolaunch d-bus without x11 $display`\n\nserviceurl: 7ac86b04d6564d36aa80ae2ad090582c.azurecr.io\nreason: warning! using --password via the cli is insecure. use --password-stdin. error saving credentials: error storing credentials - err: exit status 1, out: `cannot autolaunch d-bus without x11 $display`\n\ninfo: failed to setup runtime for job execution: job environment preparation failed on 10.0.0.5 with err exit status 1.\n<\/code><\/pre>\n<p>i also tried using the azure cli without success, same error message<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving a \"serviceerror\" message when trying to submit a train job through Azure ML Python SDK and Azure CLI, indicating that they are unable to login to the Docker image repo."
    },
    {
        "Question_id":54216797.0,
        "Question_title":"SageMaker Javascript SDK Endpoint Invocation Error: \"CustomerError: Unable to parse payload to numeric values\"",
        "Question_body":"<p>I was invoking the SageMaker endpoint from my angular front-end when I came across this error on AWS CloudWatch regarding my model making inferences from the data (In the form of a comma-separated string with target values at the first index) I was sending : <strong>Unable to parse numeric values<\/strong>. The string I'm using to invoke the endpoint was : \"1533071820,0.05619,0.05619,0.05611,0.05611,0.006076\\n\"<\/p>\n\n<p>String request = \"1533071820,0.05619,0.05619,0.05611,0.05611,0.006076\\n\"<\/p>\n\n<p>ByteBufferbuf = ByteBuffer.wrap(request.getBytes());\ninvokeEndpointRequest.setBody(buf);\n<code>Use the SageMaker API<\/code>\nAmazonSageMakerRuntime amazonSageMaker = AmazonSageMakerRuntimeClientBuilder.defaultClient();\n<code>Invoke the model endpoint on SageMaker<\/code>\nInvokeEndpointResult invokeEndpointResult = amazonSageMaker.invokeEndpoint(invokeEndpointRequest);<\/p>\n\n<p>The result I was expecting from the endpoint is a JSON object with the 'score' attribute in the format : {\"predictions\": [{\"score\": xxxxxxx}]}<\/p>\n\n<p>I am getting a 'ModelError: Unable to evaluate payload' from the IDE logs and 'Unable to parse numeric values on CloudWatch'<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1547640627280,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "javascript",
            "node.js",
            "aws-sdk",
            "amazon-sagemaker"
        ],
        "Question_view_count":305.0,
        "Owner_creation_time":1439560057472,
        "Owner_last_access_time":1579689018243,
        "Owner_reputation":29.0,
        "Owner_up_votes":14.0,
        "Owner_down_votes":0.0,
        "Owner_views":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Johannesburg North, Randburg, Gauteng, South Africa",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54216797",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  javascript sdk endpoint invocation error: \"customererror: unable to parse payload to numeric values\"; content:<p>i was invoking the  endpoint from my angular front-end when i came across this error on aws cloudwatch regarding my model making inferences from the data (in the form of a comma-separated string with target values at the first index) i was sending : <strong>unable to parse numeric values<\/strong>. the string i'm using to invoke the endpoint was : \"1533071820,0.05619,0.05619,0.05611,0.05611,0.006076\\n\"<\/p>\n\n<p>string request = \"1533071820,0.05619,0.05619,0.05611,0.05611,0.006076\\n\"<\/p>\n\n<p>bytebufferbuf = bytebuffer.wrap(request.getbytes());\ninvokeendpointrequest.setbody(buf);\n<code>use the  api<\/code>\namazonruntime amazon = amazonruntimeclientbuilder.defaultclient();\n<code>invoke the model endpoint on <\/code>\ninvokeendpointresult invokeendpointresult = amazon.invokeendpoint(invokeendpointrequest);<\/p>\n\n<p>the result i was expecting from the endpoint is a json object with the 'score' attribute in the format : {\"predictions\": [{\"score\": xxxxxxx}]}<\/p>\n\n<p>i am getting a 'modelerror: unable to evaluate payload' from the ide logs and 'unable to parse numeric values on cloudwatch'<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user encountered an error when invoking an endpoint from their Angular front-end, resulting in an \"unable to parse numeric values\" error on AWS Cloudwatch."
    },
    {
        "Question_id":72162395.0,
        "Question_title":"Handle different runs concurrently on multiple tracking servers?",
        "Question_body":"<p>Are there any resources or insights on handling multiple tracking servers concurrently? We're trying to deploy some RESTful APIs (with FastAPI) that basically launch, potentially concurrently, multiple runs on different Tracking Servers using the MLflow Python API. We've seen that there's no clear way to explicitly assign the Tracking URI during the <code>mlflow.projects.run<\/code> function and so we're obliged to use <code>set_tracking_uri<\/code> everytime before launching the new run (which I quote &quot;does not affect the currently active run (if one exists), but takes effect for successive runs.&quot;). Problem is that it may happens that multiple runs go in conflict between each other and some random errors like <code>mlflow.exceptions.RestException: RESOURCE_DOES_NOT_EXIST<\/code> may occur.<\/p>\n<p>Is there a way to handle this use case scenario or MLflow is still too unripe to be handling multiple tracking servers on a single endpoint?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1652022931417,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "fastapi",
            "mlflow"
        ],
        "Question_view_count":52.0,
        "Owner_creation_time":1420982186627,
        "Owner_last_access_time":1664038042316,
        "Owner_reputation":1065.0,
        "Owner_up_votes":35.0,
        "Owner_down_votes":0.0,
        "Owner_views":73.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Florence, Italy",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72162395",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: handle different runs concurrently on multiple tracking servers?; content:<p>are there any resources or insights on handling multiple tracking servers concurrently? we're trying to deploy some restful apis (with fastapi) that basically launch, potentially concurrently, multiple runs on different tracking servers using the  python api. we've seen that there's no clear way to explicitly assign the tracking uri during the <code>.projects.run<\/code> function and so we're obliged to use <code>set_tracking_uri<\/code> everytime before launching the new run (which i quote &quot;does not affect the currently active run (if one exists), but takes effect for successive runs.&quot;). problem is that it may happens that multiple runs go in conflict between each other and some random errors like <code>.exceptions.restexception: resource_does_not_exist<\/code> may occur.<\/p>\n<p>is there a way to handle this use case scenario or  is still too unripe to be handling multiple tracking servers on a single endpoint?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to launch multiple runs on different tracking servers using the python API, but they are encountering issues with conflicts between the runs and encountering errors such as \"resource_does_not_exist\". They are looking for resources or insights on handling multiple tracking servers concurrently, and want to know if there is a way to handle this scenario or if it is still too unripe to be handling multiple tracking servers on a single endpoint."
    },
    {
        "Question_id":29906812.0,
        "Question_title":"forecast package versions different result",
        "Question_body":"<p>I am using R forecast package auto.arima() function, testing it against a predictable sine wave time series. When I run the R code on local machine in R studio, I get a significantly different output to running exactly the same code with the same source data as in azure ML. The only difference I can see is that azure has an older version of forecast package 5.4 whereas i have downloaded the latest version on local machine 5.9. (Interestingly the older version in azure ML correctly forecasts future values, the newer version predicts an attenuating amplitude, which is incorrect). <\/p>\n\n<p>My question then is for anyone who may know why a function's behaviour would change so significantly between package versions, which strikes me as very strange. Or am I missing something here? I am new to both R and azure ML.. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1430172286407,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "r",
            "azure-virtual-machine",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":212.0,
        "Owner_creation_time":1430171674327,
        "Owner_last_access_time":1474914701380,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1483523471852,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29906812",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: forecast package versions different result; content:<p>i am using r forecast package auto.arima() function, testing it against a predictable sine wave time series. when i run the r code on local machine in r studio, i get a significantly different output to running exactly the same code with the same source data as in . the only difference i can see is that azure has an older version of forecast package 5.4 whereas i have downloaded the latest version on local machine 5.9. (interestingly the older version in  correctly forecasts future values, the newer version predicts an attenuating amplitude, which is incorrect). <\/p>\n\n<p>my question then is for anyone who may know why a function's behaviour would change so significantly between package versions, which strikes me as very strange. or am i missing something here? i am new to both r and .. <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is encountering different results when running the same R code with the \"forecast\" package's auto.arima() function in R Studio with the latest version of the package compared to in Azure ML with an older version. The older version in Azure ML gives a more accurate forecast while the newer version predicts an incorrect result. The user is seeking an explanation for why the behavior of the function would change between package versions."
    },
    {
        "Question_id":64054150.0,
        "Question_title":"CUDA out of memory when running Bert with Pytorch (Previously worked)",
        "Question_body":"<p>I am building a BERT binary classification on SageMaker using Pytorch.<\/p>\n<p>Previously when I ran the model, I set the Batch size to 16 and the model were able to run successfully. However, yesterday after I stopped SageMaker and restarted the this morning, I can't run the model with Batch size as 16 any more. I am able to run the model with batch size 8.<br \/>\nHowever, the model is not producing the same result (of course). I didn't change anything else in between. All other settings are the same. (Except I change the SageMaker volume from 30GB to 200GB.)<\/p>\n<p>Does anyone know what may cause this problem? I really want to reproduce the result with batch size 16.<\/p>\n<p>Any answers will help and thank you in advance!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_creation_time":1600980328767,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "pytorch",
            "amazon-sagemaker",
            "bert-language-model",
            "spacy-transformers"
        ],
        "Question_view_count":349.0,
        "Owner_creation_time":1600744231768,
        "Owner_last_access_time":1632788494096,
        "Owner_reputation":31.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":8.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1600981567627,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64054150",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: cuda out of memory when running bert with pytorch (previously worked); content:<p>i am building a bert binary classification on  using pytorch.<\/p>\n<p>previously when i ran the model, i set the batch size to 16 and the model were able to run successfully. however, yesterday after i stopped  and restarted the this morning, i can't run the model with batch size as 16 any more. i am able to run the model with batch size 8.<br \/>\nhowever, the model is not producing the same result (of course). i didn't change anything else in between. all other settings are the same. (except i change the  volume from 30gb to 200gb.)<\/p>\n<p>does anyone know what may cause this problem? i really want to reproduce the result with batch size 16.<\/p>\n<p>any answers will help and thank you in advance!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an issue with running a BERT binary classification model using PyTorch, where they are unable to run the model with a batch size of 16, but can run it with a batch size of 8."
    },
    {
        "Question_id":45558337.0,
        "Question_title":"What is wrong with my experiment (Trying to predict car sales)?",
        "Question_body":"<p>I have the dataset like this (just a sample of it):<\/p>\n\n<pre><code>DATE_REF,MONTH,YEAR,DAY_OF_YEAR,DAY_OF_MONTH,WEEK_DAY,WEEK_DAY_1,WEEK_DAY_2,WEEK_DAY_3,WEEK_DAY_4,WEEK_DAY_5,WEEK_DAY_6,WEEK_DAY_7,WEEK_NUMBER_IN_MONTH,WEEKEND,WORK_DAY,AMOUNT_SOLD\n20100101,1,2010,1,1,6,0,0,0,0,0,1,0,1,0,0,0\n20100102,1,2010,2,2,7,0,0,0,0,0,0,1,1,1,0,2\n20100103,1,2010,3,3,1,1,0,0,0,0,0,0,2,1,0,0\n20100104,1,2010,4,4,2,0,1,0,0,0,0,0,2,0,1,12830\n20100105,1,2010,5,5,3,0,0,1,0,0,0,0,2,0,1,19200\n20100106,1,2010,6,6,4,0,0,0,1,0,0,0,2,0,1,22930\n20100107,1,2010,7,7,5,0,0,0,0,1,0,0,2,0,1,23495\n20100108,1,2010,8,8,6,0,0,0,0,0,1,0,2,0,1,23215\n20100109,1,2010,9,9,7,0,0,0,0,0,0,1,2,1,0,172\n20100110,1,2010,10,10,1,1,0,0,0,0,0,0,3,1,0,0\n20100111,1,2010,11,11,2,0,1,0,0,0,0,0,3,0,1,18815\n20100112,1,2010,12,12,3,0,0,1,0,0,0,0,3,0,1,25415\n20100113,1,2010,13,13,4,0,0,0,1,0,0,0,3,0,1,25262\n20100114,1,2010,14,14,5,0,0,0,0,1,0,0,3,0,1,27967\n20100115,1,2010,15,15,6,0,0,0,0,0,1,0,3,0,1,26352\n20100116,1,2010,16,16,7,0,0,0,0,0,0,1,3,1,0,202\n20100117,1,2010,17,17,1,1,0,0,0,0,0,0,4,1,0,10\n20100118,1,2010,18,18,2,0,1,0,0,0,0,0,4,0,1,20295\n20100119,1,2010,19,19,3,0,0,1,0,0,0,0,4,0,1,25982\n20100120,1,2010,20,20,4,0,0,0,1,0,0,0,4,0,1,24745\n20100121,1,2010,21,21,5,0,0,0,0,1,0,0,4,0,1,28087\n20100122,1,2010,22,22,6,0,0,0,0,0,1,0,4,0,1,28417\n20100123,1,2010,23,23,7,0,0,0,0,0,0,1,4,1,0,115\n20100124,1,2010,24,24,1,1,0,0,0,0,0,0,5,1,0,5\n20100125,1,2010,25,25,2,0,1,0,0,0,0,0,5,0,1,20185\n20100126,1,2010,26,26,3,0,0,1,0,0,0,0,5,0,1,25932\n20100127,1,2010,27,27,4,0,0,0,1,0,0,0,5,0,1,31710\n20100128,1,2010,28,28,5,0,0,0,0,1,0,0,5,0,1,21020\n20100129,1,2010,29,29,6,0,0,0,0,0,1,0,5,0,1,51460\n20100130,1,2010,30,30,7,0,0,0,0,0,0,1,5,1,0,670\n20100131,1,2010,31,31,1,1,0,0,0,0,0,0,6,1,0,17\n<\/code><\/pre>\n\n<p>I'm trying to predict the <code>AMOUNT_SOLD<\/code> for new dates (<code>DATE_REF<\/code>) using the following experiment on Azure ML:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/7Mfhs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7Mfhs.png\" alt=\"Azure ML Experiment\"><\/a><\/p>\n\n<p>Then I deployed the Web Service and tested the prediction, but all I got was zero for the <code>AMOUNT_SOLD<\/code> column.<\/p>\n\n<p>What may I be missing? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1502159015170,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "machine-learning",
            "regression",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":178.0,
        "Owner_creation_time":1328174321836,
        "Owner_last_access_time":1659728310848,
        "Owner_reputation":7753.0,
        "Owner_up_votes":98.0,
        "Owner_down_votes":30.0,
        "Owner_views":743.0,
        "Answer_body":"<p>As much as I want to replicate your Azure ML experiment, I do not have enough data. But what I've done are as follows:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/XNaeg.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XNaeg.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I copied your sample data, and then multiplied it by 4 times (<strong>Add Rows x 2<\/strong>).\nThen <strong>Split Data<\/strong> (70%\/30%), random seed 7 (for reproducible results).\nThe <strong>Boosted Decision Tree Regression<\/strong> has default parameters.\nOn <strong>Tune Model Hyperparameters<\/strong>, I selected <strong><em>AMOUNT_SOLD<\/em><\/strong> as the label column.\nThen <strong>Score Model<\/strong> and <strong>Evaluate Model<\/strong>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/aIJlk.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/aIJlk.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Accuracy \/ Coefficient of Determination was pretty good.<\/p>\n\n<p>After that, to deploy this as a web service, you must setup first a Predictive Experiment from your Training Experiment. <code>Setup Web Service &gt; Predictive Experiment<\/code> You experiment will move like magic.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/gTEOl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gTEOl.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The <strong>Web Service Input<\/strong> module will be placed by default at the top of the experiment. I <strong>moved it and connected at the right side of Score Model<\/strong>, so that when you are inputting the parameters of your web service, it <em>will be predicted using your Trained Model<\/em>.<\/p>\n\n<p>After the Score Model module, I placed a <strong>Select Columns in Dataset<\/strong> module and selected only the column named <strong>Scored Labels<\/strong>. This column contains the model's predictions. Then I used <strong>Edit Metadata<\/strong> module to rename the Scored Labels column, before passing it to the <strong>Web Service Output<\/strong> module.<\/p>\n\n<p>Your experiment is now ready to deploy as a web service.<\/p>\n\n<p>To predict new values, I tested the web service using the current date details as input. (<strong>Although the DATE_REF input must be 20170818<\/strong> :D )<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/fPm65.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fPm65.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And then the output looks like this:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/R6N4B.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/R6N4B.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Your web service can now predict new values.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1503036396008,
        "Answer_score":1.0,
        "Owner_location":"Belo Horizonte - MG, Brasil",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45558337",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: what is wrong with my experiment (trying to predict car sales)?; content:<p>i have the dataset like this (just a sample of it):<\/p>\n\n<pre><code>date_ref,month,year,day_of_year,day_of_month,week_day,week_day_1,week_day_2,week_day_3,week_day_4,week_day_5,week_day_6,week_day_7,week_number_in_month,weekend,work_day,amount_sold\n20100101,1,2010,1,1,6,0,0,0,0,0,1,0,1,0,0,0\n20100102,1,2010,2,2,7,0,0,0,0,0,0,1,1,1,0,2\n20100103,1,2010,3,3,1,1,0,0,0,0,0,0,2,1,0,0\n20100104,1,2010,4,4,2,0,1,0,0,0,0,0,2,0,1,12830\n20100105,1,2010,5,5,3,0,0,1,0,0,0,0,2,0,1,19200\n20100106,1,2010,6,6,4,0,0,0,1,0,0,0,2,0,1,22930\n20100107,1,2010,7,7,5,0,0,0,0,1,0,0,2,0,1,23495\n20100108,1,2010,8,8,6,0,0,0,0,0,1,0,2,0,1,23215\n20100109,1,2010,9,9,7,0,0,0,0,0,0,1,2,1,0,172\n20100110,1,2010,10,10,1,1,0,0,0,0,0,0,3,1,0,0\n20100111,1,2010,11,11,2,0,1,0,0,0,0,0,3,0,1,18815\n20100112,1,2010,12,12,3,0,0,1,0,0,0,0,3,0,1,25415\n20100113,1,2010,13,13,4,0,0,0,1,0,0,0,3,0,1,25262\n20100114,1,2010,14,14,5,0,0,0,0,1,0,0,3,0,1,27967\n20100115,1,2010,15,15,6,0,0,0,0,0,1,0,3,0,1,26352\n20100116,1,2010,16,16,7,0,0,0,0,0,0,1,3,1,0,202\n20100117,1,2010,17,17,1,1,0,0,0,0,0,0,4,1,0,10\n20100118,1,2010,18,18,2,0,1,0,0,0,0,0,4,0,1,20295\n20100119,1,2010,19,19,3,0,0,1,0,0,0,0,4,0,1,25982\n20100120,1,2010,20,20,4,0,0,0,1,0,0,0,4,0,1,24745\n20100121,1,2010,21,21,5,0,0,0,0,1,0,0,4,0,1,28087\n20100122,1,2010,22,22,6,0,0,0,0,0,1,0,4,0,1,28417\n20100123,1,2010,23,23,7,0,0,0,0,0,0,1,4,1,0,115\n20100124,1,2010,24,24,1,1,0,0,0,0,0,0,5,1,0,5\n20100125,1,2010,25,25,2,0,1,0,0,0,0,0,5,0,1,20185\n20100126,1,2010,26,26,3,0,0,1,0,0,0,0,5,0,1,25932\n20100127,1,2010,27,27,4,0,0,0,1,0,0,0,5,0,1,31710\n20100128,1,2010,28,28,5,0,0,0,0,1,0,0,5,0,1,21020\n20100129,1,2010,29,29,6,0,0,0,0,0,1,0,5,0,1,51460\n20100130,1,2010,30,30,7,0,0,0,0,0,0,1,5,1,0,670\n20100131,1,2010,31,31,1,1,0,0,0,0,0,0,6,1,0,17\n<\/code><\/pre>\n\n<p>i'm trying to predict the <code>amount_sold<\/code> for new dates (<code>date_ref<\/code>) using the following experiment on :<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/7mfhs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/7mfhs.png\" alt=\" experiment\"><\/a><\/p>\n\n<p>then i deployed the web service and tested the prediction, but all i got was zero for the <code>amount_sold<\/code> column.<\/p>\n\n<p>what may i be missing? <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to predict car sales using an Azure ML experiment, but all the predictions are returning zero."
    },
    {
        "Question_id":66291913.0,
        "Question_title":"How to perform Real Time Object Detection with trained AWS model",
        "Question_body":"<p>After successfully training object detection model with AWS SageMaker, how do I use this model to perform real time object detection on RTSP video?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1613826543790,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "amazon-web-services",
            "object-detection",
            "amazon-sagemaker"
        ],
        "Question_view_count":162.0,
        "Owner_creation_time":1597047251990,
        "Owner_last_access_time":1663796997863,
        "Owner_reputation":139.0,
        "Owner_up_votes":11.0,
        "Owner_down_votes":0.0,
        "Owner_views":46.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66291913",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to perform real time object detection with trained aws model; content:<p>after successfully training object detection model with , how do i use this model to perform real time object detection on rtsp video?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to use the trained AWS model to perform real time object detection on an RTSP video."
    },
    {
        "Question_id":55410462.0,
        "Question_title":"Hyper parameter tuning for Random cut forest",
        "Question_body":"<p>I have used to below hyper parameters to train the model.<\/p>\n\n<pre><code>  rcf.set_hyperparameters(\n        num_samples_per_tree=200,\n        num_trees=250,\n        feature_dim=1,\n        eval_metrics =[\"accuracy\", \"precision_recall_fscore\"])\n<\/code><\/pre>\n\n<p>is there any best way to choose the num_samples_per_tree and  num_trees parameters.<\/p>\n\n<p>what are the best numbers for both num_samples_per_tree and num_trees.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1553833294783,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":642.0,
        "Owner_creation_time":1502991014790,
        "Owner_last_access_time":1610089323012,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":22.0,
        "Answer_body":"<p>There are natural interpretations for these two hyper-parameters that can help you determine good starting approximations for HPO:<\/p>\n\n<ul>\n<li><code>num_samples_per_tree<\/code> -- the reciprocal of this value approximates the density of anomalies in your data set\/stream. For example, if you set this to <code>200<\/code> then the assumption is that approximately 0.5% of the data is anomalous. Try exploring your dataset to make an educated estimate.<\/li>\n<li><code>num_trees<\/code> -- the more trees in your RCF model the less noise in scores. That is, if more trees are reporting that the input inference point is an anomaly then the point is much more likely to be an anomaly than if few trees suggest so.<\/li>\n<\/ul>\n\n<p>The total number of points sampled from the input dataset is equal to <code>num_samples_per_tree * num_trees<\/code>. You should make sure that the input training set is at least this size.<\/p>\n\n<p><em>(Disclosure - I <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/use-the-built-in-amazon-sagemaker-random-cut-forest-algorithm-for-anomaly-detection\/\" rel=\"nofollow noreferrer\">helped create<\/a> SageMaker Random Cut Forest)<\/em><\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_time":1555436380768,
        "Answer_score":1.0,
        "Owner_location":"India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55410462",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: hyper parameter tuning for random cut forest; content:<p>i have used to below hyper parameters to train the model.<\/p>\n\n<pre><code>  rcf.set_hyperparameters(\n        num_samples_per_tree=200,\n        num_trees=250,\n        feature_dim=1,\n        eval_metrics =[\"accuracy\", \"precision_recall_fscore\"])\n<\/code><\/pre>\n\n<p>is there any best way to choose the num_samples_per_tree and  num_trees parameters.<\/p>\n\n<p>what are the best numbers for both num_samples_per_tree and num_trees.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for the best way to choose the hyperparameters for their Random Cut Forest model, and what the best numbers for num_samples_per_tree and num_trees are."
    },
    {
        "Question_id":51910607.0,
        "Question_title":"How to use a PySpark UDF in a Scala Spark project?",
        "Question_body":"<p>Several people (<a href=\"https:\/\/stackoverflow.com\/questions\/41780141\/using-a-scala-udf-in-pyspark\">1<\/a>, <a href=\"https:\/\/medium.com\/wbaa\/using-scala-udfs-in-pyspark-b70033dd69b9\" rel=\"nofollow noreferrer\">2<\/a>, <a href=\"https:\/\/github.com\/amesar\/spark-python-scala-udf\" rel=\"nofollow noreferrer\">3<\/a>) have discussed using a Scala UDF in a PySpark application, usually for performance reasons.  I am interested in the opposite - using a python UDF in a Scala Spark project.<\/p>\n\n<p>I am particularly interested in building a model using sklearn (and <a href=\"https:\/\/databricks.com\/blog\/2018\/06\/05\/introducing-mlflow-an-open-source-machine-learning-platform.html\" rel=\"nofollow noreferrer\">MLFlow<\/a>) then efficiently applying that to records in a Spark streaming job.  I know I could also host the python model behind a REST API and <a href=\"https:\/\/stackoverflow.com\/questions\/41799578\/restapi-service-call-from-spark-streaming\">make calls to that API in the Spark streaming application<\/a> in <a href=\"https:\/\/spark.apache.org\/docs\/2.3.0\/api\/scala\/index.html#org.apache.spark.sql.Dataset@mapPartitions[U](f:org.apache.spark.api.java.function.MapPartitionsFunction[T,U],encoder:org.apache.spark.sql.Encoder[U]):org.apache.spark.sql.Dataset[U]\" rel=\"nofollow noreferrer\"><code>mapPartitions<\/code><\/a>, but managing concurrency for that task and setting up the API for hosted model isn't something I'm super excited about.<\/p>\n\n<p>Is this possible without too much custom development with something like Py4J? Is this just a bad idea?<\/p>\n\n\n\n<p>Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":10.0,
        "Question_creation_time":1534609811997,
        "Question_favorite_count":3.0,
        "Question_score":11.0,
        "Question_tags":[
            "scala",
            "apache-spark",
            "pyspark",
            "py4j",
            "mlflow"
        ],
        "Question_view_count":1100.0,
        "Owner_creation_time":1307578819472,
        "Owner_last_access_time":1663303813416,
        "Owner_reputation":8549.0,
        "Owner_up_votes":777.0,
        "Owner_down_votes":0.0,
        "Owner_views":393.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Atlanta, GA, United States",
        "Question_last_edit_time":1575115357760,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51910607",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to use a pyspark udf in a scala spark project?; content:<p>several people (<a href=\"https:\/\/stackoverflow.com\/questions\/41780141\/using-a-scala-udf-in-pyspark\">1<\/a>, <a href=\"https:\/\/medium.com\/wbaa\/using-scala-udfs-in-pyspark-b70033dd69b9\" rel=\"nofollow noreferrer\">2<\/a>, <a href=\"https:\/\/github.com\/amesar\/spark-python-scala-udf\" rel=\"nofollow noreferrer\">3<\/a>) have discussed using a scala udf in a pyspark application, usually for performance reasons.  i am interested in the opposite - using a python udf in a scala spark project.<\/p>\n\n<p>i am particularly interested in building a model using sklearn (and <a href=\"https:\/\/databricks.com\/blog\/2018\/06\/05\/introducing--an-open-source-machine-learning-platform.html\" rel=\"nofollow noreferrer\"><\/a>) then efficiently applying that to records in a spark streaming job.  i know i could also host the python model behind a rest api and <a href=\"https:\/\/stackoverflow.com\/questions\/41799578\/restapi-service-call-from-spark-streaming\">make calls to that api in the spark streaming application<\/a> in <a href=\"https:\/\/spark.apache.org\/docs\/2.3.0\/api\/scala\/index.html#org.apache.spark.sql.dataset@mappartitions[u](f:org.apache.spark.api.java.function.mappartitionsfunction[t,u],encoder:org.apache.spark.sql.encoder[u]):org.apache.spark.sql.dataset[u]\" rel=\"nofollow noreferrer\"><code>mappartitions<\/code><\/a>, but managing concurrency for that task and setting up the api for hosted model isn't something i'm super excited about.<\/p>\n\n<p>is this possible without too much custom development with something like py4j? is this just a bad idea?<\/p>\n\n\n\n<p>thanks!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is interested in using a Python UDF in a Scala Spark project, and is looking for a way to do this without too much custom development."
    },
    {
        "Question_id":null,
        "Question_title":"Failed to install python 3.5",
        "Question_body":"I need a conda environment with python 3.5.\n\nWhile I was creating one, it showed in the specification that python 3.5 would be installed. But after the environment was created, python version was 3.8 instead of python 3.5 (pls. see the screenshot below)\nI tried to create a new env with python 3.5 twice, but always python 3.8 in the end.\n\nI found someone had similar issue here, but I didn't find solution to this issue.\n\nCan someone explain why it happens? Thanks!",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1636717036753,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/625123\/failed-to-install-python-35.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-19T11:53:13.773Z",
                "Answer_score":1,
                "Answer_body":"Hi @YutongTie-MSFT , I just want to do a short update. Though I don't know, if someone maybe has fixed this problem on the last days (if yes, thanks!), the python version in the environment that I showed above is magically python 3.5 instead of python 3.8.5...\nIn order to test, I just created another env with python=3.5 and it succeeded this time.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: failed to install python 3.5; content:i need a conda environment with python 3.5.\n\nwhile i was creating one, it showed in the specification that python 3.5 would be installed. but after the environment was created, python version was 3.8 instead of python 3.5 (pls. see the screenshot below)\ni tried to create a new env with python 3.5 twice, but always python 3.8 in the end.\n\ni found someone had similar issue here, but i didn't find solution to this issue.\n\ncan someone explain why it happens? thanks!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to install Python 3.5 in a conda environment and has tried twice with the same result of Python 3.8 being installed instead."
    },
    {
        "Question_id":71763407.0,
        "Question_title":"Set artifact name when using kfp dsl.importer",
        "Question_body":"<p>When importing an artifact using the kfp <code>dsl.importer()<\/code> function, the imported artifact gets the default (display) name <code>artifact<\/code>. I would like to give it a custom name to make the pipeline and lineage tracking more clear. I checked the <a href=\"https:\/\/kubeflow-pipelines.readthedocs.io\/en\/latest\/source\/kfp.dsl.html#kfp.dsl.importer\" rel=\"nofollow noreferrer\">documentation<\/a>, but I can't seem to find a way to change the name of the artifact that the <code>dsl.importer()<\/code> function produces.<\/p>\n<p>Example code <code>dsl.importer()<\/code>:<\/p>\n<pre><code>    load_dataset_step = dsl.importer(\n        artifact_uri=input_data_uri,\n        artifact_class=dsl.Dataset,\n        reimport=False\n    ).set_display_name(&quot;Load Dataset&quot;)\n<\/code><\/pre>\n<p>Visualisation of the <code>dsl.importer()<\/code> step:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/b4Qx6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/b4Qx6.png\" alt=\"pipelines visualisation\" \/><\/a><\/p>\n<p>I'm making use of Google Cloud Vertex AI Pipelines.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_creation_time":1649233510080,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "kubeflow",
            "kubeflow-pipelines",
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":158.0,
        "Owner_creation_time":1353508925387,
        "Owner_last_access_time":1663854791916,
        "Owner_reputation":383.0,
        "Owner_up_votes":100.0,
        "Owner_down_votes":8.0,
        "Owner_views":132.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Belgium",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71763407",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: set artifact name when using kfp dsl.importer; content:<p>when importing an artifact using the kfp <code>dsl.importer()<\/code> function, the imported artifact gets the default (display) name <code>artifact<\/code>. i would like to give it a custom name to make the pipeline and lineage tracking more clear. i checked the <a href=\"https:\/\/kubeflow-pipelines.readthedocs.io\/en\/latest\/source\/kfp.dsl.html#kfp.dsl.importer\" rel=\"nofollow noreferrer\">documentation<\/a>, but i can't seem to find a way to change the name of the artifact that the <code>dsl.importer()<\/code> function produces.<\/p>\n<p>example code <code>dsl.importer()<\/code>:<\/p>\n<pre><code>    load_dataset_step = dsl.importer(\n        artifact_uri=input_data_uri,\n        artifact_class=dsl.dataset,\n        reimport=false\n    ).set_display_name(&quot;load dataset&quot;)\n<\/code><\/pre>\n<p>visualisation of the <code>dsl.importer()<\/code> step:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/b4qx6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/b4qx6.png\" alt=\"pipelines visualisation\" \/><\/a><\/p>\n<p>i'm making use of google cloud  pipelines.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to set a custom name for an artifact imported using the kfp dsl.importer() function, as the default name is \"artifact\" and this makes pipeline and lineage tracking more difficult."
    },
    {
        "Question_id":73110661.0,
        "Question_title":"'create' is misspelled or not recognized by the system on az ml dataset create",
        "Question_body":"<p>I'm trying to create a dataset on my azure ML workspace from a GitHub action<\/p>\n<p>I've created a datastore and uploaded data to that datastore\nwhen I try to create a dataset using the cli, I get this error:<\/p>\n<p><code>'create' is misspelled or not recognized by the system.<\/code><\/p>\n<p>this is the command i use:<\/p>\n<pre><code>&gt; az ml dataset create \n          -n insurance_dataset \n          --resource-group rg-name \n          --workspace-name ml-ws-name \n          -p 'file:azureml\/datastore\/$(az ml datastore show-default -w ml-ws-name -g rg-name --query name -o tsv)\/insurance\/insurance.csv'\n<\/code><\/pre>\n<p>any idea what am I doing wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_creation_time":1658758142813,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "azure-cli",
            "azure-machine-learning-service",
            "azuremlsdk"
        ],
        "Question_view_count":237.0,
        "Owner_creation_time":1523192621643,
        "Owner_last_access_time":1663869905612,
        "Owner_reputation":1229.0,
        "Owner_up_votes":407.0,
        "Owner_down_votes":11.0,
        "Owner_views":175.0,
        "Answer_body":"<p>in my case, the issue was solved by upgrading the ml extension to <code>azure-cli-ml v2<\/code><\/p>\n<p>Remove any existing installation of the of <code>ml<\/code> extension and also the CLI v1 <code>azure-cli-ml<\/code> extension:<\/p>\n<pre><code>az extension remove -n azure-cli-ml\naz extension remove -n ml\n<\/code><\/pre>\n<p>Now, install the ml extension:<\/p>\n<pre><code>az extension add -n ml -y\n<\/code><\/pre>\n<p>which still doesn't explain why the <code>create<\/code> command wasn't recognized, but the v2 behavior works fine for me.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1658774288592,
        "Answer_score":0.0,
        "Owner_location":"Israel",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73110661",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: 'create' is misspelled or not recognized by the system on az ml dataset create; content:<p>i'm trying to create a dataset on my  workspace from a github action<\/p>\n<p>i've created a datastore and uploaded data to that datastore\nwhen i try to create a dataset using the cli, i get this error:<\/p>\n<p><code>'create' is misspelled or not recognized by the system.<\/code><\/p>\n<p>this is the command i use:<\/p>\n<pre><code>&gt; az ml dataset create \n          -n insurance_dataset \n          --resource-group rg-name \n          --workspace-name ml-ws-name \n          -p 'file:\/datastore\/$(az ml datastore show-default -w ml-ws-name -g rg-name --query name -o tsv)\/insurance\/insurance.csv'\n<\/code><\/pre>\n<p>any idea what am i doing wrong?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when trying to create a dataset on their Azure ML workspace from a GitHub action, indicating that the command 'create' is misspelled or not recognized by the system."
    },
    {
        "Question_id":61248115.0,
        "Question_title":"how to deploy the custom model in amazon sageMaker",
        "Question_body":"<p>I am newbie to AWS sagemaker, I am trying to  deploy the time series custom  lstm model in sagemaker , please help me out and  how to perpare the script mode.\nthis  my script file <strong>timer_series.py<\/strong> code. <\/p>\n\n<pre><code>import sagemaker\nimport boto3\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n\nfrom sklearn.metrics import mean_squared_error\n\n\nif __name__ =='__main__':\n\n    parser.add_argument('--epochs', type=int, default=50)\n    parser.add_argument('--batch_size', type=int, default=72)\n    parser.add_argument('--n_train_hours', type=int, default=24*365*2)\n    parser.add_argument('--n_validation_hours', type=int, default=24*365*4)\n\n    # input data and model directories\n    parser.add_argument('--model_dir', type=str)\n\n    args, _ = parser.parse_known_args()\n\n    train_dataset_dir = os.environ.get('SM_INPUT_DIR') + '\/data\/training\/' \n    output_model_dir = os.environ.get('SM_MODEL_DIR')\n    output_object_dir = os.environ.get('SM_OUTPUT_DATA_DIR')\n\n    epochs = args.epochs\n    batch_size = args.batch_size\n    input_data = {args.input_data}\n    dataset = read_csv( train_dataset_dir + 'dataset.csv', header=0, index_col='Date')\n    dataset.sort_index(inplace=True)\n    train = dataset.iloc[:109]\n    test= dataset.iloc[109:]  \n    scaler = MinMaxScaler()\n    scaled_train = scaler.fit_transform(train)\n    scaled_test=scaler.fit_transform(test)\n    n_input = 12\n    n_feature = 1\n\n    train_generator = TimeseriesGenerator(scaled_train,scaled_train,length=n_input, batch_size=1)\n\n    model = Sequential()\n\n    model.add(LSTM(128,activation = 'relu', input_shape= (n_input, n_feature), return_sequences=True))\n    model.add(LSTM(128, activation='relu', return_sequences=True))\n    model.add(LSTM(128, activation='relu', return_sequences=False))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    history =model.fit_generator(train_generator,epochs=50, batch_size=1,verbose=1)\n\n# Get a SageMaker-compatible role used by this Notebook Instance.\n    role = get_execution_role()\n    with open(output_model_dir + '\/history.json', 'w') as f:\n         json.dump(history.history, f)\n    #Save the Scaler\n    dump(scaler, output_model_dir + '\/scaler.model', protocol=2) \n    #Save the trained model and weights\n    model_json = model.to_json()\n    with open(output_model_dir + \"\/model.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    model.save_weights(output_model_dir + \"\/model.h5\")\n<\/code><\/pre>\n\n<p>here it showing some error:<\/p>\n\n<pre><code> train_instance_type = \"ml.m4.xlarg\"\n\ntf_estimator = TensorFlow(entry_point='time_series.py', role=get_execution_role(),\n                          train_instance_count=1, train_instance_type=train_instance_type,\n                          framework_version='1.12', py_version='py3', script_mode=True,\n                          output_path = 's3:\/\/' + s3Bucket, base_job_name = \"sales-forecasting-lstm\",\n                         hyperparameters={'batch_size': 2,\n                                           'epochs': 50})\n\ntf_estimator.fit(uploaded_data_path)\n<\/code><\/pre>\n\n<p>Here I got the error. what this error , I didn't understand this error.<\/p>\n\n<pre><code>UnexpectedStatusException: Error for Training job sales-forecasting-lstm-2020-04-13-10-17-34-919: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"\/usr\/bin\/python time_series.py --batch_size 2 --epochs 50 --model_dir s3:\/\/sagemaker12\/sales-forecasting-lstm-2020-04-13-10-17-34-919\/model\"\n\n\u200b\n<\/code><\/pre>\n\n<p>Hi, I am newbie to AWS sagemaker, I am trying to  deploy the time series custom  lstm model in sagemaker , please help me out and  how to perpare the script mode , python script  for deployment.\nthis  my script file <strong>timer_series.py<\/strong> code. <\/p>\n\n<pre><code>import sagemaker\nimport boto3\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n\nfrom sklearn.metrics import mean_squared_error\n\n\nif __name__ =='__main__':\n\n    parser.add_argument('--epochs', type=int, default=50)\n    parser.add_argument('--batch_size', type=int, default=72)\n    parser.add_argument('--n_train_hours', type=int, default=24*365*2)\n    parser.add_argument('--n_validation_hours', type=int, default=24*365*4)\n\n    # input data and model directories\n    parser.add_argument('--model_dir', type=str)\n\n    args, _ = parser.parse_known_args()\n\n    train_dataset_dir = os.environ.get('SM_INPUT_DIR') + '\/data\/training\/' \n    output_model_dir = os.environ.get('SM_MODEL_DIR')\n    output_object_dir = os.environ.get('SM_OUTPUT_DATA_DIR')\n\n    epochs = args.epochs\n    batch_size = args.batch_size\n    input_data = {args.input_data}\n    dataset = read_csv( input_data + 'dataset.csv', header=0, index_col='Date')\n    dataset.sort_index(inplace=True)\n    train = dataset.iloc[:109]\n    test= dataset.iloc[109:]  \n    scaler = MinMaxScaler()\n    scaled_train = scaler.fit_transform(train)\n    scaled_test=scaler.fit_transform(test)\n    n_input = 12\n    n_feature = 1\n\n    train_generator = TimeseriesGenerator(scaled_train,scaled_train,length=n_input, batch_size=1)\n\n    model = Sequential()\n\n    model.add(LSTM(128,activation = 'relu', input_shape= (n_input, n_feature), return_sequences=True))\n    model.add(LSTM(128, activation='relu', return_sequences=True))\n    model.add(LSTM(128, activation='relu', return_sequences=False))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    history =model.fit_generator(train_generator,epochs=50, batch_size=1,verbose=1)\n\n# Get a SageMaker-compatible role used by this Notebook Instance.\n    role = get_execution_role()\n    with open(output_model_dir + '\/history.json', 'w') as f:\n         json.dump(history.history, f)\n    #Save the Scaler\n    dump(scaler, output_model_dir + '\/scaler.model', protocol=2) \n    #Save the trained model and weights\n    model_json = model.to_json()\n    with open(output_model_dir + \"\/model.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    model.save_weights(output_model_dir + \"\/model.h5\")\n<\/code><\/pre>\n\n<p>here it showing some error:<\/p>\n\n<pre><code> train_instance_type = \"ml.m4.xlarg\"\n\ntf_estimator = TensorFlow(entry_point='time_series.py', role=get_execution_role(),\n                          train_instance_count=1, train_instance_type=train_instance_type,\n                          framework_version='1.12', py_version='py3', script_mode=True,\n                          output_path = 's3:\/\/' + s3Bucket, base_job_name = \"sales-forecasting-lstm\",\n                         hyperparameters={'batch_size': 2,\n                                           'epochs': 50})\n\ntf_estimator.fit(uploaded_data_path)\n<\/code><\/pre>\n\n<p>Here I got the error. what this error , I didn't understand this error.<\/p>\n\n<pre><code>UnexpectedStatusException: Error for Training job sales-forecasting-lstm-2020-04-13-10-17-34-919: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"\/usr\/bin\/python time_series.py --batch_size 2 --epochs 50 --model_dir s3:\/\/sagemaker12\/sales-forecasting-lstm-2020-04-13-10-17-34-919\/model\"\n\n\u200b\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":7.0,
        "Question_creation_time":1587033215170,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":710.0,
        "Owner_creation_time":1583415050007,
        "Owner_last_access_time":1646745705963,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Bangalore, Karnataka, India",
        "Question_last_edit_time":1587130825143,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61248115",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to deploy the custom model in ; content:<p>i am newbie to , i am trying to  deploy the time series custom  lstm model in  , please help me out and  how to perpare the script mode.\nthis  my script file <strong>timer_series.py<\/strong> code. <\/p>\n\n<pre><code>import \nimport boto3\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow \nfrom tensorflow.keras.models import sequential\nfrom tensorflow.keras.layers import dense\nfrom tensorflow.keras.layers import lstm\nfrom sklearn.preprocessing import minmaxscaler\nfrom tensorflow.keras.preprocessing.sequence import timeseriesgenerator\n\nfrom sklearn.metrics import mean_squared_error\n\n\nif __name__ =='__main__':\n\n    parser.add_argument('--epochs', type=int, default=50)\n    parser.add_argument('--batch_size', type=int, default=72)\n    parser.add_argument('--n_train_hours', type=int, default=24*365*2)\n    parser.add_argument('--n_validation_hours', type=int, default=24*365*4)\n\n    # input data and model directories\n    parser.add_argument('--model_dir', type=str)\n\n    args, _ = parser.parse_known_args()\n\n    train_dataset_dir = os.environ.get('sm_input_dir') + '\/data\/training\/' \n    output_model_dir = os.environ.get('sm_model_dir')\n    output_object_dir = os.environ.get('sm_output_data_dir')\n\n    epochs = args.epochs\n    batch_size = args.batch_size\n    input_data = {args.input_data}\n    dataset = read_csv( train_dataset_dir + 'dataset.csv', header=0, index_col='date')\n    dataset.sort_index(inplace=true)\n    train = dataset.iloc[:109]\n    test= dataset.iloc[109:]  \n    scaler = minmaxscaler()\n    scaled_train = scaler.fit_transform(train)\n    scaled_test=scaler.fit_transform(test)\n    n_input = 12\n    n_feature = 1\n\n    train_generator = timeseriesgenerator(scaled_train,scaled_train,length=n_input, batch_size=1)\n\n    model = sequential()\n\n    model.add(lstm(128,activation = 'relu', input_shape= (n_input, n_feature), return_sequences=true))\n    model.add(lstm(128, activation='relu', return_sequences=true))\n    model.add(lstm(128, activation='relu', return_sequences=false))\n    model.add(dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    history =model.fit_generator(train_generator,epochs=50, batch_size=1,verbose=1)\n\n# get a -compatible role used by this notebook instance.\n    role = get_execution_role()\n    with open(output_model_dir + '\/history.json', 'w') as f:\n         json.dump(history.history, f)\n    #save the scaler\n    dump(scaler, output_model_dir + '\/scaler.model', protocol=2) \n    #save the trained model and weights\n    model_json = model.to_json()\n    with open(output_model_dir + \"\/model.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    model.save_weights(output_model_dir + \"\/model.h5\")\n<\/code><\/pre>\n\n<p>here it showing some error:<\/p>\n\n<pre><code> train_instance_type = \"ml.m4.xlarg\"\n\ntf_estimator = tensorflow(entry_point='time_series.py', role=get_execution_role(),\n                          train_instance_count=1, train_instance_type=train_instance_type,\n                          framework_version='1.12', py_version='py3', script_mode=true,\n                          output_path = 's3:\/\/' + s3bucket, base_job_name = \"sales-forecasting-lstm\",\n                         hyperparameters={'batch_size': 2,\n                                           'epochs': 50})\n\ntf_estimator.fit(uploaded_data_path)\n<\/code><\/pre>\n\n<p>here i got the error. what this error , i didn't understand this error.<\/p>\n\n<pre><code>unexpectedstatusexception: error for training job sales-forecasting-lstm-2020-04-13-10-17-34-919: failed. reason: algorithmerror: executeuserscripterror:\ncommand \"\/usr\/bin\/python time_series.py --batch_size 2 --epochs 50 --model_dir s3:\/\/12\/sales-forecasting-lstm-2020-04-13-10-17-34-919\/model\"\n\n\u200b\n<\/code><\/pre>\n\n<p>hi, i am newbie to , i am trying to  deploy the time series custom  lstm model in  , please help me out and  how to perpare the script mode , python script  for deployment.\nthis  my script file <strong>timer_series.py<\/strong> code. <\/p>\n\n<pre><code>import \nimport boto3\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow \nfrom tensorflow.keras.models import sequential\nfrom tensorflow.keras.layers import dense\nfrom tensorflow.keras.layers import lstm\nfrom sklearn.preprocessing import minmaxscaler\nfrom tensorflow.keras.preprocessing.sequence import timeseriesgenerator\n\nfrom sklearn.metrics import mean_squared_error\n\n\nif __name__ =='__main__':\n\n    parser.add_argument('--epochs', type=int, default=50)\n    parser.add_argument('--batch_size', type=int, default=72)\n    parser.add_argument('--n_train_hours', type=int, default=24*365*2)\n    parser.add_argument('--n_validation_hours', type=int, default=24*365*4)\n\n    # input data and model directories\n    parser.add_argument('--model_dir', type=str)\n\n    args, _ = parser.parse_known_args()\n\n    train_dataset_dir = os.environ.get('sm_input_dir') + '\/data\/training\/' \n    output_model_dir = os.environ.get('sm_model_dir')\n    output_object_dir = os.environ.get('sm_output_data_dir')\n\n    epochs = args.epochs\n    batch_size = args.batch_size\n    input_data = {args.input_data}\n    dataset = read_csv( input_data + 'dataset.csv', header=0, index_col='date')\n    dataset.sort_index(inplace=true)\n    train = dataset.iloc[:109]\n    test= dataset.iloc[109:]  \n    scaler = minmaxscaler()\n    scaled_train = scaler.fit_transform(train)\n    scaled_test=scaler.fit_transform(test)\n    n_input = 12\n    n_feature = 1\n\n    train_generator = timeseriesgenerator(scaled_train,scaled_train,length=n_input, batch_size=1)\n\n    model = sequential()\n\n    model.add(lstm(128,activation = 'relu', input_shape= (n_input, n_feature), return_sequences=true))\n    model.add(lstm(128, activation='relu', return_sequences=true))\n    model.add(lstm(128, activation='relu', return_sequences=false))\n    model.add(dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    history =model.fit_generator(train_generator,epochs=50, batch_size=1,verbose=1)\n\n# get a -compatible role used by this notebook instance.\n    role = get_execution_role()\n    with open(output_model_dir + '\/history.json', 'w') as f:\n         json.dump(history.history, f)\n    #save the scaler\n    dump(scaler, output_model_dir + '\/scaler.model', protocol=2) \n    #save the trained model and weights\n    model_json = model.to_json()\n    with open(output_model_dir + \"\/model.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    model.save_weights(output_model_dir + \"\/model.h5\")\n<\/code><\/pre>\n\n<p>here it showing some error:<\/p>\n\n<pre><code> train_instance_type = \"ml.m4.xlarg\"\n\ntf_estimator = tensorflow(entry_point='time_series.py', role=get_execution_role(),\n                          train_instance_count=1, train_instance_type=train_instance_type,\n                          framework_version='1.12', py_version='py3', script_mode=true,\n                          output_path = 's3:\/\/' + s3bucket, base_job_name = \"sales-forecasting-lstm\",\n                         hyperparameters={'batch_size': 2,\n                                           'epochs': 50})\n\ntf_estimator.fit(uploaded_data_path)\n<\/code><\/pre>\n\n<p>here i got the error. what this error , i didn't understand this error.<\/p>\n\n<pre><code>unexpectedstatusexception: error for training job sales-forecasting-lstm-2020-04-13-10-17-34-919: failed. reason: algorithmerror: executeuserscripterror:\ncommand \"\/usr\/bin\/python time_series.py --batch_size 2 --epochs 50 --model_dir s3:\/\/12\/sales-forecasting-lstm-2020-04-13-10-17-34-919\/model\"\n\n\u200b\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to deploy a custom LSTM model in and is having difficulty preparing the script mode. They are receiving an error when running the script and are unsure of what the error means."
    },
    {
        "Question_id":null,
        "Question_title":"MLOps For Python with R code",
        "Question_body":"Hello Azure MLOps Team,\n\nI am looking at the reference architecture https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/reference-architectures\/ai\/mlops-python.\n\nMost of our data science models are made in R. I am wondering, which part of the MLOps process (Azure Pipelines or Azure ML Compute\/Azure ML Pipelines) can be configured in Python for R code to run?\n\nOur preference is to leverage as much Python as possible for the code R code. I see there is an Azure ML SDK for python and R. Can we use Azure ML SDK in Python with R codebase?\n\nKind regards,\nSlava Keshkov",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_creation_time":1613119407860,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/270615\/mlops-for-python-with-r-code.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-13T20:25:30.677Z",
                "Answer_score":0,
                "Answer_body":"Hi Slava,\n\nI found this for you: https:\/\/rstudio.com\/resources\/rstudioconf-2020\/mlops-for-r-with-azure-machine-learning\/\n\nIn the video David is talking about Devops for R at 10:58. Why dont you ping David on Twitter to inquire more about it? If Microsoft is not able to support it officially I think you can build your own pipelines deploying models within AKS and using Azure storage with Azure Functions for pushing data to the model and pulling out forcasts.\n\nHope this helps.\n\nThanks,\nVaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-19T23:31:16.65Z",
                "Answer_score":0,
                "Answer_body":"Here's the azureml sdk for R repo for your reference.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: mlops for python with r code; content:hello ops team,\n\ni am looking at the reference architecture https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/reference-architectures\/ai\/mlops-python.\n\nmost of our data science models are made in r. i am wondering, which part of the mlops process (azure pipelines or  compute\/ pipelines) can be configured in python for r code to run?\n\nour preference is to leverage as much python as possible for the code r code. i see there is an  sdk for python and r. can we use  sdk in python with r codebase?\n\nkind regards,\nslava keshkov",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking to use Azure ML SDK in Python with an R codebase to run their data science models, and is wondering which part of the MLOps process can be configured in Python for R code to run."
    },
    {
        "Question_id":70603137.0,
        "Question_title":"Is it possible to integrate AWS sagemaker and delta lake",
        "Question_body":"<p>Is it possible to integrate AWS sage maker and delta lake?<\/p>\n<p>thanks\nRamabadran<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1641448912433,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-sagemaker",
            "delta-lake"
        ],
        "Question_view_count":174.0,
        "Owner_creation_time":1627004194367,
        "Owner_last_access_time":1662959987232,
        "Owner_reputation":23.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":"<p>Yes, though it depends on what part of SageMaker you mean (Training, Notebook, Inference, etc).<\/p>\n<p>Last week, an integration between SageMaker and Delta Lake was documented here (custom docker in the SageMaker Processing API)<\/p>\n<p><a href=\"https:\/\/github.com\/eitansela\/sagemaker-delta-sharing-demo\/tree\/main\/delta_lake_bring_your_own_container_processing\" rel=\"nofollow noreferrer\">https:\/\/github.com\/eitansela\/sagemaker-delta-sharing-demo\/tree\/main\/delta_lake_bring_your_own_container_processing<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1641839983127,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70603137",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is it possible to integrate  and delta lake; content:<p>is it possible to integrate aws sage maker and delta lake?<\/p>\n<p>thanks\nramabadran<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to integrate AWS Sage Maker and Delta Lake."
    },
    {
        "Question_id":null,
        "Question_title":"Confirmation page \/ custom text",
        "Question_body":"Hi All,I'm just migrating over from AWS to CX, and so far I think its great. However - the tutorial section I'm working through kind of hit a 'draw the rest of the owl' meme - if you don't know it, look it up.The difficult bit is where it gets to 'confirmation page' in the quick start - here: ",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1666408980000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":36.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Confirmation-page-custom-text\/td-p\/480915\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "AI ML General",
            "Dialogflow CX"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-25T13:34:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"In order to fulfill the create confirmation page step, you could follow the instructions given in the Create the location page section.\n\nIn order to get the example working, please double check that all steps are completed and the variable names are the same as used in order to test the completed agent.\n\nThis article could be helpful to create A Conversational Agent with Dialogflow.\n\nSome important concepts used in the quickstart:\n\nIntent\nParameters\nEntity types\nSession parameters\nConditions"
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: confirmation page \/ custom text; content:hi all,i'm just migrating over from aws to cx, and so far i think its great. however - the tutorial section i'm working through kind of hit a 'draw the rest of the owl' meme - if you don't know it, look it up.the difficult bit is where it gets to 'confirmation page' in the quick start - here: ",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty understanding the tutorial section on creating a confirmation page and is looking for more guidance."
    },
    {
        "Question_id":49775557.0,
        "Question_title":"How can I invoke a SageMaker model, trained with TensorFlow, using a csv file in the body of the call?",
        "Question_body":"<p>I have deployed a TensorFlow model on AWS SageMaker, and I want to be able to invoke it using a csv file as the body of the call. The documentation says about creating a <code>serving_input_function<\/code> like the one below: <\/p>\n\n<pre><code>def serving_input_fn(hyperparameters):\n  # Logic to the following:\n  # 1. Defines placeholders that TensorFlow serving will feed with inference requests\n  # 2. Preprocess input data\n  # 3. Returns a tf.estimator.export.ServingInputReceiver or tf.estimator.export.TensorServingInputReceiver,\n  # which packages the placeholders and the resulting feature Tensors together.\n<\/code><\/pre>\n\n<p>In step 2, where it says preprocess input data, how do I get a handle on input data to process them?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1523450778890,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "tensorflow",
            "amazon-sagemaker"
        ],
        "Question_view_count":1249.0,
        "Owner_creation_time":1423231864696,
        "Owner_last_access_time":1555605940390,
        "Owner_reputation":1109.0,
        "Owner_up_votes":29.0,
        "Owner_down_votes":0.0,
        "Owner_views":157.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Athens, Greece",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49775557",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how can i invoke a  model, trained with tensorflow, using a csv file in the body of the call?; content:<p>i have deployed a tensorflow model on , and i want to be able to invoke it using a csv file as the body of the call. the documentation says about creating a <code>serving_input_function<\/code> like the one below: <\/p>\n\n<pre><code>def serving_input_fn(hyperparameters):\n  # logic to the following:\n  # 1. defines placeholders that tensorflow serving will feed with inference requests\n  # 2. preprocess input data\n  # 3. returns a tf.estimator.export.servinginputreceiver or tf.estimator.export.tensorservinginputreceiver,\n  # which packages the placeholders and the resulting feature tensors together.\n<\/code><\/pre>\n\n<p>in step 2, where it says preprocess input data, how do i get a handle on input data to process them?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to create a serving_input_function to preprocess the input data from the csv file in order to invoke the model."
    },
    {
        "Question_id":42145256.0,
        "Question_title":"Share dataset between two azureml environnement",
        "Question_body":"<p>a friend have sent me a python3 notebook with his dataset to validate his notebook.<\/p>\n\n<p>but when i try to use his dataset on my azureml workspace i have an error saying that the dataset does not exist<\/p>\n\n<p>he sent me his datset code :<\/p>\n\n<pre><code>from azureml import Workspace\n\nws = Workspace(\n    workspace_id='toto',\n    authorization_token='titi',\n    endpoint='https:\/\/studioapi.azureml.net'\n)\nds = ws.datasets['mini.csv00']\nframe = ds.to_dataframe()\n\nframe\n<\/code><\/pre>\n\n<p>when i try to use it i have a :<\/p>\n\n<pre><code>ndexError                                Traceback (most recent call last)\n&lt;ipython-input-7-5f41120e38e4&gt; in &lt;module&gt;()\n----&gt; 1 ds = ws.datasets['mini.csv00']\n      2 frame = ds.to_dataframe()\n      3 \n      4 frame\n\n\/home\/nbuser\/anaconda3_23\/lib\/python3.4\/site-packages\/azureml\/__init__.py in __getitem__(self, index)\n    461                     return self._create_dataset(dataset)\n    462 \n--&gt; 463         raise IndexError('A data set named \"{}\" does not exist'.format(index))\n    464 \n    465     def add_from_dataframe(self, dataframe, data_type_id, name, description):\n\nIndexError: A data set named \"mini.csv00\" does not exist\n<\/code><\/pre>\n\n<p>error ...<\/p>\n\n<p>But when i try it on my computer jupyter it works.\nAny ideas ?<\/p>\n\n<p>Thanks and regards<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1486668512167,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "dataset",
            "jupyter",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":108.0,
        "Owner_creation_time":1280999248528,
        "Owner_last_access_time":1662904987340,
        "Owner_reputation":1048.0,
        "Owner_up_votes":199.0,
        "Owner_down_votes":1.0,
        "Owner_views":602.0,
        "Answer_body":"<p>I guess you are using Jupyter notebook on AzureML to do the experiment. In that case the <code>'mini.csv00'<\/code> should be in your experiments with <code>workspace_id='toto'<\/code>. <\/p>\n\n<p>Create a new experiment in your workspace named toto and put the dataset into it first. Then open the dataset using 'open in a new Notebook'. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ztIw0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ztIw0.png\" alt=\"enter image description here\"><\/a> <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1486875192387,
        "Answer_score":2.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42145256",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: share dataset between two  environnement; content:<p>a friend have sent me a python3 notebook with his dataset to validate his notebook.<\/p>\n\n<p>but when i try to use his dataset on my  workspace i have an error saying that the dataset does not exist<\/p>\n\n<p>he sent me his datset code :<\/p>\n\n<pre><code>from  import workspace\n\nws = workspace(\n    workspace_id='toto',\n    authorization_token='titi',\n    endpoint='https:\/\/studioapi..net'\n)\nds = ws.datasets['mini.csv00']\nframe = ds.to_dataframe()\n\nframe\n<\/code><\/pre>\n\n<p>when i try to use it i have a :<\/p>\n\n<pre><code>ndexerror                                traceback (most recent call last)\n&lt;ipython-input-7-5f41120e38e4&gt; in &lt;module&gt;()\n----&gt; 1 ds = ws.datasets['mini.csv00']\n      2 frame = ds.to_dataframe()\n      3 \n      4 frame\n\n\/home\/nbuser\/anaconda3_23\/lib\/python3.4\/site-packages\/\/__init__.py in __getitem__(self, index)\n    461                     return self._create_dataset(dataset)\n    462 \n--&gt; 463         raise indexerror('a data set named \"{}\" does not exist'.format(index))\n    464 \n    465     def add_from_dataframe(self, dataframe, data_type_id, name, description):\n\nindexerror: a data set named \"mini.csv00\" does not exist\n<\/code><\/pre>\n\n<p>error ...<\/p>\n\n<p>but when i try it on my computer jupyter it works.\nany ideas ?<\/p>\n\n<p>thanks and regards<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having an issue with a dataset that their friend sent them, which works on their computer but not in their workspace, and is receiving an IndexError."
    },
    {
        "Question_id":null,
        "Question_title":"Azure Machine Learning Errors",
        "Question_body":"Hello, I am trying to run some of the sample notebooks from Microsoft Docs for Azure Machine Learning. I am running into the following error and cannot find a workaround though this appears to be a common error that others have also encountered with no workaround. cannot import name 'AzureMLAggregatedException' from 'azureml.exceptions'",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1614300692297,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/289691\/azure-machine-learning-errors.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-05T02:51:15.36Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nIt is the explanation dashboards and the fairness dashboards and it cannot find the Lime library or its methods.\nRegards,\nAmy",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  errors; content:hello, i am trying to run some of the sample notebooks from microsoft docs for . i am running into the following error and cannot find a workaround though this appears to be a common error that others have also encountered with no workaround. cannot import name 'aggregatedexception' from '.exceptions'",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is encountering an error when trying to run sample notebooks from Microsoft docs and cannot find a workaround, as this appears to be a common error with no solution."
    },
    {
        "Question_id":63762477.0,
        "Question_title":"Kinesis Video Streams integration with Amazon SageMaker using KIT",
        "Question_body":"<p>I am working on a project where i need to send the video from my IP camera to Kinesis Video Stream, and use Sagemaker to host my ML model, which will then analyse the video from Kinesis Video Stream in real time. <br \/>\nI followed this link: <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/analyze-live-video-at-scale-in-real-time-using-amazon-kinesis-video-streams-and-amazon-sagemaker\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/analyze-live-video-at-scale-in-real-time-using-amazon-kinesis-video-streams-and-amazon-sagemaker\/<\/a> <br \/>\n<strong>I am done with these things -<\/strong><\/p>\n<ol>\n<li>Setup of IP camera and kinesis video stream to send video from IP camera to KVS<\/li>\n<li>Setup cloud formation template for KIT (as mentioned in the link)<\/li>\n<\/ol>\n<p><strong>I am stuck with this particular thing -<\/strong><\/p>\n<ol>\n<li><p>How do i get the video frames from aws fargate in the sagemaker notebook as input (as shown in below image, step 3)? In the link it is mentioned that the KIT comes pre-bundled with a custom Lambda function that is written to process the prediction output of one of the Amazon SageMaker examples using <strong><a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/blob\/master\/introduction_to_amazon_algorithms\/object_detection_pascalvoc_coco\/object_detection_image_json_format.ipynb\" rel=\"nofollow noreferrer\">Object Detection algorithm<\/a><\/strong>. I am not sure how this algorithm is taking input from KVS.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/1voCE.gif\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/1voCE.gif\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<\/ol>\n<p>Please if someone can help me out with this.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1599383271720,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-sagemaker",
            "amazon-kinesis-video-streams"
        ],
        "Question_view_count":1197.0,
        "Owner_creation_time":1476625156390,
        "Owner_last_access_time":1649992739043,
        "Owner_reputation":46.0,
        "Owner_up_votes":2.0,
        "Owner_down_votes":0.0,
        "Owner_views":19.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Deoria, Uttar Pradesh, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63762477",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: kinesis video streams integration with  using kit; content:<p>i am working on a project where i need to send the video from my ip camera to kinesis video stream, and use  to host my ml model, which will then analyse the video from kinesis video stream in real time. <br \/>\ni followed this link: <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/analyze-live-video-at-scale-in-real-time-using-amazon-kinesis-video-streams-and-amazon-\/\" rel=\"nofollow noreferrer\">https:\/\/aws.amazon.com\/blogs\/machine-learning\/analyze-live-video-at-scale-in-real-time-using-amazon-kinesis-video-streams-and-amazon-\/<\/a> <br \/>\n<strong>i am done with these things -<\/strong><\/p>\n<ol>\n<li>setup of ip camera and kinesis video stream to send video from ip camera to kvs<\/li>\n<li>setup cloud formation template for kit (as mentioned in the link)<\/li>\n<\/ol>\n<p><strong>i am stuck with this particular thing -<\/strong><\/p>\n<ol>\n<li><p>how do i get the video frames from aws fargate in the  notebook as input (as shown in below image, step 3)? in the link it is mentioned that the kit comes pre-bundled with a custom lambda function that is written to process the prediction output of one of the  examples using <strong><a href=\"https:\/\/github.com\/awslabs\/amazon--examples\/blob\/master\/introduction_to_amazon_algorithms\/object_detection_pascalvoc_coco\/object_detection_image_json_format.ipynb\" rel=\"nofollow noreferrer\">object detection algorithm<\/a><\/strong>. i am not sure how this algorithm is taking input from kvs.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/1voce.gif\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/1voce.gif\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<\/ol>\n<p>please if someone can help me out with this.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is working on a project to send video from an IP camera to Kinesis Video Stream and use Amazon SageMaker to host an ML model to analyse the video in real time. They are stuck on how to get the video frames from AWS Fargate into the notebook as input."
    },
    {
        "Question_id":null,
        "Question_title":"Dvc add: Location of .gitignore File",
        "Question_body":"<p>During <code>dvc add<\/code> the .gitingnore file is always created at the targets location (with <code>--file<\/code> the location of the .dvc file can be set but this does not seem to affect the location of the .gitignore file which is created or added to).<\/p>\n<p>This is not always desired, for example one could want a single .gitignore file in a projects root directory.<\/p>\n<ol>\n<li>\n<p>Did i miss something and there is a way to set the .gitignore file location?<\/p>\n<\/li>\n<li>\n<p>Wouldn\u2019t it be more convenient that the .gitignore location is always the same as the .dvc location (when using the <code>--file<\/code> argument)?<\/p>\n<\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1645453082147,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":264.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-add-location-of-gitignore-file\/1075",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2409,
                "name":"Peter Rowlands",
                "username":"pmrowla",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/7ab992\/{size}.png",
                "created_at":"2022-02-22T02:15:41.439Z",
                "cooked":"<p>This behavior is not currently configurable. Please feel free to open a feature request on our github regarding specifying the .gitignore location.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-02-22T02:15:41.439Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":0.8,
                "yours":false,
                "topic_id":1075,
                "topic_slug":"dvc-add-location-of-gitignore-file",
                "display_username":"Peter Rowlands",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":130,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  add: location of .gitignore file; content:<p>during <code> add<\/code> the .gitingnore file is always created at the targets location (with <code>--file<\/code> the location of the . file can be set but this does not seem to affect the location of the .gitignore file which is created or added to).<\/p>\n<p>this is not always desired, for example one could want a single .gitignore file in a projects root directory.<\/p>\n<ol>\n<li>\n<p>did i miss something and there is a way to set the .gitignore file location?<\/p>\n<\/li>\n<li>\n<p>wouldn\u2019t it be more convenient that the .gitignore location is always the same as the . location (when using the <code>--file<\/code> argument)?<\/p>\n<\/li>\n<\/ol>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if there is a way to set the location of the .gitignore file and if it would be more convenient if the .gitignore location was always the same as the . location when using the --file argument."
    },
    {
        "Question_id":null,
        "Question_title":"Azure ML real time endpoints stuck in 'Transitioning' state",
        "Question_body":"I am trying to deploy Azure ML models as webservice endpoints using an AKS cluster. I have deployed the real time inference pipeline using the Azure ML Studio interface.\nThe endpoints deploy successfully and quickly reach a \"Healthy\" state, however occasionally the deployments are stuck in the \"Transitioning\" state for indefinite time. This disables the testing for the endpoints on the portal and we are unable to consume the webservice for that period of time.\nAny idea why this might be happening, or what I can do to fix this?\nIs there a limit to the number of endpoints available on an inference cluster ?",
        "Question_answer_count":0,
        "Question_comment_count":3.0,
        "Question_creation_time":1606672254767,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-kubernetes-service",
            "azure-machine-learning-studio-classic"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/179215\/azure-ml-real-time-endpoints-stuck-in-39transition.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  real time endpoints stuck in 'transitioning' state; content:i am trying to deploy  models as webservice endpoints using an aks cluster. i have deployed the real time inference pipeline using the  studio interface.\nthe endpoints deploy successfully and quickly reach a \"healthy\" state, however occasionally the deployments are stuck in the \"transitioning\" state for indefinite time. this disables the testing for the endpoints on the portal and we are unable to consume the webservice for that period of time.\nany idea why this might be happening, or what i can do to fix this?\nis there a limit to the number of endpoints available on an inference cluster ?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to deploy Azure ML models as webservice endpoints using an AKS cluster, but the deployments are occasionally stuck in the \"transitioning\" state for indefinite time, disabling the testing for the endpoints on the portal and preventing the webservice from being consumed. They are wondering if there is a limit to the number of endpoints available on an inference cluster and what they can do to fix this issue."
    },
    {
        "Question_id":71612603.0,
        "Question_title":"How does one invert an encoded prediction in Keras for model serving?",
        "Question_body":"<p>I have a Keras model in which i have successfully added a <code>StringLookUp<\/code> pre-processing step as part of the model definition. This is generally a good practice because i can then feed it the raw data to get back a prediction.<\/p>\n<p>I am feeding the model string words that are mapped to an integer. The Y values are also string words that have been mapped to an integer.<\/p>\n<p>Here is the implementation of the encoder and decoders:<\/p>\n<pre><code>#generate the encoder and decoders\nencoder = tf.keras.layers.StringLookup(vocabulary=vocab, )\ndecoder = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode=&quot;int&quot;, invert=True)\n<\/code><\/pre>\n<p>Here is the some of the code that makes the inference model<\/p>\n<pre><code># For inference, you can export a model that accepts strings as input\ninputs = Input(shape=(6,), dtype=&quot;string&quot;)\nx = encoder(inputs)\noutputs = keras_model(x)\ninference_model = Model(inputs, outputs)\n\ninference_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \ninference_model.summary()\n<\/code><\/pre>\n<p>The <code>encoder<\/code> above is just a function that implements <code>tf.keras.layers.StringLookup<\/code><\/p>\n<p>Now, inside the notebook, I can easily convert the predictions back to the Original String representations by using a <code>decoder<\/code> which implements the reverse of <code>StringLookUp<\/code>.<\/p>\n<p><em><strong>Here's my problem<\/strong><\/em>\nWhile this works fine inside the notebook, this isn't very practical for deploying the model as a REST API because the calling program has no way of knowing how the encoded integer maps back to the original string representation.<\/p>\n<p><em><strong>So the question is what strategy should I use to implement the keras predict so that it returns the original string which I can then serialize using mlflow &amp; cloudpickle to deploy it as a servable model in databricks<\/strong><\/em><\/p>\n<p>Any guidance would be very much appreciated. I've seen a lot of example of Keras, but none that show how to do enact this kind of behavior for model deployment.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1648186526013,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "tensorflow",
            "keras",
            "deep-learning",
            "mlflow"
        ],
        "Question_view_count":176.0,
        "Owner_creation_time":1427492676943,
        "Owner_last_access_time":1663998407848,
        "Owner_reputation":61.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":18.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71612603",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how does one invert an encoded prediction in keras for model serving?; content:<p>i have a keras model in which i have successfully added a <code>stringlookup<\/code> pre-processing step as part of the model definition. this is generally a good practice because i can then feed it the raw data to get back a prediction.<\/p>\n<p>i am feeding the model string words that are mapped to an integer. the y values are also string words that have been mapped to an integer.<\/p>\n<p>here is the implementation of the encoder and decoders:<\/p>\n<pre><code>#generate the encoder and decoders\nencoder = tf.keras.layers.stringlookup(vocabulary=vocab, )\ndecoder = tf.keras.layers.stringlookup(vocabulary=vocab, output_mode=&quot;int&quot;, invert=true)\n<\/code><\/pre>\n<p>here is the some of the code that makes the inference model<\/p>\n<pre><code># for inference, you can export a model that accepts strings as input\ninputs = input(shape=(6,), dtype=&quot;string&quot;)\nx = encoder(inputs)\noutputs = keras_model(x)\ninference_model = model(inputs, outputs)\n\ninference_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \ninference_model.summary()\n<\/code><\/pre>\n<p>the <code>encoder<\/code> above is just a function that implements <code>tf.keras.layers.stringlookup<\/code><\/p>\n<p>now, inside the notebook, i can easily convert the predictions back to the original string representations by using a <code>decoder<\/code> which implements the reverse of <code>stringlookup<\/code>.<\/p>\n<p><em><strong>here's my problem<\/strong><\/em>\nwhile this works fine inside the notebook, this isn't very practical for deploying the model as a rest api because the calling program has no way of knowing how the encoded integer maps back to the original string representation.<\/p>\n<p><em><strong>so the question is what strategy should i use to implement the keras predict so that it returns the original string which i can then serialize using  &amp; cloudpickle to deploy it as a servable model in databricks<\/strong><\/em><\/p>\n<p>any guidance would be very much appreciated. i've seen a lot of example of keras, but none that show how to do enact this kind of behavior for model deployment.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a strategy to invert an encoded prediction in Keras for model serving, so that the original string representation can be returned and serialized for deployment."
    },
    {
        "Question_id":73068169.0,
        "Question_title":"wandb : move runs from a blocked entity",
        "Question_body":"<p>I accidentally moved several runs from my own user account to a team entity.\nUnfortunatly, this team entity had a restriction on the quantity of experiments tracked, and it now appears as blocked. I have this error message :<\/p>\n<blockquote>\n<p>Your organization is over the limit of 250 tracked hours. Please upgrade your plan to keep using W&amp;B.<\/p>\n<\/blockquote>\n<p>I can't find a way to move back these runs to my free account, does anyone know how to do this ?\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1658414318473,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "wandb"
        ],
        "Question_view_count":19.0,
        "Owner_creation_time":1598425704360,
        "Owner_last_access_time":1658749438907,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Toulouse, France",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73068169",
        "Tool":"Weights & Biases",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  : move runs from a blocked entity; content:<p>i accidentally moved several runs from my own user account to a team entity.\nunfortunatly, this team entity had a restriction on the quantity of experiments tracked, and it now appears as blocked. i have this error message :<\/p>\n<blockquote>\n<p>your organization is over the limit of 250 tracked hours. please upgrade your plan to keep using w&amp;b.<\/p>\n<\/blockquote>\n<p>i can't find a way to move back these runs to my free account, does anyone know how to do this ?\nthanks<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user accidentally moved several runs to a team entity with a restriction on the quantity of experiments tracked, and now the entity appears as blocked. They are looking for a way to move the runs back to their free account."
    },
    {
        "Question_id":null,
        "Question_title":"Receiving error while submitting the pipeline run",
        "Question_body":"I am trying to train Model in the AML Designer and on the Train Model component, I am receiving the following error when submitting it for a pipeline run\u2026\n\n\n\n\nAmlExceptionMessage:AzureMLCompute job failed.\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\n\n\n\n\nModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: \"MessageID\" is greater than allowed.",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1661308367600,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/979208\/receiving-error-while-submitting-the-pipeline-run.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-24T03:23:00.71Z",
                "Answer_score":1,
                "Answer_body":"@Srin-4824 Thanks for the question. Here is the troubleshooting document for this issue.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: receiving error while submitting the pipeline run; content:i am trying to train model in the aml designer and on the train model component, i am receiving the following error when submitting it for a pipeline run\u2026\n\n\n\n\namlexceptionmessage:compute job failed.\njobfailed: submitted script failed with a non-zero exit code; see the driver log file for details.\n\n\n\n\nmoduleexceptionmessage:columnuniquevaluesexceeded: number of unique values in column: \"messageid\" is greater than allowed.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error while submitting the pipeline run, with an AMLExceptionMessage of \"Compute job failed\" and a ModuleExceptionMessage of \"ColumnUniqueValuesExceeded: number of unique values in column: 'messageid' is greater than allowed.\""
    },
    {
        "Question_id":70565147.0,
        "Question_title":"AWS sagemaker datawrangler continues to be used after closing everything",
        "Question_body":"<p>I used data wrangler for maybe 3h a week ago, and I open my account today to see that Ive been charged for 6 days worth of data wrangler usage. Basically it was running in the background the whole time. The first 25h were part of free tier then I got charged for the rest of the time. I dont have any endpoints to close so whats the issue? I dont care about the costs, I know I can talk to support to get the charges reversed but they dont seem to know whats going on because they havent helped me at all.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1641209554070,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":36.0,
        "Owner_creation_time":1535382420716,
        "Owner_last_access_time":1647779585176,
        "Owner_reputation":41.0,
        "Owner_up_votes":5.0,
        "Owner_down_votes":0.0,
        "Owner_views":10.0,
        "Answer_body":"<p>After going over <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/data-wrangler-shut-down.html\" rel=\"nofollow noreferrer\">the docs<\/a>, I found that I needed to shut down the wrangler instance under Running Instances and Kernels button.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1641216477460,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":1641216587632,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70565147",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  datawrangler continues to be used after closing everything; content:<p>i used data wrangler for maybe 3h a week ago, and i open my account today to see that ive been charged for 6 days worth of data wrangler usage. basically it was running in the background the whole time. the first 25h were part of free tier then i got charged for the rest of the time. i dont have any endpoints to close so whats the issue? i dont care about the costs, i know i can talk to support to get the charges reversed but they dont seem to know whats going on because they havent helped me at all.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user used Data Wrangler for 3 hours a week ago, but was charged for 6 days worth of usage, indicating that it was running in the background the whole time."
    },
    {
        "Question_id":71411665.0,
        "Question_title":"Can I update NGINX version in Azure AKS Cluster?",
        "Question_body":"<p>Hopefully, I'm posting this in the right place. We have a ML team using an Azure AKS cluster which was built by me. Because this is all built around ML Studio I figured this might be the best place to ask for a dev viewpoint.<\/p>\n<p>A recent security scan identified several open ports on the nodes and workloads which identify themselves as runnning NGINX v1.10.3:<\/p>\n<pre><code>[root ~]# curl 10.210.100.62:32570 -ik\nHTTP\/1.1 200 OK\nServer: nginx\/1.10.3 (Ubuntu)\nDate: Wed, 09 Mar 2022 14:19:55 GMT\nContent-Type: text\/html; charset=utf-8\nContent-Length: 7\nConnection: keep-alive\n<\/code><\/pre>\n<p>The cluster is strictly used to host ML Studio inference endpoints.<\/p>\n<p>The open ports running NGINX are:<\/p>\n<pre><code>5001\n31366\n31419\n32570\n<\/code><\/pre>\n<p>I'm pretty sure 5001 is the listening port on all the inference endpoints, so I imagine it might have something to do with the ML Studio and how it deploys the inference endpoints. The other ports are probably some control ports on the Kubernetes nodes?<\/p>\n<p>I tried updating the kubernetes version on the control plain and nodes. But this didn't make any difference to the running NGINX version, even on the nodes. I connected to one of the hosts in a root shell, but the environment is really stripped and I didn't get very far in trying to identify where NGINX is running from or if it is even possible to update. I suspect attempting to do so in a shell can only break things.<\/p>\n<p>Does anybody know if it is even possible to update this in anyway?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1646838919210,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "nginx",
            "azure-aks",
            "azure-machine-learning-service"
        ],
        "Question_view_count":278.0,
        "Owner_creation_time":1504185478296,
        "Owner_last_access_time":1663948226207,
        "Owner_reputation":473.0,
        "Owner_up_votes":37.0,
        "Owner_down_votes":2.0,
        "Owner_views":66.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71411665",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: can i update nginx version in azure aks cluster?; content:<p>hopefully, i'm posting this in the right place. we have a ml team using an azure aks cluster which was built by me. because this is all built around ml studio i figured this might be the best place to ask for a dev viewpoint.<\/p>\n<p>a recent security scan identified several open ports on the nodes and workloads which identify themselves as runnning nginx v1.10.3:<\/p>\n<pre><code>[root ~]# curl 10.210.100.62:32570 -ik\nhttp\/1.1 200 ok\nserver: nginx\/1.10.3 (ubuntu)\ndate: wed, 09 mar 2022 14:19:55 gmt\ncontent-type: text\/html; charset=utf-8\ncontent-length: 7\nconnection: keep-alive\n<\/code><\/pre>\n<p>the cluster is strictly used to host ml studio inference endpoints.<\/p>\n<p>the open ports running nginx are:<\/p>\n<pre><code>5001\n31366\n31419\n32570\n<\/code><\/pre>\n<p>i'm pretty sure 5001 is the listening port on all the inference endpoints, so i imagine it might have something to do with the ml studio and how it deploys the inference endpoints. the other ports are probably some control ports on the kubernetes nodes?<\/p>\n<p>i tried updating the kubernetes version on the control plain and nodes. but this didn't make any difference to the running nginx version, even on the nodes. i connected to one of the hosts in a root shell, but the environment is really stripped and i didn't get very far in trying to identify where nginx is running from or if it is even possible to update. i suspect attempting to do so in a shell can only break things.<\/p>\n<p>does anybody know if it is even possible to update this in anyway?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to update the nginx version running on their Azure AKS cluster, which is used to host ML Studio inference endpoints, as identified by a security scan."
    },
    {
        "Question_id":null,
        "Question_title":"Model changes",
        "Question_body":"It appears that the default model for GCP Cloud Vision API has changed. Specifically, the current API results lack localized objects that were available previously, say around June 2021. How does the team communicate, if at all, what entities the model supports? Thanks.",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1634645580000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":322.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Model-changes\/td-p\/173396\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"As per the release notes [1], it doesn't seem like there was any change to the default model.\n\nFrom all of the available models [2], for your use case you can use the object localizer [3].\n\n[1] https:\/\/cloud.google.com\/vision\/docs\/release-notes\n[2] https:\/\/cloud.google.com\/vision\/docs\/reference\/rest\/v1\/Feature#type\n[3] https:\/\/cloud.google.com\/vision\/docs\/object-localizer"
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: model changes; content:it appears that the default model for gcp cloud vision api has changed. specifically, the current api results lack localized objects that were available previously, say around june 2021. how does the team communicate, if at all, what entities the model supports? thanks.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking how the team communicates the entities that the model supports, given that the default model for GCP Cloud Vision API appears to have changed and localized objects are no longer available."
    },
    {
        "Question_id":null,
        "Question_title":"AttributeError with dvc.api.read to azure blob storage",
        "Question_body":"<p>Hello,<\/p>\n<p>I am new to DVC and evaluate it in a proof of concept implementation for our ML projects, which seems to fit perfectly! But I encounter a problem with dvc.api.open while using an Azure Blob Storage.<\/p>\n<p>What I have done:<\/p>\n<ul>\n<li>cloned <a href=\"https:\/\/github.com\/iterative\/dataset-registry\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - iterative\/dataset-registry: Dataset registry DVC project<\/a>\n<\/li>\n<li>dvc remote add -d myremote azure:\/\/BLOB\/PATH<\/li>\n<li>dvc remote modify --local myremote connection_string \u2018CONNECTION_STRING\u2019<\/li>\n<li>created test file<\/li>\n<li>dvc add &amp; push<\/li>\n<li>removed the test file incl. cache from local repo<\/li>\n<li>dvc.api.read ==&gt; AttributeError<\/li>\n<li>dvc pull<\/li>\n<li>dvc.api.read ==&gt; works<\/li>\n<\/ul>\n<p>I am able to use dvc push and dvc pull, but by using dvc.api.read I get \u201cAttributeError: \u2018NoneType\u2019 object has no attribute \u2018account_key\u2019\u201d (see attached screenshots). If the file is downloaded with dvc pull and it is available in the cache folder everything works.<\/p>\n<p>Can anyone point me to the problem or my misunderstanding? I want to use the streaming functionality, as we have very large files and do not want to store them on the storage of a virtual machine.<\/p>\n<p>Thanks!<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/original\/1X\/3a37b2884021232141bb6f25c162527b698ad682.jpeg\" data-download-href=\"\/uploads\/short-url\/8j11vMuBq2Jq8JpCuTrAfmDO8eu.jpeg?dl=1\" title=\"Unbenannt\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/3a37b2884021232141bb6f25c162527b698ad682_2_431x500.jpeg\" alt=\"Unbenannt\" data-base62-sha1=\"8j11vMuBq2Jq8JpCuTrAfmDO8eu\" width=\"431\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/3a37b2884021232141bb6f25c162527b698ad682_2_431x500.jpeg, https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/3a37b2884021232141bb6f25c162527b698ad682_2_646x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/3a37b2884021232141bb6f25c162527b698ad682_2_862x1000.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/3a37b2884021232141bb6f25c162527b698ad682_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Unbenannt<\/span><span class=\"informations\">1000\u00d71158 273 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":6,
        "Question_comment_count":null,
        "Question_creation_time":1614251830608,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":349.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/attributeerror-with-dvc-api-read-to-azure-blob-storage\/688",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":1539,
                "name":"Peter Rowlands",
                "username":"pmrowla",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/7ab992\/{size}.png",
                "created_at":"2021-02-25T11:53:13.453Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/svenw3\">@svenw3<\/a>, could you please run <code>dvc doctor<\/code> from the command line and then post the output here?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-02-25T11:53:13.453Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":1.2,
                "yours":false,
                "topic_id":688,
                "topic_slug":"attributeerror-with-dvc-api-read-to-azure-blob-storage",
                "display_username":"Peter Rowlands",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":130,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1540,
                "name":"Sven Winkelmann",
                "username":"svenw3",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/9d8465\/{size}.png",
                "created_at":"2021-02-25T13:11:44.439Z",
                "cooked":"<h2>DVC version: 1.11.16 (pip)<\/h2>\n<p>Platform: Python 3.9.1 on Windows-10-10.0.18362-SP0<br>\nSupports: azure, http, https<br>\nCache types: hardlink<br>\nCaches: local<br>\nRemotes: https, azure<br>\nRepo: dvc, git<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-02-25T13:11:44.439Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":2,
                "reads":6,
                "readers_count":5,
                "score":11.2,
                "yours":false,
                "topic_id":688,
                "topic_slug":"attributeerror-with-dvc-api-read-to-azure-blob-storage",
                "display_username":"Sven Winkelmann",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":253,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1541,
                "name":"Peter Rowlands",
                "username":"pmrowla",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/7ab992\/{size}.png",
                "created_at":"2021-02-25T13:40:04.427Z",
                "cooked":"<p>It looks like the problem here is related to a known limitation in DVC, where local config settings (such as those set via <code>dvc remote modify --local ...<\/code>) are not used by certain DVC commands, including <code>api.open()<\/code> and <code>api.read()<\/code>.<\/p>\n<p>The good news is that this limitation has been addressed in an upcoming release, however we are not currently planning to backport these changes into DVC 1.11.x.<\/p>\n<p>Would you mind trying the pre-release version (see: <a href=\"https:\/\/dvc.org\/blog\/dvc-2-0-pre-release#install\">https:\/\/dvc.org\/blog\/dvc-2-0-pre-release#install<\/a>) from pip, and checking if that resolves your issue? When you install the prerelease version, don\u2019t forget to also install the <code>azure<\/code> dependency<\/p>\n<pre><code class=\"lang-auto\">pip install --upgrade --pre dvc[azure]\n<\/code><\/pre>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2021-02-25T13:40:29.859Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":1.2,
                "yours":false,
                "topic_id":688,
                "topic_slug":"attributeerror-with-dvc-api-read-to-azure-blob-storage",
                "display_username":"Peter Rowlands",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/dvc.org\/blog\/dvc-2-0-pre-release#install",
                        "internal":false,
                        "reflection":false,
                        "clicks":2
                    }
                ],
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":130,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1542,
                "name":"Sven Winkelmann",
                "username":"svenw3",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/9d8465\/{size}.png",
                "created_at":"2021-02-25T14:48:18.843Z",
                "cooked":"<p>Thanks for your fast reply! The problem still exists with version 2.0, see the attached screenshot.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/original\/1X\/20118ca8cd5dfa0f128b7b27325cd3b96430cbd9.jpeg\" data-download-href=\"\/uploads\/short-url\/4zGStg0lwpyM90Zf0HehJhXdoPT.jpeg?dl=1\" title=\"Unbenannt1\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/20118ca8cd5dfa0f128b7b27325cd3b96430cbd9_2_680x500.jpeg\" alt=\"Unbenannt1\" data-base62-sha1=\"4zGStg0lwpyM90Zf0HehJhXdoPT\" width=\"680\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/20118ca8cd5dfa0f128b7b27325cd3b96430cbd9_2_680x500.jpeg, https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/20118ca8cd5dfa0f128b7b27325cd3b96430cbd9_2_1020x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/20118ca8cd5dfa0f128b7b27325cd3b96430cbd9_2_1360x1000.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1X\/20118ca8cd5dfa0f128b7b27325cd3b96430cbd9_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">Unbenannt1<\/span><span class=\"informations\">1566\u00d71151 606 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2021-02-25T14:48:18.843Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":5,
                "readers_count":4,
                "score":11.0,
                "yours":false,
                "topic_id":688,
                "topic_slug":"attributeerror-with-dvc-api-read-to-azure-blob-storage",
                "display_username":"Sven Winkelmann",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/original\/1X\/20118ca8cd5dfa0f128b7b27325cd3b96430cbd9.jpeg",
                        "internal":false,
                        "reflection":false,
                        "title":"20118ca8cd5dfa0f128b7b27325cd3b96430cbd9.jpeg",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":253,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1544,
                "name":"Peter Rowlands",
                "username":"pmrowla",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/7ab992\/{size}.png",
                "created_at":"2021-02-26T00:23:42.783Z",
                "cooked":"<p>Looks like this is an azure specific bug then, would you mind filing a bug report on our github?<\/p>",
                "post_number":6,
                "post_type":1,
                "updated_at":"2021-02-26T00:23:42.783Z",
                "reply_count":0,
                "reply_to_post_number":5,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":688,
                "topic_slug":"attributeerror-with-dvc-api-read-to-azure-blob-storage",
                "display_username":"Peter Rowlands",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "reply_to_user":{
                    "username":"svenw3",
                    "name":"Sven Winkelmann",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/9d8465\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":130,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1545,
                "name":"Sven Winkelmann",
                "username":"svenw3",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/9d8465\/{size}.png",
                "created_at":"2021-02-26T05:44:45.783Z",
                "cooked":"<p>thanks, I will fill in a bug report later today.<\/p>\n<p>EDIT:<br>\nSee: <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/5524\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">dvc.api.read: AttributeError while using azure blob storage for streaming data \u00b7 Issue #5524 \u00b7 iterative\/dvc \u00b7 GitHub<\/a><\/p>",
                "post_number":7,
                "post_type":1,
                "updated_at":"2021-02-26T08:11:05.960Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":688,
                "topic_slug":"attributeerror-with-dvc-api-read-to-azure-blob-storage",
                "display_username":"Sven Winkelmann",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":2,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/github.com\/iterative\/dvc\/issues\/5524",
                        "internal":false,
                        "reflection":false,
                        "title":"dvc.api.read: AttributeError while using azure blob storage for streaming data \u00b7 Issue #5524 \u00b7 iterative\/dvc \u00b7 GitHub",
                        "clicks":6
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":253,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: attributeerror with .api.read to azure blob storage; content:<p>hello,<\/p>\n<p>i am new to  and evaluate it in a proof of concept implementation for our ml projects, which seems to fit perfectly! but i encounter a problem with .api.open while using an azure blob storage.<\/p>\n<p>what i have done:<\/p>\n<ul>\n<li>cloned <a href=\"https:\/\/github.com\/iterative\/dataset-registry\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">github - iterative\/dataset-registry: dataset registry  project<\/a>\n<\/li>\n<li> remote add -d myremote azure:\/\/blob\/path<\/li>\n<li> remote modify --local myremote connection_string \u2018connection_string\u2019<\/li>\n<li>created test file<\/li>\n<li> add &amp; push<\/li>\n<li>removed the test file incl. cache from local repo<\/li>\n<li>.api.read ==&gt; attributeerror<\/li>\n<li> pull<\/li>\n<li>.api.read ==&gt; works<\/li>\n<\/ul>\n<p>i am able to use  push and  pull, but by using .api.read i get \u201cattributeerror: \u2018nonetype\u2019 object has no attribute \u2018account_key\u2019\u201d (see attached screenshots). if the file is downloaded with  pull and it is available in the cache folder everything works.<\/p>\n<p>can anyone point me to the problem or my misunderstanding? i want to use the streaming functionality, as we have very large files and do not want to store them on the storage of a virtual machine.<\/p>\n<p>thanks!<\/p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/original\/1x\/3a37b2884021232141bb6f25c162527b698ad682.jpeg\" data-download-href=\"\/uploads\/short-url\/8j11vmubq2jq8jpcutrafmdo8eu.jpeg?dl=1\" title=\"unbenannt\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1x\/3a37b2884021232141bb6f25c162527b698ad682_2_431x500.jpeg\" alt=\"unbenannt\" data-base62-sha1=\"8j11vmubq2jq8jpcutrafmdo8eu\" width=\"431\" height=\"500\" srcset=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1x\/3a37b2884021232141bb6f25c162527b698ad682_2_431x500.jpeg, https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1x\/3a37b2884021232141bb6f25c162527b698ad682_2_646x750.jpeg 1.5x, https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1x\/3a37b2884021232141bb6f25c162527b698ad682_2_862x1000.jpeg 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/standard17\/uploads\/dataversioncontrol\/optimized\/1x\/3a37b2884021232141bb6f25c162527b698ad682_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"><\/use><\/svg><span class=\"filename\">unbenannt<\/span><span class=\"informations\">1000\u00d71158 273 kb<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user encountered an AttributeError when attempting to use the .api.read function with an Azure Blob Storage, but was able to successfully use the push and pull functions."
    },
    {
        "Question_id":61615818.0,
        "Question_title":"Setting-up MLflow on Google Colab",
        "Question_body":"<p>I frequently use Google Colab to train TF\/PyTorch models as Colab provides me with GPU\/TPU runtime. Besides, I like working with MLflow to store and compare trained models, tracking progress, sharing, etc.  What are the available solutions to use MLflow with Google Colab?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0.0,
        "Question_creation_time":1588689839033,
        "Question_favorite_count":2.0,
        "Question_score":7.0,
        "Question_tags":[
            "google-colaboratory",
            "mlflow",
            "mlops"
        ],
        "Question_view_count":6053.0,
        "Owner_creation_time":1552661046208,
        "Owner_last_access_time":1663946284312,
        "Owner_reputation":1131.0,
        "Owner_up_votes":55.0,
        "Owner_down_votes":0.0,
        "Owner_views":49.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Paris, France\/ Ternopil, Ukraine",
        "Question_last_edit_time":1621937850167,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61615818",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: setting-up  on google colab; content:<p>i frequently use google colab to train tf\/pytorch models as colab provides me with gpu\/tpu runtime. besides, i like working with  to store and compare trained models, tracking progress, sharing, etc.  what are the available solutions to use  with google colab?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for solutions to use TensorBoard with Google Colab to store and compare trained models, track progress, and share results."
    },
    {
        "Question_id":73360734.0,
        "Question_title":"Programmatically enable installed extensions in Vertex AI Managed Notebook instance",
        "Question_body":"<p>I am working in JupyterLab within a Managed Notebook instance, accessed through the Vertex AI workbench, as part of a Google Cloud Project. When the instance is created, there are a number of JupyterLab extensions that are installed by default. In the web GUI, one can click the puzzle piece icon and enable\/disable all extensions with a single button click. I currently run a post-startup bash script to manage environments and module installations, and I would like to add to this script whatever commands would turn on the existing extensions. My understanding is that I can do this with<\/p>\n<pre><code># Status of extensions\njupyter labextension list\n# Enable\/disable some extension\njupyter labextension enable extensionIdentifierHere\n<\/code><\/pre>\n<p>However, when I test the enable\/disable command in an instance Terminal window, I receive, for example<\/p>\n<pre><code>[Errno 13] Permission denied: '\/opt\/conda\/etc\/jupyter\/labconfig\/page_config.json'\n<\/code><\/pre>\n<p>If I try to run this with <code>sudo<\/code>, I am asked for a password, but have no idea what that would be, given that I just built the environment and didn't set any password.<\/p>\n<p>Any insights on how to set this up, what the command(s) may be, or how else to approach this, would be appreciated.<\/p>\n<p>Potentially relevant:<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/65950610\/not-able-to-install-jupyterlab-extensions-on-gcp-ai-platform-notebooks\">Not able to install Jupyterlab extensions on GCP AI Platform Notebooks<\/a><\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/52753205\/unable-to-sudo-to-deep-learning-image\">Unable to sudo to Deep Learning Image<\/a><\/p>\n<p><a href=\"https:\/\/jupyterlab.readthedocs.io\/en\/stable\/user\/extensions.html#enabling-and-disabling-extensions\" rel=\"nofollow noreferrer\">https:\/\/jupyterlab.readthedocs.io\/en\/stable\/user\/extensions.html#enabling-and-disabling-extensions<\/a><\/p>\n<p>Edit 1:\nAdding more detail in response to answers and comments (@gogasca, @kiranmathew). My goal is to use ipyleaft-based mapping, through the geemap and earthengine-api python modules, within the notebook. If I create a Managed Notebook instance (service account, Networks shared with me, Enable terminal, all other defaults), launch JupyterLab, open the Terminal from the Launcher, and then run a bash script that creates a venv virtual environment, exposes a custom kernel, and performs the installations, I can use geemap and ipywidgets to visualize and modify (e.g., widget sliders that change map properties) Google Earth Engine assets in a Notebook. If I try to replicate this using a Docker image, it seems to break the connection with ipyleaflet, such that when I start the instance and use a Notebook, I have access to the modules (they can be imported) but can't use ipyleaflet to do the visualization. I thought the issue was that I was not properly enabling the extensions, per the &quot;Error displaying widget: model not found&quot; error, addressed in <a href=\"https:\/\/github.com\/jupyter-widgets\/ipyleaflet\/issues\/504\" rel=\"nofollow noreferrer\">this<\/a>, <a href=\"https:\/\/github.com\/jupyter-widgets\/ipyleaflet\/issues\/889\" rel=\"nofollow noreferrer\">this<\/a>, <a href=\"https:\/\/github.com\/jupyter-widgets\/ipyleaflet\/issues\/547\" rel=\"nofollow noreferrer\">this<\/a>, <a href=\"https:\/\/leafmap.org\/faq\/\" rel=\"nofollow noreferrer\">this<\/a>, etc. -- hence the title of my post. I tried using and modifying @TylerErickson 's Dockerfile that modifies a Google deep learning container and should handle all of this (<a href=\"https:\/\/github.com\/gee-community\/ee-jupyter-contrib\/blob\/master\/docker\/gcp_ai_deep_learning_platform\/Dockerfile\" rel=\"nofollow noreferrer\">here<\/a>), but both the original and modifications break the ipyleaflet connection when booting the Managed Notebook instance from the Docker image.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1660564868170,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "google-cloud-platform",
            "jupyter-lab",
            "google-cloud-vertex-ai",
            "gcp-ai-platform-notebook"
        ],
        "Question_view_count":202.0,
        "Owner_creation_time":1459350905808,
        "Owner_last_access_time":1663857124692,
        "Owner_reputation":55.0,
        "Owner_up_votes":2.0,
        "Owner_down_votes":0.0,
        "Owner_views":5.0,
        "Answer_body":"<p>Google Managed Notebooks do not support third-party JL extensions.  Most of these extensions require a rebuild of the JupyterLab static assets bundle. This requires root access which our Managed Notebooks do not support.<\/p>\n<p>Untangling this limitation would require a significant change to the permission and security model that Managed Notebooks provides. It would also have implications for the supportability of the product itself since a user could effectively break their Managed Notebook by installing something rogue.<\/p>\n<p>I would suggest to use User Managed Notebooks.<\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_time":1660628912063,
        "Answer_score":2.0,
        "Owner_location":null,
        "Question_last_edit_time":1660731534620,
        "Answer_last_edit_time":1660634341887,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73360734",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: programmatically enable installed extensions in  managed notebook instance; content:<p>i am working in jupyterlab within a managed notebook instance, accessed through the  workbench, as part of a google cloud project. when the instance is created, there are a number of jupyterlab extensions that are installed by default. in the web gui, one can click the puzzle piece icon and enable\/disable all extensions with a single button click. i currently run a post-startup bash script to manage environments and module installations, and i would like to add to this script whatever commands would turn on the existing extensions. my understanding is that i can do this with<\/p>\n<pre><code># status of extensions\njupyter labextension list\n# enable\/disable some extension\njupyter labextension enable extensionidentifierhere\n<\/code><\/pre>\n<p>however, when i test the enable\/disable command in an instance terminal window, i receive, for example<\/p>\n<pre><code>[errno 13] permission denied: '\/opt\/conda\/etc\/jupyter\/labconfig\/page_config.json'\n<\/code><\/pre>\n<p>if i try to run this with <code>sudo<\/code>, i am asked for a password, but have no idea what that would be, given that i just built the environment and didn't set any password.<\/p>\n<p>any insights on how to set this up, what the command(s) may be, or how else to approach this, would be appreciated.<\/p>\n<p>potentially relevant:<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/65950610\/not-able-to-install-jupyterlab-extensions-on-gcp-ai-platform-notebooks\">not able to install jupyterlab extensions on gcp ai platform notebooks<\/a><\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/52753205\/unable-to-sudo-to-deep-learning-image\">unable to sudo to deep learning image<\/a><\/p>\n<p><a href=\"https:\/\/jupyterlab.readthedocs.io\/en\/stable\/user\/extensions.html#enabling-and-disabling-extensions\" rel=\"nofollow noreferrer\">https:\/\/jupyterlab.readthedocs.io\/en\/stable\/user\/extensions.html#enabling-and-disabling-extensions<\/a><\/p>\n<p>edit 1:\nadding more detail in response to answers and comments (@gogasca, @kiranmathew). my goal is to use ipyleaft-based mapping, through the geemap and earthengine-api python modules, within the notebook. if i create a managed notebook instance (service account, networks shared with me, enable terminal, all other defaults), launch jupyterlab, open the terminal from the launcher, and then run a bash script that creates a venv virtual environment, exposes a custom kernel, and performs the installations, i can use geemap and ipywidgets to visualize and modify (e.g., widget sliders that change map properties) google earth engine assets in a notebook. if i try to replicate this using a docker image, it seems to break the connection with ipyleaflet, such that when i start the instance and use a notebook, i have access to the modules (they can be imported) but can't use ipyleaflet to do the visualization. i thought the issue was that i was not properly enabling the extensions, per the &quot;error displaying widget: model not found&quot; error, addressed in <a href=\"https:\/\/github.com\/jupyter-widgets\/ipyleaflet\/issues\/504\" rel=\"nofollow noreferrer\">this<\/a>, <a href=\"https:\/\/github.com\/jupyter-widgets\/ipyleaflet\/issues\/889\" rel=\"nofollow noreferrer\">this<\/a>, <a href=\"https:\/\/github.com\/jupyter-widgets\/ipyleaflet\/issues\/547\" rel=\"nofollow noreferrer\">this<\/a>, <a href=\"https:\/\/leafmap.org\/faq\/\" rel=\"nofollow noreferrer\">this<\/a>, etc. -- hence the title of my post. i tried using and modifying @tylererickson 's dockerfile that modifies a google deep learning container and should handle all of this (<a href=\"https:\/\/github.com\/gee-community\/ee-jupyter-contrib\/blob\/master\/docker\/gcp_ai_deep_learning_platform\/dockerfile\" rel=\"nofollow noreferrer\">here<\/a>), but both the original and modifications break the ipyleaflet connection when booting the managed notebook instance from the docker image.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to programmatically enable installed extensions in a managed notebook instance accessed through Google Cloud Workbench, but is having difficulty due to permission errors."
    },
    {
        "Question_id":61415793.0,
        "Question_title":"Log metrics in PythonScriptStep",
        "Question_body":"<p>In my Azure ML pipeline I've got a PythonScriptStep that is crunching some data. I need to access the Azure ML Logger to track metrics in the step, so I'm trying to import get_azureml_logger but that's bombing out. I'm not sure what dependency I need to install via pip. <\/p>\n\n<p><code>from azureml.logging import get_azureml_logger<\/code><\/p>\n\n<p><code>ModuleNotFoundError: No module named 'azureml.logging'<\/code><\/p>\n\n<p>I came across a similar <a href=\"https:\/\/stackoverflow.com\/questions\/49438358\/azureml-logging-module-not-found\">post<\/a> but it deals with Azure Notebooks. Anyway, I tried adding that blob to my pip dependency, but it's failing with an Auth error.   <\/p>\n\n<pre><code>Collecting azureml.logging==1.0.79 [91m  ERROR: HTTP error 403 while getting\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n[0m91m  ERROR: Could not install requirement azureml.logging==1.0.79 from\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n(from -r \/azureml-environment-setup\/condaenv.g4q7suee.requirements.txt\n(line 3)) because of error 403 Client Error:\nServer failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. for url:\nhttps:\/\/azuremldownloads.blob.core.windows.net\/wheels\/latest\/azureml.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnUdTm0B%2F%2FfknhTaRInBXyu2QTTt8wA3OsXwGVgU%2BJk%3D\n<\/code><\/pre>\n\n<p>I'm not sure how to move on this, all I need to do is to log metrics in the step.  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1587755548897,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "azure-machine-learning-service"
        ],
        "Question_view_count":361.0,
        "Owner_creation_time":1330016065408,
        "Owner_last_access_time":1662160983830,
        "Owner_reputation":1704.0,
        "Owner_up_votes":61.0,
        "Owner_down_votes":7.0,
        "Owner_views":232.0,
        "Answer_body":"<p>Check out the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-track-experiments#option-2-use-scriptrunconfig\" rel=\"nofollow noreferrer\">ScriptRunConfig Section of the Monitor Azure ML experiment runs and metrics<\/a>. <code>ScriptRunConfig<\/code> works effectively the same as a <code>PythonScriptStep<\/code>.<\/p>\n\n<p>The idiom is generally to have the following in your the script of your <code>PythonScriptStep<\/code>:<\/p>\n\n<pre><code>from azureml.core.run import Run\nrun = Run.get_context()\nrun.log('foo_score', \"bar\")\n<\/code><\/pre>\n\n<p>Side note: You don't need to change your environment dependencies to use this because <code>PythonScriptStep<\/code>s have <code>azureml-defaults<\/code> installed automatically as a dependency.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1587756432003,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1587809992912,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61415793",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: log metrics in pythonscriptstep; content:<p>in my  pipeline i've got a pythonscriptstep that is crunching some data. i need to access the  logger to track metrics in the step, so i'm trying to import get__logger but that's bombing out. i'm not sure what dependency i need to install via pip. <\/p>\n\n<p><code>from .logging import get__logger<\/code><\/p>\n\n<p><code>modulenotfounderror: no module named '.logging'<\/code><\/p>\n\n<p>i came across a similar <a href=\"https:\/\/stackoverflow.com\/questions\/49438358\/-logging-module-not-found\">post<\/a> but it deals with azure notebooks. anyway, i tried adding that blob to my pip dependency, but it's failing with an auth error.   <\/p>\n\n<pre><code>collecting .logging==1.0.79 [91m  error: http error 403 while getting\nhttps:\/\/downloads.blob.core.windows.net\/wheels\/latest\/.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnudtm0b%2f%2ffknhtarinbxyu2qttt8wa3osxwgvgu%2bjk%3d\n[0m91m  error: could not install requirement .logging==1.0.79 from\nhttps:\/\/downloads.blob.core.windows.net\/wheels\/latest\/.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnudtm0b%2f%2ffknhtarinbxyu2qttt8wa3osxwgvgu%2bjk%3d\n(from -r \/-environment-setup\/condaenv.g4q7suee.requirements.txt\n(line 3)) because of error 403 client error:\nserver failed to authenticate the request. make sure the value of authorization header is formed correctly including the signature. for url:\nhttps:\/\/downloads.blob.core.windows.net\/wheels\/latest\/.logging-1.0.79-py3-none-any.whl?sv=2016-05-31&amp;si=ro-2017&amp;sr=c&amp;sig=xnudtm0b%2f%2ffknhtarinbxyu2qttt8wa3osxwgvgu%2bjk%3d\n<\/code><\/pre>\n\n<p>i'm not sure how to move on this, all i need to do is to log metrics in the step.  <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to import get__logger to track metrics in a PythonScriptStep in an Azure ML pipeline, but is encountering a ModuleNotFoundError and an authentication error when trying to install the dependency."
    },
    {
        "Question_id":null,
        "Question_title":"Add run to existing sweep",
        "Question_body":"<p>The last run of my sweep crashed, so I run the last one again, but now it\u2019s not in the sweep. Can I add this run to the sweep somehow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1655055988205,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":42.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/add-run-to-existing-sweep\/2604",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":6836,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-08-11T17:46:36.852Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":2,
                "post_type":3,
                "updated_at":"2022-08-11T17:46:36.852Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2604,
                "topic_slug":"add-run-to-existing-sweep",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: add run to existing sweep; content:<p>the last run of my sweep crashed, so i run the last one again, but now it\u2019s not in the sweep. can i add this run to the sweep somehow?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking to add a run to an existing sweep that crashed, but is not currently in the sweep."
    },
    {
        "Question_id":null,
        "Question_title":"Tensorboard sync shows incorrect number of steps",
        "Question_body":"<p>Hello!<\/p>\n<p>I have observed a strange behavior when synchronizing tensorboard runs. Two runs have different lengths in steps when uploaded on wandb. And both are wrong. They are probably different due to multiprocessing. Although, if I open the tensorboard tab in the wandb interface it shows both results correctly.<\/p>\n<p>I can provide the files if I figure out how to attach them here. Or should I upload it somewhere else?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1633617442784,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":257.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/tensorboard-sync-shows-incorrect-number-of-steps\/881",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2221,
                "name":"Martolod Slaaf",
                "username":"martslaaf",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/martslaaf\/{size}\/332_2.png",
                "created_at":"2021-10-07T15:49:08.654Z",
                "cooked":"<p>Since I haven\u2019t figured out how to paste log files here, I uploaded them to the third-party website.<br>\n<a href=\"https:\/\/turb.cc\/0u2o0f8crljr.html\" rel=\"noopener nofollow ugc\">first<\/a><br>\n<a href=\"https:\/\/turb.cc\/57d3s8c2fbd1.html\" rel=\"noopener nofollow ugc\">second<\/a><\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-10-07T15:49:08.654Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":14,
                "readers_count":13,
                "score":7.8,
                "yours":false,
                "topic_id":881,
                "topic_slug":"tensorboard-sync-shows-incorrect-number-of-steps",
                "display_username":"Martolod Slaaf",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/turb.cc\/0u2o0f8crljr.html",
                        "internal":false,
                        "reflection":false,
                        "title":"Download file events.out.tfevents.1633538634.anka-stroboscode.23605.0 (3,16 Mb) | Turbobit.net",
                        "clicks":1
                    },
                    {
                        "url":"https:\/\/turb.cc\/57d3s8c2fbd1.html",
                        "internal":false,
                        "reflection":false,
                        "title":"Download file events.out.tfevents.1633377590.anka-stroboscode.27773.0 (3,16 Mb) | Turbobit.net",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":523,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2835,
                "name":"Anmol Mann",
                "username":"anmolmann",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/c37758\/{size}.png",
                "created_at":"2021-10-27T19:58:09.480Z",
                "cooked":"<p>Hey <a class=\"mention\" href=\"\/u\/martslaaf\">@martslaaf<\/a> , apologies for the delay here. I couldn\u2019t find the files you attached above.<\/p>\n<p>Are you using <code>sync_tensorboard<\/code> and making calls to <code>wandb.log<\/code> as well in your script? If yes, this makes the default <code>step<\/code> to be incorrect, but the <code>global_step<\/code> <strong>x-axis<\/strong> trick should work for the tensorboard metrics.  Also, you might want to add <code>global_step<\/code> to the <code>wandb.log<\/code> calls you make if you want to line them up with the tensorboard metrics.<\/p>\n<p>However, if this doesn\u2019t fix your issue, could you please share:<\/p>\n<ol>\n<li>your debug bundle log (debug.log and debug-internal.log) for the runs having different steps?<\/li>\n<li>a minimal script as in how you\u2019re logging, this could help us in reproducing the issue on our side.<\/li>\n<\/ol>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-10-27T19:58:09.480Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":11,
                "readers_count":10,
                "score":7.2,
                "yours":false,
                "topic_id":881,
                "topic_slug":"tensorboard-sync-shows-incorrect-number-of-steps",
                "display_username":"Anmol Mann",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"martslaaf",
                    "name":"Martolod Slaaf",
                    "avatar_template":"\/user_avatar\/community.wandb.ai\/martslaaf\/{size}\/332_2.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":419,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2977,
                "name":"Anmol Mann",
                "username":"anmolmann",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/c37758\/{size}.png",
                "created_at":"2021-10-30T20:41:40.095Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/martslaaf\">@martslaaf<\/a> , we wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2021-10-30T20:41:40.095Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":881,
                "topic_slug":"tensorboard-sync-shows-incorrect-number-of-steps",
                "display_username":"Anmol Mann",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"anmolmann",
                    "name":"Anmol Mann",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/c37758\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":419,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: tensorboard sync shows incorrect number of steps; content:<p>hello!<\/p>\n<p>i have observed a strange behavior when synchronizing tensorboard runs. two runs have different lengths in steps when uploaded on . and both are wrong. they are probably different due to multiprocessing. although, if i open the tensorboard tab in the  interface it shows both results correctly.<\/p>\n<p>i can provide the files if i figure out how to attach them here. or should i upload it somewhere else?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user has observed a strange behavior when synchronizing tensorboard runs, where two runs have different lengths in steps when uploaded, and both are incorrect. They can provide the files if they figure out how to attach them."
    },
    {
        "Question_id":72206679.0,
        "Question_title":"How to add extra library in ML FLOW which can not be added through conda.yaml",
        "Question_body":"<p>It would be great if you can shed some light.<\/p>\n<p>I m building a data science project using MLFLOW. I can install most of library through conda.yaml. But there is one library which is in azure artifact. which can not be packaged directly. Is there any way we can mention extra libraries for MLFLOW when we run it on databricks\/Locally. Which MLFLOW can use it while running<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1652297551833,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "mlflow"
        ],
        "Question_view_count":18.0,
        "Owner_creation_time":1421042624883,
        "Owner_last_access_time":1663834967156,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72206679",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to add extra library in ml flow which can not be added through conda.yaml; content:<p>it would be great if you can shed some light.<\/p>\n<p>i m building a data science project using . i can install most of library through conda.yaml. but there is one library which is in azure artifact. which can not be packaged directly. is there any way we can mention extra libraries for  when we run it on databricks\/locally. which  can use it while running<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking how to add an extra library to ML Flow which cannot be added through conda.yaml, and is wondering if there is a way to mention extra libraries for ML Flow when running it on Databricks or locally."
    },
    {
        "Question_id":66830113.0,
        "Question_title":"Run ML pipeline using AWS step function for entire dataset?",
        "Question_body":"<p>I have a step function setup which calls preprocessing lambda and inference lambda for a data item. Now, I need to do this process on the entire dataset(over 10000 items). One way is to invoke step function parallelly for each input. Is there a better alternative to this approach?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1616839735833,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "aws-lambda",
            "amazon-sagemaker",
            "aws-step-functions"
        ],
        "Question_view_count":47.0,
        "Owner_creation_time":1616737438963,
        "Owner_last_access_time":1648106596832,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66830113",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: run ml pipeline using aws step function for entire dataset?; content:<p>i have a step function setup which calls preprocessing lambda and inference lambda for a data item. now, i need to do this process on the entire dataset(over 10000 items). one way is to invoke step function parallelly for each input. is there a better alternative to this approach?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for an alternative to invoking a step function in parallel for each item in a dataset of over 10,000 items in order to run a machine learning pipeline."
    },
    {
        "Question_id":58989610.0,
        "Question_title":"How to custom code an inference pipeline in AWS sagemaker?",
        "Question_body":"<p>I am building a time series usecase to automate the preprocess and retrain tasks.At first the data is preprocessed using numpy, pandas, statsmodels etc &amp; later a machine learning algorithm is applied to make predictions.\nThe reason for using inference pipeline is that it reuses the same preprocess code for training and inference. I have checked the examples given by AWS sagemaker team with spark and sci-kit learn. In both the examples they use a sci-kit learn container to fit &amp; transform their preprocess code. Should I also have to create a container which is not needed in my use case as I am not using any sci-kit-learn code? <\/p>\n\n<p>Can someone give me a custom example of using these pipelines? Any help is appreciated!<\/p>\n\n<p><strong>Sources looked into:<\/strong><\/p>\n\n<p><a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/tree\/master\/sagemaker-python-sdk\/scikit_learn_inference_pipeline\" rel=\"nofollow noreferrer\">https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/tree\/master\/sagemaker-python-sdk\/scikit_learn_inference_pipeline<\/a>\n<a href=\"https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/tree\/master\/advanced_functionality\/inference_pipeline_sparkml_blazingtext_dbpedia\" rel=\"nofollow noreferrer\">https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/tree\/master\/advanced_functionality\/inference_pipeline_sparkml_blazingtext_dbpedia<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1574408498230,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":1186.0,
        "Owner_creation_time":1553712330910,
        "Owner_last_access_time":1592342230092,
        "Owner_reputation":103.0,
        "Owner_up_votes":4.0,
        "Owner_down_votes":0.0,
        "Owner_views":12.0,
        "Answer_body":"<p>Apologies for the late response.<\/p>\n\n<p>Below is some documentation on inference pipelines:\n<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/inference-pipelines.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/inference-pipelines.html<\/a>\n<a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/inference-pipeline-real-time.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/inference-pipeline-real-time.html<\/a><\/p>\n\n<blockquote>\n  <p>Should I also have to create a container which is not needed in my use case as I am not using any sci-kit-learn code?<\/p>\n<\/blockquote>\n\n<p>Your container is an encapsulation of the environment needed for your custom code needed to run properly. Based on the requirements listed above, <code>numpy, pandas, statsmodels etc &amp; later a machine learning algorithm<\/code>, I would create a container if you wish to isolate your dependencies or modify an existing predefined SageMaker container, such as the scikit-learn one, and add your dependencies into that.<\/p>\n\n<blockquote>\n  <p>Can someone give me a custom example of using these pipelines? Any help is appreciated!<\/p>\n<\/blockquote>\n\n<p>Unfortunately, the two example notebooks referenced above are the only examples utilizing inference pipelines. The biggest hurdle most likely is creating containers that fulfill the preprocessing and prediction task you are seeking and then combining those two together into the inference pipeline.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1575505485728,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":1579974118672,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58989610",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to custom code an inference pipeline in ?; content:<p>i am building a time series usecase to automate the preprocess and retrain tasks.at first the data is preprocessed using numpy, pandas, statsmodels etc &amp; later a machine learning algorithm is applied to make predictions.\nthe reason for using inference pipeline is that it reuses the same preprocess code for training and inference. i have checked the examples given by  team with spark and sci-kit learn. in both the examples they use a sci-kit learn container to fit &amp; transform their preprocess code. should i also have to create a container which is not needed in my use case as i am not using any sci-kit-learn code? <\/p>\n\n<p>can someone give me a custom example of using these pipelines? any help is appreciated!<\/p>\n\n<p><strong>sources looked into:<\/strong><\/p>\n\n<p><a href=\"https:\/\/github.com\/awslabs\/amazon--examples\/tree\/master\/-python-sdk\/scikit_learn_inference_pipeline\" rel=\"nofollow noreferrer\">https:\/\/github.com\/awslabs\/amazon--examples\/tree\/master\/-python-sdk\/scikit_learn_inference_pipeline<\/a>\n<a href=\"https:\/\/github.com\/awslabs\/amazon--examples\/tree\/master\/advanced_functionality\/inference_pipeline_sparkml_blazingtext_dbpedia\" rel=\"nofollow noreferrer\">https:\/\/github.com\/awslabs\/amazon--examples\/tree\/master\/advanced_functionality\/inference_pipeline_sparkml_blazingtext_dbpedia<\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a custom example of how to code an inference pipeline for a time series use case, using numpy, pandas, statsmodels, and a machine learning algorithm, without needing to create a container for sci-kit learn."
    },
    {
        "Question_id":59767816.0,
        "Question_title":"Azure Machine Learning add_conda_package will fail when the package has name starts \"python\"",
        "Question_body":"<p>I tested to run my pythonnet based wrapper code on Azure Machine Learning.\nI tried add pythonnet package with conda_dependencies property, but it cause some errors.<\/p>\n\n<pre><code>env = Environment(name=\"env\")\nenv.python.conda_dependencies.add_conda_package(\"pythonnet\")\n<\/code><\/pre>\n\n<p>This code will report<\/p>\n\n<pre><code>TypeError: can only concatenate str (not \"NoneType\") to str\n\n\n~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\azureml\\core\\conda_dependencies.py in add_conda_package(self, conda_package)\n    461                 if conda_package.startswith(PYTHON_PREFIX):\n    462                     python_version = self._get_version(conda_package)\n--&gt; 463                     self.set_python_version(python_version)\n    464                 else:\n    465                     self._conda_dependencies[PACKAGES].append(conda_package)\n\n~\\Anaconda3\\envs\\myenv\\lib\\site-packages\\azureml\\core\\conda_dependencies.py in \nset_python_version(self, version)\n    418                 if self._python_version != version:\n    419                     # Doing an inplace update to preserve the comment above this field in the file.\n--&gt; 420                     self._conda_dependencies[PACKAGES][index] = PYTHON_PREFIX + '=' + version\n    421             else:\n    422                 self._conda_dependencies[PACKAGES].append(PYTHON_PREFIX + '=' + version)\n<\/code><\/pre>\n\n<p>I understand azureml code uderstand both package name and \"python ...\" case. It causes this error.\nDoes anyone know any work around ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_creation_time":1579171180143,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "python.net",
            "azure-machine-learning-service"
        ],
        "Question_view_count":145.0,
        "Owner_creation_time":1349439438772,
        "Owner_last_access_time":1660108412572,
        "Owner_reputation":81.0,
        "Owner_up_votes":85.0,
        "Owner_down_votes":0.0,
        "Owner_views":15.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Tokyo",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59767816",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  add_conda_package will fail when the package has name starts \"python\"; content:<p>i tested to run my pythonnet based wrapper code on .\ni tried add pythonnet package with conda_dependencies property, but it cause some errors.<\/p>\n\n<pre><code>env = environment(name=\"env\")\nenv.python.conda_dependencies.add_conda_package(\"pythonnet\")\n<\/code><\/pre>\n\n<p>this code will report<\/p>\n\n<pre><code>typeerror: can only concatenate str (not \"nonetype\") to str\n\n\n~\\anaconda3\\envs\\myenv\\lib\\site-packages\\\\core\\conda_dependencies.py in add_conda_package(self, conda_package)\n    461                 if conda_package.startswith(python_prefix):\n    462                     python_version = self._get_version(conda_package)\n--&gt; 463                     self.set_python_version(python_version)\n    464                 else:\n    465                     self._conda_dependencies[packages].append(conda_package)\n\n~\\anaconda3\\envs\\myenv\\lib\\site-packages\\\\core\\conda_dependencies.py in \nset_python_version(self, version)\n    418                 if self._python_version != version:\n    419                     # doing an inplace update to preserve the comment above this field in the file.\n--&gt; 420                     self._conda_dependencies[packages][index] = python_prefix + '=' + version\n    421             else:\n    422                 self._conda_dependencies[packages].append(python_prefix + '=' + version)\n<\/code><\/pre>\n\n<p>i understand  code uderstand both package name and \"python ...\" case. it causes this error.\ndoes anyone know any work around ?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user attempted to add a package with a name starting with \"python\" using the add_conda_package method, but encountered an error due to the code not understanding the \"python ...\" case."
    },
    {
        "Question_id":70291455.0,
        "Question_title":"SageMaker Studio PyTorch 1.8 kernel has no PyTorch, Numpy, or Matplotlib module",
        "Question_body":"<p>I'm working with SageMaker studio with the following options:<\/p>\n<ul>\n<li>kernel: PyTorch 1.8 Python 3.6 GPU optimized.<\/li>\n<li>instance: ml.g4dn.xlarge<\/li>\n<\/ul>\n<p>When running <code>import torch<\/code> <code>numpy<\/code>, <code>matplotlib<\/code> or <code>PIL<\/code>, I'm getting the <code>No module named 'X'<\/code> error. No matter when using <code>pip install<\/code> in a cell above, it will not be imported. Is this a problem only I am encountering with the new PyTorch 1.8 kernel? It also happens with the CPU-optimized version. However, PyTorch 1.6 kernel does not throw an error.<\/p>\n<p>When running <code>conda list<\/code>, I get the following output:<\/p>\n<pre><code># packages in environment at \/opt\/conda:\n#\n# Name                    Version                   Build  Channel\n_libgcc_mutex             0.1                        main  \n_openmp_mutex             4.5                       1_gnu  \napex                      0.1                      pypi_0    pypi\nargon2-cffi               21.1.0                   pypi_0    pypi\nargparse                  1.4.0                    pypi_0    pypi\nasync-generator           1.10                     pypi_0    pypi\nattrs                     21.2.0                   pypi_0    pypi\nautovizwidget             0.19.1                   pypi_0    pypi\naws-cdk-assets            1.128.0                  pypi_0    pypi\naws-cdk-aws-apigateway    1.128.0                  pypi_0    pypi\naws-cdk-aws-applicationautoscaling 1.128.0                  pypi_0    pypi\naws-cdk-aws-autoscaling   1.128.0                  pypi_0    pypi\naws-cdk-aws-autoscaling-common 1.128.0                  pypi_0    pypi\naws-cdk-aws-autoscaling-hooktargets 1.128.0                  pypi_0    pypi\naws-cdk-aws-batch         1.128.0                  pypi_0    pypi\naws-cdk-aws-certificatemanager 1.128.0                  pypi_0    pypi\naws-cdk-aws-cloudformation 1.128.0                  pypi_0    pypi\naws-cdk-aws-cloudfront    1.128.0                  pypi_0    pypi\naws-cdk-aws-cloudwatch    1.128.0                  pypi_0    pypi\naws-cdk-aws-codebuild     1.128.0                  pypi_0    pypi\naws-cdk-aws-codecommit    1.128.0                  pypi_0    pypi\naws-cdk-aws-codeguruprofiler 1.128.0                  pypi_0    pypi\naws-cdk-aws-codestarnotifications 1.128.0                  pypi_0    pypi\naws-cdk-aws-cognito       1.128.0                  pypi_0    pypi\naws-cdk-aws-dynamodb      1.128.0                  pypi_0    pypi\naws-cdk-aws-ec2           1.128.0                  pypi_0    pypi\naws-cdk-aws-ecr           1.128.0                  pypi_0    pypi\naws-cdk-aws-ecr-assets    1.128.0                  pypi_0    pypi\naws-cdk-aws-ecs           1.128.0                  pypi_0    pypi\naws-cdk-aws-efs           1.128.0                  pypi_0    pypi\naws-cdk-aws-elasticloadbalancing 1.128.0                  pypi_0    pypi\naws-cdk-aws-elasticloadbalancingv2 1.128.0                  pypi_0    pypi\naws-cdk-aws-events        1.128.0                  pypi_0    pypi\naws-cdk-aws-fsx           1.128.0                  pypi_0    pypi\naws-cdk-aws-globalaccelerator 1.128.0                  pypi_0    pypi\naws-cdk-aws-iam           1.128.0                  pypi_0    pypi\naws-cdk-aws-imagebuilder  1.128.0                  pypi_0    pypi\naws-cdk-aws-kinesis       1.128.0                  pypi_0    pypi\naws-cdk-aws-kms           1.128.0                  pypi_0    pypi\naws-cdk-aws-lambda        1.128.0                  pypi_0    pypi\naws-cdk-aws-logs          1.128.0                  pypi_0    pypi\naws-cdk-aws-route53       1.128.0                  pypi_0    pypi\naws-cdk-aws-route53-targets 1.128.0                  pypi_0    pypi\naws-cdk-aws-s3            1.128.0                  pypi_0    pypi\naws-cdk-aws-s3-assets     1.128.0                  pypi_0    pypi\naws-cdk-aws-sam           1.128.0                  pypi_0    pypi\naws-cdk-aws-secretsmanager 1.128.0                  pypi_0    pypi\naws-cdk-aws-servicediscovery 1.128.0                  pypi_0    pypi\naws-cdk-aws-signer        1.128.0                  pypi_0    pypi\naws-cdk-aws-sns           1.128.0                  pypi_0    pypi\naws-cdk-aws-sns-subscriptions 1.128.0                  pypi_0    pypi\naws-cdk-aws-sqs           1.128.0                  pypi_0    pypi\naws-cdk-aws-ssm           1.128.0                  pypi_0    pypi\naws-cdk-cloud-assembly-schema 1.128.0                  pypi_0    pypi\naws-cdk-core              1.128.0                  pypi_0    pypi\naws-cdk-custom-resources  1.128.0                  pypi_0    pypi\naws-cdk-cx-api            1.128.0                  pypi_0    pypi\naws-cdk-region-info       1.128.0                  pypi_0    pypi\naws-parallelcluster       3.0.0                    pypi_0    pypi\nawscli                    1.20.63                  pypi_0    pypi\nawsio                     0.0.1                    pypi_0    pypi\nbackcall                  0.2.0                      py_0    anaconda\nbcrypt                    3.2.0                    pypi_0    pypi\nbeautifulsoup4            4.10.0                   pypi_0    pypi\nblas                      1.0                    openblas    anaconda\nbleach                    4.1.0                    pypi_0    pypi\nblis                      0.7.4                    pypi_0    pypi\nbokeh                     2.3.3                    pypi_0    pypi\nboto3                     1.18.63                  pypi_0    pypi\nbotocore                  1.21.63                  pypi_0    pypi\nbottleneck                1.3.2                    pypi_0    pypi\nbrotlipy                  0.7.0           py36h8f6f2f9_1001    conda-forge\nbzip2                     1.0.8                h7f98852_4    conda-forge\nca-certificates           2021.9.30            h06a4308_1  \ncairo                     1.16.0            h18b612c_1001    conda-forge\ncatalogue                 2.0.6                    pypi_0    pypi\ncattrs                    1.0.0                    pypi_0    pypi\ncertifi                   2021.5.30        py36h06a4308_0  \ncffi                      1.14.6           py36hc120d54_0    conda-forge\nchardet                   4.0.0            py36h5fab9bb_1    conda-forge\ncharset-normalizer        2.0.4              pyhd3eb1b0_0  \nclick                     8.0.3                    pypi_0    pypi\nclickclick                20.10.2                  pypi_0    pypi\ncloudpickle               2.0.0                    pypi_0    pypi\ncmake                     3.18.2.post1             pypi_0    pypi\ncolorama                  0.4.3                    pypi_0    pypi\nconda                     4.10.3           py36h06a4308_0  \nconda-package-handling    1.7.3            py36h8f6f2f9_0    conda-forge\nconnexion                 2.7.0                    pypi_0    pypi\nconstructs                3.3.161                  pypi_0    pypi\ncontextvars               2.4                      pypi_0    pypi\ncryptography              35.0.0           py36hb60f036_0    conda-forge\ncycler                    0.10.0                   pypi_0    pypi\ncymem                     2.0.5                    pypi_0    pypi\ncython                    0.29.21          py36he6710b0_0    anaconda\ndataclasses               0.8                      pypi_0    pypi\ndecorator                 4.4.2                      py_0    anaconda\ndefusedxml                0.7.1                    pypi_0    pypi\ndgl-cuda11.1              0.6.1                    py36_0    dglteam\ndill                      0.3.4                    pypi_0    pypi\ndocutils                  0.15.2                   pypi_0    pypi\nentrypoints               0.3                      pypi_0    pypi\nfastai                    1.0.61                   pypi_0    pypi\nfastprogress              1.0.0                    pypi_0    pypi\nffmpeg                    4.0                  hcdf2ecd_0  \nfilelock                  3.3.1                    pypi_0    pypi\nflask                     2.0.2                    pypi_0    pypi\nfontconfig                2.13.1            hba837de_1005    conda-forge\nfreeglut                  3.2.1                h9c3ff4c_2    conda-forge\nfreetype                  2.10.4               h0708190_1    conda-forge\nfsspec                    2021.10.1                pypi_0    pypi\nfuture                    0.18.2                   py36_1    anaconda\ngevent                    21.8.0                   pypi_0    pypi\nglib                      2.69.1               h5202010_0  \ngoogle-pasta              0.2.0                    pypi_0    pypi\ngraphite2                 1.3.13            h58526e2_1001    conda-forge\ngreenlet                  1.1.2                    pypi_0    pypi\nh5py                      2.8.0            py36h989c5e5_3  \nharfbuzz                  1.8.8                hffaf4a1_0  \nhdf5                      1.10.2               hc401514_3    conda-forge\nhdijupyterutils           0.19.1                   pypi_0    pypi\nhorovod                   0.21.3                   pypi_0    pypi\nicu                       58.2              hf484d3e_1000    conda-forge\nidna                      2.10               pyhd3eb1b0_0  \nimageio                   2.9.0                    pypi_0    pypi\nimmutables                0.16                     pypi_0    pypi\nimportlib-metadata        4.8.1                    pypi_0    pypi\nimportlib-resources       5.2.2                    pypi_0    pypi\ninflection                0.5.1                    pypi_0    pypi\ninotify-simple            1.2.1                    pypi_0    pypi\nintel-openmp              2020.2                      254    anaconda\nipykernel                 5.5.6                    pypi_0    pypi\nipython                   7.16.1           py36h5ca1d4c_0    anaconda\nipython_genutils          0.2.0                    py36_0    anaconda\nipywidgets                7.6.5                    pypi_0    pypi\nisodate                   0.6.0                    pypi_0    pypi\nitsdangerous              2.0.1                    pypi_0    pypi\njasper                    2.0.14               hd8c5072_2  \njedi                      0.18.0           py36h06a4308_1  \njinja2                    3.0.2                    pypi_0    pypi\njmespath                  0.10.0                   pypi_0    pypi\njoblib                    1.0.1              pyhd3eb1b0_0  \njpeg                      9d                   h36c2ea0_0    conda-forge\njsii                      1.39.0                   pypi_0    pypi\njsonpatch                 1.32                     pypi_0    pypi\njsonpointer               2.1                      pypi_0    pypi\njsonschema                3.2.0                    pypi_0    pypi\njupyter                   1.0.0                    pypi_0    pypi\njupyter-client            7.0.6                    pypi_0    pypi\njupyter-console           6.4.0                    pypi_0    pypi\njupyter-core              4.8.1                    pypi_0    pypi\njupyterlab-pygments       0.1.2                    pypi_0    pypi\njupyterlab-widgets        1.0.2                    pypi_0    pypi\nkiwisolver                1.3.1                    pypi_0    pypi\nld_impl_linux-64          2.35.1               h7274673_9  \nlibffi                    3.3                  he6710b0_2  \nlibgcc                    7.2.0                h69d50b8_2  \nlibgcc-ng                 9.3.0               h5101ec6_17  \nlibgfortran               3.0.0                         1    conda-forge\nlibgfortran-ng            7.3.0                hdf63c60_0    anaconda\nlibglu                    9.0.0             he1b5a44_1001    conda-forge\nlibgomp                   9.3.0               h5101ec6_17  \nlibopenblas               0.3.10               h5a2b251_0    anaconda\nlibopencv                 3.4.2                hb342d67_1  \nlibopus                   1.3.1                h7f98852_1    conda-forge\nlibpng                    1.6.37               h21135ba_2    conda-forge\nlibstdcxx-ng              9.3.0               hd4cf53a_17  \nlibtiff                   4.0.10            hc3755c2_1005    conda-forge\nlibuuid                   2.32.1            h7f98852_1000    conda-forge\nlibvpx                    1.7.0                h439df22_0  \nlibxcb                    1.13              h7f98852_1003    conda-forge\nlibxml2                   2.9.12               h03d6c58_0  \nllvmlite                  0.36.0                   pypi_0    pypi\nlz4-c                     1.9.3                h9c3ff4c_1    conda-forge\nmagma-cuda111             2.5.2                         1    pytorch\nmarkupsafe                2.0.1                    pypi_0    pypi\nmarshmallow               3.13.0                   pypi_0    pypi\nmatplotlib                3.3.4                    pypi_0    pypi\nmistune                   0.8.4                    pypi_0    pypi\nmkl                       2020.2                      256    anaconda\nmkl-include               2020.2                      256    anaconda\nmock                      4.0.3                    pypi_0    pypi\nmpi4py                    3.0.3                    pypi_0    pypi\nmultiprocess              0.70.12.2                pypi_0    pypi\nmurmurhash                1.0.5                    pypi_0    pypi\nnbclient                  0.5.4                    pypi_0    pypi\nnbconvert                 6.0.7                    pypi_0    pypi\nnbformat                  5.1.3                    pypi_0    pypi\nncurses                   6.2                  he6710b0_1  \nnest-asyncio              1.5.1                    pypi_0    pypi\nnetworkx                  2.5.1              pyhd3eb1b0_0  \nnose                      1.3.7                    pypi_0    pypi\nnotebook                  6.4.4                    pypi_0    pypi\nnumba                     0.53.1                   pypi_0    pypi\nnumexpr                   2.7.3                    pypi_0    pypi\nnumpy                     1.19.1           py36h30dfecb_0    anaconda\nnumpy-base                1.19.1           py36h75fe3a5_0    anaconda\nnvidia-ml-py3             7.352.0                  pypi_0    pypi\nopenapi-schema-validator  0.1.5                    pypi_0    pypi\nopenapi-spec-validator    0.3.1                    pypi_0    pypi\nopencv                    3.4.2            py36h6fd60c2_1  \nopencv-python             4.5.3.56                 pypi_0    pypi\nopenssl                   1.1.1l               h7f8727e_0  \npackaging                 21.0                     pypi_0    pypi\npandas                    1.1.5            py36ha9443f7_0  \npandocfilters             1.5.0                    pypi_0    pypi\nparamiko                  2.8.0                    pypi_0    pypi\nparso                     0.8.0                      py_0    anaconda\npathos                    0.2.8                    pypi_0    pypi\npathy                     0.6.0                    pypi_0    pypi\npcre                      8.45                 h9c3ff4c_0    conda-forge\npexpect                   4.8.0                    py36_0    anaconda\npickleshare               0.7.5                    py36_0    anaconda\npillow                    8.3.2                    pypi_0    pypi\npip                       21.3               pyhd8ed1ab_0    conda-forge\npixman                    0.38.0            h516909a_1003    conda-forge\nplotly                    5.3.1                    pypi_0    pypi\npox                       0.3.0                    pypi_0    pypi\nppft                      1.6.6.4                  pypi_0    pypi\npreshed                   3.0.5                    pypi_0    pypi\nprogress                  1.6                      pypi_0    pypi\nprometheus-client         0.11.0                   pypi_0    pypi\nprompt-toolkit            3.0.8                      py_0    anaconda\nprotobuf                  3.18.1                   pypi_0    pypi\nprotobuf3-to-dict         0.1.5                    pypi_0    pypi\npsutil                    5.8.0                    pypi_0    pypi\npthread-stubs             0.4               h36c2ea0_1001    conda-forge\nptyprocess                0.6.0                    py36_0    anaconda\npublication               0.0.3                    pypi_0    pypi\npure-sasl                 0.6.2                    pypi_0    pypi\npy-opencv                 3.4.2            py36hb342d67_1  \npyarrow                   5.0.0                    pypi_0    pypi\npyasn1                    0.4.8                    pypi_0    pypi\npybind11                  2.8.0                    pypi_0    pypi\npycosat                   0.6.3           py36h8f6f2f9_1006    conda-forge\npycparser                 2.20                       py_2  \npydantic                  1.8.2                    pypi_0    pypi\npyfunctional              1.4.3                    pypi_0    pypi\npygments                  2.7.1                      py_0    anaconda\npyhive                    0.6.4                    pypi_0    pypi\npyinstrument              3.4.2                    pypi_0    pypi\npyinstrument-cext         0.2.4                    pypi_0    pypi\npykerberos                1.2.1                    pypi_0    pypi\npynacl                    1.4.0                    pypi_0    pypi\npyopenssl                 19.1.0                     py_1    anaconda\npyparsing                 2.4.7                    pypi_0    pypi\npyrsistent                0.18.0                   pypi_0    pypi\npysocks                   1.7.1            py36h5fab9bb_3    conda-forge\npython                    3.6.13          hffdb5ce_0_cpython    conda-forge\npython-dateutil           2.8.2              pyhd3eb1b0_0  \npython_abi                3.6                     2_cp36m    conda-forge\npytz                      2021.3             pyhd3eb1b0_0  \npyyaml                    5.4.1                    pypi_0    pypi\npyzmq                     22.3.0                   pypi_0    pypi\nqtconsole                 5.1.1                    pypi_0    pypi\nqtpy                      1.11.2                   pypi_0    pypi\nreadline                  8.1                  h27cfd23_0  \nrequests                  2.26.0             pyhd3eb1b0_0  \nrequests-kerberos         0.12.0                   pypi_0    pypi\nretrying                  1.3.3                    pypi_0    pypi\nrsa                       4.7.2                    pypi_0    pypi\nruamel_yaml               0.15.100         py36h27cfd23_0  \ns3fs                      0.4.2                    pypi_0    pypi\ns3transfer                0.5.0                    pypi_0    pypi\nsagemaker                 2.63.1                   pypi_0    pypi\nsagemaker-experiments     0.1.35                   pypi_0    pypi\nsagemaker-pytorch-training 2.4.0                    pypi_0    pypi\nsagemaker-studio-analytics-extension 0.0.2                    pypi_0    pypi\nsagemaker-studio-sparkmagic-lib 0.1.3                    pypi_0    pypi\nsagemaker-training        3.9.2                    pypi_0    pypi\nsasl                      0.3.1                    pypi_0    pypi\nscikit-learn              0.24.2           py36ha9443f7_0  \nscipy                     1.5.4                    pypi_0    pypi\nseaborn                   0.11.2                   pypi_0    pypi\nsend2trash                1.8.0                    pypi_0    pypi\nsetuptools                49.6.0           py36h5fab9bb_3    conda-forge\nshap                      0.39.0                   pypi_0    pypi\nsix                       1.16.0             pyhd3eb1b0_0  \nsklearn                   0.0                      pypi_0    pypi\nslicer                    0.0.7                    pypi_0    pypi\nsmart-open                5.2.1                    pypi_0    pypi\nsmclarify                 0.2                      pypi_0    pypi\nsmdebug                   1.0.9                    pypi_0    pypi\nsmdebug-rulesconfig       1.0.1                    pypi_0    pypi\nsmdistributed-dataparallel 1.2.0                    pypi_0    pypi\nsmdistributed-modelparallel 1.3.1                    pypi_0    pypi\nsoupsieve                 2.2.1                    pypi_0    pypi\nspacy                     3.1.3                    pypi_0    pypi\nspacy-legacy              3.0.8                    pypi_0    pypi\nsparkmagic                0.19.1                   pypi_0    pypi\nsqlite                    3.36.0               hc218d9a_0  \nsrsly                     2.4.1                    pypi_0    pypi\ntabulate                  0.8.9                    pypi_0    pypi\ntenacity                  8.0.1                    pypi_0    pypi\nterminado                 0.12.1                   pypi_0    pypi\ntestpath                  0.5.0                    pypi_0    pypi\nthinc                     8.0.10                   pypi_0    pypi\nthreadpoolctl             2.2.0              pyh0d69192_0  \nthrift                    0.15.0                   pypi_0    pypi\nthrift-sasl               0.4.3                    pypi_0    pypi\ntk                        8.6.10               hbc83047_0  \ntorch                     1.8.1                    pypi_0    pypi\ntorchfile                 0.1.0                    pypi_0    pypi\ntorchnet                  0.0.4                    pypi_0    pypi\ntorchvision               0.9.1                    pypi_0    pypi\ntornado                   6.1                      pypi_0    pypi\ntqdm                      4.61.2             pyhd3eb1b0_1  \ntraitlets                 4.3.3                    py36_0    anaconda\ntyper                     0.4.0                    pypi_0    pypi\ntyping                    3.7.4.3                  py36_0    anaconda\ntyping-extensions         3.10.0.2                 pypi_0    pypi\ntzdata                    2021a                h52ac0ba_0  \nurllib3                   1.26.6             pyhd3eb1b0_1  \nvisdom                    0.1.8.9                  pypi_0    pypi\nwasabi                    0.8.2                    pypi_0    pypi\nwcwidth                   0.2.5                      py_0    anaconda\nwebencodings              0.5.1                    pypi_0    pypi\nwebsocket-client          1.2.1                    pypi_0    pypi\nwerkzeug                  2.0.2                    pypi_0    pypi\nwheel                     0.36.2             pyhd3eb1b0_0  \nwidgetsnbextension        3.5.1                    pypi_0    pypi\nxorg-fixesproto           5.0               h7f98852_1002    conda-forge\nxorg-inputproto           2.3.2             h7f98852_1002    conda-forge\nxorg-kbproto              1.0.7             h7f98852_1002    conda-forge\nxorg-libice               1.0.10               h7f98852_0    conda-forge\nxorg-libsm                1.2.3             hd9c2040_1000    conda-forge\nxorg-libx11               1.7.2                h7f98852_0    conda-forge\nxorg-libxau               1.0.9                h7f98852_0    conda-forge\nxorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\nxorg-libxext              1.3.4                h7f98852_1    conda-forge\nxorg-libxfixes            5.0.3             h7f98852_1004    conda-forge\nxorg-libxi                1.7.10               h7f98852_0    conda-forge\nxorg-libxrender           0.9.10            h7f98852_1003    conda-forge\nxorg-renderproto          0.11.1            h7f98852_1002    conda-forge\nxorg-xextproto            7.3.0             h7f98852_1002    conda-forge\nxorg-xproto               7.0.31            h7f98852_1007    conda-forge\nxz                        5.2.5                h7b6447c_0  \nyaml                      0.2.5                h7b6447c_0  \nzipp                      3.6.0                    pypi_0    pypi\nzlib                      1.2.11               h7b6447c_3  \nzope-event                4.5.0                    pypi_0    pypi\nzope-interface            5.4.0                    pypi_0    pypi\nzstd                      1.4.9                ha95c52a_0    conda-forge\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1639059341363,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":309.0,
        "Owner_creation_time":1601991815160,
        "Owner_last_access_time":1652387269432,
        "Owner_reputation":51.0,
        "Owner_up_votes":4.0,
        "Owner_down_votes":0.0,
        "Owner_views":12.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70291455",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  studio pytorch 1.8 kernel has no pytorch, numpy, or matplotlib module; content:<p>i'm working with  studio with the following options:<\/p>\n<ul>\n<li>kernel: pytorch 1.8 python 3.6 gpu optimized.<\/li>\n<li>instance: ml.g4dn.xlarge<\/li>\n<\/ul>\n<p>when running <code>import torch<\/code> <code>numpy<\/code>, <code>matplotlib<\/code> or <code>pil<\/code>, i'm getting the <code>no module named 'x'<\/code> error. no matter when using <code>pip install<\/code> in a cell above, it will not be imported. is this a problem only i am encountering with the new pytorch 1.8 kernel? it also happens with the cpu-optimized version. however, pytorch 1.6 kernel does not throw an error.<\/p>\n",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is encountering an issue where the PyTorch 1.8 kernel does not have the PyTorch, NumPy, or Matplotlib modules, despite using the pip install command."
    },
    {
        "Question_id":null,
        "Question_title":"Aamazon SageMaker feature store throughput and latency",
        "Question_body":"What is the maximum throughput of AWS feature store. Also what is the P99 value of latency of AWS feature store (online store) ?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1639718714901,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Performance Efficiency"
        ],
        "Question_view_count":272.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUDX9mkJlNQzaR8lF50Z4H2Q\/aamazon-sage-maker-feature-store-throughput-and-latency",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI",
            "AWS Well-Architected Framework"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-17T08:05:14.816Z",
                "Answer_score":0,
                "Answer_body":"There are soft limits on Feature Store TPS, feature number etc. But soft limits can be increased based on your need.\n\nMaximum number of feature groups per AWS account: Soft limit of 100.\nMaximum number of feature definitions per feature group: 2500.\nMaximum Transactions per second (TPS) per API per AWS account: Soft limit of 10000 TPS per API excluding the BatchGetRecord API call, which has a soft limit of 500 TPS.\nMaximum size of a record: 350KB.\nMaximum size of a feature value: 350KB.\nMaximum number of concurrent feature group creation workflows: 4.\nBatchGetRecord API: Can contain as many as 100 records and can query up to 10 feature groups.\n\nYou can check Limits and Quotas in the SageMaker Developer Guide.\n\nDepending on your data ingestion use cases, your requirements and runtime context might be different:\n\nExperimenting with new ML features\nStreaming feature ingestion\n*Bulk feature ingestion as part of a batch pipeline **\n\nFor more details on use cases and Feature ingestion APIs, see this blogpost",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: a feature store throughput and latency; content:what is the maximum throughput of aws feature store. also what is the p99 value of latency of aws feature store (online store) ?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking about the maximum throughput and p99 latency of the AWS Feature Store (online store)."
    },
    {
        "Question_id":null,
        "Question_title":"Weird login error with wandb?",
        "Question_body":"<p>Error<\/p>\n<pre><code class=\"lang-auto\">---- Running your python main ----\nwandb=&lt;module 'wandb' from '\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/wandb\/__init__.py'&gt;\nwandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\nwandb: Network error (ReadTimeout), entering retry loop.\nwandb: Network error (ReadTimeout), entering retry loop.\nProblem at: \/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/wandb_logging\/common.py 25 setup_wand\nwandb: ERROR Error communicating with wandb process\nwandb: ERROR try: wandb.init(settings=wandb.Settings(start_method='fork'))\nwandb: ERROR or:  wandb.init(settings=wandb.Settings(start_method='thread'))\nwandb: ERROR For more info see: https:\/\/docs.wandb.ai\/library\/init#init-start-error\nTraceback (most recent call last):\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 323, in &lt;module&gt;\n    main()\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 254, in main\n    args: Namespace = load_args()\n  File \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 247, in load_args\n    setup_wand(args)\n  File \"\/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/wandb_logging\/common.py\", line 25, in setup_wand\n    wandb.init(project=args.wandb_project,\n  File \"\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\", line 999, in init\n    run = wi.init()\n  File \"\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/wandb\/sdk\/wandb_init.py\", line 653, in init\n    raise UsageError(error_message)\nwandb.errors.UsageError: Error communicating with wandb process\ntry: wandb.init(settings=wandb.Settings(start_method='fork'))\nor:  wandb.init(settings=wandb.Settings(start_method='thread'))\nFor more info see: https:\/\/docs.wandb.ai\/library\/init#init-start-error\n<\/code><\/pre>\n<p>Why is this happening and what is the solution?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1651943863759,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":71.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/weird-login-error-with-wandb\/2379",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":5638,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-05-10T22:19:23.551Z",
                "cooked":"<p>Hey <a class=\"mention\" href=\"\/u\/brando\">@brando<\/a>,<\/p>\n<p>I\u2019m sorry to hear you are facing this. This error usually occurs due to multiprocessing and issues with the OS. I\u2019m curious if you have tried the 2 suggestions in the error message:<\/p>\n<pre><code class=\"lang-auto\">wandb.init(settings=wandb.Settings(start_method='fork'))\nwandb.init(settings=wandb.Settings(start_method='thread'))\n<\/code><\/pre>\n<p>and if either of them worked for you. Additionally, could you share what operating system you are running your code on?<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-05-10T22:19:23.551Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":0.8,
                "yours":false,
                "topic_id":2379,
                "topic_slug":"weird-login-error-with-wandb",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5729,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-05-16T20:00:53.705Z",
                "cooked":"<p>Hi Brando,<\/p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.<\/p>\n<p>Best,<br>\nWeights &amp; Biases<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-05-16T20:00:53.705Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":0.8,
                "yours":false,
                "topic_id":2379,
                "topic_slug":"weird-login-error-with-wandb",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6426,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-07-09T22:19:42.435Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":4,
                "post_type":3,
                "updated_at":"2022-07-09T22:19:42.435Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":2379,
                "topic_slug":"weird-login-error-with-wandb",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: weird login error with ?; content:<p>error<\/p>\n<pre><code class=\"lang-auto\">---- running your python main ----\n=&lt;module '' from '\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/\/__init__.py'&gt;\n: w&amp;b api key is configured. use ` login --relogin` to force relogin\n: network error (readtimeout), entering retry loop.\n: network error (readtimeout), entering retry loop.\nproblem at: \/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/_logging\/common.py 25 setup_wand\n: error error communicating with  process\n: error try: .init(settings=.settings(start_method='fork'))\n: error or:  .init(settings=.settings(start_method='thread'))\n: error for more info see: https:\/\/docs..ai\/library\/init#init-start-error\ntraceback (most recent call last):\n  file \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 323, in &lt;module&gt;\n    main()\n  file \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 254, in main\n    args: namespace = load_args()\n  file \"\/home\/miranda9\/diversity-for-predictive-success-of-meta-learning\/div_src\/diversity_src\/experiment_mains\/main_diversity_with_task2vec.py\", line 247, in load_args\n    setup_wand(args)\n  file \"\/home\/miranda9\/ultimate-utils\/ultimate-utils-proj-src\/uutils\/logging_uu\/_logging\/common.py\", line 25, in setup_wand\n    .init(project=args._project,\n  file \"\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/\/sdk\/_init.py\", line 999, in init\n    run = wi.init()\n  file \"\/home\/miranda9\/miniconda3\/envs\/meta_learning_a100\/lib\/python3.9\/site-packages\/\/sdk\/_init.py\", line 653, in init\n    raise usageerror(error_message)\n.errors.usageerror: error communicating with  process\ntry: .init(settings=.settings(start_method='fork'))\nor:  .init(settings=.settings(start_method='thread'))\nfor more info see: https:\/\/docs..ai\/library\/init#init-start-error\n<\/code><\/pre>\n<p>why is this happening and what is the solution?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing a weird login error with a network error (readtimeout) and an error communicating with a process. The solution is to try .init(settings=.settings(start_method='fork')) or .init(settings=.settings(start_method='thread')) for more information."
    },
    {
        "Question_id":null,
        "Question_title":"Error while trying to run data",
        "Question_body":"i am new on Azure ML and trying to get familiar.i imported my data from the Web URL via HTTP. i tried running but it cant be completed as it keeps giving me Error 0030 , error while downloading the file , error 0039, error while completing operations.\nkindly help ou as i cant proceed",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1604177052600,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/147105\/error-while-trying-to-run-data.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-02T15:54:20.51Z",
                "Answer_score":0,
                "Answer_body":"@feyi-4924 Thanks for the question, Please share the steps that you performed, Also please share the web url to check. Here are the samples to work with the data.\n\nConnect data to UI:https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-connect-data-ui",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-14T18:41:10.61Z",
                "Answer_score":0,
                "Answer_body":"I come across the same issues as the person above in a similar environment. The URL: https:\/\/docs.google.com\/spreadsheets\/d\/1kIQlTMT871e9REV5UABr-PTcCJ-6BMb7TteMxYBOYeo\/pub?gid=1225723766&single=true&output=csv. I use always comes back as failed with the 0030 error. When I create the experiment, I drag the import data in. Then I change the data source to HTTP. Next I paste the URL into the source URL box. After that I connect a summarize box under the import data box to attempt to see the results but each time I run it, I always fail.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: error while trying to run data; content:i am new on  and trying to get familiar.i imported my data from the web url via http. i tried running but it cant be completed as it keeps giving me error 0030 , error while downloading the file , error 0039, error while completing operations.\nkindly help ou as i cant proceed",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty running their data on Azure ML, receiving errors 0030 and 0039. They are new to Azure ML and need help to proceed."
    },
    {
        "Question_id":null,
        "Question_title":"Use parameters with include flags",
        "Question_body":"<p>I\u2019m trying to use parameters to set portions of flags, but it seems that the parameters don\u2019t affect flags which have been imported. Here\u2019s a simple case:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">- config: config\n  flags:\n    flag-key: \"{{param-key}}\"\n\n- model: model\n  params:\n    param-key: param-value\n  operations:\n    op:\n      main: path\n      flags:\n        $include: config\n<\/code><\/pre>\n<p>This results in flag:<br>\nflag-key: \u2018{{param-key}}\u2019<br>\nwhereas I\u2019d want it to be  the same result as if I declared the flag directly in the operation config:<br>\nflag-key: param-value<\/p>\n<p>In my specific use-case I\u2019m also getting the parameters from a config which this model extends, in case that affects the issue. Essentially the setup is that we have all parameters in a single config for organization, and there\u2019s many models\/operations which each use one of a few different sets of flags, and all flag sets reference the parameters.  Any recommendations or workarounds would be appreciated, thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1667442665957,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":37.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/my.guild.ai\/t\/use-parameters-with-include-flags\/952",
        "Tool":"Guild AI",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2071,
                "name":"Ben Klingensmith",
                "username":"visimo-ben",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/v\/f9ae1b\/{size}.png",
                "created_at":"2022-11-10T21:41:25.875Z",
                "cooked":"<p>Found a workaround of using yaml anchors instead of $include.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-11-10T21:41:25.875Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.2,
                "yours":false,
                "topic_id":952,
                "topic_slug":"use-parameters-with-include-flags",
                "display_username":"Ben Klingensmith",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":180,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: use parameters with include flags; content:<p>i\u2019m trying to use parameters to set portions of flags, but it seems that the parameters don\u2019t affect flags which have been imported. here\u2019s a simple case:<\/p>\n<pre data-code-wrap=\"plaintext\"><code class=\"lang-nohighlight\">- config: config\n  flags:\n    flag-key: \"{{param-key}}\"\n\n- model: model\n  params:\n    param-key: param-value\n  operations:\n    op:\n      main: path\n      flags:\n        $include: config\n<\/code><\/pre>\n<p>this results in flag:<br>\nflag-key: \u2018{{param-key}}\u2019<br>\nwhereas i\u2019d want it to be  the same result as if i declared the flag directly in the operation config:<br>\nflag-key: param-value<\/p>\n<p>in my specific use-case i\u2019m also getting the parameters from a config which this model extends, in case that affects the issue. essentially the setup is that we have all parameters in a single config for organization, and there\u2019s many models\/operations which each use one of a few different sets of flags, and all flag sets reference the parameters.  any recommendations or workarounds would be appreciated, thanks!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to use parameters to set portions of flags, but the parameters don't seem to affect flags which have been imported. They are also getting the parameters from a config which the model extends."
    },
    {
        "Question_id":null,
        "Question_title":"Wrong display of .ilearner file",
        "Question_body":"Can anyone help me with this issue please ?\nI get the file (in .ilearner format) cannot be correctly displayed cuz it contains an unknown extension when I try to open it.",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1620835289703,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/392953\/wrong-display-of-ilearner-file.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-25T06:55:57.853Z",
                "Answer_score":0,
                "Answer_body":"@Salah-1213 Hello Salah,\n\nPer my research, the ilearn interface is supported on Azure Machine Learning Studio(class), but I can not find any official document indicate this is supported on Azure Machine Learning Designer as well. Sorry for the experience. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/ilearner-interface\n\nIf there is any document you are using has any clue please let me know.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: wrong display of .ilearner file; content:can anyone help me with this issue please ?\ni get the file (in .ilearner format) cannot be correctly displayed cuz it contains an unknown extension when i try to open it.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having an issue with a .ilearner file not displaying correctly due to an unknown extension when trying to open it, and is asking for help."
    },
    {
        "Question_id":null,
        "Question_title":"How do I upload artifacts (e.g. zip files) manually in the website GUI?",
        "Question_body":"<p>I just want to upload artifacts manually place and drop and the end of the project. I have 2 zip files. How do I do that?<\/p>\n<p>Ideally, I want to avoid writing code. I tried dropping it into a report but the report didn\u2019t do anything when I dropped my zip files.<\/p>\n<hr>\n<p>also, the artifacts guide seems unncesserily long and not explain the most basic questions imho. e.g.<\/p>\n<ol>\n<li>Are we suppose to upload artifacts on every run?<\/li>\n<li>how do we make sure we don\u2019t double upload data?<\/li>\n<li>how does wandb version to avoid duplicate data uploaded<\/li>\n<\/ol>\n<p>perhaps a shorter tutorial that is more to the point would be nice, especially explaining the expected\/common workflow with artifacts.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1633111385957,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":null,
        "Question_view_count":406.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-do-i-upload-artifacts-e-g-zip-files-manually-in-the-website-gui\/840",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2212,
                "name":"Brando Miranda",
                "username":"brando",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/brando\/{size}\/199_2.png",
                "created_at":"2021-10-06T21:24:01.391Z",
                "cooked":"<p>I am particularly interested to upload zip files to my reports.<\/p>\n<hr>\n<p>posted in tech support since the web UI doesn\u2019t do it its more likely to be a feature request: <a href=\"https:\/\/community.wandb.ai\/t\/feature-request-adding-zip-files-to-reports\/877\" class=\"inline-onebox\">Feature request: adding zip files to reports<\/a><\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-10-06T21:26:40.035Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":21,
                "reads":11,
                "readers_count":10,
                "score":167.2,
                "yours":false,
                "topic_id":840,
                "topic_slug":"how-do-i-upload-artifacts-e-g-zip-files-manually-in-the-website-gui",
                "display_username":"Brando Miranda",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":2,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/community.wandb.ai\/t\/feature-request-adding-zip-files-to-reports\/877",
                        "internal":true,
                        "reflection":true,
                        "title":"Feature request: adding zip files to reports",
                        "clicks":6
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":2
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":304,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2236,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2021-10-08T15:39:46.085Z",
                "cooked":"<p>Hey Brando,<\/p>\n<p>You can find the information about how Artifacts handle duplication here. I\u2019d also suggest checking out this tutorial showing the common workflows with Artifacts.<br>\nI followed up in the other thread on uploading zip files. Let me know if you have any questions.<\/p>\n<p>Best,<br>\nArman<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-10-08T15:39:46.085Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":1.2,
                "yours":false,
                "topic_id":840,
                "topic_slug":"how-do-i-upload-artifacts-e-g-zip-files-manually-in-the-website-gui",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how do i upload artifacts (e.g. zip files) manually in the website gui?; content:<p>i just want to upload artifacts manually place and drop and the end of the project. i have 2 zip files. how do i do that?<\/p>\n<p>ideally, i want to avoid writing code. i tried dropping it into a report but the report didn\u2019t do anything when i dropped my zip files.<\/p>\n<hr>\n<p>also, the artifacts guide seems unncesserily long and not explain the most basic questions imho. e.g.<\/p>\n<ol>\n<li>are we suppose to upload artifacts on every run?<\/li>\n<li>how do we make sure we don\u2019t double upload data?<\/li>\n<li>how does  version to avoid duplicate data uploaded<\/li>\n<\/ol>\n<p>perhaps a shorter tutorial that is more to the point would be nice, especially explaining the expected\/common workflow with artifacts.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to upload two zip files manually to the website GUI without writing code, and is also looking for a shorter tutorial that explains the expected\/common workflow with artifacts."
    },
    {
        "Question_id":65719292.0,
        "Question_title":"How to run tensorboard for tensorflow in AWS Sagemaker?",
        "Question_body":"<p>I need to visualize real-time losses and metrics for a tensorflow model on AWS Sagemaker instance.\nIn a Jupyter notebook, I tried running<\/p>\n<pre><code>%load_ext tensorboard\n%tensorboard --logdir &lt;path&gt;\n<\/code><\/pre>\n<p>But nothing really happened. How can I get this working?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1610628627223,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-web-services",
            "tensorflow",
            "tensorflow2.0",
            "tensorboard",
            "amazon-sagemaker"
        ],
        "Question_view_count":715.0,
        "Owner_creation_time":1512023194592,
        "Owner_last_access_time":1663919015323,
        "Owner_reputation":547.0,
        "Owner_up_votes":71.0,
        "Owner_down_votes":0.0,
        "Owner_views":61.0,
        "Answer_body":"<p>You need to use the conda_pytorch_36 kernel (this is the one I used) and tensorboard is not installed by default so you need to run<\/p>\n<pre><code>!pip install tensorboard\n<\/code><\/pre>\n<p>Then you will get a blank screen when you run.<\/p>\n<pre><code>%load_ext tensorboard\n%tensorboard --logdir &quot;.\/runs&quot;\n<\/code><\/pre>\n<p>You can connect to tensorboard using your URL with notebook or lab replaced with proxy\/6006<\/p>\n<pre><code>https:\/\/YOUR_NOTEBOOK_INSTANCE_NAME.notebook.ap-northeast-1.sagemaker.aws\/proxy\/6006\/\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1610631020420,
        "Answer_score":2.0,
        "Owner_location":null,
        "Question_last_edit_time":1610628935100,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65719292",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to run tensorboard for tensorflow in ?; content:<p>i need to visualize real-time losses and metrics for a tensorflow model on  instance.\nin a jupyter notebook, i tried running<\/p>\n<pre><code>%load_ext tensorboard\n%tensorboard --logdir &lt;path&gt;\n<\/code><\/pre>\n<p>but nothing really happened. how can i get this working?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to visualize real-time losses and metrics for a tensorflow model on an instance, but running the code in a jupyter notebook did not work."
    },
    {
        "Question_id":69046990.0,
        "Question_title":"How to pass dependency files to sagemaker SKLearnProcessor and use it in Pipeline?",
        "Question_body":"<p>I need to import function from different python scripts, which will used inside <code>preprocessing.py<\/code> file. I was not able to find a way to pass the dependent files to <code>SKLearnProcessor<\/code> Object, due to which I am getting <code>ModuleNotFoundError<\/code>.<\/p>\n<p><strong>Code:<\/strong><\/p>\n<pre><code>from sagemaker.sklearn.processing import SKLearnProcessor\nfrom sagemaker.processing import ProcessingInput, ProcessingOutput\n\nsklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n                                     role=role,\n                                     instance_type='ml.m5.xlarge',\n                                     instance_count=1)\n\n\nsklearn_processor.run(code='preprocessing.py',\n                      inputs=[ProcessingInput(\n                        source=input_data,\n                        destination='\/opt\/ml\/processing\/input')],\n                      outputs=[ProcessingOutput(output_name='train_data',\n                                                source='\/opt\/ml\/processing\/train'),\n                               ProcessingOutput(output_name='test_data',\n                                                source='\/opt\/ml\/processing\/test')],\n                      arguments=['--train-test-split-ratio', '0.2']\n                     )\n<\/code><\/pre>\n<p>I would like to pass,\n<code>dependent_files = ['file1.py', 'file2.py', 'requirements.txt']<\/code>. So, that <code>preprocessing.py<\/code> have access to all the dependent modules.<\/p>\n<p>And also need to install libraries from <code>requirements.txt<\/code> file.<\/p>\n<p>Can you share any work around or a right way to do this?<\/p>\n<p><strong>Update-25-11-2021:<\/strong><\/p>\n<p><strong>Q1.<\/strong>(Answered but looking to solve using <code>FrameworkProcessor<\/code>)<\/p>\n<p><a href=\"https:\/\/github.com\/aws\/sagemaker-python-sdk\/blob\/99f023e76a5db060907a796d4d8fee550f005844\/src\/sagemaker\/processing.py#L1426\" rel=\"noreferrer\">Here<\/a>, the <code>get_run_args<\/code> function, is handling <code>dependencies<\/code>, <code>source_dir<\/code> and <code>code<\/code> parameters by using <a href=\"https:\/\/github.com\/aws\/sagemaker-python-sdk\/blob\/99f023e76a5db060907a796d4d8fee550f005844\/src\/sagemaker\/processing.py#L1265\" rel=\"noreferrer\">FrameworkProcessor<\/a>. Is there any way that we can set this parameters from <code>ScriptProcessor<\/code> or <code>SKLearnProcessor<\/code> or any other <code>Processor<\/code> to set them?<\/p>\n<p><strong>Q2.<\/strong><\/p>\n<p>Can you also please show some reference to use our <code>Processor<\/code> as <code>sagemaker.workflow.steps.ProcessingStep<\/code> and then use in <code>sagemaker.workflow.pipeline.Pipeline<\/code>?<\/p>\n<p>For having <code>Pipeline<\/code>, do we need <code>sagemaker-project<\/code> as mandatory or can we create <code>Pipeline<\/code> directly without any <code>Sagemaker-Project<\/code>?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":5.0,
        "Question_creation_time":1630681185260,
        "Question_favorite_count":2.0,
        "Question_score":11.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "scikit-learn",
            "amazon-sagemaker"
        ],
        "Question_view_count":2139.0,
        "Owner_creation_time":1500824148408,
        "Owner_last_access_time":1664025062208,
        "Owner_reputation":4419.0,
        "Owner_up_votes":434.0,
        "Owner_down_votes":324.0,
        "Owner_views":962.0,
        "Answer_body":"<p>There are a couple of options for you to accomplish that.<\/p>\n<p>One that is really simple is adding all additional files to a folder, example:<\/p>\n<pre><code>.\n\u251c\u2500\u2500 my_package\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 file1.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 file2.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 preprocessing.py\n<\/code><\/pre>\n<p>Then send this entire folder as another input under the same <code>\/opt\/ml\/processing\/input\/code\/<\/code>, example:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from sagemaker.sklearn.processing import SKLearnProcessor\nfrom sagemaker.processing import ProcessingInput, ProcessingOutput\n\nsklearn_processor = SKLearnProcessor(\n    framework_version=&quot;0.20.0&quot;,\n    role=role,\n    instance_type=&quot;ml.m5.xlarge&quot;,\n    instance_count=1,\n)\n\nsklearn_processor.run(\n    code=&quot;preprocessing.py&quot;,  # &lt;- this gets uploaded as \/opt\/ml\/processing\/input\/code\/preprocessing.py\n    inputs=[\n        ProcessingInput(source=input_data, destination='\/opt\/ml\/processing\/input'),\n        # Send my_package as \/opt\/ml\/processing\/input\/code\/my_package\/\n        ProcessingInput(source='my_package\/', destination=&quot;\/opt\/ml\/processing\/input\/code\/my_package\/&quot;)\n    ],\n    outputs=[\n        ProcessingOutput(output_name=&quot;train_data&quot;, source=&quot;\/opt\/ml\/processing\/train&quot;),\n        ProcessingOutput(output_name=&quot;test_data&quot;, source=&quot;\/opt\/ml\/processing\/test&quot;),\n    ],\n    arguments=[&quot;--train-test-split-ratio&quot;, &quot;0.2&quot;],\n)\n<\/code><\/pre>\n<p>What happens is that <code>sagemaker-python-sdk<\/code> is going to put your argument <code>code=&quot;preprocessing.py&quot;<\/code> under <code>\/opt\/ml\/processing\/input\/code\/<\/code> and you will have <code>my_package\/<\/code> under the same directory.<\/p>\n<p><strong>Edit:<\/strong><\/p>\n<p>For the <code>requirements.txt<\/code>, you can add to your <code>preprocessing.py<\/code>:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import sys\nimport subprocess\n\nsubprocess.check_call([\n    sys.executable, &quot;-m&quot;, &quot;pip&quot;, &quot;install&quot;, &quot;-r&quot;,\n    &quot;\/opt\/ml\/processing\/input\/code\/my_package\/requirements.txt&quot;,\n])\n<\/code><\/pre>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1637782762627,
        "Answer_score":17.0,
        "Owner_location":"India",
        "Question_last_edit_time":1637936310430,
        "Answer_last_edit_time":1637783228436,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69046990",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to pass dependency files to  sklearnprocessor and use it in pipeline?; content:<p>i need to import function from different python scripts, which will used inside <code>preprocessing.py<\/code> file. i was not able to find a way to pass the dependent files to <code>sklearnprocessor<\/code> object, due to which i am getting <code>modulenotfounderror<\/code>.<\/p>\n<p><strong>code:<\/strong><\/p>\n<pre><code>from .sklearn.processing import sklearnprocessor\nfrom .processing import processinginput, processingoutput\n\nsklearn_processor = sklearnprocessor(framework_version='0.20.0',\n                                     role=role,\n                                     instance_type='ml.m5.xlarge',\n                                     instance_count=1)\n\n\nsklearn_processor.run(code='preprocessing.py',\n                      inputs=[processinginput(\n                        source=input_data,\n                        destination='\/opt\/ml\/processing\/input')],\n                      outputs=[processingoutput(output_name='train_data',\n                                                source='\/opt\/ml\/processing\/train'),\n                               processingoutput(output_name='test_data',\n                                                source='\/opt\/ml\/processing\/test')],\n                      arguments=['--train-test-split-ratio', '0.2']\n                     )\n<\/code><\/pre>\n<p>i would like to pass,\n<code>dependent_files = ['file1.py', 'file2.py', 'requirements.txt']<\/code>. so, that <code>preprocessing.py<\/code> have access to all the dependent modules.<\/p>\n<p>and also need to install libraries from <code>requirements.txt<\/code> file.<\/p>\n<p>can you share any work around or a right way to do this?<\/p>\n<p><strong>update-25-11-2021:<\/strong><\/p>\n<p><strong>q1.<\/strong>(answered but looking to solve using <code>frameworkprocessor<\/code>)<\/p>\n<p><a href=\"https:\/\/github.com\/aws\/-python-sdk\/blob\/99f023e76a5db060907a796d4d8fee550f005844\/src\/\/processing.py#l1426\" rel=\"noreferrer\">here<\/a>, the <code>get_run_args<\/code> function, is handling <code>dependencies<\/code>, <code>source_dir<\/code> and <code>code<\/code> parameters by using <a href=\"https:\/\/github.com\/aws\/-python-sdk\/blob\/99f023e76a5db060907a796d4d8fee550f005844\/src\/\/processing.py#l1265\" rel=\"noreferrer\">frameworkprocessor<\/a>. is there any way that we can set this parameters from <code>scriptprocessor<\/code> or <code>sklearnprocessor<\/code> or any other <code>processor<\/code> to set them?<\/p>\n<p><strong>q2.<\/strong><\/p>\n<p>can you also please show some reference to use our <code>processor<\/code> as <code>.workflow.steps.processingstep<\/code> and then use in <code>.workflow.pipeline.pipeline<\/code>?<\/p>\n<p>for having <code>pipeline<\/code>, do we need <code>-project<\/code> as mandatory or can we create <code>pipeline<\/code> directly without any <code>-project<\/code>?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to pass dependent files and install libraries from a requirements.txt file to the sklearnprocessor object in order to access the modules in preprocessing.py. They are also looking for references to use the processor as a processingstep and create a pipeline without a project."
    },
    {
        "Question_id":68919823.0,
        "Question_title":"AzureML endpoint deploy to AKS, the export parameter, deprecated since v1.14,is no longer supported",
        "Question_body":"<p>I'm trying to deploy a model in AzureML and publish it as a endpoint in a Azure Kubernetes environment. This action gives after some time the following error:<\/p>\n<blockquote>\n<p>{\n&quot;code&quot;: &quot;KubernetesError&quot;,\n&quot;message&quot;: &quot;Kubernetes error: Bad Request. Reason: {&quot; kind &quot;:&quot; Status &quot;,&quot; apiVersion &quot;:&quot; v1 &quot;,&quot; metadata &quot;:{},&quot; status &quot;:&quot; Failure &quot;,&quot; message &quot;:&quot; the export parameter, deprecated since v1.14,is no longer supported &quot;,&quot; reason &quot;:&quot; BadRequest &quot;,&quot; code &quot;:400}&quot;\n}<\/p>\n<\/blockquote>\n<p>This Kubernetes change seems to be mentioned in: <a href=\"https:\/\/github.com\/kubernetes\/kubernetes\/blob\/master\/CHANGELOG\/CHANGELOG-1.14.md#deprecations\" rel=\"nofollow noreferrer\">https:\/\/github.com\/kubernetes\/kubernetes\/blob\/master\/CHANGELOG\/CHANGELOG-1.14.md#deprecations<\/a> and I'm using Kubernetes 1.21.2<\/p>\n<p>The code is based on <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#register-a-model-from-a-local-file-1\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#register-a-model-from-a-local-file-1<\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python#deploy-to-aks\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python#deploy-to-aks<\/a><\/p>\n<p>Here is the script:<\/p>\n<pre><code>from azureml.core import Workspace, Environment\nfrom azureml.core import Environment\nfrom azureml.core.model import InferenceConfig\nimport urllib.request\nfrom azureml.core.model import Model\nfrom azureml.core.webservice.aks import AksWebservice\nfrom azureml.core.compute import ComputeTarget\n\nws=Workspace(&quot;xyz-subscription&quot;, &quot;xyz-resourcegroup&quot;, &quot;xyz-azure-ml-name&quot;)\nenv=Environment('example-env')\n\nurllib.request.urlretrieve(&quot;https:\/\/aka.ms\/bidaf-9-model&quot;, &quot;model.onnx&quot;)\n\nmodel = Model.register(ws, model_name=&quot;bidaf_onnx&quot;, model_path=&quot;.\/model.onnx&quot;)\n\ndummy_inference_config = InferenceConfig(\n    environment=env,\n    source_directory=&quot;.\/source_dir&quot;,\n    entry_script=&quot;.\/echo_score.py&quot;,\n)\n\ncompute=ComputeTarget(ws, &quot;k8s-example&quot;)\n\ndeployment_config=AksWebservice.deploy_configuration(\n    autoscale_enabled=True, \n    cpu_cores=0.1, \n    memory_gb=0.5, \n    auth_enabled=True, \n    enable_app_insights=True, \n    max_request_wait_time=4000, \n    namespace=&quot;example-namespace&quot;) \n\nservice = Model.deploy(\n    ws,\n    &quot;examplemodel&quot;,\n    [model],\n    dummy_inference_config,\n    deployment_config,\n    compute,\n    overwrite=True,\n)\nservice.wait_for_deployment(show_output=True)\n\nprint(service.get_logs())\n\n<\/code><\/pre>\n<p>Does somebody knows what is going wrong here?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1629881809147,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "azure-aks",
            "azure-machine-learning-service"
        ],
        "Question_view_count":445.0,
        "Owner_creation_time":1629880841636,
        "Owner_last_access_time":1648652265423,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1629882634087,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68919823",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  endpoint deploy to aks, the export parameter, deprecated since v1.14,is no longer supported; content:<p>i'm trying to deploy a model in  and publish it as a endpoint in a azure kubernetes environment. this action gives after some time the following error:<\/p>\n<blockquote>\n<p>{\n&quot;code&quot;: &quot;kuberneteserror&quot;,\n&quot;message&quot;: &quot;kubernetes error: bad request. reason: {&quot; kind &quot;:&quot; status &quot;,&quot; apiversion &quot;:&quot; v1 &quot;,&quot; metadata &quot;:{},&quot; status &quot;:&quot; failure &quot;,&quot; message &quot;:&quot; the export parameter, deprecated since v1.14,is no longer supported &quot;,&quot; reason &quot;:&quot; badrequest &quot;,&quot; code &quot;:400}&quot;\n}<\/p>\n<\/blockquote>\n<p>this kubernetes change seems to be mentioned in: <a href=\"https:\/\/github.com\/kubernetes\/kubernetes\/blob\/master\/changelog\/changelog-1.14.md#deprecations\" rel=\"nofollow noreferrer\">https:\/\/github.com\/kubernetes\/kubernetes\/blob\/master\/changelog\/changelog-1.14.md#deprecations<\/a> and i'm using kubernetes 1.21.2<\/p>\n<p>the code is based on <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#register-a-model-from-a-local-file-1\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#register-a-model-from-a-local-file-1<\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python#deploy-to-aks\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python#deploy-to-aks<\/a><\/p>\n<p>here is the script:<\/p>\n<pre><code>from .core import workspace, environment\nfrom .core import environment\nfrom .core.model import inferenceconfig\nimport urllib.request\nfrom .core.model import model\nfrom .core.webservice.aks import akswebservice\nfrom .core.compute import computetarget\n\nws=workspace(&quot;xyz-subscription&quot;, &quot;xyz-resourcegroup&quot;, &quot;xyz-azure-ml-name&quot;)\nenv=environment('example-env')\n\nurllib.request.urlretrieve(&quot;https:\/\/aka.ms\/bidaf-9-model&quot;, &quot;model.onnx&quot;)\n\nmodel = model.register(ws, model_name=&quot;bidaf_onnx&quot;, model_path=&quot;.\/model.onnx&quot;)\n\ndummy_inference_config = inferenceconfig(\n    environment=env,\n    source_directory=&quot;.\/source_dir&quot;,\n    entry_script=&quot;.\/echo_score.py&quot;,\n)\n\ncompute=computetarget(ws, &quot;k8s-example&quot;)\n\ndeployment_config=akswebservice.deploy_configuration(\n    autoscale_enabled=true, \n    cpu_cores=0.1, \n    memory_gb=0.5, \n    auth_enabled=true, \n    enable_app_insights=true, \n    max_request_wait_time=4000, \n    namespace=&quot;example-namespace&quot;) \n\nservice = model.deploy(\n    ws,\n    &quot;examplemodel&quot;,\n    [model],\n    dummy_inference_config,\n    deployment_config,\n    compute,\n    overwrite=true,\n)\nservice.wait_for_deployment(show_output=true)\n\nprint(service.get_logs())\n\n<\/code><\/pre>\n<p>does somebody knows what is going wrong here?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when trying to deploy a model to an Azure Kubernetes environment, which is due to the export parameter being deprecated since v1.14 and no longer supported."
    },
    {
        "Question_id":69924198.0,
        "Question_title":"INTERNAL_SERVER_ERROR in MLFlow UI",
        "Question_body":"<p>I am using MLFlow to connect to MSSQL Server.\nWhen I launch <code>mlflow ui<\/code> using command line, the UI appears with an Internal Error.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4W0B5.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4W0B5.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>On looking into SQL Profiler, I found that one of the queries is not able to execute properly.<\/p>\n<pre><code>[SQL: SELECT DISTINCT runs.run_uuid AS runs_run_uuid, runs.name AS runs_name, runs.source_type AS runs_source_type, runs.source_name AS runs_source_name, runs.entry_point_name AS runs_entry_point_name, runs.user_id AS runs_user_id, runs.status AS runs_status, runs.start_time AS runs_start_time, runs.end_time AS runs_end_time, runs.source_version AS runs_source_version, runs.lifecycle_stage AS runs_lifecycle_stage, runs.artifact_uri AS runs_artifact_uri, runs.experiment_id AS runs_experiment_id, CASE WHEN (runs.start_time IS NULL) THEN ? ELSE ? END AS anon_1\nFROM runs\nWHERE runs.experiment_id IN (?) AND runs.lifecycle_stage IN (?) ORDER BY CASE WHEN (runs.start_time IS NULL) THEN ? ELSE ? END, runs.start_time DESC, runs.run_uuid\n OFFSET ? ROWS\n FETCH FIRST ? ROWS ONLY]\n[parameters: (1, 0, '0', 'active', 1, 0, 0, 100)]\n<\/code><\/pre>\n<p>Any help regarding this is highly appreciated.\nI feel that somehow I am doing something wrong, but I have got same error while setting it up in another machine.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1636613324940,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "mlflow"
        ],
        "Question_view_count":293.0,
        "Owner_creation_time":1365013611123,
        "Owner_last_access_time":1663912254990,
        "Owner_reputation":476.0,
        "Owner_up_votes":41.0,
        "Owner_down_votes":1.0,
        "Owner_views":76.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69924198",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: internal_server_error in  ui; content:<p>i am using  to connect to mssql server.\nwhen i launch <code> ui<\/code> using command line, the ui appears with an internal error.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4w0b5.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4w0b5.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>on looking into sql profiler, i found that one of the queries is not able to execute properly.<\/p>\n<pre><code>[sql: select distinct runs.run_uuid as runs_run_uuid, runs.name as runs_name, runs.source_type as runs_source_type, runs.source_name as runs_source_name, runs.entry_point_name as runs_entry_point_name, runs.user_id as runs_user_id, runs.status as runs_status, runs.start_time as runs_start_time, runs.end_time as runs_end_time, runs.source_version as runs_source_version, runs.lifecycle_stage as runs_lifecycle_stage, runs.artifact_uri as runs_artifact_uri, runs.experiment_id as runs_experiment_id, case when (runs.start_time is null) then ? else ? end as anon_1\nfrom runs\nwhere runs.experiment_id in (?) and runs.lifecycle_stage in (?) order by case when (runs.start_time is null) then ? else ? end, runs.start_time desc, runs.run_uuid\n offset ? rows\n fetch first ? rows only]\n[parameters: (1, 0, '0', 'active', 1, 0, 0, 100)]\n<\/code><\/pre>\n<p>any help regarding this is highly appreciated.\ni feel that somehow i am doing something wrong, but i have got same error while setting it up in another machine.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an internal server error when launching the UI and has identified an issue with a query in the SQL profiler."
    },
    {
        "Question_id":65940509.0,
        "Question_title":"botocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreateModel operation: Could not access model data",
        "Question_body":"<p>I want to deploy an MLflow image to an AWS Sagemaker endpoint that contains a machine learning model. I executed the following code, which I found in <a href=\"https:\/\/towardsdatascience.com\/deploying-models-to-production-with-mlflow-and-amazon-sagemaker-d21f67909198\" rel=\"nofollow noreferrer\">this blog post<\/a>.<\/p>\n<pre><code>import mlflow.sagemaker as mfs\n\nrun_id = run_id # the model you want to deploy - this run_id was saved when we trained our model\nregion = &quot;us-east-1&quot; # region of your account\naws_id = &quot;XXXXXXXXXXX&quot; # from the aws-cli output\narn = &quot;arn:aws:iam::XXXXXXXXXXX:role\/your-role&quot;\napp_name = &quot;iris-rf-1&quot;\nmodel_uri = &quot;mlruns\/%s\/%s\/artifacts\/random-forest-model&quot; % (experiment_id,run_id) # edit this path based on your working directory\nimage_url = aws_id + &quot;.dkr.ecr.&quot; + region + &quot;.amazonaws.com\/mlflow-pyfunc:1.2.0&quot; # change to your mlflow version\n\nmfs.deploy(app_name=app_name, \n           model_uri=model_uri, \n           region_name=region, \n           mode=&quot;create&quot;,\n           execution_role_arn=arn,\n           image_url=image_url)\n<\/code><\/pre>\n<p>But I got the following error. I checked all policies and permissions attached to the IAM role. They all comply with what the error message complains about. I don't know what to do next. I'd appreciate your help. Thanks.<\/p>\n<p>botocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreateModel operation: Could not access model data at <a href=\"https:\/\/s3.amazonaws.com\/mlflow-sagemaker-us-east-1-xxx\/mlflow-xgb-demo-model-eqktjeoit5mxhmjn-abpanw\/model.tar.gz\" rel=\"nofollow noreferrer\">https:\/\/s3.amazonaws.com\/mlflow-sagemaker-us-east-1-xxx\/mlflow-xgb-demo-model-eqktjeoit5mxhmjn-abpanw\/model.tar.gz<\/a>. Please ensure that the role &quot;arn:aws:iam::xxx:role\/mlflow-sagemaker-dev&quot; exists and that its trust relationship policy allows the action &quot;sts:AssumeRole&quot; for the service principal &quot;sagemaker.amazonaws.com&quot;. Also ensure that the role has &quot;s3:GetObject&quot; permissions and that the object is located in us-east-1.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1611848849710,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker",
            "mlflow"
        ],
        "Question_view_count":1789.0,
        "Owner_creation_time":1482418107070,
        "Owner_last_access_time":1620691767510,
        "Owner_reputation":69.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Raleigh, NC, United States",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65940509",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: botocore.exceptions.clienterror: an error occurred (validationexception) when calling the createmodel operation: could not access model data; content:<p>i want to deploy an  image to an aws sagemaker endpoint that contains a machine learning model. i executed the following code, which i found in <a href=\"https:\/\/towardsdatascience.com\/deploying-models-to-production-with--and-amazon-sagemaker-d21f67909198\" rel=\"nofollow noreferrer\">this blog post<\/a>.<\/p>\n<pre><code>import .sagemaker as mfs\n\nrun_id = run_id # the model you want to deploy - this run_id was saved when we trained our model\nregion = &quot;us-east-1&quot; # region of your account\naws_id = &quot;xxxxxxxxxxx&quot; # from the aws-cli output\narn = &quot;arn:aws:iam::xxxxxxxxxxx:role\/your-role&quot;\napp_name = &quot;iris-rf-1&quot;\nmodel_uri = &quot;mlruns\/%s\/%s\/artifacts\/random-forest-model&quot; % (experiment_id,run_id) # edit this path based on your working directory\nimage_url = aws_id + &quot;.dkr.ecr.&quot; + region + &quot;.amazonaws.com\/-pyfunc:1.2.0&quot; # change to your  version\n\nmfs.deploy(app_name=app_name, \n           model_uri=model_uri, \n           region_name=region, \n           mode=&quot;create&quot;,\n           execution_role_arn=arn,\n           image_url=image_url)\n<\/code><\/pre>\n<p>but i got the following error. i checked all policies and permissions attached to the iam role. they all comply with what the error message complains about. i don't know what to do next. i'd appreciate your help. thanks.<\/p>\n<p>botocore.exceptions.clienterror: an error occurred (validationexception) when calling the createmodel operation: could not access model data at <a href=\"https:\/\/s3.amazonaws.com\/-sagemaker-us-east-1-xxx\/-xgb-demo-model-eqktjeoit5mxhmjn-abpanw\/model.tar.gz\" rel=\"nofollow noreferrer\">https:\/\/s3.amazonaws.com\/-sagemaker-us-east-1-xxx\/-xgb-demo-model-eqktjeoit5mxhmjn-abpanw\/model.tar.gz<\/a>. please ensure that the role &quot;arn:aws:iam::xxx:role\/-sagemaker-dev&quot; exists and that its trust relationship policy allows the action &quot;sts:assumerole&quot; for the service principal &quot;sagemaker.amazonaws.com&quot;. also ensure that the role has &quot;s3:getobject&quot; permissions and that the object is located in us-east-1.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when attempting to deploy an image to an AWS Sagemaker endpoint that contains a machine learning model, and is having trouble ensuring that the role and trust relationship policy are set up correctly."
    },
    {
        "Question_id":68559059.0,
        "Question_title":"DVC connect to Min.IO to access S3",
        "Question_body":"<p>What is the proper way to connect DVC to Min.IO that is connected to some buckets on S3.<\/p>\n<pre><code>AWS-S3(My_Bucket) &gt; Min.io(MY_Bucket aliased as S3)\n<\/code><\/pre>\n<p>Right now i am accessing my bucket by using mc for example <code>mc cp s3\/my_bucket\/datasets datasets<\/code> to copy stuff from there. But I need to setup my DVC to work with min.io as a hub between AWS.S3 and DVC so i can use for example <code>&quot;DVC mc-S3 pull&quot;<\/code> and <code>&quot;DVC AWS-S3 pull&quot;<\/code>.<\/p>\n<p>How do i got for it because while googling i couldn't find anything that i could easily follow.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1627469557323,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-s3",
            "minio",
            "dvc"
        ],
        "Question_view_count":375.0,
        "Owner_creation_time":1578574709920,
        "Owner_last_access_time":1648636957603,
        "Owner_reputation":85.0,
        "Owner_up_votes":7.0,
        "Owner_down_votes":0.0,
        "Owner_views":33.0,
        "Answer_body":"<p>It looks like you are looking for a combination of things.<\/p>\n<p>First, Jorge mentioned you can set <code>endpointurl<\/code> to access Minio the same way as you would access regular S3:<\/p>\n<pre><code>dvc remote add -d minio-remote s3:\/\/mybucket\/path\ndvc remote modify minio-remote endpointurl https:\/\/minio.example.com                          \n<\/code><\/pre>\n<p>Second, it seems you can create <em>two<\/em> remotes - one for S3, one for Minio and use <code>-r<\/code> option that is available for many data management related commands:<\/p>\n<pre><code>dvc pull -r minio-remote\ndvc pull -r s3-remote\ndvc push -r minio-remote\n...\n<\/code><\/pre>\n<p>This way you could <code>push<\/code>\/<code>pull<\/code> data to\/from a specific storage.<\/p>\n<blockquote>\n<p>But I need to setup my DVC to work with min.io as a hub between AWS.S3 and DVC<\/p>\n<\/blockquote>\n<p>There are other possible ways, I think to organize this. It indeed depends on what semantics you expect from <code>DVC mc-S3 pull<\/code>. Please let us know if <code>-r<\/code> is not enough and clarify the question- that would help us here.<\/p>",
        "Answer_comment_count":7.0,
        "Answer_creation_time":1627513406643,
        "Answer_score":2.0,
        "Owner_location":"Poland",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68559059",
        "Tool":"DVC",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  connect to min.io to access s3; content:<p>what is the proper way to connect  to min.io that is connected to some buckets on s3.<\/p>\n<pre><code>aws-s3(my_bucket) &gt; min.io(my_bucket aliased as s3)\n<\/code><\/pre>\n<p>right now i am accessing my bucket by using mc for example <code>mc cp s3\/my_bucket\/datasets datasets<\/code> to copy stuff from there. but i need to setup my  to work with min.io as a hub between aws.s3 and  so i can use for example <code>&quot; mc-s3 pull&quot;<\/code> and <code>&quot; aws-s3 pull&quot;<\/code>.<\/p>\n<p>how do i got for it because while googling i couldn't find anything that i could easily follow.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to set up a connection between min.io and AWS S3 in order to use commands such as \"mc-s3 pull\" and \"aws-s3 pull\"."
    },
    {
        "Question_id":null,
        "Question_title":"Mount gcsfuse in gcloud ai custom-jobs local-run",
        "Question_body":"When locally testing my custom-job through \"gcloud ai custom-jobs local-run\" command, I would like to have access to a bucket mounted though gcsFuse as it happens when I launch the same containerized job from GCloud console. Is there the option to have the same access locally?Thank you for helping",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1664326260000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":96.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Mount-gcsfuse-in-gcloud-ai-custom-jobs-local-run\/td-p\/471834\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-30T08:43:00",
                "Answer_accepted":true,
                "Answer_score":0,
                "Answer_body":"What you could do is use cloud storage as a file system within ai training, since while using fuse your training jobs on both of the platforms can access your data that is stored on Cloud Storage as files on your local file system, also the documentation I shared provides you useful information as the problems you might encounter, permissions, a brief description of cloud storage fuse, performance related information, the restrictions this method has and also how you can make use of the logs.\n\nView solution in original post"
            },
            {
                "Answer_creation_time":"2022-09-30T08:43:00",
                "Answer_accepted":true,
                "Answer_score":0,
                "Answer_body":"What you could do is use cloud storage as a file system within ai training, since while using fuse your training jobs on both of the platforms can access your data that is stored on Cloud Storage as files on your local file system, also the documentation I shared provides you useful information as the problems you might encounter, permissions, a brief description of cloud storage fuse, performance related information, the restrictions this method has and also how you can make use of the logs."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: mount gcsfuse in gcloud ai custom-jobs local-run; content:when locally testing my custom-job through \"gcloud ai custom-jobs local-run\" command, i would like to have access to a bucket mounted though gcsfuse as it happens when i launch the same containerized job from gcloud console. is there the option to have the same access locally?thank you for helping",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to have access to a bucket mounted through gcsfuse when locally testing their custom-job through the \"gcloud ai custom-jobs local-run\" command, and is asking if there is an option to have the same access locally."
    },
    {
        "Question_id":53687754.0,
        "Question_title":"SageMaker linear-learner results not exact?",
        "Question_body":"<p>I have issues with the results i get from the AWS (SageMaker) linear-learner. <\/p>\n\n<p>Namely I was trying to replicate the results I got from R, SAS or Knime (using linear regression) but unfortunately what I get from the linear-learner is different from the mentioned 3 other ways of calculating it.<\/p>\n\n<p>I tried different hyperparameters and configurations but I get inexact regression results even in the very trivial case of synthetically generated data satisfying the relationship<\/p>\n\n<p>Y=X1+2*X2+3<\/p>\n\n<p>In this case there are exact regression coefficients equal to 1,2 and intercept 3. Unlike the mentioned other software the SageMaker linear-learner is returning me values not even close to the right values\nE.g. in one example run I get [0.91547656 1.9826275 3.023757] which is simply not satisfactory.\nYou can see here the relevant part of my code!<\/p>\n\n<pre><code>study=((1.0,3.0,10.0),(2.0,3.0,11.0),(3.0,2.0,10.0),(4.0,7.0,21.0),(5.0,4.0,16.0))\na = np.array(study).astype('float32')\nother_columns=a[:,[0,1]]\nlabels = a[:,2]\nbuf = io.BytesIO()\nsmac.write_numpy_to_dense_tensor(buf, other_columns, labels)\nbuf.seek(0)\nkey = 'my-training-data'\nboto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\ns3_train_data = 's3:\/\/{}\/{}\/train\/{}'.format(bucket, prefix, key)\noutput_location = 's3:\/\/{}\/{}\/output'.format(bucket, prefix)\n\ncontainer = get_image_uri(boto3.Session().region_name, 'linear-learner')\n\nimport boto3\nsess = sagemaker.Session()\nlinear = sagemaker.estimator.Estimator(container,\n                                       role, \n                                       train_instance_count=1, \n                                       train_instance_type='ml.c4.xlarge',                                       \n                                       output_path=output_location,\n                                       sagemaker_session=sess)\nlinear.set_hyperparameters(feature_dim=2,\n                           predictor_type='regressor',\n                           loss='squared_loss',\n                           epochs=50,\n                           early_stopping_patience=100,\n                           mini_batch_size=4)\nlinear.fit({'train': s3_train_data})\n<\/code><\/pre>\n\n<p>Do you have some explanation for the observed not exact results? <\/p>\n\n<p>Thanks\nNikolas<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1544309300887,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "machine-learning",
            "linear-regression",
            "amazon-sagemaker"
        ],
        "Question_view_count":602.0,
        "Owner_creation_time":1544308981910,
        "Owner_last_access_time":1621897106767,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":17.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1544509427787,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53687754",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  linear-learner results not exact?; content:<p>i have issues with the results i get from the aws () linear-learner. <\/p>\n\n<p>namely i was trying to replicate the results i got from r, sas or knime (using linear regression) but unfortunately what i get from the linear-learner is different from the mentioned 3 other ways of calculating it.<\/p>\n\n<p>i tried different hyperparameters and configurations but i get inexact regression results even in the very trivial case of synthetically generated data satisfying the relationship<\/p>\n\n<p>y=x1+2*x2+3<\/p>\n\n<p>in this case there are exact regression coefficients equal to 1,2 and intercept 3. unlike the mentioned other software the  linear-learner is returning me values not even close to the right values\ne.g. in one example run i get [0.91547656 1.9826275 3.023757] which is simply not satisfactory.\nyou can see here the relevant part of my code!<\/p>\n\n<pre><code>study=((1.0,3.0,10.0),(2.0,3.0,11.0),(3.0,2.0,10.0),(4.0,7.0,21.0),(5.0,4.0,16.0))\na = np.array(study).astype('float32')\nother_columns=a[:,[0,1]]\nlabels = a[:,2]\nbuf = io.bytesio()\nsmac.write_numpy_to_dense_tensor(buf, other_columns, labels)\nbuf.seek(0)\nkey = 'my-training-data'\nboto3.resource('s3').bucket(bucket).object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\ns3_train_data = 's3:\/\/{}\/{}\/train\/{}'.format(bucket, prefix, key)\noutput_location = 's3:\/\/{}\/{}\/output'.format(bucket, prefix)\n\ncontainer = get_image_uri(boto3.session().region_name, 'linear-learner')\n\nimport boto3\nsess = .session()\nlinear = .estimator.estimator(container,\n                                       role, \n                                       train_instance_count=1, \n                                       train_instance_type='ml.c4.xlarge',                                       \n                                       output_path=output_location,\n                                       _session=sess)\nlinear.set_hyperparameters(feature_dim=2,\n                           predictor_type='regressor',\n                           loss='squared_loss',\n                           epochs=50,\n                           early_stopping_patience=100,\n                           mini_batch_size=4)\nlinear.fit({'train': s3_train_data})\n<\/code><\/pre>\n\n<p>do you have some explanation for the observed not exact results? <\/p>\n\n<p>thanks\nnikolas<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having issues with the results they are getting from AWS Linear-Learner, as they are not exact compared to the results they get from R, SAS, or KNIME."
    },
    {
        "Question_id":null,
        "Question_title":"[Azure][ML][Python SDK][Environment][Docker] Docker copy missing context",
        "Question_body":"Hello,\n\nI am trying to create an Azure ML Environment using a Dockerfile but it contains the 'COPY' instruction.\n\nFrom the documentation of Environment.from_dockerfile ( https:\/\/docs.microsoft.com\/fr-fr\/python\/api\/azureml-core\/azureml.core.environment(class)?view=azure-ml-py#from-dockerfile-name--dockerfile--conda-specification-none--pip-requirements-none- ), I can not find a way to give it some files along with the Dockerfile itself.\n\nSo, how to pass context to enable using COPY in the Dockerfile ?\n\nThank you for your time !",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1634739305317,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/597612\/azuremlpython-sdkenvironmentdocker-docker-copy-mis.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-21T00:05:42.763Z",
                "Answer_score":1,
                "Answer_body":"Docker context is not supported with AzureML Python SDK at the moment. Context support will added later this year",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: [azure][ml][python sdk][environment][docker] docker copy missing context; content:hello,\n\ni am trying to create an  environment using a dockerfile but it contains the 'copy' instruction.\n\nfrom the documentation of environment.from_dockerfile ( https:\/\/docs.microsoft.com\/fr-fr\/python\/api\/-core\/.core.environment(class)?view=azure-ml-py#from-dockerfile-name--dockerfile--conda-specification-none--pip-requirements-none- ), i can not find a way to give it some files along with the dockerfile itself.\n\nso, how to pass context to enable using copy in the dockerfile ?\n\nthank you for your time !",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to create an Azure ML environment using a Dockerfile, but is having difficulty passing context to enable the use of the 'copy' instruction."
    },
    {
        "Question_id":73567221.0,
        "Question_title":"reading hdf5 file from s3 to sagemaker, is the whole file transferred?",
        "Question_body":"<p>I'm reading a file from my S3 bucket in a notebook in sagemaker studio (same account) using the following code:<\/p>\n<pre><code>dataset_path_in_h5=&quot;\/Mode1\/SingleFault\/SimulationCompleted\/IDV2\/Mode1_IDVInfo_2_100\/Run1\/processdata&quot;\ns3 = s3fs.S3FileSystem()\nh5_file = h5py.File(s3.open(s3url,'rb'), 'r')\ndata = h5_file.get(dataset_path_in_h5)\n<\/code><\/pre>\n<p>But I don't know what actually append behind the scene, does the whole h5 file is being transferred  ? that's seems unlikely as the code is executed quite fast while the whole file is 20GB. Or is just the dataset in dataset_path_in_h5 is transferred ?\nI suppose that if the whole file is transferred at each call it could cost me a lot.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1662025046283,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-s3",
            "hdf5",
            "amazon-sagemaker"
        ],
        "Question_view_count":18.0,
        "Owner_creation_time":1576136255052,
        "Owner_last_access_time":1663858972456,
        "Owner_reputation":795.0,
        "Owner_up_votes":37.0,
        "Owner_down_votes":1.0,
        "Owner_views":37.0,
        "Answer_body":"<p>When you open the file, a file object is created. It has a tiny memory footprint. The dataset values aren't read into memory until you access them.<\/p>\n<p>You are returning <code>data<\/code> as a NumPy array. That loads the entire dataset into memory. (NOTE: the <code>.get()<\/code> method you are using is deprecated. Current syntax is provided in the example.)<\/p>\n<p>As an alternative to returning an array, you can create a dataset object (which also has a small memory foorprint). When you do, the data is read into memory as you need it. Dataset objects behave like NumPy arrays. (Use of a dataset object vs NumPy array depends on downstream usage. Frequently you don't need an array, but sometimes they are required.) Also, if chunked I\/O was enabled when the dataset was created, datasets are read in chunks.<\/p>\n<p>Differences shown below. Note, I used Python's file context manager to open the file. It avoids problems if the file isn't closed properly (you forget or the program exits prematurely).<\/p>\n<pre><code>dataset_path_in_h5=&quot;\/Mode1\/SingleFault\/SimulationCompleted\/IDV2\/Mode1_IDVInfo_2_100\/Run1\/processdata&quot;\ns3 = s3fs.S3FileSystem()\nwith h5py.File(s3.open(s3url,'rb'), 'r') as h5_file:\n     # your way to get a numpy array -- .get() is depreciated:\n     data = h5_file.get(dataset_path_in_h5)\n     # this is the preferred syntax to return an array:\n     data_arr = h5_file[dataset_path_in_h5][()]\n     # this returns a h5py dataset object:\n     data_ds = h5_file[dataset_path_in_h5]  # deleted [()] \n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1662041978820,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73567221",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: reading hdf5 file from s3 to , is the whole file transferred?; content:<p>i'm reading a file from my s3 bucket in a notebook in  studio (same account) using the following code:<\/p>\n<pre><code>dataset_path_in_h5=&quot;\/mode1\/singlefault\/simulationcompleted\/idv2\/mode1_idvinfo_2_100\/run1\/processdata&quot;\ns3 = s3fs.s3filesystem()\nh5_file = h5py.file(s3.open(s3url,'rb'), 'r')\ndata = h5_file.get(dataset_path_in_h5)\n<\/code><\/pre>\n<p>but i don't know what actually append behind the scene, does the whole h5 file is being transferred  ? that's seems unlikely as the code is executed quite fast while the whole file is 20gb. or is just the dataset in dataset_path_in_h5 is transferred ?\ni suppose that if the whole file is transferred at each call it could cost me a lot.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is wondering if the whole h5 file is being transferred when they use the code to read the file from their s3 bucket, or if only the dataset specified in the code is transferred."
    },
    {
        "Question_id":null,
        "Question_title":"Cuda not compatible with PyTorch installation error while training the model with 8xA100",
        "Question_body":"I tried to train the model with A100 computing cluster\nI implemented the totally same command I used for V100 computing cluster, but it doesn't work and I got the error like below\n\n \/azureml-envs\/azureml_9f42dddb00266f3582208ef8cdab4701\/lib\/python3.7\/site-packages\/torch\/cuda\/__init__.py:104: UserWarning: \n A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n If you want to use the A100-SXM4-40GB GPU with PyTorch, please check the instructions at https:\/\/pytorch.org\/get-started\/locally\/\n\nso I visited https:\/\/pytorch.org\/get-started\/locally\/ and followed to implement conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch but it doesn't work. Neither did conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia\n\nwarnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n\nso I visited https:\/\/pytorch.org\/get-started\/locally\/ and followed to implement conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch but it doesn't work. Neither did conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia\n\nHow can I solve this problem?\n\nThank you so much\n\nAdd:\nIn the conda environment below,\n\nchannels:\n- anaconda\n- defaults\ndependencies:\n- argon2-cffi=20.1.0=py37h27cfd23_1\n- async_generator=1.10=py37h28b3542_0\n- attrs=20.2.0=py_0\n- backcall=0.2.0=pyhd3eb1b0_0\n- blas=1.0=mkl\n- bleach=3.3.1=pyhd3eb1b0_0\n- ca-certificates=2021.7.5=h06a4308_1\n- certifi=2021.5.30=py37h06a4308_0\n- cffi=1.14.6=py37h400218f_0\n- cycler=0.10.0=py37_0\n- dbus=1.13.18=hb2f20db_0\n- defusedxml=0.7.1=pyhd3eb1b0_0\n- entrypoints=0.3=py37_0\n- expat=2.3.0=h2531618_2\n- fontconfig=2.13.1=h6c09931_0\n- freetype=2.10.4=h5ab3b9f_0\n- glib=2.68.1=h36276a3_0\n- gst-plugins-base=1.14.0=h8213a91_2\n- gstreamer=1.14.0=h28cd5cc_2\n- icu=58.2=he6710b0_3\n- importlib_metadata=3.10.0=hd3eb1b0_0\n- intel-openmp=2021.2.0=h06a4308_610\n- ipykernel=5.3.4=py37h5ca1d4c_0\n- ipython_genutils=0.2.0=pyhd3eb1b0_1\n- jpeg=9b=h024ee3a_2\n- jsonschema=3.2.0=py_2\n- jupyter_client=6.1.12=pyhd3eb1b0_0\n- jupyter_core=4.7.1=py37h06a4308_0\n- jupyterlab_pygments=0.1.2=py_0\n- kiwisolver=1.3.1=py37h2531618_0\n- lcms2=2.12=h3be6417_0\n- ld_impl_linux-64=2.33.1=h53a641e_7\n- libedit=3.1.20191231=h14c3975_1\n- libffi=3.3=he6710b0_2\n- libgcc-ng=9.1.0=hdf63c60_0\n- libpng=1.6.37=hbc83047_0\n- libsodium=1.0.18=h7b6447c_0\n- libstdcxx-ng=9.1.0=hdf63c60_0\n- libtiff=4.1.0=h2733197_1\n- libuuid=1.0.3=h1bed415_2\n- libxcb=1.14=h7b6447c_0\n- libxml2=2.9.10=hb55368b_3\n- lz4-c=1.9.3=h2531618_0\n- markupsafe=1.1.1=py37h14c3975_1\n- matplotlib=3.3.4=py37h06a4308_0\n- matplotlib-base=3.3.4=py37h62a2d02_0\n- mistune=0.8.4=py37h14c3975_1001\n- mkl=2021.2.0=h06a4308_296\n- mkl-service=2.3.0=py37h27cfd23_1\n- mkl_fft=1.3.0=py37h42c9631_2\n- mkl_random=1.2.1=py37ha9443f7_2\n- nbclient=0.5.3=pyhd3eb1b0_0\n- nbconvert=6.1.0=py37h06a4308_0\n- nbformat=5.1.3=pyhd3eb1b0_0\n- ncurses=6.2=he6710b0_1\n- nest-asyncio=1.5.1=pyhd3eb1b0_0\n- notebook=6.4.0=py37h06a4308_0\n- olefile=0.46=py37_0\n- openjpeg=2.3.0=h05c96fa_1\n- openssl=1.1.1k=h27cfd23_0\n- pandocfilters=1.4.3=py37h06a4308_1\n- parso=0.8.2=pyhd3eb1b0_0\n- pcre=8.44=he6710b0_0\n- pickleshare=0.7.5=pyhd3eb1b0_1003\n- pip=20.2.4=py37_0\n- prometheus_client=0.11.0=pyhd3eb1b0_0\n- ptyprocess=0.7.0=pyhd3eb1b0_2\n- pycparser=2.20=py_2\n- pyparsing=2.4.7=pyhd3eb1b0_0\n- pyqt=5.9.2=py37h05f1152_2\n- pyrsistent=0.17.3=py37h7b6447c_0\n- python=3.7.9=h7579374_0\n- python-dateutil=2.8.1=pyhd3eb1b0_0\n- qt=5.9.7=h5867ecd_1\n- readline=8.0=h7b6447c_0\n- send2trash=1.5.0=pyhd3eb1b0_1\n- setuptools=50.3.0=py37hb0f4dca_1\n- sip=4.19.8=py37hf484d3e_0\n- six=1.15.0=py37h06a4308_0\n- sqlite=3.33.0=h62c20be_0\n- terminado=0.9.4=py37h06a4308_0\n- testpath=0.5.0=pyhd3eb1b0_0\n- tk=8.6.10=hbc83047_0\n- tornado=6.0.4=py37h7b6447c_1\n- traitlets=5.0.5=pyhd3eb1b0_0\n- wcwidth=0.2.5=py_0\n- webencodings=0.5.1=py37_1\n- wheel=0.35.1=py_0\n- xz=5.2.5=h7b6447c_0\n- zeromq=4.3.4=h2531618_0\n- zlib=1.2.11=h7b6447c_3\n- zstd=1.4.9=haebb681_0\n- pip:\n- absl-py==0.12.0\n- adal==1.2.7\n- alabaster==0.7.12\n- antlr4-python3-runtime==4.8\n- azure-common==1.1.27\n- azure-core==1.16.0\n- azure-graphrbac==0.61.1\n- azure-mgmt-authorization==0.61.0\n- azure-mgmt-containerregistry==8.0.0\n- azure-mgmt-core==1.3.0\n- azure-mgmt-keyvault==9.0.0\n- azure-mgmt-resource==13.0.0\n- azure-mgmt-storage==11.2.0\n- azureml-core==1.32.0\n- babel==2.9.0\n- backports-tempfile==1.0\n- backports-weakref==1.0.post1\n- boto3==1.9.246\n- botocore==1.12.246\n- cachetools==4.2.2\n- chardet==4.0.0\n- coloredlogs==14.0\n- contextlib2==0.6.0.post1\n- cryptography==3.4.7\n- datasets==1.4.1\n- decorator==5.0.7\n- dill==0.3.3\n- docformatter==1.3\n- docker==4.4.4\n- docutils==0.15.2\n- emoji==0.5.4\n- filelock==3.0.12\n- flake8==3.7.8\n- flake8-bugbear==19.8.0\n- fsspec==2021.4.0\n- fvcore==0.1.1.post20200716\n- gitdb2==2.0.5\n- gitpython==3.0.3\n- google-auth==1.30.0\n- google-auth-oauthlib==0.4.4\n- grpcio==1.37.0\n- huggingface-hub==0.0.2\n- humanfriendly==9.1\n- hydra-core==1.0.6\n- idna==2.10\n- imagesize==1.2.0\n- importlib-metadata==4.0.1\n- importlib-resources==5.1.2\n- ipython==7.19.0\n- isodate==0.6.0\n- jedi==0.18.0\n- jeepney==0.7.0\n- jinja2==2.11.3\n- jmespath==0.10.0\n- joblib==0.14.1\n- jsonlines==1.2.0\n- jsonpickle==2.0.0\n- markdown==3.3.4\n- markdown-it-py==0.5.8\n- mccabe==0.6.1\n- more-itertools==8.7.0\n- msrest==0.6.21\n- msrestazure==0.6.4\n- multiprocess==0.70.11.1\n- myst-parser==0.12.10\n- ndg-httpsclient==0.5.1\n- nltk==3.4.5\n- numpy==1.17.5\n- oauthlib==3.1.0\n- omegaconf==2.0.6\n- packaging==20.9\n- pandas==1.1.1\n- pathspec==0.8.1\n- pexpect==4.7.0\n- pillow==8.1.1\n- pluggy==0.13.1\n- portalocker==2.3.0\n- prompt-toolkit==3.0.18\n- protobuf==3.15.8\n- py==1.10.0\n- py-gfm==1.0.2\n- py-rouge==1.1\n- pyarrow==4.0.0\n- pyasn1==0.4.8\n- pyasn1-modules==0.2.8\n- pycodestyle==2.5.0\n- pyflakes==2.1.1\n- pygments==2.8.1\n- pyjwt==2.1.0\n- pyopenssl==20.0.1\n- pytest==5.3.2\n- pytest-datadir==1.3.1\n- pytest-regressions==2.1.1\n- pytz==2021.1\n- pyyaml==5.4\n- pyzmq==18.1.0\n- regex==2020.1.8\n- requests==2.25.1\n- requests-mock==1.7.0\n- requests-oauthlib==1.3.0\n- rsa==4.7.2\n- ruamel-yaml==0.17.4\n- ruamel-yaml-clib==0.2.6\n- s3transfer==0.2.1\n- scikit-learn==0.23.1\n- scipy==1.4.1\n- secretstorage==3.3.1\n- sh==1.12.14\n- smmap==4.0.0\n- smmap2==3.0.1\n- snowballstemmer==2.1.0\n- sphinx==2.2.2\n- sphinx-autodoc-typehints==1.10.3\n- sphinx-rtd-theme==0.4.3\n- sphinxcontrib-applehelp==1.0.2\n- sphinxcontrib-devhelp==1.0.2\n- sphinxcontrib-htmlhelp==1.0.3\n- sphinxcontrib-jsmath==1.0.1\n- sphinxcontrib-qthelp==1.0.3\n- sphinxcontrib-serializinghtml==1.1.4\n- subword-nmt==0.3.7\n- tabulate==0.8.9\n- tensorboard==2.3.0\n- tensorboard-plugin-wit==1.8.0\n- tensorboardx==2.1\n- termcolor==1.1.0\n- threadpoolctl==2.1.0\n- tokenizers==0.10.2\n- torch==1.8.1\n- torchtext==0.9.1\n- tqdm==4.36.1\n- typing-extensions==3.7.4.1\n- unidecode==1.1.1\n- untokenize==0.1.1\n- urllib3==1.25.11\n- websocket-client==0.56.0\n- websocket-server==0.4\n- werkzeug==1.0.1\n- xxhash==2.0.2\n- yacs==0.1.8\n- zipp==3.4.1\n\nI implemented conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch, and export to yml file.\nThen in order to create job to computing cliuster I implemented below\n\n #A100ver\n cluster_name = 'high-A100'\n gpu_name = 'Standard_ND96asr_v4'\n experiment_name = 'speaker_identification_training_A100'\n hyperparameters = [\n     '--max_train_time', '172800'\n ]\n script_folder = '.\/script_folder'\n    \n # workspace\n ws = Workspace.from_config()\n print(ws.name, ws.location, ws.resource_group, sep='\\t')\n    \n # compute cluster\n compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", cluster_name)\n compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", gpu_name)\n    \n if compute_name in ws.compute_targets:\n     compute_target = ws.compute_targets[compute_name]\n     if compute_target and type(compute_target) is AmlCompute:\n         print('found compute target. just use it. ' + compute_name)\n else:\n     print('creating a new compute target...')\n     provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n                                                                 min_nodes=compute_min_nodes,\n                                                                 max_nodes=compute_max_nodes)\n     compute_target = ComputeTarget.create(\n         ws, compute_name, provisioning_config)\n    \n env = Environment.load_from_directory(path=\".\/.azureml6\/\")\n exp = Experiment(workspace=ws,name=experiment_name)\n command = \"pwd && pip install azure-storage-blob && python main.py\"\n # run\n src = ScriptRunConfig(source_directory=script_folder,\n  command=command,\n  compute_target=compute_target,\n  environment=env\n )\n run = exp.submit(config=src)\n\n\n\n\nActually I found that in order to use A100, pytoch version should be 1.8.1+cu111. But by implementing conda install pytorch==1.8.1 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge, I got the error like below\n\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\nCollecting package metadata (repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: |\nFound conflicts! Looking for incompatible packages.\nThis can take several minutes. Press CTRL-C to abort.\nfailed\n\n\nUnsatisfiableError: The following specifications were found\nto be incompatible with the existing python installation in your environment:\n\n\nSpecifications:\n\n\npytorch==1.8.1 -> python[version='2.7.|3.5.|3.6.|3.6.12|3.6.12|3.7.10|3.7.10|>=2.7,<2.8.0a0|>=3.5,<3.6.0a0|>=3.5|>=3.7|>=3.6,<3.7|3.7.9|3.6.9|3.6.9|3.6.9|3.6.9|3.4.',build='1_73_pypy|2_73_pypy|3_73_pypy|4_73_pypy|1_73_pypy|0_73_pypy|5_73_pypy|5_73_pypy|0_73_pypy']\n- torchaudio==0.8.0 -> python[version='2.7.|3.5.|3.6.|>=2.7,<2.8.0a0|>=3.5,<3.6.0a0|3.4.|3.9.*']\n\n\nYour python: python==3.7.9=h7579374_0\n\n\nIf python is on the left-most side of the chain, that's the version you've asked for.\nWhen python appears to the right, that indicates that the thing on the left is somehow\nnot available for the python version you are constrained to. Note that conda will not\nchange your python version to a different minor version unless you explicitly specify\nthat.\n\n\nThe following specifications were found to be incompatible with each other:\n\n\nOutput in format: Requested package -> Available versions\n\n\nPackage cudnn conflicts for:\ntorchvision==0.9.0 -> pytorch[version='>=1.8.0',build=cuda*] -> cudnn[version='>=8.2.1.32,<9.0a0']\ntorchvision==0.9.0 -> cudnn[version='>=7.6.5.32,<8.0a0|>=8.1.0.77,<9.0a0']\n\n\nPackage cudatoolkit conflicts for:\ntorchvision==0.9.0 -> cudatoolkit[version='10.2|10.2.|11.0|11.0.|11.1|11.1.|>=10.1,<10.2|>=10.2,<10.3|>=11.1,<11.2|11.2|11.2.']\ntorchaudio==0.8.0 -> pytorch==1.8.0 -> cudatoolkit[version='10.2|10.2.|11.0|11.0.|11.1|11.1.|11.2|11.2.|>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\ntorchvision==0.9.0 -> cudnn[version='>=8.1.0.77,<9.0a0'] -> cudatoolkit[version='10.0|10.0.|10.1|10.1.|10.2.|11.|>=11.3,<11.4|9.2|9.2.*']\npytorch==1.8.1 -> cudatoolkit[version='>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\n\n\nPackage libstdcxx-ng conflicts for:\npython==3.7.9=h7579374_0 -> libffi[version='>=3.3,<3.4.0a0'] -> libstdcxx-ng[version='>=7.3.0|>=7.5.0']\ntorchaudio==0.8.0 -> numpy[version='>=1.11'] -> libstdcxx-ng[version='>=4.9|>=7.3.0|>=9.3.0|>=7.5.0|>=7.2.0']\ntorchvision==0.9.0 -> libstdcxx-ng[version='>=7.5.0']\ntorchvision==0.9.0 -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=3.4|>=4.9|>=7.3.0|>=9.3.0|>=7.2.0']\npytorch==1.8.1 -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=4.9|>=7.3.0|>=9.3.0|>=7.2.0']\npytorch==1.8.1 -> libstdcxx-ng[version='>=7.5.0']\ncudatoolkit=11.1 -> libstdcxx-ng[version='>=9.3.0']\n\n\nPackage libgcc-ng conflicts for:\npython==3.7.9=h7579374_0 -> libgcc-ng[version='>=7.3.0']\npython==3.7.9=h7579374_0 -> libffi[version='>=3.3,<3.4.0a0'] -> libgcc-ng[version='>=4.9|>=7.5.0|>=9.4.0|>=9.3.0|>=7.2.0']\n\n\nPackage _libgcc_mutex conflicts for:\npython==3.7.9=h7579374_0 -> libgcc-ng[version='>=7.3.0'] -> _libgcc_mutex[version='|0.1|0.1',build='main|main|conda_forge']\ncudatoolkit=11.1 -> libgcc-ng[version='>=9.3.0'] -> _libgcc_mutex[version='|0.1',build='main|main|conda_forge']\ntorchvision==0.9.0 -> libgcc-ng[version='>=7.5.0'] -> _libgcc_mutex[version='|0.1|0.1',build='main|main|conda_forge']\npytorch==1.8.1 -> _openmp_mutex -> _libgcc_mutex[version='|0.1',build='main|main|conda_forge']\n\n\nPackage pytorch conflicts for:\ntorchvision==0.9.0 -> pytorch[version='1.8.0|>=1.8.0|>=1.8.0',build='cuda*|cpu*']\ntorchaudio==0.8.0 -> pytorch==1.8.0\n\n\nPackage nccl conflicts for:\ntorchvision==0.9.0 -> pytorch==1.8.0 -> nccl[version='>=2.10.3.1,<3.0a0|>=2.7.8.1,<3.0a0|>=2.8.4.1,<3.0a0']\ntorchaudio==0.8.0 -> pytorch==1.8.0 -> nccl[version='>=2.7.8.1,<3.0a0|>=2.8.4.1,<3.0a0']\n\n\nPackage typing-extensions conflicts for:\npytorch==1.8.1 -> typing-extensions\ntorchvision==0.9.0 -> pytorch[version='>=1.8.0',build=cpu*] -> typing-extensionsThe following specifications were found to be incompatible with your system:\n\n\nfeature:\/linux-64::__glibc==2.27=0\n- feature:|@\/linux-64::__glibc==2.27=0\n- cudatoolkit=11.1 -> __glibc[version='>=2.17,<3.0.a0']\n- cudatoolkit=11.1 -> libgcc-ng[version='>=9.3.0'] -> __glibc[version='>=2.17']\n- pytorch==1.8.1 -> cudatoolkit[version='>=11.1,<11.2'] -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n- torchaudio==0.8.0 -> pytorch==1.8.0 -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n- torchvision==0.9.0 -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n\n\nYour installed version is: 2.27\n\n\n\n\n\nCan I solve this problem by adjusting the environment? or should I give up using A100?\n\nThank you so much",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_creation_time":1629092753013,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/514710\/cuda-not-compatible-with-pytorch-installation-erro.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-17T03:41:43.467Z",
                "Answer_score":0,
                "Answer_body":"In the conda environment below,\n\nchannels:\n- anaconda\n- defaults\ndependencies:\n- argon2-cffi=20.1.0=py37h27cfd23_1\n- async_generator=1.10=py37h28b3542_0\n- attrs=20.2.0=py_0\n- backcall=0.2.0=pyhd3eb1b0_0\n- blas=1.0=mkl\n- bleach=3.3.1=pyhd3eb1b0_0\n- ca-certificates=2021.7.5=h06a4308_1\n- certifi=2021.5.30=py37h06a4308_0\n- cffi=1.14.6=py37h400218f_0\n- cycler=0.10.0=py37_0\n- dbus=1.13.18=hb2f20db_0\n- defusedxml=0.7.1=pyhd3eb1b0_0\n- entrypoints=0.3=py37_0\n- expat=2.3.0=h2531618_2\n- fontconfig=2.13.1=h6c09931_0\n- freetype=2.10.4=h5ab3b9f_0\n- glib=2.68.1=h36276a3_0\n- gst-plugins-base=1.14.0=h8213a91_2\n- gstreamer=1.14.0=h28cd5cc_2\n- icu=58.2=he6710b0_3\n- importlib_metadata=3.10.0=hd3eb1b0_0\n- intel-openmp=2021.2.0=h06a4308_610\n- ipykernel=5.3.4=py37h5ca1d4c_0\n- ipython_genutils=0.2.0=pyhd3eb1b0_1\n- jpeg=9b=h024ee3a_2\n- jsonschema=3.2.0=py_2\n- jupyter_client=6.1.12=pyhd3eb1b0_0\n- jupyter_core=4.7.1=py37h06a4308_0\n- jupyterlab_pygments=0.1.2=py_0\n- kiwisolver=1.3.1=py37h2531618_0\n- lcms2=2.12=h3be6417_0\n- ld_impl_linux-64=2.33.1=h53a641e_7\n- libedit=3.1.20191231=h14c3975_1\n- libffi=3.3=he6710b0_2\n- libgcc-ng=9.1.0=hdf63c60_0\n- libpng=1.6.37=hbc83047_0\n- libsodium=1.0.18=h7b6447c_0\n- libstdcxx-ng=9.1.0=hdf63c60_0\n- libtiff=4.1.0=h2733197_1\n- libuuid=1.0.3=h1bed415_2\n- libxcb=1.14=h7b6447c_0\n- libxml2=2.9.10=hb55368b_3\n- lz4-c=1.9.3=h2531618_0\n- markupsafe=1.1.1=py37h14c3975_1\n- matplotlib=3.3.4=py37h06a4308_0\n- matplotlib-base=3.3.4=py37h62a2d02_0\n- mistune=0.8.4=py37h14c3975_1001\n- mkl=2021.2.0=h06a4308_296\n- mkl-service=2.3.0=py37h27cfd23_1\n- mkl_fft=1.3.0=py37h42c9631_2\n- mkl_random=1.2.1=py37ha9443f7_2\n- nbclient=0.5.3=pyhd3eb1b0_0\n- nbconvert=6.1.0=py37h06a4308_0\n- nbformat=5.1.3=pyhd3eb1b0_0\n- ncurses=6.2=he6710b0_1\n- nest-asyncio=1.5.1=pyhd3eb1b0_0\n- notebook=6.4.0=py37h06a4308_0\n- olefile=0.46=py37_0\n- openjpeg=2.3.0=h05c96fa_1\n- openssl=1.1.1k=h27cfd23_0\n- pandocfilters=1.4.3=py37h06a4308_1\n- parso=0.8.2=pyhd3eb1b0_0\n- pcre=8.44=he6710b0_0\n- pickleshare=0.7.5=pyhd3eb1b0_1003\n- pip=20.2.4=py37_0\n- prometheus_client=0.11.0=pyhd3eb1b0_0\n- ptyprocess=0.7.0=pyhd3eb1b0_2\n- pycparser=2.20=py_2\n- pyparsing=2.4.7=pyhd3eb1b0_0\n- pyqt=5.9.2=py37h05f1152_2\n- pyrsistent=0.17.3=py37h7b6447c_0\n- python=3.7.9=h7579374_0\n- python-dateutil=2.8.1=pyhd3eb1b0_0\n- qt=5.9.7=h5867ecd_1\n- readline=8.0=h7b6447c_0\n- send2trash=1.5.0=pyhd3eb1b0_1\n- setuptools=50.3.0=py37hb0f4dca_1\n- sip=4.19.8=py37hf484d3e_0\n- six=1.15.0=py37h06a4308_0\n- sqlite=3.33.0=h62c20be_0\n- terminado=0.9.4=py37h06a4308_0\n- testpath=0.5.0=pyhd3eb1b0_0\n- tk=8.6.10=hbc83047_0\n- tornado=6.0.4=py37h7b6447c_1\n- traitlets=5.0.5=pyhd3eb1b0_0\n- wcwidth=0.2.5=py_0\n- webencodings=0.5.1=py37_1\n- wheel=0.35.1=py_0\n- xz=5.2.5=h7b6447c_0\n- zeromq=4.3.4=h2531618_0\n- zlib=1.2.11=h7b6447c_3\n- zstd=1.4.9=haebb681_0\n- pip:\n- absl-py==0.12.0\n- adal==1.2.7\n- alabaster==0.7.12\n- antlr4-python3-runtime==4.8\n- azure-common==1.1.27\n- azure-core==1.16.0\n- azure-graphrbac==0.61.1\n- azure-mgmt-authorization==0.61.0\n- azure-mgmt-containerregistry==8.0.0\n- azure-mgmt-core==1.3.0\n- azure-mgmt-keyvault==9.0.0\n- azure-mgmt-resource==13.0.0\n- azure-mgmt-storage==11.2.0\n- azureml-core==1.32.0\n- babel==2.9.0\n- backports-tempfile==1.0\n- backports-weakref==1.0.post1\n- boto3==1.9.246\n- botocore==1.12.246\n- cachetools==4.2.2\n- chardet==4.0.0\n- coloredlogs==14.0\n- contextlib2==0.6.0.post1\n- cryptography==3.4.7\n- datasets==1.4.1\n- decorator==5.0.7\n- dill==0.3.3\n- docformatter==1.3\n- docker==4.4.4\n- docutils==0.15.2\n- emoji==0.5.4\n- filelock==3.0.12\n- flake8==3.7.8\n- flake8-bugbear==19.8.0\n- fsspec==2021.4.0\n- fvcore==0.1.1.post20200716\n- gitdb2==2.0.5\n- gitpython==3.0.3\n- google-auth==1.30.0\n- google-auth-oauthlib==0.4.4\n- grpcio==1.37.0\n- huggingface-hub==0.0.2\n- humanfriendly==9.1\n- hydra-core==1.0.6\n- idna==2.10\n- imagesize==1.2.0\n- importlib-metadata==4.0.1\n- importlib-resources==5.1.2\n- ipython==7.19.0\n- isodate==0.6.0\n- jedi==0.18.0\n- jeepney==0.7.0\n- jinja2==2.11.3\n- jmespath==0.10.0\n- joblib==0.14.1\n- jsonlines==1.2.0\n- jsonpickle==2.0.0\n- markdown==3.3.4\n- markdown-it-py==0.5.8\n- mccabe==0.6.1\n- more-itertools==8.7.0\n- msrest==0.6.21\n- msrestazure==0.6.4\n- multiprocess==0.70.11.1\n- myst-parser==0.12.10\n- ndg-httpsclient==0.5.1\n- nltk==3.4.5\n- numpy==1.17.5\n- oauthlib==3.1.0\n- omegaconf==2.0.6\n- packaging==20.9\n- pandas==1.1.1\n- pathspec==0.8.1\n- pexpect==4.7.0\n- pillow==8.1.1\n- pluggy==0.13.1\n- portalocker==2.3.0\n- prompt-toolkit==3.0.18\n- protobuf==3.15.8\n- py==1.10.0\n- py-gfm==1.0.2\n- py-rouge==1.1\n- pyarrow==4.0.0\n- pyasn1==0.4.8\n- pyasn1-modules==0.2.8\n- pycodestyle==2.5.0\n- pyflakes==2.1.1\n- pygments==2.8.1\n- pyjwt==2.1.0\n- pyopenssl==20.0.1\n- pytest==5.3.2\n- pytest-datadir==1.3.1\n- pytest-regressions==2.1.1\n- pytz==2021.1\n- pyyaml==5.4\n- pyzmq==18.1.0\n- regex==2020.1.8\n- requests==2.25.1\n- requests-mock==1.7.0\n- requests-oauthlib==1.3.0\n- rsa==4.7.2\n- ruamel-yaml==0.17.4\n- ruamel-yaml-clib==0.2.6\n- s3transfer==0.2.1\n- scikit-learn==0.23.1\n- scipy==1.4.1\n- secretstorage==3.3.1\n- sh==1.12.14\n- smmap==4.0.0\n- smmap2==3.0.1\n- snowballstemmer==2.1.0\n- sphinx==2.2.2\n- sphinx-autodoc-typehints==1.10.3\n- sphinx-rtd-theme==0.4.3\n- sphinxcontrib-applehelp==1.0.2\n- sphinxcontrib-devhelp==1.0.2\n- sphinxcontrib-htmlhelp==1.0.3\n- sphinxcontrib-jsmath==1.0.1\n- sphinxcontrib-qthelp==1.0.3\n- sphinxcontrib-serializinghtml==1.1.4\n- subword-nmt==0.3.7\n- tabulate==0.8.9\n- tensorboard==2.3.0\n- tensorboard-plugin-wit==1.8.0\n- tensorboardx==2.1\n- termcolor==1.1.0\n- threadpoolctl==2.1.0\n- tokenizers==0.10.2\n- torch==1.8.1\n- torchtext==0.9.1\n- tqdm==4.36.1\n- typing-extensions==3.7.4.1\n- unidecode==1.1.1\n- untokenize==0.1.1\n- urllib3==1.25.11\n- websocket-client==0.56.0\n- websocket-server==0.4\n- werkzeug==1.0.1\n- xxhash==2.0.2\n- yacs==0.1.8\n- zipp==3.4.1\n\nI implemented conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch, and export to yml file.\nThen in order to create job to computing cliuster I implemented below\n\n #A100ver\n cluster_name = 'high-A100'\n gpu_name = 'Standard_ND96asr_v4'\n experiment_name = 'speaker_identification_training_A100'\n hyperparameters = [\n     '--max_train_time', '172800'\n ]\n script_folder = '.\/script_folder'\n    \n # workspace\n ws = Workspace.from_config()\n print(ws.name, ws.location, ws.resource_group, sep='\\t')\n    \n # compute cluster\n compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", cluster_name)\n compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", gpu_name)\n    \n if compute_name in ws.compute_targets:\n     compute_target = ws.compute_targets[compute_name]\n     if compute_target and type(compute_target) is AmlCompute:\n         print('found compute target. just use it. ' + compute_name)\n else:\n     print('creating a new compute target...')\n     provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n                                                                 min_nodes=compute_min_nodes,\n                                                                 max_nodes=compute_max_nodes)\n     compute_target = ComputeTarget.create(\n         ws, compute_name, provisioning_config)\n    \n env = Environment.load_from_directory(path=\".\/.azureml6\/\")\n exp = Experiment(workspace=ws,name=experiment_name)\n command = \"pwd && pip install azure-storage-blob && python main.py\"\n # run\n src = ScriptRunConfig(source_directory=script_folder,\n  command=command,\n  compute_target=compute_target,\n  environment=env\n )\n run = exp.submit(config=src)\n\n\n\n\nActually I found that in order to use A100, pytoch version should be 1.8.1+cu111. But by implementing conda install pytorch==1.8.1 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge, I got the error like below\n\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\nCollecting package metadata (repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: |\nFound conflicts! Looking for incompatible packages.\nThis can take several minutes. Press CTRL-C to abort.\nfailed\n\n\nUnsatisfiableError: The following specifications were found\nto be incompatible with the existing python installation in your environment:\n\n\nSpecifications:\n\n\npytorch==1.8.1 -> python[version='2.7.|3.5.|3.6.|3.6.12|3.6.12|3.7.10|3.7.10|>=2.7,<2.8.0a0|>=3.5,<3.6.0a0|>=3.5|>=3.7|>=3.6,<3.7|3.7.9|3.6.9|3.6.9|3.6.9|3.6.9|3.4.',build='1_73_pypy|2_73_pypy|3_73_pypy|4_73_pypy|1_73_pypy|0_73_pypy|5_73_pypy|5_73_pypy|0_73_pypy']\n- torchaudio==0.8.0 -> python[version='2.7.|3.5.|3.6.|>=2.7,<2.8.0a0|>=3.5,<3.6.0a0|3.4.|3.9.*']\n\n\nYour python: python==3.7.9=h7579374_0\n\n\nIf python is on the left-most side of the chain, that's the version you've asked for.\nWhen python appears to the right, that indicates that the thing on the left is somehow\nnot available for the python version you are constrained to. Note that conda will not\nchange your python version to a different minor version unless you explicitly specify\nthat.\n\n\nThe following specifications were found to be incompatible with each other:\n\n\nOutput in format: Requested package -> Available versions\n\n\nPackage cudnn conflicts for:\ntorchvision==0.9.0 -> pytorch[version='>=1.8.0',build=cuda*] -> cudnn[version='>=8.2.1.32,<9.0a0']\ntorchvision==0.9.0 -> cudnn[version='>=7.6.5.32,<8.0a0|>=8.1.0.77,<9.0a0']\n\n\nPackage cudatoolkit conflicts for:\ntorchvision==0.9.0 -> cudatoolkit[version='10.2|10.2.|11.0|11.0.|11.1|11.1.|>=10.1,<10.2|>=10.2,<10.3|>=11.1,<11.2|11.2|11.2.']\ntorchaudio==0.8.0 -> pytorch==1.8.0 -> cudatoolkit[version='10.2|10.2.|11.0|11.0.|11.1|11.1.|11.2|11.2.|>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\ntorchvision==0.9.0 -> cudnn[version='>=8.1.0.77,<9.0a0'] -> cudatoolkit[version='10.0|10.0.|10.1|10.1.|10.2.|11.|>=11.3,<11.4|9.2|9.2.*']\npytorch==1.8.1 -> cudatoolkit[version='>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\n\n\nPackage libstdcxx-ng conflicts for:\npython==3.7.9=h7579374_0 -> libffi[version='>=3.3,<3.4.0a0'] -> libstdcxx-ng[version='>=7.3.0|>=7.5.0']\ntorchaudio==0.8.0 -> numpy[version='>=1.11'] -> libstdcxx-ng[version='>=4.9|>=7.3.0|>=9.3.0|>=7.5.0|>=7.2.0']\ntorchvision==0.9.0 -> libstdcxx-ng[version='>=7.5.0']\ntorchvision==0.9.0 -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=3.4|>=4.9|>=7.3.0|>=9.3.0|>=7.2.0']\npytorch==1.8.1 -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=4.9|>=7.3.0|>=9.3.0|>=7.2.0']\npytorch==1.8.1 -> libstdcxx-ng[version='>=7.5.0']\ncudatoolkit=11.1 -> libstdcxx-ng[version='>=9.3.0']\n\n\nPackage libgcc-ng conflicts for:\npython==3.7.9=h7579374_0 -> libgcc-ng[version='>=7.3.0']\npython==3.7.9=h7579374_0 -> libffi[version='>=3.3,<3.4.0a0'] -> libgcc-ng[version='>=4.9|>=7.5.0|>=9.4.0|>=9.3.0|>=7.2.0']\n\n\nPackage _libgcc_mutex conflicts for:\npython==3.7.9=h7579374_0 -> libgcc-ng[version='>=7.3.0'] -> _libgcc_mutex[version='|0.1|0.1',build='main|main|conda_forge']\ncudatoolkit=11.1 -> libgcc-ng[version='>=9.3.0'] -> _libgcc_mutex[version='|0.1',build='main|main|conda_forge']\ntorchvision==0.9.0 -> libgcc-ng[version='>=7.5.0'] -> _libgcc_mutex[version='|0.1|0.1',build='main|main|conda_forge']\npytorch==1.8.1 -> _openmp_mutex -> _libgcc_mutex[version='|0.1',build='main|main|conda_forge']\n\n\nPackage pytorch conflicts for:\ntorchvision==0.9.0 -> pytorch[version='1.8.0|>=1.8.0|>=1.8.0',build='cuda*|cpu*']\ntorchaudio==0.8.0 -> pytorch==1.8.0\n\n\nPackage nccl conflicts for:\ntorchvision==0.9.0 -> pytorch==1.8.0 -> nccl[version='>=2.10.3.1,<3.0a0|>=2.7.8.1,<3.0a0|>=2.8.4.1,<3.0a0']\ntorchaudio==0.8.0 -> pytorch==1.8.0 -> nccl[version='>=2.7.8.1,<3.0a0|>=2.8.4.1,<3.0a0']\n\n\nPackage typing-extensions conflicts for:\npytorch==1.8.1 -> typing-extensions\ntorchvision==0.9.0 -> pytorch[version='>=1.8.0',build=cpu*] -> typing-extensionsThe following specifications were found to be incompatible with your system:\n\n\nfeature:\/linux-64::__glibc==2.27=0\n- feature:|@\/linux-64::__glibc==2.27=0\n- cudatoolkit=11.1 -> __glibc[version='>=2.17,<3.0.a0']\n- cudatoolkit=11.1 -> libgcc-ng[version='>=9.3.0'] -> __glibc[version='>=2.17']\n- pytorch==1.8.1 -> cudatoolkit[version='>=11.1,<11.2'] -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n- torchaudio==0.8.0 -> pytorch==1.8.0 -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n- torchvision==0.9.0 -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n\n\nYour installed version is: 2.27\n\n\n\n\n\nCan I solve this problem by adjusting the environment? or should I give up using A100?\n\nThank you so much",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: cuda not compatible with pytorch installation error while training the model with 8xa100; content:i tried to train the model with a100 computing cluster\ni implemented the totally same command i used for v100 computing cluster, but it doesn't work and i got the error like below\n\n \/-envs\/_9f42dddb00266f3582208ef8cdab4701\/lib\/python3.7\/site-packages\/torch\/cuda\/__init__.py:104: userwarning: \n a100-sxm4-40gb with cuda capability sm_80 is not compatible with the current pytorch installation.\n the current pytorch install supports cuda capabilities sm_37 sm_50 sm_60 sm_70.\n if you want to use the a100-sxm4-40gb gpu with pytorch, please check the instructions at https:\/\/pytorch.org\/get-started\/locally\/\n\nso i visited https:\/\/pytorch.org\/get-started\/locally\/ and followed to implement conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch but it doesn't work. neither did conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia\n\nwarnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n\nso i visited https:\/\/pytorch.org\/get-started\/locally\/ and followed to implement conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch but it doesn't work. neither did conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia\n\ni implemented conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch, and export to yml file.\nactually i found that in order to use a100, pytoch version should be 1.8.1+cu111. but by implementing conda install pytorch==1.8.1 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge, i got the error like below\n\nunsatisfiableerror: the following specifications were found\nto be incompatible with the existing python installation in your environment:\n\n\ncan i solve this problem by adjusting the environment? or should i give up using a100?\n\nthank you so much",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an incompatibility error between cuda and pytorch while trying to train a model with an 8xa100 computing cluster, and has attempted to solve the issue by adjusting the environment and installing different versions of pytorch."
    },
    {
        "Question_id":45328657.0,
        "Question_title":"Scheduling Azure Machine Learning Experimnets",
        "Question_body":"<p>How do i schedule Azure ML Experiments which is not deployed as web service?<\/p>\n\n<p>I have developed a Azure Experiment which imports data from on-premise database and exports data to SQL db. How can i schedule that to run weekly?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1501076325577,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning-studio"
        ],
        "Question_view_count":520.0,
        "Owner_creation_time":1359784845430,
        "Owner_last_access_time":1654012514916,
        "Owner_reputation":400.0,
        "Owner_up_votes":40.0,
        "Owner_down_votes":2.0,
        "Owner_views":147.0,
        "Answer_body":"<p>You can use <strong>Azure PowerShell<\/strong> for automating this task, and use <strong>Windows Task Scheduler<\/strong> to schedule this script to run automatically.<\/p>\n\n<p>For Azure PowerShell,<\/p>\n\n<p>You may visit <a href=\"https:\/\/github.com\/hning86\/azuremlps\" rel=\"nofollow noreferrer\"><strong>this page<\/strong><\/a> to setup an Azure PowerShell script. It's a long journey, but it's worth it. Make sure to <strong><em>follow the prerequisites to be installed on your local PC (Azure-PowerShell v4.0.1)<\/em><\/strong>.<\/p>\n\n<p>For Windows Task Scheduler,<\/p>\n\n<p>Visit <a href=\"https:\/\/www.metalogix.com\/help\/Content%20Matrix%20Console\/SharePoint%20Edition\/002_HowTo\/004_SharePointActions\/012_SchedulingPowerShell.htm\" rel=\"nofollow noreferrer\"><strong>this link<\/strong><\/a> to schedule your created Azure PowerShell script to run at a scheduled\/repeated time.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1502973065180,
        "Answer_score":1.0,
        "Owner_location":"India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45328657",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: scheduling  experimnets; content:<p>how do i schedule  experiments which is not deployed as web service?<\/p>\n\n<p>i have developed a azure experiment which imports data from on-premise database and exports data to sql db. how can i schedule that to run weekly?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to schedule an Azure ML experiment which is not deployed as a web service, and to export data to a SQL database on a weekly basis."
    },
    {
        "Question_id":72873249.0,
        "Question_title":"Deployment of Machine Learning models in Azure machine learning through mlflow",
        "Question_body":"<p>I am new to MLOps. It would be helpful if someone can share the procedure to use mlflow in deployment of Machine Learning models in azure machine learning.\nI don't want to use databricks.\nA sample run step by step with example will be helpful.. thanks in anticipation<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1657041227273,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "machine-learning",
            "mlflow"
        ],
        "Question_view_count":51.0,
        "Owner_creation_time":1431685926620,
        "Owner_last_access_time":1663756216812,
        "Owner_reputation":543.0,
        "Owner_up_votes":17.0,
        "Owner_down_votes":2.0,
        "Owner_views":125.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1657769885320,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72873249",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: deployment of machine learning models in azure machine learning through ; content:<p>i am new to mlops. it would be helpful if someone can share the procedure to use  in deployment of machine learning models in azure machine learning.\ni don't want to use databricks.\na sample run step by step with example will be helpful.. thanks in anticipation<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a step-by-step guide to deploying machine learning models in Azure Machine Learning without using Databricks."
    },
    {
        "Question_id":60903256.0,
        "Question_title":"AWS Chalice, can't get image from POST request",
        "Question_body":"<p>I'm trying to invoke my sagemaker model using aws chalice, a lambda function, and an API Gateaway.<\/p>\n\n<p>I'm attempting to send the image over <code>POST<\/code> request but I'm having problem receiving it on the lambda function.<\/p>\n\n<p>My code looks like:<\/p>\n\n<pre><code>from chalice import Chalice\nfrom chalice import BadRequestError\nimport base64\nimport os\nimport boto3\nimport ast\nimport json\n\napp = Chalice(app_name='foo')\napp.debug = True\n\n\n@app.route('\/', methods=['POST'], content_types=['application\/json'])\ndef index():\n    body = ''\n\n    try:\n        body = app.current_request.json_body # &lt;- I suspect this is the problem\n        return {'response': body}\n    except Exception as e:\n        return  {'error':  str(e)}\n<\/code><\/pre>\n\n<p>It's just returning<\/p>\n\n<p><code>&lt;Response [200]&gt; {'error': 'BadRequestError: Error Parsing JSON'}<\/code><\/p>\n\n<p>As I mentioned before, my end goal is to receive my image and make a sagemaker request with it. But I just can't seem to read the image. <\/p>\n\n<p>My python test client looks like this:<\/p>\n\n<pre><code>import base64, requests, json\n\ndef test():\n\n    url = 'api_url_from_chalice'\n    body = ''\n\n    with open('b1.jpg', 'rb') as image:\n        f = image.read()\n        body = base64.b64encode(f)\n\n    payload = {'data': body}\n    headers = {'Content-Type': 'application\/json'}\n\n    r = requests.post(url, data=payload, headers=headers)\n    print(r)\n    r = r.json()\n    # r = r['response']\n\n    print(r)\n\ntest()\n<\/code><\/pre>\n\n<p>Please help me, I spent way to much time trying to figure this out<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1585411767370,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "rest",
            "amazon-sagemaker",
            "chalice"
        ],
        "Question_view_count":1229.0,
        "Owner_creation_time":1565391938427,
        "Owner_last_access_time":1653377520683,
        "Owner_reputation":23.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":7.0,
        "Answer_body":"<p>So I was able to figure it out with the help of an aws engineer (i got lucky I suppose). I'm including the complete lambda function. Nothing changed on the client.<\/p>\n\n<pre><code>from chalice import Chalice\nfrom chalice import BadRequestError\nimport base64\nimport os\nimport boto3\nimport ast\nimport json\nimport sys\n\n\nfrom chalice import Chalice\nif sys.version_info[0] == 3:\n    # Python 3 imports.\n    from urllib.parse import urlparse, parse_qs\nelse:\n    # Python 2 imports.\n    from urlparse import urlparse, parse_qs\n\napp = Chalice(app_name='app_name')\napp.debug = True\n\n\n@app.route('\/', methods=['POST'])\ndef index():\n    parsed = parse_qs(app.current_request.raw_body.decode())\n\n    body = parsed['data'][0]\n    print(type(body))\n\n    try:\n        body = base64.b64decode(body)\n        body = bytearray(body)\n    except e:\n        return {'error': str(e)}\n\n\n    endpoint = \"object-detection-endpoint_name\"\n    runtime = boto3.Session().client(service_name='sagemaker-runtime', region_name='us-east-2')\n\n    response = runtime.invoke_endpoint(EndpointName=endpoint, ContentType='image\/jpeg', Body=body)\n\n    print(response)\n    results = response['Body'].read().decode(\"utf-8\")\n    results = results['predictions']\n\n    results = json.loads(results)\n    results = results['predictions']\n\n    return {'result': results}\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1585869968030,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1585412572920,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60903256",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: aws chalice, can't get image from post request; content:<p>i'm trying to invoke my  model using aws chalice, a lambda function, and an api gateaway.<\/p>\n\n<p>i'm attempting to send the image over <code>post<\/code> request but i'm having problem receiving it on the lambda function.<\/p>\n\n<p>my code looks like:<\/p>\n\n<pre><code>from chalice import chalice\nfrom chalice import badrequesterror\nimport base64\nimport os\nimport boto3\nimport ast\nimport json\n\napp = chalice(app_name='foo')\napp.debug = true\n\n\n@app.route('\/', methods=['post'], content_types=['application\/json'])\ndef index():\n    body = ''\n\n    try:\n        body = app.current_request.json_body # &lt;- i suspect this is the problem\n        return {'response': body}\n    except exception as e:\n        return  {'error':  str(e)}\n<\/code><\/pre>\n\n<p>it's just returning<\/p>\n\n<p><code>&lt;response [200]&gt; {'error': 'badrequesterror: error parsing json'}<\/code><\/p>\n\n<p>as i mentioned before, my end goal is to receive my image and make a  request with it. but i just can't seem to read the image. <\/p>\n\n<p>my python test client looks like this:<\/p>\n\n<pre><code>import base64, requests, json\n\ndef test():\n\n    url = 'api_url_from_chalice'\n    body = ''\n\n    with open('b1.jpg', 'rb') as image:\n        f = image.read()\n        body = base64.b64encode(f)\n\n    payload = {'data': body}\n    headers = {'content-type': 'application\/json'}\n\n    r = requests.post(url, data=payload, headers=headers)\n    print(r)\n    r = r.json()\n    # r = r['response']\n\n    print(r)\n\ntest()\n<\/code><\/pre>\n\n<p>please help me, i spent way to much time trying to figure this out<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty receiving an image from a POST request using AWS Chalice and an API Gateway, and is receiving an error when attempting to parse the JSON body."
    },
    {
        "Question_id":null,
        "Question_title":"Stop button",
        "Question_body":"<p>Hi<br>\nI\u2019m running training on aws batch (on docker image) and I want to be able to stop the run manually using the button on the wandb and ideally therefore stop that aws batch instance (since the command finished executing).<br>\nThe training runs are using bot key that was given to me. And when I click the stop button (on website, using my account), it says I can\u2019t view the page.<br>\nIs it a permission issue? Will it work as I described?<br>\nThanks<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1631713980302,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":null,
        "Question_view_count":265.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/stop-button\/614",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":1588,
                "name":"Adrian Swanberg",
                "username":"adrnswanberg",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/c67d28\/{size}.png",
                "created_at":"2021-09-16T03:35:41.791Z",
                "cooked":"<p>Hi there,<\/p>\n<p>Can you share a little more about how you\u2019re running these runs? Are they attributed to your personal account or to a service account?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-09-16T03:35:51.216Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":22,
                "readers_count":21,
                "score":49.4,
                "yours":false,
                "topic_id":614,
                "topic_slug":"stop-button",
                "display_username":"Adrian Swanberg",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":35,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1643,
                "name":"Xiongyi Cui",
                "username":"xiongyi-cui-tri",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/45deac\/{size}.png",
                "created_at":"2021-09-16T20:55:54.823Z",
                "cooked":"<p>basically we have a script to start up a aws docker run given a command, in this case to start training. The docker run stops when the command finished executing and I want to stop the training and thus stop the docker  run.<br>\nIt\u2019s service account? work account.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-09-16T20:55:54.823Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":19,
                "readers_count":18,
                "score":8.8,
                "yours":false,
                "topic_id":614,
                "topic_slug":"stop-button",
                "display_username":"Xiongyi Cui",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":377,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2147,
                "name":"Elaina Hodgkin",
                "username":"elaina_renee",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/e\/d78d45\/{size}.png",
                "created_at":"2021-10-04T15:34:04.339Z",
                "cooked":"<p>Hi! Were you the original creator of the run? I think what is likely happening is that someone else created the run and therefore you may not have permissions to stop it.<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2021-10-04T15:34:04.339Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":12,
                "readers_count":11,
                "score":2.4,
                "yours":false,
                "topic_id":614,
                "topic_slug":"stop-button",
                "display_username":"Elaina Hodgkin",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"xiongyi-cui-tri",
                    "name":"Xiongyi Cui",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/x\/45deac\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":513,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: stop button; content:<p>hi<br>\ni\u2019m running training on aws batch (on docker image) and i want to be able to stop the run manually using the button on the  and ideally therefore stop that aws batch instance (since the command finished executing).<br>\nthe training runs are using bot key that was given to me. and when i click the stop button (on website, using my account), it says i can\u2019t view the page.<br>\nis it a permission issue? will it work as i described?<br>\nthanks<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to use a stop button on a website to manually stop an AWS Batch instance, but is receiving an error that they cannot view the page. They are wondering if this is a permission issue."
    },
    {
        "Question_id":72414899.0,
        "Question_title":"fastapi prediction with machine learning model from mlflow works in local but not online on Heroku",
        "Question_body":"<p>When I test my API in local it is working fine:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TXvj9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TXvj9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>When I test it online. It is still working fine.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/FntrH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FntrH.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>When I make a prediction in local; it is still working fine. It uses a model saved online on MLflow to make the prediction.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TIjlM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TIjlM.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>But when I push my API online and try the same prediction, is it not working anymore.<\/p>\n<p>When checking the status_code, I have an error 500:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/LBeYY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LBeYY.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>And when trying to print the answer it says:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/dOxbj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/dOxbj.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Any idea why?<\/p>\n<p>Thank you<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_creation_time":1653733998743,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "heroku",
            "fastapi",
            "mlflow"
        ],
        "Question_view_count":99.0,
        "Owner_creation_time":1423404602996,
        "Owner_last_access_time":1663850779852,
        "Owner_reputation":67.0,
        "Owner_up_votes":9.0,
        "Owner_down_votes":0.0,
        "Owner_views":7.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72414899",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: fastapi prediction with machine learning model from  works in local but not online on heroku; content:<p>when i test my api in local it is working fine:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/txvj9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/txvj9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>when i test it online. it is still working fine.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/fntrh.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fntrh.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>when i make a prediction in local; it is still working fine. it uses a model saved online on  to make the prediction.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/tijlm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/tijlm.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>but when i push my api online and try the same prediction, is it not working anymore.<\/p>\n<p>when checking the status_code, i have an error 500:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/lbeyy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/lbeyy.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>and when trying to print the answer it says:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/doxbj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/doxbj.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>any idea why?<\/p>\n<p>thank you<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having an issue with their FastAPI prediction with a machine learning model from working in local but not online on Heroku, resulting in an error 500 and an inability to print the answer."
    },
    {
        "Question_id":55781509.0,
        "Question_title":"Automate the execution of a .ipynb file in SageMaker",
        "Question_body":"<p>I want to automate Jupyter's work.<\/p>\n\n<p>I created a function in AWS Lambda that when the S3 bucket receives a .csv file, it opens the determined instance of Jupyter and it works fine.<\/p>\n\n<p>Now I want to execute the .ipynb file that does all the work.<\/p>\n\n<p>I have tried using the Jupyter Configuration Lifecycle.<\/p>\n\n<p>But it always fails. Would it be possible to do it in the same lambda function?<\/p>\n\n<pre><code>jupyter nbconvert --execute --to notebook\n                  --inplace \/home\/ec2-user\/SageMaker\/Scikit.ipynb\n                  --ExecutePreprocessor.kernel_name=python3\n                  --ExecutePreprocessor.timeout=1500\n<\/code><\/pre>\n\n<p>When you run the file .ipynb does not put in running, it executes it in terminal.<\/p>\n\n<p>I would like you to run it in online mode.<\/p>\n\n<p>In the file .ipynb I call Sagemaker to bring the role and one of the errors that AWS CloudWatch shows is the following:<\/p>\n\n<pre><code>ModuleNotFoundError: No module named 'sagemaker' &lt;-- Appears in CloudWatch\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":2.0,
        "Question_creation_time":1555838885617,
        "Question_favorite_count":2.0,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "jupyter-notebook",
            "amazon-sagemaker"
        ],
        "Question_view_count":5488.0,
        "Owner_creation_time":1555836680040,
        "Owner_last_access_time":1618406804950,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1555874946830,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55781509",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: automate the execution of a .ipynb file in ; content:<p>i want to automate jupyter's work.<\/p>\n\n<p>i created a function in aws lambda that when the s3 bucket receives a .csv file, it opens the determined instance of jupyter and it works fine.<\/p>\n\n<p>now i want to execute the .ipynb file that does all the work.<\/p>\n\n<p>i have tried using the jupyter configuration lifecycle.<\/p>\n\n<p>but it always fails. would it be possible to do it in the same lambda function?<\/p>\n\n<pre><code>jupyter nbconvert --execute --to notebook\n                  --inplace \/home\/ec2-user\/\/scikit.ipynb\n                  --executepreprocessor.kernel_name=python3\n                  --executepreprocessor.timeout=1500\n<\/code><\/pre>\n\n<p>when you run the file .ipynb does not put in running, it executes it in terminal.<\/p>\n\n<p>i would like you to run it in online mode.<\/p>\n\n<p>in the file .ipynb i call  to bring the role and one of the errors that aws cloudwatch shows is the following:<\/p>\n\n<pre><code>modulenotfounderror: no module named '' &lt;-- appears in cloudwatch\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to automate the execution of a .ipynb file in AWS Lambda, but has encountered errors when trying to do so. They would like to run the file in online mode and are receiving a ModuleNotFoundError in CloudWatch."
    },
    {
        "Question_id":72933908.0,
        "Question_title":"Can I use AWS CLI to add tags to all processing jobs matching a certain regex",
        "Question_body":"<p>I have close to 100 processing jobs to which I want to add certain tags. I've found commands that you can use to tag one resource with a list of tags. Is there any way I can do this for multiple jobs? Through CLI or through python+boto?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1657515736330,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "aws-cli",
            "amazon-sagemaker"
        ],
        "Question_view_count":38.0,
        "Owner_creation_time":1498814861883,
        "Owner_last_access_time":1663830261660,
        "Owner_reputation":37.0,
        "Owner_up_votes":3.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":"<p>You can <code>ResourceGroupsTaggingAPI<\/code>'s method <code>tag_resources()<\/code>.<br \/>\nThis is used to apply one or more tags to the specified list of resources.<\/p>\n<p>References:<\/p>\n<ol>\n<li><a href=\"https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/resourcegroupstaggingapi.html#ResourceGroupsTaggingAPI.Client.tag_resources\" rel=\"nofollow noreferrer\">Tag Resources using boto3<\/a><\/li>\n<li><a href=\"https:\/\/boto3.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/services\/resourcegroupstaggingapi.html#ResourceGroupsTaggingAPI.Client.untag_resources\" rel=\"nofollow noreferrer\">UnTag Resources using boto3<\/a><\/li>\n<\/ol>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1657516175783,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":1657607287156,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72933908",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: can i use aws cli to add tags to all processing jobs matching a certain regex; content:<p>i have close to 100 processing jobs to which i want to add certain tags. i've found commands that you can use to tag one resource with a list of tags. is there any way i can do this for multiple jobs? through cli or through python+boto?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to add tags to multiple processing jobs, either through AWS CLI or Python+Boto."
    },
    {
        "Question_id":63230793.0,
        "Question_title":"How to handle errors in MLflow when a model has been served using \"mlflow models serve\"?",
        "Question_body":"<p>During training, it is possible to use tags as a way to handle exceptions according to <a href=\"https:\/\/stackoverflow.com\/questions\/59856641\/how-can-i-throw-an-exception-from-within-an-mlflow-project\">this question<\/a>.<\/p>\n<p>If a model has been created using <code>mlflow.pyfunc.PythonModel<\/code>, is it possible to throw exceptions? Is there a way to allow error handling for a model that has been served?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1596462943310,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "rest",
            "mlflow"
        ],
        "Question_view_count":266.0,
        "Owner_creation_time":1472932425400,
        "Owner_last_access_time":1623748857056,
        "Owner_reputation":3.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Pune, Maharashtra, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63230793",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to handle errors in  when a model has been served using \" models serve\"?; content:<p>during training, it is possible to use tags as a way to handle exceptions according to <a href=\"https:\/\/stackoverflow.com\/questions\/59856641\/how-can-i-throw-an-exception-from-within-an--project\">this question<\/a>.<\/p>\n<p>if a model has been created using <code>.pyfunc.pythonmodel<\/code>, is it possible to throw exceptions? is there a way to allow error handling for a model that has been served?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user can use tags to handle exceptions during training, and can also throw exceptions when using .pyfunc.pythonmodel. There is a way to allow error handling for a model that has been served."
    },
    {
        "Question_id":null,
        "Question_title":"Azure ML for SAP ERP",
        "Question_body":"I am trying to figure out about standard connectors between SAP ERP product and Azure ML especially for NLP scenarios. Can you please suggest on this.",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1664541861543,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1030800\/azure-ml-for-sap-erp.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-30T13:01:37.547Z",
                "Answer_score":0,
                "Answer_body":"@Divya-0887 Thanks for the question. Here is the blog that could help and nlp recipes.\nhttps:\/\/blogs.sap.com\/2022\/08\/03\/azure-machine-learning-triggering-calculations-ml-in-sap-data-warehouse-cloud\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  for sap erp; content:i am trying to figure out about standard connectors between sap erp product and  especially for nlp scenarios. can you please suggest on this.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to find out about standard connectors between SAP ERP and Azure ML, specifically for NLP scenarios, and is looking for suggestions."
    },
    {
        "Question_id":null,
        "Question_title":"Azure ML experiment run 70- driver log not printing after a few epoches",
        "Question_body":"I am training a deep learning artificial neural network model, usually the run submitted to the Experiment will show all the model running logs in 70-driver-log of 'outputs + logs' tab, but starting yesterday, the logs show only a few lines of logs and stop printing. I can still see the model is running since the 'metrics' tab is showing the loss and accuracy results.\n\nAnd another weird thing is that after model training finished, the model is not saved.",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_creation_time":1604880529150,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/155350\/azure-ml-experiment-run-70-driver-log-not-printing.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  experiment run 70- driver log not printing after a few epoches; content:i am training a deep learning artificial neural network model, usually the run submitted to the experiment will show all the model running logs in 70-driver-log of 'outputs + logs' tab, but starting yesterday, the logs show only a few lines of logs and stop printing. i can still see the model is running since the 'metrics' tab is showing the loss and accuracy results.\n\nand another weird thing is that after model training finished, the model is not saved.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is training a deep learning artificial neural network model, but the run submitted to the experiment is not printing all the model running logs and the model is not being saved after training is finished."
    },
    {
        "Question_id":null,
        "Question_title":"[Vertex AI] Bug - Failed to download file",
        "Question_body":"Vertex AI recently fails to download any file greater than 30M. Any downloaded file will be trimmed at 30M. The download speed is also way slower recently (200k\/s). It was working a few days ago. (downloads files of 100+M at 5M\/s) Any ideas?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1657179300000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":69.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Bug-Failed-to-download-file\/td-p\/439222\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-14T07:42:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"You can see this documentation about troubleshooting with vertex, it mentions working with files that are truncated or do not complete downloading and possible solutions."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: [] bug - failed to download file; content: recently fails to download any file greater than 30m. any downloaded file will be trimmed at 30m. the download speed is also way slower recently (200k\/s). it was working a few days ago. (downloads files of 100+m at 5m\/s) any ideas?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing a bug where they are unable to download files larger than 30m, and the download speed has significantly decreased."
    },
    {
        "Question_id":null,
        "Question_title":"SageMaker Canvas failed to import the Redshift Data",
        "Question_body":"Actions:\n\nThe Redshift connection has been setup on SageMaker Canvas.\nThe Redshift already load the sample data (users, sales, etc)\nDrag and drop table 'users' to import pane.\nCheck the import preview can show the data of 'users'\nClick Import\n\nExpected result:\n\nThe dataset can be imported successfully\n\nActual result: Import failed with below details:\n\n{'message': \"Variable '$input' got invalid value None at 'input.uri'; Expected non-nullable type 'String!' not to be None.\", 'locations': [{'line': 1, 'column': 8}], 'path': None}\n\nPlease contact your admin. Request ID: 8b849887-b067-46fc-9be9-dd122e9c8874",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1641655668805,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Amazon Redshift",
            "Amazon SageMaker Canvas"
        ],
        "Question_view_count":103.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUCUdYWY0gSV6W60g7ArukXw\/sage-maker-canvas-failed-to-import-the-redshift-data",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI",
            "Analytics"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-16T15:57:31.443Z",
                "Answer_score":0,
                "Answer_body":"Hi there @AWS-User-8556114,\n\nThis could be a mishap in the configuration of the Redshift connector on the Canvas service side. Can you try to forcefully close the Canvas app by deleting the connector first, then logging out of Canvas and\/or by deleting the app (by going into the AWS Management Console, SageMaker, your domain, your profile, and deleting the app with type Canvas), then creating it again?\n\nAlternatively, I'd have to ask you to reach out to Support so that they can help you troubleshoot this by looking into your configuration.\n\nThanks!",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  canvas failed to import the redshift data; content:actions:\n\nthe redshift connection has been setup on  canvas.\nthe redshift already load the sample data (users, sales, etc)\ndrag and drop table 'users' to import pane.\ncheck the import preview can show the data of 'users'\nclick import\n\nexpected result:\n\nthe dataset can be imported successfully\n\nactual result: import failed with below details:\n\n{'message': \"variable '$input' got invalid value none at 'input.uri'; expected non-nullable type 'string!' not to be none.\", 'locations': [{'line': 1, 'column': 8}], 'path': none}\n\nplease contact your admin. request id: 8b849887-b067-46fc-9be9-dd122e9c8874",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user attempted to import a dataset from Redshift, but the import failed with an error message and they were asked to contact their admin for assistance."
    },
    {
        "Question_id":null,
        "Question_title":"Not able to archieve specific enviornment version in azure ml",
        "Question_body":"I was trying to archive a specific environment version in azure machine learning using the \"az ml environment archive \" but getting error that the \"Version is already registered and can not be changed\".\nAs per the Microsoft documentation at https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/environment?view=azure-cli-latest#az-ml-environment-archive it is possible to archive a specific version without archiving entire environment container.",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1664433909617,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1028195\/not-able-to-archieve-specific-enviornment-version.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-29T07:10:45.163Z",
                "Answer_score":0,
                "Answer_body":"From my experience and how I understand that given documentation:\n\nIf you already have archived version 1 then you won't be able to do this again, you have to change the version to a higher value.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: not able to archieve specific enviornment version in ; content:i was trying to archive a specific environment version in  using the \"az ml environment archive \" but getting error that the \"version is already registered and can not be changed\".\nas per the microsoft documentation at https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/environment?view=azure-cli-latest#az-ml-environment-archive it is possible to archive a specific version without archiving entire environment container.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is not able to archive a specific environment version in Azure ML, despite following the Microsoft documentation, and is receiving an error that the version is already registered and cannot be changed."
    },
    {
        "Question_id":69751254.0,
        "Question_title":"Submitting multiple runs to the same node on AzureML",
        "Question_body":"<p>I want to perform hyperparameter search using AzureML. My models are small (around 1GB) thus I would like to run multiple models on the same GPU\/node to save costs but I do not know how to achieve this.<\/p>\n<p>The way I currently submit jobs is the following (resulting in one training run per GPU\/node):<\/p>\n<pre><code>experiment = Experiment(workspace, experiment_name)\nconfig = ScriptRunConfig(source_directory=&quot;.\/src&quot;,\n                         script=&quot;train.py&quot;,\n                         compute_target=&quot;gpu_cluster&quot;,\n                         environment=&quot;env_name&quot;,\n                         arguments=[&quot;--args args&quot;])\nrun = experiment.submit(config)\n<\/code><\/pre>\n<p><code>ScriptRunConfig<\/code> can be provided with a <code>distributed_job_config<\/code>. I tried to use <code>MpiConfiguration<\/code> there but if this is done the run fails due to an MPI error that reads as if the cluster is configured to only allow one run per node:<\/p>\n<blockquote>\n<pre><code>Open RTE detected a bad parameter in hostfile: [...]\nThe max_slots parameter is less than the slots parameter:\nslots = 3\nmax_slots = 1\n[...] ORTE_ERROR_LOG: Bad Parameter in file util\/hostfile\/hostfile.c at line 407\n<\/code><\/pre>\n<\/blockquote>\n<p>Using <code>HyperDriveConfig<\/code> also defaults to submitting one run to one GPU and additionally providing a <code>MpiConfiguration<\/code> leads to the same error as shown above.<\/p>\n<p>I guess I could always rewrite my train script to train multiple models in parallel, s.t. each <code>run<\/code> wraps multiple trainings. I would like to avoid this option though, because then logging and checkpoint writes become increasingly messy and it would require a large refactor of the train pipeline. Also this functionality seems so basic that I hope there is a way to do this gracefully. Any ideas?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1635412142523,
        "Question_favorite_count":null,
        "Question_score":3.0,
        "Question_tags":[
            "azure",
            "mpi",
            "cluster-computing",
            "azure-machine-learning-service"
        ],
        "Question_view_count":364.0,
        "Owner_creation_time":1396607378876,
        "Owner_last_access_time":1657293849527,
        "Owner_reputation":107.0,
        "Owner_up_votes":2.0,
        "Owner_down_votes":0.0,
        "Owner_views":17.0,
        "Answer_body":"<p>Use Run.create_children method which will start child runs that are \u201clocal\u201d to the parent run, and don\u2019t need authentication.<\/p>\n<p>For AMLcompute max_concurrent_runs map to maximum number of nodes that will be used to run  a hyperparameter tuning run.\nSo there would be 1 execution per node.<\/p>\n<p>single service deployed but you can load multiple model versions in the init then the score function, depending on the request\u2019s param, uses particular model version to score.\nor with the new ML Endpoints (Preview).\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-endpoints\" rel=\"nofollow noreferrer\">What are endpoints (preview) - Azure Machine Learning | Microsoft Docs<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1635511999763,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":1635512880996,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69751254",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: submitting multiple runs to the same node on ; content:<p>i want to perform hyperparameter search using . my models are small (around 1gb) thus i would like to run multiple models on the same gpu\/node to save costs but i do not know how to achieve this.<\/p>\n<p>the way i currently submit jobs is the following (resulting in one training run per gpu\/node):<\/p>\n<pre><code>experiment = experiment(workspace, experiment_name)\nconfig = scriptrunconfig(source_directory=&quot;.\/src&quot;,\n                         script=&quot;train.py&quot;,\n                         compute_target=&quot;gpu_cluster&quot;,\n                         environment=&quot;env_name&quot;,\n                         arguments=[&quot;--args args&quot;])\nrun = experiment.submit(config)\n<\/code><\/pre>\n<p><code>scriptrunconfig<\/code> can be provided with a <code>distributed_job_config<\/code>. i tried to use <code>mpiconfiguration<\/code> there but if this is done the run fails due to an mpi error that reads as if the cluster is configured to only allow one run per node:<\/p>\n<blockquote>\n<pre><code>open rte detected a bad parameter in hostfile: [...]\nthe max_slots parameter is less than the slots parameter:\nslots = 3\nmax_slots = 1\n[...] orte_error_log: bad parameter in file util\/hostfile\/hostfile.c at line 407\n<\/code><\/pre>\n<\/blockquote>\n<p>using <code>hyperdriveconfig<\/code> also defaults to submitting one run to one gpu and additionally providing a <code>mpiconfiguration<\/code> leads to the same error as shown above.<\/p>\n<p>i guess i could always rewrite my train script to train multiple models in parallel, s.t. each <code>run<\/code> wraps multiple trainings. i would like to avoid this option though, because then logging and checkpoint writes become increasingly messy and it would require a large refactor of the train pipeline. also this functionality seems so basic that i hope there is a way to do this gracefully. any ideas?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to run multiple models on the same GPU\/node to save costs, but is encountering an error when using the scriptrunconfig and hyperdriveconfig functions."
    },
    {
        "Question_id":null,
        "Question_title":"Is it possible to test locally SageMaker Inference Pipelines?",
        "Question_body":"Is it possible to test locally SageMaker Inference Pipelines? I would like to be able to easily troubleshoot and find the appropriate serialization between containers",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1600158011000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Machine Learning & AI"
        ],
        "Question_view_count":202.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU8R_MjbU1QPm66SCgld4spQ\/is-it-possible-to-test-locally-sage-maker-inference-pipelines",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-25T12:39:21.000Z",
                "Answer_score":0,
                "Answer_body":"If you are referring to using local mode via the SM PySDK, then pipeline deployment is not supported.\n\nAs an alternative, given your three inference containers, you could manually run the services locally and then implement a kind of facade function that invokes the three services in pipeline and manages input\/output accordingly.",
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is it possible to test locally  inference pipelines?; content:is it possible to test locally  inference pipelines? i would like to be able to easily troubleshoot and find the appropriate serialization between containers",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to know if it is possible to test locally inference pipelines and if there is an easy way to troubleshoot and find the appropriate serialization between containers."
    },
    {
        "Question_id":null,
        "Question_title":"Run experiment crashes when using a pre-build Docker image as environment",
        "Question_body":"I duplicated my question because I have not received a proper answer, yet.\nThe reason why I duplicated the question is that I need to implement something within Azure for a customer where I need to use a pre-build Docker image as an environment.\nUnfortunately, it is not working because AMLS cannot download the pre-build Docker image when you need credentials for downloading the pre-build Docker image.\nIn my opinion, the credentials for using the pre-build Docker image are not saved correctly in Azure Machine Learning Studio. This is the reason why AMLS cannot download the pre-build Docker image. I will be very grateful if someone can test the code snippets below and give me feedback if they worked or not.\n\nHere is the backstory:\nMy co-workers are using pre-build docker images for our developing environment in Azure Machine Learning Service.\nIn a separate script, they have registered these environments with the command myenv.register(workspace=ws). In another script, I should use their environment for testing our model.\n\nIn order to get one of their environments, I use the command registered_env = Environment.get(ws, 'the-specific-environment-name')\n\nUnfortunately, this does not work when I use registered_env for the experiment. I get the error \"Authentication failed for container registry name_of_their_container_registry.azurecr.io\". The experiment run works perfectly when I copy their environment definition code into my script instead of using the command registered_env = Environment.get(ws, 'the-specific-environment-name').\n\nHowever, I cannot copy every time their environment definition code into my script.\nHow can I get the environment into my script which has been defined in another script?\n\nThis StackOverFlow post is quite related to my problem:\nhttps:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der\n\n\n\n\n\nTo illustrate what my problem is, here are some code samples.\n\nThis code sample is working:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n    \n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = Model(ws, 'exemplarily_model')\n    \n inference_config = InferenceConfig(environment=exemplarily_env_docker_image, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nNow, I do a small change and the code sample is not working anymore:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = Model(ws, 'exemplarily_model')\n    \n reg_env = Environment.get(ws, \"exemplarily-env_Docker-image-AzureRegistry\")\n inference_config = InferenceConfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nWhat is working:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.save_to_directory(path=\".\/env\", overwrite=True)\n model = Model(ws, 'exemplarily_model')\n    \n reg_env = Environment.load_from_directory(path=\".\/env\")\n inference_config = InferenceConfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nWhy is the middle code sample not working? Is this a bug?",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_creation_time":1654697991800,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/881670\/run-experiment-crashes-when-using-a-pre-build-dock.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: run experiment crashes when using a pre-build docker image as environment; content:i duplicated my question because i have not received a proper answer, yet.\nthe reason why i duplicated the question is that i need to implement something within azure for a customer where i need to use a pre-build docker image as an environment.\nunfortunately, it is not working because amls cannot download the pre-build docker image when you need credentials for downloading the pre-build docker image.\nin my opinion, the credentials for using the pre-build docker image are not saved correctly in  studio. this is the reason why amls cannot download the pre-build docker image. i will be very grateful if someone can test the code snippets below and give me feedback if they worked or not.\n\nhere is the backstory:\nmy co-workers are using pre-build docker images for our developing environment in  service.\nin a separate script, they have registered these environments with the command myenv.register(workspace=ws). in another script, i should use their environment for testing our model.\n\nin order to get one of their environments, i use the command registered_env = environment.get(ws, 'the-specific-environment-name')\n\nunfortunately, this does not work when i use registered_env for the experiment. i get the error \"authentication failed for container registry name_of_their_container_registry.azurecr.io\". the experiment run works perfectly when i copy their environment definition code into my script instead of using the command registered_env = environment.get(ws, 'the-specific-environment-name').\n\nhowever, i cannot copy every time their environment definition code into my script.\nhow can i get the environment into my script which has been defined in another script?\n\nthis stackoverflow post is quite related to my problem:\nhttps:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der\n\n\n\n\n\nto illustrate what my problem is, here are some code samples.\n\nthis code sample is working:\n\n registry = containerregistry()\n registry.address = <dockerregistryaddress>\n registry.username = <username>\n registry.password = <password>\n exemplarily_env_docker_image = environment.from_docker_image('exemplarily-env_docker-image-azureregistry', <dockerimageaddress>, container_registry=registry, conda_specification=none, pip_requirements=none)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = true\n    \n # registering and getting of an environment that derives from a docker image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = model(ws, 'exemplarily_model')\n    \n inference_config = inferenceconfig(environment=exemplarily_env_docker_image, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n deployment_config = localwebservice.deploy_configuration(port=6789)\n    \n service = model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=true,\n )\n    \n service.wait_for_deployment(show_output=true)\n print(service.get_logs())\n\n\n\n\nnow, i do a small change and the code sample is not working anymore:\n\n registry = containerregistry()\n registry.address = <dockerregistryaddress>\n registry.username = <username>\n registry.password = <password>\n exemplarily_env_docker_image = environment.from_docker_image('exemplarily-env_docker-image-azureregistry', <dockerimageaddress>, container_registry=registry, conda_specification=none, pip_requirements=none)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = true\n # registering and getting of an environment that derives from a docker image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = model(ws, 'exemplarily_model')\n    \n reg_env = environment.get(ws, \"exemplarily-env_docker-image-azureregistry\")\n inference_config = inferenceconfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = localwebservice.deploy_configuration(port=6789)\n    \n service = model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=true,\n )\n    \n service.wait_for_deployment(show_output=true)\n print(service.get_logs())\n\n\n\n\nwhat is working:\n\n registry = containerregistry()\n registry.address = <dockerregistryaddress>\n registry.username = <username>\n registry.password = <password>\n exemplarily_env_docker_image = environment.from_docker_image('exemplarily-env_docker-image-azureregistry', <dockerimageaddress>, container_registry=registry, conda_specification=none, pip_requirements=none)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = true\n # registering and getting of an environment that derives from a docker image is not working because the credentials are not saved\n exemplarily_env_docker_image.save_to_directory(path=\".\/env\", overwrite=true)\n model = model(ws, 'exemplarily_model')\n    \n reg_env = environment.load_from_directory(path=\".\/env\")\n inference_config = inferenceconfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = localwebservice.deploy_configuration(port=6789)\n    \n service = model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=true,\n )\n    \n service.wait_for_deployment(show_output=true)\n print(service.get_logs())\n\n\n\n\nwhy is the middle code sample not working? is this a bug?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty running an experiment using a pre-built docker image as an environment, as the credentials for the image are not being saved correctly in Studio. They have provided code samples to illustrate the issue and are asking why the middle code sample is not working and if it is a bug."
    },
    {
        "Question_id":null,
        "Question_title":"How to retrieve output files from dvc pipeline",
        "Question_body":"<p>I have created a pipeline and run it successfully, creating output files as per the pipeline I specified. I might have done something wrong, but when I try and <code>dvc get<\/code> this output file I get an error<br>\n<code>Unable to find DVC file with output<\/code><\/p>\n<p>My aim is to be able to get the model output file created via dvc pipeline into another project. Should I approach it differently?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1635890105406,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":216.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/how-to-retrieve-output-files-from-dvc-pipeline\/948",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2152,
                "name":"Yanxiang Gao",
                "username":"YanxiangGao",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/y\/f04885\/{size}.png",
                "created_at":"2021-11-04T02:04:50.461Z",
                "cooked":"<p>Any details of it? Your repository structure?  And the output of<\/p>\n<ol>\n<li>command <code>dvc doctor<\/code>\n<\/li>\n<li>the log output of your <code>dvc get<\/code> command with a <code>-vv<\/code> flag.<\/li>\n<\/ol>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-11-04T02:04:50.461Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":0.8,
                "yours":false,
                "topic_id":948,
                "topic_slug":"how-to-retrieve-output-files-from-dvc-pipeline",
                "display_username":"Yanxiang Gao",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":340,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2154,
                "name":"Pri",
                "username":"pri",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/p\/22d042\/{size}.png",
                "created_at":"2021-11-04T09:56:51.375Z",
                "cooked":"<p>I solved the problem in the end (discussion in discord). I had used absolute paths in my dvc.yaml which I had manually created, and changing this to relative paths fixed the problem. It seems <code>dvc get<\/code> uses this to locate and retrieve files.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-11-04T09:56:51.375Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":15.8,
                "yours":false,
                "topic_id":948,
                "topic_slug":"how-to-retrieve-output-files-from-dvc-pipeline",
                "display_username":"Pri",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":359,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to retrieve output files from  pipeline; content:<p>i have created a pipeline and run it successfully, creating output files as per the pipeline i specified. i might have done something wrong, but when i try and <code> get<\/code> this output file i get an error<br>\n<code>unable to find  file with output<\/code><\/p>\n<p>my aim is to be able to get the model output file created via  pipeline into another project. should i approach it differently?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to retrieve output files from a pipeline they have created, but is getting an error when they try to do so. They are looking for a way to get the model output file into another project."
    },
    {
        "Question_id":72783781.0,
        "Question_title":"Getting R package 'bsts' to work on AWS Sagemaker Notebook Instance Python",
        "Question_body":"<p>Just wondering if anyone has been able to get a Python + R kernel working on AWS Sagemaker Notebook instance?<\/p>\n<p>The reason I'm asking is so I can use a python environment to run R packages within, specifically 'bsts' and 'boom'.<\/p>\n<p>Is there a way to create a kernel that has both Python + R installed?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1656407824147,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "r",
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":43.0,
        "Owner_creation_time":1495607959952,
        "Owner_last_access_time":1663954411663,
        "Owner_reputation":358.0,
        "Owner_up_votes":10.0,
        "Owner_down_votes":3.0,
        "Owner_views":84.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Wellington, New Zealand",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72783781",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: getting r package 'bsts' to work on  notebook instance python; content:<p>just wondering if anyone has been able to get a python + r kernel working on  notebook instance?<\/p>\n<p>the reason i'm asking is so i can use a python environment to run r packages within, specifically 'bsts' and 'boom'.<\/p>\n<p>is there a way to create a kernel that has both python + r installed?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is wondering if anyone has been able to get a Python + R kernel working on a notebook instance, so they can use a Python environment to run R packages such as 'bsts' and 'boom'."
    },
    {
        "Question_id":71151054.0,
        "Question_title":"How to log a table of metrics into mlflow",
        "Question_body":"<p>I am trying to see if mlflow is the right place to store my metrics in the model tracking.  According to the doc log_metric takes either a key value or a dict of key-values.  I am wondering how to log something like below into mlflow so it can be visualized meaningfully.<\/p>\n<pre><code>          precision    recall  f1-score   support\n\n  class1       0.89      0.98      0.93       174\n  class2       0.96      0.90      0.93        30\n  class3       0.96      0.90      0.93        30\n  class4       1.00      1.00      1.00         7\n  class5       0.93      1.00      0.96        13\n  class6       1.00      0.73      0.85        15\n  class7       0.95      0.97      0.96        39\n  class8       0.80      0.67      0.73         6\n  class9       0.97      0.86      0.91        37\n class10       0.95      0.81      0.88        26\n class11       0.50      1.00      0.67         5\n class12       0.93      0.89      0.91        28\n class13       0.73      0.84      0.78        19\n class14       1.00      1.00      1.00         6\n class15       0.45      0.83      0.59         6\n class16       0.97      0.98      0.97       245\n class17       0.93      0.86      0.89       206\n\naccuracy                           0.92       892\n<\/code><\/pre>\n<p>macro avg       0.88      0.90      0.88       892\nweighted avg       0.93      0.92      0.92       892<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1645058143563,
        "Question_favorite_count":1.0,
        "Question_score":1.0,
        "Question_tags":[
            "mlflow"
        ],
        "Question_view_count":546.0,
        "Owner_creation_time":1426639280947,
        "Owner_last_access_time":1650573965300,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71151054",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to log a table of metrics into ; content:<p>i am trying to see if  is the right place to store my metrics in the model tracking.  according to the doc log_metric takes either a key value or a dict of key-values.  i am wondering how to log something like below into  so it can be visualized meaningfully.<\/p>\n<pre><code>          precision    recall  f1-score   support\n\n  class1       0.89      0.98      0.93       174\n  class2       0.96      0.90      0.93        30\n  class3       0.96      0.90      0.93        30\n  class4       1.00      1.00      1.00         7\n  class5       0.93      1.00      0.96        13\n  class6       1.00      0.73      0.85        15\n  class7       0.95      0.97      0.96        39\n  class8       0.80      0.67      0.73         6\n  class9       0.97      0.86      0.91        37\n class10       0.95      0.81      0.88        26\n class11       0.50      1.00      0.67         5\n class12       0.93      0.89      0.91        28\n class13       0.73      0.84      0.78        19\n class14       1.00      1.00      1.00         6\n class15       0.45      0.83      0.59         6\n class16       0.97      0.98      0.97       245\n class17       0.93      0.86      0.89       206\n\naccuracy                           0.92       892\n<\/code><\/pre>\n<p>macro avg       0.88      0.90      0.88       892\nweighted avg       0.93      0.92      0.92       892<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is seeking a way to log a table of metrics into a platform so it can be visualized meaningfully and is wondering if this is the right place to store their metrics in the model tracking."
    },
    {
        "Question_id":41603082.0,
        "Question_title":"401 Errors Calling the Microsoft Luis.ai Programmatic API",
        "Question_body":"<h2><strong>ASKING THIS HERE AT THE EXPLICIT REQUEST OF THE MICROSOFT AZURE SUPPORT TEAM.<\/strong><\/h2>\n\n<p>I've been attempting to call the MS Luis.ai <em>programmatic<\/em> API (bit.ly\/2iev01n) and have been receiving a 401 unauthorized response to every request. Here's a simple GET example: <code>https:\/\/api.projectoxford.ai\/luis\/v1.0\/prog\/apps\/{appId}\/entities?subscription-key={subscription_key}<\/code>.  <\/p>\n\n<p>I am providing my appId from the Luis.ai GUI (as specified by the API docs), here:<br>\n<img src=\"https:\/\/i.stack.imgur.com\/Cg2Fw.png\" alt=\"Luis.ai App Settings App Id\"><\/p>\n\n<p>I am providing my subscription key from Azure (as specified by the API docs), here:<br>\n<img src=\"https:\/\/i.stack.imgur.com\/GS2Fe.png\" alt=\"Azure Console\"><\/p>\n\n<p>The app ID and subscription key, sourced from above, are the exact same as what I'm using to hit the query API successfully (see note at bottom). My account is pay-as-you-go (not free).<\/p>\n\n<p><strong><em>Am I doing something wrong here? Is this API deprecated, moved, down, or out-of-sync with the docs?<\/em><\/strong><\/p>\n\n<p><strong>NOTE:<\/strong> I can manipulate my model through the online GUI but that approach will be far too manual for our business needs where our model will need to be programmatically updated as new business entities come into existence.  <\/p>\n\n<p><strong>NOTE:<\/strong> The programmatic API is different from the query API which has this request URL, which is working fine for me:<br>\n<code>https:\/\/api.projectoxford.ai\/luis\/v2.0\/apps\/{appId}?subscription-key={subscription_key}&amp;verbose=true&amp;q={utterance}<\/code>  <\/p>\n\n<p><strong>NOTE:<\/strong> There doesn't seem to be a Luis.ai programmatic API for v2.0--which is why the URLs from the query and programmatic APIs have different versions.  <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_creation_time":1484180085280,
        "Question_favorite_count":1.0,
        "Question_score":4.0,
        "Question_tags":[
            "azure",
            "botframework",
            "chatbot",
            "azure-machine-learning-studio",
            "azure-language-understanding"
        ],
        "Question_view_count":1280.0,
        "Owner_creation_time":1343167997556,
        "Owner_last_access_time":1663979648103,
        "Owner_reputation":191.0,
        "Owner_up_votes":11.0,
        "Owner_down_votes":2.0,
        "Owner_views":27.0,
        "Answer_body":"<p>Answering my own question here:<\/p>\n\n<p>I have found my LUIS.ai programmatic API key. It is found by:\nLUIS.ai dashboard -> username (upper-right) -> settings in dropdown -> Subscription Keys tab -> Programmatic API Key<\/p>\n\n<p>It was not immediately obvious since it's found nowhere else: not alongside any of the other key listings in cognitive services or the LUIS.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1484669845332,
        "Answer_score":7.0,
        "Owner_location":null,
        "Question_last_edit_time":1484193011887,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41603082",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: 401 errors calling the microsoft luis.ai programmatic api; content:<h2><strong>asking this here at the explicit request of the microsoft azure support team.<\/strong><\/h2>\n\n<p>i've been attempting to call the ms luis.ai <em>programmatic<\/em> api (bit.ly\/2iev01n) and have been receiving a 401 unauthorized response to every request. here's a simple get example: <code>https:\/\/api.projectoxford.ai\/luis\/v1.0\/prog\/apps\/{appid}\/entities?subscription-key={subscription_key}<\/code>.  <\/p>\n\n<p>i am providing my appid from the luis.ai gui (as specified by the api docs), here:<br>\n<img src=\"https:\/\/i.stack.imgur.com\/cg2fw.png\" alt=\"luis.ai app settings app id\"><\/p>\n\n<p>i am providing my subscription key from azure (as specified by the api docs), here:<br>\n<img src=\"https:\/\/i.stack.imgur.com\/gs2fe.png\" alt=\"azure console\"><\/p>\n\n<p>the app id and subscription key, sourced from above, are the exact same as what i'm using to hit the query api successfully (see note at bottom). my account is pay-as-you-go (not free).<\/p>\n\n<p><strong><em>am i doing something wrong here? is this api deprecated, moved, down, or out-of-sync with the docs?<\/em><\/strong><\/p>\n\n<p><strong>note:<\/strong> i can manipulate my model through the online gui but that approach will be far too manual for our business needs where our model will need to be programmatically updated as new business entities come into existence.  <\/p>\n\n<p><strong>note:<\/strong> the programmatic api is different from the query api which has this request url, which is working fine for me:<br>\n<code>https:\/\/api.projectoxford.ai\/luis\/v2.0\/apps\/{appid}?subscription-key={subscription_key}&amp;verbose=true&amp;q={utterance}<\/code>  <\/p>\n\n<p><strong>note:<\/strong> there doesn't seem to be a luis.ai programmatic api for v2.0--which is why the urls from the query and programmatic apis have different versions.  <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving 401 unauthorized responses when attempting to call the Microsoft LUIS.ai programmatic API, despite providing the correct app ID and subscription key."
    },
    {
        "Question_id":72986981.0,
        "Question_title":"Porting custom job from GCP AI Platform to Vertex AI - how to get state and logs of job?",
        "Question_body":"<p>I am porting custom job training from gcp AI Platform to Vertex AI.\nI am able to start a job, but can't find how to to get the status and how to stream the logs to my local client.<\/p>\n<p>For AI Platform I was using this to get the state:<\/p>\n<pre><code>from google.oauth2 import service_account\nfrom googleapiclient import discovery\nscopes = ['https:\/\/www.googleapis.com\/auth\/cloud-platform']\ncredentials = service_account.Credentials.from_service_account_file(keyFile, scopes=scopes)\nml_apis = discovery.build(&quot;ml&quot;,&quot;v1&quot;, credentials=credentials, cache_discovery=False)\nx = ml_apis.projects().jobs().get(name=&quot;projects\/%myproject%\/jobs\/&quot;+job_id).execute()  # execute http request\nreturn x['state']\n<\/code><\/pre>\n<p>And this to stream the logs:<\/p>\n<pre><code>cmd = 'gcloud ai-platform jobs stream-logs ' + job_id\n<\/code><\/pre>\n<p>This does not work for Vertex AI job. What is the replacement code?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1657835239540,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "google-cloud-platform",
            "google-cloud-vertex-ai",
            "google-ai-platform"
        ],
        "Question_view_count":62.0,
        "Owner_creation_time":1254829817772,
        "Owner_last_access_time":1663965241687,
        "Owner_reputation":2595.0,
        "Owner_up_votes":462.0,
        "Owner_down_votes":5.0,
        "Owner_views":357.0,
        "Answer_body":"<p>Can you try this command for streaming logs :<\/p>\n<pre><code>gcloud ai custom-jobs stream-logs 123 --region=europe-west4\n<\/code><\/pre>\n<p>123 is the <strong>ID<\/strong> of the custom job for this case, you can add glcoud wide flags such as --format as well.<\/p>\n<p>You can visit this <a href=\"https:\/\/cloud.google.com\/sdk\/gcloud\/reference\/ai\/custom-jobs\/stream-logs\" rel=\"nofollow noreferrer\">link<\/a> for more details about this command and additional flags available.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1657854766996,
        "Answer_score":1.0,
        "Owner_location":"Germany",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":1657863259568,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72986981",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: porting custom job from gcp ai platform to  - how to get state and logs of job?; content:<p>i am porting custom job training from gcp ai platform to .\ni am able to start a job, but can't find how to to get the status and how to stream the logs to my local client.<\/p>\n<p>for ai platform i was using this to get the state:<\/p>\n<pre><code>from google.oauth2 import service_account\nfrom googleapiclient import discovery\nscopes = ['https:\/\/www.googleapis.com\/auth\/cloud-platform']\ncredentials = service_account.credentials.from_service_account_file(keyfile, scopes=scopes)\nml_apis = discovery.build(&quot;ml&quot;,&quot;v1&quot;, credentials=credentials, cache_discovery=false)\nx = ml_apis.projects().jobs().get(name=&quot;projects\/%myproject%\/jobs\/&quot;+job_id).execute()  # execute http request\nreturn x['state']\n<\/code><\/pre>\n<p>and this to stream the logs:<\/p>\n<pre><code>cmd = 'gcloud ai-platform jobs stream-logs ' + job_id\n<\/code><\/pre>\n<p>this does not work for  job. what is the replacement code?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to get the status and stream the logs of a custom job training from GCP AI Platform to , and is asking for the replacement code for the commands they used for GCP AI Platform."
    },
    {
        "Question_id":null,
        "Question_title":"Publishing Graphs\/Visualizations",
        "Question_body":"<p>I\u2019m soon going to start implementing W&amp;B for my neural network\u2019s hyperparameter tuning. This is in preparation for an academic paper I\u2019m writing on the subject. The software seems very pragmatic and well-polished, so I\u2019m quite excited to get started.<\/p>\n<p>Its visualizations in particular seem to be of a very high quality. Some present sophisticated functionality that other experiment trackers can\u2019t touch. With proper citation, can these be included for publication?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_creation_time":1638456342347,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":179.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/publishing-graphs-visualizations\/1457",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "id":3581,
                "name":"Leslie",
                "username":"lesliewandb",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/lesliewandb\/{size}\/369_2.png",
                "created_at":"2021-12-02T17:40:47.308Z",
                "cooked":"<p>Hi Logan,<\/p>\n<p>I\u2019m so happy you\u2019re excited to use our product! Our engineers have worked very hard in order to get it to where it is today. We would love for you to use our graphs in your paper. We have a few examples of how to do so here (<a href=\"https:\/\/docs.wandb.ai\/company\/academics#cite-weights-and-biases\" class=\"inline-onebox-loading\">https:\/\/docs.wandb.ai\/company\/academics#cite-weights-and-biases<\/a>).<\/p>\n<p>Warmly,<br>\nLeslie<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-12-02T17:40:47.308Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":15.8,
                "yours":false,
                "topic_id":1457,
                "topic_slug":"publishing-graphs-visualizations",
                "display_username":"Leslie",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":453,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":true
            },
            {
                "id":3638,
                "name":"Leslie",
                "username":"lesliewandb",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/lesliewandb\/{size}\/369_2.png",
                "created_at":"2021-12-06T13:25:54.781Z",
                "cooked":"<p>Hi Logan,<\/p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.<\/p>\n<p>Best,<br>\nWeights &amp; Biases<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-12-06T13:25:54.781Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":1457,
                "topic_slug":"publishing-graphs-visualizations",
                "display_username":"Leslie",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":453,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":3690,
                "name":"Leslie",
                "username":"lesliewandb",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/lesliewandb\/{size}\/369_2.png",
                "created_at":"2021-12-09T14:33:11.838Z",
                "cooked":"<p>Hi Logan,<\/p>\n<p>I\u2019m going to close this ticket, but if you have any more questions regarding wandb please let me know!<\/p>\n<p>Warmly,<br>\nLeslie<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2021-12-09T14:33:11.838Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":1457,
                "topic_slug":"publishing-graphs-visualizations",
                "display_username":"Leslie",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":453,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4386,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-01-31T14:46:26.430Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":5,
                "post_type":3,
                "updated_at":"2022-01-31T14:46:26.430Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":1457,
                "topic_slug":"publishing-graphs-visualizations",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: publishing graphs\/visualizations; content:<p>i\u2019m soon going to start implementing w&amp;b for my neural network\u2019s hyperparameter tuning. this is in preparation for an academic paper i\u2019m writing on the subject. the software seems very pragmatic and well-polished, so i\u2019m quite excited to get started.<\/p>\n<p>its visualizations in particular seem to be of a very high quality. some present sophisticated functionality that other experiment trackers can\u2019t touch. with proper citation, can these be included for publication?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is excited to use W&B for their neural network's hyperparameter tuning and is interested in using the high-quality visualizations for publication with proper citation."
    },
    {
        "Question_id":null,
        "Question_title":"Copy instead of moving runs to team",
        "Question_body":"<p>Hello,<\/p>\n<p>I know how to move runs to a team, but my problem is that the runs are then removed from my profile.<\/p>\n<p>Is there a way to copy the runs, keeping them in my profile and in the team ?<\/p>\n<p>A better solution would be to link them to a team project and if we add things to the run in the user project the changes should  also be  reported in the team project. Basically, both projects would point to the same unique run and if a user deletes a run in his project the run would still be present in team\u2019s project (only the link would be removed). If a run as no links attached to it, it should be erased.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1652890834786,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":46.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/copy-instead-of-moving-runs-to-team\/2442",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":6520,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-07-17T16:21:35.467Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":2,
                "post_type":3,
                "updated_at":"2022-07-17T16:21:35.467Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":2442,
                "topic_slug":"copy-instead-of-moving-runs-to-team",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: copy instead of moving runs to team; content:<p>hello,<\/p>\n<p>i know how to move runs to a team, but my problem is that the runs are then removed from my profile.<\/p>\n<p>is there a way to copy the runs, keeping them in my profile and in the team ?<\/p>\n<p>a better solution would be to link them to a team project and if we add things to the run in the user project the changes should  also be  reported in the team project. basically, both projects would point to the same unique run and if a user deletes a run in his project the run would still be present in team\u2019s project (only the link would be removed). if a run as no links attached to it, it should be erased.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to copy runs to a team, keeping them in their profile, and linking them to a team project so that changes to the run in the user project are reported in the team project."
    },
    {
        "Question_id":71540633.0,
        "Question_title":"'waitress-serve' is not recognized as an internal or external command,",
        "Question_body":"<p>I try run this mlflow models serve --model-uri runs:\/f3393a61d01d4289b16707ed718f23be\/log_reg_model -p 1235 script but i got this error<\/p>\n<pre><code>'waitress-serve' is not recognized as an internal or external command,\noperable program or batch file.\nTraceback (most recent call last):\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\Scripts\\mlflow-script.py&quot;, line 10, in &lt;module&gt;\n    sys.exit(cli())\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\click\\core.py&quot;, line 1128, in __call__\n    return self.main(*args, **kwargs)\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\click\\core.py&quot;, line 1053, in main\n    rv = self.invoke(ctx)\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\click\\core.py&quot;, line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\click\\core.py&quot;, line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\click\\core.py&quot;, line 1395, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\click\\core.py&quot;, line 754, in invoke\n    return __callback(*args, **kwargs)\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\mlflow\\models\\cli.py&quot;, line 59, in serve\n    ).serve(model_uri=model_uri, port=port, host=host, enable_mlserver=enable_mlserver)\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\mlflow\\pyfunc\\backend.py&quot;, line 79, in serve\n    conda_env_path, command, self._install_mlflow, command_env=command_env\n  File &quot;C:\\Users\\ahmad\\miniconda3\\envs\\mlflow\\lib\\site-packages\\mlflow\\pyfunc\\backend.py&quot;, line 168, in _execute_in_conda_env\n    &quot;Command '{0}' returned non zero return code. Return code = {1}&quot;.format(command, rc)\nException: Command 'conda activate mlflow-270591f5d4ece78a187f6457a571ae1ce1e4d11f &amp; waitress-serve --host=127.0.0.1 --port=1235 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 1\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1647712299403,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "conda",
            "mlflow",
            "waitress"
        ],
        "Question_view_count":232.0,
        "Owner_creation_time":1636549332240,
        "Owner_last_access_time":1663602637843,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71540633",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: 'waitress-serve' is not recognized as an internal or external command,; content:<p>i try run this  models serve --model-uri runs:\/f3393a61d01d4289b16707ed718f23be\/log_reg_model -p 1235 script but i got this error<\/p>\n<pre><code>'waitress-serve' is not recognized as an internal or external command,\noperable program or batch file.\ntraceback (most recent call last):\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\scripts\\-script.py&quot;, line 10, in &lt;module&gt;\n    sys.exit(cli())\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\click\\core.py&quot;, line 1128, in __call__\n    return self.main(*args, **kwargs)\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\click\\core.py&quot;, line 1053, in main\n    rv = self.invoke(ctx)\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\click\\core.py&quot;, line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\click\\core.py&quot;, line 1659, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\click\\core.py&quot;, line 1395, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\click\\core.py&quot;, line 754, in invoke\n    return __callback(*args, **kwargs)\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\\\models\\cli.py&quot;, line 59, in serve\n    ).serve(model_uri=model_uri, port=port, host=host, enable_mlserver=enable_mlserver)\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\\\pyfunc\\backend.py&quot;, line 79, in serve\n    conda_env_path, command, self._install_, command_env=command_env\n  file &quot;c:\\users\\ahmad\\miniconda3\\envs\\\\lib\\site-packages\\\\pyfunc\\backend.py&quot;, line 168, in _execute_in_conda_env\n    &quot;command '{0}' returned non zero return code. return code = {1}&quot;.format(command, rc)\nexception: command 'conda activate -270591f5d4ece78a187f6457a571ae1ce1e4d11f &amp; waitress-serve --host=127.0.0.1 --port=1235 --ident= .pyfunc.scoring_server.wsgi:app' returned non zero return code. return code = 1\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user received an error message indicating that 'waitress-serve' is not recognized as an internal or external command."
    },
    {
        "Question_id":null,
        "Question_title":"About Speech-to-Text support area",
        "Question_body":"Does Speech-to-Text have any nodes in Hong Kong?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1632630840000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":325.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/About-Speech-to-Text-support-area\/td-p\/171226\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-01T14:26:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"Speech to text is available as a global or multi regional service. You can select a region by specifying a particular endpoint.\u00a0\u00a0https:\/\/cloud.google.com\/speech-to-text\/docs\/endpoints\n\n\u00a0\n\nHong Kong is not currently available as a standalone region."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: about speech-to-text support area; content:does speech-to-text have any nodes in hong kong?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if speech-to-text has any nodes in Hong Kong."
    },
    {
        "Question_id":59548385.0,
        "Question_title":"How to make prediction with sagemaker on pandas dataframe",
        "Question_body":"<p>I am using Sagemaker to train and deploy my machine learning model. As regard to prediction, it will be executed by a lambda function as a scheduled job (every hour). The process is as follows:<\/p>\n\n<ol>\n<li>pull new data from S3 since last prediction <\/li>\n<li>preprocess, aggregate and create prediction data set <\/li>\n<li>call sagemaker endpoint and make prediction <\/li>\n<li>either save result to s3 or insert to database table<\/li>\n<\/ol>\n\n<p>Based on my finding, typically the input will either from lambda payload <\/p>\n\n<pre><code>data = json.loads(json.dumps(event))\npayload = data['data']\nprint(payload)\n\nresponse = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n                                   ContentType='text\/csv',\n                                   Body=payload)\n<\/code><\/pre>\n\n<p>or read from s3 file:\nmy_bucket = resource.Bucket('pred_data') #subsitute this for your s3 bucket name. <\/p>\n\n<pre><code>obj = client.get_object(Bucket=my_bucket, Key='foo.csv')\nlines= obj['Body'].read().decode('utf-8').splitlines()\nreader = csv.reader(lines)\nfile = io.StringIO(lines)\n\n\nresponse = runtime.invoke_endpoint(EndpointName=ENDPOINT,\n                                   ContentType='*\/*',\n                                   Body = file.getvalue(),\n                                   Body=payload)\noutput = response['Body'].read().decode('utf-8')\n<\/code><\/pre>\n\n<p>Since I will be pulling raw data from s3 and preprocess, a <code>pandas<\/code> dataframe will be generated. Is it possible to feed this directly as the input of <code>invoke_endpoint<\/code>? I could upload the aggregated dataset to another S3 bucket, but does it have to go through the <code>decoding<\/code>, <code>csv.reader<\/code>, <code>StringIO<\/code> and all that just like the example I found or is there an easy way to do it? Is the <code>decode<\/code> step really necessary to get the output?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1577825743740,
        "Question_favorite_count":2.0,
        "Question_score":8.0,
        "Question_tags":[
            "pandas",
            "lambda",
            "amazon-sagemaker",
            "inference"
        ],
        "Question_view_count":1143.0,
        "Owner_creation_time":1393477703600,
        "Owner_last_access_time":1663874937043,
        "Owner_reputation":4303.0,
        "Owner_up_votes":134.0,
        "Owner_down_votes":1.0,
        "Owner_views":536.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59548385",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to make prediction with  on pandas dataframe; content:<p>i am using  to train and deploy my machine learning model. as regard to prediction, it will be executed by a lambda function as a scheduled job (every hour). the process is as follows:<\/p>\n\n<ol>\n<li>pull new data from s3 since last prediction <\/li>\n<li>preprocess, aggregate and create prediction data set <\/li>\n<li>call  endpoint and make prediction <\/li>\n<li>either save result to s3 or insert to database table<\/li>\n<\/ol>\n\n<p>based on my finding, typically the input will either from lambda payload <\/p>\n\n<pre><code>data = json.loads(json.dumps(event))\npayload = data['data']\nprint(payload)\n\nresponse = runtime.invoke_endpoint(endpointname=endpoint_name,\n                                   contenttype='text\/csv',\n                                   body=payload)\n<\/code><\/pre>\n\n<p>or read from s3 file:\nmy_bucket = resource.bucket('pred_data') #subsitute this for your s3 bucket name. <\/p>\n\n<pre><code>obj = client.get_object(bucket=my_bucket, key='foo.csv')\nlines= obj['body'].read().decode('utf-8').splitlines()\nreader = csv.reader(lines)\nfile = io.stringio(lines)\n\n\nresponse = runtime.invoke_endpoint(endpointname=endpoint,\n                                   contenttype='*\/*',\n                                   body = file.getvalue(),\n                                   body=payload)\noutput = response['body'].read().decode('utf-8')\n<\/code><\/pre>\n\n<p>since i will be pulling raw data from s3 and preprocess, a <code>pandas<\/code> dataframe will be generated. is it possible to feed this directly as the input of <code>invoke_endpoint<\/code>? i could upload the aggregated dataset to another s3 bucket, but does it have to go through the <code>decoding<\/code>, <code>csv.reader<\/code>, <code>stringio<\/code> and all that just like the example i found or is there an easy way to do it? is the <code>decode<\/code> step really necessary to get the output?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to make predictions with on a pandas dataframe, and is wondering if they can feed the dataframe directly to the invoke_endpoint function, or if they need to go through the decoding, csv.reader, and stringio steps."
    },
    {
        "Question_id":null,
        "Question_title":"Downloading best sweep model from python",
        "Question_body":"<p>I have run a few sweeps, and now I want to get the best models from any given sweeps. I follow the tutorial here: <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide\">https:\/\/docs.wandb.ai\/guides\/track\/public-api-guide<\/a> and run my code as following<\/p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nruns = api.sweep(f\"{team_name}\/{project_name}\/{sweep_id}\").runs\nrun = sorted(runs, key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=True)[0]\nrun.file(f\"{path}{run.name}.h5\").download(replace=True)\n<\/code><\/pre>\n<p>And I get a \u201cPermission denied, ask the project owner to grant you access\u201d error on the run.file().download(), even though I followed the tutorial. I tried this in two different settings, (1) in a team where I am the admin and (2) on my personal account (note that these are the \u201cteam_name\u201d I am using in the api.sweep).<\/p>\n<p>It does find my sweep and the runs, I can also see the validation accuracies of all runs, it just doesn\u2019t allow me to download the files.<\/p>\n<p>Furthermore, and this might be unrelated, whenever I try to inspect the run elements in my pycharm, the debugger crashes. This has never happened before, but it\u2019s consistent on my machine, crashing my debugger every time<\/p>",
        "Question_answer_count":6,
        "Question_comment_count":null,
        "Question_creation_time":1642470254498,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":221.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/downloading-best-sweep-model-from-python\/1781",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":4227,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-01-18T19:10:24.862Z",
                "cooked":"<p>Hey <a class=\"mention\" href=\"\/u\/tjobbertjob\">@tjobbertjob<\/a>,<\/p>\n<p>You should be able to access your artifact through <code>run.logged_artifacts()<\/code>. I\u2019ve written a small script for you (though you might have to edit it a little bit) to achieve this for you:<\/p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\n\nsweep = api.sweep(f'{entity}\/{project}\/{sweep_id}')\nruns = sweep.runs\n\nruns = sorted(runs, key = lambda run: run.summary.get('val_loss'))\nbest_run = runs[0]\n\nartifacts = best_run.logged_artifacts()\n\nbest_model = [artifact for artifact in artifacts if artifact.type == 'model'][0]\nbest_model.download()\n<\/code><\/pre>\n<p>Please let me know if this solves your issue.<\/p>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases Support<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-01-18T19:10:24.862Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":9,
                "readers_count":8,
                "score":6.8,
                "yours":false,
                "topic_id":1781,
                "topic_slug":"downloading-best-sweep-model-from-python",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4233,
                "name":"Tobias Christensen",
                "username":"tjobbertjob",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/f6c823\/{size}.png",
                "created_at":"2022-01-18T23:37:38.517Z",
                "cooked":"<p>The artifacts list is empty, I suspect this is because I never configured it to log or send any artifacts during my sweep? Sadly though, this answer doesn\u2019t fix the issue  due to that fact. Still have not figured out why I am getting an access error when trying to download from my own account.<\/p>\n<p>I also tried it on my Linux server (my PC is windows), to see if it was machine specific, but it wasn\u2019t. I get the exact same issue on the Linux server.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-01-18T23:40:21.819Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":9,
                "readers_count":8,
                "score":6.8,
                "yours":false,
                "topic_id":1781,
                "topic_slug":"downloading-best-sweep-model-from-python",
                "display_username":"Tobias Christensen",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":2,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"ramit_goolry",
                    "name":"Ramit Goolry",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":994,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4266,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-01-20T21:09:07.372Z",
                "cooked":"<p>I see. In that case, could you check if you are able to access the name of the file you want to download through <code>run.file<\/code>?<\/p>\n<p>It would also help if you could send over the full stack trace you received and the link of the project you are trying to download the file for.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-01-20T21:09:07.372Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":1781,
                "topic_slug":"downloading-best-sweep-model-from-python",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"tjobbertjob",
                    "name":"Tobias Christensen",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/f6c823\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4304,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-01-24T23:15:58.806Z",
                "cooked":"<p>Hi Tobias,<\/p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.<\/p>\n<p>Best,<br>\nWeights &amp; Biases<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2022-01-24T23:15:58.806Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":1781,
                "topic_slug":"downloading-best-sweep-model-from-python",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4333,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-01-28T00:27:14.847Z",
                "cooked":"<p>Hi Tobias, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!<\/p>",
                "post_number":6,
                "post_type":1,
                "updated_at":"2022-01-28T00:27:14.847Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":1781,
                "topic_slug":"downloading-best-sweep-model-from-python",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5002,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-03-21T21:09:34.339Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":7,
                "post_type":3,
                "updated_at":"2022-03-21T21:09:34.339Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":0.8,
                "yours":false,
                "topic_id":1781,
                "topic_slug":"downloading-best-sweep-model-from-python",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: downloading best sweep model from python; content:<p>i have run a few sweeps, and now i want to get the best models from any given sweeps. i follow the tutorial here: <a href=\"https:\/\/docs..ai\/guides\/track\/public-api-guide\">https:\/\/docs..ai\/guides\/track\/public-api-guide<\/a> and run my code as following<\/p>\n<pre><code class=\"lang-auto\">import \napi = .api()\nruns = api.sweep(f\"{team_name}\/{project_name}\/{sweep_id}\").runs\nrun = sorted(runs, key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=true)[0]\nrun.file(f\"{path}{run.name}.h5\").download(replace=true)\n<\/code><\/pre>\n<p>and i get a \u201cpermission denied, ask the project owner to grant you access\u201d error on the run.file().download(), even though i followed the tutorial. i tried this in two different settings, (1) in a team where i am the admin and (2) on my personal account (note that these are the \u201cteam_name\u201d i am using in the api.sweep).<\/p>\n<p>it does find my sweep and the runs, i can also see the validation accuracies of all runs, it just doesn\u2019t allow me to download the files.<\/p>\n<p>furthermore, and this might be unrelated, whenever i try to inspect the run elements in my pycharm, the debugger crashes. this has never happened before, but it\u2019s consistent on my machine, crashing my debugger every time<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty downloading the best model from a sweep using the tutorial provided, and is also experiencing a debugger crash when trying to inspect the run elements."
    },
    {
        "Question_id":70753881.0,
        "Question_title":"Moving from notebook to pipeline replicating the generic datascience kernel from notebook",
        "Question_body":"<p>What would I need to do to replicate the data science kernel as an amazon image. I'm confused as it <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/amazon-sagemaker-notebook-instance-now-supports-amazon-linux-2\/#:%7E:text=SageMaker%20notebook%20instances%20use%20AMIs,AMI%20(Amazon%20Linux%202).\" rel=\"nofollow noreferrer\">says<\/a> the base image for notebook is a deep learning container but I don't think that will have all the packages installed on the deep learning kernel. Is there an easy way to replicate this environment or work out what it is? It's really difficult to work out what versions of what packages to install to make it work.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1642501076870,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":24.0,
        "Owner_creation_time":1521128898623,
        "Owner_last_access_time":1649152522772,
        "Owner_reputation":91.0,
        "Owner_up_votes":2.0,
        "Owner_down_votes":0.0,
        "Owner_views":8.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70753881",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: moving from notebook to pipeline replicating the generic datascience kernel from notebook; content:<p>what would i need to do to replicate the data science kernel as an amazon image. i'm confused as it <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/amazon--notebook-instance-now-supports-amazon-linux-2\/#:%7e:text=%20notebook%20instances%20use%20amis,ami%20(amazon%20linux%202).\" rel=\"nofollow noreferrer\">says<\/a> the base image for notebook is a deep learning container but i don't think that will have all the packages installed on the deep learning kernel. is there an easy way to replicate this environment or work out what it is? it's really difficult to work out what versions of what packages to install to make it work.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to replicate the data science kernel as an Amazon image, and is confused as the base image for notebook is a deep learning container. They need to work out what versions of what packages to install to make it work."
    },
    {
        "Question_id":null,
        "Question_title":"Azure Machine Learning Studio does not connect to Azure Table Storage",
        "Question_body":"Hi Team,\n\nI am trying to create a DataStore in Azure Machine learning to read data from Azure Table Storage.\n\nThere is no option available, Is it really possible to make this connection?",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1650452975323,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-table-storage"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/819266\/azure-machine-learning-studio-does-not-connect-to.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-20T16:13:13.037Z",
                "Answer_score":0,
                "Answer_body":"according to documentation not all Azure data storage services can be used with Azure Machine Learning: Supported data storage service types. Azure table storage is not listed there.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-25T06:54:20.147Z",
                "Answer_score":0,
                "Answer_body":"Hello @KausthubNp\n\nTo add sadomovalex's answer, Azure Machine Learning supports accessing data from Azure Blob storage, Azure Files, Azure Data Lake Storage Gen1, Azure Data Lake Storage Gen2, Azure SQL Database, and Azure Database for PostgreSQL. If you're using unsupported storage, we recommend that you move your data to supported Azure storage solutions by using Azure Data Factory and these steps. Moving data to supported storage can help you save data egress costs during machine learning experiments.\n\nAzure Data Factory provides efficient and resilient data transfer with more than 80 prebuilt connectors at no additional cost. These connectors include Azure data services, on-premises data sources, Amazon S3 and Redshift, and Google BigQuery.\n\nI hope our answers are helpful, please let us know if you have any concern.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  studio does not connect to azure table storage; content:hi team,\n\ni am trying to create a datastore in  to read data from azure table storage.\n\nthere is no option available, is it really possible to make this connection?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to create a datastore to read data from Azure Table Storage, but is unable to find the option to do so and is wondering if it is possible."
    },
    {
        "Question_id":67843602.0,
        "Question_title":"Could not find model PipelineModel",
        "Question_body":"<p>When I try to build models to create a pipeline as follows,<\/p>\n<pre><code>    &lt;code for the preprocessor&gt;\n    preprocessor = sklearn_preprocessor.create_model() #successful\n\n    &lt;code for the estimator&gt;\n    xgb_model_step = xgb_model.create_model() #successful    \n    \n    sm_model = PipelineModel(name='model', role=role, models=[preprocessor, xgb_model_step]) #successful\n    sm_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', endpoint_name=end) &lt;--- failure!\n<\/code><\/pre>\n<p>The models are created successfully. In the deploy line I get an error as,<\/p>\n<p><code>ClientError: An error occurred (ValidationException) when calling the CreateModel operation: Could not find model data at s3:\/\/sagemaker-us-east-1-1356784978535\/sagemaker-scikit-learn-2021-06-04-20-07-55-519\/output\/model.tar.gz.<\/code><\/p>\n<p>I am not sure how I can specify the path and make the deploy successful. Can somebody please help me with this?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1622838635930,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-web-services",
            "scikit-learn",
            "amazon-sagemaker"
        ],
        "Question_view_count":77.0,
        "Owner_creation_time":1473401410976,
        "Owner_last_access_time":1646051838716,
        "Owner_reputation":129.0,
        "Owner_up_votes":8.0,
        "Owner_down_votes":0.0,
        "Owner_views":41.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67843602",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: could not find model pipelinemodel; content:<p>when i try to build models to create a pipeline as follows,<\/p>\n<pre><code>    &lt;code for the preprocessor&gt;\n    preprocessor = sklearn_preprocessor.create_model() #successful\n\n    &lt;code for the estimator&gt;\n    xgb_model_step = xgb_model.create_model() #successful    \n    \n    sm_model = pipelinemodel(name='model', role=role, models=[preprocessor, xgb_model_step]) #successful\n    sm_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', endpoint_name=end) &lt;--- failure!\n<\/code><\/pre>\n<p>the models are created successfully. in the deploy line i get an error as,<\/p>\n<p><code>clienterror: an error occurred (validationexception) when calling the createmodel operation: could not find model data at s3:\/\/-us-east-1-1356784978535\/-scikit-learn-2021-06-04-20-07-55-519\/output\/model.tar.gz.<\/code><\/p>\n<p>i am not sure how i can specify the path and make the deploy successful. can somebody please help me with this?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty deploying their models after successfully creating them, receiving an error that the model data cannot be found at a specified path."
    },
    {
        "Question_id":71896741.0,
        "Question_title":"Adding label in AutoML for text classification",
        "Question_body":"<p>I am trying to create a text dataset in a <code>Pipeline<\/code> for a text classification but I believe I am doing it the wrong way or at least I don't get it. The csv passing only contains two columns <code>message<\/code> and <code>label<\/code> which is true or false.<\/p>\n<p>Inside my pipeline I am creating dataset like this which I am not very sure how dataset is recognizing that column <code>label<\/code> is the independent variable.<\/p>\n<pre><code>dataset = gcp_aip.TextDatasetCreateOp(\n    project = project # my project id,\n    display_name = display_name # reference name,\n    gcs_source  = src_uris # path to my data in gcs,\n    import_schema_uri = aiplatform.schema.dataset.ioformat.text.single_label_classification, \n)\n<\/code><\/pre>\n<p>once created the dataset, i do training like this within the <code>Pipeline<\/code><\/p>\n<pre><code># training\nmodel = gcp_aip.AutoMLTextTrainingJobRunOp(\n    project = project,\n    display_name = display_name,\n    prediction_type = &quot;classification&quot;,\n    multi_label = False,   \n    dataset = dataset.outputs[&quot;dataset&quot;],\n)\n<\/code><\/pre>\n<p>Not sure if creation and training is doing correctly since I never specified that <code>label<\/code> is my label column and needs to use <code>message<\/code> as a feature.<\/p>\n<p>In vertex ai the dataset created look like this<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3Puts.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3Puts.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>But in my training section the results from the AutML, looks like this, dont know why, label with 0% is there, which makes me doubt about the insertion of the data<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/LdSHj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LdSHj.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1650136092427,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "google-cloud-platform",
            "text",
            "vertex",
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":158.0,
        "Owner_creation_time":1505748144072,
        "Owner_last_access_time":1663921056407,
        "Owner_reputation":1102.0,
        "Owner_up_votes":108.0,
        "Owner_down_votes":1.0,
        "Owner_views":140.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1650356093116,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71896741",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: adding label in automl for text classification; content:<p>i am trying to create a text dataset in a <code>pipeline<\/code> for a text classification but i believe i am doing it the wrong way or at least i don't get it. the csv passing only contains two columns <code>message<\/code> and <code>label<\/code> which is true or false.<\/p>\n<p>inside my pipeline i am creating dataset like this which i am not very sure how dataset is recognizing that column <code>label<\/code> is the independent variable.<\/p>\n<pre><code>dataset = gcp_aip.textdatasetcreateop(\n    project = project # my project id,\n    display_name = display_name # reference name,\n    gcs_source  = src_uris # path to my data in gcs,\n    import_schema_uri = aiplatform.schema.dataset.ioformat.text.single_label_classification, \n)\n<\/code><\/pre>\n<p>once created the dataset, i do training like this within the <code>pipeline<\/code><\/p>\n<pre><code># training\nmodel = gcp_aip.automltexttrainingjobrunop(\n    project = project,\n    display_name = display_name,\n    prediction_type = &quot;classification&quot;,\n    multi_label = false,   \n    dataset = dataset.outputs[&quot;dataset&quot;],\n)\n<\/code><\/pre>\n<p>not sure if creation and training is doing correctly since i never specified that <code>label<\/code> is my label column and needs to use <code>message<\/code> as a feature.<\/p>\n<p>in  the dataset created look like this<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3puts.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3puts.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>but in my training section the results from the autml, looks like this, dont know why, label with 0% is there, which makes me doubt about the insertion of the data<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ldshj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ldshj.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to create a text dataset in a pipeline for a text classification, but is unsure how to specify that the label column is the independent variable. The dataset created looks correct, but the results from the AutoML training section show a label with 0%, which is causing doubt."
    },
    {
        "Question_id":69693666.0,
        "Question_title":"How to Deploy ML Recommender System on AWS",
        "Question_body":"<p>I'm dabbling with ML and was able to take a tutorial and get it to work for my needs.  It's a simple recommender system using TfidfVectorizer and linear_kernel.  I run into a problem with how I go about deploying it through Sagemaker with an end point.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel \nimport json\nimport csv\n\nwith open('data\/big_data.json') as json_file:\n    data = json.load(json_file)\n\nds = pd.DataFrame(data)\n\ntf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\ntfidf_matrix = tf.fit_transform(ds['content'])\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n\nresults = {}\n\nfor idx, row in ds.iterrows():\n    similar_indices = cosine_similarities[idx].argsort()[:-100:-1]\n    similar_items = [(cosine_similarities[idx][i], ds['id'][i]) for i in similar_indices]\n\n    results[row['id']] = similar_items[1:]\n\ndef item(id):\n    return ds.loc[ds['id'] == id]['id'].tolist()[0]\n\ndef recommend(item_id, num):\n    print(&quot;Recommending &quot; + str(num) + &quot; products similar to &quot; + item(item_id) + &quot;...&quot;)\n    print(&quot;-------&quot;)\n    recs = results[item_id][:num]\n    for rec in recs:\n        print(&quot;Recommended: &quot; + item(rec[1]) + &quot; (score:&quot; + str(rec[0]) + &quot;)&quot;)\n\nrecommend(item_id='129035', num=5)\n<\/code><\/pre>\n<p>As a starting point I'm not sure if the output from <code>tf.fit_transform(ds['content'])<\/code> is considered the model or the output from <code>linear_kernel(tfidf_matrix, tfidf_matrix)<\/code>.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1635046349497,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "machine-learning",
            "amazon-sagemaker",
            "tfidfvectorizer"
        ],
        "Question_view_count":63.0,
        "Owner_creation_time":1635045129020,
        "Owner_last_access_time":1650386337656,
        "Owner_reputation":53.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":11.0,
        "Answer_body":"<p>I came to the conclusion that I didn't need to deploy this through SageMaker.  Since the final linear_kernel output was a Dictionary I could do quick ID lookups to find correlations.<\/p>\n<p>I have it working on AWS with API Gateway\/Lambda, DynamoDB and an EC2 server to collect, process and plug the data into DynamoDB for fast lookups.  No expensive SageMaker endpoint needed.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1636075476147,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1635173315200,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69693666",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to deploy ml recommender system on aws; content:<p>i'm dabbling with ml and was able to take a tutorial and get it to work for my needs.  it's a simple recommender system using tfidfvectorizer and linear_kernel.  i run into a problem with how i go about deploying it through  with an end point.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nfrom sklearn.feature_extraction.text import tfidfvectorizer\nfrom sklearn.metrics.pairwise import linear_kernel \nimport json\nimport csv\n\nwith open('data\/big_data.json') as json_file:\n    data = json.load(json_file)\n\nds = pd.dataframe(data)\n\ntf = tfidfvectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\ntfidf_matrix = tf.fit_transform(ds['content'])\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n\nresults = {}\n\nfor idx, row in ds.iterrows():\n    similar_indices = cosine_similarities[idx].argsort()[:-100:-1]\n    similar_items = [(cosine_similarities[idx][i], ds['id'][i]) for i in similar_indices]\n\n    results[row['id']] = similar_items[1:]\n\ndef item(id):\n    return ds.loc[ds['id'] == id]['id'].tolist()[0]\n\ndef recommend(item_id, num):\n    print(&quot;recommending &quot; + str(num) + &quot; products similar to &quot; + item(item_id) + &quot;...&quot;)\n    print(&quot;-------&quot;)\n    recs = results[item_id][:num]\n    for rec in recs:\n        print(&quot;recommended: &quot; + item(rec[1]) + &quot; (score:&quot; + str(rec[0]) + &quot;)&quot;)\n\nrecommend(item_id='129035', num=5)\n<\/code><\/pre>\n<p>as a starting point i'm not sure if the output from <code>tf.fit_transform(ds['content'])<\/code> is considered the model or the output from <code>linear_kernel(tfidf_matrix, tfidf_matrix)<\/code>.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to deploy a ML recommender system on AWS, but is unsure if the output from tf.fit_transform(ds['content']) or linear_kernel(tfidf_matrix, tfidf_matrix) is considered the model."
    },
    {
        "Question_id":null,
        "Question_title":"I dont understand why my wandb_metadata.json file is showing this",
        "Question_body":"<p>Hello, i am pretty new to this wandb function. I have been trying to run a program with it, but it shows an error of like this:<br>\nTraceback (most recent call last):<br>\nFile \u201cmain.py\u201d, line 105, in <br>\nmain()<br>\nFile \u201cmain.py\u201d, line 99, in main<br>\ntrainer.train(start_iteration=epoch)<br>\nFile \u201c\/home\/cs2212\/Desktop\/voxel2mesh-master\/train.py\u201d, line 58, in train<br>\nloss = self.training_step(data, start_iteration)<br>\nFile \u201c\/home\/cs2212\/Desktop\/voxel2mesh-master\/train.py\u201d, line 22, in training_step<br>\nloss, log = self.net.loss(data, epoch)<br>\nFile \u201c\/home\/cs2212\/Desktop\/voxel2mesh-master\/model\/voxel2mesh.py\u201d, line 214, in loss<br>\npred_points = sample_points_from_meshes(pred_mesh, 3000)<br>\nFile \u201c\/home\/cs2212\/.local\/lib\/python3.8\/site-packages\/pytorch3d\/ops\/sample_points_from_meshes.py\u201d, line 55, in sample_points_from_meshes<br>\nareas, _ = mesh_face_areas_normals(<br>\nFile \u201c\/home\/cs2212\/.local\/lib\/python3.8\/site-packages\/pytorch3d\/ops\/mesh_face_areas_normals.py\u201d, line 44, in forward<br>\nareas, normals = _C.face_areas_normals_forward(verts, faces)<br>\nRuntimeError: Not compiled with GPU support. (FaceAreasNormalsForward at \/root\/project\/pytorch3d\/csrc\/face_areas_normals\/face_areas_normals.h:51)<\/p>\n<p>The preprocessing data job was done fine, but as I try to run the program with the preprocessed data, the upper error happens<\/p>\n<p>I checked the metadata.json file and realized the cuda was set as null even though i checked the cuda was there with nvcc --version. I am guessing the wandb not realizing the cuda is there seems to be an issue. Are there any methods of how i could solve this? Any advice is appreciated Thank you<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_creation_time":1649363599905,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":115.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/i-dont-understand-why-my-wandb-metadata-json-file-is-showing-this\/2199",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":5141,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-04-07T21:26:49.968Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/harrykwon97\">@harrykwon97<\/a>,<\/p>\n<p>Looking at the traceback of this error, this issue does not seem to be originating from wandb. The wandb library does not communicate with CUDA directly, nor is CUDA nessecary for wandb to operate, so I would not expect it to break because of wandb.<\/p>\n<p>It seems like the error actually originates from PyTorch3D, which would make sense since it would need to communicate to CUDA directly. I would suggest checking compatibility of your CUDA version with PyTorch 3D as a first step.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-04-07T21:26:49.968Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":5.6,
                "yours":false,
                "topic_id":2199,
                "topic_slug":"i-dont-understand-why-my-wandb-metadata-json-file-is-showing-this",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5226,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-04-14T19:58:00.804Z",
                "cooked":"<p>\u200bHi <a class=\"mention\" href=\"\/u\/harrykwon97\">@harrykwon97<\/a>,<\/p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.<\/p>\n<p>Best,<\/p>\n<p>Weights &amp; Biases<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-04-14T19:58:00.804Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":5.4,
                "yours":false,
                "topic_id":2199,
                "topic_slug":"i-dont-understand-why-my-wandb-metadata-json-file-is-showing-this",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"ramit_goolry",
                    "name":"Ramit Goolry",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5280,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-04-19T19:27:44.968Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/harrykwon97\">@harrykwon97<\/a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!<\/p>\n<p>\u200b<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-04-19T19:27:44.968Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":2199,
                "topic_slug":"i-dont-understand-why-my-wandb-metadata-json-file-is-showing-this",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"ramit_goolry",
                    "name":"Ramit Goolry",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6217,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-06-18T19:28:07.692Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":5,
                "post_type":3,
                "updated_at":"2022-06-18T19:28:07.692Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2199,
                "topic_slug":"i-dont-understand-why-my-wandb-metadata-json-file-is-showing-this",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: i dont understand why my _metadata.json file is showing this; content:<p>hello, i am pretty new to this  function. i have been trying to run a program with it, but it shows an error of like this:<br>\ntraceback (most recent call last):<br>\nfile \u201cmain.py\u201d, line 105, in <br>\nmain()<br>\nfile \u201cmain.py\u201d, line 99, in main<br>\ntrainer.train(start_iteration=epoch)<br>\nfile \u201c\/home\/cs2212\/desktop\/voxel2mesh-master\/train.py\u201d, line 58, in train<br>\nloss = self.training_step(data, start_iteration)<br>\nfile \u201c\/home\/cs2212\/desktop\/voxel2mesh-master\/train.py\u201d, line 22, in training_step<br>\nloss, log = self.net.loss(data, epoch)<br>\nfile \u201c\/home\/cs2212\/desktop\/voxel2mesh-master\/model\/voxel2mesh.py\u201d, line 214, in loss<br>\npred_points = sample_points_from_meshes(pred_mesh, 3000)<br>\nfile \u201c\/home\/cs2212\/.local\/lib\/python3.8\/site-packages\/pytorch3d\/ops\/sample_points_from_meshes.py\u201d, line 55, in sample_points_from_meshes<br>\nareas, _ = mesh_face_areas_normals(<br>\nfile \u201c\/home\/cs2212\/.local\/lib\/python3.8\/site-packages\/pytorch3d\/ops\/mesh_face_areas_normals.py\u201d, line 44, in forward<br>\nareas, normals = _c.face_areas_normals_forward(verts, faces)<br>\nruntimeerror: not compiled with gpu support. (faceareasnormalsforward at \/root\/project\/pytorch3d\/csrc\/face_areas_normals\/face_areas_normals.h:51)<\/p>\n<p>the preprocessing data job was done fine, but as i try to run the program with the preprocessed data, the upper error happens<\/p>\n<p>i checked the metadata.json file and realized the cuda was set as null even though i checked the cuda was there with nvcc --version. i am guessing the  not realizing the cuda is there seems to be an issue. are there any methods of how i could solve this? any advice is appreciated thank you<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when running a program due to their _metadata.json file not recognizing the CUDA, and is looking for advice on how to solve this issue."
    },
    {
        "Question_id":null,
        "Question_title":"ML Studio endpoint problem after Aks\/VM Restart",
        "Question_body":"After restarting VM's associated to AKS created with to ML Studio deployed the ws endpoint gets unreachable.\n\nTry several time to restart but it doesn't work.\n\nAny idea? Any workaround besides re-create the cluster?",
        "Question_answer_count":0,
        "Question_comment_count":8.0,
        "Question_creation_time":1605582083440,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-kubernetes-service",
            "azure-machine-learning-studio-classic"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/165092\/ml-studio-endpoint-problem-after-aksvm-restart.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: ml studio endpoint problem after aks\/vm restart; content:after restarting vm's associated to aks created with to ml studio deployed the ws endpoint gets unreachable.\n\ntry several time to restart but it doesn't work.\n\nany idea? any workaround besides re-create the cluster?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having an issue with their ML Studio endpoint becoming unreachable after restarting the AKS\/VM, and is looking for ideas or workarounds to fix the issue without having to recreate the cluster."
    },
    {
        "Question_id":60656978.0,
        "Question_title":"Display tqdm in AWS Sagemaker's jupyterlab",
        "Question_body":"<p>Does anyone nows how can we have python tqdm progress bar working on a Sagemaker Jupyterlab Noteook ? The tqdm progress bar is never displayed, components are displayed as their code. <\/p>\n\n<p>Example :<\/p>\n\n<pre><code>HBox(children=(FloatProgress(value=0.0, max=5234.0), HTML(value='')))\n<\/code><\/pre>\n\n<p>I'm aware of the usual fix describe <a href=\"https:\/\/stackoverflow.com\/questions\/57343134\/jupyter-notebooks-not-displaying-progress-bars\">here<\/a>, but It does not work since trying to executing <code>jupyter lab build<\/code> will results in the issue describe <a href=\"https:\/\/github.com\/jupyter-widgets\/ipywidgets\/issues\/2061\" rel=\"noreferrer\">here<\/a> <\/p>\n\n<p>Many thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1584026114660,
        "Question_favorite_count":1.0,
        "Question_score":9.0,
        "Question_tags":[
            "amazon-sagemaker",
            "jupyter-lab"
        ],
        "Question_view_count":4085.0,
        "Owner_creation_time":1508516090812,
        "Owner_last_access_time":1663961818460,
        "Owner_reputation":121.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":10.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60656978",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: display tqdm in 's jupyterlab; content:<p>does anyone nows how can we have python tqdm progress bar working on a  jupyterlab noteook ? the tqdm progress bar is never displayed, components are displayed as their code. <\/p>\n\n<p>example :<\/p>\n\n<pre><code>hbox(children=(floatprogress(value=0.0, max=5234.0), html(value='')))\n<\/code><\/pre>\n\n<p>i'm aware of the usual fix describe <a href=\"https:\/\/stackoverflow.com\/questions\/57343134\/jupyter-notebooks-not-displaying-progress-bars\">here<\/a>, but it does not work since trying to executing <code>jupyter lab build<\/code> will results in the issue describe <a href=\"https:\/\/github.com\/jupyter-widgets\/ipywidgets\/issues\/2061\" rel=\"noreferrer\">here<\/a> <\/p>\n\n<p>many thanks.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to display a tqdm progress bar in a Jupyterlab notebook, but components are displayed as their code instead. They are aware of the usual fix, but it does not work due to an issue described in a GitHub link."
    },
    {
        "Question_id":61791589.0,
        "Question_title":"Sagemaker: MemoryError: Unable to allocate ___for an array with shape ___ and data type float64",
        "Question_body":"<p>I am running a notebook in sagemaker and it seems like one of the arrays produced after vectorizing text is causing issues.<\/p>\n\n<p>Reading other answers it seems like it is an issue with <a href=\"https:\/\/www.kernel.org\/doc\/Documentation\/vm\/overcommit-accounting\" rel=\"noreferrer\">overcommit<\/a>. And one of the solutions proposed is to set it to always overcommit with this:<\/p>\n\n<pre><code>$ echo 1 &gt; \/proc\/sys\/vm\/overcommit_memory\n<\/code><\/pre>\n\n<p>Is there any documentation or do you have any suggestion on how to do the same thing in sagemaker?<\/p>\n\n<p>Thank you very much.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1589441004223,
        "Question_favorite_count":1.0,
        "Question_score":8.0,
        "Question_tags":[
            "arrays",
            "python-3.x",
            "pandas",
            "memory",
            "amazon-sagemaker"
        ],
        "Question_view_count":2821.0,
        "Owner_creation_time":1517932507092,
        "Owner_last_access_time":1648741816032,
        "Owner_reputation":331.0,
        "Owner_up_votes":14.0,
        "Owner_down_votes":0.0,
        "Owner_views":73.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61791589",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: : memoryerror: unable to allocate ___for an array with shape ___ and data type float64; content:<p>i am running a notebook in  and it seems like one of the arrays produced after vectorizing text is causing issues.<\/p>\n\n<p>reading other answers it seems like it is an issue with <a href=\"https:\/\/www.kernel.org\/doc\/documentation\/vm\/overcommit-accounting\" rel=\"noreferrer\">overcommit<\/a>. and one of the solutions proposed is to set it to always overcommit with this:<\/p>\n\n<pre><code>$ echo 1 &gt; \/proc\/sys\/vm\/overcommit_memory\n<\/code><\/pre>\n\n<p>is there any documentation or do you have any suggestion on how to do the same thing in ?<\/p>\n\n<p>thank you very much.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is running a notebook in and is experiencing a MemoryError due to an array with shape and data type float64. They are looking for documentation or suggestions on how to set the overcommit memory in ."
    },
    {
        "Question_id":null,
        "Question_title":"DVC with external data is very slow",
        "Question_body":"<p>Hi there,<\/p>\n<p>I think my question has two parts: firstly, is the use of external data (as described <a href=\"https:\/\/dvc.org\/doc\/user-guide\/managing-external-data\" rel=\"noopener nofollow ugc\">here<\/a>) the best way in my case and, if so, why is it so slow to add files?<\/p>\n<p>The context: my ML code + git repo live on my local machine. I develop this codebase using pycharm,  and use pycharm\u2019s remote ssh deployment to run my code on a remote machine where the data lives. The dataset is a large imaging dataset, &gt;200GB with 1000s of files, and will not fit on my local machine. When I run my code, pycharm copies it to the remote machine to run it, but it does not copy the git files so there is no git repo on my remote machine.<\/p>\n<p>As my git repo and data live on different machines, it seemed like adding the external dataset to DVC using ssh would be a good way to go about things. However the dvc add command is taking a long time to run. In fact I tried to run it on a 6GB subset of my data and it errored out:<\/p>\n<p><code>ERROR: too many open files, please visit &lt;https:\/\/error.dvc.org\/many-files&gt; to see how to handle this problem<\/code><\/p>\n<p>So my questions are:<\/p>\n<ol>\n<li>Is this a sensible way to be using DVC?<\/li>\n<li>If so, how can I speed things up? It seems like everything is getting downloaded to my local machine, even though I have set up a remote cache over ssh. Is there any way I can get it to compute the hashes on the remote machine?<\/li>\n<\/ol>\n<p>Thanks for your help,<br>\nMark<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1647375655860,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":137.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-with-external-data-is-very-slow\/1121",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2523,
                "name":"",
                "username":"dberenbaum",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/5e9695\/{size}.png",
                "created_at":"2022-03-15T21:34:34.743Z",
                "cooked":"<p>Hi Mark,<\/p>\n<p>Using external data in DVC is usually for advanced scenarios where no other setup will work. In your case, it sounds like the main reason you need this is because the primary code lives on your local machine. Would it be possible for you to instead have the code on your remote machine and to use pycharm on your local machine as described in <a href=\"https:\/\/www.jetbrains.com\/help\/pycharm\/remote-development-starting-page.html\" class=\"inline-onebox\">Remote development | PyCharm<\/a>?<\/p>\n<p>Best,<br>\nDave<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-03-15T21:34:34.743Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":1.2,
                "yours":false,
                "topic_id":1121,
                "topic_slug":"dvc-with-external-data-is-very-slow",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/www.jetbrains.com\/help\/pycharm\/remote-development-starting-page.html",
                        "internal":false,
                        "reflection":false,
                        "title":"Remote development | PyCharm",
                        "clicks":1
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":228,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2526,
                "name":"",
                "username":"dtrifiro",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/278dde\/{size}.png",
                "created_at":"2022-03-17T10:21:23.649Z",
                "cooked":"<p>Hey Mark, what\u2019s the exact command you\u2019re using? How many cpu cores does the remote server have?<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-03-17T10:21:23.649Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":6.0,
                "yours":false,
                "topic_id":1121,
                "topic_slug":"dvc-with-external-data-is-very-slow",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":396,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2527,
                "name":"Mark",
                "username":"mark",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/e9c0ed\/{size}.png",
                "created_at":"2022-03-17T16:11:05.626Z",
                "cooked":"<p>Hi, the command was<\/p>\n<p><code>dvc add --external ssh:\/\/desktop\/path\/to\/data<\/code><\/p>\n<p>and my remote machine has 16 cores<\/p>\n<p><a class=\"mention\" href=\"\/u\/dberenbaum\">@dberenbaum<\/a>  Thanks very much for the suggestion - I wasn\u2019t aware I could do the remote deployment that way round. I\u2019ll give it a go.<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-03-17T16:11:05.626Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":1121,
                "topic_slug":"dvc-with-external-data-is-very-slow",
                "display_username":"Mark",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"dtrifiro",
                    "name":"",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/d\/278dde\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":420,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  with external data is very slow; content:<p>hi there,<\/p>\n<p>i think my question has two parts: firstly, is the use of external data (as described <a href=\"https:\/\/.org\/doc\/user-guide\/managing-external-data\" rel=\"noopener nofollow ugc\">here<\/a>) the best way in my case and, if so, why is it so slow to add files?<\/p>\n<p>the context: my ml code + git repo live on my local machine. i develop this codebase using pycharm,  and use pycharm\u2019s remote ssh deployment to run my code on a remote machine where the data lives. the dataset is a large imaging dataset, &gt;200gb with 1000s of files, and will not fit on my local machine. when i run my code, pycharm copies it to the remote machine to run it, but it does not copy the git files so there is no git repo on my remote machine.<\/p>\n<p>as my git repo and data live on different machines, it seemed like adding the external dataset to  using ssh would be a good way to go about things. however the  add command is taking a long time to run. in fact i tried to run it on a 6gb subset of my data and it errored out:<\/p>\n<p><code>error: too many open files, please visit &lt;https:\/\/error..org\/many-files&gt; to see how to handle this problem<\/code><\/p>\n<p>so my questions are:<\/p>\n<ol>\n<li>is this a sensible way to be using ?<\/li>\n<li>if so, how can i speed things up? it seems like everything is getting downloaded to my local machine, even though i have set up a remote cache over ssh. is there any way i can get it to compute the hashes on the remote machine?<\/li>\n<\/ol>\n<p>thanks for your help,<br>\nmark<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if using external data is the best way to go about their project, and if so, why it is so slow to add files."
    },
    {
        "Question_id":52437543.0,
        "Question_title":"Does sagemaker use nvidia-docker or docker runtime==nvidia by default or user need to manually set up?",
        "Question_body":"<p>As stated in the question, \"Does sagemaker use nvidia-docker or docker runtime==nvidia by default or user need to manually set up?\"<\/p>\n\n<p>Some common error message showed as \"CannotStartContainerError. Please ensure the model container for variant variant-name-1 starts correctly when invoked with 'docker run  serve\u2019.\" and it didn't show as running with nividia driver.<\/p>\n\n<p>So, do we need manually set up?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1537509940017,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "docker",
            "nvidia-docker",
            "amazon-sagemaker"
        ],
        "Question_view_count":940.0,
        "Owner_creation_time":1537311568807,
        "Owner_last_access_time":1612898933127,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52437543",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: does  use nvidia-docker or docker runtime==nvidia by default or user need to manually set up?; content:<p>as stated in the question, \"does  use nvidia-docker or docker runtime==nvidia by default or user need to manually set up?\"<\/p>\n\n<p>some common error message showed as \"cannotstartcontainererror. please ensure the model container for variant variant-name-1 starts correctly when invoked with 'docker run  serve\u2019.\" and it didn't show as running with nividia driver.<\/p>\n\n<p>so, do we need manually set up?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to manually set up nvidia-docker or docker runtime==nvidia in order to avoid common error messages when running the model container."
    },
    {
        "Question_id":null,
        "Question_title":"Save multiindex dataframes",
        "Question_body":"<p>Is it possible to log a multiindex pandas dataframe?<\/p>\n<p>In addition, is it possible to save a pandas dataframe with the names of the rows? Even though my dataframe has names in the rows, in the UI I see a linear index.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1660296123520,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":86.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/save-multiindex-dataframes\/2913",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":6906,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-08-16T00:16:40.732Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/george-ai2c\">@george-ai2c<\/a>,<\/p>\n<p>Unfortuately not at the moment. Tables, as they are implemented right now only support sequential integer indexes.<\/p>\n<p>We have plans to implement more complex indexing in the future, such as objects as indices and multi-indices, but these features are not available right now.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-08-16T00:16:40.732Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2913,
                "topic_slug":"save-multiindex-dataframes",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7742,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-10-15T00:17:40.327Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":3,
                "post_type":3,
                "updated_at":"2022-10-15T00:17:40.327Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2913,
                "topic_slug":"save-multiindex-dataframes",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: save multiindex dataframes; content:<p>is it possible to log a multiindex pandas dataframe?<\/p>\n<p>in addition, is it possible to save a pandas dataframe with the names of the rows? even though my dataframe has names in the rows, in the ui i see a linear index.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to log and save a multiindex pandas dataframe, and if it is possible to save the names of the rows even though they appear as a linear index in the UI."
    },
    {
        "Question_id":54184145.0,
        "Question_title":"AWS Sagemaker does not update the package",
        "Question_body":"<p>AWS Sagemaker's notebook comes with Scikit-Learn version 0.19.1<\/p>\n\n<p>I would like to use version 0.20.2. To avoid updating it every time in the notebook code, I tried using the lifecycle configurations. I created one with the following code :<\/p>\n\n<pre><code>#!\/bin\/bash\nset -e\n\/home\/ec2-user\/anaconda3\/bin\/conda install scikit-learn -y\n<\/code><\/pre>\n\n<p>When I run the attached notebook instance and go to the terminal, the version of scikit-learn found with <code>conda list<\/code> is correct (0.20.2). But when I run a notebook and import sklearn, the version is still 0.19.2.<\/p>\n\n<pre><code>import sklearn\nprint(sklearn.__version__)\n<\/code><\/pre>\n\n<p>Is there any virtual environment on the SageMaker instances where I should install the package ? How can I fix my notebook lifecycle configuration ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1547478776530,
        "Question_favorite_count":null,
        "Question_score":5.0,
        "Question_tags":[
            "python",
            "conda",
            "amazon-sagemaker"
        ],
        "Question_view_count":1546.0,
        "Owner_creation_time":1527781503483,
        "Owner_last_access_time":1625555943023,
        "Owner_reputation":352.0,
        "Owner_up_votes":81.0,
        "Owner_down_votes":0.0,
        "Owner_views":23.0,
        "Answer_body":"<p>Your conda update does not refer to a specific virtualenv, while your notebook probably does. Therefore you dont see an update on the notebook virtualenv.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1547708377156,
        "Answer_score":2.0,
        "Owner_location":"Metz, France",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54184145",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  does not update the package; content:<p>'s notebook comes with scikit-learn version 0.19.1<\/p>\n\n<p>i would like to use version 0.20.2. to avoid updating it every time in the notebook code, i tried using the lifecycle configurations. i created one with the following code :<\/p>\n\n<pre><code>#!\/bin\/bash\nset -e\n\/home\/ec2-user\/anaconda3\/bin\/conda install scikit-learn -y\n<\/code><\/pre>\n\n<p>when i run the attached notebook instance and go to the terminal, the version of scikit-learn found with <code>conda list<\/code> is correct (0.20.2). but when i run a notebook and import sklearn, the version is still 0.19.2.<\/p>\n\n<pre><code>import sklearn\nprint(sklearn.__version__)\n<\/code><\/pre>\n\n<p>is there any virtual environment on the  instances where i should install the package ? how can i fix my notebook lifecycle configuration ?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty updating the version of scikit-learn in their notebook instance, despite having created a lifecycle configuration to do so. They are wondering if there is a virtual environment they need to install the package in, and how to fix their lifecycle configuration."
    },
    {
        "Question_id":57917437.0,
        "Question_title":"How to train for multi-label text classification in Sagemaker?",
        "Question_body":"<p>I have chosen BlazingText algorithm provided by Sagemaker.<\/p>\n\n<p>Text in my training set can have one or more labels, and I want to predict the most likely labels for an article.<\/p>\n\n<p>I didn't find how to exactly setup the training file for this. I have made the lines in the training file in the following format <\/p>\n\n<p><code>__label__1 __label__2 token1 token2 ...\n__label__2 token token token ...<\/code><\/p>\n\n<p>Am i doing it right it right?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_creation_time":1568350166147,
        "Question_favorite_count":1.0,
        "Question_score":2.0,
        "Question_tags":[
            "text-classification",
            "amazon-sagemaker",
            "multilabel-classification"
        ],
        "Question_view_count":1659.0,
        "Owner_creation_time":1492176191900,
        "Owner_last_access_time":1642675490136,
        "Owner_reputation":701.0,
        "Owner_up_votes":87.0,
        "Owner_down_votes":3.0,
        "Owner_views":116.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Lalitpur Sub-Metropolitan City, Central Development Region, Nepal",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57917437",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to train for multi-label text classification in ?; content:<p>i have chosen blazingtext algorithm provided by .<\/p>\n\n<p>text in my training set can have one or more labels, and i want to predict the most likely labels for an article.<\/p>\n\n<p>i didn't find how to exactly setup the training file for this. i have made the lines in the training file in the following format <\/p>\n\n<p><code>__label__1 __label__2 token1 token2 ...\n__label__2 token token token ...<\/code><\/p>\n\n<p>am i doing it right it right?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to train a multi-label text classification model using the BlazingText algorithm provided by Amazon SageMaker and wants to know if they are setting up the training file correctly in the format of \"__label__1 __label__2 token1 token2...\"."
    },
    {
        "Question_id":52705769.0,
        "Question_title":"Azure ML Tune Model Hyper Parameters",
        "Question_body":"<p>Here's question proposed at the end of the chapter in 70-774 exam reference book. <\/p>\n\n<blockquote>\n  <p>If you connect a neural network with a Tune Model Hyperparameters module configured\n  with Random Sweep and Maximum number of runs on random sweep = 1, how\n  many neural networks are trained during the execution of the experiment? Why? If you\n  connect a validation dataset to the third input of the Tune Model Hyperparameters\n  module, how many neural networks are trained now?<\/p>\n<\/blockquote>\n\n<p>And the answer is :<\/p>\n\n<blockquote>\n  <p>Without validation dataset 11 (10 of k-fold cross validation + 1 trained with all the data\n  with the best combination of hyperparameters). With the validation set only 1 neural\n  network is trained, so the best model is not trained using the validation set if you provide\n  it.<\/p>\n<\/blockquote>\n\n<p>Where does 10 come from? As far as I understand the number should be 2 and 1 respectively. Shouldn't it create n-folds where n is equal to the number of runs?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1539013176610,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "machine-learning",
            "neural-network",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":329.0,
        "Owner_creation_time":1528790837107,
        "Owner_last_access_time":1660146049396,
        "Owner_reputation":610.0,
        "Owner_up_votes":143.0,
        "Owner_down_votes":0.0,
        "Owner_views":203.0,
        "Answer_body":"<p>When you use the Tune Model Hyperparameters module without a validation dataset, this means, when you use only the 2nd input data port, the module works in cross-validation mode. So the best-parameters model is found by doing cross-validation over the provided dataset, and to do this, the dataset is splitted in k-folds. By default, the module splits the data in 10 folds. In case you want to split the data in a different number of folds, you can connect a Partition and Sample module at the 2nd input, selecting Assign to Folds and indicating the number of folds desired. In many cases k=5 is a reasonable option.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1539202336323,
        "Answer_score":3.0,
        "Owner_location":"Paris, France",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52705769",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  tune model hyper parameters; content:<p>here's question proposed at the end of the chapter in 70-774 exam reference book. <\/p>\n\n<blockquote>\n  <p>if you connect a neural network with a tune model hyperparameters module configured\n  with random sweep and maximum number of runs on random sweep = 1, how\n  many neural networks are trained during the execution of the experiment? why? if you\n  connect a validation dataset to the third input of the tune model hyperparameters\n  module, how many neural networks are trained now?<\/p>\n<\/blockquote>\n\n<p>and the answer is :<\/p>\n\n<blockquote>\n  <p>without validation dataset 11 (10 of k-fold cross validation + 1 trained with all the data\n  with the best combination of hyperparameters). with the validation set only 1 neural\n  network is trained, so the best model is not trained using the validation set if you provide\n  it.<\/p>\n<\/blockquote>\n\n<p>where does 10 come from? as far as i understand the number should be 2 and 1 respectively. shouldn't it create n-folds where n is equal to the number of runs?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user's question is regarding the number of neural networks trained when using a Tune Model Hyperparameters module with a random sweep and a validation dataset. The answer is that without the validation dataset, 11 neural networks are trained (10 of k-fold cross validation + 1 trained with all the data with the best combination of hyperparameters). With the validation set, only 1 neural network is trained."
    },
    {
        "Question_id":null,
        "Question_title":"Can't test real-time endpoint",
        "Question_body":"Hello,\n\nThe text box where I am meant to enter the input to test my endpoint doesn't let me enter anything. The deployment state is currently healthy.\n\n\nI can test the webservice directly without any issues. I also have the same issue with multiple browsers!",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1642850859443,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/705771\/can39t-test-real-time-endpoint.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-27T09:52:19.137Z",
                "Answer_score":1,
                "Answer_body":"@romungi-MSFT thanks for the advice! I didn't actually have a chance to report the issue, but the endpoint seems to be working fine now. I will report if it starts happening again",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: can't test real-time endpoint; content:hello,\n\nthe text box where i am meant to enter the input to test my endpoint doesn't let me enter anything. the deployment state is currently healthy.\n\n\ni can test the webservice directly without any issues. i also have the same issue with multiple browsers!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to enter anything into the text box to test their real-time endpoint, despite the deployment state being healthy, and the issue persists across multiple browsers."
    },
    {
        "Question_id":null,
        "Question_title":"xgboost sagemaker batch transform job output in multiple lines",
        "Question_body":"Hello,\n\nI've just trained a churn prediction model with XGBoost algorithm, based on the SageMaker example notebooks. I've created SageMaker batch transformation jobs using this model using input from CSV file with multiple records, however the output file is a single record CSV containing all the inferences in a single comma separated row. The result is that I'm not able to use the \"Join source\" feature with \"Input - Merge input data with job output\" since the input and output files must match the number of records. I've tried with different batch job configurations but I always get the same single line output file.\n\nDo you know if is there any configuration that allows me to merge input and output in order to have a direct association between an input column with its inference result? Is this a restriction from the XGBoost algorithm built-in implementation?",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1599771185000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker"
        ],
        "Question_view_count":199.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUYz7Bz_5sTmG0uBaqlt7J_g\/xgboost-sagemaker-batch-transform-job-output-in-multiple-lines",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-11T02:38:30.000Z",
                "Answer_score":0,
                "Answer_body":"Sounds like a configuration issue, this algorithm should be able to output proper output CSVs.\n\nAre you using accept=\"text\/csv\" and assemble_with=\"Line\" on your Transformer? Is your strategy set to SingleRecord or MultiRecord?\n\nAnd split_type=\"Line\", content_type=\"text\/csv\" on the .transform() call?\n\nI have had custom algorithms accidentally output row vectors instead of column vectors for multi-record batches in the past (because they gave a 1D output which the default serializer interpreted as a row), but not built-in algorithms.\n\nDropping to SingleRecord could be a last resort (forcing Batch Transform itself to handle the serialization), but would decrease efficiency\/speed.",
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: xgboost  batch transform job output in multiple lines; content:hello,\n\ni've just trained a churn prediction model with xgboost algorithm, based on the  example notebooks. i've created  batch transformation jobs using this model using input from csv file with multiple records, however the output file is a single record csv containing all the inferences in a single comma separated row. the result is that i'm not able to use the \"join source\" feature with \"input - merge input data with job output\" since the input and output files must match the number of records. i've tried with different batch job configurations but i always get the same single line output file.\n\ndo you know if is there any configuration that allows me to merge input and output in order to have a direct association between an input column with its inference result? is this a restriction from the xgboost algorithm built-in implementation?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to use the \"join source\" feature to merge input and output data, but is having difficulty due to the output file containing all inferences in a single comma separated row."
    },
    {
        "Question_id":null,
        "Question_title":"DVC in a directory that is already git-controlled",
        "Question_body":"<p>I want to init dvc in a directory that is already under git.<\/p>\n<p>More precisely, I already have a git-controlled directory that contains all my pycharm projects, and want to initialize dvc in its subdirectory for a specific project.<\/p>\n<p>Am I going to run into trouble later?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1566477305073,
        "Question_favorite_count":null,
        "Question_score":5.0,
        "Question_tags":null,
        "Question_view_count":465.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-in-a-directory-that-is-already-git-controlled\/208",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":452,
                "name":"Dashamir Hoxha",
                "username":"dashohoxha",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/dashohoxha\/{size}\/45_2.png",
                "created_at":"2019-08-22T13:49:46.682Z",
                "cooked":"<p>Not at all. This is the normal way that DVC is supposed to work.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2019-08-22T13:49:46.682Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":9,
                "readers_count":8,
                "score":106.8,
                "yours":false,
                "topic_id":208,
                "topic_slug":"dvc-in-a-directory-that-is-already-git-controlled",
                "display_username":"Dashamir Hoxha",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":3
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":78,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":453,
                "name":"Ivan Shcheklein",
                "username":"shcheklein",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/shcheklein\/{size}\/173_2.png",
                "created_at":"2019-08-23T04:19:46.817Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/byoussin\">@byoussin<\/a>! Do you want to initialize it specifically for a subdirectory of the git-controlled project? I\u2019m not sure DVC can do that right now. Most likely if you run <code>dvc init<\/code> it will create <code>.dvc<\/code> in the root of the git-controlled directory.  <a class=\"mention\" href=\"\/u\/kupruser\">@kupruser<\/a> can give more details for this scenario.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2019-08-23T04:19:46.817Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":9,
                "readers_count":8,
                "score":61.8,
                "yours":false,
                "topic_id":208,
                "topic_slug":"dvc-in-a-directory-that-is-already-git-controlled",
                "display_username":"Ivan Shcheklein",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":2
                    }
                ],
                "moderator":false,
                "admin":true,
                "staff":true,
                "user_id":15,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  in a directory that is already git-controlled; content:<p>i want to init  in a directory that is already under git.<\/p>\n<p>more precisely, i already have a git-controlled directory that contains all my pycharm projects, and want to initialize  in its subdirectory for a specific project.<\/p>\n<p>am i going to run into trouble later?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to initialize Git in a directory that is already under Git control, and is wondering if they will run into trouble later."
    },
    {
        "Question_id":72011565.0,
        "Question_title":"Predictions into the future Azure Machine Learning Studio Designer",
        "Question_body":"<p>I am currently developing an automated mechanism where I use the Azure Machine Learning Designer (AMLD). During development i used an 80\/20 Split to test the efficency of my predictions.\nNow i want to go live but I've missed the point where i can actually predict into the future.<\/p>\n<p>I currently get a prediction for the last 20% of my data so i can compare them to the actual data. How do i change it so that the prediction actually starts at the end of my data?<\/p>\n<p>A part of my prediction process is attached:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eh7Rv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eh7Rv.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5.0,
        "Question_creation_time":1650965432403,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "prediction",
            "forecasting",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":39.0,
        "Owner_creation_time":1592226417127,
        "Owner_last_access_time":1663873257356,
        "Owner_reputation":13.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Germany",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72011565",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: predictions into the future  studio designer; content:<p>i am currently developing an automated mechanism where i use the  designer (amld). during development i used an 80\/20 split to test the efficency of my predictions.\nnow i want to go live but i've missed the point where i can actually predict into the future.<\/p>\n<p>i currently get a prediction for the last 20% of my data so i can compare them to the actual data. how do i change it so that the prediction actually starts at the end of my data?<\/p>\n<p>a part of my prediction process is attached:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eh7rv.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eh7rv.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to change their prediction process so that it can predict into the future, rather than just predicting the last 20% of their data. They have provided a part of their prediction process as an example."
    },
    {
        "Question_id":67051812.0,
        "Question_title":"SageMaker : Sckit-learn RandomForest : REST API Value ERROR",
        "Question_body":"<p>My Lambda Code is Below.<\/p>\n<pre><code>import os\nimport io\nimport boto3\nimport json\nimport csv\n\n# grab environment variables\nENDPOINT_NAME = os.environ['ENDPOINT_NAME']\nruntime= boto3.client('runtime.sagemaker')\n\ndef lambda_handler(event, context):\n    print(&quot;Received event: &quot; + json.dumps(event, indent=2))\n    \n    data = json.loads(json.dumps(event))\n    payload = data['data']\n    print(payload)\n    \n    wrapper = csv.reader(payload.strip().split('\\n'))\n    for record in wrapper:\n        print(record)\n   \n    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n                                       ContentType='text\/csv',\n                                       Body=wrapper)\n    print(response)\n    result = json.loads(response['Body'].read().decode())\n    \n    return result\n<\/code><\/pre>\n<p>My input value is<\/p>\n<pre><code>{\n  &quot;data&quot;: &quot;231, -43&quot;\n}\n<\/code><\/pre>\n<p>Error message is<\/p>\n<pre><code>Response\n{\n  &quot;errorMessage&quot;: &quot;Parameter validation failed:\\nInvalid type for parameter Body, value: &lt;_csv.reader object at 0x7f638af1a6d8&gt;, type: &lt;class '_csv.reader'&gt;, valid types: &lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object&quot;,\n  &quot;errorType&quot;: &quot;ParamValidationError&quot;,\n  &quot;stackTrace&quot;: [\n    [\n      &quot;\/var\/task\/lambda_function.py&quot;,\n      24,\n      &quot;lambda_handler&quot;,\n      &quot;Body=wrapper)&quot;\n    ],\n    [\n      &quot;\/var\/runtime\/botocore\/client.py&quot;,\n      357,\n      &quot;_api_call&quot;,\n      &quot;return self._make_api_call(operation_name, kwargs)&quot;\n    ],\n    [\n      &quot;\/var\/runtime\/botocore\/client.py&quot;,\n      649,\n      &quot;_make_api_call&quot;,\n      &quot;api_params, operation_model, context=request_context)&quot;\n    ],\n    [\n      &quot;\/var\/runtime\/botocore\/client.py&quot;,\n      697,\n      &quot;_convert_to_request_dict&quot;,\n      &quot;api_params, operation_model)&quot;\n    ],\n    [\n      &quot;\/var\/runtime\/botocore\/validate.py&quot;,\n      293,\n      &quot;serialize_to_request&quot;,\n      &quot;raise ParamValidationError(report=report.generate_report())&quot;\n    ]\n  ]\n}\n\nFunction Logs\nSTART RequestId: 0e33f157-ae77-4524-96f2-78a2fe82bf5b Version: $LATEST\nReceived event: {\n  &quot;data&quot;: &quot;231, -43&quot;\n}\n231, -43\n['231', ' -43']\nParameter validation failed:\nInvalid type for parameter Body, value: &lt;_csv.reader object at 0x7f638af1a6d8&gt;, type: &lt;class '_csv.reader'&gt;, valid types: &lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object: ParamValidationError\nTraceback (most recent call last):\n  File &quot;\/var\/task\/lambda_function.py&quot;, line 24, in lambda_handler\n    Body=wrapper)\n  File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 357, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 649, in _make_api_call\n    api_params, operation_model, context=request_context)\n  File &quot;\/var\/runtime\/botocore\/client.py&quot;, line 697, in _convert_to_request_dict\n    api_params, operation_model)\n  File &quot;\/var\/runtime\/botocore\/validate.py&quot;, line 293, in serialize_to_request\n    raise ParamValidationError(report=report.generate_report())\nbotocore.exceptions.ParamValidationError: Parameter validation failed:\nInvalid type for parameter Body, value: &lt;_csv.reader object at 0x7f638af1a6d8&gt;, type: &lt;class '_csv.reader'&gt;, valid types: &lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object\n\nEND RequestId: 0e33f157-ae77-4524-96f2-78a2fe82bf5b\nREPORT RequestId: 0e33f157-ae77-4524-96f2-78a2fe82bf5b  Duration: 19.80 ms  Billed Duration: 20 ms  Memory Size: 128 MB Max Memory Used: 68 MB  Init Duration: 261.73 ms\n\nRequest ID\n0e33f157-ae77-4524-96f2-78a2fe82bf5b\n<\/code><\/pre>\n<p>I don't know the reason about the error.<\/p>\n<p>Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1618192960303,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "api",
            "lambda",
            "amazon-sagemaker"
        ],
        "Question_view_count":21.0,
        "Owner_creation_time":1569889641900,
        "Owner_last_access_time":1620106631043,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67051812",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  : sckit-learn randomforest : rest api value error; content:<p>my lambda code is below.<\/p>\n<pre><code>import os\nimport io\nimport boto3\nimport json\nimport csv\n\n# grab environment variables\nendpoint_name = os.environ['endpoint_name']\nruntime= boto3.client('runtime.')\n\ndef lambda_handler(event, context):\n    print(&quot;received event: &quot; + json.dumps(event, indent=2))\n    \n    data = json.loads(json.dumps(event))\n    payload = data['data']\n    print(payload)\n    \n    wrapper = csv.reader(payload.strip().split('\\n'))\n    for record in wrapper:\n        print(record)\n   \n    response = runtime.invoke_endpoint(endpointname=endpoint_name,\n                                       contenttype='text\/csv',\n                                       body=wrapper)\n    print(response)\n    result = json.loads(response['body'].read().decode())\n    \n    return result\n<\/code><\/pre>\n<p>my input value is<\/p>\n<pre><code>{\n  &quot;data&quot;: &quot;231, -43&quot;\n}\n<\/code><\/pre>\n<p>error message is<\/p>\n<pre><code>response\n{\n  &quot;errormessage&quot;: &quot;parameter validation failed:\\ninvalid type for parameter body, value: &lt;_csv.reader object at 0x7f638af1a6d8&gt;, type: &lt;class '_csv.reader'&gt;, valid types: &lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object&quot;,\n  &quot;errortype&quot;: &quot;paramvalidationerror&quot;,\n  &quot;stacktrace&quot;: [\n    [\n      &quot;\/var\/task\/lambda_function.py&quot;,\n      24,\n      &quot;lambda_handler&quot;,\n      &quot;body=wrapper)&quot;\n    ],\n    [\n      &quot;\/var\/runtime\/botocore\/client.py&quot;,\n      357,\n      &quot;_api_call&quot;,\n      &quot;return self._make_api_call(operation_name, kwargs)&quot;\n    ],\n    [\n      &quot;\/var\/runtime\/botocore\/client.py&quot;,\n      649,\n      &quot;_make_api_call&quot;,\n      &quot;api_params, operation_model, context=request_context)&quot;\n    ],\n    [\n      &quot;\/var\/runtime\/botocore\/client.py&quot;,\n      697,\n      &quot;_convert_to_request_dict&quot;,\n      &quot;api_params, operation_model)&quot;\n    ],\n    [\n      &quot;\/var\/runtime\/botocore\/validate.py&quot;,\n      293,\n      &quot;serialize_to_request&quot;,\n      &quot;raise paramvalidationerror(report=report.generate_report())&quot;\n    ]\n  ]\n}\n\nfunction logs\nstart requestid: 0e33f157-ae77-4524-96f2-78a2fe82bf5b version: $latest\nreceived event: {\n  &quot;data&quot;: &quot;231, -43&quot;\n}\n231, -43\n['231', ' -43']\nparameter validation failed:\ninvalid type for parameter body, value: &lt;_csv.reader object at 0x7f638af1a6d8&gt;, type: &lt;class '_csv.reader'&gt;, valid types: &lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object: paramvalidationerror\ntraceback (most recent call last):\n  file &quot;\/var\/task\/lambda_function.py&quot;, line 24, in lambda_handler\n    body=wrapper)\n  file &quot;\/var\/runtime\/botocore\/client.py&quot;, line 357, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  file &quot;\/var\/runtime\/botocore\/client.py&quot;, line 649, in _make_api_call\n    api_params, operation_model, context=request_context)\n  file &quot;\/var\/runtime\/botocore\/client.py&quot;, line 697, in _convert_to_request_dict\n    api_params, operation_model)\n  file &quot;\/var\/runtime\/botocore\/validate.py&quot;, line 293, in serialize_to_request\n    raise paramvalidationerror(report=report.generate_report())\nbotocore.exceptions.paramvalidationerror: parameter validation failed:\ninvalid type for parameter body, value: &lt;_csv.reader object at 0x7f638af1a6d8&gt;, type: &lt;class '_csv.reader'&gt;, valid types: &lt;class 'bytes'&gt;, &lt;class 'bytearray'&gt;, file-like object\n\nend requestid: 0e33f157-ae77-4524-96f2-78a2fe82bf5b\nreport requestid: 0e33f157-ae77-4524-96f2-78a2fe82bf5b  duration: 19.80 ms  billed duration: 20 ms  memory size: 128 mb max memory used: 68 mb  init duration: 261.73 ms\n\nrequest id\n0e33f157-ae77-4524-96f2-78a2fe82bf5b\n<\/code><\/pre>\n<p>i don't know the reason about the error.<\/p>\n<p>thank you.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving a \"parameter validation failed\" error when attempting to use a scikit-learn randomforest rest api, and is unsure of the cause."
    },
    {
        "Question_id":32451243.0,
        "Question_title":"How to load images faster from Azure Blob?",
        "Question_body":"<p>I've been trying to upload some images to azure blob and then using <strong>ImageReader<\/strong> in <strong>Azure ML studio<\/strong> to read them from the blob. The problem is that ImageReader takes a lot of time to load images and I need it in real time. <br>\nI also tried making a <strong>csv<\/strong> of <strong>4 images (four rows)<\/strong> containing 800x600 pixels as columns <strong>(500,000 cols. approx)<\/strong> and tried simple <strong>Reader<\/strong>. Reader took <strong>31 mins<\/strong> to read the file from the blob.<br>\nI want to know the alternate methods of loading and reading images in Azure ML studio. If anyone know any other method or can share a helpful and relevant link.<br>\nPlease share if i can speed up ImageReader by any means.\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1441695780200,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "opencv",
            "azure",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":803.0,
        "Owner_creation_time":1387426285030,
        "Owner_last_access_time":1659463166403,
        "Owner_reputation":2128.0,
        "Owner_up_votes":128.0,
        "Owner_down_votes":8.0,
        "Owner_views":211.0,
        "Answer_body":"<p>Look at the Azure CDN <a href=\"http:\/\/azure.microsoft.com\/en-us\/services\/cdn\/\" rel=\"nofollow\">http:\/\/azure.microsoft.com\/en-us\/services\/cdn\/<\/a> , after which the blobs will get an alternative url. My blob downloads became about 4 times faster after switching.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1441739836496,
        "Answer_score":1.0,
        "Owner_location":"Lahore, Pakistan",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32451243",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to load images faster from azure blob?; content:<p>i've been trying to upload some images to azure blob and then using <strong>imagereader<\/strong> in <strong> studio<\/strong> to read them from the blob. the problem is that imagereader takes a lot of time to load images and i need it in real time. <br>\ni also tried making a <strong>csv<\/strong> of <strong>4 images (four rows)<\/strong> containing 800x600 pixels as columns <strong>(500,000 cols. approx)<\/strong> and tried simple <strong>reader<\/strong>. reader took <strong>31 mins<\/strong> to read the file from the blob.<br>\ni want to know the alternate methods of loading and reading images in  studio. if anyone know any other method or can share a helpful and relevant link.<br>\nplease share if i can speed up imagereader by any means.\nthanks<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to upload images to Azure Blob and read them using ImageReader in Azure ML Studio, but it is taking too long. They have also tried making a CSV of 4 images with 500,000 columns and using the Reader, which took 31 minutes. They are looking for alternate methods to speed up the process."
    },
    {
        "Question_id":null,
        "Question_title":"Ranking calculation of probability programming with draw",
        "Question_body":"On the web page\u201c https:\/\/docs.microsoft.com\/zh-cn\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net \u201dAccording to the winning and losing relationship of each player and the result of the game, the players are ranked by using probabilistic programming. The source code is as follows\n\n\n\nstatic void Main(string[] args)\n{\n\u202f\u202f\u202f \/\/ The winner and loser in each of 6 samples games\n\u202f\u202f\u202f var winnerData = new[] { 0, 0, 0, 1, 3, 4 };\n\u202f\u202f\u202f var loserData = new[] { 1, 3, 4, 2, 1, 2 };\n\nHere only win or lose, such as the game is a draw, how to add a draw data, how to calculate the ranking\n\n\n     \u202f\u202f\u202f \/\/ Define the statistical model as a probabilistic program\n     \u202f\u202f\u202f var game = new Range(winnerData.Length);\n     \u202f\u202f\u202f var player = new Range(winnerData.Concat(loserData).Max() + 1);\n     \u202f\u202f\u202f var playerSkills = Variable.Array<double>(player);\n     \u202f\u202f\u202f playerSkills[player] = Variable.GaussianFromMeanAndVariance(6, 9).ForEach(player);\n     \u202f\u202f\u202f var winners = Variable.Array<int>(game);\n     \u202f\u202f\u202f var losers = Variable.Array<int>(game);\n     \u202f\u202f\u202f using (Variable.ForEach(game))\n     \u202f\u202f\u202f {\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f \/\/ The player performance is a noisy version of their skill\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f var winnerPerformance = Variable.GaussianFromMeanAndVariance(playerSkills[winners[game]], 1.0);\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f var loserPerformance = Variable.GaussianFromMeanAndVariance(playerSkills[losers[game]], 1.0);\n\n\n\n\u202f\u202f\u202f\u202f\u202f\u202f\u202f \/\/ The winner performed better in this game\n\u202f\u202f\u202f\u202f\u202f\u202f\u202f Variable.ConstrainTrue(winnerPerformance > loserPerformance);\n\u202f\u202f\u202f }\n\n     \u202f\u202f\u202f \/\/ Attach the data to the model\n     \u202f\u202f\u202f winners.ObservedValue = winnerData;\n     \u202f\u202f\u202f losers.ObservedValue = loserData;\n     \u202f\u202f\u202f \/\/ Run inference\n     \u202f\u202f\u202f var inferenceEngine = new InferenceEngine();\n     \u202f\u202f\u202f var inferredSkills = inferenceEngine.Infer<Gaussian[]>(playerSkills);\n     \u202f\u202f\u202f \/\/ The inferred skills are uncertain, which is captured in their variance\n     \u202f\u202f\u202f var orderedPlayerSkills = inferredSkills\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f.Select((s, i) => new { Player = i, Skill = s })\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f.OrderByDescending(ps => ps.Skill.GetMean());\n     \u202f\u202f\u202f foreach (var playerSkill in orderedPlayerSkills)\n     \u202f\u202f\u202f {\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f Console.WriteLine($\"Player {playerSkill.Player} skill: {playerSkill.Skill}\");\n     \u202f\u202f\u202f }\n     }\n    The result of these games is only win or lose, there is no draw, official example\u201c https:\/\/github.com\/dotnet\/infer\/blob\/master\/src\/Tutorials\/ChessAnalysis.cs \u201dI can't understand. How to use a draw game Infet.net Ranking players",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1593445781820,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40959\/ranking-calculation-of-probability-programming-wit.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-30T10:00:57.257Z",
                "Answer_score":1,
                "Answer_body":"Answered on github",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: ranking calculation of probability programming with draw; content:on the web page\u201c https:\/\/docs.microsoft.com\/zh-cn\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net \u201daccording to the winning and losing relationship of each player and the result of the game, the players are ranked by using probabilistic programming. the source code is as follows\n\n\n\nstatic void main(string[] args)\n{\n\u202f\u202f\u202f \/\/ the winner and loser in each of 6 samples games\n\u202f\u202f\u202f var winnerdata = new[] { 0, 0, 0, 1, 3, 4 };\n\u202f\u202f\u202f var loserdata = new[] { 1, 3, 4, 2, 1, 2 };\n\nhere only win or lose, such as the game is a draw, how to add a draw data, how to calculate the ranking\n\n\n     \u202f\u202f\u202f \/\/ define the statistical model as a probabilistic program\n     \u202f\u202f\u202f var game = new range(winnerdata.length);\n     \u202f\u202f\u202f var player = new range(winnerdata.concat(loserdata).max() + 1);\n     \u202f\u202f\u202f var playerskills = variable.array<double>(player);\n     \u202f\u202f\u202f playerskills[player] = variable.gaussianfrommeanandvariance(6, 9).foreach(player);\n     \u202f\u202f\u202f var winners = variable.array<int>(game);\n     \u202f\u202f\u202f var losers = variable.array<int>(game);\n     \u202f\u202f\u202f using (variable.foreach(game))\n     \u202f\u202f\u202f {\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f \/\/ the player performance is a noisy version of their skill\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f var winnerperformance = variable.gaussianfrommeanandvariance(playerskills[winners[game]], 1.0);\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f var loserperformance = variable.gaussianfrommeanandvariance(playerskills[losers[game]], 1.0);\n\n\n\n\u202f\u202f\u202f\u202f\u202f\u202f\u202f \/\/ the winner performed better in this game\n\u202f\u202f\u202f\u202f\u202f\u202f\u202f variable.constraintrue(winnerperformance > loserperformance);\n\u202f\u202f\u202f }\n\n     \u202f\u202f\u202f \/\/ attach the data to the model\n     \u202f\u202f\u202f winners.observedvalue = winnerdata;\n     \u202f\u202f\u202f losers.observedvalue = loserdata;\n     \u202f\u202f\u202f \/\/ run inference\n     \u202f\u202f\u202f var inferenceengine = new inferenceengine();\n     \u202f\u202f\u202f var inferredskills = inferenceengine.infer<gaussian[]>(playerskills);\n     \u202f\u202f\u202f \/\/ the inferred skills are uncertain, which is captured in their variance\n     \u202f\u202f\u202f var orderedplayerskills = inferredskills\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f.select((s, i) => new { player = i, skill = s })\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f.orderbydescending(ps => ps.skill.getmean());\n     \u202f\u202f\u202f foreach (var playerskill in orderedplayerskills)\n     \u202f\u202f\u202f {\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f console.writeline($\"player {playerskill.player} skill: {playerskill.skill}\");\n     \u202f\u202f\u202f }\n     }\n    the result of these games is only win or lose, there is no draw, official example\u201c https:\/\/github.com\/dotnet\/infer\/blob\/master\/src\/tutorials\/chessanalysis.cs \u201di can't understand. how to use a draw game infet.net ranking players",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to use probabilistic programming to rank players based on the winning and losing relationships of each player and the result of the game. They are having difficulty understanding how to use a draw game in Infer.NET to rank players."
    },
    {
        "Question_id":null,
        "Question_title":"\" Object of type 'int64' is not JSON serializable\" when running automl time series",
        "Question_body":"I am trying to use the Online ML studio and running an \"Automated ML\". I upload my dataset (see simple example below) which passes fine and then I start a automl experiment selecting \"time series forecasting\". I select all the revelant fields and everything starts without any issues.\n\nShortly after the process fails and the error given is:\n\n\"User error: User program failed with TypeError: Object of type 'int64' is not JSON serializable\"\n\nDigging into the logs the only log with any useful information appears to be the driver_log which has these lines with no more detail about the error unless the INFO about streaming is actually an error not information:\n\n2020-09-08 11:17:01.734 - INFO - Successfully retrieved data using dataprep.\n2020-09-08 11:17:01.734 - INFO - Streaming is not conducive due to incompatible settings. Reason[s]: [Forecasting is not supported, 'n_cross_validations' was non-empty]\n2020-09-08 11:17:01.734 - INFO - Service responded with streaming disabled\n2020-09-08 11:17:01.734 - INFO - Inferring type for feature columns.\n2020-09-08 11:17:12.669 - INFO - Error in setup_wrapper.\n2020-09-08 11:17:12.670 - ERROR - Marking Run AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55_setup as Failed.\n\n\n\n\nCan anyone suggest an answer or recommend some ways to debug this?\n\n][1]",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1599571606537,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/89272\/34-object-of-type-39int6439-is-not-json-serializab.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-08T13:41:33.393Z",
                "Answer_score":0,
                "Answer_body":"found the more detailed stacktrace\n\n\"debugInfo\": {\n\"type\": \"TypeError\",\n\"message\": \"Object of type 'int64' is not JSON serializable\",\n\"stackTrace\": \" File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/brian-ml-learning\/azureml\/automl_f5a7c759-653c-4314-98a9-c2afbcecff55_setup\/mounts\/workspaceblobstore\/azureml\/AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55_setup\/azureml-setup\/context_manager_injector.py\\\", line 166, in execute_with_context\\n runpy.run_path(sys.argv[0], globals(), run_name=\\\"main\\\")\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 263, in run_path\\n pkg_name=pkg_name, script_name=fname)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 96, in _run_module_code\\n mod_name, mod_spec, pkg_name, script_name)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 85, in _run_code\\n exec(code, run_globals)\\n File \\\"setup_AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55.py\\\", line 731, in <module>\\n result = setup_run()\\n File \\\"setup_AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55.py\\\", line 725, in setup_run\\n prep_type=preparation_type\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_remote_script.py\\\", line 578, in setup_wrapper\\n setup_run._fail_with_error(e)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/run.py\\\", line 1258, in _fail_with_error\\n logging_utilities.log_traceback(exception, logger)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/logging_utilities.py\\\", line 212, in log_traceback\\n error_msg_without_pii = _get_pii_free_message(exception)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/logging_utilities.py\\\", line 140, in _get_pii_free_message\\n return exception.get_pii_free_exception_msg_format()\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/exceptions.py\\\", line 151, in get_pii_free_exception_msg_format\\n error_dict = json.loads(self.serialize_json())\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/common\/exceptions.py\\\", line 181, in serialize_json\\n return json.dumps(error_ret, indent=indent)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/init.py\\\", line 231, in dumps\\n return default_encoder.encode(obj)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 199, in encode\\n chunks = self.iterencode(o, one_shot=True)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 257, in iterencode\\n return iterencode(o, 0)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 180, in default\\n o.class.name)\\n\",\n\"innerException\": null,\n\"data\": null,\n\"errorResponse\": null\n}",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: \" object of type 'int64' is not json serializable\" when running automl time series; content:i am trying to use the online ml studio and running an \"automated ml\". i upload my dataset (see simple example below) which passes fine and then i start a automl experiment selecting \"time series forecasting\". i select all the revelant fields and everything starts without any issues.\n\nshortly after the process fails and the error given is:\n\n\"user error: user program failed with typeerror: object of type 'int64' is not json serializable\"\n\ndigging into the logs the only log with any useful information appears to be the driver_log which has these lines with no more detail about the error unless the info about streaming is actually an error not information:\n\n2020-09-08 11:17:01.734 - info - successfully retrieved data using dataprep.\n2020-09-08 11:17:01.734 - info - streaming is not conducive due to incompatible settings. reason[s]: [forecasting is not supported, 'n_cross_validations' was non-empty]\n2020-09-08 11:17:01.734 - info - service responded with streaming disabled\n2020-09-08 11:17:01.734 - info - inferring type for feature columns.\n2020-09-08 11:17:12.669 - info - error in setup_wrapper.\n2020-09-08 11:17:12.670 - error - marking run automl_f5a7c759-653c-4314-98a9-c2afbcecff55_setup as failed.\n\n\n\n\ncan anyone suggest an answer or recommend some ways to debug this?\n\n][1]",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error that an object of type 'int64' is not json serializable when running an automated ML time series experiment, and is looking for ways to debug the issue."
    },
    {
        "Question_id":null,
        "Question_title":"How can I add a table to a run after it has completed via the API?",
        "Question_body":"<p>I would like to log a table to a wandb run, like shown here: <a href=\"https:\/\/docs.wandb.ai\/guides\/data-vis\/tables-quickstart\">https:\/\/docs.wandb.ai\/guides\/data-vis\/tables-quickstart<\/a><\/p>\n<p>The table will contain information about the performance of an RL agent in environments which differ from its training environment. I want to add the table to the wandb created during the training of the RL agent. Is this possible?<\/p>\n<p>Thanks.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":null,
        "Question_creation_time":1651088864988,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":89.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-can-i-add-a-table-to-a-run-after-it-has-completed-via-the-api\/2334",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":5515,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-04-29T19:42:20.636Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/jcoholich\">@jcoholich<\/a>,<\/p>\n<p>You can <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming?q=resume\">resume<\/a> a run and log your table through that way.<\/p>\n<p>Thanks,<br>\nRamit<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-04-29T19:42:20.636Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":1.2,
                "yours":false,
                "topic_id":2334,
                "topic_slug":"how-can-i-add-a-table-to-a-run-after-it-has-completed-via-the-api",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming?q=resume",
                        "internal":false,
                        "reflection":false,
                        "title":"Resume Runs - Documentation",
                        "clicks":4
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5569,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-05-04T04:36:06.496Z",
                "cooked":"<p>Hi <strong><a class=\"mention\" href=\"\/u\/jcoholich\">@jcoholich<\/a><\/strong>,<\/p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.<\/p>\n<p>Best,<br>\nWeights &amp; Biases<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-05-04T04:36:06.496Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":2334,
                "topic_slug":"how-can-i-add-a-table-to-a-run-after-it-has-completed-via-the-api",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5636,
                "name":"Ramit Goolry",
                "username":"ramit_goolry",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/85e7bf\/{size}.png",
                "created_at":"2022-05-10T19:13:04.965Z",
                "cooked":"<p>Hi Jeremiah, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-05-10T19:13:04.965Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":2334,
                "topic_slug":"how-can-i-add-a-table-to-a-run-after-it-has-completed-via-the-api",
                "display_username":"Ramit Goolry",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":543,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6289,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-06-28T19:42:42.352Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":5,
                "post_type":3,
                "updated_at":"2022-06-28T19:42:42.352Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":2334,
                "topic_slug":"how-can-i-add-a-table-to-a-run-after-it-has-completed-via-the-api",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how can i add a table to a run after it has completed via the api?; content:<p>i would like to log a table to a  run, like shown here: <a href=\"https:\/\/docs..ai\/guides\/data-vis\/tables-quickstart\">https:\/\/docs..ai\/guides\/data-vis\/tables-quickstart<\/a><\/p>\n<p>the table will contain information about the performance of an rl agent in environments which differ from its training environment. i want to add the table to the  created during the training of the rl agent. is this possible?<\/p>\n<p>thanks.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to add a table to a run after it has completed via the API, containing information about the performance of an RL agent in environments which differ from its training environment."
    },
    {
        "Question_id":73473209.0,
        "Question_title":"Connecting DocumentDB with SageMaker (Studio)",
        "Question_body":"<p>So, it has been more than a week that I've been trying to connect my DocumentDB with SageMaker Studio, and I haven't been able to.<\/p>\n<p>Here is the scenario. I have a DocumentDB with which I want to connect using <code>pymongo<\/code> inside a notebook in SageMaker Studio. DocumentDB is restricted to VPC, so I've created my SageMaker Studio Domain in the same VPC as my DocumentDB. Yet, I keep getting time-out errors.<\/p>\n<p>I've tried following this tutorial <a href=\"https:\/\/aws.amazon.com\/blogs\/database\/getting-started-with-amazon-documentdb-with-mongodb-compatibility-part-4-using-amazon-sagemaker-notebooks\/\" rel=\"nofollow noreferrer\">here<\/a>, yet, when I do, I still get an error and I'm not able to connect.<\/p>\n<p>Has anyone done this before? BTW, I've already checked the security groups, and DocumentDB is habilitated for any inbound.<\/p>\n<p>By the way, I'm not using the &quot;VPC Only&quot; configuration.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_creation_time":1661344235337,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker",
            "aws-documentdb"
        ],
        "Question_view_count":33.0,
        "Owner_creation_time":1427546588720,
        "Owner_last_access_time":1663941566683,
        "Owner_reputation":1467.0,
        "Owner_up_votes":186.0,
        "Owner_down_votes":0.0,
        "Owner_views":47.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Rio de Janeiro, RJ, Brasil",
        "Question_last_edit_time":1661344739087,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73473209",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: connecting documentdb with  (studio); content:<p>so, it has been more than a week that i've been trying to connect my documentdb with  studio, and i haven't been able to.<\/p>\n<p>here is the scenario. i have a documentdb with which i want to connect using <code>pymongo<\/code> inside a notebook in  studio. documentdb is restricted to vpc, so i've created my  studio domain in the same vpc as my documentdb. yet, i keep getting time-out errors.<\/p>\n<p>i've tried following this tutorial <a href=\"https:\/\/aws.amazon.com\/blogs\/database\/getting-started-with-amazon-documentdb-with-mongodb-compatibility-part-4-using-amazon--notebooks\/\" rel=\"nofollow noreferrer\">here<\/a>, yet, when i do, i still get an error and i'm not able to connect.<\/p>\n<p>has anyone done this before? btw, i've already checked the security groups, and documentdb is habilitated for any inbound.<\/p>\n<p>by the way, i'm not using the &quot;vpc only&quot; configuration.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user has been trying to connect their DocumentDB with Studio for over a week and is still getting time-out errors, despite following a tutorial and checking the security groups."
    },
    {
        "Question_id":70217529.0,
        "Question_title":"Mount NVME drive of C5d instance in Amazon Sagemaker Studio",
        "Question_body":"<p>Is it possible to mount the NVME drive of an C5d instance in an Amazon Sagemaker Studio notebook? I can see the drive under 'lsblk' but am not allowed to format or mount it. The drive is also not visible in the '\/dev' folder. I tried this with a regular C5d EC2 instance and there it works without any issue.<\/p>\n<p>Edit: I tested it with Sagemaker Notebooks, not Studio, and it also works. It seems Studio doesn't have real access to the underlying infrastructure.<\/p>\n<p>Kind regards<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1638548468933,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-sagemaker"
        ],
        "Question_view_count":61.0,
        "Owner_creation_time":1495057266928,
        "Owner_last_access_time":1654516729712,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":4.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1638565418823,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70217529",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: mount nvme drive of c5d instance in  studio; content:<p>is it possible to mount the nvme drive of an c5d instance in an  studio notebook? i can see the drive under 'lsblk' but am not allowed to format or mount it. the drive is also not visible in the '\/dev' folder. i tried this with a regular c5d ec2 instance and there it works without any issue.<\/p>\n<p>edit: i tested it with  notebooks, not studio, and it also works. it seems studio doesn't have real access to the underlying infrastructure.<\/p>\n<p>kind regards<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to mount the NVME drive of a C5D instance in an Studio notebook, but is not able to format or mount it, and the drive is not visible in the '\/dev' folder. They have tested the same process with a regular C5D EC2 instance and it works without any issue."
    },
    {
        "Question_id":null,
        "Question_title":"Connect Gdrive on a remote computer",
        "Question_body":"<p>I am working on a remote workstation and would like to pull data. I can copy and past that link<\/p>\n<pre><code class=\"lang-auto\">dvc pull\n  0% Querying remote cache|                                                                                                                                                                                       |0\/1 [00:00&lt;?,    ?files\/s]Your browser has been opened to visit:\n\n    https:\/\/accounts.google.com\/o\/oauth2\/...\n<\/code><\/pre>\n<p>into my local browser and login allow access, but then the token is not transfered to the remote machine, which gets stuck.<\/p>\n<p>To clarify, I am logged in to a workstation via ssh and want to pull the data to that workstation, while the data repository is on GDrive. I want to execute all commands on that workstation remotely and I don\u2019t want to use that workstation as my data-repo.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1657911967756,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":154.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/connect-gdrive-on-a-remote-computer\/1249",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":2785,
                "name":"Yanxiang Gao",
                "username":"YanxiangGao",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/y\/f04885\/{size}.png",
                "created_at":"2022-07-16T03:38:32.629Z",
                "cooked":"<p>Hi, rmbzmb<br>\nCould you please provide some more detailed logs through<\/p>\n<pre><code class=\"lang-auto\">dvc pull -vv\n<\/code><\/pre>\n<p>And some more DVC info through<\/p>\n<pre><code class=\"lang-auto\">dvc doctor\n<\/code><\/pre>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-07-16T03:38:53.768Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":2,
                "reads":2,
                "readers_count":1,
                "score":15.4,
                "yours":false,
                "topic_id":1249,
                "topic_slug":"connect-gdrive-on-a-remote-computer",
                "display_username":"Yanxiang Gao",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":340,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2797,
                "name":"Soren",
                "username":"rmbzmb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/ed8c4c\/{size}.png",
                "created_at":"2022-07-18T09:32:10.700Z",
                "cooked":"<p>The following I tried locally and it worked, however, when I executed the same steps on the remote workstation I get errors below. I am using the same json file though.<\/p>\n<pre><code class=\"lang-auto\">dvc remote modify storage gdrive_use_service_account true\ndvc remote modify storage --local gdrive_service_account_json_file_path .dvc\/gdrive-access.json\ndvc pull\n<\/code><\/pre>\n<blockquote>\n<p>ERROR: unexpected error - &lt;HttpError 403 when requesting <a href=\"https:\/\/www.googleapis.com\/drive\/v2\/files\/\" rel=\"noopener nofollow ugc\">https:\/\/www.googleapis.com\/drive\/v2\/files\/<\/a>\u2026?fields=driveId&amp;supportsAllDrives=true&amp;alt=json returned \u201cAccess Not Configured. Drive API has not been used in project \u2026 before or it is disabled. Enable it by visiting <a href=\"https:\/\/console.developers.google.com\/apis\/api\/drive.googleapis.com\/overview?project=...then\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Cloud Platform<\/a> retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\u201d. Details: \u201c[{\u2018domain\u2019: \u2018usageLimits\u2019, \u2018reason\u2019: \u2018accessNotConfigured\u2019, \u2018message\u2019: \u2018Access Not Configured. Drive API has not been used in project \u2026 before or it is disabled. Enable it by visiting <a href=\"https:\/\/console.developers.google.com\/apis\/api\/drive.googleapis.com\/overview?project=\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Cloud Platform<\/a>\u2026 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\u2019, \u2018extendedHelp\u2019: \u2018<a href=\"https:\/\/console.developers.google.com\/apis\/api\/drive.googleapis.com\/overview?project=\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Cloud Platform<\/a>\u2026\u2019}]\u201d&gt;<\/p>\n<\/blockquote>\n<p><code>dvc pull -vv<\/code><\/p>\n<pre><code class=\"lang-auto\">------------------------------------------------------------\n2022-07-18 03:34:29,370 DEBUG: Version info for developers:\nDVC version: 2.13.0 (pip)\n---------------------------------\nPlatform: Python 3.9.13 on Linux-5.4.0-113-generic-x86_64-with-glibc2.31\nSupports:\n        gdrive (pydrive2 = 1.10.1),\n        hdfs (fsspec = 2022.5.0, pyarrow = 8.0.0),\n        webhdfs (fsspec = 2022.5.0),\n        http (aiohttp = 3.8.1, aiohttp-retry = 2.5.2),\n        https (aiohttp = 3.8.1, aiohttp-retry = 2.5.2)\nCache types: &lt;https:\/\/error.dvc.org\/no-dvc-cache&gt;\nCaches: local\nRemotes: gdrive\nWorkspace directory: ext4 on \/dev\/mapper\/ubuntu--vg-root\nRepo: dvc, git\n\nHaving any troubles? Hit us up at https:\/\/dvc.org\/support, we are always happy to help!\n2022-07-18 03:34:29,372 DEBUG: Analytics is enabled.\n2022-07-18 03:34:29,426 DEBUG: Trying to spawn '['daemon', '-q', 'analytics', '\/tmp\/tmp5jdm7j8x']'\n2022-07-18 03:34:29,429 DEBUG: Spawned '['daemon', '-q', 'analytics', '\/tmp\/tmp5jdm7j8x']'\n<\/code><\/pre>\n<p>When I visit that google URL I am getting an error: <code>You do not have sufficient permissions to view this page<\/code>. Apparently, Chrome uses the wrong account and there is no option to change the account.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-07-18T09:46:09.757Z",
                "reply_count":0,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":2,
                "readers_count":1,
                "score":5.4,
                "yours":false,
                "topic_id":1249,
                "topic_slug":"connect-gdrive-on-a-remote-computer",
                "display_username":"Soren",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":4,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/www.googleapis.com\/drive\/v2\/files\/",
                        "internal":false,
                        "reflection":false,
                        "clicks":0
                    },
                    {
                        "url":"https:\/\/console.developers.google.com\/apis\/api\/drive.googleapis.com\/overview?project=...then",
                        "internal":false,
                        "reflection":false,
                        "title":"Google Cloud Platform",
                        "clicks":0
                    },
                    {
                        "url":"https:\/\/console.developers.google.com\/apis\/api\/drive.googleapis.com\/overview?project=",
                        "internal":false,
                        "reflection":false,
                        "title":"Google Cloud Platform",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"YanxiangGao",
                    "name":"Yanxiang Gao",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/y\/f04885\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":470,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":2803,
                "name":"Soren",
                "username":"rmbzmb",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/r\/ed8c4c\/{size}.png",
                "created_at":"2022-07-18T13:46:57.122Z",
                "cooked":"<p>Finally, it works. One of the things I had to do was to share the Gdrive folder containing the registry with the service account email with read\/write permissions. It is not enough to create the service account. Though I am not sure why with the same JSON file, I get write permissions on one computer, but not on another computer. Maybe because I authenticated the first computer with the web-form.<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2022-07-18T13:46:57.122Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":15.4,
                "yours":false,
                "topic_id":1249,
                "topic_slug":"connect-gdrive-on-a-remote-computer",
                "display_username":"Soren",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":470,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: connect gdrive on a remote computer; content:<p>i am working on a remote workstation and would like to pull data. i can copy and past that link<\/p>\n<pre><code class=\"lang-auto\"> pull\n  0% querying remote cache|                                                                                                                                                                                       |0\/1 [00:00&lt;?,    ?files\/s]your browser has been opened to visit:\n\n    https:\/\/accounts.google.com\/o\/oauth2\/...\n<\/code><\/pre>\n<p>into my local browser and login allow access, but then the token is not transfered to the remote machine, which gets stuck.<\/p>\n<p>to clarify, i am logged in to a workstation via ssh and want to pull the data to that workstation, while the data repository is on gdrive. i want to execute all commands on that workstation remotely and i don\u2019t want to use that workstation as my data-repo.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to connect to a Google Drive repository from a remote workstation via SSH, but is having difficulty transferring the token to the remote machine."
    },
    {
        "Question_id":70909916.0,
        "Question_title":"No GPU detected on AWS SageMaker pytorch-1.8-gpu-py36 instance",
        "Question_body":"<p>I've got a pytorch-1.8-gpu-py36 instance running on AWS SageMaker Studio.<\/p>\n<p>If I'm in a notebook in and I enter:<\/p>\n<pre><code>!nvidia-smi -L\n<\/code><\/pre>\n<p>I get:<\/p>\n<pre><code>GPU 0: Tesla T4 (UUID: GPU-786d298a-2648-3506-6c3a-f541fa46d777)\n<\/code><\/pre>\n<p>But if I open a terminal and enter:<\/p>\n<pre><code>nvidia-smi -L\n<\/code><\/pre>\n<p>I get command not found, and if I try to run a .py script that requires a GPU I get this error from PyTorch:<\/p>\n<pre><code>pytorch_lightning.utilities.exceptions.MisconfigurationException: \nYou requested GPUs: [0]\nBut your machine only has: []\n<\/code><\/pre>\n<p>Do the terminal windows and notebooks run off of separate instances even if they're in the same folder? Is there a way to get the terminal to be part of the same instance as the notebook?<\/p>\n<p>I can't simply run the command line from the notebook as I require a Conda environment that can't be activated from the notebook interface.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1643491948780,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "jupyter-notebook",
            "amazon-sagemaker"
        ],
        "Question_view_count":278.0,
        "Owner_creation_time":1369310121732,
        "Owner_last_access_time":1661886805676,
        "Owner_reputation":931.0,
        "Owner_up_votes":7.0,
        "Owner_down_votes":0.0,
        "Owner_views":48.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1643519980470,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70909916",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: no gpu detected on  pytorch-1.8-gpu-py36 instance; content:<p>i've got a pytorch-1.8-gpu-py36 instance running on  studio.<\/p>\n<p>if i'm in a notebook in and i enter:<\/p>\n<pre><code>!nvidia-smi -l\n<\/code><\/pre>\n<p>i get:<\/p>\n<pre><code>gpu 0: tesla t4 (uuid: gpu-786d298a-2648-3506-6c3a-f541fa46d777)\n<\/code><\/pre>\n<p>but if i open a terminal and enter:<\/p>\n<pre><code>nvidia-smi -l\n<\/code><\/pre>\n<p>i get command not found, and if i try to run a .py script that requires a gpu i get this error from pytorch:<\/p>\n<pre><code>pytorch_lightning.utilities.exceptions.misconfigurationexception: \nyou requested gpus: [0]\nbut your machine only has: []\n<\/code><\/pre>\n<p>do the terminal windows and notebooks run off of separate instances even if they're in the same folder? is there a way to get the terminal to be part of the same instance as the notebook?<\/p>\n<p>i can't simply run the command line from the notebook as i require a conda environment that can't be activated from the notebook interface.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to detect a GPU when running a .py script from a terminal window, but can detect it when running from a notebook in Studio. They are wondering if the terminal and notebook are running off of separate instances and if there is a way to get the terminal to be part of the same instance as the notebook."
    },
    {
        "Question_id":73652143.0,
        "Question_title":"auto-ml-forecasting-many-models retrieve training results",
        "Question_body":"<p>I'm following the Python SDK tutorial for training many models: Here a <a href=\"https:\/\/github.com\/azure\/machinelearningnotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-many-models\/auto-ml-forecasting-many-models.ipynb\" rel=\"nofollow noreferrer\">link<\/a> to the notebook<\/p>\n<p>So everything is working fine, but now I'm interested in the training results. When I check the Azure ML Studio I can see the pipeline steps as followed: <a href=\"https:\/\/i.stack.imgur.com\/aYAyi.png\" rel=\"nofollow noreferrer\">training pipeline<\/a>.<\/p>\n<p>In the outputs directory of mm-models train I do not get the information I need. But if I check the child-jobs I go down in granularity <a href=\"https:\/\/i.stack.imgur.com\/uLNmw.png\" rel=\"nofollow noreferrer\">child-jobs<\/a>.<\/p>\n<p>Here I can see the trained models and their hyper-parameters for example for the partitioned entities which I want to forecast. So for example a specific product in a certain region. <a href=\"https:\/\/i.stack.imgur.com\/MHuhn.png\" rel=\"nofollow noreferrer\">models for a partitioned entity<\/a><\/p>\n<p>Now what I want now is from the Python SDK (or in general programatically) retrieve the information stored in this child-jobs which I can access via the Azure ML Studio GUI such as cross-validation forecasts or measures for explainability such as these: <a href=\"https:\/\/i.stack.imgur.com\/w7dIs.png\" rel=\"nofollow noreferrer\">Azure ML GUI<\/a>.<\/p>\n<p>I can see that this information is stored in the output folder of the child-jobs: <a href=\"https:\/\/i.stack.imgur.com\/k1rUw.png\" rel=\"nofollow noreferrer\">Output + logs<\/a><\/p>\n<p>I can't figure out from the Documentation of the Python SDK how to retrieve these results. I also tried to get the results from a child-job via the Rest API following this <a href=\"https:\/\/docs.microsoft.com\/en-gb\/rest\/api\/batchservice\/job\/get?tabs=HTTP\" rel=\"nofollow noreferrer\">thread<\/a>. The output that I got looks like this: <a href=\"https:\/\/i.stack.imgur.com\/ugefY.png\" rel=\"nofollow noreferrer\">error response<\/a> Additionally I would not know how to get all the IDs from the child jobs from within the python SDK.<\/p>\n<p>I would appreciate any help!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1662653379880,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-service",
            "azure-rest-api",
            "azureml-python-sdk"
        ],
        "Question_view_count":56.0,
        "Owner_creation_time":1574846807488,
        "Owner_last_access_time":1663593674092,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Cologne",
        "Question_last_edit_time":1662657114452,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73652143",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: auto-ml-forecasting-many-models retrieve training results; content:<p>i'm following the python sdk tutorial for training many models: here a <a href=\"https:\/\/github.com\/azure\/machinelearningnotebooks\/blob\/master\/how-to-use-\/automated-machine-learning\/forecasting-many-models\/auto-ml-forecasting-many-models.ipynb\" rel=\"nofollow noreferrer\">link<\/a> to the notebook<\/p>\n<p>so everything is working fine, but now i'm interested in the training results. when i check the  studio i can see the pipeline steps as followed: <a href=\"https:\/\/i.stack.imgur.com\/ayayi.png\" rel=\"nofollow noreferrer\">training pipeline<\/a>.<\/p>\n<p>in the outputs directory of mm-models train i do not get the information i need. but if i check the child-jobs i go down in granularity <a href=\"https:\/\/i.stack.imgur.com\/ulnmw.png\" rel=\"nofollow noreferrer\">child-jobs<\/a>.<\/p>\n<p>here i can see the trained models and their hyper-parameters for example for the partitioned entities which i want to forecast. so for example a specific product in a certain region. <a href=\"https:\/\/i.stack.imgur.com\/mhuhn.png\" rel=\"nofollow noreferrer\">models for a partitioned entity<\/a><\/p>\n<p>now what i want now is from the python sdk (or in general programatically) retrieve the information stored in this child-jobs which i can access via the  studio gui such as cross-validation forecasts or measures for explainability such as these: <a href=\"https:\/\/i.stack.imgur.com\/w7dis.png\" rel=\"nofollow noreferrer\"> gui<\/a>.<\/p>\n<p>i can see that this information is stored in the output folder of the child-jobs: <a href=\"https:\/\/i.stack.imgur.com\/k1ruw.png\" rel=\"nofollow noreferrer\">output + logs<\/a><\/p>\n<p>i can't figure out from the documentation of the python sdk how to retrieve these results. i also tried to get the results from a child-job via the rest api following this <a href=\"https:\/\/docs.microsoft.com\/en-gb\/rest\/api\/batchservice\/job\/get?tabs=http\" rel=\"nofollow noreferrer\">thread<\/a>. the output that i got looks like this: <a href=\"https:\/\/i.stack.imgur.com\/ugefy.png\" rel=\"nofollow noreferrer\">error response<\/a> additionally i would not know how to get all the ids from the child jobs from within the python sdk.<\/p>\n<p>i would appreciate any help!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to programmatically retrieve the training results from the child-jobs of an auto-ml-forecasting-many-models pipeline, such as cross-validation forecasts and measures for explainability."
    },
    {
        "Question_id":null,
        "Question_title":"Wanb.watch(model) causing CUDA OOM",
        "Question_body":"<p>I am trying to use wandb gradient visualization to debug the gradient flow in my neural net on Google Colab. Without wandb logging, the training runs without error, taking up 11Gb\/16GB on the p100 gpu. However, adding this line <code>wandb.watch(model, log='all', log_freq=3)<\/code> causes a cuda out of memory error. How does wandb logging create extra gpu memory overhead? Is there some way to reduce the overhead? Thank you for your help.<\/p>",
        "Question_answer_count":5,
        "Question_comment_count":null,
        "Question_creation_time":1631287205142,
        "Question_favorite_count":null,
        "Question_score":3.0,
        "Question_tags":null,
        "Question_view_count":545.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/wanb-watch-model-causing-cuda-oom\/499",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":1263,
                "name":"Sanyam Bhutani",
                "username":"bhutanisanyam1",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/bhutanisanyam1\/{size}\/18_2.png",
                "created_at":"2021-09-10T20:21:45.773Z",
                "cooked":"<p>Hello and welcome to the forums <a class=\"mention\" href=\"\/u\/ambrose\">@ambrose<\/a>! <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/wave.png?v=10\" title=\":wave:\" class=\"emoji\" alt=\":wave:\"><\/p>\n<p>Please do introduce yourself in the <a class=\"hashtag\" href=\"\/c\/start-here\/2\">#<span>start-here<\/span><\/a> category if you\u2019d like to!<\/p>\n<p>Please allow me to replicate this issue, and ask the team for help.<br>\nI\u2019ll get back once I\u2019m able to replicate the issue, Thanks for the Q! <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-09-10T20:21:45.773Z",
                "reply_count":2,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":13,
                "readers_count":12,
                "score":12.6,
                "yours":false,
                "topic_id":499,
                "topic_slug":"wanb-watch-model-causing-cuda-oom",
                "display_username":"Sanyam Bhutani",
                "primary_group_name":"team",
                "flair_name":"team",
                "flair_url":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/27bab8f920bcd41717e467ec0a2929adc33869e5.png",
                "flair_bg_color":"ffffff",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"\/c\/start-here\/2",
                        "internal":true,
                        "reflection":false,
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":"Community Team",
                "title_is_group":true,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":5,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1267,
                "name":"Ambrose Plante",
                "username":"ambrose",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/ambrose\/{size}\/198_2.png",
                "created_at":"2021-09-11T00:52:29.061Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/bhutanisanyam1\">@bhutanisanyam1<\/a>,<\/p>\n<p>Thank you for your reply and welcome! I am quite excited to use WandB and join the community.<\/p>\n<p>Ambrose<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-09-11T00:52:29.061Z",
                "reply_count":0,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":1,
                "reads":14,
                "readers_count":13,
                "score":7.8,
                "yours":false,
                "topic_id":499,
                "topic_slug":"wanb-watch-model-causing-cuda-oom",
                "display_username":"Ambrose Plante",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"bhutanisanyam1",
                    "name":"Sanyam Bhutani",
                    "avatar_template":"\/user_avatar\/community.wandb.ai\/bhutanisanyam1\/{size}\/18_2.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":303,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1284,
                "name":"Ambrose Plante",
                "username":"ambrose",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/ambrose\/{size}\/198_2.png",
                "created_at":"2021-09-11T19:32:36.707Z",
                "cooked":"<p>Hmm I think WandB is creating extra copies of the gradients during the logging. In case it helps, here is the error traceback:<\/p>\n<pre><code class=\"lang-auto\">---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-11-13de83557b55&gt; in &lt;module&gt;()\n     60         get_ipython().system(\"nvidia-smi | grep MiB | awk '{print $9 $10 $11}'\")\n     61 \n---&gt; 62         loss.backward()\n     63 \n     64         print('check 10')\n\n4 frames\n\/usr\/local\/lib\/python3.7\/dist-packages\/torch\/_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs)\n    253                 create_graph=create_graph,\n    254                 inputs=inputs)\n--&gt; 255         torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n    256 \n    257     def register_hook(self, hook):\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/torch\/autograd\/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\n    147     Variable._execution_engine.run_backward(\n    148         tensors, grad_tensors_, retain_graph, create_graph, inputs,\n--&gt; 149         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n    150 \n    151 \n\n\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/wandb_torch.py in &lt;lambda&gt;(grad)\n    283             self.log_tensor_stats(grad.data, name)\n    284 \n--&gt; 285         handle = var.register_hook(lambda grad: _callback(grad, log_track))\n    286         self._hook_handles[name] = handle\n    287         return handle\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/wandb_torch.py in _callback(grad, log_track)\n    281             if not log_track_update(log_track):\n    282                 return\n--&gt; 283             self.log_tensor_stats(grad.data, name)\n    284 \n    285         handle = var.register_hook(lambda grad: _callback(grad, log_track))\n\n\/usr\/local\/lib\/python3.7\/dist-packages\/wandb\/wandb_torch.py in log_tensor_stats(self, tensor, name)\n    219         # Remove nans from tensor. There's no good way to represent that in histograms.\n    220         flat = flat[~torch.isnan(flat)]\n--&gt; 221         flat = flat[~torch.isinf(flat)]\n    222         if flat.shape == torch.Size([0]):\n    223             # Often the whole tensor is nan or inf. Just don't log it in that case.\n\nRuntimeError: CUDA out of memory. Tried to allocate 4.65 GiB (GPU 0; 15.90 GiB total capacity; 10.10 GiB already allocated; 717.75 MiB free; 14.27 GiB reserved in total by PyTorch)\n<\/code><\/pre>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2021-09-11T19:32:36.707Z",
                "reply_count":1,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":4,
                "reads":14,
                "readers_count":13,
                "score":27.8,
                "yours":false,
                "topic_id":499,
                "topic_slug":"wanb-watch-model-causing-cuda-oom",
                "display_username":"Ambrose Plante",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"bhutanisanyam1",
                    "name":"Sanyam Bhutani",
                    "avatar_template":"\/user_avatar\/community.wandb.ai\/bhutanisanyam1\/{size}\/18_2.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":303,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1285,
                "name":"Ambrose Plante",
                "username":"ambrose",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/ambrose\/{size}\/198_2.png",
                "created_at":"2021-09-11T20:00:25.419Z",
                "cooked":"<p>Indeed, commenting out the offending line <code>flat = flat[~torch.isinf(flat)]<\/code> gets the WandB log step to just barely fit into the GPU memory. This is not a great solution though.<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2021-09-11T20:00:25.419Z",
                "reply_count":0,
                "reply_to_post_number":4,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":14,
                "readers_count":13,
                "score":17.8,
                "yours":false,
                "topic_id":499,
                "topic_slug":"wanb-watch-model-causing-cuda-oom",
                "display_username":"Ambrose Plante",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"ambrose",
                    "name":"Ambrose Plante",
                    "avatar_template":"\/user_avatar\/community.wandb.ai\/ambrose\/{size}\/198_2.png"
                },
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":303,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5365,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-04-20T18:02:07.124Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":6,
                "post_type":3,
                "updated_at":"2022-04-20T18:02:07.124Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":2,
                "reads":3,
                "readers_count":2,
                "score":10.6,
                "yours":false,
                "topic_id":499,
                "topic_slug":"wanb-watch-model-causing-cuda-oom",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: wanb.watch(model) causing cuda oom; content:<p>i am trying to use  gradient visualization to debug the gradient flow in my neural net on google colab. without  logging, the training runs without error, taking up 11gb\/16gb on the p100 gpu. however, adding this line <code>.watch(model, log='all', log_freq=3)<\/code> causes a cuda out of memory error. how does  logging create extra gpu memory overhead? is there some way to reduce the overhead? thank you for your help.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to debug the gradient flow in their neural net on Google Colab and is experiencing a CUDA out of memory error when adding a line of code to log the model. They are wondering how logging creates extra GPU memory overhead and if there is a way to reduce it."
    },
    {
        "Question_id":71108775.0,
        "Question_title":"How do I invoke a data enrichment function before model.predict while serving the model in Databricks",
        "Question_body":"<p>In Databricks, I have used mlflow and got my model served through REST API. It works fine when all model features are provided. But my use case is that only a single feature (the primary key) will be provided by the consumer application, and my code has to lookup the other features from a database based on that key and then use the model.predict to return the prediction. I tried researching but understood that the REST endpoints will simply invoke the model.predict function. How can I make it invoke a data massaging function before predicting?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1644826322870,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "model",
            "databricks",
            "mlflow",
            "serving"
        ],
        "Question_view_count":109.0,
        "Owner_creation_time":1531142162080,
        "Owner_last_access_time":1657102181380,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":1.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1644835966403,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71108775",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how do i invoke a data enrichment function before model.predict while serving the model in databricks; content:<p>in databricks, i have used  and got my model served through rest api. it works fine when all model features are provided. but my use case is that only a single feature (the primary key) will be provided by the consumer application, and my code has to lookup the other features from a database based on that key and then use the model.predict to return the prediction. i tried researching but understood that the rest endpoints will simply invoke the model.predict function. how can i make it invoke a data massaging function before predicting?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to invoke a data enrichment function before model.predict while serving the model in Databricks."
    },
    {
        "Question_id":null,
        "Question_title":"Build docker image to deploy from databricks",
        "Question_body":"Hi guys!\n\n\nI'm a new MLFlow user and I would like to deploy models on Kubernets. Is there any tutorial for that?\n\n\nI'm using Databricks to run my experiments and train my models but I don't know how to deploy from that.\n\n\nHow the community deals with that?\n\n\nThanks a lot!\nRegards!",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1567179127000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":355.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/bHaU6sQ17O0",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[
            {
                "Answer_creation_time":"2019-09-12T18:42:12",
                "Answer_body":"Hi Rafael,\n\n\nThe build-docker command described here can build a Docker container from your model that you can deploy to Kubernetes:\u00a0https:\/\/www.mlflow.org\/docs\/latest\/cli.html#mlflow-models-build-docker. You can run this command on a server that has Docker and have it read models from your Databricks workspace by configuring your MLflow client to talk to the Databricks tracking server using the MLFLOW_TRACKING_URI environment variable as described here:\u00a0https:\/\/docs.databricks.com\/applications\/mlflow\/tracking.html#log-to-a-tracking-server-from-the-api-or-cli. Then it will find the models that are stored on Databricks and download them and package them as Docker containers.\n\n\nMatei\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/72e7a673-0d3a-4567-98d5-ef00851a04b6%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-09-12T19:44:27",
                "Answer_body":"Hey Rafael!\n\n\nTune into our online workshop this Saturday (Sept 14). \u00a0Link is below.\n\n\nWe\u2019ll be doing exactly what you want to do - except we\u2019ll do it with 100% open source code, so Databricks is not required.\n\n\nRSVP here!\n\n\nhttps:\/\/www.eventbrite.com\/e\/full-day-workshop-kubeflow-kerastensorflow-20-tf-extended-tfx-kubernetes-pytorch-xgboost-airflow-tickets-63362929227\n\n\nOn Sep 12, 2019, at 3:42 PM, Matei Zaharia <ma...@databricks.com> wrote:\n\n\n\ufeffHi Rafael,\n\ue5d3\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/0C544387-6337-42DE-864C-BDA0A16CA548%40databricks.com."
            },
            {
                "Answer_creation_time":"2019-09-17T15:47:46",
                "Answer_body":"Workshop Slides: \u00a0https:\/\/www.slideshare.net\/cfregly\/handson-learning-with-kubeflow-kerastensorflow-20-tf-extended-tfx-kubernetes-pytorch-xgboost-airflow-mlflow-spark-jupyter-tpu-172188147\n\n\nWorkshop Video: \u00a0https:\/\/www.youtube.com\/watch?v=AaBqhGEwxXI\n\n\nWorkshop Notebooks: \u00a0https:\/\/github.com\/PipelineAI\/pipeline\/tree\/master\/kubeflow\/notebooks\u00a0\u00a0\n\n\nEnjoy!\n\n\n-Chris\n\ue5d3"
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: build docker image to deploy from databricks; content:hi guys!\n\n\ni'm a new  user and i would like to deploy models on kubernets. is there any tutorial for that?\n\n\ni'm using databricks to run my experiments and train my models but i don't know how to deploy from that.\n\n\nhow the community deals with that?\n\n\nthanks a lot!\nregards!",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is new to deploying models on Kubernetes and is looking for a tutorial to help them deploy from Databricks. They are also interested in how the community deals with this issue."
    },
    {
        "Question_id":59637596.0,
        "Question_title":"Where does Python modules installed on Azure Machine Learning Studio",
        "Question_body":"<p>I understand the azure machine learning studio (classic) version using Anaconda distribution but my question is where would the python modules like pandas\/tensorflow are installed when using <strong>IPython interface of Azure ML<\/strong>. Is this on AML studio itself or in azure blob (AML studio uses blob as backend store)? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1578440246977,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "azure",
            "azure-machine-learning-studio"
        ],
        "Question_view_count":136.0,
        "Owner_creation_time":1500744375327,
        "Owner_last_access_time":1660004233300,
        "Owner_reputation":255.0,
        "Owner_up_votes":20.0,
        "Owner_down_votes":0.0,
        "Owner_views":130.0,
        "Answer_body":"<p>Here is my screenshots for tabs <code>EXPERIMENTS<\/code> and <code>NOTEBOOKS<\/code> in Azure Machine Learning Studio (classic), as the figures below.<\/p>\n\n<p>Fig 1. I created a <code>Excute Python Script<\/code> module with the code to print the <code>sys.path<\/code> and the real path of <code>pandas<\/code> installed.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/KdkJa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KdkJa.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 2. The <code>View output log<\/code> page of the code in Fig 1 shows <code>EXPERIMENTS<\/code> is a runtime of Anaconda on Windows. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/zo9te.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zo9te.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 3. I created a notebook named <code>demo<\/code> and run the same code as Fig 1, the result shows <code>NOTEBOOKS<\/code> is a runtime of Anaconda on Linux, even the notenooks url is started with <code>notebooks.azure.com<\/code>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/uAGRk.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uAGRk.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 4. I used different commands like <code>lsb_release -a<\/code>, <code>fdisk -l<\/code>, <code>lsdev<\/code>, <code>ls \/dev<\/code>, <code>df -a<\/code> to try to see the Linux version and its disk or partition information, the result shows it's a Ubuntu Linux container.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/R4wC6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/R4wC6.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Other infomation what you want to know, you can try to check by yourself.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1578465543192,
        "Answer_score":0.0,
        "Owner_location":null,
        "Question_last_edit_time":1578440835316,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59637596",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: where does python modules installed on  studio; content:<p>i understand the  studio (classic) version using anaconda distribution but my question is where would the python modules like pandas\/tensorflow are installed when using <strong>ipython interface of <\/strong>. is this on aml studio itself or in azure blob (aml studio uses blob as backend store)? <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking where Python modules such as Pandas and TensorFlow are installed when using the IPython interface of Azure ML, and whether they are installed on the AML Studio itself or in Azure Blob."
    },
    {
        "Question_id":66917129.0,
        "Question_title":"Specify host and port in mlflow.yml and run \"kedro mlflow ui\", but host and port still default (localhost:5000) not change",
        "Question_body":"<p>I build sample kedro project refer to <a href=\"https:\/\/kedro-mlflow.readthedocs.io\/en\/0.6.0\/source\/03_getting_started\/01_example_project.html\" rel=\"nofollow noreferrer\">this page<\/a>,\nand specify host as my global ip address in mlflow.yml.\nbut when I hit &quot;kedro mlflow ui&quot; command, it still listen to local.\neven I only specify port to 5001 (not default) in mlflow.yml, it does not work.\nCan anyone help me.<\/p>\n<p>python version: 3.6.8 (anaconda)\nkedro version: 0.17.0\nkedro mlflow version: 0.6.0<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1617355258347,
        "Question_favorite_count":1.0,
        "Question_score":2.0,
        "Question_tags":[
            "mlflow",
            "kedro"
        ],
        "Question_view_count":2006.0,
        "Owner_creation_time":1617353591860,
        "Owner_last_access_time":1621919902550,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":2.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66917129",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: specify host and port in .yml and run \"kedro  ui\", but host and port still default (localhost:5000) not change; content:<p>i build sample kedro project refer to <a href=\"https:\/\/kedro-.readthedocs.io\/en\/0.6.0\/source\/03_getting_started\/01_example_project.html\" rel=\"nofollow noreferrer\">this page<\/a>,\nand specify host as my global ip address in .yml.\nbut when i hit &quot;kedro  ui&quot; command, it still listen to local.\neven i only specify port to 5001 (not default) in .yml, it does not work.\ncan anyone help me.<\/p>\n<p>python version: 3.6.8 (anaconda)\nkedro version: 0.17.0\nkedro  version: 0.6.0<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty getting the host and port specified in the .yml file to take effect when running the \"kedro ui\" command, despite using the correct versions of Python and Kedro."
    },
    {
        "Question_id":60362994.0,
        "Question_title":"How to copy local MLflow run to remote tracking server?",
        "Question_body":"<p>I am currently tracking my MLflow runs to a local file path URI. I would also like to set up a remote tracking server to share with my collaborators. One thing I would like to avoid is to log everything to the server, as it might soon be flooded with failed runs.<\/p>\n\n<p>Ideally, I'd like to keep my local tracker, and then be able to send only the promising runs to the server.<\/p>\n\n<p>What is the recommended way of copying a run from a local tracker to a remote server?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1582466676413,
        "Question_favorite_count":1.0,
        "Question_score":7.0,
        "Question_tags":[
            "mlflow"
        ],
        "Question_view_count":611.0,
        "Owner_creation_time":1492200983870,
        "Owner_last_access_time":1656593519288,
        "Owner_reputation":199.0,
        "Owner_up_votes":132.0,
        "Owner_down_votes":1.0,
        "Owner_views":16.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60362994",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to copy local  run to remote tracking server?; content:<p>i am currently tracking my  runs to a local file path uri. i would also like to set up a remote tracking server to share with my collaborators. one thing i would like to avoid is to log everything to the server, as it might soon be flooded with failed runs.<\/p>\n\n<p>ideally, i'd like to keep my local tracker, and then be able to send only the promising runs to the server.<\/p>\n\n<p>what is the recommended way of copying a run from a local tracker to a remote server?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to keep their local tracker and send only the promising runs to the remote server, and is looking for the recommended way to copy a run from the local tracker to the remote server."
    },
    {
        "Question_id":52889337.0,
        "Question_title":"mxnet sagemaker load model",
        "Question_body":"<p>I'm trying to load an already trained model from sagemaker MXnet.<\/p>\n\n<p>I have the model.tar.gz file, however, when I try to do<\/p>\n\n<pre><code>&gt; %%bash\n&gt; tar -xzf model.tar.gz rm model.tar.gz\n&gt; prefix = 'model_name' \n&gt; sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, 0) \n&gt; mod = mx.mod.Module(symbol=sym,\n&gt; context=ctx, label_names=None) mod.bind(for_training=False, data_shapes=[('data', (1,3,480,480))], label_shapes=mod._label_shapes)\n&gt; mod.set_params(arg_params, aux_params)\n<\/code><\/pre>\n\n<p>I keep getting the error Error in operator multibox_target: [09:08:47] src\/operator\/contrib\/.\/multibox_target-inl.h:225: Check failed: lshape.ndim() == 3 (0 vs. 3) Label should be [batch-num_labels-(>=5)] tensor<\/p>\n\n<p>Can anyone help me with this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1.0,
        "Question_creation_time":1539940520883,
        "Question_favorite_count":1.0,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-web-services",
            "mxnet",
            "amazon-sagemaker"
        ],
        "Question_view_count":294.0,
        "Owner_creation_time":1509392519216,
        "Owner_last_access_time":1552779156336,
        "Owner_reputation":33.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1539984799352,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52889337",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: mxnet  load model; content:<p>i'm trying to load an already trained model from  mxnet.<\/p>\n\n<p>i have the model.tar.gz file, however, when i try to do<\/p>\n\n<pre><code>&gt; %%bash\n&gt; tar -xzf model.tar.gz rm model.tar.gz\n&gt; prefix = 'model_name' \n&gt; sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, 0) \n&gt; mod = mx.mod.module(symbol=sym,\n&gt; context=ctx, label_names=none) mod.bind(for_training=false, data_shapes=[('data', (1,3,480,480))], label_shapes=mod._label_shapes)\n&gt; mod.set_params(arg_params, aux_params)\n<\/code><\/pre>\n\n<p>i keep getting the error error in operator multibox_target: [09:08:47] src\/operator\/contrib\/.\/multibox_target-inl.h:225: check failed: lshape.ndim() == 3 (0 vs. 3) label should be [batch-num_labels-(>=5)] tensor<\/p>\n\n<p>can anyone help me with this?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to load a trained model in MXNet and encountering an error with the operator \"multibox_target\" which states that the label shape should be a tensor with 3 dimensions, however, the label has only 0 dimensions."
    },
    {
        "Question_id":71255132.0,
        "Question_title":"API Gateway + AWS SageMaker - AWS ARN for integration contains invalid action for integration with sagemaker",
        "Question_body":"<p>As mentioned in step-3 of <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/creating-a-machine-learning-powered-rest-api-with-amazon-api-gateway-mapping-templates-and-amazon-sagemaker\/\" rel=\"nofollow noreferrer\">this blog by AWS<\/a>, I have created a role to invoke sagemaker endpoint. But, when I deploy the API to a stage, I get &quot;AWS ARN for integration contains invalid action&quot; and I can't deploy the stage.\n<a href=\"https:\/\/i.stack.imgur.com\/maMdl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/maMdl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>blog suggested to select API Gateway under services and to keep on next, but didn't mention which policy will be attached. and also that another inline policy to invoke a specific sagemaker endpoint to be created and attached.\n<a href=\"https:\/\/i.stack.imgur.com\/uQwx0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uQwx0.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>and as mentioned in <a href=\"https:\/\/docs.aws.amazon.com\/apigateway\/latest\/developerguide\/integration-request-basic-setup.html\" rel=\"nofollow noreferrer\">AWS Docs<\/a>:<\/p>\n<blockquote>\n<p>It must also have API Gateway declared (in the role's trust\nrelationship) as a trusted entity to assume the role.<\/p>\n<\/blockquote>\n<p>my role also have the trust-relationshp:\n<a href=\"https:\/\/i.stack.imgur.com\/VJ9aU.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/VJ9aU.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What's missing in my role that led to the error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3.0,
        "Question_creation_time":1645719715780,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "aws-api-gateway",
            "amazon-iam",
            "amazon-sagemaker"
        ],
        "Question_view_count":177.0,
        "Owner_creation_time":1559910246180,
        "Owner_last_access_time":1664039951323,
        "Owner_reputation":2046.0,
        "Owner_up_votes":2858.0,
        "Owner_down_votes":5.0,
        "Owner_views":369.0,
        "Answer_body":"<p>Check in all your API methods that you haven't specified &quot;Use Action Name&quot; for any integration request, and then left the &quot;Action&quot; field blank. If you do the &quot;AWS ARN for integration contains invalid action&quot; error message will be shown.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/EXEnQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EXEnQ.png\" alt=\"action type choice\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1645781417427,
        "Answer_score":1.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Question_last_edit_time":1645720170123,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71255132",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: api gateway +  - aws arn for integration contains invalid action for integration with ; content:<p>as mentioned in step-3 of <a href=\"https:\/\/aws.amazon.com\/blogs\/machine-learning\/creating-a-machine-learning-powered-rest-api-with-amazon-api-gateway-mapping-templates-and-amazon-\/\" rel=\"nofollow noreferrer\">this blog by aws<\/a>, i have created a role to invoke  endpoint. but, when i deploy the api to a stage, i get &quot;aws arn for integration contains invalid action&quot; and i can't deploy the stage.\n<a href=\"https:\/\/i.stack.imgur.com\/mamdl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mamdl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>blog suggested to select api gateway under services and to keep on next, but didn't mention which policy will be attached. and also that another inline policy to invoke a specific  endpoint to be created and attached.\n<a href=\"https:\/\/i.stack.imgur.com\/uqwx0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uqwx0.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>and as mentioned in <a href=\"https:\/\/docs.aws.amazon.com\/apigateway\/latest\/developerguide\/integration-request-basic-setup.html\" rel=\"nofollow noreferrer\">aws docs<\/a>:<\/p>\n<blockquote>\n<p>it must also have api gateway declared (in the role's trust\nrelationship) as a trusted entity to assume the role.<\/p>\n<\/blockquote>\n<p>my role also have the trust-relationshp:\n<a href=\"https:\/\/i.stack.imgur.com\/vj9au.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vj9au.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>what's missing in my role that led to the error?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error when attempting to deploy an API stage due to an invalid action in the AWS ARN for integration, and is unsure what is missing from their role that is causing the issue."
    },
    {
        "Question_id":72783902.0,
        "Question_title":"Is it possible to run Vertex AI Workbench on Spot machines?",
        "Question_body":"<p>I'm trying to save budget on jupyter notebooks on Google Cloud but couldn't find a way to run Vertex AI Workbench (Notebooks) on spot machines.\nWhat are my alternatives?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1656408332770,
        "Question_favorite_count":1.0,
        "Question_score":2.0,
        "Question_tags":[
            "google-cloud-platform",
            "jupyter-notebook",
            "jupyter",
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":176.0,
        "Owner_creation_time":1322253579120,
        "Owner_last_access_time":1661153607008,
        "Owner_reputation":73.0,
        "Owner_up_votes":14.0,
        "Owner_down_votes":0.0,
        "Owner_views":14.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72783902",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is it possible to run  workbench on spot machines?; content:<p>i'm trying to save budget on jupyter notebooks on google cloud but couldn't find a way to run  workbench (notebooks) on spot machines.\nwhat are my alternatives?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to save budget on Jupyter notebooks on Google Cloud, but is unable to run Workbench (notebooks) on spot machines. They are looking for alternatives."
    },
    {
        "Question_id":69282549.0,
        "Question_title":"Unable to schedule training job to Azure Machine Learning AKS cluster",
        "Question_body":"<p>I am using the preview feature of configuring an AKS cluster via Arc in Azure Machine Learning Studio and attempting to submit a job for training however it gets stuck in Queued state with the following message:<\/p>\n<p><em>Queue Information : Job is waiting for available resources, that required for 1 instance with 1.00 vCPU(s), 4.00 GB memory and 0 GPU(s). The best-fit compute can only provide 1.90 vCPU(s), 4.46 GB memory and 0 GPU(s). Please continue to wait or change to a smaller instance type<\/em><\/p>\n<p>I am not too sure exactly what this is telling me because (aside from the grammar) the job requirements are LESS than what is available so why is it blocking? Also its telling me to change to a smaller instance type, which I did and it still gave me the same.<\/p>\n<p>Anyone come across this or know how to get past it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1632306875657,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning-studio",
            "azure-machine-learning-service"
        ],
        "Question_view_count":194.0,
        "Owner_creation_time":1336005137536,
        "Owner_last_access_time":1663876727532,
        "Owner_reputation":752.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":4.0,
        "Owner_views":117.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69282549",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: unable to schedule training job to  aks cluster; content:<p>i am using the preview feature of configuring an aks cluster via arc in  studio and attempting to submit a job for training however it gets stuck in queued state with the following message:<\/p>\n<p><em>queue information : job is waiting for available resources, that required for 1 instance with 1.00 vcpu(s), 4.00 gb memory and 0 gpu(s). the best-fit compute can only provide 1.90 vcpu(s), 4.46 gb memory and 0 gpu(s). please continue to wait or change to a smaller instance type<\/em><\/p>\n<p>i am not too sure exactly what this is telling me because (aside from the grammar) the job requirements are less than what is available so why is it blocking? also its telling me to change to a smaller instance type, which i did and it still gave me the same.<\/p>\n<p>anyone come across this or know how to get past it?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to schedule a training job to an AKS cluster and is receiving a message that the job requirements are less than what is available, but the job is still blocked."
    },
    {
        "Question_id":70515292.0,
        "Question_title":"How to create SageMaker Studio environment from CLI?",
        "Question_body":"<p>I can create SageMaker Notebook instance from <code>aws sagemaker create-notebook-instance --notebook-instance-name test-123<\/code><br \/>\nbut I can't find a similiar CLI command to create a <strong>&quot;SageMaker Studio&quot;<\/strong> instance?<\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1640753939010,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "jupyter-notebook",
            "amazon-sagemaker"
        ],
        "Question_view_count":247.0,
        "Owner_creation_time":1513169810216,
        "Owner_last_access_time":1663827622683,
        "Owner_reputation":409.0,
        "Owner_up_votes":25.0,
        "Owner_down_votes":0.0,
        "Owner_views":54.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70515292",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to create  studio environment from cli?; content:<p>i can create  notebook instance from <code> create-notebook-instance --notebook-instance-name test-123<\/code><br \/>\nbut i can't find a similiar cli command to create a <strong>&quot; studio&quot;<\/strong> instance?<\/p>\n<p>thanks<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a CLI command to create a \"studio\" instance, but cannot find one."
    },
    {
        "Question_id":null,
        "Question_title":"By default, does Sagemaker endpoint handles parallel requests?",
        "Question_body":"When there are multiple concurrent InvokeEndpoint requests being called to a deployed AWS Sagemaker endpoint, how is it being handled?\n\nI have deployed an endpoint with a P3.2xlarge instance. Currently one job takes around ~45 seconds to process. I have tried sending 4 different InvokeEndpoint requests at the same time and I noticed from CloudWatch logs that the jobs are being done serially depending on which request arrives first. --I suspect there is some sort of queue internally within the server model itself.--\n\nI am aware of automatic scaling as described here: https:\/\/aws.amazon.com\/\/blogs\/machine-learning\/load-test-and-optimize-an-amazon-sagemaker-endpoint-using-automatic-scaling\/ but my question is by default does aws sagemaker not allow concurrent requests being handled at the same time?\n\nUPDATE\nUpon further investigation and testing here are some additional information.\nI have deployed an ml.m4xlarge instance that simply sleeps for 45 seconds inside the transform function. Looks somewhat like\n\ndef transform_fn(model, request_body, content_type, accept_type):       \r\n    request_body_dict = json.loads(request_body)\r\n    time.sleep(45)\r\n    ...\n\n\nFurthermore, I have set the server timeout to be 420 seconds like so.\n\nsagemaker_model = MXNetModel(model_data = 's3:\/\/' + sagemaker_session.default_bucket() + '\/model\/yolo_object_person_detector.tar.gz',\r\n                             role = role, \r\n                             entry_point = 'load_testing_entrypoint.py',\r\n                             py_version='py3',\r\n                             framework_version='1.4.1',\r\n                             sagemaker_session = sagemaker_session,\r\n                            env = {'SAGEMAKER_MODEL_SERVER_TIMEOUT' : '420' })\r\n\r\npredictor = sagemaker_model.deploy(\r\n                            initial_instance_count=1,\r\n                            instance_type='ml.m4.xlarge',\r\n                            endpoint_name='load-testing')\n\n\nI tried sending 9 consecutive requests and monitored how they are being executed and what I've found is that there is no specific order in which the requests are being handled.\n\nA few questions I have from this experiment is:\n\nDoes AWS Sagemaker not process requests concurrently? Meaning, I would expect the server being able to handle two requests at the same time?\nFrom the client's side, how is it handling the case when the server is busy? I notice that it internally does retries for about 3 times after every 60 seconds if the request is not being handled\nWithin each of the 60 seconds time window, how is the client code calling the Endpoint? Is it constantly calling after every 1,2,4,6,8 seconds ?\n\nHere is the client side code\n\nsagemaker_client = boto3.client('sagemaker-runtime')\r\nresponse = sagemaker_client.invoke_endpoint(EndpointName='load-testing',Body=request_body)\n\n\nEdited by: ptanugraha on Nov 14, 2019 10:44 AM",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1573757044000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker"
        ],
        "Question_view_count":319.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUfOh3ije6SsGZ-xrzRz0xzg\/by-default-does-sagemaker-endpoint-handles-parallel-requests",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-05-21T19:01:30.000Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for trying SageMaker and our apologies for late response.\n\nDoes AWS Sagemaker not process requests concurrently? Meaning, I would expect the server being able to handle two requests at the same time?\nAnswer: SageMaker does process requests concurrently. We keep sending the requests to model container as we get them and does not enqueue. However, we do have throttling in place which can kick in if there are too many requests coming which the endpoint is not able to handle. In case of throttling you will get the error response immediately. Here it is possible that your model is processing the requests sequentially. I suggest please test your model container locally with concurrent requests.\n\nFrom the client's side, how is it handling the case when the server is busy? I notice that it internally does retries for about 3 times after every 60 seconds if the request is not being handled\n\nWithin each of the 60 seconds time window, how is the client code calling the Endpoint? Is it constantly calling after every 1,2,4,6,8 seconds ?\nAnswer: For these you can refer to aws sdk client configuration:\nhttps:\/\/botocore.amazonaws.com\/v1\/documentation\/api\/latest\/reference\/config.html\nhttps:\/\/docs.aws.amazon.com\/AWSJavaSDK\/latest\/javadoc\/com\/amazonaws\/ClientConfiguration.html\nTo answer your question, api call will wait for the response. If it gets any exception or timeout then it will do the retry depending on the retry policy you set for the sdk client configuration.\n\nThanks\n\nEdited by: harishataws on May 21, 2020 12:01 PM",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: by default, does  endpoint handles parallel requests?; content:when there are multiple concurrent invokeendpoint requests being called to a deployed  endpoint, how is it being handled?\n\ni have deployed an endpoint with a p3.2xlarge instance. currently one job takes around ~45 seconds to process. i have tried sending 4 different invokeendpoint requests at the same time and i noticed from cloudwatch logs that the jobs are being done serially depending on which request arrives first. --i suspect there is some sort of queue internally within the server model itself.--\n\ni am aware of automatic scaling as described here: https:\/\/aws.amazon.com\/\/blogs\/machine-learning\/load-test-and-optimize-an-amazon--endpoint-using-automatic-scaling\/ but my question is by default does  not allow concurrent requests being handled at the same time?\n\nupdate\nupon further investigation and testing here are some additional information.\ni have deployed an ml.m4xlarge instance that simply sleeps for 45 seconds inside the transform function. looks somewhat like\n\ndef transform_fn(model, request_body, content_type, accept_type):       \r\n    request_body_dict = json.loads(request_body)\r\n    time.sleep(45)\r\n    ...\n\n\nfurthermore, i have set the server timeout to be 420 seconds like so.\n\n_model = mxnetmodel(model_data = 's3:\/\/' + _session.default_bucket() + '\/model\/yolo_object_person_detector.tar.gz',\r\n                             role = role, \r\n                             entry_point = 'load_testing_entrypoint.py',\r\n                             py_version='py3',\r\n                             framework_version='1.4.1',\r\n                             _session = _session,\r\n                            env = {'_model_server_timeout' : '420' })\r\n\r\npredictor = _model.deploy(\r\n                            initial_instance_count=1,\r\n                            instance_type='ml.m4.xlarge',\r\n                            endpoint_name='load-testing')\n\n\ni tried sending 9 consecutive requests and monitored how they are being executed and what i've found is that there is no specific order in which the requests are being handled.\n\na few questions i have from this experiment is:\n\ndoes  not process requests concurrently? meaning, i would expect the server being able to handle two requests at the same time?\nfrom the client's side, how is it handling the case when the server is busy? i notice that it internally does retries for about 3 times after every 60 seconds if the request is not being handled\nwithin each of the 60 seconds time window, how is the client code calling the endpoint? is it constantly calling after every 1,2,4,6,8 seconds ?\n\nhere is the client side code\n\n_client = boto3.client('-runtime')\r\nresponse = _client.invoke_endpoint(endpointname='load-testing',body=request_body)\n\n\nedited by: ptanugraha on nov 14, 2019 10:44 am",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user has deployed an endpoint with a p3.2xlarge instance and noticed that multiple concurrent invokeendpoint requests are being handled serially. They are aware of automatic scaling, but are wondering if by default, does  handle parallel requests. After further investigation and testing, they found that there is no specific order in which the requests are being handled and are wondering if  processes requests concurrently and how the client code is calling the endpoint."
    },
    {
        "Question_id":null,
        "Question_title":"How to export tresained models to ECR as container image",
        "Question_body":"I want to train and build the model in Sagemaker studio and then be able to export the model as a container image to ECR, so I can use the model in external platform by sharing the ECR image to another account where I Can create container with the image from ECR",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1663258467464,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Amazon Elastic Container Registry (ECR)",
            "Containers",
            "Amazon SageMaker Studio Lab"
        ],
        "Question_view_count":29.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUZHWz5-hpSc-80dEIkuxwQw\/how-to-export-tresained-models-to-ecr-as-container-image",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI",
            "Containers"
        ],
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-16T23:05:33.114Z",
                "Answer_score":0,
                "Answer_body":"The models you train in SageMaker are stored in S3 as .tar.gz files that you can use to deploy to an endpoint, or even test locally (extracting the model file from the tar file). If you are using a built-in algorithm, you can share the .tar.gz file to the second account and deploy the model in the second account, since built-in algorithm containers can be accessed from any AWS account.\n\nIf you are using a custom training image (docs here), you can push this image to ECR and allow a second account to pull the image and then use the image with the model that you have trained. However, note that Studio at this time does not support building Docker images out of the box. You can use SageMaker Notebook Instances instead.\n\nI would recommend keeping the model (.tar.gz) and the image (Docker) separate, since you can easily retrain and deploy the newer versions of models without updating the image every single time.",
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to export tresained models to ecr as container image; content:i want to train and build the model in  studio and then be able to export the model as a container image to ecr, so i can use the model in external platform by sharing the ecr image to another account where i can create container with the image from ecr",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to train and build a model in Studio and then export it as a container image to ECR, so they can use the model in an external platform by sharing the ECR image to another account."
    },
    {
        "Question_id":70252478.0,
        "Question_title":"Azure Machine Learning Designer Error: JobConfigurationMaxSizeExceeded",
        "Question_body":"<p>I have an Azure Machine Learning Designer pipeline that I've run successfully many dozens of times.  Suddenly, today, The pipeline is getting down to the 'Train Model' node and failing with the following error:<\/p>\n<p><code>JobConfigurationMaxSizeExceeded: The specified job configuration exceeds the max allowed size of 32768 characters. Please reduce the size of the job's command line arguments and environment settings<\/code><\/p>\n<p>How do I address this error in designer-built pipelines?<\/p>\n<p>I have even gone back to previously successful runs of this pipeline and resubmitted one of these runs which also failed with the exact same error.  A resubmitted run should have the exact same pipeline architecture and input data (afaik), so it seems like a problem outside my control.<\/p>\n<p>Pipeline with error:\n<a href=\"https:\/\/i.stack.imgur.com\/uLoIe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uLoIe.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Pipeline run overview:\n<a href=\"https:\/\/i.stack.imgur.com\/eTzTA.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eTzTA.png\" alt=\"enter image description here\" \/><\/a>\nAny ideas?<\/p>\n<p>EDIT:  I'm able to repro this with a really simple pipeline.  Simply trying to exclude columns in a <code>Select Columns<\/code> node from a dataset gives me this error:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qZKj1.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qZKj1.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1638827883783,
        "Question_favorite_count":null,
        "Question_score":3.0,
        "Question_tags":[
            "azure-machine-learning-studio"
        ],
        "Question_view_count":358.0,
        "Owner_creation_time":1340833876128,
        "Owner_last_access_time":1663795160110,
        "Owner_reputation":751.0,
        "Owner_up_votes":68.0,
        "Owner_down_votes":5.0,
        "Owner_views":73.0,
        "Answer_body":"<p>This appears to be a bug introduced by Microsoft's rollout of their new Compute Common Runtime.<\/p>\n<p>If I go into any nodes failing with the <code>JobConfigurationMaxSizeExceeded<\/code> exception and manually set <code>AZUREML_COMPUTE_USE_COMMON_RUNTIME:false<\/code> in their  <code>Environment JSON<\/code> field, then they work correctly.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1638852273883,
        "Answer_score":2.0,
        "Owner_location":null,
        "Question_last_edit_time":1638837173276,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70252478",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  designer error: jobconfigurationmaxsizeexceeded; content:<p>i have an  designer pipeline that i've run successfully many dozens of times.  suddenly, today, the pipeline is getting down to the 'train model' node and failing with the following error:<\/p>\n<p><code>jobconfigurationmaxsizeexceeded: the specified job configuration exceeds the max allowed size of 32768 characters. please reduce the size of the job's command line arguments and environment settings<\/code><\/p>\n<p>how do i address this error in designer-built pipelines?<\/p>\n<p>i have even gone back to previously successful runs of this pipeline and resubmitted one of these runs which also failed with the exact same error.  a resubmitted run should have the exact same pipeline architecture and input data (afaik), so it seems like a problem outside my control.<\/p>\n<p>pipeline with error:\n<a href=\"https:\/\/i.stack.imgur.com\/uloie.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uloie.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>pipeline run overview:\n<a href=\"https:\/\/i.stack.imgur.com\/etzta.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/etzta.png\" alt=\"enter image description here\" \/><\/a>\nany ideas?<\/p>\n<p>edit:  i'm able to repro this with a really simple pipeline.  simply trying to exclude columns in a <code>select columns<\/code> node from a dataset gives me this error:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qzkj1.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qzkj1.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an error with their designer pipeline, where the job configuration exceeds the max allowed size of 32768 characters. They have attempted to resubmit a previously successful run, but the same error persists."
    },
    {
        "Question_id":null,
        "Question_title":"Dvc push to public S3 bucket",
        "Question_body":"<p>Hello there. I\u2019m excited to try DVC\u2019s features but I\u2019m stuck with a basic problem in S3. Ideally, I\u2019d like to push to a private S3 bucket, which I could do with <code>aws-vault<\/code>. Before doing that, I wanted to check how that would work in a public bucket. But when I try to push to a public S3, I get:<\/p>\n<pre><code>$ dvc remote list\nstorage\ts3:\/\/ml-ci\nhttps3\thttps:\/\/ml-ci.s3.amazonaws.com\/\n\n$ dvc push -r storage\nERROR: unexpected error - An error occurred (403) when calling the HeadObject operation: Forbidden\n<\/code><\/pre>\n<p>So I thought I\u2019d try a suggestion from another thread on this forum and add a HTTPS remote endpoint instead (though I know it was suggested as a read-only solution):<\/p>\n<pre><code>$ dvc push -r https3\nERROR: failed to upload '.dvc\/cache\/a3\/04afb96060aad9017xxxx' to 'https:\/\/ml-ci.s3.amazonaws.com\/a3\/04afb96060aad9017xxxx' - could not perform a POST request\nERROR: failed to push data to the cloud - 1 files failed to upload\n<\/code><\/pre>\n<p>What am I doing incorrectly here with remote setup? Is private + <code>aws-vault<\/code> the only option? I\u2019d really appreciate some help, thank you!<\/p>",
        "Question_answer_count":7,
        "Question_comment_count":null,
        "Question_creation_time":1595914363359,
        "Question_favorite_count":null,
        "Question_score":4.0,
        "Question_tags":null,
        "Question_view_count":2481.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/dvc-push-to-public-s3-bucket\/457",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":1022,
                "name":"LB",
                "username":"braaannigan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/b\/ccd318\/{size}.png",
                "created_at":"2020-07-28T13:47:42.512Z",
                "cooked":"<p>I\u2019m having a similar issue with pushing to a private bucket. It might be related to IAM roles.<\/p>\n<p>In my case I also get a 404 when I do <code>dvc push<\/code>. I get the same error if I just run <code>aws s3 ls s3:\/\/bucket-name<\/code>.<\/p>\n<p>However, if I add my work profile name it works: <code>aws s3 ls s3:\/\/bucket-name --profile work-profile<\/code><\/p>\n<p>I\u2019ve tried setting the AWS_PROFILE env variable to <code>work-profile<\/code>, but nothing changes. Any idea how I force it to see the right profile?<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2020-07-28T13:47:42.512Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":17,
                "reads":16,
                "readers_count":15,
                "score":83.2,
                "yours":false,
                "topic_id":457,
                "topic_slug":"dvc-push-to-public-s3-bucket",
                "display_username":"LB",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":166,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1023,
                "name":"Ruslan Kuprieiev",
                "username":"kupruser",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/e95f7d\/{size}.png",
                "created_at":"2020-07-28T13:55:08.128Z",
                "cooked":"<p><a class=\"mention\" href=\"\/u\/sumita\">@sumita<\/a> Are you able to use <code>aws<\/code> CLI utility with it?<\/p>\n<p><a class=\"mention\" href=\"\/u\/braaannigan\">@braaannigan<\/a> How do you set AWS_PROFILE env var? If awscli with <code>--profile<\/code> works, then dvc also should. We have a <code>profile<\/code> config option <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify\">https:\/\/dvc.org\/doc\/command-reference\/remote\/modify<\/a> , e.g.:<\/p>\n<pre><code class=\"lang-auto\">dvc remote modify myremote profile work-profile\n<\/code><\/pre>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2020-07-28T13:55:08.128Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":16,
                "reads":16,
                "readers_count":15,
                "score":88.2,
                "yours":false,
                "topic_id":457,
                "topic_slug":"dvc-push-to-public-s3-bucket",
                "display_username":"Ruslan Kuprieiev",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify",
                        "internal":false,
                        "reflection":false,
                        "clicks":20
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":3,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1024,
                "name":"LB",
                "username":"braaannigan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/b\/ccd318\/{size}.png",
                "created_at":"2020-07-28T14:02:21.072Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/kupruser\">@kupruser<\/a><\/p>\n<p>I\u2019ve found the answer on an old thread (with a slight modification of the credential path):<br>\ndvc remote modify myremote credentialpath ~\/.aws\/credentials<br>\ndvc remote modify myremote profile profile-name<\/p>\n<p>Thanks<\/p>",
                "post_number":4,
                "post_type":1,
                "updated_at":"2020-07-28T14:02:21.072Z",
                "reply_count":0,
                "reply_to_post_number":3,
                "quote_count":0,
                "incoming_link_count":60,
                "reads":15,
                "readers_count":14,
                "score":348.0,
                "yours":false,
                "topic_id":457,
                "topic_slug":"dvc-push-to-public-s3-bucket",
                "display_username":"LB",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"kupruser",
                    "name":"Ruslan Kuprieiev",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/e95f7d\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":166,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1050,
                "name":"",
                "username":"sumita",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/34f0e0\/{size}.png",
                "created_at":"2020-08-09T16:56:07.055Z",
                "cooked":"<p>I eventually solved this with aws-vault, but I missed that there\u2019s documentation about how to use dvc remote to add credentials here: <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#available-parameters-per-storage-type\" rel=\"nofollow noopener\">https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#available-parameters-per-storage-type<\/a>.<\/p>\n<p>Thank you!<\/p>",
                "post_number":5,
                "post_type":1,
                "updated_at":"2020-08-09T16:56:07.055Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":7,
                "reads":11,
                "readers_count":10,
                "score":82.2,
                "yours":false,
                "topic_id":457,
                "topic_slug":"dvc-push-to-public-s3-bucket",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/dvc.org\/doc\/command-reference\/remote\/modify#available-parameters-per-storage-type",
                        "internal":false,
                        "reflection":false,
                        "clicks":78
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":165,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1057,
                "name":"Jorge Orpinel Perez",
                "username":"jorgeorpinel",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/jorgeorpinel\/{size}\/46_2.png",
                "created_at":"2020-08-15T03:18:05.533Z",
                "cooked":"<p>Hi!<\/p>\n<p>I\u2019ve added this comment about improving the S3 remote error:<\/p>\n<aside class=\"onebox githubissue\">\n  <header class=\"source\">\n      <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/3050#issuecomment-674340656\" target=\"_blank\" rel=\"noopener\">github.com\/iterative\/dvc<\/a>\n  <\/header>\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewBox=\"0 0 14 16\" aria-hidden=\"true\"><path d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"><\/path><\/svg>\n  <\/div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https:\/\/github.com\/iterative\/dvc\/issues\/3050#issuecomment-674340656\" target=\"_blank\" rel=\"noopener\">exceptions: general refactor<\/a>\n    <\/h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-01-03\" data-time=\"21:04:37\" data-timezone=\"UTC\">09:04PM - 03 Jan 20 UTC<\/span>\n      <\/div>\n\n\n      <div class=\"user\">\n        <a href=\"https:\/\/github.com\/mroutis\" target=\"_blank\" rel=\"noopener\">\n          <img alt=\"mroutis\" src=\"https:\/\/avatars0.githubusercontent.com\/u\/7363250?v=4\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          mroutis\n        <\/a>\n      <\/div>\n    <\/div>\n  <\/div>\n<\/div>\n\n<div class=\"github-row\">\n  <p class=\"github-content\">Improving exceptions would bring a better experience to DVC users and developers:\n\nMove exceptions to a single module (dvc\/exceptions.py), there would be...<\/p>\n<\/div>\n\n<div class=\"labels\">\n    <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">discussion<\/span>\n    <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">p3-nice-to-have<\/span>\n    <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">refactoring<\/span>\n<\/div>\n\n  <\/article>\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>Thanks<\/p>",
                "post_number":6,
                "post_type":1,
                "updated_at":"2020-08-15T03:18:05.533Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":52,
                "reads":9,
                "readers_count":8,
                "score":261.8,
                "yours":false,
                "topic_id":457,
                "topic_slug":"dvc-push-to-public-s3-bucket",
                "display_username":"Jorge Orpinel Perez",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/github.com\/iterative\/dvc\/issues\/3050#issuecomment-674340656",
                        "internal":false,
                        "reflection":false,
                        "title":"exceptions: general refactor \u00b7 Issue #3050 \u00b7 iterative\/dvc \u00b7 GitHub",
                        "clicks":14
                    },
                    {
                        "url":"https:\/\/github.com\/mroutis",
                        "internal":false,
                        "reflection":false,
                        "title":"mroutis (Ram\u00f3n Valles) \u00b7 GitHub",
                        "clicks":0
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":80,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1058,
                "name":"Jorge Orpinel Perez",
                "username":"jorgeorpinel",
                "avatar_template":"\/user_avatar\/discuss.dvc.org\/jorgeorpinel\/{size}\/46_2.png",
                "created_at":"2020-08-15T04:01:55.065Z",
                "cooked":"<p>p.s. <a class=\"mention\" href=\"\/u\/sumita\">@sumita<\/a> you might want to take a look at <a href=\"https:\/\/github.com\/iterative\/dvc.org\/issues\/1699\">https:\/\/github.com\/iterative\/dvc.org\/issues\/1699<\/a> and <a href=\"https:\/\/github.com\/iterative\/dvc.org\/issues\/1700\">https:\/\/github.com\/iterative\/dvc.org\/issues\/1700<\/a>.<\/p>\n<p><a href=\"https:\/\/dvc.org\/doc\/user-guide\/contributing\/docs\">Docs contributors<\/a> are welcome! <img src=\"https:\/\/emoji.discourse-cdn.com\/apple\/slightly_smiling_face.png?v=9\" title=\":slightly_smiling_face:\" class=\"emoji\" alt=\":slightly_smiling_face:\"><\/p>",
                "post_number":7,
                "post_type":1,
                "updated_at":"2020-08-15T04:02:03.565Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":7,
                "reads":7,
                "readers_count":6,
                "score":41.4,
                "yours":false,
                "topic_id":457,
                "topic_slug":"dvc-push-to-public-s3-bucket",
                "display_username":"Jorge Orpinel Perez",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/github.com\/iterative\/dvc.org\/issues\/1699",
                        "internal":false,
                        "reflection":false,
                        "title":"remote: better prioritize and highlight common config options \u00b7 Issue #1699 \u00b7 iterative\/dvc.org \u00b7 GitHub",
                        "clicks":64
                    },
                    {
                        "url":"https:\/\/github.com\/iterative\/dvc.org\/issues\/1700",
                        "internal":false,
                        "reflection":false,
                        "title":"run: simplify intro. examples leaving bare min. usage \u00b7 Issue #1700 \u00b7 iterative\/dvc.org \u00b7 GitHub",
                        "clicks":43
                    },
                    {
                        "url":"https:\/\/dvc.org\/doc\/user-guide\/contributing\/docs",
                        "internal":false,
                        "reflection":false,
                        "clicks":3
                    }
                ],
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":80,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":1060,
                "name":"",
                "username":"sumita",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/s\/34f0e0\/{size}.png",
                "created_at":"2020-08-17T16:49:20.896Z",
                "cooked":"<p>Thanks so much <a class=\"mention\" href=\"\/u\/jorgeorpinel\">@jorgeorpinel<\/a>!  I looked at both the issues and the comments you left on the post (which I\u2019ll respond to there). The issues make sense and I look forward to those enhancements - thanks again.<\/p>",
                "post_number":8,
                "post_type":1,
                "updated_at":"2020-08-17T16:49:20.896Z",
                "reply_count":0,
                "reply_to_post_number":7,
                "quote_count":0,
                "incoming_link_count":4,
                "reads":7,
                "readers_count":6,
                "score":36.4,
                "yours":false,
                "topic_id":457,
                "topic_slug":"dvc-push-to-public-s3-bucket",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"jorgeorpinel",
                    "name":"Jorge Orpinel Perez",
                    "avatar_template":"\/user_avatar\/discuss.dvc.org\/jorgeorpinel\/{size}\/46_2.png"
                },
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":165,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  push to public s3 bucket; content:<p>hello there. i\u2019m excited to try \u2019s features but i\u2019m stuck with a basic problem in s3. ideally, i\u2019d like to push to a private s3 bucket, which i could do with <code>aws-vault<\/code>. before doing that, i wanted to check how that would work in a public bucket. but when i try to push to a public s3, i get:<\/p>\n<pre><code>$  remote list\nstorage\ts3:\/\/ml-ci\nhttps3\thttps:\/\/ml-ci.s3.amazonaws.com\/\n\n$  push -r storage\nerror: unexpected error - an error occurred (403) when calling the headobject operation: forbidden\n<\/code><\/pre>\n<p>so i thought i\u2019d try a suggestion from another thread on this forum and add a https remote endpoint instead (though i know it was suggested as a read-only solution):<\/p>\n<pre><code>$  push -r https3\nerror: failed to upload '.\/cache\/a3\/04afb96060aad9017xxxx' to 'https:\/\/ml-ci.s3.amazonaws.com\/a3\/04afb96060aad9017xxxx' - could not perform a post request\nerror: failed to push data to the cloud - 1 files failed to upload\n<\/code><\/pre>\n<p>what am i doing incorrectly here with remote setup? is private + <code>aws-vault<\/code> the only option? i\u2019d really appreciate some help, thank you!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty pushing to a public S3 bucket and is wondering if private + aws-vault is the only option."
    },
    {
        "Question_id":62057838.0,
        "Question_title":"How to retrieve the labels used in a segmentation mask in AWS Sagemaker",
        "Question_body":"<p>From a segmentation mask, I am trying to retrieve what labels are being represented in the mask. <\/p>\n\n<p>This is the image I am running through a semantic segmentation model in AWS Sagemaker.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/XbMMP.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XbMMP.png\" alt=\"Motorbike and everything else background\"><\/a><\/p>\n\n<p>Code for making prediction and displaying mask.<\/p>\n\n<pre><code>from sagemaker.predictor import json_serializer, json_deserializer, RealTimePredictor\nfrom sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n\n%%time\nss_predict = sagemaker.RealTimePredictor(endpoint=ss_model.endpoint_name, \n                                     sagemaker_session=sess,\n                                    content_type = 'image\/jpeg',\n                                    accept = 'image\/png')\n\nreturn_img = ss_predict.predict(img)\n\nfrom PIL import Image\nimport numpy as np\nimport io\n\nnum_labels = 21\nmask = np.array(Image.open(io.BytesIO(return_img)))\nplt.imshow(mask, vmin=0, vmax=num_labels-1, cmap='jet')\nplt.show()\n<\/code><\/pre>\n\n<p>This image is the segmentation mask that was created and it represents the motorbike and everything else is the background.<\/p>\n\n<p>[<img src=\"https:\/\/i.stack.imgur.com\/6FbVn.png\" alt=\"Segmented mask[2]\"><\/p>\n\n<p>As you can see from the code there are 21 possible labels and 2 were used in the mask, one for the motorbike and another for the background. What I would like to figure out now is how to print which labels were actually used in this mask out of the 21 possible options?<\/p>\n\n<p>Please let me know if you need any further information and any help is much appreciated. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1590644898463,
        "Question_favorite_count":1.0,
        "Question_score":8.0,
        "Question_tags":[
            "python",
            "python-imaging-library",
            "amazon-sagemaker",
            "mxnet",
            "semantic-segmentation"
        ],
        "Question_view_count":489.0,
        "Owner_creation_time":1449513251820,
        "Owner_last_access_time":1629436707116,
        "Owner_reputation":693.0,
        "Owner_up_votes":47.0,
        "Owner_down_votes":0.0,
        "Owner_views":56.0,
        "Answer_body":"<p>Somewhere you should have a mapping from label integers to label classes, e.g.<\/p>\n\n<pre><code>label_map = {0: 'background', 1: 'motorbike', 2: 'train', ...}\n<\/code><\/pre>\n\n<p>If you are using the Pascal VOC dataset, that would be (1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle, 6=bus, 7=car , 8=cat, 9=chair, 10=cow, 11=diningtable, 12=dog, 13=horse, 14=motorbike, 15=person, 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv\/monitor) - see here: <a href=\"http:\/\/host.robots.ox.ac.uk\/pascal\/VOC\/voc2012\/segexamples\/index.html\" rel=\"nofollow noreferrer\">http:\/\/host.robots.ox.ac.uk\/pascal\/VOC\/voc2012\/segexamples\/index.html<\/a><\/p>\n\n<p>Then you can simply use that map:<\/p>\n\n<pre><code>used_classes = np.unique(mask)\nfor cls in used_classes:\n    print(\"Found class: {}\".format(label_map[cls]))\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1592390011563,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62057838",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to retrieve the labels used in a segmentation mask in ; content:<p>from a segmentation mask, i am trying to retrieve what labels are being represented in the mask. <\/p>\n\n<p>this is the image i am running through a semantic segmentation model in .<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/xbmmp.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/xbmmp.png\" alt=\"motorbike and everything else background\"><\/a><\/p>\n\n<p>code for making prediction and displaying mask.<\/p>\n\n<pre><code>from .predictor import json_serializer, json_deserializer, realtimepredictor\nfrom .content_types import content_type_csv, content_type_json\n\n%%time\nss_predict = .realtimepredictor(endpoint=ss_model.endpoint_name, \n                                     _session=sess,\n                                    content_type = 'image\/jpeg',\n                                    accept = 'image\/png')\n\nreturn_img = ss_predict.predict(img)\n\nfrom pil import image\nimport numpy as np\nimport io\n\nnum_labels = 21\nmask = np.array(image.open(io.bytesio(return_img)))\nplt.imshow(mask, vmin=0, vmax=num_labels-1, cmap='jet')\nplt.show()\n<\/code><\/pre>\n\n<p>this image is the segmentation mask that was created and it represents the motorbike and everything else is the background.<\/p>\n\n<p>[<img src=\"https:\/\/i.stack.imgur.com\/6fbvn.png\" alt=\"segmented mask[2]\"><\/p>\n\n<p>as you can see from the code there are 21 possible labels and 2 were used in the mask, one for the motorbike and another for the background. what i would like to figure out now is how to print which labels were actually used in this mask out of the 21 possible options?<\/p>\n\n<p>please let me know if you need any further information and any help is much appreciated. <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to retrieve the labels used in a segmentation mask from an image and display them out of the 21 possible options."
    },
    {
        "Question_id":73412804.0,
        "Question_title":"Load testing of endpoint in Azure ML",
        "Question_body":"<p>I wanted to load test a deployed model endpoint and add it to an MLOps framework, so that new deployed models can go through load testing. I tried Azure load testing resource for web app but I think it is just for static content. Also, I saw a python package - locust which seems promising. Is there any other approach?\u00a0<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1660891473553,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "deployment",
            "endpoint",
            "azure-machine-learning-service",
            "azure-deployment"
        ],
        "Question_view_count":35.0,
        "Owner_creation_time":1562319822372,
        "Owner_last_access_time":1663945268727,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":9.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1661318531123,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73412804",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: load testing of endpoint in ; content:<p>i wanted to load test a deployed model endpoint and add it to an mlops framework, so that new deployed models can go through load testing. i tried azure load testing resource for web app but i think it is just for static content. also, i saw a python package - locust which seems promising. is there any other approach?\u00a0<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to load test a deployed model endpoint and add it to an MLOps framework, and has tried Azure Load Testing Resource for Web App and the Python package Locust."
    },
    {
        "Question_id":null,
        "Question_title":"Exposing a non CLI API",
        "Question_body":"<p>Hi,<\/p>\n<p>Is there any plan to expose a pure python API so that DVC commands can be run directly within a python script ? (At the moment, I am building a pipeline based on a series of subprocesses that call the various DVC commands, but development \/ debugging would be smoother if I could directly call the underlying python code).<\/p>\n<p>It is probably already possible, but there are no examples in the documentation about this use case.<\/p>\n<p>Thanks !<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1536759195852,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":479.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/discuss.dvc.org\/t\/exposing-a-non-cli-api\/95",
        "Tool":"DVC",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":186,
                "name":"Ruslan Kuprieiev",
                "username":"kupruser",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/e95f7d\/{size}.png",
                "created_at":"2018-09-12T13:53:51.134Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/tmain\">@tmain<\/a> !<\/p>\n<p>We do have an internal python API( <code>dvc\/project.py<\/code> ), but it is not stable, not documented and thus not yet ready to be relied on. The only API that is stable and for which we guarantee backward compatibility is CLI(that being said it will also change in the next major release v1.0 which we\u2019ve planned a lot of improvements for). Considering that the CLI will be changed in v1.0, python API will be changed as well, so it makes sense to stabilize it for 1.0. We plan to release 1.0 in the nearest future.<\/p>\n<p>Thanks,<br>\nRuslan<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2018-09-12T13:53:51.134Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":51.2,
                "yours":false,
                "topic_id":95,
                "topic_slug":"exposing-a-non-cli-api",
                "display_username":"Ruslan Kuprieiev",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":3,
                "hidden":false,
                "trust_level":2,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":188,
                "name":"",
                "username":"tmain",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/t\/2acd7d\/{size}.png",
                "created_at":"2018-09-12T14:05:42.493Z",
                "cooked":"<p>Excellent news, will look forward to it !<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2018-09-12T14:05:42.493Z",
                "reply_count":0,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":6,
                "readers_count":5,
                "score":1.2,
                "yours":false,
                "topic_id":95,
                "topic_slug":"exposing-a-non-cli-api",
                "display_username":"",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"kupruser",
                    "name":"Ruslan Kuprieiev",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/k\/e95f7d\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":35,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":true,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: exposing a non cli api; content:<p>hi,<\/p>\n<p>is there any plan to expose a pure python api so that  commands can be run directly within a python script ? (at the moment, i am building a pipeline based on a series of subprocesses that call the various  commands, but development \/ debugging would be smoother if i could directly call the underlying python code).<\/p>\n<p>it is probably already possible, but there are no examples in the documentation about this use case.<\/p>\n<p>thanks !<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if there is a plan to expose a pure Python API so that commands can be run directly within a Python script, as this would make development and debugging easier."
    },
    {
        "Question_id":62441146.0,
        "Question_title":"Revert a dvc remove -p command",
        "Question_body":"<p>I have just removed a DVC tracking file by mistake using the command <code>dvc remove training_data.dvc -p<\/code>, which led to all my training dataset gone completely. I know in Git, we can easily revert a deleted branch based on its hash. Does anyone know how to revert all my lost data in DVC?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1592445622650,
        "Question_favorite_count":null,
        "Question_score":3.0,
        "Question_tags":[
            "dvc"
        ],
        "Question_view_count":687.0,
        "Owner_creation_time":1467943515392,
        "Owner_last_access_time":1664083114540,
        "Owner_reputation":173.0,
        "Owner_up_votes":97.0,
        "Owner_down_votes":0.0,
        "Owner_views":28.0,
        "Answer_body":"<p>You should be safe (at least data is not gone) most likely. From the <code>dvc remove<\/code> <a href=\"https:\/\/dvc.org\/doc\/command-reference\/remove\" rel=\"nofollow noreferrer\">docs<\/a>:<\/p>\n\n<blockquote>\n  <p>Note that it does not remove files from the DVC cache or remote storage (see dvc gc). However, remember to run <code>dvc push<\/code> to save the files you actually want to use or share in the future.<\/p>\n<\/blockquote>\n\n<p>So, if you created <code>training_data.dvc<\/code> as with <code>dvc add<\/code> and\/or <code>dvc run<\/code> and <code>dvc remove -p<\/code> didn't ask\/warn you about anything, means that data is cached similar to Git in the <code>.dvc\/cache<\/code>. <\/p>\n\n<p>There are ways to retrieve it, but I would need to know a little bit more details - how exactly did you add your dataset? Did you commit <code>training_data.dvc<\/code> or it's completely gone? Was it the only data you have added so far? (happy to help you in comments).<\/p>\n\n<h2>Recovering a directory<\/h2>\n\n<p>First of all, <a href=\"https:\/\/dvc.org\/doc\/user-guide\/dvc-files-and-directories#structure-of-cache-directory\" rel=\"nofollow noreferrer\">here<\/a> is the document that describes briefly how DVC stores directories in the cache.<\/p>\n\n<p>What we can do is to find all <code>.dir<\/code> files in the <code>.dvc\/cache<\/code>:<\/p>\n\n<p><code>find .dvc\/cache -type f -name \"*.dir\"<\/code><\/p>\n\n<p>outputs something like:<\/p>\n\n<pre><code>.dvc\/cache\/20\/b786b6e6f80e2b3fcf17827ad18597.dir\n.dvc\/cache\/00\/db872eebe1c914dd13617616bb8586.dir\n.dvc\/cache\/2d\/1764cb0fc973f68f31f5ff90ee0883.dir\n<\/code><\/pre>\n\n<p>(if the local cache is lost and we are restoring data from the remote storage, the same logic applies, commands (e.g. to find files on S3 with .dir extension) look different)<\/p>\n\n<p>Each <code>.dir<\/code> file is a JSON with a content of one version of a directory (file names, hashes, etc). It has all the information needed to restore it. The next thing we need to do is to understand which one do we need. There is no one single rule for that, what I would recommend to check (and pick depending on your use case):<\/p>\n\n<ul>\n<li>Check the date modified (if you remember when this data was added).<\/li>\n<li>Check the content of those files - if you remember a specific file name that was present only in the directory you are looking for - just grep it.<\/li>\n<li>Try to restore them one by one and check the directory content.<\/li>\n<\/ul>\n\n<p>Okay, now let's imagine we decided that we want to restore <code>.dvc\/cache\/20\/b786b6e6f80e2b3fcf17827ad18597.dir<\/code>, (e.g. because content of it looks like:<\/p>\n\n<pre><code>[\n{\"md5\": \"6f597d341ceb7d8fbbe88859a892ef81\", \"relpath\": \"test.tsv\"}, {\"md5\": \"32b715ef0d71ff4c9e61f55b09c15e75\", \"relpath\": \"train.tsv\"}\n]\n<\/code><\/pre>\n\n<p>and we want to get a directory with <code>train.tsv<\/code>).<\/p>\n\n<p>The only thing we need to do is to create a <code>.dvc<\/code> file that references this directory:<\/p>\n\n<pre class=\"lang-yaml prettyprint-override\"><code>outs:\n- md5: 20b786b6e6f80e2b3fcf17827ad18597.dir\n  path: my-directory\n<\/code><\/pre>\n\n<p>(note, that path \/20\/b786b6e6f80e2b3fcf17827ad18597.dir became a hash value: 20b786b6e6f80e2b3fcf17827ad18597.dir)<\/p>\n\n<p>And run <code>dvc pull<\/code> on this file.<\/p>\n\n<p>That should be it.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1592457436920,
        "Answer_score":3.0,
        "Owner_location":"Danang, H\u1ea3i Ch\u00e2u District, Da Nang, Vietnam",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":1592496929888,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62441146",
        "Tool":"DVC",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: revert a  remove -p command; content:<p>i have just removed a  tracking file by mistake using the command <code> remove training_data. -p<\/code>, which led to all my training dataset gone completely. i know in git, we can easily revert a deleted branch based on its hash. does anyone know how to revert all my lost data in ?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user mistakenly removed a tracking file using the command \"remove training_data. -p\" and is looking for a way to revert the lost data."
    },
    {
        "Question_id":null,
        "Question_title":"Structuring Code For Interruptible session",
        "Question_body":"<p>Looking to scale up my project to some cloud service, and it seems the prices are much cheaper for interruptible sessions.<\/p>\n<p>How do I use W&amp;B for an experiment (either a single train run or a HP sweep) in such an environment? Is there anything fancy needed to re-start a sweep where it left off?<\/p>\n<p>I\u2019m using Pytorch Lightning for the model\/trainer and hoping to use AWS\/Grid.ai\/other cloud service to scale up.<\/p>\n<p>Thanks,<br>\nMax<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1631972632591,
        "Question_favorite_count":null,
        "Question_score":5.0,
        "Question_tags":null,
        "Question_view_count":299.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/structuring-code-for-interruptible-session\/697",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":1729,
                "name":"Scott Condron",
                "username":"_scott",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/_scott\/{size}\/95_2.png",
                "created_at":"2021-09-18T20:49:55.589Z",
                "cooked":"<p>Hi Max!<\/p>\n<p>Here\u2019s some documentation on running wandb sweeps on preemptible instances.<\/p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming#preemptible-sweeps\">\n  <header class=\"source\">\n      <img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming#preemptible-sweeps\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai<\/a>\n  <\/header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690\/362;\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"><\/div>\n\n<h3><a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming#preemptible-sweeps\" target=\"_blank\" rel=\"noopener\">Resume Runs<\/a><\/h3>\n\n\n\n  <\/article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  <\/div>\n\n  <div style=\"clear: both\"><\/div>\n<\/aside>\n\n<p>I know I sent this on the PyTorch Lightning forum, but hopefully this\u2019ll help people who find this post.<\/p>\n<p>I\u2019d love to hear how you get on experimenting with this and PyTorch Lightning <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/zap.png?v=10\" title=\":zap:\" class=\"emoji\" alt=\":zap:\"><\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-09-18T20:49:55.589Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":16,
                "readers_count":15,
                "score":108.2,
                "yours":false,
                "topic_id":697,
                "topic_slug":"structuring-code-for-interruptible-session",
                "display_username":"Scott Condron",
                "primary_group_name":"team",
                "flair_name":"team",
                "flair_url":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/27bab8f920bcd41717e467ec0a2929adc33869e5.png",
                "flair_bg_color":"ffffff",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/resuming#preemptible-sweeps",
                        "internal":false,
                        "reflection":false,
                        "clicks":3
                    }
                ],
                "read":true,
                "user_title":"Community Team",
                "title_is_group":true,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":3
                    }
                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":85,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5321,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-04-20T18:02:05.366Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":3,
                "post_type":3,
                "updated_at":"2022-04-20T18:02:05.366Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":697,
                "topic_slug":"structuring-code-for-interruptible-session",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: structuring code for interruptible session; content:<p>looking to scale up my project to some cloud service, and it seems the prices are much cheaper for interruptible sessions.<\/p>\n<p>how do i use w&amp;b for an experiment (either a single train run or a hp sweep) in such an environment? is there anything fancy needed to re-start a sweep where it left off?<\/p>\n<p>i\u2019m using pytorch lightning for the model\/trainer and hoping to use aws\/grid.ai\/other cloud service to scale up.<\/p>\n<p>thanks,<br>\nmax<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking to scale up their project to a cloud service and is wondering how to use W&B for an experiment in an interruptible session, as well as if anything is needed to re-start a sweep where it left off."
    },
    {
        "Question_id":72214072.0,
        "Question_title":"How to time tigger a python script in the Azure ML notebooks",
        "Question_body":"<p>Hi I am currently working on a small image classification project where the model classifies whether the image contains potholes or not. For this section i have wrote the python script, and this script needs to be triggered at scheduled time. I created a scheduled compute instance but the script doesn't get implemented when the compute instance is running. So i want to know what method should i use to get this sorted.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2.0,
        "Question_creation_time":1652351760120,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "azure-functions",
            "azure-machine-learning-studio",
            "azure-container-instances",
            "azure-notebooks"
        ],
        "Question_view_count":82.0,
        "Owner_creation_time":1556718046720,
        "Owner_last_access_time":1662885742376,
        "Owner_reputation":25.0,
        "Owner_up_votes":14.0,
        "Owner_down_votes":0.0,
        "Owner_views":6.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"1040\/3 Athurugiriya Road, Malabe, Sri Lanka",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72214072",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to time tigger a python script in the  notebooks; content:<p>hi i am currently working on a small image classification project where the model classifies whether the image contains potholes or not. for this section i have wrote the python script, and this script needs to be triggered at scheduled time. i created a scheduled compute instance but the script doesn't get implemented when the compute instance is running. so i want to know what method should i use to get this sorted.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to time trigger a Python script in Azure ML Notebooks for an image classification project."
    },
    {
        "Question_id":50281188.0,
        "Question_title":"Sagemaker Java client generate IOrecord",
        "Question_body":"<p>I am trying to build a training set for Sagemaker using the Linear Learner algorithm. This algorithm supports recordIO wrapped protobuf and csv as format for the training data. As the training data is generated using spark I am having issues to generate a csv file from a dataframe (this seem broken for now), so I am trying to use protobuf. <\/p>\n\n<p>I managed to create a binary file for the training dataset using Protostuff which is a library that allows to generate protobuf messages from POJO objects. The problem is when triggering the training job I receive that message from SageMaker:\nClientError: No training data processed. Either the training channel is empty or the mini-batch size is too high. Verify that training data contains non-empty files and the mini-batch size is less than the number of records per training host.<\/p>\n\n<p>The training file is certainly not null. I suspect the way I generate the training data to be incorrect as I am able to train models using the libsvm format. Is there a way to generate IOrecord using the Sagemaker java client ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1525984750483,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "amazon-sagemaker"
        ],
        "Question_view_count":222.0,
        "Owner_creation_time":1428454496052,
        "Owner_last_access_time":1570063575876,
        "Owner_reputation":35.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":10.0,
        "Answer_body":"<p>Answering my own question. It was an issue in the algorithm configuration. I reduced mini batch size and it worked fine.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1526653073368,
        "Answer_score":1.0,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50281188",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  java client generate iorecord; content:<p>i am trying to build a training set for  using the linear learner algorithm. this algorithm supports recordio wrapped protobuf and csv as format for the training data. as the training data is generated using spark i am having issues to generate a csv file from a dataframe (this seem broken for now), so i am trying to use protobuf. <\/p>\n\n<p>i managed to create a binary file for the training dataset using protostuff which is a library that allows to generate protobuf messages from pojo objects. the problem is when triggering the training job i receive that message from :\nclienterror: no training data processed. either the training channel is empty or the mini-batch size is too high. verify that training data contains non-empty files and the mini-batch size is less than the number of records per training host.<\/p>\n\n<p>the training file is certainly not null. i suspect the way i generate the training data to be incorrect as i am able to train models using the libsvm format. is there a way to generate iorecord using the  java client ?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to build a training set for Amazon SageMaker using the linear learner algorithm but encountering issues with the format of the training data. They have tried to generate the training data using protobuf but have encountered an error when triggering the training job. The user suspects the way they generated the training data is incorrect and is seeking a way to generate iorecord using the Java client."
    },
    {
        "Question_id":null,
        "Question_title":"Unable to parse the response from the Azure ML Web Service in Azure Stream Analytics",
        "Question_body":"Hi, using Azure ML Studio I have created an endpoint for a model generated with automated ML. The model works fine in test (consume) - provides an expected outcome. Then I created a Stream Analytics query using the function to consume the same ML endpoint. However when I test the Stream Analytics query I receive the following error:\n\n\"Callout failed within query runner. An error was encountered while calling the Azure ML web service. An error occurred when parsing the Azure ML web service response. Please check your Azure ML web service and data model. The content of the response from the ML web service should be a JSON array. The response received from the Web Service is: {\"Results\": [\"none\", \"none\", \"none\"]} Parameter name: result\"\n\nThe result I am getting is fine - as expected - but the problem seems to be with parsing the result.\nSo by reading the docs I understand the desired output format from ML endpoint is JSON Array like this [\"none\", \"none\", \"none\"], while I am getting a JSON object. {\"Results\": [\"none\", \"none\", \"none\"]}\nThe question is, can I (how I) modify the output format (swagger?) to have it return the json array? The model was calculated by automated ML (no-code)\n\nFor the record the Stream Analytics query is like this:\n\nSELECT udf.pdmpredict(TRY_CAST(inputArray AS record))\nINTO [pdm-predict-data]\nFROM ModelInput\nWHERE inputArray is not null\n\nudf.pdmpredict is my ASA ML function created in accordance to this article: https:\/\/learn.microsoft.com\/en-us\/azure\/stream-analytics\/machine-learning-udf\n\nAny ideas will be greatly appreciated!\nThanks.",
        "Question_answer_count":0,
        "Question_comment_count":7.0,
        "Question_creation_time":1664971317523,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1036188\/unable-to-parse-the-response-from-the-azure-ml-web-1.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":17.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: unable to parse the response from the  web service in azure stream analytics; content:hi, using  studio i have created an endpoint for a model generated with automated ml. the model works fine in test (consume) - provides an expected outcome. then i created a stream analytics query using the function to consume the same ml endpoint. however when i test the stream analytics query i receive the following error:\n\n\"callout failed within query runner. an error was encountered while calling the  web service. an error occurred when parsing the  web service response. please check your  web service and data model. the content of the response from the ml web service should be a json array. the response received from the web service is: {\"results\": [\"none\", \"none\", \"none\"]} parameter name: result\"\n\nthe result i am getting is fine - as expected - but the problem seems to be with parsing the result.\nso by reading the docs i understand the desired output format from ml endpoint is json array like this [\"none\", \"none\", \"none\"], while i am getting a json object. {\"results\": [\"none\", \"none\", \"none\"]}\nthe question is, can i (how i) modify the output format (swagger?) to have it return the json array? the model was calculated by automated ml (no-code)\n\nfor the record the stream analytics query is like this:\n\nselect udf.pdmpredict(try_cast(inputarray as record))\ninto [pdm-predict-data]\nfrom modelinput\nwhere inputarray is not null\n\nudf.pdmpredict is my asa ml function created in accordance to this article: https:\/\/learn.microsoft.com\/en-us\/azure\/stream-analytics\/machine-learning-udf\n\nany ideas will be greatly appreciated!\nthanks.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to parse the response from the Azure ML web service in Azure Stream Analytics, as the response received from the web service is a JSON object instead of the desired JSON array. The user is looking for a way to modify the output format (Swagger?) to have it return the JSON array."
    },
    {
        "Question_id":null,
        "Question_title":"Create or update Sagemaker Endpoint via CloudFormation",
        "Question_body":"A wants to manage Sagemaker resources (such as models and endpoints) via CloudFormation. As part of their model deployment pipeline, they'd like to be able to create or update existing Sagemaker Endpoint with new model data. Customers wants to re-use the same endpoint name for a given workload.\n\nQuestion:\n\nHow to express in CF a following logic:\n\nIf Sagemaker endpoint with name \"XYZ\" doesn't exist in customer account, then create a new endpoint;\nIf Sagemaker endpoint with name \"XYZ\" already exist, then update existing endpoint with new model data.",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1607356793000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "AWS CloudFormation",
            "DevOps"
        ],
        "Question_view_count":242.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUXiLSnlxkQHKzQVFj6GKT7w\/create-or-update-sagemaker-endpoint-via-cloud-formation",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI",
            "Management & Governance",
            "DevOps"
        ],
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-07T16:06:33.000Z",
                "Answer_score":0,
                "Answer_body":"This functionality of \"UPSERT\" type does not exist in CFn natively. You would need to use a Custom Resource to handle this logic. One alternative that is not exactly what you asked for but might be a decent compromise is to use a Parameter to supply the endpoint if it does exist. Then use a condition to check the value. If the paramter is blank then create an endpoint if not use the value supplied. I know this is not what you asked for but it allows you to avoid the custom resource solution.\n\nSample of similiar UPSERT example for a VPC:\n\nParameters :\n\n  Vpc:\n    Type: AWS::EC2::VPC::Id\n\nConditions:\n\n  VpcNotSupplied: !Equals [!Ref Vpc, '']\n\nResources:\n\n  NewVpc:\n    Type: AWS::EC2::VPC\n    Condition: VpcNotSupplied\n    Properties:\n      CidrBlock: 10.0.0.0\/16\n\n  SecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      GroupDescription: Sample\n      GroupName: Sample\n      VpcId: !If [VpcNotSupplied, !Ref NewVpc, !Ref Vpc ]\n\n\nHere the Vpc input parameter can be supplied if the VPC you wish to use already exists, left blank if you want to create a new one. The NewVPC resource uses the Condition to only create if the supplied Vpc parameter value is blank. The Security group then uses the same condition to decide whetehr to use and existing Vpc or the newly created one.\n\nHope this makes sense.",
                "Answer_has_accepted":true
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: create or update  endpoint via cloudformation; content:a wants to manage  resources (such as models and endpoints) via cloudformation. as part of their model deployment pipeline, they'd like to be able to create or update existing  endpoint with new model data. customers wants to re-use the same endpoint name for a given workload.\n\nquestion:\n\nhow to express in cf a following logic:\n\nif  endpoint with name \"xyz\" doesn't exist in customer account, then create a new endpoint;\nif  endpoint with name \"xyz\" already exist, then update existing endpoint with new model data.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to be able to create or update an existing endpoint with new model data using CloudFormation, and re-use the same endpoint name for a given workload. They need to express a logic in CloudFormation that will create a new endpoint if it doesn't exist, or update an existing endpoint with new model data if it does."
    },
    {
        "Question_id":68502272.0,
        "Question_title":"Deploying custom preprocessing and postprocessing scripts in SageMaker",
        "Question_body":"<p>I am trying to convert some python scripts into a callable endpoint in SageMaker. My preprocessing(feature engineering) and postprocessing scripts are written in python and have a few interdependent scripts and methods in them. The preprocessing steps are also not necessarily from SKLearn, they are customized functions and need to be called from the preprocessing endpoint every time on the raw data that will then be used for prediction using a model saved as a second endpoint. The third endpoint will be for the postprocessing steps and connecting these 3 endpoints we want to get our data from the raw format to the output format every time.<\/p>\n<p>We currently have normal python scripts that preprocesses the data using some highly customized functions( all features are ultimately derived features) and then performs some inference and then again using some highly customized postprocessing generates the final results. While the input is a CSV file, after each stage of preprocessing and post processing the dimensions of the data and also the format of the output(dataframe, list, list of lists) are likely to change.<\/p>\n<p>For reference, we are using, <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/scikit_learn_iris\/scikit_learn_estimator_example_with_batch_transform.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/scikit_learn_iris\/scikit_learn_estimator_example_with_batch_transform.ipynb<\/a> and <a href=\"https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/scikit_learn_inference_pipeline\/Inference%20Pipeline%20with%20Scikit-learn%20and%20Linear%20Learner.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/amazon-sagemaker-examples\/blob\/master\/sagemaker-python-sdk\/scikit_learn_inference_pipeline\/Inference%20Pipeline%20with%20Scikit-learn%20and%20Linear%20Learner.ipynb<\/a>.<\/p>\n<p>Please let me know if there is any better reference that caters to our specific requirements.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1627057313750,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "endpoint",
            "amazon-sagemaker"
        ],
        "Question_view_count":543.0,
        "Owner_creation_time":1626193734376,
        "Owner_last_access_time":1647843874500,
        "Owner_reputation":21.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":5.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68502272",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: deploying custom preprocessing and postprocessing scripts in ; content:<p>i am trying to convert some python scripts into a callable endpoint in . my preprocessing(feature engineering) and postprocessing scripts are written in python and have a few interdependent scripts and methods in them. the preprocessing steps are also not necessarily from sklearn, they are customized functions and need to be called from the preprocessing endpoint every time on the raw data that will then be used for prediction using a model saved as a second endpoint. the third endpoint will be for the postprocessing steps and connecting these 3 endpoints we want to get our data from the raw format to the output format every time.<\/p>\n<p>we currently have normal python scripts that preprocesses the data using some highly customized functions( all features are ultimately derived features) and then performs some inference and then again using some highly customized postprocessing generates the final results. while the input is a csv file, after each stage of preprocessing and post processing the dimensions of the data and also the format of the output(dataframe, list, list of lists) are likely to change.<\/p>\n<p>for reference, we are using, <a href=\"https:\/\/github.com\/aws\/amazon--examples\/blob\/master\/-python-sdk\/scikit_learn_iris\/scikit_learn_estimator_example_with_batch_transform.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/amazon--examples\/blob\/master\/-python-sdk\/scikit_learn_iris\/scikit_learn_estimator_example_with_batch_transform.ipynb<\/a> and <a href=\"https:\/\/github.com\/aws\/amazon--examples\/blob\/master\/-python-sdk\/scikit_learn_inference_pipeline\/inference%20pipeline%20with%20scikit-learn%20and%20linear%20learner.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/aws\/amazon--examples\/blob\/master\/-python-sdk\/scikit_learn_inference_pipeline\/inference%20pipeline%20with%20scikit-learn%20and%20linear%20learner.ipynb<\/a>.<\/p>\n<p>please let me know if there is any better reference that caters to our specific requirements.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to deploy custom preprocessing and postprocessing scripts in order to convert raw data into an output format. They have customized functions and need to call them from an endpoint every time the raw data is used for prediction."
    },
    {
        "Question_id":57483440.0,
        "Question_title":"Flask and Gunicorn with Additional Threads",
        "Question_body":"<p>I'm trying to build a Flask app with Gunicorn to serve concurrent requests. For what it's worth, the context is a bring-your-own-container Sagemaker application.<\/p>\n\n<p>The issue is that I need the application to periodically check for updates. So I thought to implement a thread for this. Here is a minimal example of some Flask code with an update thread. <\/p>\n\n<p>server.py<\/p>\n\n<pre><code>from flask import Flask\nimport time, threading\n\napp = Flask(__name__)\n\nmessage = True\n\ndef update():\n  while True:\n    message = not message\n    time.sleep(10)\n\n@app.route(\"\/\")\ndef hello():\n  global message\n  return message\n\nupdate_thread = threading.Thread(target=update)\n\nif __name__ == \"__main__\":\n  update_thread.start()\n  app.run()\n  update_thread.join()\n<\/code><\/pre>\n\n<p>I then launch with gunicorn:<\/p>\n\n<p><code>gunicorn -k gevent -b unix:\/tmp\/gunicorn.sock -w 4 server:app<\/code><\/p>\n\n<p>Perhaps unsurprisingly the update thread doesn't start since the <code>__main__<\/code> section is never executed. <\/p>\n\n<blockquote>\n  <p><strong>Question<\/strong>: <em>How can one use an update thread (or similar construct) in a Flask app with Gunicorn?<\/em><\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1565720684053,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python",
            "multithreading",
            "flask",
            "gunicorn",
            "amazon-sagemaker"
        ],
        "Question_view_count":858.0,
        "Owner_creation_time":1413222980680,
        "Owner_last_access_time":1655488449107,
        "Owner_reputation":493.0,
        "Owner_up_votes":11.0,
        "Owner_down_votes":0.0,
        "Owner_views":59.0,
        "Answer_body":"<p>It looks like this can be accomplished using <code>Flask-APScheduler<\/code> as follows:<\/p>\n\n<p><code>pip install flask_apscheduler<\/code><\/p>\n\n<p>server.py<\/p>\n\n<pre><code>from flask import Flask\nfrom apscheduler.schedulers.background import BackgroundScheduler\nimport atexit\n\napp = Flask(__name__)\n\nmessage = True\n\ndef update():\n  global message\n  message = not message\n\nscheduler = BackgroundScheduler()\nscheduler.add_job(func=update,trigger=\"interval\",seconds=10)\nscheduler.start()\n# shut down the scheduler when exiting the app\natexit.register(scheduler.shutdown)\n\n@app.route(\"\/\")\ndef hello():\n  global message\n  return message\n\nif __name__ == \"__main__\":\n  app.run()\n<\/code><\/pre>\n\n<p>Then launching as usual with \n<code>gunicorn -k gevent -b unix:\/tmp\/gunicorn.sock -w 4 server:app<\/code><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1565727707500,
        "Answer_score":0.0,
        "Owner_location":"Richland, WA",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57483440",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: flask and gunicorn with additional threads; content:<p>i'm trying to build a flask app with gunicorn to serve concurrent requests. for what it's worth, the context is a bring-your-own-container  application.<\/p>\n\n<p>the issue is that i need the application to periodically check for updates. so i thought to implement a thread for this. here is a minimal example of some flask code with an update thread. <\/p>\n\n<p>server.py<\/p>\n\n<pre><code>from flask import flask\nimport time, threading\n\napp = flask(__name__)\n\nmessage = true\n\ndef update():\n  while true:\n    message = not message\n    time.sleep(10)\n\n@app.route(\"\/\")\ndef hello():\n  global message\n  return message\n\nupdate_thread = threading.thread(target=update)\n\nif __name__ == \"__main__\":\n  update_thread.start()\n  app.run()\n  update_thread.join()\n<\/code><\/pre>\n\n<p>i then launch with gunicorn:<\/p>\n\n<p><code>gunicorn -k gevent -b unix:\/tmp\/gunicorn.sock -w 4 server:app<\/code><\/p>\n\n<p>perhaps unsurprisingly the update thread doesn't start since the <code>__main__<\/code> section is never executed. <\/p>\n\n<blockquote>\n  <p><strong>question<\/strong>: <em>how can one use an update thread (or similar construct) in a flask app with gunicorn?<\/em><\/p>\n<\/blockquote>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to build a flask app with gunicorn to serve concurrent requests and needs to periodically check for updates, but is having difficulty getting the update thread to start when launching with gunicorn."
    },
    {
        "Question_id":null,
        "Question_title":"Is there a way to export experiment parameters and logged metrics in Azure ML to CSV?",
        "Question_body":"I am running a bunch of ML experiments using AzureML, sometimes changing training parameters and sometimes aspects of the data preprocessing. In general, for a given experiment I will be able to get a table (aka \"view\") like this:\n\nWhile the UI allows some minimum level of customization, sorting runs by e.g. desired columns (say the accuracy to identify the best runs) seems really problematic.\n\nThe only workaround I am aware of is to save the page to HTML (!) and extract the values from there.\nThe data in the cells can't by copied with a cursor either...\n\nIs there an easy way to export the data collected during several runs, via the UI or programmatically, without the need to scrape the blob storage of the Azure ML workspace (I am asking the community here as docs don't seem particularly helpful)?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1605641332880,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/166057\/is-there-a-way-to-export-experiment-parameters-and.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-18T08:02:11.3Z",
                "Answer_score":2,
                "Answer_body":"@DavideFiocco-7346 You can use the SDK to export the run\/s using Run() or get_runs()\nThis sample provides an example to get all the files associated with a run. I think you can use the SDK to get all the runs with get_runs() and load the list to a dataframe and export the same to csv.\n\nThe portal does not have the functionality to export the table but we will provide the feedback to our team for upcoming updates to the portal. Thanks!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is there a way to export experiment parameters and logged metrics in  to csv?; content:i am running a bunch of ml experiments using , sometimes changing training parameters and sometimes aspects of the data preprocessing. in general, for a given experiment i will be able to get a table (aka \"view\") like this:\n\nwhile the ui allows some minimum level of customization, sorting runs by e.g. desired columns (say the accuracy to identify the best runs) seems really problematic.\n\nthe only workaround i am aware of is to save the page to html (!) and extract the values from there.\nthe data in the cells can't by copied with a cursor either...\n\nis there an easy way to export the data collected during several runs, via the ui or programmatically, without the need to scrape the blob storage of the  workspace (i am asking the community here as docs don't seem particularly helpful)?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for an easy way to export the data collected during several runs from Azure ML to a CSV file, either through the UI or programmatically, without the need to scrape the blob storage of the Azure ML workspace."
    },
    {
        "Question_id":69882574.0,
        "Question_title":"How to download an artifact from MLFlow using REST?",
        "Question_body":"<p>I see the Python API:\n<code>download_artifacts(run_id: str, path: str, dst_path: Optional[str] = None) \u2192 str<\/code> (<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.download_artifacts\" rel=\"nofollow noreferrer\">here<\/a>), but I can't find the equivalent in REST.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1636370032513,
        "Question_favorite_count":1.0,
        "Question_score":3.0,
        "Question_tags":[
            "rest",
            "databricks",
            "mlflow"
        ],
        "Question_view_count":243.0,
        "Owner_creation_time":1244984040076,
        "Owner_last_access_time":1663968051750,
        "Owner_reputation":13408.0,
        "Owner_up_votes":306.0,
        "Owner_down_votes":12.0,
        "Owner_views":687.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"New York, NY",
        "Question_last_edit_time":1636454691216,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69882574",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to download an artifact from  using rest?; content:<p>i see the python api:\n<code>download_artifacts(run_id: str, path: str, dst_path: optional[str] = none) \u2192 str<\/code> (<a href=\"https:\/\/www..org\/docs\/latest\/python_api\/.tracking.html#.tracking.client.download_artifacts\" rel=\"nofollow noreferrer\">here<\/a>), but i can't find the equivalent in rest.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for the equivalent of the Python API download_artifacts() in REST."
    },
    {
        "Question_id":60141029.0,
        "Question_title":"GPU not detected by Keras\/Tensorflow on AWS ml.p2.xlarge instance managed by SageMaker",
        "Question_body":"<p>I'm using a custom Docker container for use with SageMaker on a <code>ml.p2.xlarge<\/code> instance. <\/p>\n\n<p>The base image is <a href=\"https:\/\/hub.docker.com\/r\/tiangolo\/python-machine-learning\" rel=\"nofollow noreferrer\">tiangolo\/python-machine-learning:cuda9.1-python3.7<\/a>, which normally comes with the required CUDA toolkit. The python packages are installed via conda using the following minimalist <code>environment.yaml<\/code>:<\/p>\n\n<pre><code>dependencies:\n  - boto3\n  - joblib\n  - keras\n  - numpy\n  - pandas\n  - scikit-learn\n  - scipy\n  - tensorflow=2.0\n<\/code><\/pre>\n\n<p>But when I run the training job for a small <code>lenet5<\/code> CNN, I don't see any GPU activity in the logs (and the training last as long as on a non-GPU instance). <\/p>\n\n<p>More worrying, <code>len(tf.config.experimental.list_physical_devices('GPU')<\/code> returns <code>0<\/code>, and <code>K.tensorflow_backend._get_available_gpus()<\/code> is empty. Finally, if I inspect device placement (using <code>tf.debugging.set_log_device_placement(True)<\/code>) on a basic operation such as the following:<\/p>\n\n<pre><code>a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\nc = tf.matmul(a, b)\nprint(c)\n<\/code><\/pre>\n\n<p>I get <\/p>\n\n<pre><code>Executing op _MklMatMul in device \/job:localhost\/replica:0\/task:0\/device:CPU:0\n<\/code><\/pre>\n\n<p>Confirming that the operation has taken place on the CPU. <\/p>\n\n<p>At first I thought my use case was too light to trigger GPU usage, but it seems the GPU is not detected at all! Am I missing any steps or components required for this to work?  <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1581280285490,
        "Question_favorite_count":1.0,
        "Question_score":4.0,
        "Question_tags":[
            "keras",
            "gpu",
            "amazon-sagemaker"
        ],
        "Question_view_count":2047.0,
        "Owner_creation_time":1339196227196,
        "Owner_last_access_time":1664028210780,
        "Owner_reputation":548.0,
        "Owner_up_votes":26.0,
        "Owner_down_votes":0.0,
        "Owner_views":47.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Belgium",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60141029",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: gpu not detected by keras\/tensorflow on aws ml.p2.xlarge instance managed by ; content:<p>i'm using a custom docker container for use with  on a <code>ml.p2.xlarge<\/code> instance. <\/p>\n\n<p>the base image is <a href=\"https:\/\/hub.docker.com\/r\/tiangolo\/python-machine-learning\" rel=\"nofollow noreferrer\">tiangolo\/python-machine-learning:cuda9.1-python3.7<\/a>, which normally comes with the required cuda toolkit. the python packages are installed via conda using the following minimalist <code>environment.yaml<\/code>:<\/p>\n\n<pre><code>dependencies:\n  - boto3\n  - joblib\n  - keras\n  - numpy\n  - pandas\n  - scikit-learn\n  - scipy\n  - tensorflow=2.0\n<\/code><\/pre>\n\n<p>but when i run the training job for a small <code>lenet5<\/code> cnn, i don't see any gpu activity in the logs (and the training last as long as on a non-gpu instance). <\/p>\n\n<p>more worrying, <code>len(tf.config.experimental.list_physical_devices('gpu')<\/code> returns <code>0<\/code>, and <code>k.tensorflow_backend._get_available_gpus()<\/code> is empty. finally, if i inspect device placement (using <code>tf.debugging.set_log_device_placement(true)<\/code>) on a basic operation such as the following:<\/p>\n\n<pre><code>a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\nc = tf.matmul(a, b)\nprint(c)\n<\/code><\/pre>\n\n<p>i get <\/p>\n\n<pre><code>executing op _mklmatmul in device \/job:localhost\/replica:0\/task:0\/device:cpu:0\n<\/code><\/pre>\n\n<p>confirming that the operation has taken place on the cpu. <\/p>\n\n<p>at first i thought my use case was too light to trigger gpu usage, but it seems the gpu is not detected at all! am i missing any steps or components required for this to work?  <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is not seeing any GPU activity in their logs and is unable to detect the GPU when running a basic operation on a ml.p2.xlarge instance managed by AWS."
    },
    {
        "Question_id":72143004.0,
        "Question_title":"How to copy local runs from mlflow to remote tracking server?",
        "Question_body":"<p>Dear mlflow community,<\/p>\n<p>I am struggeling with a performant environment for both testing and production.<\/p>\n<p>What I want to do is, train models locally and compare them in mlflow. In case I have found a good model I would like to push it to a remote mlflow instance.<\/p>\n<p>For this purpose I have set up a tracking server with postgres and S3.<\/p>\n<p>How can I push the model and all artifacts in the run to the remote mlflfow instance?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1651846786927,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "python-3.x",
            "tensorflow",
            "mlflow"
        ],
        "Question_view_count":72.0,
        "Owner_creation_time":1419378602192,
        "Owner_last_access_time":1663758616000,
        "Owner_reputation":1499.0,
        "Owner_up_votes":98.0,
        "Owner_down_votes":14.0,
        "Owner_views":297.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72143004",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to copy local runs from  to remote tracking server?; content:<p>dear  community,<\/p>\n<p>i am struggeling with a performant environment for both testing and production.<\/p>\n<p>what i want to do is, train models locally and compare them in . in case i have found a good model i would like to push it to a remote  instance.<\/p>\n<p>for this purpose i have set up a tracking server with postgres and s3.<\/p>\n<p>how can i push the model and all artifacts in the run to the remote mlflfow instance?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to train models locally and compare them in MLflow, and then push the best model and its artifacts to a remote MLflow instance."
    },
    {
        "Question_id":null,
        "Question_title":"Sagemaker endpoint running but constantly restarting",
        "Question_body":"I have deployed a model to a Sagemaker endpoint using BentoML\/BentoCTL. This is a tool for building APIs and containerizing models. To test, I use curl with a JSON payload to make a request. When I run the created docker container on my local machine I can successfully invoke it and get responses back. So I don't think the problem is in the docker image.\n\nWhen I deploy to sagemaker, I receive the message {\"message\":\"Service Unavailable\"} as a response to my curl request. I can see the endpoint running in the Sagemaker\/Endpoints dashboard. Viewing the cloudwatch logs, it appears that the the endpoint is constantly restarting. There are messages that are printed at startup (e.g. Tensorflow loading messages) that are written to the log over and over.\n\nI thought that this might be due to using an instance type with low memory (t2.medium) so I switched to m5.4xlarge as a test, but the result is the same.\n\nWhat can I do? How can I determine what's causing the endless restarts?",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1660140840225,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker",
            "Amazon CloudWatch Logs",
            "Amazon SageMaker Deployment"
        ],
        "Question_view_count":81.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUQi42sIDTTSW5KN3P-DT4LQ\/sagemaker-endpoint-running-but-constantly-restarting",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI",
            "Management & Governance"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-12T17:17:23.953Z",
                "Answer_score":0,
                "Answer_body":"When you mean restart? Does it mean \"Updating\" the endpoint? Do you have an autoscaling policy attached to the endpoint? Do you see any errors in the Cloudwatch logs?",
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-09T05:06:38.531Z",
                "Answer_score":0,
                "Answer_body":"Hello - can you check the Tensorflow version and use the latest supported version 2.2? Thank you!\n\nhttps:\/\/aws.amazon.com\/releasenotes\/available-deep-learning-containers-images\/ https:\/\/sagemaker.readthedocs.io\/en\/stable\/frameworks\/tensorflow\/deploying_tensorflow_serving.html",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  endpoint running but constantly restarting; content:i have deployed a model to a  endpoint using bentoml\/bentoctl. this is a tool for building apis and containerizing models. to test, i use curl with a json payload to make a request. when i run the created docker container on my local machine i can successfully invoke it and get responses back. so i don't think the problem is in the docker image.\n\nwhen i deploy to , i receive the message {\"message\":\"service unavailable\"} as a response to my curl request. i can see the endpoint running in the \/endpoints dashboard. viewing the cloudwatch logs, it appears that the the endpoint is constantly restarting. there are messages that are printed at startup (e.g. tensorflow loading messages) that are written to the log over and over.\n\ni thought that this might be due to using an instance type with low memory (t2.medium) so i switched to m5.4xlarge as a test, but the result is the same.\n\nwhat can i do? how can i determine what's causing the endless restarts?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user has deployed a model to an endpoint using BentoML\/Bentoctl, but the endpoint is constantly restarting and they are receiving a \"service unavailable\" response to their curl request."
    },
    {
        "Question_id":null,
        "Question_title":"Is it possible to use a Windows Account for configuring Machine Learning Server 9.4.7?",
        "Question_body":"After configuring Machine Learning Server with a password, one connects to the server through the user name \"admin\" and the designated password. Is it possible configure Machine Learning Server to use a Windows Account instead of the default \"admin\"?",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1610029811687,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/222486\/is-it-possible-to-use-a-windows-account-for-config.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-09T00:30:26.617Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nIf you are asking the password at below step, the answer is no:\n\n\"Set a password used to protect your configuration settings. Later, after configuration is finished, anyone who wants to use the CLI to modify a configuration must provide this password to gain access to settings and operations.\n\nThe password must meet these requirements: 8-16 characters long, with at least one upper-case letter, one lower-case letter, one number, and one special character.\"\n\nPlease let me know if you have more questions. Thanks and happy new year.\n\nRegards,\nYutong",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is it possible to use a windows account for configuring machine learning server 9.4.7?; content:after configuring machine learning server with a password, one connects to the server through the user name \"admin\" and the designated password. is it possible configure machine learning server to use a windows account instead of the default \"admin\"?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if it is possible to configure Machine Learning Server 9.4.7 to use a Windows account instead of the default \"admin\" account after configuring the server with a password."
    },
    {
        "Question_id":72235578.0,
        "Question_title":"Is there a way to stream cloudwatch logs while executing a Jenkins build",
        "Question_body":"<p>I'm trying to stream cloud watch logs in jenkins console output as and when my sagemaker processing job is executing. But unsure if there is a plugin for the same. I'm aware a Jenkins plugin to send Pipeline build logs to cloudwatch logs is available but wondering if there was one vice versa.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1.0,
        "Question_creation_time":1652477167210,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "jenkins",
            "amazon-cloudwatch",
            "amazon-sagemaker",
            "console.log",
            "cicd"
        ],
        "Question_view_count":184.0,
        "Owner_creation_time":1644597268608,
        "Owner_last_access_time":1655471328660,
        "Owner_reputation":1.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72235578",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: is there a way to stream cloudwatch logs while executing a jenkins build; content:<p>i'm trying to stream cloud watch logs in jenkins console output as and when my  processing job is executing. but unsure if there is a plugin for the same. i'm aware a jenkins plugin to send pipeline build logs to cloudwatch logs is available but wondering if there was one vice versa.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to stream CloudWatch logs in Jenkins console output while their processing job is executing, and is wondering if there is a plugin available to do this."
    },
    {
        "Question_id":60607041.0,
        "Question_title":"AWS Sagemaker Spark S3 access issue",
        "Question_body":"<p>I am new in AWS sagemaker. I created a notebook in a VPC with private subnet, kms default encrypted key, root access, no direct internet access. I have attached policy which have full access to Sagemaker and S3 in IAM as per documentations.  Now while one of data scientist trying to run his code in jupyter, getting below error. I can see jar files (\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/sagemaker_pyspark\/jars\/), I have even given access key and secret key in code, is there anything we are doing wrong here<\/p>\n\n<pre><code>import os\nimport boto3\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nimport sagemaker\nfrom sagemaker import get_execution_role\nimport sagemaker_pyspark\nimport pyspark\n\nrole = get_execution_role()\nspark = SparkSession.builder \\\n            .appName(\"app_name2\") \\\n            .getOrCreate()\n\nsc=pyspark.SparkContext.getOrCreate()\nsc.setSystemProperty(\"com.amazonaws.services.s3.enableV4\", \"true\")\n\nhadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", 'access_key')\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", 'secret_key')\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-2.amazonaws.com\")\nspark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3a.enableV4\", \"true\")\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\");\nspark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\ndf= spark.read.csv(\"s3a:\/\/mybucket\/ConsolidatedData\/my.csv\",header=\"true\")\n\n\nPy4JJavaError: An error occurred while calling o579.csv.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n    at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n    at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n    at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n    at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n    at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n    at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:709)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1583781550823,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "apache-spark",
            "pyspark",
            "jupyter",
            "amazon-sagemaker"
        ],
        "Question_view_count":933.0,
        "Owner_creation_time":1513883236660,
        "Owner_last_access_time":1663906475808,
        "Owner_reputation":465.0,
        "Owner_up_votes":11.0,
        "Owner_down_votes":0.0,
        "Owner_views":46.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Noida, Uttar Pradesh, India",
        "Question_last_edit_time":1583817907990,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60607041",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  spark s3 access issue; content:<p>i am new in . i created a notebook in a vpc with private subnet, kms default encrypted key, root access, no direct internet access. i have attached policy which have full access to  and s3 in iam as per documentations.  now while one of data scientist trying to run his code in jupyter, getting below error. i can see jar files (\/home\/ec2-user\/anaconda3\/envs\/python3\/lib\/python3.6\/site-packages\/_pyspark\/jars\/), i have even given access key and secret key in code, is there anything we are doing wrong here<\/p>\n\n<pre><code>import os\nimport boto3\n\nfrom pyspark import sparkcontext, sparkconf\nfrom pyspark.sql import sparksession\n\nimport \nfrom  import get_execution_role\nimport _pyspark\nimport pyspark\n\nrole = get_execution_role()\nspark = sparksession.builder \\\n            .appname(\"app_name2\") \\\n            .getorcreate()\n\nsc=pyspark.sparkcontext.getorcreate()\nsc.setsystemproperty(\"com.amazonaws.services.s3.enablev4\", \"true\")\n\nhadoop_conf = spark.sparkcontext._jsc.hadoopconfiguration()\nspark._jsc.hadoopconfiguration().set(\"fs.s3a.access.key\", 'access_key')\nspark._jsc.hadoopconfiguration().set(\"fs.s3a.secret.key\", 'secret_key')\nspark._jsc.hadoopconfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-2.amazonaws.com\")\nspark._jsc.hadoopconfiguration().set(\"com.amazonaws.services.s3a.enablev4\", \"true\")\nspark._jsc.hadoopconfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\");\nspark._jsc.hadoopconfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.s3afilesystem\")\ndf= spark.read.csv(\"s3a:\/\/mybucket\/consolidateddata\/my.csv\",header=\"true\")\n\n\npy4jjavaerror: an error occurred while calling o579.csv.\n: java.lang.runtimeexception: java.lang.classnotfoundexception: class org.apache.hadoop.fs.s3a.s3afilesystem not found\n    at org.apache.hadoop.conf.configuration.getclass(configuration.java:2195)\n    at org.apache.hadoop.fs.filesystem.getfilesystemclass(filesystem.java:2654)\n    at org.apache.hadoop.fs.filesystem.createfilesystem(filesystem.java:2667)\n    at org.apache.hadoop.fs.filesystem.access$200(filesystem.java:94)\n    at org.apache.hadoop.fs.filesystem$cache.getinternal(filesystem.java:2703)\n    at org.apache.hadoop.fs.filesystem$cache.get(filesystem.java:2685)\n    at org.apache.hadoop.fs.filesystem.get(filesystem.java:373)\n    at org.apache.hadoop.fs.path.getfilesystem(path.java:295)\n    at org.apache.spark.sql.execution.datasources.datasource$.org$apache$spark$sql$execution$datasources$datasource$$checkandglobpathifnecessary(datasource.scala:709)\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is experiencing an issue with accessing S3 from a notebook in a VPC with no direct internet access, and is receiving a \"ClassNotFoundException\" error."
    },
    {
        "Question_id":61270842.0,
        "Question_title":"Azure ML SDK to DataIKU (python Recepie) integration",
        "Question_body":"<p>WE are installing Azure Machine Learning SDK in Python Code Recipe in DataIKU.<\/p>\n\n<p>The Model coding is more manual when using SDK, Is there a way where we can create models in ML Studio (Drag and Drop) and use it's service in Python to get the output. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1587123889007,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning-studio",
            "azure-machine-learning-service"
        ],
        "Question_view_count":62.0,
        "Owner_creation_time":1578649477907,
        "Owner_last_access_time":1590997946847,
        "Owner_reputation":41.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":11.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61270842",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  sdk to dataiku (python recepie) integration; content:<p>we are installing  sdk in python code recipe in dataiku.<\/p>\n\n<p>the model coding is more manual when using sdk, is there a way where we can create models in ml studio (drag and drop) and use it's service in python to get the output. <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to create models in Azure ML Studio and use its service in Python to get the output, as the model coding is more manual when using the SDK."
    },
    {
        "Question_id":53405502.0,
        "Question_title":"How can I invoke AWS SageMaker endpoint to get inferences?",
        "Question_body":"<p>I want to get real time predictions using my machine learning model with the help of SageMaker. I want to directly get inferences on my website. How can I use the deployed model for predictions?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0.0,
        "Question_creation_time":1542776226677,
        "Question_favorite_count":2.0,
        "Question_score":8.0,
        "Question_tags":[
            "amazon-web-services",
            "machine-learning",
            "data-science",
            "amazon-sagemaker"
        ],
        "Question_view_count":7900.0,
        "Owner_creation_time":1528095970836,
        "Owner_last_access_time":1611845381423,
        "Owner_reputation":91.0,
        "Owner_up_votes":1.0,
        "Owner_down_votes":0.0,
        "Owner_views":13.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53405502",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how can i invoke  endpoint to get inferences?; content:<p>i want to get real time predictions using my machine learning model with the help of . i want to directly get inferences on my website. how can i use the deployed model for predictions?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to use an endpoint to get real-time predictions from their machine learning model and use it on their website."
    },
    {
        "Question_id":null,
        "Question_title":"Use a trained model for use cases (a new data set)",
        "Question_body":"Dear all\n\nI conducted some experiments with Microsoft Azure automated ML and DESIGNER.\n\nAs far as I understand the given results, the trained model shows e.g. the accuracy? How well or in how many cases can the trained model predict the value (e.g. TRUE or FALSE) correctly?\n\nNow, I want to use the \"trained\" model(s) for use cases. My goal is to use the trained model(s) and provide predictions for new samples (a new data set). E.g. I want to predict the value \"TRUE\" or \"FALSE\" for the values of the new data set.\n\nIn my case, there is no value in the column (TRUE or FALSE). I want the model to provide me with the answers.\n\nNext steps: As far as I see, I need to deploy the model so that I can conduct the same experiments with new samples?\n\nOr how can I apply my trained model for the new use cases? (please see my description above)\n\nThank you for your feedback\n\nBest regards\n\nLukas",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1665310129110,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning"
        ],
        "Question_view_count":null,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1040790\/use-a-trained-model-for-use-cases-a-new-data-set.html",
        "Tool":"Azure Machine Learning",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-10T14:14:26.413Z",
                "Answer_score":0,
                "Answer_body":"@LukasBusers-1078 After you create a deployment, you can score it as described in Test the endpoint with sample data.\nAre you facing any error, if yes please add the error details.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-26T14:46:01.66Z",
                "Answer_score":0,
                "Answer_body":"Tutorial Overview\nThis tutorial is divided into three parts; they are:\n\nPrepare a Training Dataset\nHow to Fit a Model on the Training Dataset\nHow to Connect Predictions With Inputs to the Model\n2. Prepare a Training Dataset\nLet\u2019s start off by defining a dataset that we can use with our model.\n\nYou may have your own dataset in a CSV file or in a NumPy array in memory.\n\nIn this case, we will use a simple two-class or binary classification problem with two numerical input variables.\n\nInputs: Two numerical input variables:\nOutputs: A class label as either a 0 or 1.\nWe can use the make_blobs() scikit-learn function to create this dataset with 1,000 examples.\n\nThe example below creates the dataset with separate arrays for the input (X) and outputs (y).",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: use a trained model for use cases (a new data set); content:dear all\n\ni conducted some experiments with microsoft azure automated ml and designer.\n\nas far as i understand the given results, the trained model shows e.g. the accuracy? how well or in how many cases can the trained model predict the value (e.g. true or false) correctly?\n\nnow, i want to use the \"trained\" model(s) for use cases. my goal is to use the trained model(s) and provide predictions for new samples (a new data set). e.g. i want to predict the value \"true\" or \"false\" for the values of the new data set.\n\nin my case, there is no value in the column (true or false). i want the model to provide me with the answers.\n\nnext steps: as far as i see, i need to deploy the model so that i can conduct the same experiments with new samples?\n\nor how can i apply my trained model for the new use cases? (please see my description above)\n\nthank you for your feedback\n\nbest regards\n\nlukas",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to use a trained model to provide predictions for a new data set and is looking for guidance on how to deploy the model to do so."
    },
    {
        "Question_id":null,
        "Question_title":"Feature Engineering Vertex AI\/AutoML",
        "Question_body":"Hey There,I am writing my Master Thesis at the moment. I am comparing AutoML products for image classification. There I compare the product Vertex AI with Azure from Microsoft. However, I can't find the concrete methods of feature engineering and model selection from the documentation. Does anybody know these methodes used for Google AutoML for image classification?Thanks a lot!Arndt",
        "Question_answer_count":1,
        "Question_comment_count":null,
        "Question_creation_time":1658999880000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":88.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Feature-Engineering-Vertex-AI-AutoML\/td-p\/447814\/jump-to\/first-unread-message",
        "Tool":"Vertex AI",
        "Forum":"Tool-specific",
        "Question_topic":[
            "AutoML"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-03T15:31:00",
                "Answer_accepted":false,
                "Answer_score":0,
                "Answer_body":"Think you are looking for this documentation it describes how feature engineering works within autoML and how it supports it in different ways."
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: feature engineering \/automl; content:hey there,i am writing my master thesis at the moment. i am comparing automl products for image classification. there i compare the product  with azure from microsoft. however, i can't find the concrete methods of feature engineering and model selection from the documentation. does anybody know these methodes used for google automl for image classification?thanks a lot!arndt",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is writing a master thesis comparing Automl products for image classification and is looking for the concrete methods of feature engineering and model selection used for Google Automl for image classification."
    },
    {
        "Question_id":57547110.0,
        "Question_title":"How to load file in sagemaker custom deploy endpoint script",
        "Question_body":"<p>I am trying to deploy a sentiment analysis model on sagemaker to an endpoint to predict sentiment in real time of an input text. This model will take a single text String as input and return the sentiment.<\/p>\n\n<p>To train the xgboost model, I followed this <a href=\"https:\/\/github.com\/NadimKawwa\/sagemaker_ml\/blob\/master\/SageMaker_IMDB_highlevel.ipynb\" rel=\"nofollow noreferrer\"> notebook<\/a> upto step 23. \nThis uploaded model.tar.gz to s3 bucket. I additionally uploaded vocabulary_dict generated by sklearn's CountVectorizer(to create bag of words)to s3 bucket as well. <\/p>\n\n<p>To deploy this pre-trained model, I can use <a href=\"https:\/\/sagemaker.readthedocs.io\/en\/stable\/using_sklearn.html#deploying-endpoints-from-model-data\" rel=\"nofollow noreferrer\">this method<\/a> and supply an entry point python file predict.py.<\/p>\n\n<pre><code>sklearn_model = SKLearnModel(model_data=\"s3:\/\/bucket\/model.tar.gz\", role=\"SageMakerRole\", entry_point=\"predict.py\")\n<\/code><\/pre>\n\n<p>Documentation says that I have to provide model.tar.gz only as argument and it will be loaded in model_fn. But if I am writing my own model_fn, how do I load the model then? If I put additional files in the same directory as of model.tar.gz in S3, can I load them as well?<\/p>\n\n<p>Now to do the classification, I will have to vectorize the input text before calling model.predict(bow_vector) in the method predict_fn. In order to do that, I need word_dict which I prepared during pre-processing training data and wrote to s3. <\/p>\n\n<p>My question is how do I get the word_dict inside the model_fn? Can I load it from s3? \nBelow is code for predict.py.<\/p>\n\n<pre><code>import os\nimport re\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport nltk\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import *\nfrom bs4 import BeautifulSoup\nimport sagemaker_containers\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n\n\ndef model_fn(model_dir):\n\n    #TODO How to load the word_dict.\n    #TODO How to load the model.\n    return model, word_dict\n\ndef predict_fn(input_data, model):\n    print('Inferring sentiment of input data.')\n    trained_model, word_dict = model\n    if word_dict is None:\n        raise Exception('Model has not been loaded properly, no word_dict.')\n\n    #Process input_data so that it is ready to be sent to our model.\n\n    input_bow_csv = process_input_text(word_dict, input_data)\n    prediction = trained_model.predict(input_bow_csv)\n    return prediction\n\n\ndef process_input_text(word_dict, input_data):\n\n    words = text_to_words(input_data);\n    vectorizer = CountVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x, word_dict)\n    bow_array = vectorizer.transform([words]).toarray()[0]\n    bow_csv = \",\".join(str(bit) for bit in bow_array)\n    return bow_csv\n\ndef text_to_words(text):\n    \"\"\"\n    Uses the Porter Stemmer to stem words in a review\n    \"\"\"\n    #instantiate stemmer\n    stemmer = PorterStemmer()\n    text_nohtml = BeautifulSoup(text, \"html.parser\").get_text() # Remove HTML tags\n    text_lower = re.sub(r\"[^a-zA-Z0-9]\", \" \", text_nohtml.lower()) # Convert to lower case\n    words = text_lower.split() # Split string into words\n    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n    words = [PorterStemmer().stem(w) for w in words] # stem\n    return words\n\ndef input_fn(input_data, content_type):\n    return input_data;\n\ndef output_fn(prediction_output, accept):\n    return prediction_output;\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1566151471257,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "python",
            "amazon-web-services",
            "scikit-learn",
            "aws-sdk",
            "amazon-sagemaker"
        ],
        "Question_view_count":676.0,
        "Owner_creation_time":1566093196300,
        "Owner_last_access_time":1569443278816,
        "Owner_reputation":21.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57547110",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to load file in  custom deploy endpoint script; content:<p>i am trying to deploy a sentiment analysis model on  to an endpoint to predict sentiment in real time of an input text. this model will take a single text string as input and return the sentiment.<\/p>\n\n<p>to train the xgboost model, i followed this <a href=\"https:\/\/github.com\/nadimkawwa\/_ml\/blob\/master\/_imdb_highlevel.ipynb\" rel=\"nofollow noreferrer\"> notebook<\/a> upto step 23. \nthis uploaded model.tar.gz to s3 bucket. i additionally uploaded vocabulary_dict generated by sklearn's countvectorizer(to create bag of words)to s3 bucket as well. <\/p>\n\n<p>to deploy this pre-trained model, i can use <a href=\"https:\/\/.readthedocs.io\/en\/stable\/using_sklearn.html#deploying-endpoints-from-model-data\" rel=\"nofollow noreferrer\">this method<\/a> and supply an entry point python file predict.py.<\/p>\n\n<pre><code>sklearn_model = sklearnmodel(model_data=\"s3:\/\/bucket\/model.tar.gz\", role=\"role\", entry_point=\"predict.py\")\n<\/code><\/pre>\n\n<p>documentation says that i have to provide model.tar.gz only as argument and it will be loaded in model_fn. but if i am writing my own model_fn, how do i load the model then? if i put additional files in the same directory as of model.tar.gz in s3, can i load them as well?<\/p>\n\n<p>now to do the classification, i will have to vectorize the input text before calling model.predict(bow_vector) in the method predict_fn. in order to do that, i need word_dict which i prepared during pre-processing training data and wrote to s3. <\/p>\n\n<p>my question is how do i get the word_dict inside the model_fn? can i load it from s3? \nbelow is code for predict.py.<\/p>\n\n<pre><code>import os\nimport re\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport nltk\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import *\nfrom bs4 import beautifulsoup\nimport _containers\n\nfrom sklearn.feature_extraction.text import countvectorizer\n\n\n\ndef model_fn(model_dir):\n\n    #todo how to load the word_dict.\n    #todo how to load the model.\n    return model, word_dict\n\ndef predict_fn(input_data, model):\n    print('inferring sentiment of input data.')\n    trained_model, word_dict = model\n    if word_dict is none:\n        raise exception('model has not been loaded properly, no word_dict.')\n\n    #process input_data so that it is ready to be sent to our model.\n\n    input_bow_csv = process_input_text(word_dict, input_data)\n    prediction = trained_model.predict(input_bow_csv)\n    return prediction\n\n\ndef process_input_text(word_dict, input_data):\n\n    words = text_to_words(input_data);\n    vectorizer = countvectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x, word_dict)\n    bow_array = vectorizer.transform([words]).toarray()[0]\n    bow_csv = \",\".join(str(bit) for bit in bow_array)\n    return bow_csv\n\ndef text_to_words(text):\n    \"\"\"\n    uses the porter stemmer to stem words in a review\n    \"\"\"\n    #instantiate stemmer\n    stemmer = porterstemmer()\n    text_nohtml = beautifulsoup(text, \"html.parser\").get_text() # remove html tags\n    text_lower = re.sub(r\"[^a-za-z0-9]\", \" \", text_nohtml.lower()) # convert to lower case\n    words = text_lower.split() # split string into words\n    words = [w for w in words if w not in stopwords.words(\"english\")] # remove stopwords\n    words = [porterstemmer().stem(w) for w in words] # stem\n    return words\n\ndef input_fn(input_data, content_type):\n    return input_data;\n\ndef output_fn(prediction_output, accept):\n    return prediction_output;\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to deploy a sentiment analysis model on AWS to predict sentiment in real-time of an input text and is having trouble with loading the word_dict and model in the model_fn of their custom deploy endpoint script. They need to load the word_dict and the model in the model_fn so they can use it in predict_fn to vectorize the input text and make a prediction."
    },
    {
        "Question_id":67699023.0,
        "Question_title":"How to render a column n datetime format from AzureML Dataset?",
        "Question_body":"<p>I have registered a dataset after an Azure Databricks ETL operation. When it is registered as an AzureML Dataset, one of the columns is rendered as a timestamp. I know the schema has been inferred properly as the Dataset-&gt;Explore blade renders it properly:\n<a href=\"https:\/\/i.stack.imgur.com\/qQTUc.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qQTUc.png\" alt=\"Dataset_in_Explore_Tab\" \/><\/a><\/p>\n<p>However, when using <code> Dataset.get_by_name(ws,&lt;name&gt;).to_pandas_dataframe()<\/code>, the timestamp column is rendered as all None:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/5zS2V.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/5zS2V.png\" alt=\"Pandas_Dataframe\" \/><\/a><\/p>\n<p>How do I mention the schema so that it is rendered properly while Getting the <code>Dataset.get_by_name()<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1622007145393,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning-service"
        ],
        "Question_view_count":88.0,
        "Owner_creation_time":1601729162436,
        "Owner_last_access_time":1663774065772,
        "Owner_reputation":887.0,
        "Owner_up_votes":187.0,
        "Owner_down_votes":32.0,
        "Owner_views":130.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67699023",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to render a column n datetime format from  dataset?; content:<p>i have registered a dataset after an azure databricks etl operation. when it is registered as an  dataset, one of the columns is rendered as a timestamp. i know the schema has been inferred properly as the dataset-&gt;explore blade renders it properly:\n<a href=\"https:\/\/i.stack.imgur.com\/qqtuc.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qqtuc.png\" alt=\"dataset_in_explore_tab\" \/><\/a><\/p>\n<p>however, when using <code> dataset.get_by_name(ws,&lt;name&gt;).to_pandas_dataframe()<\/code>, the timestamp column is rendered as all none:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/5zs2v.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/5zs2v.png\" alt=\"pandas_dataframe\" \/><\/a><\/p>\n<p>how do i mention the schema so that it is rendered properly while getting the <code>dataset.get_by_name()<\/code><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to render a column in a datetime format from a dataset registered after an Azure Databricks ETL operation, but when using dataset.get_by_name(), the timestamp column is rendered as all none."
    },
    {
        "Question_id":73789674.0,
        "Question_title":"How can I know how many iterations are left when tuning accross multiple hyperparameters in SparkML?",
        "Question_body":"<p>I'm running a crossvalidation accross a grid of multiple hyperparameters with XgBoost model using Pyspark in Databricks and I would like to know the progress of this operation...So far it has been running for almost 24 hours and I have no idea if it's halfway done or only 10% of the way. I have a 128k combinations of hyperparameters of 5 folds each so a total of 640k runs...<\/p>\n<p>I've tried clicking on MLflow logged run but it's an empty page with an UNFINISHED status. Is there any way to know the progress ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1663690227917,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "databricks",
            "cross-validation",
            "apache-spark-mllib",
            "hyperparameters",
            "mlflow"
        ],
        "Question_view_count":13.0,
        "Owner_creation_time":1558118783688,
        "Owner_last_access_time":1663939366183,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1663694262408,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73789674",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how can i know how many iterations are left when tuning accross multiple hyperparameters in sparkml?; content:<p>i'm running a crossvalidation accross a grid of multiple hyperparameters with xgboost model using pyspark in databricks and i would like to know the progress of this operation...so far it has been running for almost 24 hours and i have no idea if it's halfway done or only 10% of the way. i have a 128k combinations of hyperparameters of 5 folds each so a total of 640k runs...<\/p>\n<p>i've tried clicking on  logged run but it's an empty page with an unfinished status. is there any way to know the progress ?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to find a way to track the progress of a crossvalidation operation with xgboost model using pyspark in databricks, which has a total of 640k runs."
    },
    {
        "Question_id":61225608.0,
        "Question_title":"Azure Machine Learning : unable to create compute instance with 12 month trial license",
        "Question_body":"<p>I am preparing for DP-100 certification.\nAs a part of self-learning, I created one trial account using my outlook email for 12 months.\nDuring the part where I needed to set up a <strong>Compute Instance<\/strong>, I encounter an error as shown below.\nWhat is the reason, Can't I create a <strong>Compute Instance<\/strong> with a trial account.<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/MWsnt.png\" alt=\"enter image description here\"><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1586943598133,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure",
            "azure-machine-learning-studio",
            "azure-machine-learning-service",
            "azure-machine-learning-workbench"
        ],
        "Question_view_count":19.0,
        "Owner_creation_time":1586942899727,
        "Owner_last_access_time":1600269683563,
        "Owner_reputation":11.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":0.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":1586944099443,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61225608",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  : unable to create compute instance with 12 month trial license; content:<p>i am preparing for dp-100 certification.\nas a part of self-learning, i created one trial account using my outlook email for 12 months.\nduring the part where i needed to set up a <strong>compute instance<\/strong>, i encounter an error as shown below.\nwhat is the reason, can't i create a <strong>compute instance<\/strong> with a trial account.<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/mwsnt.png\" alt=\"enter image description here\"><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to create a compute instance with their 12 month trial license and is receiving an error when attempting to do so."
    },
    {
        "Question_id":73760407.0,
        "Question_title":"Unable to connect Azure DevOps and Azure ML",
        "Question_body":"<p>I have created an automated Service Principal from the service requests on Azure Devops with sufficient permissions. Now, when I am trying to create an artifact which is an ML model (registered) it is not auto populating the registered models and resulting in an error.<\/p>\n<p>I am using a free trial Azure account and attempting to implement CI CD for ML. I turned my firewall off and attempted as well but still the issue persists.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/imvGo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/imvGo.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1663480318187,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure",
            "azure-devops",
            "azure-machine-learning-service"
        ],
        "Question_view_count":40.0,
        "Owner_creation_time":1501747110080,
        "Owner_last_access_time":1664026893236,
        "Owner_reputation":51.0,
        "Owner_up_votes":4.0,
        "Owner_down_votes":0.0,
        "Owner_views":47.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73760407",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: unable to connect azure devops and ; content:<p>i have created an automated service principal from the service requests on azure devops with sufficient permissions. now, when i am trying to create an artifact which is an ml model (registered) it is not auto populating the registered models and resulting in an error.<\/p>\n<p>i am using a free trial azure account and attempting to implement ci cd for ml. i turned my firewall off and attempted as well but still the issue persists.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/imvgo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/imvgo.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is unable to connect Azure DevOps and Azure ML, despite creating an automated service principal with sufficient permissions and turning off the firewall."
    },
    {
        "Question_id":null,
        "Question_title":"What are the recommended practices on how to use DDP with wandb?",
        "Question_body":"<p>I often use distributed data laoders in pytorch DDP and often just check the rank and have only rank 0 log. Is that the recommended way to use DDP and wandb?<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1631289824937,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":null,
        "Question_view_count":324.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/what-are-the-recommended-practices-on-how-to-use-ddp-with-wandb\/502",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":1376,
                "name":"Sanyam Bhutani",
                "username":"bhutanisanyam1",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/bhutanisanyam1\/{size}\/18_2.png",
                "created_at":"2021-09-13T17:17:20.017Z",
                "cooked":"<p><a href=\"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/distributed-training#logging-distributed-training-experiments-with-w-and-b\">Here<\/a> is link to the docs sharing the relevant suggestions. Please let me know incase you have any follow up Qs <img src=\"https:\/\/emoji.discourse-cdn.com\/twitter\/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"><\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-09-13T17:17:20.017Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":12,
                "readers_count":11,
                "score":32.4,
                "yours":false,
                "topic_id":502,
                "topic_slug":"what-are-the-recommended-practices-on-how-to-use-ddp-with-wandb",
                "display_username":"Sanyam Bhutani",
                "primary_group_name":"team",
                "flair_name":"team",
                "flair_url":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/27bab8f920bcd41717e467ec0a2929adc33869e5.png",
                "flair_bg_color":"ffffff",
                "flair_color":"",
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/docs.wandb.ai\/guides\/track\/advanced\/distributed-training#logging-distributed-training-experiments-with-w-and-b",
                        "internal":false,
                        "reflection":false,
                        "clicks":3
                    }
                ],
                "read":true,
                "user_title":"Community Team",
                "title_is_group":true,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":2
                    }
                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":5,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":5334,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-04-20T18:02:05.406Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":3,
                "post_type":3,
                "updated_at":"2022-04-20T18:02:05.406Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":502,
                "topic_slug":"what-are-the-recommended-practices-on-how-to-use-ddp-with-wandb",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: what are the recommended practices on how to use ddp with ?; content:<p>i often use distributed data laoders in pytorch ddp and often just check the rank and have only rank 0 log. is that the recommended way to use ddp and ?<\/p>\n<p>thanks!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking about the recommended practices for using distributed data loaders in PyTorch DDP, and whether it is sufficient to only check the rank and have only rank 0 log."
    },
    {
        "Question_id":66266759.0,
        "Question_title":"Convert jpeg image data stored in AWS s3 to TFRecords where the sub-directory is the unique label associated with these images using AWS SageMaker",
        "Question_body":"<p>I have a directory of jpeg images in AWS s3 where the sub-directory is the unique label associated with these images. I am attempting to follow this <a href=\"https:\/\/github.com\/tensorflow\/models\/blob\/f87a58cd96d45de73c9a8330a06b2ab56749a7fa\/research\/inception\/inception\/data\/build_image_data.py\" rel=\"nofollow noreferrer\">example<\/a> using AWS SageMaker and I am making a mess of input and output paths while being inexperienced with flags. Any guidance on applying the linked solution using s3 and SageMaker or another approach to achieve the output of TFRecords then saved back to s3 would be greatly appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0.0,
        "Question_creation_time":1613676013737,
        "Question_favorite_count":1.0,
        "Question_score":0.0,
        "Question_tags":[
            "tensorflow",
            "amazon-s3",
            "tensorflow-datasets",
            "amazon-sagemaker",
            "tfrecord"
        ],
        "Question_view_count":316.0,
        "Owner_creation_time":1554323448856,
        "Owner_last_access_time":1633020158367,
        "Owner_reputation":57.0,
        "Owner_up_votes":4.0,
        "Owner_down_votes":0.0,
        "Owner_views":3.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66266759",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: convert jpeg image data stored in aws s3 to tfrecords where the sub-directory is the unique label associated with these images using ; content:<p>i have a directory of jpeg images in aws s3 where the sub-directory is the unique label associated with these images. i am attempting to follow this <a href=\"https:\/\/github.com\/tensorflow\/models\/blob\/f87a58cd96d45de73c9a8330a06b2ab56749a7fa\/research\/inception\/inception\/data\/build_image_data.py\" rel=\"nofollow noreferrer\">example<\/a> using  and i am making a mess of input and output paths while being inexperienced with flags. any guidance on applying the linked solution using s3 and  or another approach to achieve the output of tfrecords then saved back to s3 would be greatly appreciated.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is attempting to convert jpeg image data stored in AWS S3 to TFRecords, where the sub-directory is the unique label associated with the images."
    },
    {
        "Question_id":73279871.0,
        "Question_title":"Proper Format of Vertex AI AutoML Action Recognition Data Labels",
        "Question_body":"<p>I'm trying to build an action recognition model in Vertex AI AutoML. I've studied the documentation thoroughly, but so far my model is not able to make any decent predictions in the wild. I've made three attempts so far, and my most recent attempt had a precision-recall curve that could be described as 'respectable', but the predictions are really awful. I'll try to explain my process below as best as I can.<\/p>\n<h2>The Raw Data<\/h2>\n<p>I recorded the same action in 34 ~3 min videos, with the number of actions in each video varying between 30 and 100. The actions themselves take &lt; 1 second. I recorded the data from 4 cameras at multiple angles, and because I was moving around a lot, there was plenty of variance in each action performed. While each raw video contains only one action, there are a total of six classes of action we hope to identify.<\/p>\n<h2>First Model Attempt<\/h2>\n<p>According to the Vertex AI documentation, it's expecting time segments for the actions The annotation JSONL\/CSV documentation says as much, but somewhere else in the documentation it says it's expecting the maximal point at which the action is performed if you wish to label the videos inside the console. Anyways, I created a labeling job and my team and I labeled all the time segments for the actions in the videos. The precision-recall curve alluded to some kind of data leakage, and when we inspected the batch prediction results we discovered that it appeared that the model was training on the 0th frame of the time segment. We were careful not to include any frames that weren't part of the action, but due to the nature of the actions, they all essentially start and end at a 'neutral' spot. At seemingly random intervals in the video, multiple or all actions would be labeled, but ONLY in those spots.<\/p>\n<h2>Second Attempt<\/h2>\n<p>We took the annotation data that we had built with the labeling job and chopped up the original videos into a series of subclips. We had all the labels and the time segments, so we did this with a simple script. We did not remove any of the frames of the video, so the neutral position in the beginning and end frames were still present. The precision-recall curve again looked suspicious, but slightly better. Inference in the wild yielded the same results.<\/p>\n<h2>Third Attempt<\/h2>\n<p>After further reviewing the documentation, Vertex AI appeared to contradict itself in what it expects in the data labels:<\/p>\n<blockquote>\n<p>When the action starts appearing that you want to identify, slowly\nprogress through till you find the center or the most representative\nmoment of the action using &quot;Next frame&quot; option.<\/p>\n<\/blockquote>\n<p>To avoid spending a ton of time on another labeling task (takes us about three days), we labeled a subset of the original subclip dataset according to this information and trained a model to analyze the precision-recall curve. FINALLY something much more respectable. However, the inferences in the wild were still terrible, suffering from the same.<\/p>\n<p>My question is: <strong>do I need to annotate negative action sequences?<\/strong> In the object tracking or object detection documentation it says that adding a <code>None_of_the_above<\/code> label would help the model to identify that which it doesn't need to focus on. And again in the action recognition documentation it points out a limitation in the labeling console:<\/p>\n<blockquote>\n<p>Limitation: There's a limitation when using the VAR labeling console,\nwhich means if you want to use the labeling tool to label actions, you\nmust label all the actions in that video.<\/p>\n<\/blockquote>\n<p>I can write a script to fill in the dead space in the video as a negative action sequence, but I'd like to know what the best practice is before going down that route and spending the money to train yet another terrible model.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2.0,
        "Question_creation_time":1659970389697,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "google-cloud-platform",
            "computer-vision",
            "automl",
            "google-cloud-automl",
            "google-cloud-vertex-ai"
        ],
        "Question_view_count":44.0,
        "Owner_creation_time":1360536048187,
        "Owner_last_access_time":1663951121943,
        "Owner_reputation":45.0,
        "Owner_up_votes":5.0,
        "Owner_down_votes":0.0,
        "Owner_views":22.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Miami, FL, USA",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73279871",
        "Tool":"Vertex AI",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: proper format of  automl action recognition data labels; content:<p>i'm trying to build an action recognition model in  automl. i've studied the documentation thoroughly, but so far my model is not able to make any decent predictions in the wild. i've made three attempts so far, and my most recent attempt had a precision-recall curve that could be described as 'respectable', but the predictions are really awful. i'll try to explain my process below as best as i can.<\/p>\n<h2>the raw data<\/h2>\n<p>i recorded the same action in 34 ~3 min videos, with the number of actions in each video varying between 30 and 100. the actions themselves take &lt; 1 second. i recorded the data from 4 cameras at multiple angles, and because i was moving around a lot, there was plenty of variance in each action performed. while each raw video contains only one action, there are a total of six classes of action we hope to identify.<\/p>\n<h2>first model attempt<\/h2>\n<p>according to the  documentation, it's expecting time segments for the actions the annotation jsonl\/csv documentation says as much, but somewhere else in the documentation it says it's expecting the maximal point at which the action is performed if you wish to label the videos inside the console. anyways, i created a labeling job and my team and i labeled all the time segments for the actions in the videos. the precision-recall curve alluded to some kind of data leakage, and when we inspected the batch prediction results we discovered that it appeared that the model was training on the 0th frame of the time segment. we were careful not to include any frames that weren't part of the action, but due to the nature of the actions, they all essentially start and end at a 'neutral' spot. at seemingly random intervals in the video, multiple or all actions would be labeled, but only in those spots.<\/p>\n<h2>second attempt<\/h2>\n<p>we took the annotation data that we had built with the labeling job and chopped up the original videos into a series of subclips. we had all the labels and the time segments, so we did this with a simple script. we did not remove any of the frames of the video, so the neutral position in the beginning and end frames were still present. the precision-recall curve again looked suspicious, but slightly better. inference in the wild yielded the same results.<\/p>\n<h2>third attempt<\/h2>\n<p>after further reviewing the documentation,  appeared to contradict itself in what it expects in the data labels:<\/p>\n<blockquote>\n<p>when the action starts appearing that you want to identify, slowly\nprogress through till you find the center or the most representative\nmoment of the action using &quot;next frame&quot; option.<\/p>\n<\/blockquote>\n<p>to avoid spending a ton of time on another labeling task (takes us about three days), we labeled a subset of the original subclip dataset according to this information and trained a model to analyze the precision-recall curve. finally something much more respectable. however, the inferences in the wild were still terrible, suffering from the same.<\/p>\n<p>my question is: <strong>do i need to annotate negative action sequences?<\/strong> in the object tracking or object detection documentation it says that adding a <code>none_of_the_above<\/code> label would help the model to identify that which it doesn't need to focus on. and again in the action recognition documentation it points out a limitation in the labeling console:<\/p>\n<blockquote>\n<p>limitation: there's a limitation when using the var labeling console,\nwhich means if you want to use the labeling tool to label actions, you\nmust label all the actions in that video.<\/p>\n<\/blockquote>\n<p>i can write a script to fill in the dead space in the video as a negative action sequence, but i'd like to know what the best practice is before going down that route and spending the money to train yet another terrible model.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is trying to build an action recognition model in AutoML, but their attempts so far have failed to produce acceptable results. The user is uncertain about how to properly format their data labels for the model, and is asking for best practices regarding the annotation of negative action sequences."
    },
    {
        "Question_id":55147110.0,
        "Question_title":"Sending Azure Blob Storage csv file as an attachment to user on Microsoft Azure",
        "Question_body":"<p>I have created a Logic App in Microsoft Azure. I am having a scheduler recurrence first and then I am calling Azure ML Batch Job with Job Input and Output.  After this now, I have to send email to the user with azure blob storage .csv file generated in Azure after running Azure ML job. So, how can I send the azure blob storage file to user after running Azure ML Batch Job with Job Input and Output?  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1552495494130,
        "Question_favorite_count":null,
        "Question_score":2.0,
        "Question_tags":[
            "azure",
            "email-attachments",
            "azure-logic-apps",
            "azure-machine-learning-studio",
            "azure-blob-storage"
        ],
        "Question_view_count":3796.0,
        "Owner_creation_time":1552323389192,
        "Owner_last_access_time":1589532064896,
        "Owner_reputation":19.0,
        "Owner_up_votes":0.0,
        "Owner_down_votes":0.0,
        "Owner_views":16.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55147110",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: sending azure blob storage csv file as an attachment to user on microsoft azure; content:<p>i have created a logic app in microsoft azure. i am having a scheduler recurrence first and then i am calling  batch job with job input and output.  after this now, i have to send email to the user with azure blob storage .csv file generated in azure after running  job. so, how can i send the azure blob storage file to user after running  batch job with job input and output?  <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user needs to send an Azure Blob Storage CSV file as an attachment to a user after running an Azure ML Batch Job with Job Input and Output."
    },
    {
        "Question_id":68606277.0,
        "Question_title":"AWS Sagemaker DeepAR Validation Error Additional Properties not allowed ('training' was unexpected)",
        "Question_body":"<p>I don't know what the issue is. Here is the code:<\/p>\n<pre><code>estimator = sagemaker.estimator.Estimator(\n    image_uri=image_name,\n    sagemaker_session=sagemaker_session,\n    role=role,\n    train_instance_count=1,\n    train_instance_type=&quot;ml.m5.large&quot;,\n    base_job_name=&quot;deepar-stock&quot;,\n    output_path=s3_output_path,\n)\n\nhyperparameters = {\n    &quot;time_freq&quot;: &quot;24H&quot;,\n    &quot;epochs&quot;: &quot;100&quot;,\n    &quot;early_stopping_patience&quot;: &quot;10&quot;,\n    &quot;mini_batch_size&quot;: &quot;64&quot;,\n    &quot;learning_rate&quot;: &quot;5E-4&quot;,\n    &quot;context_length&quot;: str(context_length),\n    &quot;prediction_length&quot;: str(prediction_length),\n    &quot;likelihood&quot;: &quot;gaussian&quot;,\n}\n\nestimator.set_hyperparameters(**hyperparameters)\n\n%%time\n\nestimator.fit(inputs=f&quot;{s3_data_path}\/train\/&quot;)\n<\/code><\/pre>\n<p>And when I try to train the model I get the following error (in its entirety).<\/p>\n<pre><code>------------------------------------------------------------------------\n\n---\nUnexpectedStatusException                 Traceback (most recent call last)\n&lt;timed eval&gt; in &lt;module&gt;\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/estimator.py in fit(self, inputs, wait, logs, job_name, experiment_config)\n    681         self.jobs.append(self.latest_training_job)\n    682         if wait:\n--&gt; 683             self.latest_training_job.wait(logs=logs)\n    684 \n    685     def _compilation_job_name(self):\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/estimator.py in wait(self, logs)\n   1626         # If logs are requested, call logs_for_jobs.\n   1627         if logs != &quot;None&quot;:\n-&gt; 1628             self.sagemaker_session.logs_for_job(self.job_name, wait=True, log_type=logs)\n   1629         else:\n   1630             self.sagemaker_session.wait_for_job(self.job_name)\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in logs_for_job(self, job_name, wait, poll, log_type)\n   3658 \n   3659         if wait:\n-&gt; 3660             self._check_job_status(job_name, description, &quot;TrainingJobStatus&quot;)\n   3661             if dot:\n   3662                 print()\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/sagemaker\/session.py in _check_job_status(self, job, desc, status_key_name)\n   3218                 ),\n   3219                 allowed_statuses=[&quot;Completed&quot;, &quot;Stopped&quot;],\n-&gt; 3220                 actual_status=status,\n   3221             )\n   3222 \nUnexpectedStatusException: Error for Training job deepar-2021-07-31-22-25-54-110: Failed. Reason: ClientError: Unable to initialize the algorithm. Failed to validate input data configuration. (caused by ValidationError)\n\nCaused by: Additional properties are not allowed ('training' was unexpected)\n\nFailed validating 'additionalProperties' in schema:\n    {'$schema': 'http:\/\/json-schema.org\/draft-04\/schema#',\n     'additionalProperties': False,\n     'anyOf': [{'required': ['train']}, {'required': ['state']}],\n     'definitions': {'data_channel': {'properties': {'ContentType': {'enum': ['json',\n                                                                              'json.gz',\n                                                                              'parquet',\n                                                                              'auto'],\n                                                                     'type': 'string'},\n                                                     'RecordWrapperType': {'enum': ['None'],\n\nOn instance:\n    {'training': {'RecordWrapperType': 'None',\n                  'S3DistributionType': 'FullyReplicated',\n                  'TrainingInputMode': 'File'}}\n<\/code><\/pre>\n<p>Here it says <code>'training' was unexpected<\/code>. I don't know why it says <code>'training'<\/code> on that last line <code>On instance:<\/code>. I don't know how to solve this. I've looked at other pages for help but I can't find a straight answer. I know that my data is structured right. The errors seem to be with the hyperparameters but I don't know that for sure. Please help!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1627771170133,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "python",
            "amazon-sagemaker",
            "deepar"
        ],
        "Question_view_count":157.0,
        "Owner_creation_time":1405609706592,
        "Owner_last_access_time":1660146579012,
        "Owner_reputation":3113.0,
        "Owner_up_votes":145.0,
        "Owner_down_votes":5.0,
        "Owner_views":317.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Michigan, United States",
        "Question_last_edit_time":1627771514767,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68606277",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  deepar validation error additional properties not allowed ('training' was unexpected); content:<p>i don't know what the issue is. here is the code:<\/p>\n<pre><code>estimator = .estimator.estimator(\n    image_uri=image_name,\n    _session=_session,\n    role=role,\n    train_instance_count=1,\n    train_instance_type=&quot;ml.m5.large&quot;,\n    base_job_name=&quot;deepar-stock&quot;,\n    output_path=s3_output_path,\n)\n\nhyperparameters = {\n    &quot;time_freq&quot;: &quot;24h&quot;,\n    &quot;epochs&quot;: &quot;100&quot;,\n    &quot;early_stopping_patience&quot;: &quot;10&quot;,\n    &quot;mini_batch_size&quot;: &quot;64&quot;,\n    &quot;learning_rate&quot;: &quot;5e-4&quot;,\n    &quot;context_length&quot;: str(context_length),\n    &quot;prediction_length&quot;: str(prediction_length),\n    &quot;likelihood&quot;: &quot;gaussian&quot;,\n}\n\nestimator.set_hyperparameters(**hyperparameters)\n\n%%time\n\nestimator.fit(inputs=f&quot;{s3_data_path}\/train\/&quot;)\n<\/code><\/pre>\n<p>and when i try to train the model i get the following error (in its entirety).<\/p>\n<pre><code>------------------------------------------------------------------------\n\n---\nunexpectedstatusexception                 traceback (most recent call last)\n&lt;timed eval&gt; in &lt;module&gt;\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/estimator.py in fit(self, inputs, wait, logs, job_name, experiment_config)\n    681         self.jobs.append(self.latest_training_job)\n    682         if wait:\n--&gt; 683             self.latest_training_job.wait(logs=logs)\n    684 \n    685     def _compilation_job_name(self):\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/estimator.py in wait(self, logs)\n   1626         # if logs are requested, call logs_for_jobs.\n   1627         if logs != &quot;none&quot;:\n-&gt; 1628             self._session.logs_for_job(self.job_name, wait=true, log_type=logs)\n   1629         else:\n   1630             self._session.wait_for_job(self.job_name)\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/session.py in logs_for_job(self, job_name, wait, poll, log_type)\n   3658 \n   3659         if wait:\n-&gt; 3660             self._check_job_status(job_name, description, &quot;trainingjobstatus&quot;)\n   3661             if dot:\n   3662                 print()\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/\/session.py in _check_job_status(self, job, desc, status_key_name)\n   3218                 ),\n   3219                 allowed_statuses=[&quot;completed&quot;, &quot;stopped&quot;],\n-&gt; 3220                 actual_status=status,\n   3221             )\n   3222 \nunexpectedstatusexception: error for training job deepar-2021-07-31-22-25-54-110: failed. reason: clienterror: unable to initialize the algorithm. failed to validate input data configuration. (caused by validationerror)\n\ncaused by: additional properties are not allowed ('training' was unexpected)\n\nfailed validating 'additionalproperties' in schema:\n    {'$schema': 'http:\/\/json-schema.org\/draft-04\/schema#',\n     'additionalproperties': false,\n     'anyof': [{'required': ['train']}, {'required': ['state']}],\n     'definitions': {'data_channel': {'properties': {'contenttype': {'enum': ['json',\n                                                                              'json.gz',\n                                                                              'parquet',\n                                                                              'auto'],\n                                                                     'type': 'string'},\n                                                     'recordwrappertype': {'enum': ['none'],\n\non instance:\n    {'training': {'recordwrappertype': 'none',\n                  's3distributiontype': 'fullyreplicated',\n                  'traininginputmode': 'file'}}\n<\/code><\/pre>\n<p>here it says <code>'training' was unexpected<\/code>. i don't know why it says <code>'training'<\/code> on that last line <code>on instance:<\/code>. i don't know how to solve this. i've looked at other pages for help but i can't find a straight answer. i know that my data is structured right. the errors seem to be with the hyperparameters but i don't know that for sure. please help!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error that additional properties are not allowed ('training' was unexpected) when attempting to train a model, and is unsure of how to solve the issue."
    },
    {
        "Question_id":60054554.0,
        "Question_title":"How to add more tables in mlflow?",
        "Question_body":"<p>I want to add more tables in mlflow.<\/p>\n\n<p>As mlflow provide facility to do machine learning experiments but I just want to add those experiment in project level that User can create multiple projects and in that project multiple experiment can be performed.<\/p>\n\n<p>So, Is their any way to achieve this feature in mlflow <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2.0,
        "Question_creation_time":1580809398747,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "mlflow"
        ],
        "Question_view_count":208.0,
        "Owner_creation_time":1536230167272,
        "Owner_last_access_time":1664083164110,
        "Owner_reputation":720.0,
        "Owner_up_votes":21.0,
        "Owner_down_votes":6.0,
        "Owner_views":134.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Surat, Gujarat, India",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60054554",
        "Tool":"MLflow",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to add more tables in ?; content:<p>i want to add more tables in .<\/p>\n\n<p>as  provide facility to do machine learning experiments but i just want to add those experiment in project level that user can create multiple projects and in that project multiple experiment can be performed.<\/p>\n\n<p>so, is their any way to achieve this feature in  <\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user wants to add more tables in and is looking for a way to do so in order to create multiple projects and perform multiple experiments."
    },
    {
        "Question_id":73780686.0,
        "Question_title":"How to set up security group in vpc only mode in sagemaker?",
        "Question_body":"<p>I'm setting a vpc only mode in sagemaker studio . based on documentation here <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/studio-notebooks-and-internet-access.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/studio-notebooks-and-internet-access.html<\/a>, it  is stated that &quot;This is required for connectivity between the JupyterServer app and the KernelGateway apps. You must allow access to at least ports in the range 8192-65535.&quot; i have set up following security group as below, I understand that these port needs to open for connectivity between the jupyter server and kernel gateway so what should one user for CidrIp instead of 0.0.0.0\/0.<\/p>\n<pre><code>SecurityGroup:\n        Type: AWS::EC2::SecurityGroup\n        Properties:\n            GroupDescription: &quot;Open tcp&quot;\n            VpcId: !Ref VPC          \n            SecurityGroupIngress:\n                - IpProtocol: tcp\n                  FromPort: 8192\n                  ToPort: 65535\n                  CidrIp: 0.0.0.0\/0   \n            SecurityGroupEgress:\n                - IpProtocol: tcp\n                  FromPort: 8192\n                  ToPort: 65535\n                  CidrIp: 0.0.0.0\/0  \n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1663636366313,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "tcp",
            "amazon-sagemaker",
            "amazon-vpc"
        ],
        "Question_view_count":19.0,
        "Owner_creation_time":1590797441983,
        "Owner_last_access_time":1664049080543,
        "Owner_reputation":525.0,
        "Owner_up_votes":69.0,
        "Owner_down_votes":0.0,
        "Owner_views":98.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73780686",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to set up security group in vpc only mode in ?; content:<p>i'm setting a vpc only mode in  studio . based on documentation here <a href=\"https:\/\/docs.aws.amazon.com\/\/latest\/dg\/studio-notebooks-and-internet-access.html\" rel=\"nofollow noreferrer\">https:\/\/docs.aws.amazon.com\/\/latest\/dg\/studio-notebooks-and-internet-access.html<\/a>, it  is stated that &quot;this is required for connectivity between the jupyterserver app and the kernelgateway apps. you must allow access to at least ports in the range 8192-65535.&quot; i have set up following security group as below, i understand that these port needs to open for connectivity between the jupyter server and kernel gateway so what should one user for cidrip instead of 0.0.0.0\/0.<\/p>\n<pre><code>securitygroup:\n        type: aws::ec2::securitygroup\n        properties:\n            groupdescription: &quot;open tcp&quot;\n            vpcid: !ref vpc          \n            securitygroupingress:\n                - ipprotocol: tcp\n                  fromport: 8192\n                  toport: 65535\n                  cidrip: 0.0.0.0\/0   \n            securitygroupegress:\n                - ipprotocol: tcp\n                  fromport: 8192\n                  toport: 65535\n                  cidrip: 0.0.0.0\/0  \n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user should replace 0.0.0.0\/0 with the specific CIDR IP address for the security group in order to allow connectivity between the JupyterServer app and the KernelGateway apps."
    },
    {
        "Question_id":69827748.0,
        "Question_title":"get metrics out of AutoMLRun based on test_data",
        "Question_body":"<p>I\u2019m using the following script to execute an AutoML run, also passing the test dataset<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>automl_settings = {\n    &quot;n_cross_validations&quot;: 10,\n    &quot;primary_metric&quot;: 'spearman_correlation',\n    &quot;enable_early_stopping&quot;: True,\n    &quot;max_concurrent_iterations&quot;: 10, \n    &quot;max_cores_per_iteration&quot;: -1,   \n    &quot;experiment_timeout_hours&quot;: 1,\n    &quot;featurization&quot;: 'auto',\n    &quot;verbosity&quot;: logging.INFO}\nautoml_config = AutoMLConfig(task = 'regression',\n                             debug_log = 'automl_errors.log',\n                             compute_target = compute_target,\n                             training_data = training_data,\n                             test_data = test_data,\n                             label_column_name = label_column_name,\n                             model_explainability = True,\n                             **automl_settings                            )\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0.0,
        "Question_creation_time":1635954155380,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":[
            "azure-machine-learning-service"
        ],
        "Question_view_count":85.0,
        "Owner_creation_time":1405457120427,
        "Owner_last_access_time":1663947733100,
        "Owner_reputation":3359.0,
        "Owner_up_votes":1187.0,
        "Owner_down_votes":14.0,
        "Owner_views":555.0,
        "Answer_body":"<p>Note that the TEST DATASET SUPPORT is a feature still in PRIVATE PREVIEW. It'll probably be released as PUBLIC PREVIEW later in NOVEMBER, but until then, you need to be enrolled in the PRIVATE PREVIEW in order to see the &quot;Test runs and metrics&quot; in the UI. You can send me an email to cesardl at microsoft dot com and send me your AZURE SUBSCRIPTION ID to be enabled so you see it in the UI.<\/p>\n<p>You can see further info on how to get started here:\n<a href=\"https:\/\/github.com\/Azure\/automl-testdataset-preview\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/automl-testdataset-preview<\/a><\/p>\n<p>About how to use it, you need to either provide the test_Data (specific Test AML Tabular Dataset that for instance you loaded from a file os split manually previously)\nor you can provide a test_size which is the % (i.e. 0.2 is 20%) to be split from the single\/original dataset.<\/p>\n<p>About the TEST metrics, since you can make multiple TEST runs against a single model, you need to go to the specific TEST run available under the link &quot;Test results&quot;<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3pPPS.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1635964127852,
        "Answer_score":3.0,
        "Owner_location":"Seattle, WA, USA",
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69827748",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: get metrics out of automlrun based on test_data; content:<p>i\u2019m using the following script to execute an automl run, also passing the test dataset<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>automl_settings = {\n    &quot;n_cross_validations&quot;: 10,\n    &quot;primary_metric&quot;: 'spearman_correlation',\n    &quot;enable_early_stopping&quot;: true,\n    &quot;max_concurrent_iterations&quot;: 10, \n    &quot;max_cores_per_iteration&quot;: -1,   \n    &quot;experiment_timeout_hours&quot;: 1,\n    &quot;featurization&quot;: 'auto',\n    &quot;verbosity&quot;: logging.info}\nautoml_config = automlconfig(task = 'regression',\n                             debug_log = 'automl_errors.log',\n                             compute_target = compute_target,\n                             training_data = training_data,\n                             test_data = test_data,\n                             label_column_name = label_column_name,\n                             model_explainability = true,\n                             **automl_settings                            )\n<\/code><\/pre>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is attempting to use an automated machine learning run to get metrics out of a test dataset."
    },
    {
        "Question_id":null,
        "Question_title":"'Remote end closed connection without response' in log_batch()",
        "Question_body":"The following exception is raised through a call to log_batch(). Anyone experienced something similar?\n\n\n\n\nraise ConnectionError(err, request=request)\n\nrequests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1576600519000,
        "Question_favorite_count":null,
        "Question_score":null,
        "Question_tags":null,
        "Question_view_count":2.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/9R3dx94gWns",
        "Tool":"MLflow",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: 'remote end closed connection without response' in log_batch(); content:the following exception is raised through a call to log_batch(). anyone experienced something similar?\n\n\n\n\nraise connectionerror(err, request=request)\n\nrequests.exceptions.connectionerror: ('connection aborted.', remotedisconnected('remote end closed connection without response',))",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user experienced a connection error with a remote end closing the connection without response, resulting in a requests.exceptions.connectionerror being raised."
    },
    {
        "Question_id":48514346.0,
        "Question_title":"ERROR:root:Line magic function `%azureml` not found?",
        "Question_body":"<p>I have created a \"Blank Jupyter Notebook\" project in Azure ML Workbench. When I try to run the Sample notebook found in the project, I get this error message:<\/p>\n\n<pre><code>ERROR:root:Line magic function `%azureml` not found.\n<\/code><\/pre>\n\n<p>What is missing?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1.0,
        "Question_creation_time":1517289481150,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning-workbench"
        ],
        "Question_view_count":259.0,
        "Owner_creation_time":1469113829743,
        "Owner_last_access_time":1663792327612,
        "Owner_reputation":2166.0,
        "Owner_up_votes":44.0,
        "Owner_down_votes":1.0,
        "Owner_views":151.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48514346",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: error:root:line magic function `%` not found?; content:<p>i have created a \"blank jupyter notebook\" project in  workbench. when i try to run the sample notebook found in the project, i get this error message:<\/p>\n\n<pre><code>error:root:line magic function `%` not found.\n<\/code><\/pre>\n\n<p>what is missing?<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an error message when trying to run a sample notebook in an Azure ML Workbench project and is wondering what is missing."
    },
    {
        "Question_id":null,
        "Question_title":"Interprete gradient graphs",
        "Question_body":"<p>Hi everyone,<br>\nAttached is the gradient histograms of my training. It seems that the gradient for lin1.weight and line2.weight are mostly zero everywhere.  Does it mean that the model doesn\u2019t learn anything from these parameters and should I exclude them my optimizer?<\/p>\n<p>Thank you very much<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367.png\" data-download-href=\"\/uploads\/short-url\/uhFmZAeJe0w8aS6Cbez7CQKl5j1.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_690x238.png\" alt=\"image\" data-base62-sha1=\"uhFmZAeJe0w8aS6Cbez7CQKl5j1\" width=\"690\" height=\"238\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_690x238.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_1035x357.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_1380x476.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/optimized\/1X\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1808\u00d7624 111 KB<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1662125101171,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":180.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/interprete-gradient-graphs\/3052",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":7259,
                "name":"Mohammad Bakir",
                "username":"mohammadbakir",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/a9a28c\/{size}.png",
                "created_at":"2022-09-07T20:41:05.455Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/thongnt\">@thongnt<\/a> , it\u2019s difficult to say why your gradients are zeroed out. Assuming it\u2019s not an error in your code, you may be encountering a vanishing gradient which could be leading to overflow \/ underflow issues. Here are some debugging steps I can suggest. 1) ensure the that you\u2019re calling <code>optimizer.zero_grad()<\/code> before each batch 2). try normalizing the weights and inputs 3). Try implementing gradient clipping. Please let me know if any of these work for you.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-09-07T20:41:05.455Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":2,
                "readers_count":1,
                "score":0.4,
                "yours":false,
                "topic_id":3052,
                "topic_slug":"interprete-gradient-graphs",
                "display_username":"Mohammad Bakir",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1458,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":7324,
                "name":"Mohammad Bakir",
                "username":"mohammadbakir",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/m\/a9a28c\/{size}.png",
                "created_at":"2022-09-12T23:12:34.255Z",
                "cooked":"<p>Hi <a class=\"mention\" href=\"\/u\/thongnt\">@thongnt<\/a> ,  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-09-12T23:12:34.255Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":3052,
                "topic_slug":"interprete-gradient-graphs",
                "display_username":"Mohammad Bakir",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1458,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":8103,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-11-11T23:12:37.911Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":4,
                "post_type":3,
                "updated_at":"2022-11-11T23:12:37.911Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":3052,
                "topic_slug":"interprete-gradient-graphs",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: interprete gradient graphs; content:<p>hi everyone,<br>\nattached is the gradient histograms of my training. it seems that the gradient for lin1.weight and line2.weight are mostly zero everywhere.  does it mean that the model doesn\u2019t learn anything from these parameters and should i exclude them my optimizer?<\/p>\n<p>thank you very much<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/1x\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367.png\" data-download-href=\"\/uploads\/short-url\/uhfmzaeje0w8as6cbez7cqkl5j1.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_690x238.png\" alt=\"image\" data-base62-sha1=\"uhfmzaeje0w8as6cbez7cqkl5j1\" width=\"690\" height=\"238\" srcset=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_690x238.png, https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_1035x357.png 1.5x, https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_1380x476.png 2x\" data-small-upload=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/optimized\/1x\/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"><\/use><\/svg><span class=\"filename\">image<\/span><span class=\"informations\">1808\u00d7624 111 kb<\/span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"><\/use><\/svg>\n<\/div><\/a><\/div><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is asking if the mostly zero gradients for lin1.weight and line2.weight mean that the model isn't learning anything from these parameters and if they should be excluded from the optimizer."
    },
    {
        "Question_id":null,
        "Question_title":"How to prevent disassociating SageMaker LifecycleConfig unintentionally",
        "Question_body":"When you go to SageMaker Notebook Instance edit screen in AWS Web Console (to change the Instance Type for example), it is sometimes the case that Lifecycle configuration is popped up as No Configuration even though the configuration is actually set earlier. This results in an unintentional disassociation of the LifecycleConfig because it's easy to save the instance change without noticing the change in Lifecycle Config. This is a serious problem for us. I was able to reproduce this issue in Chrome and Firefox (but you need to try several times to repro the issue).\n\nI am in the position of provisioning different cloud resources for the end users and I need a way to systematically prevent this disassociation to happen. I considered applying an IAM policy that denies the update operation containing the change in the LifecycleConfig of notebooks, but there seems no condition key for LifecycleConfig which makes me think this approach isn't feasible.\n\nWhat can I do?\n\nThanks.",
        "Question_answer_count":0,
        "Question_comment_count":null,
        "Question_creation_time":1646363723581,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker"
        ],
        "Question_view_count":28.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QUTvkDhX_yQXyW7WpFinO_vA\/how-to-prevent-disassociating-sage-maker-lifecycle-config-unintentionally",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[

        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how to prevent disassociating  lifecycleconfig unintentionally; content:when you go to  notebook instance edit screen in aws web console (to change the instance type for example), it is sometimes the case that lifecycle configuration is popped up as no configuration even though the configuration is actually set earlier. this results in an unintentional disassociation of the lifecycleconfig because it's easy to save the instance change without noticing the change in lifecycle config. this is a serious problem for us. i was able to reproduce this issue in chrome and firefox (but you need to try several times to repro the issue).\n\ni am in the position of provisioning different cloud resources for the end users and i need a way to systematically prevent this disassociation to happen. i considered applying an iam policy that denies the update operation containing the change in the lifecycleconfig of notebooks, but there seems no condition key for lifecycleconfig which makes me think this approach isn't feasible.\n\nwhat can i do?\n\nthanks.",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a way to systematically prevent unintentional disassociation of lifecycleconfig when making changes to notebook instances in the AWS web console."
    },
    {
        "Question_id":57960177.0,
        "Question_title":"issue with the datadrift notebook",
        "Question_body":"<p>when running this <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/monitor-models\/data-drift\/azure-ml-datadrift.ipynb\" rel=\"nofollow noreferrer\">Data Drift sample notebook<\/a>, I'm having issues running a particular cell :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>exp = Experiment(ws, datadrift._id)\ndd_run = Run(experiment=exp, run_id=run)\nRunDetails(dd_run).show()\n<\/code><\/pre>\n\n<p>This generates the following traceback : <\/p>\n\n<pre><code>(...)\nImportError: cannot import name 'get_run_ids_and_metric_types_filter_expression'\n<\/code><\/pre>\n\n<p>I believe there might be a version issue with this notebook. I'm running AzureML SDK 1.0.60, and this sample is drawn from the 1.0.60 version of the notebook (at least the one in the master branch as of today)<\/p>\n\n<p>Or is this an issue with my environment?<\/p>\n\n<p>I also realized, by inspecting the output logs of the run that I'm getting a traceback on the job itself :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>The experiment failed. Finalizing run...\nTraceback (most recent call last):\n  File \"datadrift_run.py\", line 173, in &lt;module&gt;\n    run.run(target_date)\n  File \"datadrift_run.py\", line 100, in run\n    drift_main(arguments_drift)\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/playground-olivier\/azureml\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/mounts\/workspacefilestore\/azureml\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/_generate_script.py\", line 363, in main\n    'datadrift_id': args.datadrift_id\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/playground-olivier\/azureml\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/mounts\/workspacefilestore\/azureml\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/_generate_script.py\", line 75, in _get_drift_metrics\n    diff_metrics = dsdo.run()\n  File \"\/azureml-envs\/azureml_9a12ab39ef186b06eb543bbc347567d8\/lib\/python3.6\/site-packages\/azureml\/data\/_dataset_diff.py\", line 840, in run\n    base_profile_metrics = get_dataprofile_metrics(self.base_datasetprofile, self.config)\n  File \"\/azureml-envs\/azureml_9a12ab39ef186b06eb543bbc347567d8\/lib\/python3.6\/site-packages\/azureml\/data\/_dataset_diff.py\", line 163, in get_dataprofile_metrics\n    column_type = column_type_classifier[(dp.columns[c].value_counts is None, dp.columns[c].histogram is None)]\nKeyError: 'usaf'\n<\/code><\/pre>\n\n<p>These two are unrelated but generated by the same notebook.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4.0,
        "Question_creation_time":1568648053330,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "azure-machine-learning-service"
        ],
        "Question_view_count":103.0,
        "Owner_creation_time":1538275960603,
        "Owner_last_access_time":1658458641830,
        "Owner_reputation":381.0,
        "Owner_up_votes":75.0,
        "Owner_down_votes":2.0,
        "Owner_views":50.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":"Montreal, QC, Canada",
        "Question_last_edit_time":1568648619143,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57960177",
        "Tool":"Azure Machine Learning",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: issue with the datadrift notebook; content:<p>when running this <a href=\"https:\/\/github.com\/azure\/machinelearningnotebooks\/blob\/master\/how-to-use-\/monitor-models\/data-drift\/azure-ml-datadrift.ipynb\" rel=\"nofollow noreferrer\">data drift sample notebook<\/a>, i'm having issues running a particular cell :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>exp = experiment(ws, datadrift._id)\ndd_run = run(experiment=exp, run_id=run)\nrundetails(dd_run).show()\n<\/code><\/pre>\n\n<p>this generates the following traceback : <\/p>\n\n<pre><code>(...)\nimporterror: cannot import name 'get_run_ids_and_metric_types_filter_expression'\n<\/code><\/pre>\n\n<p>i believe there might be a version issue with this notebook. i'm running  sdk 1.0.60, and this sample is drawn from the 1.0.60 version of the notebook (at least the one in the master branch as of today)<\/p>\n\n<p>or is this an issue with my environment?<\/p>\n\n<p>i also realized, by inspecting the output logs of the run that i'm getting a traceback on the job itself :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>the experiment failed. finalizing run...\ntraceback (most recent call last):\n  file \"datadrift_run.py\", line 173, in &lt;module&gt;\n    run.run(target_date)\n  file \"datadrift_run.py\", line 100, in run\n    drift_main(arguments_drift)\n  file \"\/mnt\/batch\/tasks\/shared\/ls_root\/jobs\/playground-olivier\/\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/mounts\/workspacefilestore\/\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/_generate_script.py\", line 363, in main\n    'datadrift_id': args.datadrift_id\n  file \"\/mnt\/batch\/tasks\/shared\/ls_root\/jobs\/playground-olivier\/\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/mounts\/workspacefilestore\/\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/_generate_script.py\", line 75, in _get_drift_metrics\n    diff_metrics = dsdo.run()\n  file \"\/-envs\/_9a12ab39ef186b06eb543bbc347567d8\/lib\/python3.6\/site-packages\/\/data\/_dataset_diff.py\", line 840, in run\n    base_profile_metrics = get_dataprofile_metrics(self.base_datasetprofile, self.config)\n  file \"\/-envs\/_9a12ab39ef186b06eb543bbc347567d8\/lib\/python3.6\/site-packages\/\/data\/_dataset_diff.py\", line 163, in get_dataprofile_metrics\n    column_type = column_type_classifier[(dp.columns[c].value_counts is none, dp.columns[c].histogram is none)]\nkeyerror: 'usaf'\n<\/code><\/pre>\n\n<p>these two are unrelated but generated by the same notebook.<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having issues running a particular cell in the data drift sample notebook, and is also getting a traceback on the job itself."
    },
    {
        "Question_id":73451801.0,
        "Question_title":"AWS Sagemaker Error for Training job - Algorithm Error",
        "Question_body":"<p>I am receiving the following error when I try and train an XGBoost model and have no idea how to fix it. Any help please?<\/p>\n<pre><code>UnexpectedStatusException: Error for Training job sagemaker-xgboost-2022-08-22-21-37-39-774: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File &quot;\/miniconda3\/lib\/python3.6\/site-packages\/sagemaker_containers\/_trainer.py&quot;, line 84, in train\n    entrypoint()\n  File &quot;\/miniconda3\/lib\/python3.6\/site-packages\/sagemaker_xgboost_container\/training.py&quot;, line 94, in main\n    train(framework.training_env())\n  File &quot;\/miniconda3\/lib\/python3.6\/site-packages\/sagemaker_xgboost_container\/training.py&quot;, line 90, in train\n    run_algorithm_mode()\n  File &quot;\/miniconda3\/lib\/python3.6\/site-packages\/sagemaker_xgboost_container\/training.py&quot;, line 68, in run_algorithm_mode\n    checkpoint_config=checkpoint_config\n  File &quot;\/miniconda3\/lib\/python3.6\/site-packages\/sagemaker_xgboost_container\/algorithm_mode\/train.py&quot;, line 110, in sagemaker_train\n    validated_train_config = hyperparameters.validate(train_config)\n  File &quot;\/miniconda3\/lib\/python3.6\/site-packages\/sagemaker_algorithm_toolkit\/hyperparameter_validation.py&quot;, line 270, in validate\n    raise exc.UserError(&quot;Missing required hyperparameter: {}&quot;.format(hp)\n<\/code><\/pre>\n<p>My full notebook is too large to post here, but below I have also added an image of the code right before the training<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eXDtH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eXDtH.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0.0,
        "Question_creation_time":1661209444407,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "amazon-web-services",
            "amazon-sagemaker"
        ],
        "Question_view_count":51.0,
        "Owner_creation_time":1513674173560,
        "Owner_last_access_time":1663749682723,
        "Owner_reputation":101.0,
        "Owner_up_votes":4.0,
        "Owner_down_votes":0.0,
        "Owner_views":12.0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73451801",
        "Tool":"Amazon SageMaker",
        "Forum":"Stack Overflow",
        "Question_topic":null,
        "Question_has_accepted_answer":null,
        "Answer_list":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  error for training job - algorithm error; content:<p>i am receiving the following error when i try and train an xgboost model and have no idea how to fix it. any help please?<\/p>\n<pre><code>unexpectedstatusexception: error for training job -xgboost-2022-08-22-21-37-39-774: failed. reason: algorithmerror: framework error: \ntraceback (most recent call last):\n  file &quot;\/miniconda3\/lib\/python3.6\/site-packages\/_containers\/_trainer.py&quot;, line 84, in train\n    entrypoint()\n  file &quot;\/miniconda3\/lib\/python3.6\/site-packages\/_xgboost_container\/training.py&quot;, line 94, in main\n    train(framework.training_env())\n  file &quot;\/miniconda3\/lib\/python3.6\/site-packages\/_xgboost_container\/training.py&quot;, line 90, in train\n    run_algorithm_mode()\n  file &quot;\/miniconda3\/lib\/python3.6\/site-packages\/_xgboost_container\/training.py&quot;, line 68, in run_algorithm_mode\n    checkpoint_config=checkpoint_config\n  file &quot;\/miniconda3\/lib\/python3.6\/site-packages\/_xgboost_container\/algorithm_mode\/train.py&quot;, line 110, in _train\n    validated_train_config = hyperparameters.validate(train_config)\n  file &quot;\/miniconda3\/lib\/python3.6\/site-packages\/_algorithm_toolkit\/hyperparameter_validation.py&quot;, line 270, in validate\n    raise exc.usererror(&quot;missing required hyperparameter: {}&quot;.format(hp)\n<\/code><\/pre>\n<p>my full notebook is too large to post here, but below i have also added an image of the code right before the training<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/exdth.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/exdth.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is receiving an unexpected status exception error when trying to train an XGBoost model and is looking for help."
    },
    {
        "Question_id":null,
        "Question_title":"Remove multiple runs at the same time",
        "Question_body":"<p>Hello,<\/p>\n<p>I think it would be beneficial to select and delete several experiments at the same time.<br>\nNow I have to delete one by one and it is very time consuming.<\/p>\n<p>Thank you!<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1652776776526,
        "Question_favorite_count":null,
        "Question_score":1.0,
        "Question_tags":null,
        "Question_view_count":99.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/remove-multiple-runs-at-the-same-time\/2435",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":1.0,
        "Answer_list":[
            {
                "id":5746,
                "name":"Arman Harutyunyan",
                "username":"armanharutyunyan",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png",
                "created_at":"2022-05-18T11:54:10.582Z",
                "cooked":"<p>Hey <a class=\"mention\" href=\"\/u\/lucasventura\">@lucasventura<\/a>, you can do it like <a href=\"https:\/\/docs.wandb.ai\/ref\/app\/features\/runs-table#filter-and-delete-unwanted-runs\">this<\/a>.<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2022-05-18T11:54:10.582Z",
                "reply_count":1,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":20.6,
                "yours":false,
                "topic_id":2435,
                "topic_slug":"remove-multiple-runs-at-the-same-time",
                "display_username":"Arman Harutyunyan",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "link_counts":[
                    {
                        "url":"https:\/\/docs.wandb.ai\/ref\/app\/features\/runs-table#filter-and-delete-unwanted-runs",
                        "internal":false,
                        "reflection":false,
                        "clicks":3
                    }
                ],
                "read":true,
                "user_title":"Tier 1 Support Engineer ",
                "title_is_group":false,
                "bookmarked":false,
                "actions_summary":[
                    {
                        "id":2,
                        "count":1
                    }
                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":475,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":true
            },
            {
                "id":5748,
                "name":"Lucas Ventura",
                "username":"lucasventura",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/l\/a4c791\/{size}.png",
                "created_at":"2022-05-18T13:20:23.382Z",
                "cooked":"<p>Thank you <a class=\"mention\" href=\"\/u\/armanharutyunyan\">@armanharutyunyan<\/a> !<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2022-05-18T13:20:23.382Z",
                "reply_count":0,
                "reply_to_post_number":2,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":3,
                "readers_count":2,
                "score":0.6,
                "yours":false,
                "topic_id":2435,
                "topic_slug":"remove-multiple-runs-at-the-same-time",
                "display_username":"Lucas Ventura",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "reply_to_user":{
                    "username":"armanharutyunyan",
                    "name":"Arman Harutyunyan",
                    "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/a\/a6a055\/{size}.png"
                },
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":1449,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":6519,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-07-17T13:20:50.378Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":4,
                "post_type":3,
                "updated_at":"2022-07-17T13:20:50.378Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":1,
                "readers_count":0,
                "score":0.2,
                "yours":false,
                "topic_id":2435,
                "topic_slug":"remove-multiple-runs-at-the-same-time",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: remove multiple runs at the same time; content:<p>hello,<\/p>\n<p>i think it would be beneficial to select and delete several experiments at the same time.<br>\nnow i have to delete one by one and it is very time consuming.<\/p>\n<p>thank you!<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user would like to be able to select and delete multiple experiments at the same time, as the current process of deleting one by one is time consuming."
    },
    {
        "Question_id":null,
        "Question_title":"How does one do hyper parameter sweeps when using HPCs\/clusters?",
        "Question_body":"<p>I saw the great video:<\/p>\n<div class=\"onebox lazyYT lazyYT-container\" data-youtube-id=\"9zrmUIlScdY\" data-youtube-title=\"\ud83e\uddf9 Tune Hyperparameters Easily with W&amp;B Sweeps\" data-parameters=\"feature=oembed&amp;wmode=opaque\">\n  <a href=\"https:\/\/www.youtube.com\/watch?v=9zrmUIlScdY\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img class=\"ytp-thumbnail-image\" src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/78f57e7161a9ebbb48349d07f5a7e73ee9046047.jpeg\" title=\"\ud83e\uddf9 Tune Hyperparameters Easily with W&amp;B Sweeps\" width=\"480\" height=\"360\">\n  <\/a>\n<\/div>\n\n<p>but I still wasn\u2019t 100% how to use it in a HPC cluster. I understand there is a central sweep master at wandb\u2019s servers sending commands, but how does it connect to the HPC\/clsuter?<\/p>\n<p>There are some cases I am worried baout<\/p>\n<ol>\n<li>the HPC needs my password<\/li>\n<li>the HPC needs an ssh key<\/li>\n<li>a VPN to connect to the hpc<\/li>\n<li>the HPC needs duo authentication<\/li>\n<li>the HPC uses a workload manager e.g. slurm or condor<\/li>\n<\/ol>\n<p>it would be very nice to have a concrete example with some of these. Perhaps slurm + password is the most common (although I admit I\u2019ve been using condor with a VPN wall + password is my real use case right now).<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":null,
        "Question_creation_time":1637078110724,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":null,
        "Question_view_count":242.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/community.wandb.ai\/t\/how-does-one-do-hyper-parameter-sweeps-when-using-hpcs-clusters\/1317",
        "Tool":"Weights & Biases",
        "Forum":"Tool-specific",
        "Question_topic":null,
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "id":3293,
                "name":"Joris wuts",
                "username":"jwuts",
                "avatar_template":"https:\/\/avatars.discourse-cdn.com\/v4\/letter\/j\/ecccb3\/{size}.png",
                "created_at":"2021-11-17T12:45:55.282Z",
                "cooked":"<p>Hey,<\/p>\n<p>I run W&amp;B sweeps on HPC clusters with slurm as well.<br>\nJust prepare all your code and data on the cluster and create the sweep as explained above.<\/p>\n<p>Then from the sweep page in your project, copy the wandb agent command.<br>\nLogin to your hpc, and put the wandb agent command in the queue.<br>\nIt is especially usefull o nHPC clusters as you have multiple nodes available. the wandb API automatically puts the right set of new hyperparameters on seperate nodes!<\/p>",
                "post_number":2,
                "post_type":1,
                "updated_at":"2021-11-17T12:45:55.282Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":8,
                "readers_count":7,
                "score":1.6,
                "yours":false,
                "topic_id":1317,
                "topic_slug":"how-does-one-do-hyper-parameter-sweeps-when-using-hpcs-clusters",
                "display_username":"Joris wuts",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":750,
                "hidden":false,
                "trust_level":0,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":3315,
                "name":"Leslie",
                "username":"lesliewandb",
                "avatar_template":"\/user_avatar\/community.wandb.ai\/lesliewandb\/{size}\/369_2.png",
                "created_at":"2021-11-18T14:59:49.656Z",
                "cooked":"<p>Thank you for the help Joris, let us know if you still need further assistance Brando.<\/p>",
                "post_number":3,
                "post_type":1,
                "updated_at":"2021-11-18T14:59:49.656Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":5,
                "readers_count":4,
                "score":1.0,
                "yours":false,
                "topic_id":1317,
                "topic_slug":"how-does-one-do-hyper-parameter-sweeps-when-using-hpcs-clusters",
                "display_username":"Leslie",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":"",
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":false,
                "admin":false,
                "staff":false,
                "user_id":453,
                "hidden":false,
                "trust_level":1,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            },
            {
                "id":4193,
                "name":"system",
                "username":"system",
                "avatar_template":"https:\/\/global.discourse-cdn.com\/business7\/uploads\/wandb\/original\/1X\/366b649231631dbab896843020da0056074ac79d.png",
                "created_at":"2022-01-16T12:46:36.956Z",
                "cooked":"<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.<\/p>",
                "post_number":4,
                "post_type":3,
                "updated_at":"2022-01-16T12:46:36.956Z",
                "reply_count":0,
                "reply_to_post_number":null,
                "quote_count":0,
                "incoming_link_count":0,
                "reads":4,
                "readers_count":3,
                "score":0.8,
                "yours":false,
                "topic_id":1317,
                "topic_slug":"how-does-one-do-hyper-parameter-sweeps-when-using-hpcs-clusters",
                "display_username":"system",
                "primary_group_name":null,
                "flair_name":null,
                "flair_url":null,
                "flair_bg_color":null,
                "flair_color":null,
                "version":1,
                "can_edit":false,
                "can_delete":false,
                "can_recover":false,
                "can_wiki":false,
                "read":true,
                "user_title":null,
                "bookmarked":false,
                "actions_summary":[

                ],
                "moderator":true,
                "admin":true,
                "staff":true,
                "user_id":-1,
                "hidden":false,
                "trust_level":4,
                "deleted_at":null,
                "user_deleted":false,
                "edit_reason":null,
                "can_view_edit_history":false,
                "wiki":false,
                "action_code":"autoclosed.enabled",
                "can_accept_answer":false,
                "can_unaccept_answer":false,
                "accepted_answer":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title: how does one do hyper parameter sweeps when using hpcs\/clusters?; content:<p>i saw the great video:<\/p>\n<div class=\"onebox lazyyt lazyyt-container\" data-youtube-id=\"9zrmuilscdy\" data-youtube-title=\"\ud83e\uddf9 tune hyperparameters easily with w&amp;b sweeps\" data-parameters=\"feature=oembed&amp;wmode=opaque\">\n  <a href=\"https:\/\/www.youtube.com\/watch?v=9zrmuilscdy\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img class=\"ytp-thumbnail-image\" src=\"https:\/\/global.discourse-cdn.com\/business7\/uploads\/\/original\/1x\/78f57e7161a9ebbb48349d07f5a7e73ee9046047.jpeg\" title=\"\ud83e\uddf9 tune hyperparameters easily with w&amp;b sweeps\" width=\"480\" height=\"360\">\n  <\/a>\n<\/div>\n\n<p>but i still wasn\u2019t 100% how to use it in a hpc cluster. i understand there is a central sweep master at \u2019s servers sending commands, but how does it connect to the hpc\/clsuter?<\/p>\n<p>there are some cases i am worried baout<\/p>\n<ol>\n<li>the hpc needs my password<\/li>\n<li>the hpc needs an ssh key<\/li>\n<li>a vpn to connect to the hpc<\/li>\n<li>the hpc needs duo authentication<\/li>\n<li>the hpc uses a workload manager e.g. slurm or condor<\/li>\n<\/ol>\n<p>it would be very nice to have a concrete example with some of these. perhaps slurm + password is the most common (although i admit i\u2019ve been using condor with a vpn wall + password is my real use case right now).<\/p>",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is looking for a concrete example of how to use hyperparameter sweeps with an HPC\/cluster, taking into account various authentication methods such as passwords, SSH keys, VPNs, and Duo authentication, as well as workload managers such as Slurm and Condor."
    },
    {
        "Question_id":null,
        "Question_title":"SageMaker ValidationException",
        "Question_body":"Hi All\nI am brand new to AWS and find it all very overwhelming and confusing.\nI am trying to use SageMaker and Forecast - however I am having issues with trying to get into SageMaker Studio. I am getting the following error:\nValidationException\n1 validation error detected\nValue '[]' at 'subnetIds' failed to satisfy constraint: Member must have length greater than or equal to 1\n\nI have asked out internal team and they are not sure, and opened a support ticket. The support person said that I should be using the Standard setup rather than the Quick setup. However, this is still giving the same issue. To which he said that this is an advanced problem and he can't assist with it.\nIs anyone able to help me? give me an idea of what is wrong?",
        "Question_answer_count":2,
        "Question_comment_count":null,
        "Question_creation_time":1612307749000,
        "Question_favorite_count":null,
        "Question_score":0.0,
        "Question_tags":[
            "Amazon SageMaker"
        ],
        "Question_view_count":460.0,
        "Owner_creation_time":null,
        "Owner_last_access_time":null,
        "Owner_reputation":null,
        "Owner_up_votes":null,
        "Owner_down_votes":null,
        "Owner_views":null,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_time":null,
        "Answer_score":null,
        "Owner_location":null,
        "Question_last_edit_time":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/repost.aws\/questions\/QU-bXA28SLQryx60CbXdb9wg\/sage-maker-validation-exception",
        "Tool":"Amazon SageMaker",
        "Forum":"Tool-specific",
        "Question_topic":[
            "Machine Learning & AI"
        ],
        "Question_has_accepted_answer":0.0,
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-21T07:59:07.109Z",
                "Answer_score":0,
                "Answer_body":"Hello\n\nyou can go for standard and then fill the VPC and subnet in the Network and Storage block",
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-25T04:08:30.000Z",
                "Answer_score":0,
                "Answer_body":"I can get the same error (Value '[]' at 'subnetIds' failed to satisfy constraint: Member must have length greater than or equal to 1) if:\n\nI start with an AWS account which has been customized (for example, no default VPC)\nChoose \"Quick Setup\" when setting up SageMaker studio\n\nAs @ArturoT mentioned, choosing \"Standard\" when setting up SageMaker Studio and selecting VPC and subnets does work for me.",
                "Answer_has_accepted":false
            }
        ],
        "Question_follower_count":null,
        "Question_converted_from_issue":null,
        "Question_original_content_preprocessed_text":"title:  validationexception; content:hi all\ni am brand new to aws and find it all very overwhelming and confusing.\ni am trying to use  and forecast - however i am having issues with trying to get into  studio. i am getting the following error:\nvalidationexception\n1 validation error detected\nvalue '[]' at 'subnetids' failed to satisfy constraint: member must have length greater than or equal to 1\n\ni have asked out internal team and they are not sure, and opened a support ticket. the support person said that i should be using the standard setup rather than the quick setup. however, this is still giving the same issue. to which he said that this is an advanced problem and he can't assist with it.\nis anyone able to help me? give me an idea of what is wrong?",
        "Question_preprocessed_content":"",
        "Question_preprocessed_content_gpt_summary":"",
        "Question_original_content_gpt_summary":"The user is having difficulty accessing AWS Studio and is receiving a ValidationException error. They have asked their internal team and opened a support ticket, but the support person said it is an advanced problem and they cannot assist."
    }
]