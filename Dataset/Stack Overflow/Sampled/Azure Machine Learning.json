[
    {
        "Question_id":60539094,
        "Question_title":"Is it possible to share compute instance with other user?",
        "Question_body":"<p>I create one compute instance 'yhd-notebook' in Azure Machine Learning compute with user1. When I login with user2, and try to open the JupyterLab of this compute instance, it shows an error message like below.<\/p>\n\n<blockquote>\n  <p>User user2 does not have access to compute instance yhd-notebook.<\/p>\n  \n  <p>Only the creator can access a compute instance.<\/p>\n  \n  <p>Click here to sign out and sign in again with a different account.<\/p>\n<\/blockquote>\n\n<p>Is it possible to share compute instance with another user? BTW, both user1 and user2 have Owner role with the Azure subscription.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-05 06:06:52.943 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":8,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":3705,
        "Owner_creation_date":"2020-02-22 08:47:11.693 UTC",
        "Owner_last_access_date":"2022-06-18 01:34:40.367 UTC",
        "Owner_reputation":393,
        "Owner_up_votes":37,
        "Owner_down_votes":1,
        "Owner_views":58,
        "Answer_body":"<p>According to MS, all users in the workspace contributor and owner role can create, delete, start, stop, and restart compute instances across the workspace. However, only the creator of a specific compute instance is allowed to access Jupyter, JupyterLab, and RStudio on that compute instance. The creator of the compute instance has the compute instance dedicated to them, have root access, and can terminal in through Jupyter. Compute instance will have single-user login of creator user and all actions will use that user\u2019s identity for RBAC and attribution of experiment runs. SSH access is controlled through public\/private key mechanism.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-03-05 07:30:58.82 UTC",
        "Answer_score":7.0,
        "Owner_location":"Guangzhou, China",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60539094",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61736810,
        "Question_title":"Where does the Azure ML profiler run?",
        "Question_body":"<p>Where does the model profiler run in Azure ML?<\/p>\n\n<p>The <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where#profilemodel\" rel=\"nofollow noreferrer\">doc<\/a> here explains how to register a dataset, specify the inference configuration (scoring script and environment) and run the profiler.<\/p>\n\n<p>I am trying to profile a tensorflow model and I get this error, which essentially tells nothing about what went wrong:<\/p>\n\n<pre><code>{\n    \"name\": \"tf-profiler-experiment3\",\n    \"createdTime\": \"2020-05-11T18:19:46.827933+00:00\",\n    \"state\": \"Failed\",\n    \"requestedCpu\": 3.5,\n    \"requestedMemoryInGB\": 15.0,\n    \"requestedQueriesPerSecond\": 0,\n    \"error\": {\n        \"code\": \"ModelProfilingJobFailed\",\n        \"statusCode\": 500,\n        \"message\": \"An internal server error occurred. Please try again. If the problem persists, contact support\",\n        \"details\": []\n    }\n}\n<\/code><\/pre>\n\n<p>So where exactly are 3.5 CPUs and 15 GB requested? And where to find the details of the error?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-11 18:34:49.21 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":65,
        "Owner_creation_date":"2012-04-14 18:32:45.947 UTC",
        "Owner_last_access_date":"2022-09-23 18:52:37.23 UTC",
        "Owner_reputation":10217,
        "Owner_up_votes":2753,
        "Owner_down_votes":6,
        "Owner_views":1282,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61736810",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61128120,
        "Question_title":"Cant connect to workspace",
        "Question_body":"<p>Im trying to complete the very first training module offered by MS. Something Im missing that isn't detailed on the documentation of the training.<\/p>\n\n<p>These are the instructions I'm following\n<a href=\"https:\/\/github.com\/MicrosoftDocs\/mslearn-aml-labs\/blob\/master\/labdocs\/Lab01.md\" rel=\"nofollow noreferrer\">https:\/\/github.com\/MicrosoftDocs\/mslearn-aml-labs\/blob\/master\/labdocs\/Lab01.md<\/a><\/p>\n\n<p>All good until I have to run the second command defined on the notebook called \n\"01-Getting_Started_with_Azure_ML.ipynb\". \nAnd yes I entered the device login code as the instructions indicate.<\/p>\n\n<p>Look at the attached screenshot of the error returned after running the command of the notebook.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/uKSLT.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uKSLT.jpg\" alt=\"Scheenshot\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-09 18:45:09.503 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":26,
        "Owner_creation_date":"2018-06-21 12:32:13.47 UTC",
        "Owner_last_access_date":"2021-03-05 20:01:04.397 UTC",
        "Owner_reputation":26,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61128120",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70833499,
        "Question_title":"AzureML Environment for Inference : can't add pip packages to dependencies",
        "Question_body":"<p>I can't find the proper way to add dependencies to my Azure Container Instance for ML Inference.<\/p>\n<p>I basically started by following this tutorial : <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-train-deploy-notebook\" rel=\"nofollow noreferrer\">Train and deploy an image classification model with an example Jupyter Notebook<\/a><\/p>\n<p>It works fine.<\/p>\n<p>Now I want to deploy my trained TensorFlow model for inference. I tried many ways, but I was never able to add python dependencies to the Environment.<\/p>\n<h1>From the TensorFlow curated environment<\/h1>\n<p>Using <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/resource-curated-environments#inference-curated-environments-and-prebuilt-docker-images\" rel=\"nofollow noreferrer\">AzureML-tensorflow-2.4-ubuntu18.04-py37-cpu-inference<\/a> :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace\n\n\n# connect to your workspace\nws = Workspace.from_config()\n\n# names\nexperiment_name = &quot;my-experiment&quot;\nmodel_name = &quot;my-model&quot;\nenv_version=&quot;1&quot;\nenv_name=&quot;my-env-&quot;+env_version\nservice_name = str.lower(model_name + &quot;-service-&quot; + env_version)\n\n\n# create environment for the deploy\nfrom azureml.core.environment import Environment, DEFAULT_CPU_IMAGE\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.webservice import AciWebservice\n\n# get a curated environment\nenv = Environment.get(\n    workspace=ws, \n    name=&quot;AzureML-tensorflow-2.4-ubuntu18.04-py37-cpu-inference&quot;,\n# )\ncustom_env = env.clone(env_name)\ncustom_env.inferencing_stack_version='latest'\n\n# add packages\nconda_dep = CondaDependencies()\npython_packages = ['joblib', 'numpy', 'os', 'json', 'tensorflow']\nfor package in python_packages:\n    conda_dep.add_pip_package(package)\n    conda_dep.add_conda_package(package)\n\n# Adds dependencies to PythonSection of env\ncustom_env.python.user_managed_dependencies=True\ncustom_env.python.conda_dependencies=conda_dep\n\ncustom_env.register(workspace=ws)\n\n# create deployment config i.e. compute resources\naciconfig = AciWebservice.deploy_configuration(\n    cpu_cores=1,\n    memory_gb=1,\n    tags={&quot;experiment&quot;: experiment_name, &quot;model&quot;: model_name},\n)\n\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.model import Model\n\n# get the registered model\nmodel = Model(ws, model_name)\n\n# create an inference config i.e. the scoring script and environment\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=custom_env)\n\n# deploy the service\nservice = Model.deploy(\n    workspace=ws,\n    name=service_name,\n    models=[model],\n    inference_config=inference_config,\n    deployment_config=aciconfig,\n)\n\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>I get the following log :<\/p>\n<pre><code>\nAzureML image information: tensorflow-2.4-ubuntu18.04-py37-cpu-inference:20220110.v1\n\n\nPATH environment variable: \/opt\/miniconda\/envs\/amlenv\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPYTHONPATH environment variable: \n\nPip Dependencies\n---------------\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2022-01-24T10:21:09,855130300+00:00 - iot-server\/finish 1 0\n2022-01-24T10:21:09,856870100+00:00 - Exit code 1 is normal. Not restarting iot-server.\nabsl-py==0.15.0\napplicationinsights==0.11.10\nastunparse==1.6.3\nazureml-inference-server-http==0.4.2\ncachetools==4.2.4\ncertifi==2021.10.8\ncharset-normalizer==2.0.10\nclick==8.0.3\nFlask==1.0.3\nflatbuffers==1.12\ngast==0.3.3\ngoogle-auth==2.3.3\ngoogle-auth-oauthlib==0.4.6\ngoogle-pasta==0.2.0\ngrpcio==1.32.0\ngunicorn==20.1.0\nh5py==2.10.0\nidna==3.3\nimportlib-metadata==4.10.0\ninference-schema==1.3.0\nitsdangerous==2.0.1\nJinja2==3.0.3\nKeras-Preprocessing==1.1.2\nMarkdown==3.3.6\nMarkupSafe==2.0.1\nnumpy==1.19.5\noauthlib==3.1.1\nopt-einsum==3.3.0\npandas==1.1.5\nprotobuf==3.19.1\npyasn1==0.4.8\npyasn1-modules==0.2.8\npython-dateutil==2.8.2\npytz==2021.3\nrequests==2.27.1\nrequests-oauthlib==1.3.0\nrsa==4.8\nsix==1.15.0\ntensorboard==2.7.0\ntensorboard-data-server==0.6.1\ntensorboard-plugin-wit==1.8.1\ntensorflow==2.4.0\ntensorflow-estimator==2.4.0\ntermcolor==1.1.0\ntyping-extensions==3.7.4.3\nurllib3==1.26.8\nWerkzeug==2.0.2\nwrapt==1.12.1\nzipp==3.7.0\n\n\nEntry script directory: \/var\/azureml-app\/.\n\nDynamic Python package installation is disabled.\nStarting AzureML Inference Server HTTP.\n\nAzure ML Inferencing HTTP server v0.4.2\n\n\nServer Settings\n---------------\nEntry Script Name: score.py\nModel Directory: \/var\/azureml-app\/azureml-models\/my-model\/1\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311\/\nScore:          POST  127.0.0.1:31311\/score\n\nStarting gunicorn 20.1.0\nListening at: http:\/\/0.0.0.0:31311 (69)\nUsing worker: sync\nBooting worker with pid: 100\nException in worker process\nTraceback (most recent call last):\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 589, in spawn_worker\n    worker.init_process()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 134, in init_process\n    self.load_wsgi()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 146, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 58, in load\n    return self.load_wsgiapp()\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 48, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 359, in import_app\n    mod = importlib.import_module(module)\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/importlib\/__init__.py&quot;, line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/entry.py&quot;, line 1, in &lt;module&gt;\n    import create_app\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/create_app.py&quot;, line 4, in &lt;module&gt;\n    from routes_common import main\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/routes_common.py&quot;, line 32, in &lt;module&gt;\n    from aml_blueprint import AMLBlueprint\n  File &quot;\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py&quot;, line 28, in &lt;module&gt;\n    main_module_spec.loader.exec_module(main)\n  File &quot;\/var\/azureml-app\/score.py&quot;, line 4, in &lt;module&gt;\n    import joblib\nModuleNotFoundError: No module named 'joblib'\nWorker exiting (pid: 100)\nShutting down: Master\nReason: Worker failed to boot.\n2022-01-24T10:21:13,851467800+00:00 - gunicorn\/finish 3 0\n2022-01-24T10:21:13,853259700+00:00 - Exit code 3 is not normal. Killing image.\n<\/code><\/pre>\n<h1>From a Conda specification<\/h1>\n<p>Same as before, but with a fresh environment from Conda specification and changing the <code>env_version<\/code> number :<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># ...\n\n\nenv_version=&quot;2&quot;\n\n# ...\n\ncustom_env = Environment.from_conda_specification(name=env_name, file_path=&quot;my-env.yml&quot;)\ncustom_env.docker.base_image = DEFAULT_CPU_IMAGE\n\n# ...\n\n<\/code><\/pre>\n<p>with <code>my-env.yml<\/code> :<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>name: my-env\ndependencies:\n- python\n\n- pip:\n  - azureml-defaults\n  - azureml-sdk\n  - sklearn\n  - numpy\n  - matplotlib\n  - joblib\n  - uuid\n  - requests\n  - tensorflow\n\n<\/code><\/pre>\n<p>I get this log :<\/p>\n<pre><code>2022-01-24T11:06:54,887886931+00:00 - iot-server\/run \n2022-01-24T11:06:54,891839877+00:00 - rsyslog\/run \n2022-01-24T11:06:54,893640998+00:00 - gunicorn\/run \n2022-01-24T11:06:54,912032812+00:00 - nginx\/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2022-01-24T11:06:55,398420960+00:00 - iot-server\/finish 1 0\n2022-01-24T11:06:55,414425146+00:00 - Exit code 1 is normal. Not restarting iot-server.\n\nPATH environment variable: \/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPYTHONPATH environment variable: \n\nPip Dependencies\n---------------\nbrotlipy==0.7.0\ncertifi==2020.6.20\ncffi @ file:\/\/\/tmp\/build\/80754af9\/cffi_1605538037615\/work\nchardet @ file:\/\/\/tmp\/build\/80754af9\/chardet_1605303159953\/work\nconda==4.9.2\nconda-package-handling @ file:\/\/\/tmp\/build\/80754af9\/conda-package-handling_1603018138503\/work\ncryptography @ file:\/\/\/tmp\/build\/80754af9\/cryptography_1605544449973\/work\nidna @ file:\/\/\/tmp\/build\/80754af9\/idna_1593446292537\/work\npycosat==0.6.3\npycparser @ file:\/\/\/tmp\/build\/80754af9\/pycparser_1594388511720\/work\npyOpenSSL @ file:\/\/\/tmp\/build\/80754af9\/pyopenssl_1605545627475\/work\nPySocks @ file:\/\/\/tmp\/build\/80754af9\/pysocks_1594394576006\/work\nrequests @ file:\/\/\/tmp\/build\/80754af9\/requests_1592841827918\/work\nruamel-yaml==0.15.87\nsix @ file:\/\/\/tmp\/build\/80754af9\/six_1605205313296\/work\ntqdm @ file:\/\/\/tmp\/build\/80754af9\/tqdm_1605303662894\/work\nurllib3 @ file:\/\/\/tmp\/build\/80754af9\/urllib3_1603305693037\/work\n\nStarting HTTP server\n2022-01-24T11:06:59,701365128+00:00 - gunicorn\/finish 127 0\n.\/run: line 127: exec: gunicorn: not found\n2022-01-24T11:06:59,706177784+00:00 - Exit code 127 is not normal. Killing image.\n    \n<\/code><\/pre>\n<p>I really don't know what I'm missing, and I've been searching for too long already (Azure docs, SO, ...).<\/p>\n<p>Thanks for your help !<\/p>\n<p>Edit : Non-exhaustive list of solutions I tried :<\/p>\n<ul>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/65159778\/how-to-create-azureml-environement-and-add-required-packages\">How to create AzureML environement and add required packages<\/a><\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/65159308\/how-to-use-existing-conda-environment-as-a-azureml-environment\">how to use existing conda environment as a AzureML environment<\/a><\/li>\n<li>...<\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-environments#environment-building-caching-and-reuse\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-environments#environment-building-caching-and-reuse<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments#add-packages-to-an-environment\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments#add-packages-to-an-environment<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-inferencing-gpus\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-inferencing-gpus<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-a-deployment-configuration\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-a-deployment-configuration<\/a><\/li>\n<li>...<\/li>\n<\/ul>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-24 11:57:28.957 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2022-01-26 02:17:34.173 UTC",
        "Question_score":0,
        "Question_tags":"python|tensorflow|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":902,
        "Owner_creation_date":"2012-05-24 14:00:50.813 UTC",
        "Owner_last_access_date":"2022-09-23 12:35:53.207 UTC",
        "Owner_reputation":483,
        "Owner_up_votes":39,
        "Owner_down_votes":2,
        "Owner_views":105,
        "Answer_body":"<p>OK, I got it working : I started over from scratch and it worked.<\/p>\n<p>I have no idea what was wrong in all my preceding tries, and that is terrible.<\/p>\n<p>Multiple problems and how I (think I) solved them :<\/p>\n<ul>\n<li><code>joblib<\/code> : I actually didn't need it to load my Keras model. But the problem was not with this specific library, rather that I couldn't add dependencies to the inference environment.<\/li>\n<li><code>Environment<\/code> : finally, I was only able to make things work with a custom env : <code>Environment.from_conda_specification(name=version, file_path=&quot;conda_dependencies.yml&quot;)<\/code> . I haven't been able to add my libraries (or specify a specific package version) to a &quot;currated environment&quot;. I don't know why though...<\/li>\n<li><code>TensorFlow<\/code> : last problem I had was that I trained and registered my model in AzureML Notebook's <code>azureml_py38_PT_TF<\/code> kernel (<code>tensorflow==2.7.0<\/code>), and tried to load it in the inference Docker image (<code>tensorflow==2.4.0<\/code>). So I had to specify the version of TensorFlow I wanted to use in the inference image (which required the previous point to be solved).<\/li>\n<\/ul>\n<p>What finally worked :<\/p>\n<ul>\n<li>notebook.ipynb<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>import uuid\nfrom azureml.core import Workspace, Environment, Model\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.model import InferenceConfig\n\n\nversion = &quot;test-&quot;+str(uuid.uuid4())[:8]\n\nenv = Environment.from_conda_specification(name=version, file_path=&quot;conda_dependencies.yml&quot;)\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=env)\n\nws = Workspace.from_config()\nmodel = Model(ws, model_name)\n\naci_config = AciWebservice.deploy_configuration(\n    cpu_cores=1,\n    memory_gb=1,\n)\n\nservice = Model.deploy(\n    workspace=ws,\n    name=version,\n    models=[model],\n    inference_config=inference_config,\n    deployment_config=aci_config,\n    overwrite=True,\n)\n\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<ul>\n<li>conda_dependencies.yml<\/li>\n<\/ul>\n<pre class=\"lang-yaml prettyprint-override\"><code>channels:\n- conda-forge\ndependencies:\n- python=3.8\n- pip:\n  - azureml-defaults\n  - azureml-sdk\n  - numpy\n  - tensorflow==2.7.0\n\n<\/code><\/pre>\n<ul>\n<li>score.py<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nimport numpy as np\nimport tensorflow as tf\n\n\ndef init():\n    global model\n\n    model_path = os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;model\/data\/model&quot;)\n    model = tf.keras.models.load_model(model_path)\n\n\n\ndef run(raw_data):\n    data = np.array(json.loads(raw_data)[&quot;data&quot;])\n    y_hat = model.predict(data)\n\n    return y_hat.tolist()\n\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-26 09:14:08.82 UTC",
        "Answer_score":1.0,
        "Owner_location":"Paris, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70833499",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69887045,
        "Question_title":"Issues using SendGrid with Azure ML",
        "Question_body":"<p>I'm trying to send an email using SendGrid within Azure Machine Learning. This is initially just a basic test email to ensure it is working correctly.<\/p>\n<p>The steps I have taken:<\/p>\n<ol>\n<li>Pip installed SendGrid;<\/li>\n<li>Zipped the SendGrid download and uploaded as a dataset to AML platform;<\/li>\n<li>Attempted to run the example SendGrid Python code (which can be seen below):<\/li>\n<\/ol>\n<p>I have copied steps in similar posts concerning uploading modules to AML <a href=\"https:\/\/stackoverflow.com\/questions\/46222606\/updating-pandas-to-version-0-19-in-azure-ml-studio\/46232963#46232963\">here<\/a> and <a href=\"https:\/\/stackoverflow.com\/questions\/46523924\/adding-python-modules-to-azureml-workspace\">here<\/a> as well as ensuring the correct settings for the SendGrid API key were established on setup <a href=\"https:\/\/stackoverflow.com\/questions\/51078310\/sending-simple-email-on-azure-with-sendgrid\">here<\/a>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def azureml_main():\n\n    import sendgrid\n    from sendgrid import SendGridAPIClient\n    from sendgrid.helpers.mail import Mail\n\n\n    message = Mail(\n        from_email='xxx@xyz.com',\n        to_emails='xxx@xyz.com',\n        subject='Sending with Twilio SendGrid is Fun',\n        html_content='&lt;strong&gt;and easy to do anywhere, even with Python&lt;\/strong&gt;')\n    try:\n        sg = SendGridAPIClient(os.environ.get('SG API Code'))\n        response = sg.send(message)\n        print(response.status_code)\n        print(response.body)\n        print(response.headers)\n    except Exception as e:\n        print(e)\n<\/code><\/pre>\n<p>No error message is returned in the terminal. To me this indicates there weren't any issues with the code, yet no emails have been received\/sent.<\/p>\n<pre><code>python ScheduleRun.py \nazureuser@will1:~\/cloudfiles\/code\/Users\/will\/Schedule$ \nazureuser@will1:~\/cloudfiles\/code\/Users\/will\/Schedule$ python ScheduleRun.py \nazureuser@will1:~\/cloudfiles\/code\/Users\/will\/Schedule$  \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-08 16:48:51.843 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-08 23:23:28.7 UTC",
        "Question_score":0,
        "Question_tags":"python|sendgrid|azure-machine-learning-service",
        "Question_view_count":37,
        "Owner_creation_date":"2021-06-24 10:29:22.66 UTC",
        "Owner_last_access_date":"2021-12-15 15:44:15.45 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69887045",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68558469,
        "Question_title":"Azure ML MSI deployment over ARM Templates enables purge protection on Key Vault",
        "Question_body":"<p>I have discovered lately that when you deploy an <code>Azure ML<\/code> instance from the <code>ARM Template<\/code>, the <code>MSI<\/code> will override the purge protection settings of the <code>Key Vault<\/code>. It will enable purge protection on the <code>Key Vault<\/code>. This is not the behavior that I am looking for, because when trying to deploy it again, the template will fail saying that the <code>Key Vault<\/code> with the name already exists and you can't deleted before the retention period.<\/p>\n<p>If you deploy the <code>Azure ML<\/code> instance manually and select the Key Vault, it will keep the disable purge settings. Any ideas how can we keep purge disabled hier?<\/p>\n<p>The Azure ML properties that we used are mentioned bellow:<\/p>\n<pre><code>  {\n    &quot;type&quot;: &quot;Microsoft.MachineLearningServices\/workspaces&quot;,\n    &quot;apiVersion&quot;: &quot;2020-09-01-preview&quot;,\n    &quot;name&quot;: &quot;[variables('machineLearningWorkspaceName')]&quot;,\n    &quot;location&quot;: &quot;[parameters('location')]&quot;,\n    &quot;identity&quot;: {\n      &quot;type&quot;: &quot;[parameters('amlManagedIdentityOption')]&quot;\n    },\n    &quot;dependsOn&quot;: [\n      &quot;[resourceId('Microsoft.Storage\/storageAccounts', variables('storageAccountName'))]&quot;,\n      &quot;[resourceId('Microsoft.Insights\/components', variables('applicationInsightsName'))]&quot;,\n      &quot;[resourceId('Microsoft.ContainerRegistry\/registries', variables('containerRegistryName'))]&quot;\n    ],\n    &quot;tags&quot;: &quot;[parameters('resourceTags')]&quot;,\n    &quot;properties&quot;: {\n      &quot;friendlyName&quot;: &quot;[variables('machineLearningWorkspaceName')]&quot;,\n      &quot;storageAccount&quot;: &quot;[variables('storageAccount')]&quot;,\n      &quot;keyVault&quot;: &quot;[variables('keyVault')]&quot;,\n      &quot;applicationInsights&quot;: &quot;[variables('applicationInsights')]&quot;,\n      &quot;containerRegistry&quot;: &quot;[ variables('containerRegistry')]&quot;,\n      &quot;adbWorkspace&quot;: &quot;[variables('adbWorkSpace')]&quot;,\n      &quot;hbiWorkspace&quot;: &quot;[parameters('confidential_data')]&quot;,\n      &quot;allowPublicAccessWhenBehindVnet&quot;: &quot;[parameters('allowPublicAccessWhenBehindVnet')]&quot;\n    }\n  }\n<\/code><\/pre>\n<p>On the Key Vault ARM we have the following properties:<\/p>\n<pre><code>         &quot;properties&quot;: {\n                 &quot;enabledForDeployment&quot;: &quot;[parameters('enabledForDeployment')]&quot;,\n                 &quot;enabledForTemplateDeployment&quot;: &quot;[parameters('enabledForTemplateDeployment')]&quot;,\n                 &quot;enabledForVolumeEncryption&quot;: &quot;[parameters('enableVaultForVolumeEncryption')]&quot;,\n                 &quot;softDeleteRetentionInDays&quot;: 7,\n                 &quot;tenantId&quot;: &quot;[subscription().tenantId]&quot;,\n                 &quot;copy&quot;: [\n                     {\n                         &quot;name&quot;: &quot;accessPolicies&quot;,\n                         &quot;count&quot;: &quot;[length(parameters('userObjectId'))]&quot;,\n                         &quot;input&quot;: {\n                             &quot;tenantId&quot;: &quot;[subscription().tenantId]&quot;,\n                             &quot;objectId&quot;: &quot;[parameters('userObjectId')[copyIndex('accessPolicies')].Id]&quot;,\n                             &quot;permissions&quot;: &quot;[parameters('userObjectId')[copyIndex('accessPolicies')].Permissions]&quot;\n                         }\n }\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Qywye.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Qywye.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2021-07-28 10:13:53.883 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-07-28 14:37:37.64 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-devops|azure-resource-manager|azure-machine-learning-studio|infrastructure-as-code",
        "Question_view_count":444,
        "Owner_creation_date":"2014-07-27 10:46:49.257 UTC",
        "Owner_last_access_date":"2022-09-23 08:53:07.093 UTC",
        "Owner_reputation":599,
        "Owner_up_votes":204,
        "Owner_down_votes":5,
        "Owner_views":224,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Stuttgart, Deutschland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68558469",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37549591,
        "Question_title":"How to import a library \u201crmarkdown\u201d using the AzureML package?",
        "Question_body":"<p>I'm trying to import <code>rmarkdown<\/code> into <code>AzureML<\/code> for one of my projects.<\/p>\n\n<p>This is the function I'm trying to upload into <code>AzureML<\/code>. <\/p>\n\n<p>The <code>R.version<\/code> check is because the function is evaluated in the local environment before uploaded to <code>AzureML<\/code>. <\/p>\n\n<pre><code>fun &lt;- function (b5) {\n    if (R.version[[\"os\"]]==\"mingw32\" &amp;&amp; ! require(talection)) {\n        install.packages(\n            \"src\/rmarkdown_0.9.6.zip\",\n            lib=\".\",\n            type=\"win.binary\",\n            repos=NULL,\n            verbose=TRUE)\n    }\n    ans &lt;- as.data.frame(c(\"Finished\"))\n}\n<\/code><\/pre>\n\n<p><code>rmarkdown_0.9.6.zip<\/code> is in a <code>miniCRAN<\/code> library. <\/p>\n\n<p>The following code, is the code that uploads <code>rmarkwodn<\/code> to <code>Azure ML<\/code>. Please note the line <code>packages<\/code>, which tells R to upload <code>rmarkdown<\/code> to <code>Azure ML<\/code>. <\/p>\n\n<pre><code>test &lt;- as.data.frame(\n    cbind(\n        c(0.0,  0.3,  0.0,  0.0,  0.0),\n        c(0.0,  0.0,  0.0, -0.4,  0.0),\n        c(0,      0,    0,    0,    0))\n)\n\nep &lt;- publishWebService (\n  ws,\n  fun = fun,\n  name = \"Talection-fun\",\n  inputSchema = test,\n  outputSchema = list(\n    ans = \"character\"\n  ),\n  packages = c(\"rmarkdown\")\n)\n\nprint(consume(ep,test))\n<\/code><\/pre>\n\n<p>The code returns <\/p>\n\n<blockquote>\n  <p>Request failed with status 400. Waiting 12.7 seconds before retry<br>\n  Request failed with status 400. Waiting 33.6 seconds before retry<br>\n  Request failed with status 400. Waiting 76.7 seconds before retry<br>\n  Request failed with status 400. Waiting 234.3 seconds before retry<br>\n  Request failed with status 400. Waiting 123.1 seconds before retry<br>\n  Error: AzureML returns error code:<br>\n  HTTP status code : 400<br>\n  AzureML error code  : LibraryExecutionError  <\/p>\n<\/blockquote>\n\n<p>Any and all relevant suggestions welcome. Thank you.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2016-05-31 15:17:27.62 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-11-03 12:19:31.603 UTC",
        "Question_score":3,
        "Question_tags":"r|r-markdown|azure-machine-learning-studio",
        "Question_view_count":147,
        "Owner_creation_date":"2012-11-11 09:14:39.067 UTC",
        "Owner_last_access_date":"2022-06-13 17:53:53.847 UTC",
        "Owner_reputation":445,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":63,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Levanger, Norway",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37549591",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72133111,
        "Question_title":"Azure ML: What means reconnecting terminal?",
        "Question_body":"<p>I am a newbie in this, and I am facing some problems with the Azure ML workspace. I ran a python code from the terminal, and then I opened another terminal to check the process. I got the following message in the terminal that checked the process:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9XLPw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9XLPw.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What does this mean? It keeps running, but I don't know if it is a bad message. It takes soo long, and I don't want to lose the processing time.<\/p>\n<p>I appreciate any tips.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-05 20:12:30.743 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azure-python-sdk",
        "Question_view_count":48,
        "Owner_creation_date":"2019-11-30 18:16:16.887 UTC",
        "Owner_last_access_date":"2022-09-23 17:51:17.98 UTC",
        "Owner_reputation":45,
        "Owner_up_votes":21,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":"<blockquote>\n<p>What does this mean? It keeps running, but I don't know if it is a bad message. It takes soo long, and I don't want to lose the processing time.<\/p>\n<\/blockquote>\n<ul>\n<li><code>Reconnecting terminal<\/code> message can appear for multiple reasons like intermittent connectivity issues, unused active terminal sessions, processing of different size\/format of data.<\/li>\n<li>Make sure you close any unused terminal sessions to preserve your compute instance's resources. Idle terminals may impact the performance of compute instances.<\/li>\n<\/ul>\n<p>You can refer to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#manage-terminal-sessions\" rel=\"nofollow noreferrer\">Access a compute instance terminal in your workspace<\/a>, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-optimize-data-processing\" rel=\"nofollow noreferrer\">Optimize data processing with Azure Machine Learning<\/a> and <a href=\"https:\/\/www.youtube.com\/watch?v=kiScfw9i4FM\" rel=\"nofollow noreferrer\">Azure ML: Speed up processing time<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-05-06 08:27:02.423 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72133111",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39652384,
        "Question_title":"How can I import into Azure machine learning studio from azure table storage with ODATA query?",
        "Question_body":"<p>The Import Data module for Azure Table documention can be found here: <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/mt674699\" rel=\"nofollow\">https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/mt674699<\/a><\/p>\n\n<p>In there it mentions that:<\/p>\n\n<blockquote>\n  <p>The Import Data module does not support filtering as data is being read. The exception is reading from data feeds, which sometimes allow you to specify a filter condition as part of the feed URL.<\/p>\n<\/blockquote>\n\n<p>There is a large amount of data in our table storage and it is not feasible to re-download the entire data set each time we run the experiment. I'm aware that there is the option to cache the data, however there is new data constantly being inserted and we would like to be able to use the new data whenever the experiment is run.<\/p>\n\n<p>Is there an alternative to the Import Data module that we could use to get table storage data with an ODATA query instead?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-09-23 03:59:43.637 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-table-storage|azure-machine-learning-studio",
        "Question_view_count":324,
        "Owner_creation_date":"2015-12-20 22:57:46.693 UTC",
        "Owner_last_access_date":"2020-12-29 19:40:03.983 UTC",
        "Owner_reputation":802,
        "Owner_up_votes":30,
        "Owner_down_votes":1,
        "Owner_views":152,
        "Answer_body":"<p>There is no generic way to incrementally update a dataset. <\/p>\n\n<p>However, depending on what you want to do with the data, there are different options for adding new data:<\/p>\n\n<p>The Add Rows module effectively concatenates two datasets. So you could use the old, cached dataset on the left-hand input and add the new data on the right-hand input. That way you only have to read in the new data.\nHowever, you would have to create some complex logic for figuring out which rows were new and old, and then maintain that outside Azure ML.<\/p>\n\n<p>You could create an OData feed based on table storage, to enable filtering and get the new data that way. Just be aware that right now only public feeds are supported. And you would have to use Join or Add Rows to recombine the old and new data as described above. <\/p>\n\n<p>You might also look into ways of using the <a href=\"https:\/\/blog.maartenballiauw.be\/post\/2012\/10\/08\/what-partitionkey-and-rowkey-are-for-in-windows-azure-table-storage.html\" rel=\"nofollow\">table names<\/a>, partitions, and rowkeys to chunk your data. <\/p>\n\n<p>If you are retraining a model and you want to update your feature statistics, the <a href=\"https:\/\/msdn.microsoft.com\/library\/dn913056.aspx\" rel=\"nofollow\">Learning with Counts<\/a> modules support incremental updates of count-based features. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-09-24 01:03:09.117 UTC",
        "Answer_score":1.0,
        "Owner_location":"Brisbane, Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39652384",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56812071,
        "Question_title":"Is it possible to access datastores from a Azure ML Service webservice?",
        "Question_body":"<p>According to the Azure ML Service <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-access-data#access-datastores-during-training\" rel=\"nofollow noreferrer\">documentation<\/a> it is possible to access datastores during training, but I couldn't find anything about using data from datastores inside the Webservice.<\/p>\n<p>Even though is not necessary use external data to make an Webservice work, to use my model as I intend I need to use some datasets with features created based on historical data. For example: imagine that I'm trying to forecast if a client is going to pay a bill in the right date a good strategy is to create a feature based on previous payments of this same client.<\/p>\n<p>The only external file that I could use in a Webservice is the 'model.pkl' which stores the ML model that I created previously.<\/p>\n<p>How can I get an Azure ML webservice access a datastore?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-28 19:04:43.06 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2022-07-27 15:58:05.407 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":935,
        "Owner_creation_date":"2019-06-26 17:47:39.943 UTC",
        "Owner_last_access_date":"2021-08-26 03:29:09.313 UTC",
        "Owner_reputation":19,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56812071",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62886435,
        "Question_title":"Using a custom docker with Azure ML",
        "Question_body":"<p>I'm following the guidelines (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments<\/a>) to use a custom docker file on Azure. My script to create the environment looks like this:<\/p>\n<pre><code>from azureml.core.environment import Environment\n\nmyenv = Environment(name = &quot;myenv&quot;)\nmyenv.docker.enabled = True\ndockerfile = r&quot;&quot;&quot;\nFROM mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04\nRUN apt-get update &amp;&amp; apt-get install -y libgl1-mesa-glx\nRUN echo &quot;Hello from custom container!&quot;\n&quot;&quot;&quot;\nmyenv.docker.base_image = None\nmyenv.docker.base_dockerfile = dockerfile\n<\/code><\/pre>\n<p>Upon execution, this is totally ignored and libgl1 is not installed. Any ideas why?<\/p>\n<p>EDIT: Here's the rest of my code:<\/p>\n<pre><code>est = Estimator(\n    source_directory = '.',\n    script_params = script_params,\n    use_gpu = True,\n    compute_target = 'gpu-cluster-1',\n    pip_packages = ['scipy==1.1.0', 'torch==1.5.1'],\n    entry_script = 'AzureEntry.py',\n    )\n\nrun = exp.submit(config = est)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments<\/a><\/p>",
        "Question_answer_count":5,
        "Question_comment_count":2,
        "Question_creation_date":"2020-07-14 00:45:13.407 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-14 13:00:46.43 UTC",
        "Question_score":4,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":1819,
        "Owner_creation_date":"2013-04-17 22:31:48.703 UTC",
        "Owner_last_access_date":"2021-02-08 16:39:27.677 UTC",
        "Owner_reputation":170,
        "Owner_up_votes":5,
        "Owner_down_votes":1,
        "Owner_views":23,
        "Answer_body":"<p>This should work :<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.environment import Environment\nfrom azureml.train.estimator import Estimator\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core import Experiment\n\nws = Workspace (...)\nexp = Experiment(ws, 'test-so-exp')\n\nmyenv = Environment(name = &quot;myenv&quot;)\nmyenv.docker.enabled = True\ndockerfile = r&quot;&quot;&quot;\nFROM mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04\nRUN apt-get update &amp;&amp; apt-get install -y libgl1-mesa-glx\nRUN echo &quot;Hello from custom container!&quot;\n&quot;&quot;&quot;\nmyenv.docker.base_image = None\nmyenv.docker.base_dockerfile = dockerfile\n\n## You need to instead put your packages in the Environment definition instead... \n## see below for some changes too\n\nmyenv.python.conda_dependencies = CondaDependencies.create(pip_packages = ['scipy==1.1.0', 'torch==1.5.1'])\n<\/code><\/pre>\n<p>Finally you can build your estimator a bit differently :<\/p>\n<pre><code>est = Estimator(\n    source_directory = '.',\n#     script_params = script_params,\n#     use_gpu = True,\n    compute_target = 'gpu-cluster-1',\n#     pip_packages = ['scipy==1.1.0', 'torch==1.5.1'],\n    entry_script = 'AzureEntry.py',\n    environment_definition=myenv\n    )\n<\/code><\/pre>\n<p>And submit it :<\/p>\n<pre><code>run = exp.submit(config = est)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>Let us know if that works.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-07-14 18:13:46.867 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62886435",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39941622,
        "Question_title":"Parallel *apply in Azure Machine Learning Studio",
        "Question_body":"<p>I have just started to get myself acquainted with parallelism in R. <\/p>\n\n<p>As I am planning to use <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow\">Microsoft Azure Machine Learning Studio<\/a> for my project, I have started investigating what <a href=\"https:\/\/mran.revolutionanalytics.com\/documents\/rro\/multithread\/\" rel=\"nofollow\">Microsoft R Open<\/a> offers for parallelism, and thus, I found <a href=\"https:\/\/mran.revolutionanalytics.com\/documents\/rro\/multithread\/\" rel=\"nofollow\">this<\/a>, in which it says that parallelism is done under the hood that leverages the benefit of all available cores, without changing the R code. The article also shows some performance benchmarks, however, most of them demonstrate the performance benefit in doing mathematical operations.<\/p>\n\n<p>This was good so far. In addition, I am also interested to know whether it also parallelize the <code>*apply<\/code> functions under the hood or not. I also found these 2 articles that describes how to parallelize <code>*apply<\/code> functions in general:<\/p>\n\n<ol>\n<li><a href=\"https:\/\/www.r-bloggers.com\/quick-guide-to-parallel-r-with-snow\/\" rel=\"nofollow\">Quick guide to parallel R with snow<\/a>: describes facilitating parallelism using <a href=\"https:\/\/cran.r-project.org\/web\/packages\/snow\/snow.pdf\" rel=\"nofollow\"><code>snow<\/code><\/a> package, <code>par*apply<\/code> function family, and <code>clusterExport<\/code>.<\/li>\n<li><a href=\"http:\/\/www.win-vector.com\/blog\/2016\/01\/parallel-computing-in-r\/\" rel=\"nofollow\">A gentle introduction to parallel computing in R<\/a>: using <code>parallel<\/code> package, <code>par*apply<\/code> function family, and binding values to environment.<\/li>\n<\/ol>\n\n<p>So my question is when I will be using <code>*apply<\/code> functions in Microsoft Azure Machine Learning Studio, will that be parallelized under the hood by default, or I need to make use of packages like <code>parallel<\/code>, <code>snow<\/code> etc.?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-09 08:37:36.777 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"r|parallel-processing|azure-machine-learning-studio|microsoft-r",
        "Question_view_count":501,
        "Owner_creation_date":"2013-04-11 12:50:40.14 UTC",
        "Owner_last_access_date":"2022-09-24 10:13:30.763 UTC",
        "Owner_reputation":4588,
        "Owner_up_votes":1194,
        "Owner_down_votes":3,
        "Owner_views":453,
        "Answer_body":"<p>Personally, I think we could have marketed MRO a bit differently, without making such a big deal about parallelism\/multithreading. Ah well.<\/p>\n\n<p>R comes with an Rblas.dll\/.so which implements the routines used for linear algebra computations. These routines are used in various places, but one common use case is for fitting regression models. With MRO, we replace the standard Rblas with one that uses the <a href=\"https:\/\/software.intel.com\/en-us\/intel-mkl\" rel=\"noreferrer\">Intel Math Kernel Library<\/a>. When you call a function like <code>lm<\/code> or <code>glm<\/code>, MRO will use multiple threads and optimized CPU instructions to fit the model, which can get you dramatic speedups over the standard implementation.<\/p>\n\n<p>MRO isn't the only way you can get this sort of speedup; you can also compile\/download other BLAS implementations that are similarly optimized. We just make it an easy one-step download.<\/p>\n\n<p>Note that the MKL only affects code that involves linear algebra. It isn't a general-purpose speedup tool; any R code that doesn't do matrix computations won't see a performance improvement. In particular, it won't speed up any code that involves <em>explicit<\/em> parallelism, such as code using the parallel package, SNOW, or other cluster computing tools.<\/p>\n\n<p>On the other hand, it won't <em>degrade<\/em> them either. You can still use packages like parallel, SNOW, etc to create compute clusters and distribute your code across multiple processes. MRO works just like regular CRAN R in this respect. (One thing you might want to do, though, if you're creating a cluster of nodes on the one machine, is reduce the number of MKL threads. Otherwise you risk contention between the nodes for CPU cores, which will degrade performance.)<\/p>\n\n<p>Disclosure: I work for Microsoft.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-10-09 14:51:38.777 UTC",
        "Answer_score":5.0,
        "Owner_location":"Paderborn, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39941622",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73137433,
        "Question_title":"ModuleNotFoundError while using AzureML pipeline with yml file based RunConfiguration and environment.yml",
        "Question_body":"<p>I am running into a ModuleNotFoundError for pandas while using the following code to orchestrate my Azure Machine Learning Pipeline:<\/p>\n<pre><code># Loading run config\nprint(&quot;Loading run config&quot;)\ntask_1_run_config = RunConfiguration.load(\n    os.path.join(WORKING_DIR + '\/pipeline\/task_runconfigs\/T01_Test_Task.yml')\n    ) \n\ntask_1_script_run_config = ScriptRunConfig(\n    source_directory=os.path.join(WORKING_DIR + '\/pipeline\/task_scripts'),\n    run_config=task_1_run_config    \n)\n\ntask_1_py_script_step = PythonScriptStep(\n    name='Task_1_Step',\n    script_name=task_1_script_run_config.script,\n    source_directory=task_1_script_run_config.source_directory,\n    compute_target=compute_target\n)\n\npipeline_run_config = Pipeline(workspace=workspace, steps=[task_1_py_script_step])#, task_2])\n\npipeline_run = Experiment(workspace, 'Test_Run_New_Pipeline').submit(pipeline_run_config)\npipeline_run.wait_for_completion()\n<\/code><\/pre>\n<p>The environment.yml<\/p>\n<pre><code>name: phinmo_pipeline_env\ndependencies:\n- python=3.8\n- pip:\n  - pandas\n  - azureml-core==1.43.0\n  - azureml-sdk\n  - scipy\n  - scikit-learn\n  - numpy\n  - pyyaml==6.0\n  - datetime\n  - azure\nchannels:\n  - conda-forge\n<\/code><\/pre>\n<p>The loaded RunConfiguration in T01_Test_Task.yml looks like this:<\/p>\n<pre><code># The script to run.\nscript: T01_Test_Task.py\n# The arguments to the script file.\narguments: [\n  &quot;--test&quot;, False,\n  &quot;--date&quot;, &quot;2022-07-26&quot;\n]\n# The name of the compute target to use for this run.\ncompute_target: phinmo-compute-cluster\n# Framework to execute inside. Allowed values are &quot;Python&quot;, &quot;PySpark&quot;, &quot;CNTK&quot;, &quot;TensorFlow&quot;, and &quot;PyTorch&quot;.\nframework: Python\n# Maximum allowed duration for the run.\nmaxRunDurationSeconds: 6000\n# Number of nodes to use for running job.\nnodeCount: 1\n\n#Environment details.\nenvironment:\n  # Environment name\n  name: phinmo_pipeline_env\n  # Environment version\n  version:\n  # Environment variables set for the run.\n  #environmentVariables:\n  #  EXAMPLE_ENV_VAR: EXAMPLE_VALUE\n  # Python details\n  python:\n    # user_managed_dependencies=True indicates that the environmentwill be user managed. False indicates that AzureML willmanage the user environment.\n    userManagedDependencies: false\n    # The python interpreter path\n    interpreterPath: python\n    # Path to the conda dependencies file to use for this run. If a project\n    # contains multiple programs with different sets of dependencies, it may be\n    # convenient to manage those environments with separate files.\n    condaDependenciesFile: environment.yml\n    # The base conda environment used for incremental environment creation.\n    baseCondaEnvironment: AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\n  # Docker details\n  \n# History details.\nhistory:\n  # Enable history tracking -- this allows status, logs, metrics, and outputs\n  # to be collected for a run.\n  outputCollection: true\n  # Whether to take snapshots for history.\n  snapshotProject: true\n  # Directories to sync with FileWatcher.\n  directoriesToWatch:\n  - logs\n# data reference configuration details\ndataReferences: {}\n# The configuration details for data.\ndata: {}\n# Project share datastore reference.\nsourceDirectoryDataStore:\n<\/code><\/pre>\n<p>I already tried a few things like overwriting the environment attribute in the RunConfiguration object with a environment.python.conda_dependencies object or assigning a version number to pandas in the environment.yml, changing the location of the environment.yml. But I am at a loss at what else to try. the T01_Test_Task.py runs without issues on its own. But putting it into a pipeline just does not seem to work.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-27 11:53:18.813 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-27 12:19:20.077 UTC",
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":51,
        "Owner_creation_date":"2018-12-11 10:32:51.74 UTC",
        "Owner_last_access_date":"2022-09-21 21:24:10.723 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":"<p>Okay I found the issue.\nI am unnecessarily using the ScriptRunConfig which overwrites the assigned environment with some default azureml environment. I was able to see that only in the Task description in the Azure Machine Learning Studio UI.<\/p>\n<p>I was able to just remove that part and now it works:<\/p>\n<pre><code>task_1_run_config = RunConfiguration.load(\n    os.path.join(WORKING_DIR + '\/pipeline\/task_runconfigs\/T01_Test_Task.yml')\n    ) \ntask_1_py_script_step = PythonScriptStep(\n    name='Task_1_Step',\n    script_name='T01_Test_Task.py',\n    source_directory=os.path.join(WORKING_DIR + '\/pipeline\/task_scripts'),\n    runconfig=task_1_run_config, \n    compute_target=compute_target\n)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-27 16:00:35.37 UTC",
        "Answer_score":0.0,
        "Owner_location":"Cologne Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73137433",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65153543,
        "Question_title":"AzureML: How to delete detached Kubernetes service clusters?",
        "Question_body":"<p>On AzureMl, I have created some Kubernetes service clusters using <code>ComputeTarget.create()<\/code>.<\/p>\n<p>Unfortunately, I have detached some of them and I can no longer see them from the AzureML page (Compute &gt; Inference Clusters). I can re-attach them on the AzureMl page but the delete bottom is not available for the re-attached clusters.<\/p>\n<p>Because those idle clusters occupy the Total Regional Cores quota I can't create new clusters, I am wondering if there is a way to delete them?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-05 03:43:18.633 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-01-14 22:18:11.497 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":112,
        "Owner_creation_date":"2017-04-29 23:38:18.56 UTC",
        "Owner_last_access_date":"2022-09-21 16:48:13.03 UTC",
        "Owner_reputation":155,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65153543",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53270630,
        "Question_title":"Real world scenario : which machine learning algorithm to choose best attributions",
        "Question_body":"<p>I am a .NET Developer and in my company we have developed an engine that attributes missions (transport those packages from A to B) to the best matching driver based on simple rules (pickup address, delivery address, driver's address, driver's vehicule caracteristics (max weight, length), distance to travel, package types to transport, etc ...).\nThis engine tries to make its best to provide to the user with the 3 best matching drivers the transport mission.<\/p>\n\n<p>We are trying to address this scenario with machine learning (100000+ missions in our database).\nWe want to answer this questions:\n- Who is the best matching driver for this mission?\n- What is the matching score for XXX driver for this mission?<\/p>\n\n<p>As a side note, our pool of drivers is evolving (some drivers are removed while some others are added in our system over time).<\/p>\n\n<p>I am discovering ML and learning about basic ML algorithms, but I can not find an algorithm that could answer to this question.<\/p>\n\n<p>I would like to develop with the new (still in preview) Microsoft Framework for .NET developers (ML.NET), or maybe Azure Machine Learning Studio or Azure Machine Learning Service<\/p>\n\n<p>Our data look like (simplified) :<\/p>\n\n<pre>\nDrivers :\n\nName        City            VehicleMaxWeight    VehicleLength ... StreetName, ZipCode, Country, Latitude, Longitude ... \nPierre      Paris           19000Kg             12m\nFrancois    Bordeaux        26000Kg             12m\nGuillaume   Montpellier     44000Kg             16.50m\nJacques     Montpellier     32000Kg             16.50m\nJean        Paris           12000Kg             8m\nBernard     Montauban       26000Kg             12m     \n\nTransport mission history :\n\nPickupCity      DeliveryCity    Service         TotalWeight     TotalLenght     DriverAssignment        (Distance to PickupCity)\nParis           Marseille       S1               2000Kg         5m              Jean                    (5km)\nParis           Lyon            S2              15000Kg         10m             Pierre                  (8km)\nToulouse        Lyon            S3              5000Kg          5m              Bernard                 (53km)\n...             ...             ...             ...             ...             ...                     (...)\nLyon            Paris           S2              3000Kg          3m              ????????????????\n<\/pre>\n\n<p>Or if the first problem cannot be easily addressed, it would be useful to answer to this question :\nWhich driver can I select to go from Lyon to Paris for service S2, given the following history ?<\/p>\n\n<pre>\nTransport mission history :\n\nPickupCity      DeliveryCity    Service         DriverAssignment\nParis           Marseille       S1              Jean            \nParis           Lyon            S2              Pierre          \nToulouse        Lyon            S3              Bernard         \n...             ...             ...             ...             \nLyon            Paris           S2              ????????????????\n<\/pre>\n\n<p>I would try to predict the column <pre>DriverAssignment<\/pre><\/p>\n\n<p>Could you please help me find an algorithm for this task ? And maybe how I can implement it in ML.NET or Azure ML Studio \/ Service ?<\/p>\n\n<p>Thank you !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2018-11-12 21:51:23.117 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2018-11-13 10:06:26.997 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|artificial-intelligence|azure-machine-learning-studio|ml.net",
        "Question_view_count":240,
        "Owner_creation_date":"2012-04-06 13:41:43.773 UTC",
        "Owner_last_access_date":"2020-11-24 13:19:36.427 UTC",
        "Owner_reputation":657,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53270630",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54747199,
        "Question_title":"Authentication problems",
        "Question_body":"<p>I am trying to automate the process to create a model with azure machine learning services and I get some problems with the authentication. When I run my code on my remote machine everything is fine but when I run the code on remote I get this authentication sentence:<\/p>\n\n<pre><code>Make sure your code doesn't require 'az login' to have happened before using azureml-SDK, except the case when you are specifying AzureCliAuthentication in azureml-SDK.\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https:\/\/microsoft.com\/devicelogin and enter the code CZMKCYS8B to authenticate\"\n<\/code><\/pre>\n\n<p>Azure ask me for authentication and I have to make it manually.\nI would like to know if there is some way to do it automatically.<\/p>\n\n<p>I was looking for it and I was investigated how to do it using tokens but I couldn't find any solution<\/p>\n\n<p>Someone can give me an advice?<\/p>\n\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2019-02-18 12:20:51.81 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-02-18 12:50:45.457 UTC",
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":653,
        "Owner_creation_date":"2017-08-01 17:34:44.543 UTC",
        "Owner_last_access_date":"2022-01-10 11:29:26.423 UTC",
        "Owner_reputation":71,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54747199",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71649163,
        "Question_title":"Can azureml pass variables from one step to another?",
        "Question_body":"<p>I have a requirement to use azure machine learning to develop a pipeline. In this pipeline we don't pass data as inputs\/outputs but variables (for example a list or an int). I have looked on the Microsoft documentation but could not seem to find something fitting my case. Also tried to use the PipelineData class but could not retrieve my variables.<\/p>\n<ol>\n<li>Is this possible?<\/li>\n<li>Is this a good approach?<\/li>\n<\/ol>\n<p>Thanks for your help.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2022-03-28 14:35:11.533 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":399,
        "Owner_creation_date":"2022-03-28 14:29:33.363 UTC",
        "Owner_last_access_date":"2022-09-15 11:40:33.903 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>I know I'm a bit late to the party but here we go:<\/p>\n<p><strong>Passing variables between AzureML Pipeline Steps<\/strong><\/p>\n<p>To directly answer your question, to my knowledge it is not possible to pass variables directly between PythonScriptSteps in an AzureML Pipeline.<\/p>\n<p>The reason for that is that the steps are executed in isolation, i.e. the code is run in different processes or even computes. The only interface a PythonScriptStep has is (a) command line arguments that need to be set prior to submission of the pipeline and (b) data.<\/p>\n<p><strong>Using datasets to pass information between PythonScriptSteps<\/strong><\/p>\n<p>As a workaround you can use PipelineData to pass data between steps.\nThe previously posted blog post may help: <a href=\"https:\/\/vladiliescu.net\/3-ways-to-pass-data-between-azure-ml-pipeline-steps\/\" rel=\"nofollow noreferrer\">https:\/\/vladiliescu.net\/3-ways-to-pass-data-between-azure-ml-pipeline-steps\/<\/a><\/p>\n<p>As for your concrete problem:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># pipeline.py\n\n# This will make Azure create a unique directory on the datastore everytime the pipeline is run.\nvariables_data = PipelineData(&quot;variables_data&quot;, datastore=datastore)\n\n# `variables_data` will be mounted on the target compute and a path is given as a command line argument\nwrite_variable = PythonScriptStep(\n    script_name=&quot;write_variable.py&quot;,\n    arguments=[\n        &quot;--data_path&quot;,\n        variables_data\n    ],\n    outputs=[variables_data],\n)\n\nread_variable = PythonScriptStep(\n    script_name=&quot;read_variable.py&quot;,\n    arguments=[\n        &quot;--data_path&quot;,\n        variables_data\n    ],\n    inputs=[variables_data],\n)\n\n<\/code><\/pre>\n<p>In your script you'll want to serialize the variable \/ object that you're trying to pass between steps:<\/p>\n<p>(You could of course use JSON or any other serialization method)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># write_variable.py\n\nimport argparse\nimport pickle\nfrom pathlib import Path\n\nparser = argparse.ArgumentParser()\nparser.add_argument(&quot;--data_path&quot;)\nargs = parser.parse_args()\n\nobj = [1, 2, 3, 4]\n\nPath(args.data_path).mkdir(parents=True, exist_ok=True)\nwith open(args.data_path + &quot;\/obj.pkl&quot;, &quot;wb&quot;) as f:\n    pickle.dump(obj, f)\n<\/code><\/pre>\n<p>Finally, you can read the variable in the next step:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># read_variable.py\n\nimport argparse\nimport pickle\n\nparser = argparse.ArgumentParser()\nparser.add_argument(&quot;--data_path&quot;)\nargs = parser.parse_args()\n\n\nwith open(args.data_path + &quot;\/obj.pkl&quot;, &quot;rb&quot;) as f:\n    obj = pickle.load(f)\n\nprint(obj)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-26 09:10:30.38 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-07-26 09:12:27.247 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71649163",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65343148,
        "Question_title":"How to load a AzureML model in an Azure Databricks compute?",
        "Question_body":"<p>I am trying to run a <code>DatabricksStep<\/code>. I have used <code>ServicePrincipalAuthentication<\/code> to authenticate the run:<\/p>\n<pre><code>appId = dbutils.secrets.get(&lt;secret-scope-name&gt;, &lt;client-id&gt;)\ntenant = dbutils.secrets.get(&lt;secret-scope-name&gt;, &lt;directory-id&gt;)\nclientSecret = dbutils.secrets.get(&lt;secret-scope-name&gt;, &lt;client-secret&gt;)\nsubscription_id = dbutils.secrets.get(&lt;secret-scope-name&gt;, &lt;subscription-id&gt;)\nresource_group = &lt;aml-rgp-name&gt;\nworkspace_name = &lt;aml-ws-name&gt;\n\nsvc_pr = ServicePrincipalAuthentication(\n       tenant_id=tenant,\n       service_principal_id=appId,\n       service_principal_password=clientSecret)\n\nws = Workspace(\n       subscription_id=subscription_id,\n       resource_group=resource_group,\n       workspace_name=workspace_name,\n       auth=svc_pr\n       )\n<\/code><\/pre>\n<p>The authentication is successful since running the following block of code gives the desired output:<\/p>\n<pre><code>subscription_id = ws.subscription_id\nresource_group = ws.resource_group\nworkspace_name = ws.name\nworkspace_region = ws.location\nprint(subscription_id, resource_group, workspace_name, workspace_region, sep='\\n')\n<\/code><\/pre>\n<p>However, the following block of codes gives an error:<\/p>\n<pre><code>model_name=&lt;registered-model-name&gt;\nmodel_path = Model.get_model_path(model_name=model_name, _workspace=ws)\nloaded_model = joblib.load(model_path)\nprint('model loaded!')\n<\/code><\/pre>\n<p>This is giving an error:<\/p>\n<pre><code>UserErrorException:\n    Message: \nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\n1. You are not authorized to access this resource, or directory listing denied.\n2. you may not login your azure service, or use other subscription, you can check your\ndefault account by running azure cli commend:\n'az account list -o table'.\n3. You have multiple objects\/login session opened, please close all session and try again.\n                \n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;\\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\\n1. You are not authorized to access this resource, or directory listing denied.\\n2. you may not login your azure service, or use other subscription, you can check your\\ndefault account by running azure cli commend:\\n'az account list -o table'.\\n3. You have multiple objects\/login session opened, please close all session and try again.\\n                &quot;,\n        &quot;code&quot;: &quot;UserError&quot;\n    }\n}\n<\/code><\/pre>\n<p>The error is <code>Forbidden Error<\/code> even though I have authenticated using <code>ServicePrincipalAuthentication<\/code>.\nHow to resolve this error to run inference using an AML registered model in ADB?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2020-12-17 14:59:00.29 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-databricks|azure-machine-learning-service",
        "Question_view_count":466,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65343148",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32431471,
        "Question_title":"Not Getting the Expected Output in AzureML",
        "Question_body":"<p>Background: I am working on a project that aims to classify product reviews into positive and negative using Sentiment Analysis in Azure ML. I got stuck when I was classifying reviews into different departments.<\/p>\n\n<p>I am basically reading words from csv files and checking whether the review(v: list of sentences) contains these words. If some of these words are found in the review then I am noting the sentence number and pushing it into respective lists( FinanceList, QualityList, LogisticsList ). In the end I am converting the lists to strings and pushing them into a dataframe.<\/p>\n\n<p>The output is not getting logged for the print statements that I have written in the script in Azure ML.<\/p>\n\n<p>The values in the dataframe are always turning out to be 0 but when I run the code locally I get the expected output.<\/p>\n\n<p>Description of First Image: The columns of the dataframe showing 0 values.<\/p>\n\n<p>Description of Second Image: I have highlighted the expected output that I got locally for the same review which was used in AzureML.<\/p>\n\n<p><a href=\"http:\/\/imgur.com\/0C3wcYj.png\" rel=\"nofollow\">Image 1<\/a><\/p>\n\n<p><a href=\"http:\/\/i.imgur.com\/lyHsM8z.png\" rel=\"nofollow\">Image 2<\/a><\/p>\n\n<p>The things that I have already checked:<\/p>\n\n<ol>\n<li>The csv files are read properly.<\/li>\n<li>The review contains the words that I am searching.<\/li>\n<\/ol>\n\n<p>I am unable to understand where I am going wrong.<\/p>\n\n<p>'<\/p>\n\n<pre><code>import csv\nimport math\nimport pandas as pd\nimport numpy as np\n\ndef azureml_main( data, ud):\n\n   FinanceDept = []\n   LogisticsDept = []\n   QualityDept = []\n  #Reading from the csv files\n   with open('.\\Script Bundle\\\\quality1.csv', 'rb') as fin:\n      reader = csv.reader(fin)\n      QualityDept = list(reader)\n\n   with open('.\\Script Bundle\\\\finance1.csv', 'rb') as f:\n      reader = csv.reader(f)\n      FinanceDept = list(reader)\n\n   with open('.\\Script Bundle\\\\logistics1.csv', 'rb') as f:\n      reader = csv.reader(f)\n      LogisticDept = list(reader)\n\n   FinanceList = []\n   LogisticsList = []\n   QualityList = []\n\n#Initializing the Lists   \n   FinanceList.append(0)\n   LogisticsList.append(0)\n   QualityList.append(0)\n\n   rev = data['Data']\n   v = rev[0].split('.')\n\n   print FinanceDept\n\n   S = 0   \n   for sentence in v:\n      S = S + 1\n      z = sentence.split(' ')\n      for c in z:\n         c = c.lower()\n         if c in FinanceDept and S not in FinanceList:\n            FinanceList.append(S)\n         if c in LogisticsDept and S not in LogisticsList:\n            LogisticsList.append(S)\n         if c in QualityDept and S not in QualityList:\n            QualityList.append(S)\n   #Compute User Reputation Score\n   Upvotes = int(ud['upvotes'].tolist()[0])\n   Downvotes = int(ud['downvotes'].tolist()[0])\n   TotalVotes = max(1,Upvotes+Downvotes)\n\n   q = data['Score']\n\n   print FinanceList\n\n   repScore = float(Upvotes)\/TotalVotes \n   repScore = repScore*float( q[0] )\n   str1 = ','.join(str(e) for e in FinanceList) \n   str2 = ','.join(str(e) for e in QualityList)\n   str3 = ','.join(str(e) for e in LogisticsList)\n\n   x = ud['id']\n\n   #df = pd.DataFrame(  [str(repScore), str1  , str2  , str3 ], columns=[Write the columns])\n   d = {'id': x[0], 'Score': float(repScore),'Logistics':str3,'Finance':str1,'Quality':str2}\n   df = pd.DataFrame(data=d, index=np.arange(1))\n   return df,`\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-09-07 05:11:36.04 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-09-07 05:35:24.89 UTC",
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":1013,
        "Owner_creation_date":"2015-09-06 16:07:31.89 UTC",
        "Owner_last_access_date":"2019-03-21 12:50:57.223 UTC",
        "Owner_reputation":143,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":45,
        "Answer_body":"<p>@Anuj Shankar,\nAfter my colleague tested, we can read data from <code>CSV<\/code> files and get the expected results. Please refer to this experience:<\/p>\n\n<p>1)  Input data  - It has <code>apple.zip<\/code> file which has two <code>csv<\/code> files similar to you and each csv file includes bag of words related to company.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/yrXst.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yrXst.jpg\" alt=\"enter image description here\"><\/a>\n2)  Python script: <\/p>\n\n<pre><code># The script MUST contain a function named azureml_main\n# which is the entry point for this module.\n#\n# The entry point function can contain up to two input arguments:\n#   Param&lt;dataframe1&gt;: a pandas.DataFrame\n#   Param&lt;dataframe2&gt;: a pandas.DataFrame\nimport csv\nimport numpy as np\nimport pandas as pd\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    # Execution logic goes here\n    #print('Input pandas.DataFrame #1:\\r\\n\\r\\n{0}'.format(dataframe1))\n\n    # If a zip file is connected to the third input port is connected,\n    # it is unzipped under \".\\Script Bundle\". This directory is added\n    # to sys.path. Therefore, if your zip file contains a Python file\n    # mymodule.py you can import it using:\n    # import mymodule\n\n    apple = {}\n    microsoft = {}\n  #Reading from the csv files\n    with open('.\\Script Bundle\\\\apple.csv', 'rb') as f:\n      reader = csv.reader(f)\n      apple = list_to_dict(list(reader)[0])\n\n    with open('.\\Script Bundle\\\\microsoft.csv', 'rb') as f:\n      reader = csv.reader(f)\n      microsoft = list_to_dict(list(reader)[0])\n\n#    print('hello world' + ' '.join(apple[0]))\n    applecount = 0\n    microsoftcount = 0\n\n    input = \"i want to buy surface which runs on windows\"\n    splitted_input = input.split(' ')\n\n    for word in splitted_input:\n        if word in apple:\n            applecount = applecount + 1\n        if word in microsoft:\n            microsoftcount = microsoftcount + 1\n\n    print(\"apple bag of words count - \" + str(applecount))\n    print(\"microsoft bag of words count - \" + str(microsoftcount))\n    mydata = [{'input words': len(splitted_input)}, {'applecount':applecount},\n        {'microsoftcount':microsoftcount}]       \n    # Return value must be of a sequence of pandas.DataFrame\n    return pd.DataFrame(mydata),\n\n\ndef list_to_dict(li):      \n    dct = {}  \n    for item in li:\n        if dct.has_key(item):              \n            dct[item] = dct[item] + 1  \n        else:  \n            dct[item] = 1  \n    return dct  \n<\/code><\/pre>\n\n<p>3)  Output  - if I consider a string \"i want to buy surface which runs on windows\". It has 2 words related to microsoft and 0 related to apple which are visualized in below snapshot.\n<a href=\"https:\/\/i.stack.imgur.com\/ifE1t.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ifE1t.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-09-30 03:07:41.283 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bangalore, Karnataka, India",
        "Answer_last_edit_date":"2016-08-23 11:00:10.497 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32431471",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30016116,
        "Question_title":"SQL - How to join two tables using values from the other table for missing or null values in either table",
        "Question_body":"<p><strong>Alright StackOverflow, I have a problem:<\/strong><\/p>\n\n<p>I am doing some work with <a href=\"http:\/\/azureml.com\" rel=\"nofollow\" title=\"Azure Machine Learning\">Azure Machine Learning<\/a> and I have reached an impasse. I have two tables, and I need to join them. The tables look like this:<\/p>\n\n<pre><code>   TABLE A          TABLE B   \n+-----------+    +-----------+\n| a | b | c |    | a | b | c |\n+-----------+    +-----------+\n| 1 | 2 |   |    |   | 2 | 3 |\n+-----------+    +-----------+\n<\/code><\/pre>\n\n<p>(those are just examples.)<\/p>\n\n<p>I need to join these tables when columns they share (in this case only b, but could be multiple) are equivalent. I also, however, need to populate missing values. If TABLE A is missing a value for one of its columns, and TABLE B has it for a matching row, they should combine values in the result table. I know that there is a way to do this one way, but it also needs to work in reverse, so that if TABLE B is missing a value, and TABLE A has one, it is populated.<\/p>\n\n<p><strong>EDIT: Desired Result:<\/strong><\/p>\n\n<pre><code>   TABLE C\n+-----------+\n| a | b | c |\n+-----------+\n| 1 | 2 | 3 |\n+-----------+\n<\/code><\/pre>\n\n<p>Some background information:<\/p>\n\n<ul>\n<li>AzureML uses a form of SQLite for their SQL interpretation, so please try and keep your answers in as basic SQL as possible. Thanks! :)<\/li>\n<li>AzureML has a built in join module, for those familiar with AzureML, but I don't think it'll be able to accomplish what is necessary. I'll use the SQL interpretation module.<\/li>\n<\/ul>\n\n<p>Your assistance is appreciated! Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2015-05-03 16:11:51.03 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2015-05-03 18:15:24.82 UTC",
        "Question_score":0,
        "Question_tags":"mysql|sqlite|join|azure-machine-learning-studio",
        "Question_view_count":90,
        "Owner_creation_date":"2014-10-29 22:21:46.62 UTC",
        "Owner_last_access_date":"2022-09-22 21:50:59.473 UTC",
        "Owner_reputation":1000,
        "Owner_up_votes":327,
        "Owner_down_votes":8,
        "Owner_views":124,
        "Answer_body":"<p><strong>Answering my own question:<\/strong><\/p>\n\n<p>It turned out the join type I needed was a <em>Full Outer Join.<\/em><\/p>\n\n<p>Background information:<\/p>\n\n<ul>\n<li>For those pursuing AzureML related to this question in the future, I had to enable the functionality to save columns from the 'Right' table input.<\/li>\n<li>I then ran this through a 'Project Columns' module and a 'Metadata' module to rename them to the form I desired.<\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-05-03 18:28:28.887 UTC",
        "Answer_score":1.0,
        "Owner_location":"Raleigh, NC, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30016116",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64257530,
        "Question_title":"Import data and python scripts in azure ml entry script when deploying models",
        "Question_body":"<p>I have an existing machine learning model saved on my local system. I want to deploy this model as a web service so I can consume this model as a request-response i.e. send an HTTP request to the model and get back a predicted response.<\/p>\n<p>When attempting to deploy this model on AzureML I run into a few problems<\/p>\n<p>The model needs to be initialized in an entry script int the init() function, but for initializing my model I have a custom class and require few txt files to be loaded.<\/p>\n<p>below is the code to initialize the model object<\/p>\n<pre><code>from model_file import MyModelClass  # this is the file which contains the model class\n\ndef init():\n  global robert_model\n\n  my_model = MyModelClass(vocab_path='&lt;path-to-text-files&gt;',\n                          model_paths=['&lt;path-to-model-file&gt;'],\n                          iterations=5,\n                          min_error_probability=0.0,\n                          min_probability=0.0,\n                          weigths=None)\ndef run(json_data):\n  try:\n    data = json.loads(json_data)\n    preds, cnt = my_model.handle_batch([sentence.split()])\n    return {'output': pred, 'count': cnt}\n  except Exception as e:\n    error = str(e)\n    return error\n<\/code><\/pre>\n<p>I don't know how to import those class files and text files in the entry script<\/p>\n<p>I don't know much about azure, and I am having a hard time figuring this out. Please help.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-08 07:15:48.237 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-10-08 17:17:30.75 UTC",
        "Question_score":3,
        "Question_tags":"python|azure|machine-learning|web-deployment|azure-machine-learning-service",
        "Question_view_count":2616,
        "Owner_creation_date":"2020-07-25 14:11:29.65 UTC",
        "Owner_last_access_date":"2022-07-16 07:43:34.863 UTC",
        "Owner_reputation":91,
        "Owner_up_votes":49,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64257530",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56455761,
        "Question_title":"Access data on AML datastore from training script",
        "Question_body":"<p>I am looking for a working example how to access data on a <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-access-data#access-datastores-during-training\" rel=\"nofollow noreferrer\">Azure Machine Learning managed data store<\/a> from within a train.py script. I followed the instructions in the link and my script is able to resolve the datastore.<\/p>\n\n<p>However, whatever I tried (<code>as_download(), as_mount()<\/code>) the only thing I always got was a <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.data_reference.datareference?view=azure-ml-py\" rel=\"nofollow noreferrer\">DataReference<\/a> object. Or maybe I just don't understand how actually read data from a file with that.<\/p>\n\n<pre><code>run = Run.get_context()\nexp = run.experiment\nws = run.experiment.workspace\n\nds = Datastore.get(ws, datastore_name='mydatastore')\ndata_folder_mount = ds.path('mnist').as_mount()\n\n# So far this all works. But how to go from here?\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2019-06-05 07:14:00.513 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":866,
        "Owner_creation_date":"2012-07-19 08:06:15.157 UTC",
        "Owner_last_access_date":"2022-09-24 20:46:16.14 UTC",
        "Owner_reputation":12103,
        "Owner_up_votes":430,
        "Owner_down_votes":19,
        "Owner_views":1451,
        "Answer_body":"<p>You can pass in the DataReference object you created as the input to your training product (scriptrun\/estimator\/hyperdrive\/pipeline). Then in your training script, you can access the mounted path via argument.\nfull tutorial: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-train-models-with-aml\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-train-models-with-aml<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-08-08 18:37:38.36 UTC",
        "Answer_score":2.0,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56455761",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55353889,
        "Question_title":"Azure container instances deployment failed",
        "Question_body":"<p>I am deploying a machine learning image to Azure Container Instances from Azure Machine Learning services according to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml\" rel=\"nofollow noreferrer\">this article<\/a>, but am always stuck with the error message:<\/p>\n\n<blockquote>\n  <p>Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.<br>\n  Please check the logs for your container instance xxxxxxx'.<\/p>\n<\/blockquote>\n\n<p>I tried:<\/p>\n\n<ol>\n<li>increasing memory_gb=4 in aci_config.<\/li>\n<li>I did\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-troubleshoot-deployment#debug-the-docker-image-locally\" rel=\"nofollow noreferrer\">troubleshooting<\/a> locally, but I could not have found any.<\/li>\n<\/ol>\n\n<p>Below is my score.py<\/p>\n\n<pre><code>def init():\n    global model\n    model_path = Model.get_model_path('pofc_fc_model')\n    model = joblib.load(model_path)\n\ndef run(raw_data):\n    data = np.array(json.loads(raw_data)['data'])\n    y_hat = model.predict(data)\n    return y_hat.tolist()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-03-26 09:39:33.31 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-07-08 20:41:13.093 UTC",
        "Question_score":2,
        "Question_tags":"python|containers|azure-container-instances|azure-machine-learning-service",
        "Question_view_count":3020,
        "Owner_creation_date":"2017-11-17 23:13:29.297 UTC",
        "Owner_last_access_date":"2021-12-22 23:30:03.973 UTC",
        "Owner_reputation":306,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Answer_body":"<p>Have you registered the model <code>'pofc_fc_model'<\/code> in your workspace using the <code>register()<\/code> function on the model object? If not, there will be no model path and that can cause failure.<\/p>\n\n<p>See this section on model registration: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#registermodel\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#registermodel<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-03-27 19:34:49.51 UTC",
        "Answer_score":1.0,
        "Owner_location":"Bangkok Thailand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55353889",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71177443,
        "Question_title":"Why is AzureML SDK corrupting the default datastore?",
        "Question_body":"<p>I have tried following the documentation instructions  <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-machine-learning-pipelines\" rel=\"nofollow noreferrer\">here<\/a> (see my code below), and the pipeline seems to run okay. However, when I view it on ML Studio, it says the pipeline has failed because the container does not exist.<\/p>\n<p>Worse, if I log into Microsoft Azure Storage Explorer, the default datastore appears to be corrupted somehow and displays the following message: <code>The specified container does not exist.<\/code>.\nBefore running this I was able to add files and folders to the container.<\/p>\n<p>I have now tried this on two separate ML instances.<\/p>\n<p>Does anyone know why?<\/p>\n<p>I need to persist some data, so am using an <code>OutputFileDatasetConfig<\/code> object, and I am running code below on an Azure ML compute instance.<\/p>\n<pre><code>from azureml.core import Workspace, Dataset, Datastore\nfrom azureml.core.compute.compute import ComputeTarget\nimport azureml.core\nfrom azureml.core import Workspace, Experiment\nfrom azureml.core.environment import Environment\nfrom azureml.pipeline.core import Pipeline\nfrom azureml.pipeline.steps import PythonScriptStep\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.data import OutputFileDatasetConfig\n\n\ninteractive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\nworkspace = Workspace(\n    subscription_id, resource_group, workspace_name, auth=interactive_auth)\noutput_datastore = Datastore(\n    workspace=workspace,\n     name=resource_manager.get_output_datastore())\noutput_config = OutputFileDatasetConfig(\n    destination=(output_datastore, 'DomainConfiguration'))\n\nstep1 = PythonScriptStep(\n    name=&quot;Script&quot;,\n    script_name=&quot;script.py&quot;, \n    compute_target=compute_target, \n    source_directory=source_directory,\n    arguments=[\n        &quot;--output_configuration&quot;,\n        output_config.as_mount(),\n        ],\n    allow_reuse=True,\n    runconfig=runconfig,\n    )\nsteps.append(step1)\npipeline = Pipeline(workspace=workspace, steps=steps)\npipeline.validate()\nexperiment = Experiment(workspace,'ExperimentName')\nrun = experiment.submit(pipeline, regenerate_outputs=False)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-18 17:16:58.153 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-storage|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":161,
        "Owner_creation_date":"2022-02-18 17:01:42.717 UTC",
        "Owner_last_access_date":"2022-07-25 08:42:30.473 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71177443",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73579615,
        "Question_title":"Microsoft packages revoscalepy and microsoftml source code",
        "Question_body":"<p>Does anybody know how to find the source code for Microsoft packages for R\/Python called <code>revoscalepy<\/code> and <code>microsoftml<\/code> (also <code>azure-machine-learning-sdk<\/code> would be great). These packages contain implementation of different machine learning algos and could be installed by SQL Server installer. Model serialized by <code>revoscalepy<\/code> could be used directly in SQL script.<\/p>\n<p>Packages seem to be proprietary, but the documentation is confusing because parameters in different methods are not used, algorithms versions are not known definetely. Moreover, results differ too much with well-known <code>scikit-learn<\/code> library.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-02 08:13:24.983 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|sql-server|machine-learning|azure-machine-learning-studio",
        "Question_view_count":23,
        "Owner_creation_date":"2017-08-27 14:11:32.62 UTC",
        "Owner_last_access_date":"2022-09-22 10:47:17.127 UTC",
        "Owner_reputation":1683,
        "Owner_up_votes":155,
        "Owner_down_votes":9,
        "Owner_views":116,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Kaz\u00e1n, \u0420\u043e\u0441\u0441\u0438\u044f",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73579615",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51395552,
        "Question_title":"Value changed after Azure ML Studio Web Service",
        "Question_body":"<p>I am using Azure ML Studio in order to predict some values. I have noticed that one of my value was changed when I receive the result from the Web Service. Indeed, I have the following array <strong>[27,7,2018,11,2,4,1]<\/strong> which become <strong>[27,7,2018,11,2,4,0]<\/strong>. It is the first time I notice a such comportment. I did not see other value changed in my csv. It occurs all the time with my actual input. I do not know where to start to find the source of the issue.<\/p>\n\n<p>I tried to read the response that way :<\/p>\n\n<pre><code>HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\nif (response.IsSuccessStatusCode)\n{\n    string result = await response.Content.ReadAsStringAsync();\n}\n<\/code><\/pre>\n\n<p>And that way :<\/p>\n\n<pre><code>HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\n\nif (response.IsSuccessStatusCode)\n{\n    var tmp3 = await response.Content.ReadAsStreamAsync();\n    var tmp4 = ReadFully(tmp3);\n    var tmp5 = System.Text.Encoding.UTF8.GetString(tmp4);\n}\n\npublic static byte[] ReadFully(Stream input)\n    {\n        byte[] buffer = new byte[16 * 1024];\n        using (MemoryStream ms = new MemoryStream())\n        {\n            int read;\n            while ((read = input.Read(buffer, 0, buffer.Length)) &gt; 0)\n            {\n                ms.Write(buffer, 0, read);\n            }\n            return ms.ToArray();\n        }\n    }\n<\/code><\/pre>\n\n<p>This is the shape of my model on Azure ML (In the top left, top right and bottom python scripts random forest is applied) :\n<a href=\"https:\/\/i.stack.imgur.com\/XfIq9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XfIq9.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2018-07-18 07:03:10.873 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-07-19 06:57:56.933 UTC",
        "Question_score":0,
        "Question_tags":"c#|web-services|azure-machine-learning-studio",
        "Question_view_count":24,
        "Owner_creation_date":"2016-07-17 08:43:00.41 UTC",
        "Owner_last_access_date":"2022-09-23 16:04:38.85 UTC",
        "Owner_reputation":334,
        "Owner_up_votes":108,
        "Owner_down_votes":1,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51395552",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":33741912,
        "Question_title":"How connect Azure Machine Learning and Spark Streaming or Apache Storm",
        "Question_body":"<p>Is there possibility to get stream from Spark Streaming or Apache Storm into Azure Machine Learning? In <strong><em>reader<\/em><\/strong> option there is an input to read data from Hive database\n<a href=\"https:\/\/i.stack.imgur.com\/8Em26.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8Em26.png\" alt=\"hive\"><\/a><\/p>\n\n<p>but how to achive real time stream of data from Spark or Storm, for example <strong><em>Real-time fraud detection<\/em><\/strong><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-11-16 18:12:20.763 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-03-01 16:32:46.663 UTC",
        "Question_score":0,
        "Question_tags":"azure|hadoop|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":549,
        "Owner_creation_date":"2012-01-25 08:53:59.093 UTC",
        "Owner_last_access_date":"2022-09-23 09:28:05.37 UTC",
        "Owner_reputation":2923,
        "Owner_up_votes":875,
        "Owner_down_votes":5,
        "Owner_views":838,
        "Answer_body":"<p>To do real time Fraud detection typically you will create a Model on Azure ML, then publish that model to oWeb service, then on you Spark or Storm system you will call that Web service, in  sequence ( like payment happened on commercial sites for example), then you will get an immediate answer about the actual parameters you had sent in you web service call.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-11-25 13:19:15.593 UTC",
        "Answer_score":1.0,
        "Owner_location":"Poznan, Poland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/33741912",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47668450,
        "Question_title":"How to upload .r file into azure ml studio and run it?",
        "Question_body":"<p>I have a R file and I want to run the same in azureML studio. \nAfter running the codes in Rstudio I zip the r file and import it into Azure studio's datasets.I pull the dataset and Execute R script module to the experiment and attach script bundle port to the zip file. It asks for a src path which I am not sure of. When I run, it says CONNECTION NOT FOUND. <\/p>\n\n<p>What should be done to find the connection?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-12-06 06:48:57.367 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-12-06 08:12:17.873 UTC",
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":288,
        "Owner_creation_date":"2016-11-27 16:51:54.083 UTC",
        "Owner_last_access_date":"2022-08-17 08:26:10.093 UTC",
        "Owner_reputation":913,
        "Owner_up_votes":16,
        "Owner_down_votes":1,
        "Owner_views":318,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47668450",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42931155,
        "Question_title":"How do I transform a list of items into groups to predict group ratings in azure machine learning?",
        "Question_body":"<p>I'm newbie to azure machine learning and I'm trying to build a model that rates groups of items.<\/p>\n\n<p>My data is a file with a list of items with features (small list - less than 80 items) and I need to make groups (of diferent sizes - groups of 2, 3, 4,... 10 items, for all the possible combinations) so that the model rate those groups (rates from 1 to 10). I also have some group rates to train the model.<\/p>\n\n<p>I don't know how to transform the items into groups. <\/p>\n\n<p>Another thing is, I'm not sure which model is the best. From all I gather, I think that a multiclass classification is the most suitable for this problem. Is it?<\/p>\n\n<p>Thank you in advance and sorry for any grammar error in my text. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-03-21 15:17:36.7 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":32,
        "Owner_creation_date":"2017-03-21 15:13:53.573 UTC",
        "Owner_last_access_date":"2017-04-18 11:52:40.78 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42931155",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63306816,
        "Question_title":"Use a Dask Cluster in a PythonScriptStep",
        "Question_body":"<p>Is it possible to have a multi-node Dask cluster be the compute for a <code>PythonScriptStep<\/code> with AML Pipelines?<\/p>\n<p>We have a <code>PythonScriptStep<\/code> that uses <code>featuretools<\/code>'s, deep feature synthesis (<code>dfs<\/code>) (<a href=\"https:\/\/docs.featuretools.com\/en\/stable\/generated\/featuretools.dfs.html\" rel=\"nofollow noreferrer\">docs<\/a>). <code>ft.dfs()<\/code> has a param, <code>n_jobs<\/code> which allows for parallelization. When we run on a single machine, the job takes three hours, and runs much faster on a Dask. How can I operationalize this within an Azure ML pipeline?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-07 17:43:21.793 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"dask|azure-machine-learning-service",
        "Question_view_count":362,
        "Owner_creation_date":"2014-07-15 20:45:20.427 UTC",
        "Owner_last_access_date":"2022-09-23 15:42:13.1 UTC",
        "Owner_reputation":3359,
        "Owner_up_votes":1187,
        "Owner_down_votes":14,
        "Owner_views":555,
        "Answer_body":"<p>We've been working and recently released a <code>dask_cloudprovider.AzureMLCluster<\/code> that might be of interest to you: <a href=\"https:\/\/github.com\/dask\/dask-cloudprovider\" rel=\"noreferrer\">link to repo<\/a>. You can install it via <code>pip install dask-cloudprovider<\/code>.<\/p>\n<p>The <code>AzureMLCluster<\/code> instantiates Dask cluster on AzureML service with elasticity of scaling up to 100s of nodes should you require that. The only required parameter is the <code>Workspace<\/code> object, but you can pass your own <code>ComputeTarget<\/code> should you choose to.<\/p>\n<p>An example of how to use it you can <a href=\"https:\/\/github.com\/drabastomek\/GTC\/blob\/master\/SJ_2020\/workshop\/1_Setup\/Setup.ipynb\" rel=\"noreferrer\">found here<\/a>. In this example I use my custom GPU\/RAPIDS docker image but you can use any images within the <code>Environment<\/code> class.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-08-07 18:08:34.437 UTC",
        "Answer_score":6.0,
        "Owner_location":"Seattle, WA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63306816",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68843120,
        "Question_title":"AzureML pass data between pipeline without saving it",
        "Question_body":"<p>I have made two scripts using PythonScriptStep where data_prep.py prepares a dataset by doing some data transformation which is thereafter sent to train.py for training an ML model in AzureML.<\/p>\n<p>It is possible passing data between pipeline steps using PipelineData and OutputFileDatasetConfig, however these seem to save the data in azure blob.<\/p>\n<p>Q: How can I send the data between the steps <strong>without<\/strong> saving the data anywhere?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-19 06:39:43.933 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-pipelines|azure-machine-learning-service",
        "Question_view_count":100,
        "Owner_creation_date":"2021-08-19 06:33:39.277 UTC",
        "Owner_last_access_date":"2022-09-23 11:34:32.393 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68843120",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63617788,
        "Question_title":"How is Azure Machine Learning's average GpuUtilization metric computed?",
        "Question_body":"<p>How is the &quot;GpuUtilization&quot; metric computed for an Azure Machine Learning (AML) workspace? What are the inputs and what is the equation used to compute GpuUtilization?<\/p>\n<p>The &quot;metrics&quot; tab in the AML web portal shows a chart of the GpuUtilization over a specified time period, along with the average GpuUtilization for that time period. However, I have found that average GpuUtilization does not appear to accurately reflect the data shown in the chart for some of my organization's AML workspaces.<\/p>\n<p>For example, the following screenshot shows the GpuUtilization for July 1-31, with the average GpuUtilization reported as 54.06. This is clearly much higher than what is shown in the chart. When I download the data from the chart (Share -&gt; Download to Excel), I compute the average GpuUtilization to be ~11% in Excel. Why is there such a discrepancy?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/igqST.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/igqST.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I have found similar discrepancies for other AML workspaces as well. However, the average GpuUtilization appears to be more accurate for the August 1-25 time period than it is for July 1-31. I wish to better understand how AML computes the average GpuUtilization over a time period so we can accurately account for my organization's AML GPU usage on a per-workspace basis.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-27 14:06:04.793 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":126,
        "Owner_creation_date":"2013-05-29 21:42:57.597 UTC",
        "Owner_last_access_date":"2022-05-20 21:27:31.763 UTC",
        "Owner_reputation":335,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":23,
        "Answer_body":"<p>The 54.06 is likely the average over time when GPU VM was allocated. If the VM gets deallocated, the Azure Monitor gets no data. These missing values get interpolated as zeros on the chart.<\/p>\n<p>To get a better estimate of utilization, you could check when the VM was stopped, and exclude that time interval from the average.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-08-28 15:05:14.363 UTC",
        "Answer_score":0.0,
        "Owner_location":"Cambridge, MA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63617788",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57960177,
        "Question_title":"issue with the datadrift notebook",
        "Question_body":"<p>when running this <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/monitor-models\/data-drift\/azure-ml-datadrift.ipynb\" rel=\"nofollow noreferrer\">Data Drift sample notebook<\/a>, I'm having issues running a particular cell :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>exp = Experiment(ws, datadrift._id)\ndd_run = Run(experiment=exp, run_id=run)\nRunDetails(dd_run).show()\n<\/code><\/pre>\n\n<p>This generates the following traceback : <\/p>\n\n<pre><code>(...)\nImportError: cannot import name 'get_run_ids_and_metric_types_filter_expression'\n<\/code><\/pre>\n\n<p>I believe there might be a version issue with this notebook. I'm running AzureML SDK 1.0.60, and this sample is drawn from the 1.0.60 version of the notebook (at least the one in the master branch as of today)<\/p>\n\n<p>Or is this an issue with my environment?<\/p>\n\n<p>I also realized, by inspecting the output logs of the run that I'm getting a traceback on the job itself :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>The experiment failed. Finalizing run...\nTraceback (most recent call last):\n  File \"datadrift_run.py\", line 173, in &lt;module&gt;\n    run.run(target_date)\n  File \"datadrift_run.py\", line 100, in run\n    drift_main(arguments_drift)\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/playground-olivier\/azureml\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/mounts\/workspacefilestore\/azureml\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/_generate_script.py\", line 363, in main\n    'datadrift_id': args.datadrift_id\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/playground-olivier\/azureml\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/mounts\/workspacefilestore\/azureml\/13f371b5-1985-44c2-921c-fd66b0dbe852_1568646629244\/_generate_script.py\", line 75, in _get_drift_metrics\n    diff_metrics = dsdo.run()\n  File \"\/azureml-envs\/azureml_9a12ab39ef186b06eb543bbc347567d8\/lib\/python3.6\/site-packages\/azureml\/data\/_dataset_diff.py\", line 840, in run\n    base_profile_metrics = get_dataprofile_metrics(self.base_datasetprofile, self.config)\n  File \"\/azureml-envs\/azureml_9a12ab39ef186b06eb543bbc347567d8\/lib\/python3.6\/site-packages\/azureml\/data\/_dataset_diff.py\", line 163, in get_dataprofile_metrics\n    column_type = column_type_classifier[(dp.columns[c].value_counts is None, dp.columns[c].histogram is None)]\nKeyError: 'usaf'\n<\/code><\/pre>\n\n<p>These two are unrelated but generated by the same notebook.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_date":"2019-09-16 15:34:13.33 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-09-16 15:43:39.143 UTC",
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":103,
        "Owner_creation_date":"2018-09-30 02:52:40.603 UTC",
        "Owner_last_access_date":"2022-07-22 02:57:21.83 UTC",
        "Owner_reputation":381,
        "Owner_up_votes":75,
        "Owner_down_votes":2,
        "Owner_views":50,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Montreal, QC, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57960177",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65769868,
        "Question_title":"Where does the Azure Machine ACI Webservice deploy?",
        "Question_body":"<p>When we deploy a model as an ACIWebService in Azure Machine Learning Service, we do not need to specify any <code>deployment_target<\/code>.<\/p>\n<p>According to the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config-none--deployment-config-none--deployment-target-none--overwrite-false-\" rel=\"nofollow noreferrer\">AzureML documentation<\/a> for <code>azureml.core.model.model<\/code> class,<\/p>\n<pre><code>deployment_target\nComputeTarget\ndefault value: None\nA ComputeTarget to deploy the Webservice to. As Azure Container Instances has no associated ComputeTarget, leave this parameter as None to deploy to Azure Container Instances.\n<\/code><\/pre>\n<p>What does Microsoft mean by<\/p>\n<blockquote>\n<p>As Azure Container Instances has no associated ComputeTarget<\/p>\n<\/blockquote>\n<p>In which &quot;Compute Target&quot; is an ACIWebService deployed?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-18 06:40:43.25 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service|azure-container-instances",
        "Question_view_count":317,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/container-instances\/container-instances-overview\" rel=\"nofollow noreferrer\">Azure Container Instances<\/a> itself is the compute platform. It spins up a container in a serverless-fashion.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-01-18 08:30:55.96 UTC",
        "Answer_score":3.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65769868",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68354159,
        "Question_title":"`pipeline_job` registered model input",
        "Question_body":"<p>I'm using the pipeline private preview from CLI (v2).<\/p>\n<p>I'd like to know how to use a registered model as an input of my pipeline.<\/p>\n<p>Similarly to how I access the blob storage:<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>inputs:\n  input_data:\n    data:\n      datastore: azureml:dualcam\n      path: \/image-20210701*\n<\/code><\/pre>\n<p>I'm expecting to be able to use my registered model but I can find the schema to add it.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-07-12 21:40:44.697 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":29,
        "Owner_creation_date":"2012-01-26 14:27:40.553 UTC",
        "Owner_last_access_date":"2022-09-24 16:26:41.58 UTC",
        "Owner_reputation":802,
        "Owner_up_votes":288,
        "Owner_down_votes":0,
        "Owner_views":91,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68354159",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64486262,
        "Question_title":"Is there a way to un-register an environment in Azure ML studio",
        "Question_body":"<p>I am trying to deploy a model in Azure ML and kept on getting the error 'model not found' from my score.py. So I decided to start from scratch again. I had my custom environment registered, and the Azure ML API for Environment class doesn't seem to have anything like 'delete' or 'unregister'. is there a way to work around this? Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-22 16:12:00.473 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-11-01 23:56:25.247 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":424,
        "Owner_creation_date":"2020-07-19 00:31:40.083 UTC",
        "Owner_last_access_date":"2021-08-19 14:16:52.393 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>You can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py&amp;preserve-view=true#delete--\" rel=\"nofollow noreferrer\">delete<\/a> method in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py\" rel=\"nofollow noreferrer\">Model<\/a> class to delete a registered model.<\/p>\n<p>This can also be done via the Azure CLI as:<\/p>\n<pre><code>az ml model delete &lt;model id&gt;\n<\/code><\/pre>\n<p>Other commands can be found here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/model?view=azure-cli-latest\" rel=\"nofollow noreferrer\">az ml model<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-31 13:34:49.467 UTC",
        "Answer_score":0.0,
        "Owner_location":"Toronto, ON, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64486262",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35973168,
        "Question_title":"How could I save dataset from ipython notebook in Azure ML Studio?",
        "Question_body":"<p>I use next command to save output results:<\/p>\n\n<pre><code>ws.datasets.add_from_dataframe(data, 'GenericCSV', 'output.csv', 'Uotput results')\n<\/code><\/pre>\n\n<p>where <code>ws<\/code> is <code>azureml.Workspace<\/code> object and <code>data<\/code> is <code>pandas.DataFrame<\/code>.<\/p>\n\n<p>It works fine if my dataset size less than 4 mb. Otherwise I got a error:<\/p>\n\n<pre><code>AzureMLHttpError: Maximum request length exceeded.\n<\/code><\/pre>\n\n<p>As I understood this is the error raised by Azure environment limits and the maximum size of the dataset could not be changed. <\/p>\n\n<p>I could split my dataset to 4 mb parts and download them from Azure ML studio, but it is very inconvinient if size of my output dataset is more than 400 mb.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":3,
        "Question_creation_date":"2016-03-13 17:11:27.747 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-03-14 13:57:35.453 UTC",
        "Question_score":4,
        "Question_tags":"python|azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":3128,
        "Owner_creation_date":"2016-01-10 11:51:15.697 UTC",
        "Owner_last_access_date":"2021-03-17 10:54:36.293 UTC",
        "Owner_reputation":77,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":"<p>I have read the source code in the python package <strong>azureml<\/strong>, and found out that they are using a simple request post when uploading a dataset, which has a limited content length 4194304 bytes.<\/p>\n\n<p>I tried to modify the code inside \"http.py\" within the python package <strong>azureml<\/strong>. I posted the request with a chunked data, and I got the following error:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \".\\azuremltest.py\", line 10, in &lt;module&gt;\n    ws.datasets.add_from_dataframe(frame, 'GenericCSV', 'output2.csv', 'Uotput results')\n  File \"C:\\Python34\\lib\\site-packages\\azureml\\__init__.py\", line 507, in add_from_dataframe\n    return self._upload(raw_data, data_type_id, name, description)\n  File \"C:\\Python34\\lib\\site-packages\\azureml\\__init__.py\", line 550, in _upload\nraw_data, None)\n  File \"C:\\Python34\\lib\\site-packages\\azureml\\http.py\", line 135, in upload_dataset\n    upload_result = self._send_post_req(api_path, raw_data)\n  File \"C:\\Python34\\lib\\site-packages\\azureml\\http.py\", line 197, in _send_post_req\n    raise AzureMLHttpError(response.text, response.status_code)\nazureml.errors.AzureMLHttpError: Chunked transfer encoding is not permitted. Upload size must be indicated in the Content-Length header.\nRequest ID: 7b692d82-845c-4106-b8ec-896a91ecdf2d 2016-03-14 04:32:55Z\n<\/code><\/pre>\n\n<p>The REST API in <strong>azureml<\/strong> package does not support chunked transfer encoding. Hence, I took a look at how the Azure ML studio implements this, and I found out this:<\/p>\n\n<ol>\n<li><p>It post a request with content-length=0 to <code>https:\/\/studioapi.azureml.net\/api\/resourceuploads\/workspaces\/&lt;workspace_id&gt;\/?userStorage=true&amp;dataTypeId=GenericCSV<\/code>, which will return an id in the response body.<\/p><\/li>\n<li><p>Break the .csv file into chunks less than 4194304 bytes, and post them to <code>https:\/\/studioapi.azureml.net\/api\/blobuploads\/workspaces\/&lt;workspace_id&gt;\/?numberOfBlocks=&lt;the number of chunks&gt;&amp;blockId=&lt;index of chunk&gt;&amp;uploadId=&lt;the id you get from previous request&gt;&amp;dataTypeId=GenericCSV<\/code><\/p><\/li>\n<\/ol>\n\n<p>If you really want this functionality, you can implement it with python and the above REST API.<\/p>\n\n<p>If you think it's too complicated, report the issue to <a href=\"https:\/\/github.com\/Azure\/Azure-MachineLearning-ClientLibrary-Python\/issues\" rel=\"nofollow\">this<\/a>. The <strong>azureml<\/strong> python package is still under development, so your suggestion would be very helpful for them.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2016-03-14 06:01:52.407 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2016-03-14 07:04:27.983 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35973168",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61789949,
        "Question_title":"Epoch time increasing when running Pytorch on AML docker",
        "Question_body":"<p>The epoch time keeps increasing when running Pytorch training on AML and a custom docker image.\nWhen the same code is running locally the epoch time is constant (the difference here is that there is no docker image involved and the training dataset exists locally, so not a mounted blob storage by AML and the machine is different)<\/p>\n\n<p>Any suggestions on how I can figure out what's happening?\nFor example how can I log useful memory consumption? GPU, Pytorch, disk access, etc.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-14 05:29:34.053 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-05-14 14:31:52.97 UTC",
        "Question_score":0,
        "Question_tags":"docker|machine-learning|pytorch|azure-machine-learning-service",
        "Question_view_count":35,
        "Owner_creation_date":"2018-03-01 09:03:25.313 UTC",
        "Owner_last_access_date":"2022-03-13 07:26:26.35 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61789949",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66670673,
        "Question_title":"Selecting a model by name using Webservice.list on AzureML",
        "Question_body":"<p>I deployed a huggingface ML model on Azure and now I'm trying to select it using the Python SDK.<\/p>\n<p>I'm trying this:<\/p>\n<pre><code>from azureml.core import Workspace, Webservice\nmlw = Workspace.from_config(&quot;mlw.json&quot;)\nservices = Webservice.list(mlw)\nservices_filtered = Webservice.list(mlw, model_name=services[0].name)\n<\/code><\/pre>\n<p>Now, <code>services<\/code> is a list containing two models, but <code>services_filtered<\/code> is an empty list. What am I doing wrong here?<\/p>\n<p>Of course, I could select the right one afterwards using the names, but that just doesn't seem right.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-17 09:53:36.863 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-03-17 10:21:40.667 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|api|azure-machine-learning-service",
        "Question_view_count":30,
        "Owner_creation_date":"2012-05-28 21:32:39.273 UTC",
        "Owner_last_access_date":"2022-09-16 10:18:21.743 UTC",
        "Owner_reputation":2449,
        "Owner_up_votes":420,
        "Owner_down_votes":7,
        "Owner_views":253,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Utrecht",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66670673",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37250368,
        "Question_title":"How to delete web service in AzureML with mystery endpoint",
        "Question_body":"<p>I have an AzureML free account in South Central US. At some point I set up a web service, which I no longer need. I also suspect it's blocking my other web services as I'm getting 503 errors whenever I try to use them.<\/p>\n\n<p>When I try to delete the web service it gives the error message:\n<code>Cannot delete web service \"azuremlweb\" because one or more additional endpoints were created for it. These endpoints must be deleted before you can delete the web service.<\/code><\/p>\n\n<p>I didn't intentionally set up any extra endpoints and when trying to follow the instructions <a href=\"https:\/\/azure.microsoft.com\/en-gb\/documentation\/articles\/machine-learning-manage-workspace\/\" rel=\"nofollow noreferrer\">on this doc page<\/a> I couldn't see any endpoints listed that I can remove.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/n5Kg2.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/n5Kg2.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The only unusual thing I can think of about the service was that it had multiple inputs.<\/p>\n\n<p>I've more or less deleted everything in the workspace now: experiments, other web services, but it still won't go. Any thoughts?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-16 09:11:34.77 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1550,
        "Owner_creation_date":"2013-07-23 10:49:49.267 UTC",
        "Owner_last_access_date":"2021-05-27 22:59:00.507 UTC",
        "Owner_reputation":635,
        "Owner_up_votes":27,
        "Owner_down_votes":1,
        "Owner_views":48,
        "Answer_body":"<p>You can try to use Azure ML PowerShell module to discover and delete web service endpoints, and web service.<\/p>\n\n<p><a href=\"http:\/\/aka.ms\/amlps\" rel=\"nofollow\">http:\/\/aka.ms\/amlps<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2016-05-16 14:08:37.73 UTC",
        "Answer_score":3.0,
        "Owner_location":"UK",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37250368",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73440722,
        "Question_title":"Azure AutoML with historical data context forecast",
        "Question_body":"<p>I have a question about the peculiar behaviour of Azure AutoML when using forecasting with historical data context.<\/p>\n<p>Basically, I want to apply this usecase from the documentation (<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-forecast-function\/auto-ml-forecasting-function.ipynb\" rel=\"nofollow noreferrer\">documentation<\/a>)<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Qz6pW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Qz6pW.png\" alt=\"Automl usecase\" \/><\/a><\/p>\n<p>The idea is to train a model with historical data (imagine, 3 months of historical data) and then feed the model the current prediction context (for example, the last two weeks) in order to predict a certain prediction horizon.<\/p>\n<p>According to the documentation, to train the model with historical data,  need to do something like this for configuration:<\/p>\n<pre><code>    forecasting_parameters = ForecastingParameters(time_column_name='Timestamp', \n                                               target_aggregation_function = &quot;mean&quot;,\n                                               freq='H',\n                                               forecast_horizon = prediction_horizon_hours,\n                                               target_lags = 'auto',\n                                               )\n\n    label = signalTags\n\nautoml_config = AutoMLConfig(task='forecasting',\n                             primary_metric='normalized_root_mean_squared_error',\n                             experiment_timeout_minutes=30,\n                             blocked_models=[&quot;AutoArima&quot;],\n                             enable_early_stopping=True,\n                             training_data=Data,\n                             label_column_name=label,\n                             n_cross_validations=3,\n                             enable_ensembling=False,\n                             verbosity=logging.INFO,\n                             forecasting_parameters = forecasting_parameters)\n<\/code><\/pre>\n<p>After training, in order to perform a predictiton I need to feed the &quot;context&quot; according to what I want to predict in the form of a dataframe (where the values for the target column are filled in in case of the context and empty in case of values I want to predict) and then just call forecast. Something like this:<\/p>\n<pre><code>     Timestamp                               Signal\n0    2022-08-07T23:00:00Z                     63.16\n1    2022-08-08T00:00:00Z                     62.92\n2    2022-08-08T01:00:00Z                     62.89\n3    2022-08-08T02:00:00Z                     62.79\n4    2022-08-08T03:00:00Z                     62.75\n..                    ...                       ...\n233  2022-08-23T17:00:00Z                       nan\n234  2022-08-23T18:00:00Z                       nan\n235  2022-08-23T19:00:00Z                       nan\n236  2022-08-23T20:00:00Z                       nan\n237  2022-08-23T21:00:00Z                       nan\n<\/code><\/pre>\n<p>After all this context (pun intended) here is the question\/problem.<\/p>\n<p>When I use the above dataframe to forecast ahead I get an error that mentions the following:<\/p>\n<pre><code>ForecastingConfigException:\n    Message: Expected column(s) target value column not found in y_pred.\n    InnerException: None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Expected column(s) target value column not found in y_pred.&quot;,\n        &quot;target&quot;: &quot;y_pred&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;BadArgument&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;MissingColumnsInData&quot;\n            }\n        },\n        &quot;reference_code&quot;: &quot;ac316505-87e4-4877-a855-65a24c3a796b&quot;\n    }\n}\n<\/code><\/pre>\n<p>However, if I feed a slightly different dataframe (where the data to be forecasted has any other time except exactly on the hour, i.e. 10h30,11h01, 10h23 etc.) it works normally. If I give it something like this:<\/p>\n<pre><code> Timestamp                               Signal\n0    2022-08-07T23:00:00Z                     63.16\n1    2022-08-08T00:00:00Z                     62.92\n2    2022-08-08T01:00:00Z                     62.89\n3    2022-08-08T02:00:00Z                     62.79\n4    2022-08-08T03:00:00Z                     62.75\n..                    ...                       ...\n233  2022-08-23T17:00:01Z                       nan\n234  2022-08-23T18:00:01Z                       nan\n235  2022-08-23T19:00:01Z                       nan\n236  2022-08-23T20:00:01Z                       nan\n237  2022-08-23T21:00:01Z                       nan\n<\/code><\/pre>\n<p>It outputs good results. What gives?<\/p>\n<p>I have tried resetting the index of the dataframe, replace None with nan but nothing seems to work. Azure Automl can predict any date except ones that are on the hour.<\/p>\n<p>What can I do to fix this?<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-22 05:55:51.903 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|automl|azuremlsdk",
        "Question_view_count":30,
        "Owner_creation_date":"2018-01-15 18:38:26.383 UTC",
        "Owner_last_access_date":"2022-09-23 08:46:06.34 UTC",
        "Owner_reputation":43,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73440722",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":29283841,
        "Question_title":"Grant Azure Machine Learning access to SQL Server on Virtual Machine with ACL",
        "Question_body":"<p>We are in the process of setting up Azure Machine Learning within our Azure instance. Our SQL Server sits on a virtual machine and access is restricted using ACL's  <\/p>\n\n<p>We have looked extensively for a virtual IP or an IP within Machine Learning to add to the ACL but we cannot find it. <\/p>\n\n<p>We have tested access by entering 0.0.0.0\/0 to our ACL which allows access to ML  but obviously this isnt secure and not something that we wish to continue with. <\/p>\n\n<p>Thanks in advance. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2015-03-26 16:27:41.24 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"sql-server|azure|machine-learning|acl|azure-machine-learning-studio",
        "Question_view_count":229,
        "Owner_creation_date":"2013-08-01 14:06:45.447 UTC",
        "Owner_last_access_date":"2021-07-15 12:17:15.727 UTC",
        "Owner_reputation":151,
        "Owner_up_votes":25,
        "Owner_down_votes":2,
        "Owner_views":39,
        "Answer_body":"<p>Azure public IP address are published and refreshed at regular intervals it can be found here: <a href=\"http:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=41653\" rel=\"nofollow\">http:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=41653<\/a><\/p>\n\n<p>You can use these to specify the restricted IP range for access<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2015-03-30 22:14:48.88 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29283841",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65362041,
        "Question_title":"Pick up Results From ML Studio Pipeline in Data Factory Pipeline",
        "Question_body":"<p>We currently have a Data Factory pipeline that is able to call one of our ML Studio Pipelines successfully.  After the ML Studio Pipeline completed, we wanted Azure Data Factory to pick up the results of the ML Studio Pipeline and store the results in SQL Server.<\/p>\n<p>We found the PipelineData class stores the results in a folder in blob based on the child run id, which makes it hard for Data factory to pick up the results.  We then discovered OutputFileDatasetConfig which allows ML Studio to save the results to a static location for Data Factory.  This worked great for Data Factory except OutputFileDatasetConfig doesn't always work :( since it's experimental class.  It took us a while to figure this out and we even created a stackoverflow question for this, which we resolved, and can be found here:  <a href=\"https:\/\/stackoverflow.com\/questions\/65240603\/azure-ml-studio-ml-pipeline-exception-no-temp-file-found\/65350106#65350106\">Azure ML Studio ML Pipeline - Exception: No temp file found<\/a><\/p>\n<p>We returned to using PipelineData class which stores the results in a folder in blob based on the child run id, but we can't figure out how to get Data factory to find the blob based on the child run id of the ML Studio Pipeline it just ran.<\/p>\n<p><strong>So my question is, how do you get Data Factory to pick up the results of a ML Studio Pipeline which was triggered from a Data Factory Pipeline???<\/strong><\/p>\n<p>Here is a simple visual of the Data Factory pipeline we're trying to build.<\/p>\n<pre><code>Step 1: Store Data in azure file store --&gt;\nStep 2: Run ML Studio scoring Pipeline --&gt;\nStep 3: Copy Results to SQL Server\n<\/code><\/pre>\n<p>Step 3 is the step we can't figure out.  Any help would be greatly appreciated.  Thanks and happy coding!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-18 18:16:58.553 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-data-factory|azure-data-factory-2|azure-machine-learning-service|ml-studio|azureml-python-sdk",
        "Question_view_count":281,
        "Owner_creation_date":"2018-06-10 03:57:32.363 UTC",
        "Owner_last_access_date":"2022-09-23 22:17:15.213 UTC",
        "Owner_reputation":247,
        "Owner_up_votes":637,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65362041",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70831378,
        "Question_title":"Azure Machine Learning compute instance : Static IP address?",
        "Question_body":"<p>I have a SQL Server database which is accessible only by whitelisting IP addresses. I would like to use an Azure Machine Learning compute instance to run some python code to query the database using the <code>pyodbc<\/code> library.<\/p>\n<p>Does a compute instance in Azure Machine Learning have a static IP address ?\nIf yes, can I safely provide this address to be whitelisted or is there a risk that it might change through time ?<\/p>\n<p>Thank you very much.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-24 09:10:26.183 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|machine-learning|static-ip-address|azure-machine-learning-service",
        "Question_view_count":139,
        "Owner_creation_date":"2020-04-10 11:23:52.39 UTC",
        "Owner_last_access_date":"2022-08-12 18:19:53.33 UTC",
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70831378",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67570921,
        "Question_title":"score\/entry file for azure machine learning web services using azuremlsdk",
        "Question_body":"<p>Looking at <a href=\"https:\/\/github.com\/Azure\/azureml-sdk-for-r\/blob\/master\/samples\/deployment\/deploy-to-aci\/deploy-to-aci.R\" rel=\"nofollow noreferrer\">this example<\/a>:<\/p>\n<pre><code>library(azuremlsdk)\nlibrary(jsonlite)\n\nws &lt;- load_workspace_from_config()\n\n# Register the model\nmodel &lt;- register_model(ws, model_path = &quot;model.rds&quot;, model_name = &quot;model.rds&quot;)\n\n# Create environment\nr_env &lt;- r_environment(name = &quot;r_env&quot;)\n\n# Create inference config\ninference_config &lt;- inference_config(\n  entry_script = &quot;score.R&quot;,\n  source_directory = &quot;.&quot;,\n  environment = r_env)\n\n# Create ACI deployment config\ndeployment_config &lt;- aci_webservice_deployment_config(cpu_cores = 1,\n                                                      memory_gb = 1)\n\n# Deploy the web service\nservice_name &lt;- paste0('aciwebservice-', sample(1:100, 1, replace=TRUE))\nservice &lt;- deploy_model(ws, \n                        service_name, \n                        list(model), \n                        inference_config, \n                        deployment_config)\nwait_for_deployment(service, show_output = TRUE)\n<\/code><\/pre>\n<p>Could it be that score.R has to be uploaded to the Azure environment and is not local as in the sense that it is on the dev machine? My current thinking is, that source_directory . refers to the local system (i.e. on the dev machine)?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-17 13:44:07.413 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":50,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Somewhere",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67570921",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64819708,
        "Question_title":"Register Azure ML Model from DatabricksStep",
        "Question_body":"<p>I'm calculating a model while executing a DatabricksStep in an Azure ML Pipeline, save it on my Blob Storage as .pkl file and upload it to the current Azure ML Run using Run.upload_file (). All this works without any problems.<\/p>\n<p>But as soon as I try to register the model to the Azure ML Workspace using Run.register_model (), the script throws the following error:<\/p>\n<p>UserErrorException: UserErrorException:\nMessage:\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:<\/p>\n<ol>\n<li>You are not authorized to access this resource, or directory listing denied.<\/li>\n<li>you may not login your azure service, or use other subscription, you can check your\ndefault account by running azure cli commend:\n'az account list -o table'.<\/li>\n<li>You have multiple objects\/login session opened, please close all session and try again.<\/li>\n<\/ol>\n<p>InnerException None\nErrorResponse\n{\n&quot;error&quot;: {\n&quot;code&quot;: &quot;UserError&quot;,\n&quot;message&quot;: &quot;\\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\\n1. You are not authorized to access this resource, or directory listing denied.\\n2. you may not login your azure service, or use other subscription, you can check your\\ndefault account by running azure cli commend:\\n'az account list -o table'.\\n3. You have multiple objects\/login session opened, please close all session and try again.\\n                &quot;\n}\n}<\/p>\n<p>with the following call stack<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/models_client.py in register_model(self, name, tags, properties, description, url, mime_type, framework, framework_version, unpack, experiment_name, run_id, datasets, sample_input_data, sample_output_data, resource_requirements)\n70         return self.<br \/>\n71             _execute_with_workspace_arguments(self._client.ml_models.register, model,\n---&gt; 72                                               custom_headers=ModelsClient.get_modelmanagement_custom_headers())\n73\n74     @error_with_model_id_handling<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/workspace_client.py in _execute_with_workspace_arguments(self, func, *args, **kwargs)\n65\n66     def _execute_with_workspace_arguments(self, func, *args, **kwargs):\n---&gt; 67         return self._execute_with_arguments(func, copy.deepcopy(self._workspace_arguments), *args, **kwargs)\n68\n69     def get_or_create_experiment(self, experiment_name, is_async=False):<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)\n536                 return self._call_paginated_api(func, *args_list, **kwargs)\n537             else:\n--&gt; 538                 return self._call_api(func, *args_list, **kwargs)\n539         except ErrorResponseException as e:\n540             raise ServiceException(e)<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, *args, **kwargs)\n234                 return AsyncTask(future, _ident=ident, _parent_logger=self._logger)\n235             else:\n--&gt; 236                 return self._execute_with_base_arguments(func, *args, **kwargs)\n237\n238     def _call_paginated_api(self, func, *args, **kwargs):<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, *args, **kwargs)\n323         total_retry = 0 if self.retries &lt; 0 else self.retries\n324         return ClientBase._execute_func_internal(\n--&gt; 325             back_off, total_retry, self._logger, func, _noop_reset, *args, **kwargs)\n326\n327     @classmethod<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n343                 return func(*args, **kwargs)\n344             except Exception as error:\n--&gt; 345                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n346\n347             reset_func(*args, **kwargs)  # reset_func is expected to undo any side effects from a failed func call.<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n384 3. You have multiple objects\/login session opened, please close all session and try again.\n385                 &quot;&quot;&quot;\n--&gt; 386                 raise_from(UserErrorException(error_msg), error)\n387\n388             elif error.response.status_code == 429:<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/six.py in raise_from(value, from_value)<\/p>\n<p>Did anybody experience the same error and knows what is its cause and how to solve it?<\/p>\n<p>Best,\nJonas<\/p>\n<p>UPDATE:<\/p>\n<pre><code> model = sklearn.linear_model.LinearRegression ( )\n model_path = &quot;&lt;path to 'model.pkl' in my blob storage&gt;&quot;\n joblib.dump(model, model_path)\n aml_run = azureml.core.get_context ( )\n aml_run.upload_file (name = &quot;model.pkl&quot;, path_or_stream = model_path)\n # Until this point, everything works fine\n    \n aml_run.register_model (model_name = &quot;model.pkl&quot;)\n # This throws the posted &quot;Forbidden&quot;-Error\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-11-13 10:58:44.633 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-11-16 07:57:08.203 UTC",
        "Question_score":2,
        "Question_tags":"azure-databricks|azure-machine-learning-studio",
        "Question_view_count":620,
        "Owner_creation_date":"2020-07-16 05:39:33.727 UTC",
        "Owner_last_access_date":"2022-01-24 09:55:29.407 UTC",
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64819708",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70010018,
        "Question_title":"Read MobileNetSSd model files from azure ML Registered Models",
        "Question_body":"<p>1<\/p>\n<p>I have a pre-trained <code>MobileNetSSd.caffemodelmodel<\/code> and <code>MobileNetSSd.prototxt<\/code> files. Now I want to deploy these to Azure ML in a pipeline<\/p>\n<p>first I tried to register both these models with the below code:<\/p>\n<pre><code>#Register the model\ncaffemodel = Model.register(model_path = &quot;mobilenet_ssd\/MobileNetSSD.caffemodel&quot;, #local path\n                       model_name = &quot;caffemodel&quot;,\n                       tags = {&quot;severity&quot;: &quot;1&quot;},\n                       description = &quot;object detection caffemodel&quot;,\n                       workspace = ws)\n\nprototxt = Model.register(model_path = &quot;mobilenet_ssd\/MobileNetSSD.prototxt&quot;,  \n                       model_name = &quot;prototxt&quot;,\n                       tags = {&quot;severity&quot;: &quot;1&quot;},\n                       description = &quot;object detection prototxt&quot;,\n                       workspace = ws)\n<\/code><\/pre>\n<p>files are registered successfully and visible under the <code>Home\/Models<\/code> directory<\/p>\n<p>Now I need to read these models, but I am not able to read them.<\/p>\n<p>I tried with the below code, but it gives me an error as mentioned below:<\/p>\n<pre><code>from azureml.core.model import Model\n\nglobal caffemodel\nglobal prototxt\ncaffemodel = Model.get_model_path('caffemodel')\nprototxt = Model.get_model_path('prototxt')\n<\/code><\/pre>\n<p>#Error:<\/p>\n<pre><code>    826         # Probing azureml-models\/&lt;name&gt;\n    827         if not os.path.exists(candidate_model_path):\n--&gt; 828             return Model._get_model_path_local_from_root(model_name)\n    829         else:\n    830             # Probing azureml-models\/&lt;name&gt; exists, probing version\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/model.py in _get_model_path_local_from_root(model_name)\n    870         raise ModelNotFoundException(&quot;Model {} not found in cache at {} or in current working directory {}. &quot;\n    871                                      &quot;For more info, set logging level to DEBUG.&quot;.format(model_name, MODELS_DIR,\n--&gt; 872                                                                                          os.getcwd()))\n    873 \n    874     @staticmethod\n\nModelNotFoundException: ModelNotFoundException:\n    Message: Model caffemodel not found in cache at azureml-models or in current working directory \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/jsing2091\/code\/Users\/jsing209\/Computer_Vision\/Realtime_People_Counting. For more info, set logging level to DEBUG.\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Model caffemodel not found in cache at azureml-models or in current working directory \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/jsing2091\/code\/Users\/jsing209\/Computer_Vision\/Realtime_People_Counting. For more info, set logging level to DEBUG.&quot;\n    }\n}\n<\/code><\/pre>\n<p>I am not sure why it is not able to find the model...\nI am a bit lost, If anybody can help me read these models, I would appreciate it<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-17 18:52:40.577 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|single-shot-detector",
        "Question_view_count":46,
        "Owner_creation_date":"2016-09-14 06:56:22.757 UTC",
        "Owner_last_access_date":"2022-09-23 16:27:52.133 UTC",
        "Owner_reputation":628,
        "Owner_up_votes":27,
        "Owner_down_votes":1,
        "Owner_views":30,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Pune, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70010018",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58500807,
        "Question_title":"Run failed: User program failed with ModuleNotFoundError: No module named 'amlrun' in Azure ML Experiment",
        "Question_body":"<p>I'm using VS Code to submit a Machine Learning experiment in Azure Portal. When running the experiment I'm obtaining the following error:<\/p>\n\n<p>Run failed: User program failed with ModuleNotFoundError: No module named 'amlrun'<\/p>\n\n<p>This is the code structure:<\/p>\n\n<p>.vscode (json configuration file)<\/p>\n\n<p>aml_config<\/p>\n\n<p>scripts<\/p>\n\n<p>----- amlrun.py (a script with some functions)<\/p>\n\n<p>----- model_training.py (a script creating and saving the model)<\/p>\n\n<p>This is the configuration file:<\/p>\n\n<pre><code>{\n    \"script\": \"model_training.py\",\n    \"framework\": \"Python\",\n    \"communicator\": \"None\",\n    \"target\": \"testazure\",\n    \"environment\": {\n        \"python\": {\n            \"userManagedDependencies\": false,\n            \"condaDependencies\": {\n                \"dependencies\": [\n                    \"python=3.6.2\",\n                    \"scikit-learn\",\n                    \"numpy\",\n                    \"pandas\",\n                    {\n                        \"pip\": [\n                            \"azureml-defaults\"\n                        ]\n                    }\n                ]\n            }\n        },\n        \"docker\": {\n            \"baseImage\": \"mcr.microsoft.com\/azureml\/base:0.2.4\",\n            \"enabled\": true,\n            \"baseImageRegistry\": {\n                \"address\": null,\n                \"username\": null,\n                \"password\": null\n            }\n        }\n    },\n    \"history\": {\n        \"outputCollection\": true,\n        \"snapshotProject\": false,\n        \"directoriesToWatch\": [\n            \"logs\"\n        ]\n    }\n}\n<\/code><\/pre>\n\n<p>Am I missing something?\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-22 09:10:33.2 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":901,
        "Owner_creation_date":"2019-01-10 16:33:51.703 UTC",
        "Owner_last_access_date":"2020-12-14 18:08:49.513 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>When your training script is running in azure, it's not able to find all your local imports i.e. <code>amlrun.py<\/code> script. <\/p>\n\n<p>The submitted training job to azure builds a docker image with your files first and runs the experiment; but in this case the extension hasn't included <code>amlrun.py<\/code>. <\/p>\n\n<p>This is probably because when you have submit the training job with the extension, the visual studio code window opened is not pointing to be in <code>scripts<\/code> folder.<\/p>\n\n<p>Taken from one of the replies to a <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/24032\" rel=\"nofollow noreferrer\">previously raised github issue<\/a>:<\/p>\n\n<blockquote>\n  <p>The extension currently requires the script you are working on to be\n  in the folder that is open in VS Code and not in a sub-directory.<\/p>\n<\/blockquote>\n\n<hr>\n\n<p>To fix this you can do <strong>either<\/strong> of the following:<\/p>\n\n<ol>\n<li><p>You would need to re-open Visual Studio Code in <code>scripts<\/code> folder instead of parent directory.<\/p><\/li>\n<li><p>Move all files in <code>script<\/code> directory to be in it's parent directory.<\/p><\/li>\n<\/ol>\n\n<hr>\n\n<p>If you're looking for more flexible way to submit training jobs and managing aml - you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/intro?view=azure-ml-py\" rel=\"nofollow noreferrer\">azure machine learning sdk<\/a> for python.<\/p>\n\n<p>Some examples of using the SDK to manage expirements can be found in the links below:<\/p>\n\n<ol>\n<li><p><a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/service\/tutorial-train-models-with-aml.md\" rel=\"nofollow noreferrer\">Scikit Learn Model Training Docs<\/a> <\/p><\/li>\n<li><p><a href=\"https:\/\/github.com\/rithinch\/heartfulness-similar-content-service\" rel=\"nofollow noreferrer\">Basic Pytorch Model Training and Deployment Example Repo<\/a><\/p><\/li>\n<\/ol>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-10-23 13:25:18.727 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2019-10-23 13:46:12.44 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58500807",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68208679,
        "Question_title":"Run script locally with remote dataset on AzureML",
        "Question_body":"<p>I have a script that for development purposes I would like to run and debug locally. However, I do not want to store the data needed for my experiment on my local machine.<\/p>\n<p>I am using the <code>azureml<\/code> library with the Azure Machine Learning Studio. See my code below<\/p>\n<pre><code># General\nimport os\nimport argparse\n\n# Data analysis and wrangling\nimport pandas as pd\n\n# Machine learning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom azureml.core import Run\n\n# Get the environment of this run\nrun = Run.get_context()\n\nif __name__ == &quot;__main__&quot;:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--data_path',\n        type=str,\n        help='Path to the training data',\n        # The default path is on my local machine, however I would like to reference a remote datastore on Azure as a parameter to this script\n        default=os.path.join(os.getcwd(), 'data')\n    )\n    args = parser.parse_args()\n\n    # Obtain the data from the datastore\n    train_df = pd.read_csv(os.path.join(args.data_path, os.listdir(args.data_path)[0]))\n\n    # Drop unnecessary columns\n    train_df = train_df.drop(['Name', 'PassengerId', 'Ticket', 'Cabin'], axis=1)\n\n    # Encode non-numeric features as dummies\n    train_df = pd.get_dummies(train_df)\n\n    # Drop NA's\n    train_df.dropna(inplace=True)\n\n    # Use gridsearch CV to find the best parameters for the model\n    parameters = {'kernel': ('linear', 'rbf'),\n                  'C': [1, 10]}\n\n    # Initialize the grid search\n    search = GridSearchCV(SVC(), param_grid=parameters, cv=8)\n\n    # Train the model\n    search.fit(train_df.drop(&quot;Survived&quot;, axis=1), train_df[&quot;Survived&quot;])\n\n<\/code><\/pre>\n<p>Now, the script uses a local folder 'data'. However, I would like to give an argument to this script that indicates I would like to use a remote datastore in the Azure Machine Learning Studio. How could I achieve that?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-07-01 10:39:02.17 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":245,
        "Owner_creation_date":"2020-04-06 10:20:27.24 UTC",
        "Owner_last_access_date":"2022-09-23 14:24:39.773 UTC",
        "Owner_reputation":299,
        "Owner_up_votes":44,
        "Owner_down_votes":2,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68208679",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48560183,
        "Question_title":"how to predict more multiple values in azure ml?",
        "Question_body":"<p>I am creating Azure ML experienment to predict multiple values. but in azure ml we can not train a model to predict multiple values. my question is how to bring multiple trained models in single experienment and create webout put that gives me multiple prediction.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-02-01 10:13:16.49 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-02-07 09:27:38.06 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":666,
        "Owner_creation_date":"2018-02-01 09:59:53.607 UTC",
        "Owner_last_access_date":"2018-05-07 08:02:09.147 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48560183",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62701556,
        "Question_title":"Strange algorithm selection when using Azure AutoML with XBoostClassifier on categorial data",
        "Question_body":"<p>I have a data model consisting only of categorial features and a categorial label.<\/p>\n<p>So when I build that model manually in XGBoost, I would basically transform the features to binary columns (using LabelEncoder and OneHotEncoder), and the label into classes using LabelEncoder. I would then run a <strong>Multilabel Classification<\/strong> (multi:softmax).\nI tried that with my dataset and ended up with an accuracy around 0.4 (unfortunately can't share the dataset due to confidentiality)<\/p>\n<p>Now, if I run the same dataset in Azure AutoML, I end up with an accuracy around 0.85 in the best experiment. But what is really interesting is that the AutoML uses SparseNormalizer, XGBoostClassifier, with <strong>reg:logistic<\/strong> as objective.\nSo if I interpret this right, AzureML just normalizes the data (somehow from categorial data?) and then executes a logistic regression? Is this even possible \/ does this make sense with categorial data?<\/p>\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2020-07-02 17:05:08.303 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-03 08:58:58.543 UTC",
        "Question_score":3,
        "Question_tags":"xgboost|azure-machine-learning-service",
        "Question_view_count":281,
        "Owner_creation_date":"2018-08-20 09:07:42.257 UTC",
        "Owner_last_access_date":"2022-09-09 15:27:41.8 UTC",
        "Owner_reputation":87,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p><code>TL;DR<\/code> You're right that normalization doesn't make sense for training gradient-boosted decision trees (<code>GBDT<\/code>s) on categorical data, but it won't have an adverse impact. AutoML is an automated framework for modeling. In exchange for calibration control, you get ease-of-use. It is still worth verifying first that AutoML is receiving data with the columns properly encoded as categorical.<\/p>\n<p>Think of an AutoML model as effectively a <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.pipeline.Pipeline.html\" rel=\"nofollow noreferrer\">sklearn Pipeline<\/a>, which is a bundled set of pre-processing steps along with a predictive Estimator. AutoML will attempt to sample from a large swath of pre-configured Pipelines such that the most accurate Pipeline will be discovered. As <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-automated-ml#automatic-featurization-standard\" rel=\"nofollow noreferrer\">the docs<\/a> say:<\/p>\n<blockquote>\n<p>In every automated machine learning experiment, your data is automatically scaled or normalized to help algorithms perform well. During model training, one of the following scaling or normalization techniques will be applied to each model.<\/p>\n<\/blockquote>\n<p>Too see this, you can called <code>.named_steps<\/code> on your fitted model. Also check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#automated-feature-engineering\" rel=\"nofollow noreferrer\"><code>fitted_model.get_featurization_summary()<\/code><\/a><\/p>\n<p>I especially empathize with your concern especially w.r.t. how <code>LightGBM<\/code> (MSFT's GBDT implementation) is levered by AutoML. <code>LightGBM<\/code> accepts categorical columns and instead of one-hot encoding, will bin them into two subsets whenever split. Despite this, AutoML will pre-process away the categorical columns by one-hot encoding, scaling, and\/or normalization; so this unique categorical approach is never utilized in AutoML.<\/p>\n<p>If you're interested in &quot;manual&quot; ML in Azure ML, I highly suggest looking into <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-train-machine-learning-model#estimators\" rel=\"nofollow noreferrer\"><code>Estimators<\/code><\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-train-machine-learning-model#machine-learning-pipeline\" rel=\"nofollow noreferrer\"><code>Azure ML Pipelines<\/code><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2020-07-03 16:57:00.677 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-07-06 20:48:21.473 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62701556",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37191043,
        "Question_title":"Uploading libraries to Azure using AzureML",
        "Question_body":"<p>I've been experimenting a bit with the AzureML package. It weems works fine <em>unless<\/em> there is a need for external libraries.<\/p>\n\n<p>Consider the following code (the function <em>fun<\/em> usually does quite a bit more):<\/p>\n\n<pre><code>fun&lt;- function (b5) {\n    res &lt;- require(rmarkdown)\n    res\n}\n\ntest &lt;- as.data.frame(\n    cbind(\n        c(0.0,  0.3,  0.0,  0.0,  0.0),\n        c(0.0,  0.0,  0.0, -0.4,  0.0),\n        c(0,      0,    0,    0,    0))\n)\n\n\napi &lt;- publishWebService (\n  ws,\n  fun = fun,\n  name = \"Talection-fun\",\n  inputSchema = test,\n  packages = c(\"talection\",\"psych\",\"jsonlite\",\"rmarkdown\",\"knitr\")\n)\n<\/code><\/pre>\n\n<p>The service returns FALSE<\/p>\n\n<pre><code>Created new folder: \/var\/folders\/zf\/587__ss15z7_tq240vtpb68c0000gn\/T\/\/Rtmpyu2qRC\/dir138e46cbc778f\/packages\/bin\/windows\/contrib\/3.1\nRequest failed with status 401. Waiting 9.7 seconds before retry\n..........    ans\n1 FALSE\nSourced file '\/Users\/roffe\/Documents\/talections\/code\/Web Services\/WebServices.R'\n<\/code><\/pre>\n\n<p>It seems that <em>knitr<\/em>, <em>psych<\/em> and <em>jsonlite<\/em> work OK, whereas <em>rmarkdown<\/em> and <em>talection<\/em> (all of which are binary packages in a miniCRAN repository) apparently are located and uploaded, but not installed. Because there's an error message if I remove them from the miniCRAN repository.<\/p>\n\n<p>Is there a way to trace what happens to the libraries? Or anything else I can do to make this work?<\/p>\n\n<p>All suggestions and comments appreciated.<\/p>\n\n<p>Thank you,<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2016-05-12 15:14:31.353 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":134,
        "Owner_creation_date":"2012-11-11 09:14:39.067 UTC",
        "Owner_last_access_date":"2022-06-13 17:53:53.847 UTC",
        "Owner_reputation":445,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":63,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Levanger, Norway",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37191043",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50953736,
        "Question_title":"Finding a date between two date columns in Azure Python",
        "Question_body":"<p>I'm trying to find all dates in one column that fall between the dates in 2 other columns, but I'm still getting results from outside of the limits. I suspect it may be an issue with strftime, and I should be using strptime instead, but I can't seem to get it to work.<\/p>\n\n<p>The data I have is something like this:<\/p>\n\n<pre><code>Prod_Date                 Date                      Lead_Date\n08\/02\/1985 12:00:00 AM    08\/02\/1970 12:00:00 AM    08\/02\/1988 12:00:00 AM\n08\/02\/1986 12:00:00 AM    08\/02\/1971 12:00:00 AM    08\/02\/2018 12:00:00 AM\n08\/02\/1987 12:00:00 AM    08\/02\/1972 12:00:00 AM    08\/02\/1986 12:00:00 AM\n08\/02\/1988 12:00:00 AM    08\/02\/1973 12:00:00 AM    08\/02\/2018 12:00:00 AM\n<\/code><\/pre>\n\n<p>I want to limit the dataframe to Prod_Date values that fall between the Date and Lead_Date columns. I don't get any errors with my code, but I'll get a lot of erroneous values that are either before the Date value, or after the Lead_Date value.<\/p>\n\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code># imports up here can be used to \nimport pandas as pd\nimport datetime\n\n# The entry point function can contain up to two input arguments:\n#   Param&lt;dataframe1&gt;: a pandas.DataFrame\n#   Param&lt;dataframe2&gt;: a pandas.DataFrame\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n\n    # Convert strings to datetime\n    dataframe1['Date'] = dataframe1.Date.apply(\n        lambda x: pd.to_datetime(x).strftime('%d\/%m\/%Y %I:%M:%S %p'))\n\n    dataframe1['Prod_Date'] = dataframe1.Prod_Date.apply(\n        lambda x: pd.to_datetime(x).strftime('%d\/%m\/%Y %I:%M:%S %p'))\n \n    dataframe1['Lead_Date'] = dataframe1.Lead_Date.apply(\n        lambda x: pd.to_datetime(x).strftime('%d\/%m\/%Y %I:%M:%S %p'))\n        \n    # Keeping only the rows for production that are contained between the date and lead_date:\n    dataframe1 = dataframe1[(dataframe1['Date'] &lt; dataframe1['Prod_Date']) &amp; (dataframe1['Prod_Date'] &lt; dataframe1['Lead_Date'])]<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2018-06-20 17:16:41.767 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-06-20 17:45:29.937 UTC",
        "Question_score":0,
        "Question_tags":"python|datetime|azure-machine-learning-studio|strptime|strftime",
        "Question_view_count":60,
        "Owner_creation_date":"2012-01-16 01:17:17.42 UTC",
        "Owner_last_access_date":"2022-09-14 18:15:37.52 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":40,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50953736",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50514817,
        "Question_title":"Azure Machine Learning Studio SelectColumnsTransform - how to patch or set web service input parameter?",
        "Question_body":"<p>The sentiment analysis sample at <a href=\"https:\/\/gallery.azure.ai\/Collection\/Twitter-Sentiment-Analysis-Collection-1\" rel=\"nofollow noreferrer\">https:\/\/gallery.azure.ai\/Collection\/Twitter-Sentiment-Analysis-Collection-1<\/a> shows use of Filter Based Feature Selection in the training experiment, which is used to generate a SelectColumnsTransform to be saved and used in the predictive experiment, alongside the trained model. The article at <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/create-models-and-endpoints-with-powershell\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/create-models-and-endpoints-with-powershell<\/a> explains how you can programmatically train multiple models on different datasets, save those models and create then patch multiple new endpoints, so that each can be used for scoring using a different model. The same technique can also be used to create and save multiple SelectColumnsTransform outputs, for feature selection specific to a given set of training data. However, the Patch-AmlWebServiceEndpoint does not appear to allow a SelectColumnsTransform in a scoring web service to be amended to use the relevant itransform saved during training. An 'EditableResourcesNotAvailable' message is returned, along with a list of resources that can be edited which includes models but not transformations. In addition, unlike (say) ImportData, a SelectColumnsTransform does not offer any parameters that can be exposed as web service parameters. <\/p>\n\n<p>So, how is it possible to create multiple web service endpoints programmatically that each use different SelectColumnsTransform itransform blobs, such as for a document classification service where each endpoint is based on a different set of training data?<\/p>\n\n<p>Any information much appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-24 17:14:19.56 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":74,
        "Owner_creation_date":"2018-04-25 12:15:35.683 UTC",
        "Owner_last_access_date":"2020-10-23 11:00:26.277 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>Never mind. I got rid of the SelectColumnsTransform altogether (departing from the example experiment), instead using a R script in the training experiment to save the names of the columns selected, then another R script in the predictive experiment to load those names and remove any other feature columns.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-06-01 15:11:30.43 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50514817",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53952110,
        "Question_title":"Having a problem calling the function AudioConfig.FromWavFileInput through python library",
        "Question_body":"<p>I am trying to process a .wav file with the Azure Cognitive Speech Service. I am using the script below. I get an exception that says \"type object 'AudioConfig' has no attribute 'FromWavFileInput'\" when I try to setup the wav file by calling <a href=\"https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/microsoft.cognitiveservices.speech.audio.audioconfig.fromwavfileinput\" rel=\"nofollow noreferrer\">AudioConfig.FromWavFileInput()<\/a>. The documentation says the function exists, at least in the .net library. Does FromWaveFileInput exist for the <a href=\"https:\/\/pypi.org\/project\/azure-cognitiveservices-speech\/\" rel=\"nofollow noreferrer\">cognitiveservices-speech python library<\/a>? How can I process an audio file with python?<\/p>\n\n<pre><code>import azure.cognitiveservices.speech as speechsdk\n\nspeechKey = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\nservice_region = 'eastus2'\n\n#### # Creates an instance of a speech config with specified subscription key and service region.\n#### # Replace with your own subscription key and service region (e.g., \"westus\").\nspeech_config = speechsdk.SpeechConfig(subscription=speechKey, region=service_region)\n\naudioInput = speechsdk.AudioConfig.FromWavFileInput('RainSpain.wav')\n\n#### # Creates a recognizer with the given settings\nspeech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_input=audioInput)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2018-12-27 23:47:26.91 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-12-31 06:19:34.287 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|speech-recognition|azure-machine-learning-studio",
        "Question_view_count":1136,
        "Owner_creation_date":"2015-05-29 21:19:32.58 UTC",
        "Owner_last_access_date":"2021-11-03 17:53:17.473 UTC",
        "Owner_reputation":5,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>Indeed as you said. I searched for the keywords <code>AudioConfig<\/code> &amp; <code>FromWavFileInput<\/code> on GitHub repo <a href=\"https:\/\/github.com\/Azure-Samples\/cognitive-services-speech-sdk\" rel=\"nofollow noreferrer\"><code>Azure-Samples\/cognitive-services-speech-sdk<\/code><\/a>, there is not any Python codes about it except for Java, C#, and <a href=\"https:\/\/github.com\/Azure-Samples\/cognitive-services-speech-sdk\/blob\/3131ab75577116fe9359242d6d86321808601e19\/samples\/cpp\/windows\/console\/samples\/speech_recognition_samples.cpp#L116\" rel=\"nofollow noreferrer\">C++<\/a>.<\/p>\n\n<p>So per my experience, there are two workaround ways to do it.<\/p>\n\n<ol>\n<li>Wrap the C++ codes as a <a href=\"https:\/\/docs.python.org\/3\/c-api\/index.html\" rel=\"nofollow noreferrer\">Python extension module<\/a>, or communicate with C++\/Java codes.<\/li>\n<li>Directly using <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/rest-apis\" rel=\"nofollow noreferrer\">Speech service REST APIs<\/a> with <a href=\"http:\/\/docs.python-requests.org\/en\/master\/\" rel=\"nofollow noreferrer\"><code>requests<\/code><\/a>, it's simple for Python and Azure Speech Service.<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-12-31 09:44:01.007 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53952110",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39706790,
        "Question_title":"NLTK in Azure ML",
        "Question_body":"<p>Folks,<\/p>\n\n<p>I have the below code to create pos tagger in nltk implemented as an \"Execute Python Script\" in Azure ML. The problem is the script has to download <em>maxent_treebank_pos_tagger<\/em> every time. Commenting the line would throw the below error. I even tried downloading using nltk.download('all') but still it did not help.<\/p>\n\n<pre><code>\"C:\\\\pyhome\\\\lib\\\\site-packages\\\\nltk\\\\data.py\\\", line 467, in find\\r\\n raise LookupError(resource_not_found)\\r\\nLookupError: \\r\\n**********************************************************************\\r\\n Resource 'taggers\/maxent_treebank_pos_tagger\/english.pickle' not\\r\\n found. Please use the NLTK Downloader to obtain the resource:\\r\\n &gt;&gt;&gt; nltk.download()\\r\\n Searched in:\\r\\n - 'C:\\\\\\\\Users\\\\\\\\Client\/nltk_data'\\r\\n - 'C:\\\\\\\\nltk_data'\\r\\n - 'D:\\\\\\\\nltk_data'\\r\\n - 'E:\\\\\\\\nltk_data'\\r\\n - 'C:\\\\\\\\pyhome\\\\\\\\nltk_data'\\r\\n - 'C:\\\\\\\\pyhome\\\\\\\\lib\\\\\\\\nltk_data'\\r\\n - 'C:\\\\\\\\Users\\\\\\\\Client\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\nltk_data'\\r\\n**********************************************************************\\r\\nProcess returned with non-zero exit code 1\\r\\n\\r\\n---------- End of error message from Python interpreter ----------\"}}Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:---------- Start of error message from Python interpreter ----------Caught exception while executing function: Traceback (most recent call last): File \"C:\\server\\invokepy.py\", line 199, in batch odfs = mod.azureml_main(*idfs) File \"C:\\temp\\febff15ac9584d978d04d40f0c7bd565.py\", line 32, in azureml_main tagged = nltk.pos_tag(tokens) File \"C:\\pyhome\\lib\\site-packages\\nltk\\tag\\__init__.py\", line 99, in pos_tag tagger = load(_POS_TAGGER) File \"C:\\pyhome\\lib\\site-packages\\nltk\\data.py\", line 605, in load resource_val = pickle.load(_open(resource_url)) File \"C:\\pyhome\\lib\\site-packages\\nltk\\data.py\", line 686, in _open return find(path).open() File \"C:\\pyhome\\lib\\site-packages\\nltk\\data.py\", line 467, in find raise LookupError(resource_not_found)LookupError: ********************************************************************** Resource 'taggers\/maxent_treebank_pos_tagger\/english.pickle' not found. Please use the NLTK Downloader to obtain the resource: &gt;&gt;&gt; nltk.download() Searched in: - 'C:\\\\Users\\\\Client\/nltk_data' - 'C:\\\\nltk_data' - 'D:\\\\nltk_data' - 'E:\\\\nltk_data' - 'C:\\\\pyhome\\\\nltk_data' - 'C:\\\\pyhome\\\\lib\\\\nltk_data' - 'C:\\\\Users\\\\Client\\\\AppData\\\\Roaming\\\\nltk_data'**********************************************************************Process returned with non-zero exit code 1---------- End of error message from Python interpreter ---------- Process exited with error code -2\n<\/code><\/pre>\n\n<p>Below is my code in Azure ml<\/p>\n\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n# import required packages\nimport pandas as pd\nimport nltk\nimport numpy as np\n# tokenize the review text and store the word corpus\nword_dict = {}\ntoken_list = []\n#nltk.download('all')\n#nltk.download(info_or_id='punkt', download_dir='C:\/users\/client\/nltk_data')\n#nltk.download(info_or_id='maxent_treebank_pos_tagger', download_dir='C:\/users\/client\/nltk_data')\nfor text in dataframe1[\"tweet_text\"]:\n    tokens = nltk.word_tokenize(text.decode('utf8'))\n    tagged = nltk.pos_tag(tokens)\n\n\n  # convert feature vector to dataframe object\ndataframe_output = pd.DataFrame(tagged, columns=['Word', 'Type'])\nreturn [dataframe_output]\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2016-09-26 15:30:09.613 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|nltk|azure-machine-learning-studio",
        "Question_view_count":989,
        "Owner_creation_date":"2013-06-11 04:20:18.39 UTC",
        "Owner_last_access_date":"2022-09-18 05:28:20.357 UTC",
        "Owner_reputation":1748,
        "Owner_up_votes":136,
        "Owner_down_votes":55,
        "Owner_views":339,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Toronto, ON, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39706790",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56558892,
        "Question_title":"Share notebooks across Azure Machine learning service notebook VM",
        "Question_body":"<p>Is there any way to share a Azure notebook across multiple users who use different notebook VMs? It seems the VMs itself is not shareable across users. <\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-12 09:29:42.567 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":1224,
        "Owner_creation_date":"2012-11-19 09:24:15.073 UTC",
        "Owner_last_access_date":"2020-02-05 16:47:07.973 UTC",
        "Owner_reputation":773,
        "Owner_up_votes":33,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Answer_body":"<p>Notebook VMs has own Jupyter environment and we don't need to use notebooks.azure.com. The former can be used in enterprise scenarios within the team to share the resources, and the latter is open, similar to google colab. When each user login to his notebook VM, there is a top level folder with his\/her alias and under that all notebooks are stored. this is stored in an Azure storage and each user's notebook VM will mount same storage. Hence If I want to view other person \\'s notebook, I need to navigate to his alias in the Jupyter nb in my nbvm<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-07-08 06:01:29.11 UTC",
        "Answer_score":2.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56558892",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72621994,
        "Question_title":"How to build Face\/ Image Classifier in Azure ML like Google Photos",
        "Question_body":"<p>I need to build an image classification model in Azure  ML- which initially takes an input from Phone (A check in app which takes information like ID and also we will capture the image of the person- Here ID is used to tag the image) which will be redirected to data storage. once it's done, we will upload the n number of images of person to the data storage, it should able to classify the image based on facial recognition and should categorize as separate image folder for different person( Just like Google Photos). In short, If there's a 100 unique people come for check in and during the event if we click random images of these 100 unique persons, when we load this data to blob - it should categorize the persons separately.<\/p>\n<p>Can I go with approach-<\/p>\n<p>1.Check in app-- Loads image with tag\n2.Blob- store the image\n3. custom vison- ML classifier\n4.Loding n number of images to blob\n5. comparing the image with check in app loaded image and categorizing as album just like google photos\n6. Loading albums to app to make attendees to see the images<\/p>\n<p>Please guide me with the solution and services need to be considered to make this possible in azure<\/p>\n<p>Thanks in adavance<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-14 18:48:29.777 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-cognitive-services|image-classification|azure-machine-learning-service|microsoft-custom-vision|facial-identification",
        "Question_view_count":34,
        "Owner_creation_date":"2022-04-29 04:57:54.493 UTC",
        "Owner_last_access_date":"2022-08-10 04:18:56.12 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72621994",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37228027,
        "Question_title":"How do get my custom Python code into Azure Machine Learning for use a a ZIP resource?",
        "Question_body":"<p>The <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-execute-python-scripts\/\" rel=\"nofollow\">documentation<\/a> for the Azure Machine Learning Python script module describes using a ZIP file containing code as a resource, but I don't see how to create and upload such a ZIP file in the first place.<\/p>\n\n<p>How do get my custom Python code into Azure Machine Learning for use as a ZIP resource?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-14 14:45:05.637 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-05-14 15:00:39.27 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":664,
        "Owner_creation_date":"2011-03-12 19:54:30.313 UTC",
        "Owner_last_access_date":"2022-09-21 19:06:38.42 UTC",
        "Owner_reputation":41475,
        "Owner_up_votes":1198,
        "Owner_down_votes":107,
        "Owner_views":1912,
        "Answer_body":"<p>Just upload it as a dataset. <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-execute-python-scripts\/\" rel=\"nofollow\">Reference.<\/a> (search for it, as it is not on the first page).<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-walkthrough-2-upload-data\/#upload-the-dataset-to-machine-learning-studio\" rel=\"nofollow\">Reference<\/a> on how to upload the dataset. <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2016-05-14 15:02:38.72 UTC",
        "Answer_score":1.0,
        "Owner_location":"United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37228027",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70871300,
        "Question_title":"Azure ML Internal Server Error and 404 Error",
        "Question_body":"<p>Azure ML pipeline run failed with status message ServiceError: InternalServerError.\n<a href=\"https:\/\/i.stack.imgur.com\/Opik3.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Opik3.png\" alt=\"Internal server error\" \/><\/a><\/p>\n<p>404 error when viewing executionlogs.txt, stderrlogs.txt, and stdoutlogs.txt.\n<a href=\"https:\/\/i.stack.imgur.com\/hgJax.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/hgJax.png\" alt=\"404 error\" \/><\/a><\/p>\n<p>A pipeline run completed the day before. No changes were made between these runs.\n<a href=\"https:\/\/i.stack.imgur.com\/1KVuc.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/1KVuc.png\" alt=\"Pipeline runs\" \/><\/a><\/p>\n<p>Compute cluster properties:<\/p>\n<ul>\n<li>VM size: Standard_D3_v2 (4 cores, 14 GB RAM, 200 GB disk)<\/li>\n<li>Processing unit: CPU - General purpose<\/li>\n<li>OS type: Linux<\/li>\n<li>Location: East US<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-26 22:59:45.707 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":155,
        "Owner_creation_date":"2019-06-07 06:29:38.77 UTC",
        "Owner_last_access_date":"2022-09-22 21:28:04.37 UTC",
        "Owner_reputation":569,
        "Owner_up_votes":448,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70871300",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45958534,
        "Question_title":"Azure ML Import Data connection has special character in password",
        "Question_body":"<p>Azure ML Import Data from Azure SQL DB connection has special character <code>]<\/code> in password.<\/p>\n\n<p>In connection wizard it is successfully connected.<\/p>\n\n<p>But when run the experiment, it gives error with no error message.<\/p>\n\n<p>After long analysis this issue is identified.<\/p>\n\n<p>Anyone knows how to escape character for Import Data functionality in Azure ML?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2017-08-30 10:52:55.203 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-sql-database|azure-sql-server",
        "Question_view_count":32,
        "Owner_creation_date":"2012-09-10 12:46:42.153 UTC",
        "Owner_last_access_date":"2022-01-27 20:21:57.583 UTC",
        "Owner_reputation":8112,
        "Owner_up_votes":47,
        "Owner_down_votes":28,
        "Owner_views":597,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Vadodara, Gujarat, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45958534",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72659937,
        "Question_title":"CI \/ CD and repository integration for Azure ML Workspace",
        "Question_body":"<p>I am interested in knowing how can I integrate a repository with Azure Machine Learning Workspace.<\/p>\n<h2>What have I tried ?<\/h2>\n<p>I have some experience with Azure Data Factory and usually I have setup workflows where<\/p>\n<ol>\n<li><p>I have a <code>dev<\/code> azure data factory instance that is linked to azure repository.<\/p>\n<\/li>\n<li><p>Changes made to the repository using the code editor.<\/p>\n<\/li>\n<li><p>These changes are published via the <code>adf_publish<\/code> branch to the live <code>dev<\/code> instance<\/p>\n<\/li>\n<li><p>I use CI \/ CD pipeline and the AzureRMTemplate task to deploy the templates in the publish branch to release the changes to <code>production<\/code> environment<\/p>\n<\/li>\n<\/ol>\n<h2>Question:<\/h2>\n<ul>\n<li>How can I achieve the same \/ similar workflow with Azure Machine Learning Workspace ?<\/li>\n<li>How is CI \/ CD done with Azure ML Workspace<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-17 13:11:31.697 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":94,
        "Owner_creation_date":"2010-04-12 17:27:26.887 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:17.55 UTC",
        "Owner_reputation":9826,
        "Owner_up_votes":1723,
        "Owner_down_votes":15,
        "Owner_views":1238,
        "Answer_body":"<p>The following workflow is the official practice to be followed to achieve the task required.<\/p>\n<ol>\n<li>Starting with the architecture mentioned below<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/KdRUa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KdRUa.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ul>\n<li>we need to have a specific data store to handle the dataset<\/li>\n<li>Perform the regular code modifications using the IDE like Jupyter Notebook or VS Code<\/li>\n<li>Train and test the model<\/li>\n<li>To register and operate on the model, deploy the model image as a web service and operate the rest.<\/li>\n<\/ul>\n<ol start=\"2\">\n<li><strong>Configure the CI Pipeline:<\/strong><\/li>\n<\/ol>\n<ul>\n<li><p>Follow the below steps to complete the procedure<\/p>\n<p><strong>Before implementation:<\/strong><\/p>\n<pre><code>- We need azure subscription enabled account\n- DevOps activation must be activated.\n<\/code><\/pre>\n<\/li>\n<li><p>Open DevOps portal with enabled SSO<\/p>\n<\/li>\n<li><p>Navigate to <strong>Pipeline -&gt; Builds -&gt; Choose the model which was created -&gt; Click on EDIT<\/strong>\n<a href=\"https:\/\/i.stack.imgur.com\/yUVZl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yUVZl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Build pipeline will be looking like below screen\n<a href=\"https:\/\/i.stack.imgur.com\/VSKJq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/VSKJq.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>We need to use Anaconda distribution for this example to get all the dependencies.<\/p>\n<\/li>\n<li><p>To install environment dependencies, check the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/devops\/pipelines\/tasks\/package\/conda-environment?view=azure-devops&amp;viewFallbackFrom=azdevops\" rel=\"nofollow noreferrer\">link<\/a><\/p>\n<\/li>\n<li><p>Use the python environment, under <strong>Install Requirements<\/strong> in user setup.<\/p>\n<\/li>\n<li><p>Select <strong>create or get workspace<\/strong> select your account subscription as mentioned in below screen<\/p>\n<\/li>\n<\/ul>\n<p><a href=\"https:\/\/i.stack.imgur.com\/vt0el.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vt0el.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ul>\n<li>Save the changes happened in other tasks and all those muse be in same subscription.\n<a href=\"https:\/\/i.stack.imgur.com\/WJxCL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/WJxCL.png\" alt=\"enter image description here\" \/><\/a><\/li>\n<\/ul>\n<p>The entire CI\/CD procedure and solution was documented in <a href=\"https:\/\/www.azuredevopslabs.com\/labs\/vstsextend\/aml\/#author-praneet-singh-solanki\" rel=\"nofollow noreferrer\">link<\/a><\/p>\n<p><strong>Document Credit: Praneet Singh Solanki<\/strong><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-06-19 23:45:28.283 UTC",
        "Answer_score":0.0,
        "Owner_location":"United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72659937",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70179691,
        "Question_title":"Resources for displaying Azure ML Studio application insights on Grafana",
        "Question_body":"<p>I'm looking to display specific metrics from Azure ML Studio application insights on a Grafana Dashboard and haven't found any great documentations so far. Can you please point me to a good resource for this need? Thank you.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-01 05:54:04.333 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|grafana|azure-machine-learning-service",
        "Question_view_count":44,
        "Owner_creation_date":"2021-11-29 18:53:13.203 UTC",
        "Owner_last_access_date":"2022-04-27 15:05:10.08 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70179691",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73418843,
        "Question_title":"Azure ML ExecutableNotFound: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
        "Question_body":"<p>I am using LightGBM in Azure ML Jupyter notebooks, it works fine and I also installed graphviz.<\/p>\n<p>However this line:<\/p>\n<pre><code>lgb.plot_tree(clf, tree_index = 1, figsize=(20,12))\n<\/code><\/pre>\n<p>throws this error:<\/p>\n<pre><code>ExecutableNotFound: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-19 15:11:42.893 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|graphviz|azure-machine-learning-studio|lightgbm",
        "Question_view_count":94,
        "Owner_creation_date":"2011-04-05 19:05:03.093 UTC",
        "Owner_last_access_date":"2022-09-16 12:42:27.473 UTC",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Answer_body":"<p>Common problem (very common).  There are two systems named Graphviz, and you need both!\nsee <a href=\"https:\/\/stackoverflow.com\/questions\/73040021\/im-getting-this-issue-when-trying-to-run-the-code-i-found-on-github-pydot-and\/73041302#73041302\">I&#39;m getting this issue when trying to run the code I found on GitHub. Pydot and graphivz are installed but still getting this error<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-08-19 15:22:10.25 UTC",
        "Answer_score":1.0,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73418843",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71075255,
        "Question_title":"AzureML: TabularDataset.to_pandas_dataframe() hangs when parquet file is empty",
        "Question_body":"<p>I have created a Tabular Dataset using Azure ML python API. Data under question is a bunch of parquet files (~10K parquet files each of size of 330 KB) residing in Azure Data Lake Gen 2 spread across multiple partitions. When I try to load the dataset using the API <code>TabularDataset.to_pandas_dataframe()<\/code>, it continues forever (hangs), if there are empty parquet files included in the Dataset. If the tabular dataset doesn't include those empty parquet files, <code>TabularDataset.to_pandas_dataframe()<\/code> completes within few minutes.<\/p>\n<p>By empty parquet file, I mean that the if I read the individual parquet file using pandas (pd.read_parquet()), it results in an empty DF (df.empty == True).<\/p>\n<p>I discovered the root cause while working on another issue mentioned <code>[here][1]<\/code>.<\/p>\n<p><strong>My question is how can make <code>TabularDataset.to_pandas_dataframe()<\/code> work even when there are empty parquet files?<\/strong><\/p>\n<p><strong>Update<\/strong>\nThe issue has been fixed in the following version:<\/p>\n<ul>\n<li>azureml-dataprep : 3.0.1<\/li>\n<li>azureml-core :  1.40.0<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-11 04:14:23.947 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-03-30 12:30:47.773 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":300,
        "Owner_creation_date":"2010-07-30 15:52:19.753 UTC",
        "Owner_last_access_date":"2022-09-23 12:22:17.867 UTC",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Answer_body":"<p>Thanks for reporting it.\nThis is a bug in handling of the parquet files with columns but empty row set. This has been fixed already and will be included in next release.<\/p>\n<p>I could not repro the hang on multiple files, though, so if you could provide more info on that would be nice.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2022-03-04 22:25:24.77 UTC",
        "Answer_score":1.0,
        "Owner_location":"Bangalore, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71075255",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60342645,
        "Question_title":"Azure ML inference pipeline deployment authorization token error",
        "Question_body":"<p>When deploying a real-time inferencing pipeline in Azure ML (as per <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy#deploy-the-real-time-endpoint\" rel=\"nofollow noreferrer\">this<\/a> tutorial), I receive the below error. I've tried forcibly logging out using OAuth. Tried creating a new Azure workspace but continue to receive the same error.<\/p>\n\n<p>It looks like the tenant id causing the problem is example.onmicrosoft.com (72f988bf-86f1-41af-91ab-2d7cd011db47)<\/p>\n\n<hr>\n\n<p><em>Deploy: Failed on step CreateServiceFromModels. Details: AzureML service API error. Error calling ServiceCreate: {\"code\":\"Unauthorized\",\"statusCode\":401,\"message\":\"Unauthorized\",\"details\":[{\"code\":\"EmptyOrInvalidToken\",\"message\":\"Error: Service invocation failed!\\r\\nRequest: GET <a href=\"https:\/\/management.azure.com\/subscriptions\/subscription_id\/resourceGroups\/dev-rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/dev-ws\/providers\/Microsoft.Authorization\/permissions?api-version=2015-07-01\" rel=\"nofollow noreferrer\">https:\/\/management.azure.com\/subscriptions\/subscription_id\/resourceGroups\/dev-rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/dev-ws\/providers\/Microsoft.Authorization\/permissions?api-version=2015-07-01<\/a>\\r\\nStatus Code: 401 Unauthorized\\r\\nReason Phrase: Unauthorized\\r\\nResponse Body: {\\\"error\\\":{\\\"code\\\":\\\"InvalidAuthenticationTokenTenant\\\",\\\"message\\\":\\\"The access token is from the wrong issuer '<a href=\"https:\/\/sts.windows.net\/72f988bf-86f1-41af-91ab-2d7cd011db47\/\" rel=\"nofollow noreferrer\">https:\/\/sts.windows.net\/72f988bf-86f1-41af-91ab-2d7cd011db47\/<\/a>'. It must match the tenant '<a href=\"https:\/\/sts.windows.net\/correct_tenant_id\/\" rel=\"nofollow noreferrer\">https:\/\/sts.windows.net\/correct_tenant_id\/<\/a>' associated with this subscription. Please use the authority (URL) '<a href=\"https:\/\/login.windows.net\/correct_tenant_id\" rel=\"nofollow noreferrer\">https:\/\/login.windows.net\/correct_tenant_id<\/a>' to get the token. Note, if the subscription is transferred to another tenant there i<\/em><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2020-02-21 16:22:36.893 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-02-22 18:16:51.243 UTC",
        "Question_score":2,
        "Question_tags":"azure|azure-active-directory|azure-machine-learning-studio|azure-deployment|azure-machine-learning-service",
        "Question_view_count":481,
        "Owner_creation_date":"2020-02-21 16:06:42.873 UTC",
        "Owner_last_access_date":"2022-09-22 17:03:13.143 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>I appear to have had User Access Administrator role only (in addition to Classic Service Administrator). As soon as I added myself to the Owner role in the Access Control (IAM) section of the Azure Portal, the deployment succeeded.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-02-24 15:03:17.823 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60342645",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53548259,
        "Question_title":"Webservice.deploy_from_image fails with \"AttributeError: 'str' object has no attribute 'creation_state'\"",
        "Question_body":"<p>I'm trying to deploy an image to a web service in an Azure Container Instance using the new ML service SDK. The <code>Webservice.deploy_from_image<\/code> method is failing with the following messages: <\/p>\n\n<pre><code>&gt; Traceback (most recent call last):   File\n&gt; \"c:\/Users\/chrcam\/git\/amlIrisClassification\/deploy_iris_to_aci.py\",\n&gt; line 18, in &lt;module&gt;\n&gt;     workspace = ws)   File \"C:\\Users\\chrcam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py\",\n&gt; line 258, in deploy_from_image\n&gt;     return deployment_config._webservice_type._deploy(workspace, name, image, deployment_config)   File\n&gt; \"C:\\Users\\chrcam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\azureml\\core\\webservice\\aci.py\",\n&gt; line 121, in _deploy\n&gt;     deployment_config.validate_image(image)   File \"C:\\Users\\chrcam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py\",\n&gt; line 883, in validate_image\n&gt;     if image.creation_state != 'Succeeded': AttributeError: 'str' object has no attribute 'creation_state'\n<\/code><\/pre>\n\n<p>I started on the 1.68 release of the SDK and just upgraded to 1.80 with the same result. <\/p>\n\n<p>The model and image are both registered in the my workspace. <\/p>\n\n<p>The code is fairly simple. Any feedback or direction would be helpful. <\/p>\n\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.webservice import AciWebservice\n\nws = Workspace.from_config()\n\nimage_name = 'irisimage'\nservice_name = 'aciiris'\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                               memory_gb = 1, \n                                               tags = {\"data\": \"iris\", \"type\": \"classification\"},\n                                               description = 'Iris Classification')\n\nservice = Webservice.deploy_from_image(deployment_config = aciconfig,\n                                            image = image_name,\n                                            name = service_name,\n                                            workspace = ws)\n\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2018-11-29 22:01:29.66 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2019-05-03 20:27:33.283 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":1094,
        "Owner_creation_date":"2016-04-28 16:39:32.987 UTC",
        "Owner_last_access_date":"2019-04-04 14:41:52.5 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53548259",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72471691,
        "Question_title":"How to deploy multiple models to an endpoint using Azure Machine Learning CLI v2?",
        "Question_body":"<p>At the GA of <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/azure-machine-learning-release-notes-cli-v2#2022-05-24\" rel=\"nofollow noreferrer\">az ml cli v2<\/a>, we've been working on some POC using <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-deployment-managed-online\" rel=\"nofollow noreferrer\">yml online deployment<\/a> on top of managed endpoint and it all went well for single model, until when there's certain scenario where there is requirement to deploy multiple trained and registered models to one managed endpoint, it seems there is no documentations on how to achieve that.<\/p>\n<p>Previously using Python SDK, it was able to deploy list of models to AKS cluster.<\/p>\n<p>Checking if there's any limitation or could be some docs I might have missed?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-02 06:34:23.59 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-cli|azure-machine-learning-service",
        "Question_view_count":181,
        "Owner_creation_date":"2019-09-11 07:07:53.007 UTC",
        "Owner_last_access_date":"2022-09-15 16:01:06.153 UTC",
        "Owner_reputation":383,
        "Owner_up_votes":70,
        "Owner_down_votes":1,
        "Owner_views":35,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72471691",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42019977,
        "Question_title":"AzureML - Trained clustering Model cannot be connected with Web Service Output",
        "Question_body":"<p>In AzureML it is not possible to connect trained Clustering Model with web service output. <\/p>\n\n<p>Why does AzureML only allow ILearnerDotNet to be connected with Web Service Output and not IClusterDotNet? <\/p>\n\n<p>This is a serious bug which halts clustering models from deploying them as a web service.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2017-02-03 08:37:01.187 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-02-03 08:50:07.267 UTC",
        "Question_score":1,
        "Question_tags":"azure|machine-learning|cluster-analysis|azure-machine-learning-studio",
        "Question_view_count":192,
        "Owner_creation_date":"2016-01-12 14:22:43.363 UTC",
        "Owner_last_access_date":"2019-07-02 21:45:24.25 UTC",
        "Owner_reputation":105,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42019977",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41336102,
        "Question_title":"How to recognizie number of people from photo taken from above?",
        "Question_body":"<p>I have 3 person sofa in room. I have camera storing images to Azure Blob storage.<\/p>\n\n<p>I have tested that Azure Cognitive Services Emotion API can count number of faces if camera is located in front of user. It can count that 1,2 or 2 person is sitting. I'm using blog triggered Azure functions to process data to Emotion API.<\/p>\n\n<p>I realize now that camera must be installed to roof because of physical requirement of room. Roof is only place where camera can be mounted.<\/p>\n\n<p>Emotion API cannot be used since camera from above cannot see faces. Camera sees top of head.<\/p>\n\n<p>1) Do you know any methods for counting number of people from above?<\/p>\n\n<p>2) Do you know if I'm able to determine which position is used. Let say that person sits in left side and middle and right side is unused.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2016-12-26 20:41:49.977 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"image-processing|microsoft-cognitive|azure-machine-learning-studio",
        "Question_view_count":575,
        "Owner_creation_date":"2016-11-04 09:17:30.693 UTC",
        "Owner_last_access_date":"2022-09-22 08:39:28.943 UTC",
        "Owner_reputation":1519,
        "Owner_up_votes":116,
        "Owner_down_votes":0,
        "Owner_views":375,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Finland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41336102",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45351020,
        "Question_title":"how to add the column names to the input dataset using R script in Machine Learning model",
        "Question_body":"<p>I am trying to add the column names to the input dataset using below R script.<\/p>\n\n<pre><code>dataset1 &lt;- maml.mapInputPort(1)#class: data.frame\n# Sample operation\ncols &lt;- c(\"age\",\n    \"workclass\",\n    \"fnlwgt\",\n    \"education\",\n    \"education-num\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"capital-gain\",\n    \"capital-loss\",\n    \"hours-per-week\",\n    \"native-country\",\n    \"income\")\n colnames(data.frame) &lt;- cols\n data.set = dataset1;\n maml.mapOutputPort(\"data.set\");\n<\/code><\/pre>\n\n<p>But I am getting the error like below figure.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/m4vwp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/m4vwp.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Can you please tell me how to add the column names to the input dataset using R script in Machine Learning model?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-07-27 12:36:30.353 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":224,
        "Owner_creation_date":"2015-10-21 11:13:32.267 UTC",
        "Owner_last_access_date":"2022-09-07 05:24:44.26 UTC",
        "Owner_reputation":4594,
        "Owner_up_votes":240,
        "Owner_down_votes":22,
        "Owner_views":1089,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bangalore, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45351020",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68422680,
        "Question_title":"how to write to Azure PipelineData properly?",
        "Question_body":"<p>Im trying to learn Azure, with little luck (yet). All the tutorials show using PipelineData just as a file, when configured in &quot;upload&quot; mode. However, im getting &quot;FileNotFoundError: [Errno 2] No such file or directory: ''&quot; error. I would love to ask a more specific question, but i just can't see what im doing wrong.<\/p>\n<pre><code>from azureml.core import Workspace, Datastore,Dataset,Environment\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.pipeline.steps import PythonScriptStep\nfrom azureml.pipeline.core import Pipeline, PipelineData\nimport os\n\nws = Workspace.from_config()\ndatastore = ws.get_default_datastore()\n\ncompute_name = &quot;cpucluster&quot;\ncompute_target = ComputeTarget(workspace=ws, name=compute_name)\naml_run_config = RunConfiguration()\naml_run_config.target = compute_target\naml_run_config.environment.python.user_managed_dependencies = False\naml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n    conda_packages=['pandas','scikit-learn'], \n    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n    pin_sdk_version=False)\n\noutput1 = PipelineData(&quot;processed_data1&quot;,datastore=datastore, output_mode=&quot;upload&quot;)\nprep_step = PythonScriptStep(\n    name=&quot;dataprep&quot;,\n    script_name=&quot;dataprep.py&quot;,\n    source_directory=os.path.join(os.getcwd(),'dataprep'),\n    arguments=[&quot;--output&quot;, output1],\n    outputs = [output1],\n    compute_target=compute_target,\n    runconfig=aml_run_config,\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>In the dataprep.py i hve the following:<\/p>\n<pre><code>import numpy, argparse, pandas\nfrom azureml.core import Run\nrun = Run.get_context()\nparser = argparse.ArgumentParser()\nparser.add_argument('--output', dest='output', required=True)\nargs = parser.parse_args()\ndf = pandas.DataFrame(numpy.random.rand(100,3))\ndf.iloc[:, 2] = df.iloc[:,0] + df.iloc[:,1]\nprint(df.iloc[:5,:])\ndf.to_csv(args.output)\n\n<\/code><\/pre>\n<p>So, yeah. pd is supposed to write to the output, but my compute cluster says the following:<\/p>\n<pre><code>&quot;User program failed with FileNotFoundError: [Errno 2] No such file or directory: ''\\&quot;.\n<\/code><\/pre>\n<p>When i dont include the to_csv() function, the cluster does not complain<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-07-17 17:11:28.29 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-07-17 22:09:08.577 UTC",
        "Question_score":4,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":404,
        "Owner_creation_date":"2020-05-02 13:08:31.653 UTC",
        "Owner_last_access_date":"2022-09-25 01:27:33.107 UTC",
        "Owner_reputation":59,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>Here is an <a href=\"https:\/\/github.com\/james-tn\/highperformance_python_in_azure\/blob\/master\/parallel_python_processing\/pipeline_definition.ipynb\" rel=\"nofollow noreferrer\">example<\/a> for PRS.\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipelinedata?view=azure-ml-py\" rel=\"nofollow noreferrer\">PipelineData<\/a> was intended to represent &quot;transient&quot; data from one step to the next one, while OutputDatasetConfig was intended for capturing the final state of a dataset (and hence why you see features like lineage, ADLS support, etc). PipelineData always outputs data in a folder structure like {run_id}{output_name}. OutputDatasetConfig allows to decouple the data from the run and hence it allows you to control where to land the data (although by default it will produce similar folder structure). The OutputDatasetConfig allows even to register the output as a Dataset, where getting rid of such folder structure makes sense. From the docs itself: &quot;Represent how to copy the output of a run and be promoted as a FileDataset. The OutputFileDatasetConfig allows you to specify how you want a particular local path on the compute target to be uploaded to the specified destination&quot;.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-batch-scoring-classification#create-dataset-objects\" rel=\"nofollow noreferrer\">OutFileDatasetConfig<\/a> is a control plane concept to pass data between pipeline steps.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-07-19 04:05:19.373 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-07-19 04:14:27.887 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68422680",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42215613,
        "Question_title":"Machine Learning Studio - Experiment stuck in queued",
        "Question_body":"<p>When I try to run my experiment I find that I am stuck in queued. <\/p>\n\n<p>Yes I am on a free account but I am not running two projects at the same time. <\/p>\n\n<p>I have tried deleting all my projects and creating a new one but this also does not get passed the queued stage.<\/p>\n\n<p>Thank you for the help<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-13 23:55:39.75 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":1030,
        "Owner_creation_date":"2015-10-12 03:10:51.79 UTC",
        "Owner_last_access_date":"2022-09-22 00:25:05.207 UTC",
        "Owner_reputation":823,
        "Owner_up_votes":98,
        "Owner_down_votes":8,
        "Owner_views":48,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Sydney NSW, Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42215613",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46422216,
        "Question_title":"Multiple outputs from custom module",
        "Question_body":"<p><a href=\"https:\/\/docs.microsoft.com\/de-de\/azure\/machine-learning\/studio\/custom-r-modules\" rel=\"nofollow noreferrer\">This Microsoft Azure documentation<\/a> shows how to author custom modules for the Azure Machine Learning Studio. There is a paragraph about returning multiple outputs from your module. Yet following the instructions I can only see data in the visualization of the first output port while the others remain empty.<\/p>\n\n<p>This is a follow-up question to <a href=\"https:\/\/stackoverflow.com\/questions\/46340959\/multiple-inputs-outputs-from-execute-r-script\">this one<\/a>. I accepted the answer there because I misinterpreted the result of the custom module I wrote - it is possible for some output ports to be empty and I hastily assumed the output to be correct. However, running the same code in RStudio does indeed generate data that should have been returned in ML Studio as well. Also, printing the data works.  <\/p>\n\n<p><strong>Minimal example:<\/strong><\/p>\n\n<p>The source files contained in the module's ZIP file:<\/p>\n\n<p>test.R<\/p>\n\n<pre><code>foo &lt;- function() {\n    require(data.table)\n    out1 &lt;- data.table(mtcars)\n    out2 &lt;- data.table(cars)\n\n    print(\"out1:\")\n    print(head(out1))\n    print(\"out2:\")\n    print(head(out2))\n\n    return(list(out1, out2))\n}\n<\/code><\/pre>\n\n<p>test.xml<\/p>\n\n<pre><code>&lt;Module name=\"Multiple outputs\"&gt;\n  &lt;Owner&gt;...&lt;\/Owner&gt;\n  &lt;Language name=\"R\" sourceFile=\"test.R\" entryPoint=\"foo\"\/&gt; \n    &lt;Ports&gt;\n      &lt;Output id=\"out_1\" name=\"out1\" type=\"DataTable\"&gt;\n        &lt;Description&gt;...&lt;\/Description&gt;\n      &lt;\/Output&gt;\n      &lt;Output id=\"out_2\" name=\"out2\" type=\"DataTable\"&gt;\n        &lt;Description&gt;...&lt;\/Description&gt;\n      &lt;\/Output&gt;   \n    &lt;\/Ports&gt;\n&lt;\/Module&gt;\n<\/code><\/pre>\n\n<p>Which yields this module that runs successfully:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/tyKFa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/tyKFa.png\" alt=\"Module in Azure\"><\/a><\/p>\n\n<p>The visualizations of the output however look like this:\n<a href=\"https:\/\/i.stack.imgur.com\/QSJ98.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/QSJ98.png\" alt=\"Correct visualization of output 1\"><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/wie4o.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wie4o.png\" alt=\"Empty visualization of output 2\"><\/a><\/p>\n\n<p>Whereas the output log looks good:<\/p>\n\n<pre><code>[ModuleOutput] [1] \"out1:\"\n[ModuleOutput] \n[ModuleOutput]     mpg cyl disp  hp drat    wt  qsec vs am gear carb\n[ModuleOutput] \n[ModuleOutput] 1: 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n[ModuleOutput] \n[ModuleOutput] 2: 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n[ModuleOutput] \n[ModuleOutput] 3: 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n[ModuleOutput] \n[ModuleOutput] 4: 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n[ModuleOutput] \n[ModuleOutput] 5: 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n[ModuleOutput] \n[ModuleOutput] 6: 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n[ModuleOutput] \n[ModuleOutput] [1] \"out2:\"\n[ModuleOutput] \n[ModuleOutput]    speed dist\n[ModuleOutput] \n[ModuleOutput] 1:     4    2\n[ModuleOutput] \n[ModuleOutput] 2:     4   10\n[ModuleOutput] \n[ModuleOutput] 3:     7    4\n[ModuleOutput] \n[ModuleOutput] 4:     7   22\n[ModuleOutput] \n[ModuleOutput] 5:     8   16\n[ModuleOutput] \n[ModuleOutput] 6:     9   10\n<\/code><\/pre>\n\n<p>I think I followed the instructions from the documentation correctly.\nHas someone encountered this problem before? Are there any known solutions?<\/p>\n\n<p>Any help would be much appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-09-26 09:08:08.3 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":256,
        "Owner_creation_date":"2014-01-15 14:12:16.837 UTC",
        "Owner_last_access_date":"2022-09-21 12:01:29.24 UTC",
        "Owner_reputation":625,
        "Owner_up_votes":88,
        "Owner_down_votes":3,
        "Owner_views":36,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46422216",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73572304,
        "Question_title":"Frozen training of Keras \/ Tensorflow model",
        "Question_body":"<p>I am training CNN Keras\/TF models in AzureML on GPU compute instance.\nBelow exemplary architecture that I am running:<\/p>\n<pre><code>def define_model_1D_v17():\n   model = Sequential()\n   model.add( Conv1D(256, (5,), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(22, 20)))\n   model.add(Flatten())\n   model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform',))\n   model.add(Dense(1, activation='sigmoid'))\n   opt = Adam(learning_rate=0.0005)\n   model.compile(optimizer=opt, loss='binary_crossentropy ', metrics=['accuracy'])\n   return model\n<\/code><\/pre>\n<p>I observe &quot;non deterministic&quot; problem of &quot;freezing&quot; training procedure.\nMore specifically, some invocations of:<\/p>\n<pre><code>history = model.fit(train_gen, epochs=10, validation_data=test_gen, verbose=1)\n<\/code><\/pre>\n<p>have almost constant loss\/accuracy over batches and epochs (only slightly oscillating).\nExemplary printout is following (first run frozen, second ok):<\/p>\n<pre><code>fold 2 a45db86ea43b5a95a96ef7be349d9f2f\nEpoch 1\/10\n1846\/1846 [==============================] - 50s 27ms\/step - loss: 0.4508 - accuracy: 0.5489 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 2\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 3\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 4\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 5\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 6\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 7\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 8\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 9\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\nEpoch 10\/10\n1846\/1846 [==============================] - 49s 27ms\/step - loss: 0.4508 - accuracy: 0.5492 - val_loss: 0.5220 - val_accuracy: 0.47\n14716\/14716 [==============================] - 26s 2ms\/step\nfold 3 8fa8e37b3c345f05b5aeff167939cc96\nEpoch 1\/10\n1875\/1875 [==============================] - 51s 27ms\/step - loss: 0.1372 - accuracy: 0.8224 - val_loss: 0.0954 - val_accuracy: 0.86\nEpoch 2\/10\n1875\/1875 [==============================] - 50s 27ms\/step - loss: 0.1058 - accuracy: 0.8511 - val_loss: 0.0921 - val_accuracy: 0.87\nEpoch 3\/10\n1875\/1875 [==============================] - 51s 27ms\/step - loss: 0.1038 - accuracy: 0.8539 - val_loss: 0.0944 - val_accuracy: 0.86\nEpoch 4\/10\n1875\/1875 [==============================] - 51s 27ms\/step - loss: 0.1021 - accuracy: 0.8563 - val_loss: 0.0931 - val_accuracy: 0.86\nEpoch 5\/10\n1875\/1875 [==============================] - 51s 27ms\/step - loss: 0.1003 - accuracy: 0.8590 - val_loss: 0.0912 - val_accuracy: 0.87\nEpoch 6\/10\n 1875\/1875 [==============================] - 50s 27ms\/step - loss: 0.0982 - accuracy: 0.8623 - val_loss: 0.0915 - val_accuracy: 0.87\nEpoch 7\/10\n1875\/1875 [==============================] - 51s 27ms\/step - loss: 0.0957 - accuracy: 0.8665 - val_loss: 0.0918 - val_accuracy: 0.87\nEpoch 8\/10\n1875\/1875 [==============================] - 51s 27ms\/step - loss: 0.0924 - accuracy: 0.8723 - val_loss: 0.0928 - val_accuracy: 0.86\nEpoch 9\/10\n1875\/1875 [==============================] - 51s 27ms\/step - loss: 0.0882 - accuracy: 0.8795 - val_loss: 0.0943 - val_accuracy: 0.86\nEpoch 10\/10\n1875\/1875 [==============================] - 51s 27ms\/step - loss: 0.0835 - accuracy: 0.8874 - val_loss: 0.0950 - val_accuracy: 0.86\n<\/code><\/pre>\n<p>I tried both &quot;he_uniform&quot; and default kernel initializer, no effect.<\/p>\n<p>I also monitor RAM usage and is not close to full.<\/p>\n<p>I also checked the predictions that those are actually screwed up, not only the printout.<\/p>\n<p>Interestingly, I also experienced this type of problems in the past on CPU machine (with older version of Keras\/TF).<\/p>\n<p>How to fix\/limit this problem?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2022-09-01 15:54:50.41 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-05 07:44:56.87 UTC",
        "Question_score":0,
        "Question_tags":"python|tensorflow|keras|azure-machine-learning-service",
        "Question_view_count":64,
        "Owner_creation_date":"2019-08-30 07:54:34.137 UTC",
        "Owner_last_access_date":"2022-09-21 14:49:35.58 UTC",
        "Owner_reputation":304,
        "Owner_up_votes":221,
        "Owner_down_votes":1,
        "Owner_views":35,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Krak\u00f3w, Poland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73572304",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64167233,
        "Question_title":"How to modify default docker base image during deployment of Azure Kubernetes service",
        "Question_body":"<p>I have been using DEFAULT_GPU_IMAGE as my base image in Azure ML but now it started throwing the\n<code>ImportError: libGL.so.1: cannot open shared object file: No such file or directory<\/code> error when importing opencv.\nSome answers here on stackoverflow say i need to run apt-get update on the image. specifically:<\/p>\n<pre><code>RUN apt-get update ##[edited] \nRUN apt-get install 'ffmpeg'\\\n'libsm6'\\ \n'libxext6'  -y\n<\/code><\/pre>\n<p>Would you know where can i find the docker file to add the lines to  or is there a way to patch the image during the deployment of the AKS service? (same way as pip and conda packages are possible to be installed during the deployment)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-02 06:51:07.67 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|docker|opencv|kubernetes|azure-machine-learning-service",
        "Question_view_count":148,
        "Owner_creation_date":"2011-12-10 11:29:59.543 UTC",
        "Owner_last_access_date":"2022-09-08 09:27:26.173 UTC",
        "Owner_reputation":548,
        "Owner_up_votes":118,
        "Owner_down_votes":3,
        "Owner_views":55,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Taipei",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64167233",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71057503,
        "Question_title":"Can I set Azure ML output to real JSON using Azure API Management?",
        "Question_body":"<p>I have started using Azure ML to deploy ML service, but it sent results as raw text. I see Azure API Management can use to set outbound body. Can I use it to convert raw text to JSON? and how?<\/p>\n<p>This is an example result from Azure ML WebService.<\/p>\n<pre><code>&quot;{\\&quot;transcript\\&quot;: \\&quot;\\\\u0e27\\\\u0e31\\\\u0e19\\&quot;}&quot;\n<\/code><\/pre>\n<p>Another question, Can I decode UTF-8 in set-body policy?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-09 22:17:50.46 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-10 04:41:59.117 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-api-management|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":76,
        "Owner_creation_date":"2020-04-19 09:04:21.137 UTC",
        "Owner_last_access_date":"2022-08-18 12:43:12.697 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bangkok, Thailand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71057503",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48906201,
        "Question_title":"TypeError: object of type 'numpy.float64' has no len() when finding mean",
        "Question_body":"<p>I am doing a simple operations in Azure ML Studio using Python script.<\/p>\n\n<pre><code>import numpy as np\n\ndt_mean = np.mean(dt.iloc[:,0].values)\n<\/code><\/pre>\n\n<p>but it throws error<\/p>\n\n<pre><code>[Critical]     Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nCaught exception while executing function: Traceback (most recent call last):\n  File \"C:\\server\\invokepy.py\", line 211, in batch\n    xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True)\n  File \"C:\\server\\XDRReader\\xdrutils.py\", line 51, in DataFrameToRFile\n    attributes = XDRBridge.DataFrameToRObject(dataframe)\n  File \"C:\\server\\XDRReader\\xdrbridge.py\", line 40, in DataFrameToRObject\n    if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):\nTypeError: object of type 'numpy.float64' has no len()\nProcess returned with non-zero exit code 1\n<\/code><\/pre>\n\n<p>This one works perfectly fine in Spyder. But it's not working in Azure ML Python script. <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2018-02-21 12:40:30.073 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|mean|azure-machine-learning-studio",
        "Question_view_count":1037,
        "Owner_creation_date":"2017-03-16 06:09:20.42 UTC",
        "Owner_last_access_date":"2022-02-28 05:24:42.01 UTC",
        "Owner_reputation":791,
        "Owner_up_votes":55,
        "Owner_down_votes":4,
        "Owner_views":253,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Planet Earth",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48906201",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":27461432,
        "Question_title":"Cannot connect PlainText (JSON) to Dataset at Azure Machine Learning",
        "Question_body":"<p>I uploaded a PlainText file in a JSON format to the new Azure Machine Learning Studio (studio.azureml.net), but I cannot connect the PlainText object with any module. I get all the time the error message \"Cannot connect PlainText to Dataset...\". <\/p>\n\n<p>At the documentation (<a href=\"http:\/\/help.azureml.net\/Content\/html\/e8219c57-e8dd-4989-9559-bbd73ba5bcea.htm\" rel=\"nofollow\">here<\/a>) is written that \"Plain text can be read and then split up into columns with the help of downstream preprocessing modules.\", but I can't find any downstream preprocessing modules.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2014-12-13 17:07:45.2 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2015-10-30 08:07:34.607 UTC",
        "Question_score":5,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":2157,
        "Owner_creation_date":"2014-08-18 15:14:53.79 UTC",
        "Owner_last_access_date":"2022-02-02 05:52:18.31 UTC",
        "Owner_reputation":53,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p>Actually Azure ML can't process JSON data. It will probably be added in a future update, but the easiest way (in my opinion) to consume that data is to convert it into CSV format. This can be done quickly with Power Query. Then you upload the CSV file as a new dataset.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2014-12-18 16:18:15.8 UTC",
        "Answer_score":6.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/27461432",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37085588,
        "Question_title":"Categorical Variable in EditMetadata module of Azure ML",
        "Question_body":"<p>Could anyone please let me know what is the purpose of making some variable as Categorical in EditMetadata module of Machine Learning? Would appreciate if explained with some example. Also is it applicable on both features as well as label?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-07 07:05:51.65 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":892,
        "Owner_creation_date":"2014-12-22 04:31:22.013 UTC",
        "Owner_last_access_date":"2016-09-01 11:17:01.79 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37085588",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63891547,
        "Question_title":"How to connect AMLS to ADLS Gen 2?",
        "Question_body":"<p>I would like to register a dataset from ADLS Gen2 in my Azure Machine Learning workspace (<code>azureml-core==1.12.0<\/code>). Given that service principal information is not required in the Python SDK <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py#register-azure-data-lake-gen2-workspace--datastore-name--filesystem--account-name--tenant-id-none--client-id-none--client-secret-none--resource-url-none--authority-url-none--protocol-none--endpoint-none--overwrite-false-\" rel=\"noreferrer\">documentation<\/a> for <code>.register_azure_data_lake_gen2()<\/code>, I successfully used the following code to register ADLS gen2 as a datastore:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Datastore\n\nadlsgen2_datastore_name = os.environ['adlsgen2_datastore_name']\naccount_name=os.environ['account_name'] # ADLS Gen2 account name\nfile_system=os.environ['filesystem']\n\nadlsgen2_datastore = Datastore.register_azure_data_lake_gen2(\n    workspace=ws,\n    datastore_name=adlsgen2_datastore_name,\n    account_name=account_name, \n    filesystem=file_system\n)\n<\/code><\/pre>\n<p>However, when I try to register a dataset, using<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Dataset\nadls_ds = Datastore.get(ws, datastore_name=adlsgen2_datastore_name)\ndata = Dataset.Tabular.from_delimited_files((adls_ds, 'folder\/data.csv'))\n<\/code><\/pre>\n<p>I get an error<\/p>\n<blockquote>\n<p>Cannot load any data from the specified path. Make sure the path is accessible and contains data.\n<code>ScriptExecutionException<\/code> was caused by <code>StreamAccessException<\/code>.\nStreamAccessException was caused by AuthenticationException.\n<code>'AdlsGen2-ReadHeaders'<\/code> for '[REDACTED]' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation using this permission.), client request ID &lt;CLIENT_REQUEST_ID&gt;, request ID &lt;REQUEST_ID&gt;. Error message: [REDACTED]\n| session_id=&lt;SESSION_ID&gt;<\/p>\n<\/blockquote>\n<p>Do I need the to enable the service principal to get this to work? Using the ML Studio UI, it appears that the service principal is required even to register the datastore.<\/p>\n<p>Another issue I noticed is that AMLS is trying to access the dataset here:\n<code>https:\/\/adls_gen2_account_name.**dfs**.core.windows.net\/container\/folder\/data.csv<\/code> whereas the actual URI in ADLS Gen2 is: <code>https:\/\/adls_gen2_account_name.**blob**.core.windows.net\/container\/folder\/data.csv<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-14 20:39:51.93 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-09-15 09:03:51.357 UTC",
        "Question_score":7,
        "Question_tags":"python|azure-machine-learning-service|azure-data-lake-gen2",
        "Question_view_count":3331,
        "Owner_creation_date":"2020-05-17 18:00:51.347 UTC",
        "Owner_last_access_date":"2022-06-27 19:36:47.687 UTC",
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":"<p>According to this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#azure-data-lake-storage-generation-2\" rel=\"noreferrer\">documentation<\/a>,you need to enable the service principal.<\/p>\n<p>1.you need to register your application and grant the service principal with <strong>Storage Blob Data Reader access<\/strong>.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/FZl8O.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FZl8O.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>2.try this code:<\/p>\n<pre><code>adlsgen2_datastore = Datastore.register_azure_data_lake_gen2(workspace=ws,\n                                                             datastore_name=adlsgen2_datastore_name,\n                                                             account_name=account_name,\n                                                             filesystem=file_system,\n                                                             tenant_id=tenant_id,\n                                                             client_id=client_id,\n                                                             client_secret=client_secret\n                                                             )\n\nadls_ds = Datastore.get(ws, datastore_name=adlsgen2_datastore_name)\ndataset = Dataset.Tabular.from_delimited_files((adls_ds,'sample.csv'))\nprint(dataset.to_pandas_dataframe())\n<\/code><\/pre>\n<p><strong>Result:<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/50mit.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/50mit.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-09-15 07:41:56.36 UTC",
        "Answer_score":9.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-09-15 10:47:14.147 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63891547",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65597337,
        "Question_title":"filter TabularDataset in azure ML",
        "Question_body":"<p>My Dataset is huge. I am using Azure ML notebooks and using azureml.core to read dateset and convert to azureml.data.tabular_dataset.TabularDataset. Is there anyway i would filter the data in the tabularDataset with out converting to pandas data frame.\nI am using below code to read the data. as the data is huge pandas data-frame is running out of memory. I don't have to load complete data into the program. Only subset is required. is there any way i could filter the records before converting to pandas data frame<\/p>\n<pre><code>def read_Dataset(dataset):\n    ws = Workspace.from_config()\n    ds = ws.datasets\n    tab_dataset = ds.get(dataset)\n    dataframe = tab_dataset.to_pandas_dataframe()\n    return dataframe\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-06 14:11:22.227 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pandas|azure-machine-learning-studio|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":1003,
        "Owner_creation_date":"2020-05-13 19:38:36.837 UTC",
        "Owner_last_access_date":"2022-09-21 10:55:50.367 UTC",
        "Owner_reputation":273,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65597337",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57502236,
        "Question_title":"AML service - web service deployment and security questions",
        "Question_body":"<p>I have questions around Azure ML Service with regards to web service deployment \/ security. Can you please help me with these questions:<\/p>\n\n<ul>\n<li>By default, published web service URIs are public addressable without any requirement for authentication.  What are the best practices for securing these web services?<\/li>\n<li>When authenticating from unattended processes such as web services, DevOps, etc, what are the options \/ best practices for authenticating?\nManaged Identity does not seem to be supported by Azure ML Service.\nApp registrations?\nOther?<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-08-14 21:22:22.793 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":73,
        "Owner_creation_date":"2017-03-10 22:19:35.75 UTC",
        "Owner_last_access_date":"2020-05-06 17:18:52.25 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57502236",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63691515,
        "Question_title":"Azure Machine Learning Studio: cannot create Datastore from Azure SQL Database",
        "Question_body":"<p>I am trying to connect to an Azure SQL Database from inside Azure Machine Learning Studio. Based on <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py<\/a>, it seems that the recommended pattern is to create a Datastore using the Datastore.register_azure_sql_database method as follows:<\/p>\n<pre><code>import os\nfrom azureml.core import Workspace, Datastore\n\nws = Workspace.from_config() # asks for interactive authentication the first time\n\nsql_datastore_name  = &quot;datastore_test_01&quot; # any name should be fine\nserver_name         = os.getenv(&quot;SQL_SERVERNAME&quot;    , &quot;{SQL_SERVERNAME}&quot;) # Name of the Azure SQL server\ndatabase_name       = os.getenv(&quot;SQL_DATABASENAME&quot;  , &quot;{SQL_DATABASENAME}&quot;) # Name of the Azure SQL database\nusername            = os.getenv(&quot;SQL_USER_NAME&quot;     , &quot;{SQL_USER_NAME}&quot;) # The username of the database user.\npassword            = os.getenv(&quot;SQL_USER_PASSWORD&quot; , &quot;{SQL_USER_PASSWORD}&quot;) # The password of the database user.\n\nsql_datastore = Datastore.register_azure_sql_database(workspace      = ws,\n                                                      datastore_name = sql_datastore_name,\n                                                      server_name    = server_name,\n                                                      database_name  = database_name,\n                                                      username       = username,\n                                                      password       = password)\n<\/code><\/pre>\n<p>I am pretty sure I have set all parameters right, having copied them from the ADO.NET connection string at my SQL Database resource --&gt; Settings --&gt; Connection strings:<\/p>\n<pre><code>Server=tcp:{SQL_SERVERNAME}.database.windows.net,1433;Initial Catalog={SQL_DATABASENAME};Persist Security Info=False;User ID={SQL_USER_NAME};Password={SQL_USER_PASSWORD};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;\n<\/code><\/pre>\n<p>However, I get the following error:<\/p>\n<pre><code>Registering datastore failed with a 400 error code and error message 'Azure SQL Database Error -2146232060: Please check the correctness of the datastore information.'\n<\/code><\/pre>\n<p>Am I missing something? E.g., a firewall rule? I have also tried adding the Azure ML compute resource's public IP address to the list of allowed IP addresses in my SQL Database resource, but still no success.<\/p>\n<hr \/>\n<p><strong>UPDATE<\/strong>: adding <code>skip_validation = True<\/code> to <code>Datastore.register_azure_sql_database<\/code> solves the issue. I can then query the data with<\/p>\n<pre><code>from azureml.core import Dataset\nfrom azureml.data.datapath import DataPath\n\nquery   = DataPath(sql_datastore, 'SELECT * FROM my_table')\ntabular = Dataset.Tabular.from_sql_query(query, query_timeout = 10)\ndf = tabular.to_pandas_dataframe()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-01 16:13:13.243 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-09-02 07:46:58.923 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-sql-database|azure-machine-learning-studio|azure-machine-learning-service|azure-sdk-python",
        "Question_view_count":793,
        "Owner_creation_date":"2017-08-11 12:35:17.96 UTC",
        "Owner_last_access_date":"2021-01-27 09:52:25.2 UTC",
        "Owner_reputation":132,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":"<p>is the datastore behind vnet? where are you running the registration code above? On a compute instance behind the same vnet?\nhere is the doc that describe what you need to do to connect to data behind vnet:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#use-datastores-and-datasets\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#use-datastores-and-datasets<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-09-01 16:53:06.26 UTC",
        "Answer_score":2.0,
        "Owner_location":"Milano, MI, Italia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63691515",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70927461,
        "Question_title":"Azureml ignore environment variables in condas env.yml",
        "Question_body":"<p>I am configuring an Environment in azureml based on a conda enviroment file.\nThe azureml environment seems to be ignoring the enviromnet variables however.<\/p>\n<pre><code>from azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\n\nCondaDependencies._VALID_YML_KEYS.append(&quot;variables&quot;)\npipeline_env = Environment.from_conda_specification(&quot;pipeline_env&quot;, &quot;env.yml&quot;)\nprint(pipeline_env.environment_variables)\n<\/code><\/pre>\n<p>This results in the following being printed.<\/p>\n<pre><code>{'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}\n<\/code><\/pre>\n<p>My env.yml contain the follow section at the bottom<\/p>\n<pre><code>variables:\n- KEY_ONE: 1.1.0.1\n- KEY_TWO: 1.1.0.1\n<\/code><\/pre>\n<p>And if i save my environment to directory like this<\/p>\n<pre><code>pipeline_env.save_to_directory(&quot;env&quot;)\n<\/code><\/pre>\n<p>it produces a folder named &quot;env&quot; which contain two files.<\/p>\n<ul>\n<li>conda_dependencies.yml<\/li>\n<li>azureml_environment.json<\/li>\n<\/ul>\n<p>In the azureml_environment i can see that my two keys do <strong>not<\/strong> exist.\nThey do however exist in the conda_dependancies.yml which indicate to me that they are correctly defined in the env.yml file.<\/p>\n<p>I also had to add the &quot;varialbes&quot; key as a valid yml key as shown, if not azureml threw an error.<\/p>\n<p>I am starting to suspect that azureml does not allow this method of setting the environment variables, and that the only way to set them correctly is to use the following method:<\/p>\n<pre><code> pipeline_env.environment_variables = {&quot;KEY_ONE&quot;, &quot;1.1.0.1&quot;,\n                                       &quot;KEY_TWO&quot;, &quot;1.1.0.1&quot;)\n<\/code><\/pre>\n<p>As this does work, i would prefer to use the .yml file however.\nSo i guess my question is: <strong>Should i be able to set environment variables using the .yml file, or is my assumption correct that i have to use the enviroment_variables function?<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-31 14:14:59.807 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":214,
        "Owner_creation_date":"2015-07-22 12:57:19.603 UTC",
        "Owner_last_access_date":"2022-03-21 08:35:07.183 UTC",
        "Owner_reputation":1186,
        "Owner_up_votes":128,
        "Owner_down_votes":31,
        "Owner_views":133,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Norway",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70927461",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72641789,
        "Question_title":"Azure Machine Learning workspace's storage account permission issue",
        "Question_body":"<p>Was working on az ml cli v2 to deploy real-time endpoint with command <code>az ml online-deployment<\/code> through Azure pipeline. had double confirmed that the service connection used in this pipeline task had added the permissions below in Azure Portal but still showing the same error.<\/p>\n<pre><code>ERROR: Error with code: You don't have permission to alter this storage account. Ensure that you have been assigned both Storage Blob Data Reader and Storage Blob Data Contributor roles.\n<\/code><\/pre>\n<p>Using the same service connection, we are able to perform the creation of online endpoint with <code>az ml online-endpoint create<\/code> in the same and other workspaces.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-16 07:10:03.56 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-devops|azure-storage|azure-machine-learning-service",
        "Question_view_count":129,
        "Owner_creation_date":"2019-09-11 07:07:53.007 UTC",
        "Owner_last_access_date":"2022-09-15 16:01:06.153 UTC",
        "Owner_reputation":383,
        "Owner_up_votes":70,
        "Owner_down_votes":1,
        "Owner_views":35,
        "Answer_body":"<p>Issue was resolved. I did not change anything in the service principal and running it on second day using same yml got through the issue. I guess there might be some propagation issue, but longer than usual.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-17 01:37:08.623 UTC",
        "Answer_score":0.0,
        "Owner_location":"Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72641789",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56393818,
        "Question_title":"How to retrieve auth keys for an ACI deployment in Azure Portal (or Cloud Shell)?",
        "Question_body":"<p>I have created a <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#aci\" rel=\"nofollow noreferrer\">deployment on ACI with Azure ML service<\/a>, and its status is healthy.<br>\nWhen deploying, I set <code>auth_enabled=True<\/code>, so that the service requires authorization keys to respond.<\/p>\n\n<p>I can get the service auth keys for that deployment in my Azure ML service workspace <code>ws<\/code> in a Python console via<\/p>\n\n<pre><code>from azureml.core.webservice import Webservice\nservices = Webservice.list(ws)\nservices[0].get_keys()\n<\/code><\/pre>\n\n<p>However, it would be convenient to access to this information through Azure Portal or the Cloud Shell. <\/p>\n\n<p>In Azure Portal (differently to what happens for AKS) there's no auth fields shown, also when accessing Advanced Settings by trying to edit the deployment:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/3Qudh.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3Qudh.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Can you suggest ways to access those credentials?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-31 10:58:22.887 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-05-31 17:32:04.667 UTC",
        "Question_score":0,
        "Question_tags":"azureportal|azure-aks|azure-container-instances|azure-cloud-shell|azure-machine-learning-service",
        "Question_view_count":169,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Verona, VR, Italy",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56393818",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41416908,
        "Question_title":"How to develop people count of office?",
        "Question_body":"<p>I would like to count how many persons are in 1) conference room and 2) Office for 100 persons. I would like to have bar graph for room or office occupancy.<\/p>\n\n<p>I learned from vendor like Viametrics that camera like thermal camera must be installed to roof outside of conference room to count in and out of traffic. It seem regular camera can be used or some kind of mats as well.<\/p>\n\n<p>I tried Azure Cognitive Emotion API for people counting, but it is reliable only if camera sees whole face. Result of experiment was that we cannot use Emotion API.<\/p>\n\n<p>I would like to know that if I had camera and RaspBerry(or Arduino) plus Azure or Bluemix or VM, how to build people counting solution. Do you know any library or API? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-01-01 16:17:30.873 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"image-processing|machine-learning|azure-machine-learning-studio",
        "Question_view_count":426,
        "Owner_creation_date":"2016-11-04 09:17:30.693 UTC",
        "Owner_last_access_date":"2022-09-22 08:39:28.943 UTC",
        "Owner_reputation":1519,
        "Owner_up_votes":116,
        "Owner_down_votes":0,
        "Owner_views":375,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Finland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41416908",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38077884,
        "Question_title":"Can Azure calculate confidence interval for regressions?",
        "Question_body":"<p>I plan to try different regression methods provided by Azure ML Studio to predict numeric values. I wonder if it is possible to get the predictions together with corresponding confidence intervals. In other words, I would like the regression function to tell me not only the expected value (prediction) but also how confident it (the model) is about this value. Does Azure regression support this functionality?<\/p>\n\n<p><strong>ADDED<\/strong><\/p>\n\n<p>A related question. Can build in \"regressors\" estimate probability density functions? For example for a given case (a row in a data table) I would like to have not only a single number as a prediction (expected value) but also probabilities of all possible values.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-28 13:40:49.227 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-06-28 14:19:10.237 UTC",
        "Question_score":1,
        "Question_tags":"azure|regression|confidence-interval|azure-machine-learning-studio",
        "Question_view_count":332,
        "Owner_creation_date":"2010-01-07 13:20:49.817 UTC",
        "Owner_last_access_date":"2022-05-17 14:56:51.04 UTC",
        "Owner_reputation":116085,
        "Owner_up_votes":820,
        "Owner_down_votes":37,
        "Owner_views":4661,
        "Answer_body":"<p>Currently, you will have to use R or python within Azure ML for confidence interval <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-06-30 06:29:36.063 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38077884",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72983144,
        "Question_title":"azureml tabular dataset over azure gen2 datalake",
        "Question_body":"<h1>What have I tried<\/h1>\n<ul>\n<li>set up an AzureML DataStore using Identity based authentication<\/li>\n<li>set up an AzureML Dataset for a single file under a specific file system<\/li>\n<\/ul>\n<pre class=\"lang-py prettyprint-override\"><code>\n    workspace = Workspace.from_config(&quot;config.json&quot;, auth= auth)\n    dataset = Dataset.get_by_name(workspace, 'engage_event_type')\n    frame = dataset.to_pandas_dataframe()\n<\/code><\/pre>\n<p>I am able to explore the dataset from azure portal and it displays the right data correctly.<\/p>\n<p>However running ^ where <code>auth<\/code> is a Service Principal which has the same rights as Azure Workspace Instance I get a bunch of calls like, but no errors \/ exceptions \/ completion.<\/p>\n<p>The data underneath is &lt; 10kb<\/p>\n<pre><code>Resolving access token for scope &quot;https:\/\/datalake.azure.net\/\/.default&quot; using identity of type &quot;SP&quot;.\nResolving access token for scope &quot;https:\/\/datalake.azure.net\/\/.default&quot; using identity of type &quot;SP&quot;.\n<\/code><\/pre>\n<ul>\n<li>I have tried running the script on a local compute<\/li>\n<li>I have tried running the script on a compute instance<\/li>\n<\/ul>\n<p>both gave the same issue<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-14 15:35:16.327 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":431,
        "Owner_creation_date":"2010-04-12 17:27:26.887 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:17.55 UTC",
        "Owner_reputation":9826,
        "Owner_up_votes":1723,
        "Owner_down_votes":15,
        "Owner_views":1238,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72983144",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":31838017,
        "Question_title":"Access GlobalParameters in Azure ML Python script",
        "Question_body":"<p>How can one access the global parameters (\"GlobalParameters\") sent from a web service in a Python script on Azure ML?<\/p>\n\n<p>I tried:<\/p>\n\n<pre><code>if 'GlobalParameters' in globals():\n    myparam = GlobalParameters['myparam']\n<\/code><\/pre>\n\n<p>but with no success. <\/p>\n\n<h2>EDIT: Example<\/h2>\n\n<p>In my case, I'm sending a sound file over the web service (as a list of samples). I would also like to send a sample rate and the number of bits per sample. I've successfully configured the web service (I think) to take these parameters, so the GlobalParameters now look like:<\/p>\n\n<pre><code>\"GlobalParameters\": {\n     \"sampleRate\": \"44100\",\n     \"bitsPerSample\": \"16\",\n}\n<\/code><\/pre>\n\n<p>However, I cannot access these variables from the Python script, neither as <code>GlobalParameters[\"sampleRate\"]<\/code> nor as <code>sampleRate<\/code>. Is it possible? Where are they stored?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_date":"2015-08-05 16:27:15.673 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-08-07 17:05:09.633 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":673,
        "Owner_creation_date":"2010-02-19 16:12:07.52 UTC",
        "Owner_last_access_date":"2021-10-11 05:53:43.067 UTC",
        "Owner_reputation":7681,
        "Owner_up_votes":284,
        "Owner_down_votes":8,
        "Owner_views":361,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/31838017",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61168984,
        "Question_title":"Azure ML free trial: how to submit pipeline?",
        "Question_body":"<p>I'm using a free trial account on MS Azure and I'm following this tutorial.<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score<\/a><\/p>\n\n<p>I'm stuck when I try to \"submit the pipeline\".<\/p>\n\n<p>The reason seems to be that I can't create a compute instance or a training cluster on a free plan.\nI still have 200USDs of free credits. I guess there must be a solution?<\/p>\n\n<hr>\n\n<p>Error messages:<\/p>\n\n<pre><code>Invalid graph: The pipeline compute target is invalid.\n\n400: Compute Test3 in state Failed, which is not able to use\n\nCompute instance: creation failed\nThe specified subscription has a total vCPU quota of 0 and is less than the requested compute training cluster and\/or compute instance's min nodes of 1 which maps to 4 vCPUs\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-12 08:54:46.103 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-04-12 11:18:01.397 UTC",
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":370,
        "Owner_creation_date":"2012-07-30 21:09:03.65 UTC",
        "Owner_last_access_date":"2022-06-23 06:47:02.477 UTC",
        "Owner_reputation":135,
        "Owner_up_votes":51,
        "Owner_down_votes":0,
        "Owner_views":45,
        "Answer_body":"<p>Please check the announcement from MS Team regarding this:<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/blog\/our-commitment-to-customers-and-microsoft-cloud-services-continuity\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/blog\/our-commitment-to-customers-and-microsoft-cloud-services-continuity\/<\/a><\/p>\n\n<p>All the free trials will not work as of now<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-04-12 08:55:59.587 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61168984",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68778097,
        "Question_title":"Get current workspace from inside a AzureML Pipeline step",
        "Question_body":"<p>I'm using the Python SDK.<\/p>\n<p>I assume there is a way to get a handle to the workspace on which the <code>PythonScriptStep<\/code> is running from inside the <code>PythonScriptStep<\/code> but I can't find it.<\/p>\n<p>Any idea how this can be achieved?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-13 20:35:17.863 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":500,
        "Owner_creation_date":"2012-01-26 14:27:40.553 UTC",
        "Owner_last_access_date":"2022-09-24 16:26:41.58 UTC",
        "Owner_reputation":802,
        "Owner_up_votes":288,
        "Owner_down_votes":0,
        "Owner_views":91,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68778097",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59143762,
        "Question_title":"Is it supported to create an integrated notebookVM when the workspace is configured to be in a VNET?",
        "Question_body":"<p>Trying to follow doc at <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-enable-virtual-network#use-a-machine-learning-compute\" rel=\"nofollow noreferrer\">secure your experiments<\/a> but after configuring default workspace storage for VNET access,  attempts to create integrated notebook VM fails with what looks like a storage access error.\n\ueb90\nCreate Failed: \nFailed to clone samples. Error details: Microsoft.WindowsAzure.Storage This request is not authorized to perform this operation.<\/p>\n\n<p>thanks,\njim<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-12-02 17:17:23.767 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-12-02 17:19:26.703 UTC",
        "Question_score":1,
        "Question_tags":"jupyter-notebook|azure-machine-learning-service|vnet",
        "Question_view_count":36,
        "Owner_creation_date":"2019-12-02 17:01:19.827 UTC",
        "Owner_last_access_date":"2019-12-03 13:06:26.62 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59143762",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70187397,
        "Question_title":"How do I create a DatatSet with Data Type: ModelDirectory in Azure Machine Learning Studio?",
        "Question_body":"<p>I'm attempting to manually create a DataSet with Data Type: ModelDirectory in Azure Machine Learning Studio, in order to use it in an Inference Pipeline.  I have taken an existing ModelDirectory DataSet and attempted to replicate it.  Everything is identical, <em>except<\/em> that the replica has Data Type:  AnyDirectory, and can not be hooked up to the input of a ScoreModel node in the designer.  How can I (manually in the UI or, better yet, programmatically) create a DataSet with Data Type: ModelDirectory from the output files of a trained model?<\/p>\n<p>Existing DataSet:\n<a href=\"https:\/\/i.stack.imgur.com\/56g9x.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/56g9x.png\" alt=\"enter image description here\" \/><\/a>\nExisting DataSet outputs:\n<a href=\"https:\/\/i.stack.imgur.com\/0aBSc.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0aBSc.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Manually Created Replica DataSet:\n<a href=\"https:\/\/i.stack.imgur.com\/DiQdp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DiQdp.png\" alt=\"enter image description here\" \/><\/a>\nManually Created Replica DataSet outputs:\n<a href=\"https:\/\/i.stack.imgur.com\/DIYFY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DIYFY.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>As you can see, the outputs of both DataSets are <em>identical<\/em>.  The only difference between the two DataSets, seems to be the 'Data Type' properties, although in the output view, you can see that both have 'type: ModelDirectory'.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-01 15:59:27.86 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":80,
        "Owner_creation_date":"2012-06-27 21:51:16.13 UTC",
        "Owner_last_access_date":"2022-09-21 21:19:20.11 UTC",
        "Owner_reputation":751,
        "Owner_up_votes":68,
        "Owner_down_votes":5,
        "Owner_views":73,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70187397",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36763479,
        "Question_title":"How to tell the learner type of machine learning models",
        "Question_body":"<p>It is my first time to use Azure Machine Learning...<\/p>\n\n<p>When I have trained 2 models using the same training data and testing data, when it comes to evaluate model, it shows error<\/p>\n\n<blockquote>\n  <p>All models must have the same learner type<\/p>\n<\/blockquote>\n\n<p>Do you know what is \"learner type\" of machine learning models and how to tell the learner type of a model?<\/p>\n\n<p>Below is the screenshot of my basic practice on Azure Machine Learning:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/plx4V.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/plx4V.png\" alt=\"Azure Machine Learning practice\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2016-04-21 08:05:39.707 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":516,
        "Owner_creation_date":"2013-02-19 02:19:40.857 UTC",
        "Owner_last_access_date":"2022-09-22 18:09:08.467 UTC",
        "Owner_reputation":3349,
        "Owner_up_votes":865,
        "Owner_down_votes":1,
        "Owner_views":465,
        "Answer_body":"<p>The models you compare should be of the same type - binary classification, regression, multi-class classification etc. For example, you can't compare effectiveness of linear regression to the effectiveness of logistics regression. They solve absolutely different tasks.<\/p>\n\n<p>This is the case for you - you try to compare linear regression (which outputs real value) with the multiclass decision forest, which tries to classify input to some class.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-04-21 14:31:25.857 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36763479",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39190415,
        "Question_title":"How can I use Bokeh in an Azure ML notebook",
        "Question_body":"<p>I can run the following code in a Jupyter notebook (Python 3.5) on my PC using Anaconda, and it works fine. But when I run the same code in an Azure ML notebook, I get the plot, but also the error message described below. Does anyone know how to use Bokeh in Azure ML notebooks ? Is there perhaps a way to import the seemingly missing module 'ipykernel'<\/p>\n\n<pre><code>from bokeh.plotting import figure, show, output_notebook\nfrom bokeh.sampledata.iris import flowers\n\ncolormap = {'setosa': 'red', 'versicolor': 'green', 'virginica': 'blue'}\ncolors = [colormap[x] for x in flowers['species']]\n\np = figure(title = \"Iris Morphology\")\np.xaxis.axis_label = 'Petal Length'\np.yaxis.axis_label = 'Petal Width'\n\np.circle(flowers[\"petal_length\"], flowers[\"petal_width\"],\n     color=colors, fill_alpha=0.2, size=10)\n\noutput_notebook()\nshow(p)\n<\/code><\/pre>\n\n<p>produces the plot, but also the following errors<\/p>\n\n<pre><code>---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n&lt;ipython-input-17-c50d1a94007e&gt; in &lt;module&gt;()\n 13 \n 14 output_notebook()\n---&gt; 15 show(p)\n\n\/home\/nbuser\/env3\/lib\/python3.4\/site-packages\/bokeh\/io.py in show(obj,        browser, new)\n    299 \n    300     '''\n--&gt; 301     return _show_with_state(obj, _state, browser, new)\n    302 \n    303 def _show_with_state(obj, state, browser, new):\n\n\/home\/nbuser\/env3\/lib\/python3.4\/site-packages\/bokeh\/io.py in     _show_with_state(obj, state, browser, new)\n    307 \n    308     if state.notebook:\n--&gt; 309         comms_handle = _show_notebook_with_state(obj, state)\n    310 \n    311     elif state.server_enabled:\n\n\/home\/nbuser\/env3\/lib\/python3.4\/site-packages\/bokeh\/io.py in     _show_notebook_with_state(obj, state)\n    329         comms_target = make_id()\n    330         publish_display_data({'text\/html': notebook_div(obj,   comms_target)})\n--&gt; 331         handle = _CommsHandle(get_comms(comms_target), state.document,     state.document.to_json())\n    332         state.last_comms_handle = handle\n    333         return handle\n\n\/home\/nbuser\/env3\/lib\/python3.4\/site-packages\/bokeh\/util\/notebook.py in   get_comms(target_name)\n    109 \n    110     '''\n--&gt; 111     from ipykernel.comm import Comm \n    112     return Comm(target_name=target_name, data={})\n    113 \n\nImportError: No module named 'ipykernel'\n\nIn [16]:\n<\/code><\/pre>\n\n<p>\u200b<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-08-28 10:39:24.853 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure|jupyter-notebook|bokeh|azure-machine-learning-studio",
        "Question_view_count":575,
        "Owner_creation_date":"2016-01-16 08:33:09.997 UTC",
        "Owner_last_access_date":"2020-10-04 08:40:30.297 UTC",
        "Owner_reputation":36,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Oslo, Norway",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39190415",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70126843,
        "Question_title":"Create data container via Azure Machine learning REST API",
        "Question_body":"<p>I understand API is in preview but maybe someone can help me out here .<\/p>\n<p>I am trying to create <code>Data container<\/code> as its described in <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/data-containers\/create-or-update#datacontainer\" rel=\"nofollow noreferrer\">AML REST API<\/a><\/p>\n<pre><code>curl --location --request PUT 'https:\/\/management.azure.com\/subscriptions\/{{subscriptionId}}\/resourceGroups\/{{resourceGroupName}}\/providers\/Microsoft.MachineLearningServices\/workspaces\/{{workspaceName}}\/data\/abc?api-version=2021-03-01-preview' \\\n--header 'Authorization: Bearer ' \\\n--header 'Content-Type: application\/json' \\\n--data-raw '{&quot;properties&quot;: { &quot;description&quot;: &quot;string&quot;,\n&quot;tags&quot;: { },\n&quot;properties&quot;: {}\n}\n}'\n<\/code><\/pre>\n<p>I receive <code>400<\/code> status code with message<\/p>\n<pre><code>Error setting value to 'Description' on 'Microsoft.MachineLearning.ManagementFrontEnd.Contracts.V20210301Preview.Assets.DataContainer'.&quot;\n<\/code><\/pre>\n<p>after removing Description which should be optional<\/p>\n<pre><code>DataContainers_CreateOrUpdate is not supported\n<\/code><\/pre>\n<p>How can I create Dataset with local files? I cannot use UI. There it works and I can receive it with GET list method.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-26 15:39:00.327 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|curl|azure-machine-learning-service",
        "Question_view_count":132,
        "Owner_creation_date":"2013-01-22 14:57:30.523 UTC",
        "Owner_last_access_date":"2022-09-23 08:13:32.32 UTC",
        "Owner_reputation":720,
        "Owner_up_votes":438,
        "Owner_down_votes":1,
        "Owner_views":133,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Switzerland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70126843",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62571695,
        "Question_title":"AzureML Model.profile() timeout without ever running the model",
        "Question_body":"<p>When trying to profile our AzureML model we run into a timeout. According to the log statements, <strong>the model is initialized<\/strong> but the <strong>run function is never called<\/strong>.<\/p>\n<p>The dataset provided contains one column (&quot;profile_requests&quot;) and 100 samples of serialized json that the model usually consumes. Both model and score.py work fine when deploying via Model.deploy (see below).<\/p>\n<p>Why is the run function never called?<\/p>\n<pre><code>profile = Model.profile(ws, \n    profile_name='my-profile-name',\n    models=[latest_model], \n    inference_config=InferenceConfig(\n                                    entry_script='score.py', \n                                    source_directory=&quot;deployment&quot;,\n                                    environment=Environment.get(ws, &quot;my_environment&quot;)), \n    input_dataset=processed_dataset,\n    cpu=2,\n    memory_in_gb=3)\n<\/code><\/pre>\n<pre><code>{...,\n 'error': {'code': 'ModelTestTimeOut',\n  'statusCode': 500,\n  'message': 'The model did not finish the test within the allowed time: 30 min. Error logs URL: https:\/\/link-to-logfile',\n  'details': []},\n 'errorLogsUri': 'https:\/\/link-to-logfile'}\n<\/code><\/pre>\n<p>Profiling log file:<\/p>\n<pre><code>==========Logs from model deployed to container with 2 cpu and 3 GB memory==========\n[...]\nInvoking user's init function\nModel loaded.\nUsers's init has completed successfully\nScoring timeout setting is not found. Use default timeout: 3600000 ms\n<\/code><\/pre>\n<p>One sample from the DataFrame (<code>sample_event=processed_dataset.to_pandas_dataframe().loc[0,&quot;profile_requests&quot;]<\/code>)<\/p>\n<pre><code>'{&quot;allevents&quot;: [{&quot;temperature&quot;: 103.76252626686478, &quot;ambienttemperature&quot;: 20.763083531178108, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:02&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 104.00700291712167, &quot;ambienttemperature&quot;: 20.77088671236806, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:07&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.73538818128196, &quot;ambienttemperature&quot;: 20.927115571418366, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:12&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.26993925975171, &quot;ambienttemperature&quot;: 20.977784248757075, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:17&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.47584351197627, &quot;ambienttemperature&quot;: 20.528207412934027, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:22&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.53497833736942, &quot;ambienttemperature&quot;: 21.176729435416277, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:27&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.33621482217512, &quot;ambienttemperature&quot;: 21.083552645791112, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:32&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.13542993745558, &quot;ambienttemperature&quot;: 20.80351544511668, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:37&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.45331951321728, &quot;ambienttemperature&quot;: 21.404335822865523, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:42&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.52506972734126, &quot;ambienttemperature&quot;: 20.51882900857312, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:47&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.61395300883524, &quot;ambienttemperature&quot;: 21.110307039511532, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:52&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.49871551548077, &quot;ambienttemperature&quot;: 21.133206947070178, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:57&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}]}'\n<\/code><\/pre>\n<p>Running the sample against the deployed webservice that uses the same environment and score.py <code>service.run(sample_event)<\/code> works as expected.<\/p>\n<pre><code>{'result': False,\n 'ConnectionDeviceId': 'milkbottleEdge',\n 'timeCreatedStart': '2020-04-02T12:07:02',\n 'timeCreatedEnd': '2020-04-02T12:07:57',\n 'hasError': False,\n 'errorMessage': None}\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-25 09:03:04.063 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":176,
        "Owner_creation_date":"2020-03-20 14:42:07.427 UTC",
        "Owner_last_access_date":"2021-08-19 12:58:38.267 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Hamburg, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62571695",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65349712,
        "Question_title":"How to install Jupyter extensions on Azure Machine Learning Notebooks?",
        "Question_body":"<p>I created a virtual machine on Azure Machine Learning and I'm running a simple jupyter notebook. I would like to install the jupyter extensions since I really need the collapsible titles but it seem it isn't working. I tried with pip install and it's already installed but the menu does not appear...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-17 23:17:51.16 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|jupyter-notebook|azure-machine-learning-studio",
        "Question_view_count":320,
        "Owner_creation_date":"2020-03-17 01:48:16.707 UTC",
        "Owner_last_access_date":"2022-09-15 01:18:42.977 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Switzerland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65349712",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47281734,
        "Question_title":"Azure ML Web Service + Python for Querying Pandas Data Frame",
        "Question_body":"<p>I want to use Azure ML Web Service for a non machine learning task with Python. The goal is the following:<\/p>\n\n<p>I have a Pandas DF like this:<\/p>\n\n<pre><code>   Id   Value\n0  111  0.1\n1  222  7.3\n2  333  3.1\n3  444  5.0\n<\/code><\/pre>\n\n<p>I can query this DF successfully (what is the value of a certain row by Id?):<\/p>\n\n<pre><code>float(df.loc[pot['Id'] == 222, 'Value'])\n<\/code><\/pre>\n\n<p>Now, I want to deploy a function in Azure ML Web Service with this functionality where a function uses an uploaded data set as fix lookup table. I constructed the function which gets an Id number as argument, looks for the value in the pre-uploade dataset and gives it back as a float:<\/p>\n\n<pre><code>from azureml import services\nimport pandas as pd\n\n@services.publish(workspace_id, workspace_token)\n@services.types(id=int)\n@services.returns(float)\ndef my_func(id):\n    my_df = ws.datasets[\"uploaded_df.csv\"].to_dataframe()\n    return float(my_df.loc[cent['Id'] == id, 'Value'])\n<\/code><\/pre>\n\n<p>I can deploy it on Azure Web Services but when I try to run a test query It gets stuck (no way even to peep into the details). What is the problem here?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-11-14 09:13:44.677 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":428,
        "Owner_creation_date":"2016-06-24 18:19:52.047 UTC",
        "Owner_last_access_date":"2022-07-19 04:30:48.127 UTC",
        "Owner_reputation":1078,
        "Owner_up_votes":12,
        "Owner_down_votes":1,
        "Owner_views":90,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47281734",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72218563,
        "Question_title":"Azure ML: how to change the \"cluster purpose\" of an existing inference cluster from \"dev_test\" to \"production\"?",
        "Question_body":"<p>I have a cluster whose &quot;cluster_purpose&quot; was set to &quot;dev_test&quot;. I want to change it to &quot;production&quot;. Couldn't find anything in the documentation.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-12 15:45:22.527 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":32,
        "Owner_creation_date":"2014-12-18 15:16:56.597 UTC",
        "Owner_last_access_date":"2022-09-23 16:12:30.223 UTC",
        "Owner_reputation":1572,
        "Owner_up_votes":33,
        "Owner_down_votes":5,
        "Owner_views":59,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Palermo, PA, Italia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72218563",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48158545,
        "Question_title":"How to execute multiple rows in web service Azure Machine Learning Studio",
        "Question_body":"<p>I create a model in Azure ML studio. \nI deployed the web service.<\/p>\n\n<p>Now, I know how to check one record at a time, but how can I load a csv file and made the algorithm go through all records ?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/1tHuM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/1tHuM.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>If I click on Batch Execution - it will ask me to create an account for Azure storage. <\/p>\n\n<p>Is any way to execute multiple records from csv file without creating any other accounts?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/90zP7.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/90zP7.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-01-08 21:47:45.933 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|ml-studio",
        "Question_view_count":204,
        "Owner_creation_date":"2016-03-10 08:00:45.393 UTC",
        "Owner_last_access_date":"2022-09-23 23:59:58.457 UTC",
        "Owner_reputation":4046,
        "Owner_up_votes":505,
        "Owner_down_votes":7,
        "Owner_views":825,
        "Answer_body":"<p>Yes, there is a way and it is simple. What you need is an excel add-in. You need not create any other account.<\/p>\n\n<p>You can either read <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/excel-add-in-for-web-services\" rel=\"nofollow noreferrer\">Excel Add-in for Azure Machine Learning web services doc<\/a> or you can watch <a href=\"https:\/\/www.youtube.com\/watch?v=ju1CzDjiOMQ\" rel=\"nofollow noreferrer\">Azure ML Excel Add-in video<\/a>. <\/p>\n\n<p>If you search for <a href=\"https:\/\/www.google.co.in\/search?q=excel%20add%20in%20for%20azure%20ml&amp;client=firefox-b-ab&amp;dcr=0&amp;source=lnms&amp;tbm=vid&amp;sa=X&amp;ved=0ahUKEwinqP3a_67ZAhXBr48KHdiYAXUQ_AUICigB&amp;biw=1280&amp;bih=616\" rel=\"nofollow noreferrer\">videos on excel add in for azure ml<\/a>, you get other useful videos too. <\/p>\n\n<p>I hope this is the solution you are looking for.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-02-18 08:10:29.767 UTC",
        "Answer_score":1.0,
        "Owner_location":"San Diego, CA, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48158545",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73411852,
        "Question_title":"Issue with data lake mounting in custom RStudio application Azure ML",
        "Question_body":"<ol>\n<li>previously while creating a compute instance  we were able to see RStudio application by default and we were able to mount\/access the data lake from RStudio.<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/J17ne.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/J17ne.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3l8Q4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3l8Q4.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"2\">\n<li>In current situation we are not able to access RStudio application by default.<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/nx5GL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/nx5GL.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"3\">\n<li>with the help of below link we are able to create custom RStudio application<\/li>\n<\/ol>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/flQyy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/flQyy.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>4.In custom RStudio we are not able to mount\/access the data lake.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2dWL9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2dWL9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Is there way to mount\/access the data lake in custom RStudio app<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-08-19 04:30:31 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-23 15:38:07.767 UTC",
        "Question_score":0,
        "Question_tags":"r|azure|installation|azure-machine-learning-studio|rstudio-server",
        "Question_view_count":71,
        "Owner_creation_date":"2022-06-15 09:26:58.33 UTC",
        "Owner_last_access_date":"2022-09-22 12:13:16.827 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Pune",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73411852",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37728314,
        "Question_title":"Refactor columns and features in Azure Machine Learning",
        "Question_body":"<p>Is there any way I can make my dataset features in Azure ML into something else than what it already is? <\/p>\n\n<p>I found a dataset of the Titanic ship in the sample datasets which I would like to work with but all of my columns are either a numeric feature or string feature, but I would like to categorize these. Also is there any possibility to rename the columns within my model so it\u2019s more descriptive than what I initially got? I have no clue what SibSp means for instance.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-09 14:08:01.33 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-06-15 07:52:59.12 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":297,
        "Owner_creation_date":"2016-06-07 19:08:35.433 UTC",
        "Owner_last_access_date":"2016-06-16 07:03:45.923 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>What you are doing is essentially recreating this experiment made by Raja Iqbal for the Titanic dataset. I recommend you check that out here: <a href=\"http:\/\/gallery.cortanaintelligence.com\/Experiment\/Tutorial-Building-a-classification-model-in-Azure-ML-8?share=1\" rel=\"nofollow noreferrer\">http:\/\/gallery.cortanaintelligence.com\/Experiment\/Tutorial-Building-a-classification-model-in-Azure-ML-8?share=1<\/a><\/p>\n\n<p>To answer your question, the module you can drag to your canvas in order to make the features into categories; is the Edit Metadata module where you select the columns you want and change the \u201cunchanged\u201d into \u201cMake categorical\u201d within the Categorical-properties pane like in the image below:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/2NDht.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2NDht.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>You can also use the same module to make better sense from your columns by giving them a different column name. SibSp means SiblingSpouse like I have renamed it to in the image below:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Gm9Rr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Gm9Rr.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And at last you can assign the targeted value (survived) and make the field into a label for ease of use.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LyN0j.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LyN0j.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-06-09 14:56:24.003 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37728314",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73450499,
        "Question_title":"AzureML Studio - Unable to Export Data using Designer",
        "Question_body":"<ul>\n<li>I built a classification model using the new AzureML Studio Designer. I am trying to export\nenter code herethe scored model as CSV file using the pill Export Data. I have selected\nworkspaceblobstore as datastore and csv as file format. The pipeline runs fine, but the\ndataset does not show up under Data. I am also unable to just right-click on the scored model\nand download a csv file.*<\/li>\n<\/ul>\n<pre><code>[Pipeline][1]\n[Export Data Parameters][2]\n[Output][3]\n\n\n  [1]: https:\/\/i.stack.imgur.com\/dlaec.png\n  [2]: https:\/\/i.stack.imgur.com\/PLwRv.png\n  [3]: https:\/\/i.stack.imgur.com\/rua29.png\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-22 20:08:32.923 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":37,
        "Owner_creation_date":"2022-08-22 19:29:39.58 UTC",
        "Owner_last_access_date":"2022-09-16 15:30:20.413 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73450499",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69577842,
        "Question_title":"AzureML Notebook AssertionError: Torch not compiled with CUDA enabled",
        "Question_body":"<p>I'm getting the error above while trying to excute this block of code in azureML notebook :<\/p>\n<pre><code>cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(&quot;COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_1x.yaml&quot;))\ncfg.MODEL.weights = model_zoo.get_checkpoint_url(&quot;COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_1x.yaml&quot;)\npredictor = DefaultPredictor(cfg)\n<\/code><\/pre>\n<p>Does anyone know why ?\nBy the way the conda environment i'm using is this :<\/p>\n<pre><code>channels:\n  - conda-forge\n  - pytorch\n  - anaconda\n  - defaults\ndependencies:\n  - python==3.8\n  - matplotlib\n  - numpy\n  - pytorch==1.8.0\n  - torchvision==0.9.0\n  - cpuonly\n  - scikit-learn\n  - pip\n  - pip:\n      - azureml-defaults\n      - pandas\n      - joblib\n      - opencv-python-headless\n      - 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'\nname: azureml_350ac2b8c050124461fa60260e56928b\n<\/code><\/pre>\n<p>I thank you in advance guy!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2021-10-14 22:01:32.677 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|conda|azure-machine-learning-service|detectron|azureml-python-sdk",
        "Question_view_count":740,
        "Owner_creation_date":"2021-10-05 10:01:17.933 UTC",
        "Owner_last_access_date":"2022-08-10 00:34:58.65 UTC",
        "Owner_reputation":59,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69577842",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49320679,
        "Question_title":"Difference between Azure ML and Azure ML experimentation",
        "Question_body":"<p>I am new to Azure ML. I am having some doubts .Could anyone please clarify my doubts listed below.<\/p>\n\n<ol>\n<li>What is the difference between Azure ML service Azure ML experimentation service.<\/li>\n<li>What is the difference between Azure ML workbench and Azure ML Studio.<\/li>\n<li>I want to use azure ML Experimentation service for building few models and creating web API's. Is it possible to do the same with ML studio. <\/li>\n<li>And also ML Experimentation service requires me to have a docker for windows installed for creating web services.\nCan i create web services without using docker?<\/li>\n<\/ol>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2018-03-16 12:22:52.1 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-04-07 22:05:38.927 UTC",
        "Question_score":4,
        "Question_tags":"azure|docker|azure-machine-learning-studio|azure-machine-learning-workbench|azure-machine-learning-service",
        "Question_view_count":763,
        "Owner_creation_date":"2015-01-23 10:56:16.07 UTC",
        "Owner_last_access_date":"2022-09-22 17:02:38.423 UTC",
        "Owner_reputation":388,
        "Owner_up_votes":62,
        "Owner_down_votes":2,
        "Owner_views":124,
        "Answer_body":"<ol>\n<li><p>The AML Experimentation is one of our many new ML offerings, including data preparation, experimentation, model management, and operationalization. Workbench is a PREVIEW product that provides a GUI for some of these services. But it is just a installer\/wrapper for the CLI that is needed to run. The services are Spark and Python based. Other Python frameworks will work, and you can get a little hacky to call Java\/Scala from Python. Not really sure what you mean by an \"Azure ML Service\", perhaps you are referring to the operationalization service I mentioned above. This will quickly let you create new Python based APIs using Docker containers, and will connect with the model management account to keep track of the linage between your models and your services. All services here are still in preview and may breaking change before GA release. <\/p><\/li>\n<li><p>Azure ML Studio is an older product that is perhaps simpler for some(myself an engineer not a data scientist). It offers a drag and drop experience, but is limited in it's data size to about 10G. This product is GA. <\/p><\/li>\n<li><p>It is, but you need smaller data sizes, and the job flow is not spark based. I use this to do rapid PoC's. Also you will less control over the scalability of your scoring (batch or real time), because it is PaaS, compared to the newer service which is more IaaS. I would recommend looking at the new service instead of studio for most use cases. <\/p><\/li>\n<li><p>The web services are completely based on Docker. Needing docker for experimentation is more about running things locally, which I myself rarely do. But, for the real time service, everything you package is placed into a docker container so it can be deployed to an ACS cluster. <\/p><\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-05-06 18:02:33.687 UTC",
        "Answer_score":2.0,
        "Owner_location":"United Kingdom House, London, UK",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49320679",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60202189,
        "Question_title":"How to create azure machine learning resource using terraform resource providers?",
        "Question_body":"<p>I wants to create azure machine learning workspace using terraform scripts.Is there any terraform provider to achieve this.<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_creation_date":"2020-02-13 07:04:51.623 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|terraform|azure-machine-learning-service|azure-rm",
        "Question_view_count":1152,
        "Owner_creation_date":"2019-08-12 18:04:59.383 UTC",
        "Owner_last_access_date":"2021-10-29 06:22:06.15 UTC",
        "Owner_reputation":110,
        "Owner_up_votes":22,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":"<p>In the meantime Microsoft has added a Terraform resource for ML Workspace in the Azure Provider. This should make any custom scripting obsolete.<\/p>\n<p><a href=\"https:\/\/www.terraform.io\/docs\/providers\/azurerm\/r\/machine_learning_workspace.html\" rel=\"nofollow noreferrer\">https:\/\/www.terraform.io\/docs\/providers\/azurerm\/r\/machine_learning_workspace.html<\/a><\/p>\n<pre><code>resource &quot;azurerm_machine_learning_workspace&quot; &quot;example&quot; {\n  name                    = &quot;example-workspace&quot;\n  location                = azurerm_resource_group.example.location\n  resource_group_name     = azurerm_resource_group.example.name\n  application_insights_id = azurerm_application_insights.example.id\n  key_vault_id            = azurerm_key_vault.example.id\n  storage_account_id      = azurerm_storage_account.example.id\n\n  identity {\n    type = &quot;SystemAssigned&quot;\n  }\n}\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-09-16 19:42:13.65 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60202189",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72530367,
        "Question_title":"Azure machine learning studio Pipeline run: ModuleNotFoundError: No module named 'pyodbc'",
        "Question_body":"<p>Scenario:<\/p>\n<p>1.I am using Machine learning studio for creating machine learning pipeline and when I am trying to call the .py file which has below code:<\/p>\n<pre><code>import os\nos.system(f&quot;pip install pandas&quot;)\nos.system(f&quot;pip install scikit-learn&quot;)\nos.system(f&quot;pip install pyodbc&quot;)\nos.system(f&quot;pip install SQLAlchemy&quot;)\n\nimport glob\nimport json\nimport pandas as pd\nfrom sklearn import preprocessing\nimport logging\nimport os\nimport sys\nimport pyodbc\nimport urllib\nfrom sqlalchemy.pool import NullPool\nimport sqlalchemy\n<\/code><\/pre>\n<p>and when I am trying to create and run pipeline from note book getting error:<\/p>\n<pre><code>    Collecting pyodbc\n    Downloading pyodbc-4.0.32.tar.gz (280 kB)\n    Building wheels for collected packages: pyodbc\n    Building wheel for pyodbc (setup.py): started\n    Building wheel for pyodbc (setup.py): finished with status 'error\n.....\n....\n....\n...\nModuleNotFoundError: No module named 'pyodbc'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-07 11:24:57.867 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":94,
        "Owner_creation_date":"2020-10-11 16:34:42.703 UTC",
        "Owner_last_access_date":"2022-08-05 12:44:13.273 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72530367",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34545078,
        "Question_title":"Azure ML vs Cortana Analytics Suite",
        "Question_body":"<p>I am wondering what is the difference between Cortana Analytics and Azure ML ?<\/p>\n\n<ul>\n<li>those are 2 distincts solutions ? <\/li>\n<li>one is part of the other ?<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-12-31 10:36:32.573 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-12-01 14:24:24.23 UTC",
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":1150,
        "Owner_creation_date":"2015-03-06 10:29:40.19 UTC",
        "Owner_last_access_date":"2020-11-18 21:41:29.05 UTC",
        "Owner_reputation":559,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":18,
        "Answer_body":"<p>Azure Machine Learning is part of the Cortana analytics suite<\/p>\n\n<p>You will find more info with the link below<\/p>\n\n<p><a href=\"http:\/\/www.sqlchick.com\/entries\/2015\/8\/22\/what-is-the-cortana-analytics-suite\" rel=\"nofollow\">All the details on the Cortana link here<\/a><\/p>\n\n<p>All the best<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-12-31 10:47:14.643 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2016-03-08 14:24:57.077 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34545078",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62939528,
        "Question_title":"Azure ML Error: You must provide an InferenceConfig when deploying a model with model_framework set to AutoML",
        "Question_body":"<p>I am trying to deploy an Azure ML AutoML generated model with an ML Notebook (script is shortened for brevity):<\/p>\n<pre><code>automl_settings = {\n    &quot;experiment_timeout_minutes&quot;: 20,\n    &quot;primary_metric&quot;: 'AUC_weighted',\n    &quot;max_concurrent_iterations&quot;: 8, \n    &quot;max_cores_per_iteration&quot;: -1,\n    &quot;enable_dnn&quot;: False,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;validation_size&quot;: 0.3,\n    &quot;verbosity&quot;: logging.INFO,\n}\n\nautoml_config = AutoMLConfig(task = 'classification',\n                             debug_log = 'automl_errors.log',\n                             compute_target=compute_target,\n                             blacklist_models=['LogisticRegression','MultinomialNaiveBayes','BernoulliNaiveBayes','LinearSVM','DecisionTree','RandomForest','ExtremeRandomTrees','LightGBM','KNN','SVM','StackEnsemble','VotingEnsemble'],\n                             training_data=train_dataset,\n                             label_column_name=target_column_name,\n                             **automl_settings\n                            )\n\nautoml_run = experiment.submit(automl_config, show_output=True)\n\nbest_run, fitted_model = automl_run.get_output()\nbest_run_metrics = best_run.get_metrics()\n\nchildren = list(automl_run.get_children(recursive=True))\nsummary_df = pd.DataFrame(index=['run_id', 'run_algorithm',\n                                    'primary_metric', 'Score'])\ngoal_minimize = False\nfor run in children:\n    if('run_algorithm' in run.properties and 'score' in run.properties):\n        summary_df[run.id] = [run.id, run.properties['run_algorithm'],\n                                run.properties['primary_metric'],\n                                float(run.properties['score'])]\n        if('goal' in run.properties):\n            goal_minimize = run.properties['goal'].split('_')[-1] == 'min'\n\n    summary_df = summary_df.T.sort_values(\n        'Score',\n        ascending=goal_minimize).drop_duplicates(['run_algorithm'])\n    summary_df = summary_df.set_index('run_algorithm')\n    \n    best_dnn_run_id = summary_df['run_id'].iloc[0]\n    best_dnn_run = Run(experiment, best_dnn_run_id)\n\nmodel_dir = 'Model' # Local folder where the model will be stored temporarily\nif not os.path.isdir(model_dir):\n    os.mkdir(model_dir)\n    \nbest_run.download_file('outputs\/model.pkl', model_dir + '\/model.pkl')\n\n# Register the model\nmodel_name = best_run.properties['model_name']\n\nmodel_path=os.path.join(&quot;.\/outputs&quot;,'model.pkl')\n\ndescription = 'My Model'\nmodel = best_run.register_model(model_name=model_name, model_path=model_path, model_framework='AutoML', description = description, tags={'env': 'sandbox'})\n\n# Deploy the Model\n\nservice_name = 'my-ml-service'\nservice = Model.deploy(ws, service_name, [model], overwrite=True)\n\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>Everything appears to run fine until I try to deploy the model:<\/p>\n<pre><code>--------------------------------------------------------------------------- UserErrorException                        Traceback (most recent call last) &lt;ipython-input-48-5c72d1613c28&gt; in &lt;module&gt;\n      3 service_name = 'my-service'\n      4 \n----&gt; 5 service = Model.deploy(ws, service_name, [model], overwrite=True)\n      6 \n      7 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/model.py in deploy(workspace, name, models, inference_config, deployment_config, deployment_target, overwrite)    1577               logger=module_logger)    1578 \n-&gt; 1579             return Model._deploy_no_code(workspace, name, models, deployment_config, deployment_target, overwrite)    1580     1581         # Environment-based webservice.\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/model.py in _deploy_no_code(workspace, name, models, deployment_config, deployment_target, overwrite)    1795         :rtype: azureml.core.Webservice    1796         &quot;&quot;&quot;\n-&gt; 1797         environment_image_request = build_and_validate_no_code_environment_image_request(models)    1798   1799         return Model._deploy_with_environment_image_request(workspace, name, environment_image_request,\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_model_management\/_util.py in build_and_validate_no_code_environment_image_request(models)    1180         raise UserErrorException('You must provide an InferenceConfig when deploying a model with model_framework '    1181  'set to {}. Default environments are only provided for these frameworks: {}.'\n-&gt; 1182                                  .format(model.model_framework, Model._SUPPORTED_FRAMEWORKS_FOR_NO_CODE_DEPLOY))    1183     1184    \n# Only specify the model IDs; MMS will provide the environment, driver program, etc.\n\nUserErrorException: UserErrorException:     Message: You must provide an InferenceConfig when deploying a model with model_framework set to AutoML. Default environments are only provided for these frameworks: ['Onnx', 'ScikitLearn', 'TensorFlow'].     InnerException None     ErrorResponse  {\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;You must provide an InferenceConfig when deploying a model with model_framework set to AutoML. Default environments are only provided for these frameworks: ['Onnx', 'ScikitLearn', 'TensorFlow'].&quot;\n    }\n<\/code><\/pre>\n<p>When deploying an AutoML generated model from the Azure Machine Learning Studio, I am not prompted to provide an entry script or dependencies file (or an InferenceConfig). Is there a way to configure this with the Python SDK so that I can &quot;no code deploy&quot; an AutoML generated model?  Is there something wrong in my code?  Hope you can help.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2020-07-16 16:45:49.997 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"python-3.x|azure|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":869,
        "Owner_creation_date":"2012-11-26 18:54:38.177 UTC",
        "Owner_last_access_date":"2022-05-25 15:24:46.07 UTC",
        "Owner_reputation":3398,
        "Owner_up_votes":1614,
        "Owner_down_votes":81,
        "Owner_views":404,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Chicago, IL, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62939528",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73720400,
        "Question_title":"cannot load the model in Azure ML",
        "Question_body":"<p>when I try to load a model in Azure ML with below code I get an error.\nanyone know how to fix the issue with Azure?<\/p>\n<pre><code>from tensorflow import keras\nkeras.models.load_model('model.h5')\n<\/code><\/pre>\n<pre><code>AttributeError                            Traceback (most recent call last)\n    Input In [24], in &lt;cell line: 2&gt;()\n          1 from tensorflow import keras\n    ----&gt; 2 keras.models.load_model('model_base-3.h5')\n    \n    File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/tensorflow\/python\/keras\/saving\/save.py:184, in load_model(filepath, custom_objects, compile)\n        181 with generic_utils.CustomObjectScope(custom_objects or {}):\n        182   if (h5py is not None and (\n        183       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n    --&gt; 184     return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\n        186   if sys.version_info &gt;= (3, 4) and isinstance(filepath, pathlib.Path):\n        187     filepath = str(filepath)\n    \n    File \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/tensorflow\/python\/keras\/saving\/hdf5_format.py:176, in load_model_from_hdf5(filepath, custom_objects, compile)\n        174 if model_config is None:\n        175   raise ValueError('No model found in config file.')\n    --&gt; 176 model_config = json.loads(model_config.decode('utf-8'))\n        177 model = model_config_lib.model_from_config(model_config,\n        178                                            custom_objects=custom_objects)\n        180 # set weights\n    \n    AttributeError: 'str' object has no attribute 'decode'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-14 16:37:53.4 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-14 20:02:35.307 UTC",
        "Question_score":0,
        "Question_tags":"azure|machine-learning|keras|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":50,
        "Owner_creation_date":"2019-11-14 20:02:36.677 UTC",
        "Owner_last_access_date":"2022-09-16 12:14:18.027 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73720400",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69824104,
        "Question_title":"Azure Devops: Model Register and package through Azure CLI in Devops pipeline Task",
        "Question_body":"<p>While Registering the model in Azure devops pipeline task through Inline script, its giving below issue:<\/p>\n<p>Command:<\/p>\n<pre><code>az ml model register -g $(ml.resourceGroup) -w $(ml.workspace) -n model_test --model-path .\/Configuration\/outputs\/ -t model.json\n<\/code><\/pre>\n<p>Error:<\/p>\n<blockquote>\n<p>Encountered authorization while uploading to blob storage. Please\ncheck the blob storage account attached to your workspace. Make sure\ncurrent user is authorized to access the storage account and that the\nrequest is not blocked by firewall , virtual network and other\nsecurity setting.<\/p>\n<p>status code: 403<\/p>\n<\/blockquote>\n<p>can someone help e on above issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-03 11:32:51.583 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-03 11:37:54.66 UTC",
        "Question_score":2,
        "Question_tags":"azure|azure-devops|azure-pipelines|azure-machine-learning-service",
        "Question_view_count":123,
        "Owner_creation_date":"2021-11-03 11:27:49.703 UTC",
        "Owner_last_access_date":"2022-04-14 12:06:14.393 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69824104",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57403281,
        "Question_title":"Installing textshape package for Microsoft R Open 3.4.4 on Azure ML Studio",
        "Question_body":"<p>I'm trying to use the R <code>sentimentr<\/code> package on Azure ML Studio. As this package is not supported, I'm trying to install it and its dependencies as described <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/execute-r-script#bkmk_AddingANewPackage\" rel=\"nofollow noreferrer\">in the documentation<\/a>.<\/p>\n\n<p>The steps that I have performed are:<\/p>\n\n<ul>\n<li><p>downloaded Windows binaries from the R Open 3.4.4 snapshot at <a href=\"https:\/\/mran.microsoft.com\/timemachine\" rel=\"nofollow noreferrer\">CRAN time machine<\/a><\/p>\n\n<ul>\n<li><code>sentimentr_2.2.3.zip<\/code><\/li>\n<li><code>syuzhet_1.0.4.zip<\/code><\/li>\n<li><code>textclean_0.6.3.zip<\/code><\/li>\n<li><code>lexicon_0.7.4.zip<\/code><\/li>\n<li><code>textshape_1.5.0.zip<\/code> <\/li>\n<\/ul><\/li>\n<li><p>zipped those zip files into a zipped folder <code>packages.zip<\/code><\/p><\/li>\n<li>uploaded <code>packages.zip<\/code> as a dataset to Microsoft Azure ML Studio<\/li>\n<\/ul>\n\n<p>In my ML experiment I connect the <code>packages.zip<\/code> dataset to the \"Script Bundle (Zip)\" input port on \"Execute R Script\" and include this code:<\/p>\n\n<pre><code># install R package contained in src  \ninstall.packages(\"src\/lexicon_0.7.4.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/textclean_0.6.3.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/textshape_1.5.0.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/syuzhet_1.0.4.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/sentimentr_2.2.3.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\n# load libraries\nlibrary(sentimentr, lib.loc = \".\", verbose = TRUE)\n<\/code><\/pre>\n\n<p>The experiment runs successfully, until I include a function from <code>sentimentr<\/code>:<\/p>\n\n<pre><code>mydata &lt;- mydata %&gt;%\n  get_sentences() %&gt;%\n  sentiment()\n<\/code><\/pre>\n\n<p>This gives the error:<\/p>\n\n<blockquote>\n  <p>there is no package called 'textshape'<\/p>\n<\/blockquote>\n\n<p>Which is difficult to understand given that the output log does not indicate an issue with the packages:<\/p>\n\n<pre><code>[Information]         The following files have been unzipped for sourcing in path=[\"src\"]:\n[Information]                           Name  Length                Date\n[Information]         1 sentimentr_2.2.3.zip 3366245 2019-08-07 14:57:00\n[Information]         2    syuzhet_1.0.4.zip 2918474 2019-08-07 15:05:00\n[Information]         3  textclean_0.6.3.zip 1154814 2019-08-07 15:13:00\n[Information]         4    lexicon_0.7.4.zip 4551995 2019-08-07 15:17:00\n[Information]         5  textshape_1.5.0.zip  463095 2019-08-07 15:42:00\n[Information]         Loading objects:\n[Information]           port1\n[Information]         [1] \"Loading variable port1...\"\n[Information]         package 'lexicon' successfully unpacked and MD5 sums checked   \n[Information]         package 'textclean' successfully unpacked and MD5 sums checked\n[Information]         package 'textshape' successfully unpacked and MD5 sums checked\n[Information]         package 'syuzhet' successfully unpacked and MD5 sums checked\n[Information]         package 'sentimentr' successfully unpacked and MD5 sums checked\n<\/code><\/pre>\n\n<p>Has anyone seen this, or similar issues? Is it possible that \"successfully unpacked\" is not the same as successfully installed and usable?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-07 23:12:10.07 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"r|package|azure-machine-learning-studio",
        "Question_view_count":157,
        "Owner_creation_date":"2009-04-10 14:49:12.693 UTC",
        "Owner_last_access_date":"2022-09-23 09:38:34.63 UTC",
        "Owner_reputation":30129,
        "Owner_up_votes":685,
        "Owner_down_votes":51,
        "Owner_views":2937,
        "Answer_body":"<p>I can now answer my own question thanks to <a href=\"https:\/\/twitter.com\/bryan_hepworth\/status\/1159432174225055749\" rel=\"nofollow noreferrer\">a hint on Twitter<\/a> from @bryan_hepworth.<\/p>\n\n<p>The R packages were installed correctly, but not in the standard library location. So when a function from <code>sentimentr<\/code> runs, R tries to load the dependency package <code>textshape<\/code>:<\/p>\n\n<pre><code>library(textshape)\n<\/code><\/pre>\n\n<p>Which of course does not exist <em>in the standard location<\/em> as Azure ML does not support it.<\/p>\n\n<p>The solution is to load <code>textshape<\/code> explicitly from its installed location:<\/p>\n\n<pre><code>library(textshape, lib.loc = \".\")\n<\/code><\/pre>\n\n<p>So the solution is: explicitly load packages that you installed at the start of your R code, rather than letting R try to load them as dependencies, which will fail.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-08-08 22:14:34.167 UTC",
        "Answer_score":0.0,
        "Owner_location":"Sydney, Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57403281",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41743792,
        "Question_title":"Is there an Azure Machine Learning Studio module that works like the Pandas 'mask' method?",
        "Question_body":"<p>I'm trying to perform the following Python Pandas operation in Azure Machine Learning Studio, but cannot find a module that handles it:<\/p>\n\n<pre><code>df.credit_score = df.credit_score.mask(df.credit_score &gt; 800, df.credit_score \/ 10)\n<\/code><\/pre>\n\n<p>So I'm effectively just trying to find all values in my 'credit_score' column that are greater than 800 and divide them by 10.  I have been unable so far to find a module in AML Studio that does that.<\/p>\n\n<p>Also, I should add that I'm having issues with my Python script in AML Studio, which is why I'm attempting to replicate all of my code using AML built-in modules.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-01-19 14:07:57.413 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-01-19 14:17:35.797 UTC",
        "Question_score":1,
        "Question_tags":"pandas|azure-machine-learning-studio",
        "Question_view_count":57,
        "Owner_creation_date":"2017-01-08 15:14:18.947 UTC",
        "Owner_last_access_date":"2019-05-03 18:29:28.66 UTC",
        "Owner_reputation":107,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<p>To my knowledge, there's no built-in module to do this succinctly (to my knowledge). If you prefer to use built-ins, you could:<\/p>\n\n<ol>\n<li>Use a Split Dataset module to split the entries based on credit\nscore<\/li>\n<li>Divide the credit score in large-credit-score rows by 10 using\nApply Math Operation<\/li>\n<li>Concatenate the two datasets row-wise with an Add Rows module<\/li>\n<\/ol>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-01-25 13:26:55.923 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41743792",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47904508,
        "Question_title":"Change the name of a Python library within its file",
        "Question_body":"<p>I'm using Azure Machine Learning Studio which supports version 17.0 of scikit-learn. I would like to use newer one. You can do it as described <a href=\"https:\/\/stackoverflow.com\/questions\/44593469\/how-can-certain-python-libraries-be-imported-in-azure-mllike-the-line-import-hu\">here<\/a>. But this causes name aliasing so I would have to change the name of the library which file can be found <a href=\"https:\/\/pypi.python.org\/pypi\/scikit-learn\/0.19.1\" rel=\"nofollow noreferrer\">here<\/a>. I don't know which parts of files I'm supposed to change so I can import scikit-learn as something else than <code>import sklearn<\/code> <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_creation_date":"2017-12-20 11:00:40.81 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-12-20 11:49:08.857 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|scikit-learn|azure-machine-learning-studio",
        "Question_view_count":129,
        "Owner_creation_date":"2016-05-12 14:33:46.38 UTC",
        "Owner_last_access_date":"2022-09-23 16:26:46.45 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":316,
        "Owner_down_votes":1,
        "Owner_views":127,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Ljubljana, Slovenija",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47904508",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72214072,
        "Question_title":"How to time tigger a python script in the Azure ML notebooks",
        "Question_body":"<p>Hi I am currently working on a small image classification project where the model classifies whether the image contains potholes or not. For this section i have wrote the python script, and this script needs to be triggered at scheduled time. I created a scheduled compute instance but the script doesn't get implemented when the compute instance is running. So i want to know what method should i use to get this sorted.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2022-05-12 10:36:00.12 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure-functions|azure-machine-learning-studio|azure-container-instances|azure-notebooks",
        "Question_view_count":82,
        "Owner_creation_date":"2019-05-01 13:40:46.72 UTC",
        "Owner_last_access_date":"2022-09-11 08:42:22.377 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"1040\/3 Athurugiriya Road, Malabe, Sri Lanka",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72214072",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72525654,
        "Question_title":"Azure ML failed to deploy endpoint",
        "Question_body":"<h2>Problem Description<\/h2>\n<p>I am following <a href=\"https:\/\/www.analyticsvidhya.com\/blog\/2022\/02\/deploy-your-ml-model-as-a-web-service-in-microsoft-azure-cloud\/\" rel=\"nofollow noreferrer\">this tutorial<\/a> to deploy an ML model to Azure ML as a web service.<\/p>\n<p>The model has been uploaded successfully (Image 1), but it failed when I created the web service endpoint (Image 2).<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/nQEDr.png\" alt=\"Image 1: succeeded model upload\" \/><\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/QJUEO.png\" alt=\"Image 2: failed endpoint deployment\" \/><\/p>\n<p>I am new to cloud computing and still confused about how to troubleshoot this issue. The &quot;Deployment logs&quot; tab only contained short information as below.<\/p>\n<pre><code>container &quot;predict&quot; in pod &quot;wk-caas-f62cbd87d3e3400a8fffc23a20f0744e-8c212518c5f6b7404584eb194515f3a1-pod&quot; is waiting to start: PodInitializing\n<\/code><\/pre>\n<p>Here are the model and source codes I used in the deployment:<\/p>\n<ul>\n<li><a href=\"https:\/\/github.com\/mari-bangkit\/prediction-model\/blob\/main\/regressor.pkl\" rel=\"nofollow noreferrer\">Model<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/mari-bangkit\/prediction-model\/blob\/main\/scoring.py\" rel=\"nofollow noreferrer\">Entry script<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/mari-bangkit\/prediction-model\/blob\/main\/conda_env.yml\" rel=\"nofollow noreferrer\">Conda environment YAML<\/a><\/li>\n<li><a href=\"https:\/\/pastebin.com\/nUy8YGyh\" rel=\"nofollow noreferrer\">Deployment logs<\/a><\/li>\n<\/ul>\n<h2>Question<\/h2>\n<p>Any advice to solve this issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-06-07 03:38:30.807 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2022-06-07 05:16:09.707 UTC",
        "Question_score":1,
        "Question_tags":"python|azure|machine-learning|conda|azure-machine-learning-service",
        "Question_view_count":211,
        "Owner_creation_date":"2019-11-30 10:44:54.723 UTC",
        "Owner_last_access_date":"2022-09-22 13:21:33.573 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72525654",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59939361,
        "Question_title":"Azure ML-Training Model on Voice",
        "Question_body":"<p>Is it possible to train a Azure model on Voice?<\/p>\n\n<p>I am working on a call center use case where in , when a customer calls in with a complaint based on the description the ML model should be able to predict &amp; classify the Customer Complaint<\/p>\n\n<p>Actually I was able to train \"two class boosted decision tree\" model, on text based complaints using feature hashing technique, but specifically looking to train the model on Voice<\/p>\n\n<p>Guidance, examples &amp; references would help<\/p>\n\n<p>Incase OOB feature wouldn't exist in MLS, open to hear about workarounds as well<\/p>\n\n<p>Thanks<\/p>\n\n<p>Hi, Thanks for the response. This is the core idea<\/p>\n\n<p>Call center would have data Comprising of Label Customer Complaint and Feature Issue description  <\/p>\n\n<p>Sample \"Customer Complaint\" would be Billing issue or Internet speed<\/p>\n\n<p>Sample description would be \"Hey i was paying $x but the price went up by $y, can you apply some promotion to being my monthly bill down by $z\"<\/p>\n\n<p>the webservice will take Voice input Issue Description &amp; should product either voice\/text output Customer complaint<\/p>\n\n<p>We would want to train ML model with the data and deploy as web service. THis way when the consumer calls with an issue, they need not dial options 1,2,3 rather the model is able to route them to appropriate queue<\/p>\n\n<p>(1) How do I convert text data to Voice in Azure MLS?<\/p>\n\n<p>(2) How do i apply , train &amp; Score model in Voice <\/p>\n\n<p>(3) How to make the webservice accept Voice input to produce the scored label\/value as webservice output <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-01-27 21:45:20.073 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-01-30 15:56:13.337 UTC",
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":55,
        "Owner_creation_date":"2018-09-11 23:43:12.93 UTC",
        "Owner_last_access_date":"2020-07-07 19:57:39.68 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59939361",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65819401,
        "Question_title":"Exporting an Azure Machine Learning Experiment to a Jupyter notebook",
        "Question_body":"<p>I'm new to machine learning and I created an experiment in Azure Machine Learning Studio.\n<a href=\"https:\/\/i.stack.imgur.com\/wBLov.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wBLov.png\" alt=\"experiement\" \/><\/a><\/p>\n<p>Is there a way to export this code to python or a jupyter notebook? I have not been able to find anything in Microsoft's documentation<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-21 00:02:00.76 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":132,
        "Owner_creation_date":"2014-05-06 01:11:14.593 UTC",
        "Owner_last_access_date":"2022-07-21 23:41:41.833 UTC",
        "Owner_reputation":317,
        "Owner_up_votes":251,
        "Owner_down_votes":3,
        "Owner_views":78,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Los Angeles, CA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65819401",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53605129,
        "Question_title":"What does \"Number of points\" mean when you select the Parameter Range option",
        "Question_body":"<p>What does \"Number of points\" mean on the various models when you select the Parameter Range option for Create Trainer Mode.  Can anyone shed light on what this parameter means.<\/p>\n\n<p>The Azure ML Studio documentation does not mention this parameter, either in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/two-class-logistic-regression\" rel=\"nofollow noreferrer\">the documentation for the model<\/a> or in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/tune-model-hyperparameters\" rel=\"nofollow noreferrer\">documentation to tune hyperparameters<\/a>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/6De7r.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6De7r.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2018-12-04 03:07:05.22 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-12-06 07:16:03.543 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|logistic-regression|azure-machine-learning-studio",
        "Question_view_count":72,
        "Owner_creation_date":"2018-09-30 02:23:26.613 UTC",
        "Owner_last_access_date":"2021-08-13 13:02:53.707 UTC",
        "Owner_reputation":798,
        "Owner_up_votes":21,
        "Owner_down_votes":2,
        "Owner_views":64,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53605129",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62949488,
        "Question_title":"AMLS Experiment run stuck in status \"Running\"",
        "Question_body":"<p>I made an Azure Machine Learning Service Experiment run and logged neural network losses with Jupyter Notebook. Logging worked fine and NN training completed as it should. However, the experiment is stuck in the running status. Shutting down the compute resources does not shut down the Experiment run and I cannot cancel it from the Experiment panel. In addition, the run does not have any log-files.<\/p>\n<p>Has anyone had the same behavior? Run has now lasted for over 24 hours.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/KzAoS.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KzAoS.jpg\" alt=\"AMLS Experiment run\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-17 07:51:00.903 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2020-07-17 12:35:03.64 UTC",
        "Question_score":2,
        "Question_tags":"python|azure|neural-network|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":887,
        "Owner_creation_date":"2019-07-23 09:35:53.357 UTC",
        "Owner_last_access_date":"2022-09-23 18:22:54.737 UTC",
        "Owner_reputation":881,
        "Owner_up_votes":1241,
        "Owner_down_votes":14,
        "Owner_views":106,
        "Answer_body":"<p>this totally happens from time to time. it is certainly frustrating especially because the &quot;Cancel&quot; button it grayed out. You can use either the CLI or Python SDK  to cancel the run.<\/p>\n<h2>SDK<\/h2>\n<h3>&gt;= 1.16.0<\/h3>\n<p>As of version <code>1.16.0<\/code> you no longer an <code>Experiment<\/code> object is no longer needed. Instead you can access using the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#get-workspace--run-id-&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\"><code>Run<\/code><\/a> or <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace(class)?view=azure-ml-py#get-run-run-id-&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\"><code>Workspace<\/code><\/a> objects directly<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace, Experiment, Run, VERSION\nprint(&quot;SDK version:&quot;, VERSION)\n\nws = Workspace.from_config()\n\nrun = ws.get_run('YOUR_RUN_ID')\nrun = Run().get(ws, 'YOUR_RUN_ID') # also works\nrun.cancel()\n<\/code><\/pre>\n<h3>&lt; 1.16.0<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace, Experiment, Run, VERSION\nprint(&quot;SDK version:&quot;, VERSION)\n\nws = Workspace.from_config()\nexp = Experiment(workspace = ws, name = 'YOUR_EXP_NAME')\n\nrun = Run(exp, run_id='YOUR STEP RUN ID')\n\nrun.cancel() # or run.fail()\n<\/code><\/pre>\n<h1>CLI<\/h1>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-azure-machine-learning-cli#install-the-extension\" rel=\"nofollow noreferrer\">More CLI details here<\/a><\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>az login\naz ml run cancel --run YOUR_RUN_ID\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-07-17 16:45:39.51 UTC",
        "Answer_score":5.0,
        "Owner_location":"Helsinki, Finland",
        "Answer_last_edit_date":"2020-11-09 08:58:51.753 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62949488",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66623001,
        "Question_title":"How can I save or extract my machine learning model developed in Azure ML Studio?",
        "Question_body":"<p>So I have built my machine learning prediction model in Azure ML Studio. I want to use that model for my Web App where I will be using Flask &amp; Heroku for development purpose.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-03-14 09:41:36.987 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"machine-learning|azure-machine-learning-studio|azure-machine-learning-service|machine-learning-model",
        "Question_view_count":1552,
        "Owner_creation_date":"2019-05-24 15:55:49.56 UTC",
        "Owner_last_access_date":"2022-03-24 11:57:04.927 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66623001",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50993858,
        "Question_title":"Score Matchbox Recommender Stuck or Throwing an Error",
        "Question_body":"<p>I'm using the Score Matchbox Recommender set to recommend items from unrated items. This module will run for over 3 hours (I haven't tried longer) and not finish. It will work fine when I'm recommending from rated items to evaluate the recommender, but as soon as I switch to unrated it will run indefinitely. I'm currently using the split data module on already split data to get an even smaller sample of about 20,000 rows. Is this too much for this module to handle? <\/p>\n\n<p>If I try to take the sample even smaller using the partition and sample module (yes I know it's not a recommender split), I immediately get an Exception 0000: Internal system error. <\/p>\n\n<p>Any idea why it's taking so long\/how to fix it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2018-06-22 18:35:32.74 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":215,
        "Owner_creation_date":"2015-07-13 20:16:19.27 UTC",
        "Owner_last_access_date":"2022-06-30 20:42:10.207 UTC",
        "Owner_reputation":474,
        "Owner_up_votes":322,
        "Owner_down_votes":12,
        "Owner_views":28,
        "Answer_body":"<p>Using the \"Filter Based Feature Selection\" module and then removing all columns besides those found significant and the identifiers seemed to fix the issue. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-07-02 18:12:50.483 UTC",
        "Answer_score":0.0,
        "Owner_location":"Eugene, OR, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50993858",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68912185,
        "Question_title":"Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties' in Azure Machine Learning Designer",
        "Question_body":"<p>From today (Aug 24th, 2021) I'm receiving the following error message when submit any operation in Azure Machine Learning Designer with a dataset:<\/p>\n<p><strong>Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties'<\/strong><\/p>\n<p>Complete error message:<\/p>\n<p><em>UserError: Job submission to AzureML Compute encountered an Exception with status code , Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties'. Path 'properties.intellectualPropertyPublisher', line 309, position 36.<\/em><\/p>\n<p>I'm seeing there's new items in user interface, maybe could be an updating error?\nSomeone is receiving something that?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2021-08-24 18:10:02.63 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-08-30 23:00:58.667 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":30,
        "Owner_creation_date":"2021-08-24 18:04:02.253 UTC",
        "Owner_last_access_date":"2022-05-27 17:17:39.74 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68912185",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35627916,
        "Question_title":"Azure machine learning even sampling",
        "Question_body":"<p>I'm trying to do some basic multi-label classification in Azure ML. I have some basic data in the following format:<\/p>\n\n<pre><code>value_x value_y label\nx1      y1      label1\nx2      y2      label1\nx3      y3      label2\n.....\n<\/code><\/pre>\n\n<p>My problem is that in my data certain labels (out of a total of five) are overrepresented, as about 40% of the data is label1, about 20% is label 2 and the rest around 10%. <\/p>\n\n<p>I would like to get a sampling out of these to train my model, so that each label is represented in equal amounts. <\/p>\n\n<p>Tried the stratification option in the Sampling module on the labels column, but that just gives me a sampling with the same distribution of labels as in the initial dataset.<\/p>\n\n<p>Any idea how I could do this with a module?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2016-02-25 12:53:42.827 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-02-25 14:36:19.577 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|classification|sampling|multilabel-classification|azure-machine-learning-studio",
        "Question_view_count":539,
        "Owner_creation_date":"2013-10-10 11:47:41.54 UTC",
        "Owner_last_access_date":"2022-09-22 10:35:54.783 UTC",
        "Owner_reputation":185,
        "Owner_up_votes":42,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p>I was able to do this using a combination of <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/70530644-c97a-4ab6-85f7-88bf30a8be5f\" rel=\"nofollow\">Split Data<\/a>, <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/a8726e34-1b3e-4515-b59a-3e4a475654b8\" rel=\"nofollow\">Partition and Sample<\/a>, and <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/b2ebdabd-217d-4915-86cc-5b05972f7270\" rel=\"nofollow\">Add Rows<\/a> modules.  There may be an easier way to do it, but I did confirm it works.  :)  I published my work at <a href=\"http:\/\/gallery.azureml.net\/Details\/1245147fd7004e91bc7a3683cda19cc7\" rel=\"nofollow\">http:\/\/gallery.azureml.net\/Details\/1245147fd7004e91bc7a3683cda19cc7<\/a> so you can grab it directly from there, and run to confirm it does what you expect.  <\/p>\n\n<p>Since you said you wanted a sampling of the data, I just reduced each of the labels to 10% to have all labels represented equally.  Since you have a good understanding of the distribution in your dataset, leave label 3, 4, and 5 all at about 10%, and reduce label 1 by 1\/4 and label 2 by 1\/2 to get about 10% of them as well.  <\/p>\n\n<p>To explain what I did in the workspace linked above:<\/p>\n\n<ul>\n<li>I used some \"Split Data\" modules to filter out the label1 and label2 data.  In the Split Data module, change the Splitting mode to \"Regular Expression\" and set the regular expression to <strong>\\\"Label\" ^label1<\/strong> (to get the label1 data, for example).  <\/li>\n<li>Then I used some \"Partition and Sample\" modules to reduce the size of the label1 and label2 data appropriately.  <\/li>\n<li>Finally, I used some \"Add Rows\" modules to join all of the data back together again.  <\/li>\n<\/ul>\n\n<p>Finally, I didn't include this in my work, but you can also look at the <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/9f3fe1c4-520e-49ac-a152-2e104169912a\" rel=\"nofollow\">SMOTE<\/a> module.  It will increase the number of low-occurring samples using synthetic minority oversampling.  <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-02-26 03:51:29.16 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35627916",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57578332,
        "Question_title":"Failure of experiment when using base_dockerfile instead of base_image",
        "Question_body":"<p>I am attempting to submit an experiment to the Azure Machine Learning Service using a custom docker image.  Everything works ok when I provide the docker image, but fails if I choose to provide a dockerfile.<\/p>\n\n<p>The use of a base_dockerfile in the DockerSection object is documented <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.environment.dockersection?view=azure-ml-py\" rel=\"nofollow noreferrer\">here<\/a> and was added in v1.0.53 of the sdk (as noted <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/service\/azure-machine-learning-release-notes.md\" rel=\"nofollow noreferrer\">here<\/a>)<\/p>\n\n<p>Example code:<\/p>\n\n<pre><code>ds = DockerSection()\nds.enabled = True\nds.base_dockerfile = \"FROM ubuntu:latest RUN echo 'Hello world!'\"\nds.base_image = None\n<\/code><\/pre>\n\n<p>The rest of the code is the same as when running with a predefined image from the registry (e.g. setting base_image in the above code).<\/p>\n\n<p>Example error from ML service is:<\/p>\n\n<blockquote>\n  <p>raise ActivityFailedException(error_details=json.dumps(error,\n  indent=4))\n  azureml.exceptions._azureml_exception.ActivityFailedException:\n  ActivityFailedException:\n          Message: Activity Failed: {\n      \"error\": {\n          \"code\": \"ServiceError\",\n          \"message\": \"InternalServerError\",\n          \"details\": []\n      },\n      \"correlation\": {\n          \"operation\": null,\n          \"request\": \"K\/C4FSnEz74=\"\n      },\n      \"environment\": \"southcentralus\",\n      \"location\": \"southcentralus\",\n      \"time\": \"2019-08-20T16:33:17.130928Z\" }\n          InnerException None\n          ErrorResponse {\"error\": {\"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"ServiceError\\\",\\n<br>\n  \\\"message\\\": \\\"InternalServerError\\\",\\n        \\\"details\\\": []\\n<br>\n  },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n<br>\n  \\\"request\\\": \\\"K\/C4FSnEz74=\\\"\\n  },\\n    \\\"environment\\\":\n  \\\"southcentralus\\\",\\n    \\\"location\\\": \\\"southcentralus\\\",\\n<br>\n  \\\"time\\\": \\\"2019-08-20T16:33:17.130928Z\\\"\\n}\"}}<\/p>\n<\/blockquote>\n\n<p>I've used an example dockerfile in the code above (taken from the SDK documentation) but get the same error if I use the dockerfile that created the base image that works ok from the registry.<\/p>\n\n<p>Any ideas - or pointers to samples where this actually works - appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-20 16:53:54.643 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":307,
        "Owner_creation_date":"2012-12-13 22:14:25.377 UTC",
        "Owner_last_access_date":"2022-08-16 01:57:33.6 UTC",
        "Owner_reputation":55,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>Thanks for reporting this issue! This appears to be a bug that our team is investigating.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-08-20 17:44:18.62 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57578332",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58757573,
        "Question_title":"Facing issues connecting\/Attaching Data science VM(Ubuntu) to Azure ML Services",
        "Question_body":"<p>I have a data science VM(Ubuntu) which is in Corporate Network (No public IP). I'm trying to connect\/attach this VM with Azure ML Services(Enterprise). <\/p>\n\n<p>I get below error\nProvisioning error : Connection failed: Connection attempt timed out. Verify that server is accessible and SSH service is accepting connections. Resource: '172.16.204.199:8000'.\nTried with both ports 8000 and 22 as well.<\/p>\n\n<p>Client Request ID : 270308d4-1beb-4346-9adc-154307835f1b   Service Request ID : |af2659de20174c1d8131d3f05f954c48<\/p>\n\n<p>It would be great if there's a solution to this. I can confirm that VM is running and I'm able to log into jupyter using the private ip address.\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-11-07 22:07:28.787 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":100,
        "Owner_creation_date":"2019-11-07 21:36:23.633 UTC",
        "Owner_last_access_date":"2019-11-19 21:39:47.6 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58757573",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32060196,
        "Question_title":"Azure ML Internal Error",
        "Question_body":"<p>When I try to test my Azure ML model, I get the following error: \u201cError code: InternalError, Http status code: 500\u201d, so it appears something is failing inside of the machine learning service. How do I get around this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-08-17 21:44:21.947 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-08-18 13:57:02.223 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":1408,
        "Owner_creation_date":"2015-08-17 21:40:18.3 UTC",
        "Owner_last_access_date":"2016-04-28 08:03:01.207 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>I've run into this error before, and unfortunately, the only workaround I found was to create a new ML workspace backed by a storage account that you know is online. Then copy your experiment over to the new workspace, and things should work. It can be a bit cumbersome, but it should get rid of your error message. With the service being relatively new, things sometimes get corrupted as updates are being made, so I recommend checking the box labeled \"disable updates\" within your experiment.  Hope that helps!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-08-17 21:47:56.38 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32060196",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49364530,
        "Question_title":"Predicting a users next action based on current day and time",
        "Question_body":"<p>I'm using Microsoft Azure Machine Learning Studio to try an experiment where I use previous analytics captured about a user (at a time, on a day) to try and predict their next action (based on day and time) so that I can adjust the UI accordingly. So if a user normally visits a certain page every Thursday at 1pm, then I would like to predict that behaviour.<\/p>\n\n<p>Warning - I am a complete novice with ML, but have watched quite a few videos and worked through tutorials like the movie recommendations example.<\/p>\n\n<p>I have a csv dataset with userid,action,datetime and would like to train a matchbox recommendation model, which, from my research appears to be the best model to use. I can't see a way to use date\/time in the training. The idea being that if I could pass in a userid and the date, then the recommendation model should be able to give me a probably result of what that user is most likely to do.<\/p>\n\n<p>I get results from the predictive endpoint, but the training endpoint gives the following error:<\/p>\n\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>{\n    \"error\": {\n        \"code\": \"ModuleExecutionError\",\n        \"message\": \"Module execution encountered an error.\",\n        \"details\": [\n            {\n                \"code\": \"18\",\n                \"target\": \"Train Matchbox Recommender\",\n                \"message\": \"Error 0018: Training dataset of user-item-rating triples contains invalid data.\"\n            }\n        ]\n    }\n}<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n\n<p><a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/User-analytics\" rel=\"noreferrer\">Here is a link to a public version of the experiment<\/a><\/p>\n\n<p>Any help would be appreciated.<\/p>\n\n<p>Thanks.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Z6Uhr.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Z6Uhr.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2018-03-19 13:46:14.213 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2018-03-22 17:05:38.663 UTC",
        "Question_score":11,
        "Question_tags":"azure|machine-learning|analytics|azure-machine-learning-studio",
        "Question_view_count":925,
        "Owner_creation_date":"2009-12-10 21:40:32.61 UTC",
        "Owner_last_access_date":"2022-05-10 08:54:49.827 UTC",
        "Owner_reputation":659,
        "Owner_up_votes":30,
        "Owner_down_votes":5,
        "Owner_views":203,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49364530",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44330391,
        "Question_title":"How to apply learning curves on Azure Machine Learning",
        "Question_body":"<p>I have started using the Azure Studio ML and would like to know if there is a way of inputting a learning curve code (python or R) into my model.<\/p>\n\n<p>I am training with Two-Class Boosted Decision Tree and I want to check if my results are overfitting or not. <\/p>\n\n<p>I have also found some codes for Learning Curves and I know there is a box to execute the codes in either R or Python but I do not know what I have change in the code (if I actually have to) and how do I connect my dataset to this code<\/p>\n\n<p>Code source: <a href=\"http:\/\/www.ritchieng.com\/machinelearning-learning-curve\/\" rel=\"nofollow noreferrer\">http:\/\/www.ritchieng.com\/machinelearning-learning-curve\/<\/a><\/p>\n\n<p>Thank you,\nLucas<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-06-02 13:42:00.413 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|r|azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":187,
        "Owner_creation_date":"2015-10-26 12:25:19.373 UTC",
        "Owner_last_access_date":"2020-06-04 14:49:16.817 UTC",
        "Owner_reputation":155,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":37,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44330391",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32917356,
        "Question_title":"Azure Machine Learning - Serialization error",
        "Question_body":"<p>I have tried to create a predictive webservice (following the movie recommender tutorial) but when I run the predective experiment I get an error:<\/p>\n\n<p><strong>Model could not be deserialized because it is likely serialized with an older serialization format. Please retrain and re-save the model. . ( Error 0082 )<\/strong><\/p>\n\n<p>Have you any idea?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/3BwSe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3BwSe.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2015-10-02 23:41:16.443 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":157,
        "Owner_creation_date":"2012-10-10 01:45:06.287 UTC",
        "Owner_last_access_date":"2022-09-23 13:44:34.203 UTC",
        "Owner_reputation":2577,
        "Owner_up_votes":306,
        "Owner_down_votes":88,
        "Owner_views":212,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Lima, Peru",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32917356",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45354047,
        "Question_title":"How can I load a trained model in Azure ML Studio?",
        "Question_body":"<p>I'm trying to load a trained model from the trained models tab in Azure ML studio into another experiment. According to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/load-trained-model#load-the-model-into-a-new-experiment\" rel=\"nofollow noreferrer\">the docs<\/a> its possible to do as follows:<\/p>\n\n<blockquote>\n  <p>Add the Load Trained Model module to your experiment. For Data source,\n  indicate the location of the trained model, using one of the following\n  options:\n      Select Web URL via HTTP and then type the URL.\n      The URL should point to the experiment and the file representing the trained model. In Azure Machine Learning, trained models are by\n  default saved in the iLearner format.<\/p>\n<\/blockquote>\n\n<p>However, does anyone know what URL I would use for models saved in my workspace? Where is the file representing the model hosted?  <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-07-27 14:41:17.883 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-03-20 19:49:57.787 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|ml-studio",
        "Question_view_count":673,
        "Owner_creation_date":"2016-03-23 12:08:55.013 UTC",
        "Owner_last_access_date":"2017-11-03 14:40:18.777 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45354047",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":43576656,
        "Question_title":"Join 2 tables with with mutiple keys in Azure ML Studio",
        "Question_body":"<p>I have two datasets with multiple columns. I would like to join the two tables with the following keys: zip code, year, month, data, hour<\/p>\n\n<p>However whenever I use a <strong>Join Module<\/strong> on these two tables, the Join doesn't happen, and I just get a Table with Columns from Right Table with empty values.<\/p>\n\n<p>Here is the R equivalent of what I am trying to do:<\/p>\n\n<pre><code>YX &lt;- leftTableDT\nYX %&lt;&gt;% merge( rightTableDT, all.x = TRUE, by=c('zip','year','month','day','hour') )\n<\/code><\/pre>\n\n<p>Any ideas on why Join Module in Azure ML Studio doesn't work for multiple keys?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-04-23 21:25:00.45 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":582,
        "Owner_creation_date":"2010-08-14 18:36:47.747 UTC",
        "Owner_last_access_date":"2022-09-21 17:16:05.413 UTC",
        "Owner_reputation":3675,
        "Owner_up_votes":387,
        "Owner_down_votes":8,
        "Owner_views":638,
        "Answer_body":"<p>Double-check that you've selected \"Allow duplicates and preserve column order in selection\" in column selection options, so it matches the columns in listed order.<\/p>\n\n<p>Also, you could try Apply SQL Transformation module to join datasets.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-05-03 13:08:46.63 UTC",
        "Answer_score":0.0,
        "Owner_location":"Capitola, CA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/43576656",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65991587,
        "Question_title":"AzureDevOPS ML Error: We could not find config.json in: \/home\/vsts\/work\/1\/s or in its parent directories",
        "Question_body":"<p>I am trying to create an Azure DEVOPS ML Pipeline. The following code works 100% fine on Jupyter Notebooks, but when I run it in Azure Devops I get this error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;src\/my_custom_package\/data.py&quot;, line 26, in &lt;module&gt;\n    ws = Workspace.from_config()\n  File &quot;\/opt\/hostedtoolcache\/Python\/3.8.7\/x64\/lib\/python3.8\/site-packages\/azureml\/core\/workspace.py&quot;, line 258, in from_config\n    raise UserErrorException('We could not find config.json in: {} or in its parent directories. '\nazureml.exceptions._azureml_exception.UserErrorException: UserErrorException:\n    Message: We could not find config.json in: \/home\/vsts\/work\/1\/s or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;We could not find config.json in: \/home\/vsts\/work\/1\/s or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;\n    }\n}\n<\/code><\/pre>\n<p>The code is:<\/p>\n<pre><code>#import\nfrom sklearn.model_selection import train_test_split\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.core.experiment import Experiment\nfrom datetime import date\nfrom azureml.core import Workspace, Dataset\n\n\n\nimport pandas as pd\nimport numpy as np\nimport logging\n\n#getdata\nsubscription_id = 'mysubid'\nresource_group = 'myrg'\nworkspace_name = 'mlplayground'\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\ndataset = Dataset.get_by_name(workspace, name='correctData')\n\n\n#auto ml\nws = Workspace.from_config()\n\n\nautoml_settings = {\n    &quot;iteration_timeout_minutes&quot;: 2880,\n    &quot;experiment_timeout_hours&quot;: 48,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;primary_metric&quot;: 'spearman_correlation',\n    &quot;featurization&quot;: 'auto',\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;n_cross_validations&quot;: 5,\n    &quot;max_concurrent_iterations&quot;: 4,\n    &quot;max_cores_per_iteration&quot;: -1,\n}\n\n\n\ncpu_cluster_name = &quot;computecluster&quot;\ncompute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\nprint(compute_target)\nautoml_config = AutoMLConfig(task='regression',\n                             compute_target = compute_target,\n                             debug_log='automated_ml_errors.log',\n                             training_data = dataset,\n                             label_column_name=&quot;paidInDays&quot;,\n                             **automl_settings)\n\ntoday = date.today()\nd4 = today.strftime(&quot;%b-%d-%Y&quot;)\n\nexperiment = Experiment(ws, &quot;myexperiment&quot;+d4)\nremote_run = experiment.submit(automl_config, show_output = True)\n\nfrom azureml.widgets import RunDetails\nRunDetails(remote_run).show()\n\nremote_run.wait_for_completion()\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-02-01 11:05:33.493 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":2339,
        "Owner_creation_date":"2011-04-05 19:05:03.093 UTC",
        "Owner_last_access_date":"2022-09-16 12:42:27.473 UTC",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Answer_body":"<p>There is something weird happening on your code, you are getting the data from a first workspace (<code>workspace = Workspace(subscription_id, resource_group, workspace_name)<\/code>), then using the resources from a second one (<code>ws = Workspace.from_config()<\/code>). I would suggest avoiding having code relying on two different workspaces, especially when you know that an underlying datasource can be registered (linked) to multiple workspaces (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#create-and-register-datastores\" rel=\"nofollow noreferrer\">documentation<\/a>).<\/p>\n<p>In general using a <code>config.json<\/code> file when instantiating a <code>Workspace<\/code> object will result in an interactive authentication. When your code will be processed and you will have a log asking you to reach a specific URL and enter a code. This will use your Microsoft account to verify that you are authorized to access the Azure resource (in this case your <code>Workspace('mysubid', 'myrg', 'mlplayground')<\/code>). This has its limitations when you start deploying the code onto virtual machines or agents, you will not always manually check the logs, access the URL and authenticate yourself.<\/p>\n<p>For this matter it is strongly recommended setting up more advanced authentication methods and personally I would suggest using the service principal one since it is simple, convinient and secure if done properly.\nYou can follow Azure's official documentation <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-setup-authentication#configure-a-service-principal\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-02-09 10:17:20.13 UTC",
        "Answer_score":1.0,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65991587",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71897851,
        "Question_title":"Azure Machine Learning Computes - Template properties - Required properties for attach operation",
        "Question_body":"<p>As described in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/workspaces\/computes?tabs=bicep\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/workspaces\/computes?tabs=bicep<\/a> there are the properties <code>location<\/code>, <code>sku<\/code>, <code>tags<\/code> and <code>identity<\/code>.<\/p>\n<p>For me it is not clear whether these properties relate to the parent workspace or to the compute resource (e.g. as the there is also <code>computeLocation<\/code> or <code>sku<\/code> as far as I can see should have the same value as the workspace)...<\/p>\n<p>It would be great when someone can clarify to which resource these properties and related values belong to (workspace vs. compute resource).<\/p>\n<p><strong>EDIT:<\/strong>\nAlso: which properties are actually required for attach versus create? E.g. do I need <code>identity<\/code> or <code>computeLocation<\/code> for attach, and if yes what is the purpose of it as the compute resource is being created in another context?<\/p>\n<p>I also figured out that <code>location<\/code> as well as <code>disableLocalAuth<\/code> are required for the attach operation - why when the resource is being deployed in another context and only attached?<\/p>\n<p>And why do I get <code>unsupported compute type<\/code> when checking for the compute resources via Azure CLI for the attached AKS?<\/p>\n<pre><code>{\n    &quot;description&quot;: &quot;Default AKS Cluster&quot;,\n    &quot;id&quot;: &quot;\/subscriptions\/xxx\/resourceGroups\/xxx\/providers\/Microsoft.MachineLearningServices\/workspaces\/xxx\/computes\/DefaultAKS&quot;,\n    &quot;location&quot;: &quot;westeurope&quot;,\n    &quot;name&quot;: &quot;DefaultAKS&quot;,\n    &quot;provisioning_state&quot;: &quot;Succeeded&quot;,\n    &quot;resourceGroup&quot;: &quot;xxx&quot;,\n    &quot;resource_id&quot;: &quot;\/subscriptions\/xxx\/resourcegroups\/xxx\/providers\/Microsoft.ContainerService\/managedClusters\/xxx&quot;,\n    &quot;type&quot;: &quot;*** unsupported compute type ***&quot;\n}\n<\/code><\/pre>\n<p><strong>EDIT-2:<\/strong><\/p>\n<p>So based on the response from @SairamTadepalli-MT all the properties actually relate to the compute resource - what makes sense. Still, I don't understand the purpose of a few of these properties. For instance why is there a &quot;location&quot; and a &quot;computeLocation&quot; or what is the meaning of &quot;sku&quot; (e.g. I tried &quot;AmlCompute&quot; and provided the value &quot;Basic&quot; - but &quot;Basic&quot; is the &quot;sku&quot; of the workspace and for &quot;AmlCompute&quot; the size is actually defined by the &quot;vmSize&quot; or?...).<\/p>\n<p>What brings me to the next point: the current documentation currently lacks a detailed description in which scenarios which properties can have which values respectively need to be provided (beside &quot;properties&quot;).<\/p>\n<p>This is also true for attach (i.e. providing a &quot;resourceId&quot;) vs. create (i.e. providing &quot;properties&quot;): which properties are actually required for attach? For what I figured out it requires &quot;location&quot; and &quot;disableLocalAuth&quot; - why do I need these properties as I would assume &quot;name&quot; and &quot;resourceId&quot; (and maybe &quot;computeType&quot;) should be sufficient to attach a compute resource? What is the purpose of properties like &quot;sku&quot;, &quot;tags&quot; or &quot;identity&quot; when I attach an existing compute resource?<\/p>\n<p>Finally regarding &quot;unsupported compute type&quot;: not sure if your response really helps me. The AKS is successfully attached, so I don't understand why I get &quot;unsupported compute type&quot;. This should be fixed.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-16 22:14:33.33 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-04-19 07:22:58.357 UTC",
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azure-bicep",
        "Question_view_count":96,
        "Owner_creation_date":"2016-10-12 19:46:58.963 UTC",
        "Owner_last_access_date":"2022-09-15 10:44:58.51 UTC",
        "Owner_reputation":8729,
        "Owner_up_votes":128,
        "Owner_down_votes":0,
        "Owner_views":251,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71897851",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63462513,
        "Question_title":"'MSSQL' encountered unexpected exception of type 'InvalidOperationException' with HResult 'x80131509' while opening connection",
        "Question_body":"<p>When I am trying to load a query into a tabular dateset (from a devops docker image) I will get the following error:<\/p>\n<pre><code>raise DatasetValidationError(error_message + '\\n' + str(e), e)\nazureml.data.dataset_error_handling.DatasetValidationError: Cannot load any data from the datastore using the SQL query &quot;&lt;azureml.data.datapath.DataPath object at 0x&gt;&quot;. Please make sure the datastore and query is correct.\n\nError Code: ScriptExecution.DatabaseConnection.Unexpected\nFailed Step: 9ad57100-4870-49d2-a32f-1c9c15c244e0\nError Message: ScriptExecutionException was caused by DatabaseConnectionException.\n  DatabaseConnectionException was caused by UnexpectedException.\n    'MSSQL' encountered unexpected exception of type 'InvalidOperationException' with HResult 'x80131509' while opening connection.\n      Internal connection fatal error.\n<\/code><\/pre>\n<p>I believe that I have allowed the connection in firewall (I might not have done it quite right).<\/p>\n<p>I don't get the error when I am running it from the notebook (on the compute instance).<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-18 05:42:27.383 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":156,
        "Owner_creation_date":"2020-08-18 02:37:03.227 UTC",
        "Owner_last_access_date":"2021-09-26 10:54:30.93 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63462513",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41260237,
        "Question_title":"Not getting proper result in Model Training while using Azure Machine Learning Studio with Two Class Bayes Point Machine Algorithm",
        "Question_body":"<p>We are using <strong>Azure Machine Learning Studio<\/strong> for building Trained Model and for that we have used <strong>Two Class Bayes Point Machine Algorithm<\/strong>.\nFor sample data , we have imported .CSV file that contains columns such as: <strong>Tweets and Label<\/strong>.<\/p>\n\n<p>After deploying the web service, we got improper output.\nWe want our algorithm to predict the result of Label as 0 or 1 on the basis of different types tweets, that are already stored in the dataset. <\/p>\n\n<p>While testing it with the tweets that are there in the dataset, it gives proper result, but the problem occurs while testing it with other tweets(that are not there in the dataset).<\/p>\n\n<p>You can view our experiment over here:\n <a href=\"https:\/\/i.stack.imgur.com\/sqB9z.png\" rel=\"nofollow noreferrer\">Experiment<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-12-21 10:12:16.443 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":128,
        "Owner_creation_date":"2016-10-01 10:03:57.327 UTC",
        "Owner_last_access_date":"2019-03-13 13:05:11.79 UTC",
        "Owner_reputation":85,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41260237",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52353941,
        "Question_title":"How to limit the request parameters in Azure Machine Learning",
        "Question_body":"<p>I'm stuck with web services in Azure ML :\/<\/p>\n\n<p>I am setting up a web service with Azure Machine Learning to estimate a car price based on 5 attributes out of 150 in my database. It works fine in the way that if I provide in the test endpoint 5 attributes out of the 150 it requires, it gives me a valid answer. As you can see below \"Scored Label : 10185....\".<\/p>\n\n<p>My question is the following : how do you get the web service to only require 4 input ? The ones I want are in the output (gearingType,MakeTxt,mileage,modelTxt). Price, is off course what I try to guess.<\/p>\n\n<p>Thanks for any help!\nRegards,\nAlexandre<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ksW5P.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ksW5P.png\" alt=\"unexpected endpoint fields in input (150 vs 4) and output (6 vs 1)\"><\/a><\/p>\n\n<p>Here is what my experience looks like, as you can see I used \"Select Columns in Dataset\" to select my 4 input + 1 output <a href=\"https:\/\/i.stack.imgur.com\/Rn3IC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Rn3IC.png\" alt=\"here is what it looks like in AzureML\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/uTxpM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uTxpM.png\" alt=\"and here are the columns I selected\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ksW5P.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ksW5P.png\" alt=\"unexpected endpoint fields in input (150 vs 4) and output (6 vs 1)\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2018-09-16 12:03:22.26 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-09-16 15:22:32.337 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":358,
        "Owner_creation_date":"2012-02-20 10:37:33.273 UTC",
        "Owner_last_access_date":"2021-11-01 14:16:52.27 UTC",
        "Owner_reputation":1543,
        "Owner_up_votes":33,
        "Owner_down_votes":0,
        "Owner_views":75,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bruxelles, Belgique",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52353941",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72864516,
        "Question_title":"Azure ML v2 Pipeline Yaml : Steps not running in the specified Conda Environment",
        "Question_body":"<p>I am trying to build an azure ML pipeline using the Azureml cli v2 but the steps in the  pipeline are not running in the specified conda environment because I am getting a dependency error (which is already installed in the specified environment). Here is the yaml I am writing to generate the pipeline:<\/p>\n<pre><code>$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/pipelineJob.schema.json\ntype: pipeline\nexperiment_name: my_training\ndescription: Training Pipeline to train a model for binary classification\ninputs:\n training_images:\n    type: uri_folder\n    mode: download # pick ro_mount, rw_mount or download\n    path: azureml:\/\/datastores\/mydatastore\/paths\/my_data\/dummy_dataset\/**\n\noutputs:\n  step_output_train:\n    type: uri_folder\nsettings:\n  default_datastore: azureml:mydatastore\n  continue_on_step_failure: false\n\njobs:\n  train:\n    name: training\n    display_name: Model-training\n    environment: azureml:training_env@latest\n    code: ..\/..\/my_code\/training\n    command: &gt;-\n      python train.py\n      --step_output ${{outputs.step_output}}\n      --epochs ${{inputs.epochs}}\n    inputs:\n      epochs: 1  \n    outputs:\n      step_output: ${{parent.outputs.step_output_train}}\n    compute: azureml:mycomputeclust\n    resources:\n      instance_count: 1 \n\n<\/code><\/pre>\n<p>Please guide me how we can tackle this issue.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-05 05:48:40.017 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-pipelines|azure-machine-learning-service",
        "Question_view_count":86,
        "Owner_creation_date":"2018-08-19 06:02:24.467 UTC",
        "Owner_last_access_date":"2022-09-01 13:39:30.257 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72864516",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61225608,
        "Question_title":"Azure Machine Learning : unable to create compute instance with 12 month trial license",
        "Question_body":"<p>I am preparing for DP-100 certification.\nAs a part of self-learning, I created one trial account using my outlook email for 12 months.\nDuring the part where I needed to set up a <strong>Compute Instance<\/strong>, I encounter an error as shown below.\nWhat is the reason, Can't I create a <strong>Compute Instance<\/strong> with a trial account.<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/MWsnt.png\" alt=\"enter image description here\"><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-15 09:39:58.133 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-04-15 09:48:19.443 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":19,
        "Owner_creation_date":"2020-04-15 09:28:19.727 UTC",
        "Owner_last_access_date":"2020-09-16 15:21:23.563 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61225608",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40798184,
        "Question_title":"Azure ML Batch Run - Single Output",
        "Question_body":"<p>I create an forecasting experiment using R engine. My data source is pivoted, hence I need to pass row by row.\nThe output works great with single row prediction. But when I try to populate multiple lines, it still gives single row output - for the first record only.<\/p>\n\n<p>I'm trying to loop my result as follows :<\/p>\n\n<pre><code># Map 1-based optional input ports to variables\ndataset1 &lt;- maml.mapInputPort(1) # class: data.frame\n\nlibrary(forecast)\nlibrary(reshape)\nlibrary(dplyr)\nlibrary(zoo)\n#exclude non required columns\nmy.ds &lt;- dataset1[, -c(4,5,6)]\n# set the CIs we want to use here, so we can reuse this vector\ncis &lt;- c(80, 95)\n\nfor (i in 1:nrow(my.ds)) {\nmy.start &lt;- my.ds[i,c(3)]\nmy.product &lt;- my.ds[i, \"Product\"]\nmy.location &lt;- my.ds[i, \"Location\"]\nmy.result &lt;- melt(my.ds[i,], id = c(\"Product\",\"Location\"))\nmy.ts &lt;- ts(my.result$value, frequency=52, start=c(my.start,1))\n# generate the forecast using those ci levels\nf &lt;- forecast(na.interp(my.ts), h=52, level=cis)\n# make a data frame containing the forecast information, including the index\nz &lt;- as.data.frame(cbind(seq(1:52),\n                       f$mean,\n                       Reduce(cbind, lapply(seq_along(cis), function(i) cbind(f$lower[,i], f$upper[,i])))))\n# give the columns better names\nnames(z) &lt;- c(\"index\", \"mean\", paste(rep(c(\"lower\", \"upper\"), times = length(cis)), rep(cis, each = 2), sep = \".\"))\n# manipulate the results as you describe\nzw &lt;- z %&gt;%\n# keep only the variable you want and its index\nmutate(sssf = upper.95 - mean) %&gt;%\nselect(index, mean, sssf) %&gt;%\n# add product and location info\nmutate(product = my.product,\n       location = my.location) %&gt;%\n# rearrange columns so it's easier to read\nselect(product, location, index, mean, sssf)\nzw &lt;- melt(zw, id.vars = c(\"product\", \"location\", \"index\"), measure.vars = c(\"mean\",\"sssf\"))\ndata.set &lt;- cast(zw, product + location ~ index + variable, value = \"value\")\n# Select data.frame to be sent to the output Dataset port\nmaml.mapOutputPort(\"data.set\");\n}\n<\/code><\/pre>\n\n<p>This is design of my experiment :\n<a href=\"https:\/\/i.stack.imgur.com\/6lYd1.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6lYd1.png\" alt=\"experiment\"><\/a><\/p>\n\n<p>And this is how sample <a href=\"https:\/\/www.dropbox.com\/s\/xgfc7pnyy29frid\/dhf-00009E850%20-%20Copy.csv?dl=0\" rel=\"nofollow noreferrer\" title=\"input file\">input<\/a> looks like :<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/QlRiE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/QlRiE.png\" alt=\"Sample input\"><\/a><\/p>\n\n<p>I'm testing using the Excel test workbook downloaded from experiment site.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-11-25 05:19:58.437 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-11-25 15:00:26.02 UTC",
        "Question_score":2,
        "Question_tags":"r|forecasting|azure-machine-learning-studio",
        "Question_view_count":195,
        "Owner_creation_date":"2013-08-20 11:57:52.723 UTC",
        "Owner_last_access_date":"2022-09-06 11:40:53.407 UTC",
        "Owner_reputation":998,
        "Owner_up_votes":162,
        "Owner_down_votes":6,
        "Owner_views":136,
        "Answer_body":"<p>I figured out the problem :<\/p>\n\n<pre><code>{\n...\nds &lt;- cast(zw, product + location ~ index + variable, value = \"value\")\ndata.set &lt;- rbind(data.set, ds)\n}\n# Select data.frame to be sent to the output Dataset port\nmaml.mapOutputPort(\"data.set\");\n<\/code><\/pre>\n\n<p>I should be merging the rows and then output outside of the loop.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-11-25 15:02:05.487 UTC",
        "Answer_score":1.0,
        "Owner_location":"Malaysia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40798184",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72518344,
        "Question_title":"Logging and Fetching Run Parameters in AzureML",
        "Question_body":"<p>I am able to log and fetch metrics to AzureML using Run.log, however, I need a way to also log run parameters, like Learning Rate, or Momentum. I can't seem to find anything in the AzureML Python SDK documentation to achieve this. However, if I use MLflow's mlflow.log_param, I am able to log parameters, and they even nicely show up on the AzureML Studio Dashboard (bottom right of the image):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/q9b7Q.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/q9b7Q.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Again, I am able to fetch this using MLflow's get_params() function, but I can't find a way to do this using just AzureML's Python SDK. Is there a way to do this directly using <code>azureml<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-06 13:22:27.343 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|mlflow|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":73,
        "Owner_creation_date":"2019-04-05 20:51:24.963 UTC",
        "Owner_last_access_date":"2022-09-24 07:41:48.093 UTC",
        "Owner_reputation":438,
        "Owner_up_votes":15,
        "Owner_down_votes":2,
        "Owner_views":120,
        "Answer_body":"<p>The retrieving of log run parameters like <strong>Learning Rate, or Momentum<\/strong> is not possible with <strong>AzureML<\/strong> alone. Because it was tied with <strong>MLFlow<\/strong> and <strong>azureml-core<\/strong>. without those two involvements, we cannot retrieve the log run parameters.<\/p>\n<pre><code>pip install azureml-core mlflow azureml-mlflow\n<\/code><\/pre>\n<p>Need to install these three for getting run parameters. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Link<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-05 05:29:14.31 UTC",
        "Answer_score":1.0,
        "Owner_location":"Hyderabad, Telangana, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72518344",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63839680,
        "Question_title":"Unable to create pyspark DataFrame from Datastore in azureml-sdk (version 1.12.0)",
        "Question_body":"<p>I am trying to read contents from a CSV file into Spark DataFrame using azureml-sdk using following code but an exception is being thrown.<\/p>\n<p><strong>Code throwing exception<\/strong><\/p>\n<pre><code>import pyspark.sql as spark\nfrom azureml.core import Dataset\ndataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\nsdf: spark.DataFrame = dataset.to_spark_dataframe()\nsdf.show()\n<\/code><\/pre>\n<p><strong>Exception<\/strong><\/p>\n<pre><code>---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _try_execute(action, operation, dataset_info, **kwargs)\n    100         else:\n--&gt; 101             return action()\n    102     except Exception as e:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/_loggerfactory.py in wrapper(*args, **kwargs)\n    178                 try:\n--&gt; 179                     return func(*args, **kwargs)\n    180                 except Exception as e:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/dataflow.py in to_spark_dataframe(self)\n    763         self._raise_if_missing_secrets()\n--&gt; 764         return self._spark_executor.get_dataframe(steps_to_block_datas(self._steps), use_sampling=False)\n    765 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in get_dataframe(self, steps, use_sampling, overrides, use_first_record_schema)\n    136                              overrides,\n--&gt; 137                              use_first_record_schema)\n    138 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in _execute(self, blocks, export_format, use_sampling, overrides, use_first_record_schema)\n    169                                           + lariat_version + '.')\n--&gt; 170             raise e\n    171 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in _execute(self, blocks, export_format, use_sampling, overrides, use_first_record_schema)\n    160             if export_format == ExportScriptFormat.PYSPARKDATAFRAMELOADER:\n--&gt; 161                 return module.LoadData(secrets=secrets, schemaFromFirstRecord=use_first_record_schema)\n    162             else:\n\n\/tmp\/spark-6ce53791-c8e4-4db0-bd37-bedb53a1ef1e\/userFiles-dda6cd30-5d1e-48cf-af87-9c7c2a4b8038\/loaderb9bc01c2b40c4b7aa86a95d343021e0c.py in LoadData(secrets, schemaFromFirstRecord)\n      8 def LoadData(secrets=dict(), schemaFromFirstRecord=False):\n----&gt; 9     pex = Executor(&quot;S4ddf53ee8d5f4173bd3dcf4b51d78247&quot;, &quot;dprep_2.11&quot;, &quot;0.116.0&quot;, &quot;42315&quot;, &quot;39a925e4-9ae9-4588-93c4-5433250b7f73&quot;)\n     10     jex = pex.jex\n\n\/tmp\/spark-6ce53791-c8e4-4db0-bd37-bedb53a1ef1e\/userFiles-dda6cd30-5d1e-48cf-af87-9c7c2a4b8038\/Executor.py in __init__(self, scalaName, dprepMavenPackageName, dprepMavenPackageMatchingVersion, pythonHostChannelPort, pythonHostSecret)\n     54             pythonHostChannelPort,\n---&gt; 55             pythonHostSecret)\n     56 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/py4j\/java_gateway.py in __call__(self, *args)\n   1568         return_value = get_return_value(\n-&gt; 1569             answer, self._gateway_client, None, self._fqn)\n   1570 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/py4j\/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    327                     &quot;An error occurred while calling {0}{1}{2}.\\n&quot;.\n--&gt; 328                     format(target_id, &quot;.&quot;, name), value)\n    329             else:\n\nPy4JJavaError: An error occurred while calling None.com.microsoft.dprep.execution.PySparkExecutor.\n: java.lang.NoClassDefFoundError: Could not initialize class com.microsoft.dprep.integration.azureml.AmlPySdkInvoker$\n    at com.microsoft.dprep.execution.PySparkExecutor.&lt;init&gt;(PySparkExecutor.scala:79)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:238)\n    at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n    at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n    at py4j.GatewayConnection.run(GatewayConnection.java:238)\n    at java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\nAzureMLException                          Traceback (most recent call last)\n&lt;ipython-input-30-c546b1aded42&gt; in &lt;module&gt;\n      2 from azureml.core import Dataset\n      3 dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\n----&gt; 4 sdf: spark.DataFrame = dataset.to_spark_dataframe()\n      5 sdf.show()\n      6 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_loggerfactory.py in wrapper(*args, **kwargs)\n    124             with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n    125                 try:\n--&gt; 126                     return func(*args, **kwargs)\n    127                 except Exception as e:\n    128                     if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/tabular_dataset.py in to_spark_dataframe(self)\n    187         return _try_execute(dataflow.to_spark_dataframe,\n    188                             'to_spark_dataframe',\n--&gt; 189                             None if self.id is None else {'id': self.id, 'name': self.name, 'version': self.version})\n    190 \n    191     @track(_get_logger, custom_dimensions={'app_name': 'TabularDataset'}, activity_type=_PUBLIC_API)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _try_execute(action, operation, dataset_info, **kwargs)\n    102     except Exception as e:\n    103         message, is_dprep_exception = _construct_message_and_check_exception_type(e, dataset_info, operation)\n--&gt; 104         _dataprep_error_handler(e, message, is_dprep_exception)\n    105 \n    106 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _dataprep_error_handler(e, message, is_dprep_exception)\n    143         raise AzureMLException(message, inner_exception=e)\n    144     else:\n--&gt; 145         raise AzureMLException(message, inner_exception=e)\n    146 \n    147 \n\nAzureMLException: AzureMLException:\n    Message: Execution failed unexpectedly due to: Py4JJavaError\n    InnerException An error occurred while calling None.com.microsoft.dprep.execution.PySparkExecutor.\n: java.lang.NoClassDefFoundError: Could not initialize class com.microsoft.dprep.integration.azureml.AmlPySdkInvoker$\n    at com.microsoft.dprep.execution.PySparkExecutor.&lt;init&gt;(PySparkExecutor.scala:79)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:238)\n    at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n    at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n    at py4j.GatewayConnection.run(GatewayConnection.java:238)\n    at java.lang.Thread.run(Thread.java:748)\n\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Execution failed unexpectedly due to: Py4JJavaError&quot;\n    }\n}\n<\/code><\/pre>\n<p>However, I can read and print the data with the following code i.e. create as a <code>Panda<\/code>'s <code>DataFrame<\/code>.<\/p>\n<p><strong>Working code<\/strong><\/p>\n<pre><code>dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\n#sdf: spark.DataFrame = dataset.to_spark_dataframe()\nsdf: pd.DataFrame = dataset.to_pandas_dataframe()\nprint(sdf.head(3))\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-09-11 01:38:28.583 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":420,
        "Owner_creation_date":"2009-06-23 03:11:55.29 UTC",
        "Owner_last_access_date":"2022-09-25 03:45:28.337 UTC",
        "Owner_reputation":77230,
        "Owner_up_votes":2724,
        "Owner_down_votes":43,
        "Owner_views":6359,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Cumming, GA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63839680",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73211086,
        "Question_title":"pandas, problem with sklearn's KNNImputer: MemoryError: Unable to allocate 2.37 PiB for an array with shape (2567655, 130060533) and data type float64",
        "Question_body":"<p>I have data with the shape 130060533 rows \u00d7 4 columns, and I am trying to run KNNImputer(n_neighbors=2)  from sklearn.impute, but I get this message:<\/p>\n<blockquote>\n<p>MemoryError: Unable to allocate 2.37 PiB for an array with shape\n(2567655, 130060533) and data type float64<\/p>\n<\/blockquote>\n<p>I tried reducing the size of the table by using the int8 type, but still no change.\nI am running this on Azure ML Studio on a Jupyter notebook on a computer with 64-core and 128GB RAM.\nI also checked and I am using python 64 bit.\nDo you have any suggestions?<\/p>\n<p>thanks<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-08-02 16:53:02.94 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-02 17:04:44.16 UTC",
        "Question_score":0,
        "Question_tags":"pandas|out-of-memory|knn|azure-machine-learning-service|imputation",
        "Question_view_count":46,
        "Owner_creation_date":"2018-04-30 21:48:05.907 UTC",
        "Owner_last_access_date":"2022-09-23 23:23:36.143 UTC",
        "Owner_reputation":65,
        "Owner_up_votes":20,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Los Angeles, CA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73211086",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":43587399,
        "Question_title":"Azure ML Experiment Scheduling - No web service",
        "Question_body":"<p>I want to schedule an Azure ML experiment to run everyday without creating a web service. Is that possible. Is there no scheduler in Azure ML itself.<\/p>\n\n<p>I basically import the latest data from Azuresql and then export the predictions again into AzureSql.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-04-24 11:54:50.893 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":116,
        "Owner_creation_date":"2017-04-24 11:43:32.61 UTC",
        "Owner_last_access_date":"2017-07-11 09:55:17.333 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/43587399",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68242220,
        "Question_title":"Azure Application Insight: Stream Telemetry to a file",
        "Question_body":"<p>I'm interested in gathering some metrics on who and when someone is assigned\/removed from a task.  The idea is to use that data for machine learning purposes.<\/p>\n<p>Since I feel that storing those metrics in SQL Server would be pointless due to its read-only nature of and the potential volume of rows that would be created, I wanted to use Azure's Application Insights to record those metrics.<\/p>\n<p>While logging those events should be straightforward, I would also like to know whether it's possible to stream those events to a file so that my machine learning model can process them?  That way, if data is purged from Application Insights, I would have a backup.<\/p>\n<p>Alternatively, what ways can I have my machine learning model get data from Application Insights?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-07-04 06:17:38.397 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-application-insights|azure-monitoring|azure-machine-learning-service",
        "Question_view_count":74,
        "Owner_creation_date":"2020-01-26 01:44:39.763 UTC",
        "Owner_last_access_date":"2022-09-23 02:50:03.947 UTC",
        "Owner_reputation":425,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":40,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68242220",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41614428,
        "Question_title":"Caret package in Microsoft Azure ML",
        "Question_body":"<p>I want to load caret library in Azure ML. This works when R version is set to be CRAN R 3.1.0, but on Microsoft R Open 3.2.2 won't work. I must use R Open version because of the other packages that I'm using in my project, which are not supported in that earlier version 3.1.0.\nTherefore, the question is how to load this library on ML Azure using Microsoft R Open 3.2.2?<\/p>\n\n<p>Thanks!<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2017-01-12 13:27:03.947 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2018-12-02 15:37:10.773 UTC",
        "Question_score":2,
        "Question_tags":"r|azure|load|r-caret|azure-machine-learning-studio",
        "Question_view_count":961,
        "Owner_creation_date":"2011-08-15 17:31:11.893 UTC",
        "Owner_last_access_date":"2022-06-28 08:24:44.033 UTC",
        "Owner_reputation":830,
        "Owner_up_votes":212,
        "Owner_down_votes":2,
        "Owner_views":128,
        "Answer_body":"<p>From one of your comments above, it sounds like the version of the <code>caret<\/code> package you've used requires an R version >3.1.2. I recommend using an older version of the package: the <code>caret<\/code> binary from <a href=\"http:\/\/cran.cnr.berkeley.edu\/bin\/windows\/contrib\/3.1\/\" rel=\"nofollow noreferrer\">this 3.1 archive<\/a> (6.0-68) worked for me. I used these statements to load the package:<\/p>\n\n<pre><code>install.packages(\"src\/caret_6.0-68.zip\", lib=\".\", repos= NULL, verbose=TRUE)\nlibrary(\"caret\", lib.loc=\".\", verbose=TRUE)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-01-25 02:16:45.283 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41614428",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64338898,
        "Question_title":"How to load an experiment in azureml?",
        "Question_body":"<p>I have many experiment, like:<\/p>\n<p><img src=\"https:\/\/user-images.githubusercontent.com\/40580910\/95883598-82a07d00-0d51-11eb-847d-872452f6caa4.png\" alt=\"image\" \/><\/p>\n<p>and now, i want load an experiment<\/p>\n<pre><code>#%% sumonando os pacotes e verificando azureml.core\nimport azureml.core\nimport pandas as pd\nimport numpy as np\nimport logging\n\nprint(&quot;AzureML SDK Version: &quot;, azureml.core.VERSION)\n\n#%% Conectando ao azure e crinado o exparimento\n\nfrom azureml.core import Workspace, Experiment\n\nws = Workspace.from_config() \nprint(Experiment.list(ws))\n#%%\nExperiment = Experiment.from_directory('teste2-Monitor-Runs') `\n<\/code><\/pre>\n<p>but<\/p>\n<pre><code>&quot;error&quot;: {\n    &quot;message&quot;: &quot;No cache found for current project, try providing resource group and workspace \narguments&quot;\n}`\n<\/code><\/pre>\n<hr \/>\n<p>Content: <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.experiment(class)?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.core.Experiment class - Azure Machine Learning Python<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-13 16:00:47.24 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":254,
        "Owner_creation_date":"2018-04-02 02:01:36.793 UTC",
        "Owner_last_access_date":"2022-09-23 14:36:15.803 UTC",
        "Owner_reputation":264,
        "Owner_up_votes":276,
        "Owner_down_votes":2,
        "Owner_views":23,
        "Answer_body":"<p>I believe it is that way.<\/p>\n<pre><code>from azureml.core import Experiment, Workspace\nExperiment = ws.experiments[&quot;teste2-Monitor-Runs&quot;]\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-14 18:31:40.72 UTC",
        "Answer_score":0.0,
        "Owner_location":"Rio de Janeiro, RJ, Brasil",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64338898",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65556574,
        "Question_title":"How to make prediction after model registration in azure?",
        "Question_body":"<p>I created a simply model and then registered in azure. How can I make a prediction?<\/p>\n<pre><code>from sklearn import svm\nimport joblib\nimport numpy as np\n\n# customer ages\nX_train = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\nX_train = X_train.reshape(-1, 1)\n# churn y\/n\ny_train = [&quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;]\n\nclf = svm.SVC(gamma=0.001, C=100.)\nclf.fit(X_train, y_train)\n\njoblib.dump(value=clf, filename=&quot;churn-model.pkl&quot;)\n<\/code><\/pre>\n<p>Registration:<\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.get(name=&quot;myworkspace&quot;, subscription_id='My_subscription_id', resource_group='ML_Lingaro')\n\nfrom azureml.core.model import Model\nmodel = Model.register(workspace=ws, model_path=&quot;churn-model.pkl&quot;, model_name=&quot;churn-model-test&quot;)\n<\/code><\/pre>\n<p>Prediction:<\/p>\n<pre><code>from azureml.core.model import Model\nimport os\n\nmodel = Model(workspace=ws, name=&quot;churn-model-test&quot;)\nX_test = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\nmodel.predict(X_test) ???? \n<\/code><\/pre>\n<p>Error: <code>AttributeError: 'Model' object has no attribute 'predict'<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-04 01:09:35.69 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-01-04 01:24:17.017 UTC",
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":540,
        "Owner_creation_date":"2020-11-20 01:00:01.337 UTC",
        "Owner_last_access_date":"2021-04-10 20:06:50.227 UTC",
        "Owner_reputation":73,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":"<p>great question -- I also had the same misconception starting out. The missing piece is that there's a difference between model 'registration' and model 'deployment'. Registration is simply for tracking and for easy downloading at a later place and time. Deployment is what you're after, making a model available to be scored against.<\/p>\n<p>There's a <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">whole section in the docs about deployment<\/a>. My suggestion would be to deploy it locally first for testing.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-01-04 05:20:26.627 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65556574",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67517072,
        "Question_title":"Deploying YOLOV5 on Azure Machine Learning",
        "Question_body":"<p>I have a YOLOV5 model trained on a custom dataset and I try to deploy it to Azure with a pipeline.<\/p>\n<p>First I tried it with a notebook instance and everything is fine but since I need to automatize it I am try to create a &quot;dataset&quot; on Azure but when I upload the dataset it changes the dataset type (Normally in YOLO it must be like this -images(folder) -labels(folder))<\/p>\n<p>Later tried it with method below:<\/p>\n<pre><code>run = Experiment(ws, name='try').submit(src)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>but when I run it I am having the following error<\/p>\n<pre><code>TypeError: '&gt;' not supported between instances of 'int' and 'str'\n<\/code><\/pre>\n<p>I read several guides from Microsoft but none of them includes deploying an object detection model with a custom dataset.<\/p>\n<p>So I am a bit lost, If anybody can guide me I would appreciate it<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-05-13 09:41:58.617 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-05-14 07:17:25.207 UTC",
        "Question_score":1,
        "Question_tags":"azure|object-detection|yolo|azure-machine-learning-service|yolov5",
        "Question_view_count":1035,
        "Owner_creation_date":"2021-03-24 10:00:57.473 UTC",
        "Owner_last_access_date":"2022-09-10 14:40:32.643 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67517072",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44910388,
        "Question_title":"azure ML studio terrible performance",
        "Question_body":"<p>the last day or two Azure ML studio performance is terrible.<\/p>\n\n<p>It can take up to 10 mins to save a simple experiment and another 10 mins to run it.<\/p>\n\n<p>These are simple tutorial experiments, nothing massive, using at maximum 18mb of data.<\/p>\n\n<p>When i finally get the experiment to run and try to view the evaluation results, ML Studio spins for 5 mins before giving the error \"Error producing the visualization of the output \"<\/p>\n\n<p>Note this error also occasionally occurs when i am just trying to view the list of saved experiments.<\/p>\n\n<p>Im in the process of completing the Microsoft data science professional course and this is completely blocking me from making any progress.<\/p>\n\n<p>Any info on what might be wrong would be appreciated. <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2017-07-04 16:10:24.33 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":478,
        "Owner_creation_date":"2015-11-16 13:58:07.793 UTC",
        "Owner_last_access_date":"2018-11-15 18:44:42.427 UTC",
        "Owner_reputation":194,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":44,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Nairobi, Kenya",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44910388",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41236871,
        "Question_title":"How to download the trained models from Azure machine studio?",
        "Question_body":"<p>I have created two models in azure ml studio and i want to download those models.<\/p>\n\n<p>Is it possible to download train and score models from azure ml studio?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_creation_date":"2016-12-20 07:25:22.783 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":7,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":7873,
        "Owner_creation_date":"2016-12-20 07:20:54.343 UTC",
        "Owner_last_access_date":"2017-06-06 09:45:50.99 UTC",
        "Owner_reputation":73,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>Models can be trained, scored, saved, and run in AzureML studio, but can't downloaded to your local machine. There's no way to do anything with a model outside of AzureML.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2017-01-14 01:18:43.537 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41236871",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72464079,
        "Question_title":"I can not register a model in my Azure ml experiment using run context",
        "Question_body":"<p>I am trying to register a model  inside one of my azure ml  experiments. I am able to register it via <code>Model.register<\/code> but not via <code>run_context.register_model<\/code><\/p>\n<p>This are the two code sentences I use. The commented one is the one that fails<\/p>\n<pre><code>learn.path = Path('.\/outputs').absolute()\nModel.register(run_context.experiment.workspace, &quot;outputs\/login_classification.pkl&quot;,&quot;login_classification&quot;, tags=metrics)\nrun_context.register_model(&quot;login_classification&quot;, &quot;outputs\/login_classification.pkl&quot;, tags=metrics)\n<\/code><\/pre>\n<p>I received the next error:<\/p>\n<pre><code>Message: Could not locate the provided model_path outputs\/login_classification.pkl\n<\/code><\/pre>\n<p>But model is stored in this path:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/MNojQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/MNojQ.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-01 15:01:58.64 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":86,
        "Owner_creation_date":"2011-12-01 10:02:27.387 UTC",
        "Owner_last_access_date":"2022-09-23 12:26:18.907 UTC",
        "Owner_reputation":729,
        "Owner_up_votes":44,
        "Owner_down_votes":1,
        "Owner_views":85,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72464079",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73234673,
        "Question_title":"Trying to work on R using Azure ML Studio Notebook and facing challenges with ODBC package",
        "Question_body":"<p>I am trying to work on R notebook on ML Studio. Using regular python is easy and works as expected but with R i am facing challenges.<\/p>\n<p>While trying to connect to MS SQL database using odbc() :<\/p>\n<pre><code>library(odbc)\ncon &lt;- dbConnect(odbc(),\n                 Driver = &quot;SQL Server&quot;,\n                 Server = &quot;server&quot;,\n                 Database = &quot;db&quot;,\n                 UID = &quot;user&quot;,\n                 PWD = &quot;password&quot;,\n                 Port = 1433)\n\n\n\nError: nanodbc\/nanodbc.cpp:1021: 00000: [unixODBC][Driver Manager]Can't open lib 'SQL Server' : file not found\n<\/code><\/pre>\n<p>As suggested in some posts, i have also tried replacing  Driver = &quot;SQL Server&quot;, with Driver = &quot;ODBC Driver 11 for SQL Server&quot;. But i see similar error<\/p>\n<pre><code>Error: nanodbc\/nanodbc.cpp:1021: 00000: [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 11 for SQL Server' : file not found \nTraceback:\n<\/code><\/pre>\n<p>Please suggest a work around.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-08-04 10:54:35.93 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-service",
        "Question_view_count":52,
        "Owner_creation_date":"2017-06-02 12:27:30.497 UTC",
        "Owner_last_access_date":"2022-09-20 06:48:21.12 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bangalore, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73234673",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40253448,
        "Question_title":"How Can I use gensim package in Azure ML?",
        "Question_body":"<p>I am using text analysis with Azure ML. So in my python script I want to create a bag of word model and then calculate TFIDF of each words. For that I am using gensim model, It's not working on Azure ML. So is there any options for me? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-26 03:51:57.853 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"machine-learning|text-analysis|azure-machine-learning-studio",
        "Question_view_count":1024,
        "Owner_creation_date":"2016-02-11 19:00:50.737 UTC",
        "Owner_last_access_date":"2022-09-23 07:23:55.703 UTC",
        "Owner_reputation":3811,
        "Owner_up_votes":118,
        "Owner_down_votes":13,
        "Owner_views":703,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Auckland, New Zealand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40253448",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58241305,
        "Question_title":"Is there a way of controlling the version of the Model?",
        "Question_body":"<p>I have one workspace A and a workspace B and I am looking to copy models from workspace A to workspace B.<\/p>\n\n<p>Let's say the model <strong>M_1<\/strong> is in version <strong>V_1<\/strong> in workspace A. I would like to register this model <strong>M_1<\/strong> in workspace B with the <em>same<\/em> version <strong>V_1<\/strong>.<\/p>\n\n<p>Using the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none-\" rel=\"nofollow noreferrer\">register method<\/a><\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>Model.register(workspace_B, model_path, model_from_workspace_A.name)\n<\/code><\/pre>\n\n<p>I am not able to choose the version for this model. By default it sets the version of the registered model as 1 (if it does not exist) or <strong>M_2 + 1<\/strong>\nif it already exists in workspace B.<\/p>\n\n<p>Is there a workaround for this?<\/p>\n\n<p>Thank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-04 18:06:59.847 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":48,
        "Owner_creation_date":"2014-09-14 14:48:11.817 UTC",
        "Owner_last_access_date":"2022-03-01 18:30:27.267 UTC",
        "Owner_reputation":300,
        "Owner_up_votes":38,
        "Owner_down_votes":1,
        "Owner_views":30,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Brazil",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58241305",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60633916,
        "Question_title":"VS Code : Sign In Error :You appear to be offline. Please check your network connection",
        "Question_body":"<p>In VS Code when i try to run the below command for sign in<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/SW9ua.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/SW9ua.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I get below error message and it is not able to login <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/y8zln.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/y8zln.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":3,
        "Question_comment_count":3,
        "Question_creation_date":"2020-03-11 10:29:34.367 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-03-11 11:56:02.623 UTC",
        "Question_score":4,
        "Question_tags":"visual-studio-code|vscode-settings|azure-machine-learning-studio",
        "Question_view_count":2203,
        "Owner_creation_date":"2018-09-14 09:06:45.08 UTC",
        "Owner_last_access_date":"2022-07-05 16:35:06.303 UTC",
        "Owner_reputation":401,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":57,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60633916",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73447386,
        "Question_title":"OpenSSL critical Vulnerability in AzureML Model Deployment to Kubernetes",
        "Question_body":"<p>I have an issue with OpenSSL, I am using the following command to install the latest version of OpenSSL in my Base Docker Image of Azure ML Deployment as the older version has some critical security vulnerability. However, the final image still has the older versions of OPENSSL, it could either be that or AzureML is installing the packages by itself, can anyone tell me how to get past this issue? or delete older versions of OpenSSL?<\/p>\n<pre><code>FROM ubuntu:18.04\n\n# Install dependencies:\nRUN apt-get update  &amp;&amp; apt-get -y install openssl\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/jDAXW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/jDAXW.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-22 15:13:45.127 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-24 07:32:54.98 UTC",
        "Question_score":0,
        "Question_tags":"docker|kubernetes|openssl|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":46,
        "Owner_creation_date":"2016-01-26 08:54:35.09 UTC",
        "Owner_last_access_date":"2022-09-21 20:10:11.297 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73447386",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72729267,
        "Question_title":"Degrading the services automatically by autoscaling in azure services - vCPU",
        "Question_body":"<p>I am designing a learning management system and inflow for the website is more in some cases and  less in another time. I would like to know about the getting the vCPU's which are scaled up to make it down after the stipulated time. I found a document regarding <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/best-practices\/auto-scaling\" rel=\"nofollow noreferrer\">scaling up<\/a> but didn't find a way to scale it down.<\/p>\n<p>Any help is appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-23 11:19:28.11 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-cognitive-services|azure-machine-learning-service",
        "Question_view_count":49,
        "Owner_creation_date":"2022-05-09 19:08:30.643 UTC",
        "Owner_last_access_date":"2022-09-16 03:29:45.173 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":"<p>There is a chance of auto scaling for the normal services in azure cloud services, that means for stipulated time you can increase or decrease as mentioned in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/cloud-services\/cloud-services-how-to-scale-portal\" rel=\"nofollow noreferrer\">link<\/a>.<\/p>\n<p>When it comes for vCPU which is cannot be performed automatically. vCPU can be scaled up based on the request criteria and in the same manner we need to request the support team to scale those down to the normal.<\/p>\n<p><strong>There is no specific procedure to make the auto scaling for vCPU operations. We can increase the capacity of core, but to reduce to the normal, we need to approach the support system for manual changing. You can change it from 10 cores to next level 16 cores, but cannot be performed automatic scaling down from 16 cores to 10 cores.<\/strong><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-06-23 11:38:25.567 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72729267",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58753430,
        "Question_title":"Is there a way to list out my datastores if I've deployed to a VNET?",
        "Question_body":"<p>I followed the instructions in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-enable-virtual-network\" rel=\"nofollow noreferrer\">MSFT Docs<\/a>, but now I can't list our my Datastores either via the SDK nor the Azure Machine Learning studio. <\/p>\n\n<p>Instead, in the studio I see this:\n<a href=\"https:\/\/i.stack.imgur.com\/im2oe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/im2oe.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Is there a way to make this work? Did I miss a step?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-11-07 16:45:27.473 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":164,
        "Owner_creation_date":"2018-06-19 20:17:41.717 UTC",
        "Owner_last_access_date":"2022-09-21 12:31:28.057 UTC",
        "Owner_reputation":392,
        "Owner_up_votes":8,
        "Owner_down_votes":4,
        "Owner_views":39,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58753430",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":28590690,
        "Question_title":"Azure ML App - Complete Experince - Train automatically and Consume",
        "Question_body":"<p>I played a bit around with Azure ML studio. So as I understand the process goes like this:<\/p>\n\n<p>a) Create training experiment. Train it with data. <\/p>\n\n<p>b) Create Scoring experiment. This will include the trained model from the training experiment. Expose this as a service to be consumed over REST.<\/p>\n\n<p>Maybe a stupid question but what is the recommended way to get the complete experience like the one i get when I use an app like <a href=\"https:\/\/datamarket.azure.com\/dataset\/amla\/mba\" rel=\"nofollow\">https:\/\/datamarket.azure.com\/dataset\/amla\/mba<\/a> (Frequently Bought Together API built with Azure Machine Learning). <\/p>\n\n<p>I mean the following:<\/p>\n\n<p>a) Expose 2 or more services - one to train the model and the other to consume (test) the trained model. <\/p>\n\n<p>b) User periodically sends training data to train the model <\/p>\n\n<p>c) The trained model\/models now gets saved available for consumption<\/p>\n\n<p>d) User is now able to send a dataframe to get the predicted results.<\/p>\n\n<p>Is there an additional wrapper that needs to be built?<\/p>\n\n<p>If there is a link documenting this please point me to the same. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-02-18 18:05:24.78 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-02-18 19:04:32.933 UTC",
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":769,
        "Owner_creation_date":"2015-02-18 17:59:15.667 UTC",
        "Owner_last_access_date":"2016-07-08 12:44:42.013 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>The Azure ML retraining API is designed to handle the workflow you describe:<\/p>\n\n<p><a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-retrain-models-programmatically\/\" rel=\"nofollow\">http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-retrain-models-programmatically\/<\/a><\/p>\n\n<p>Hope this helps,<\/p>\n\n<p>Roope - Microsoft Azure ML Team<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-03-03 23:52:28.317 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/28590690",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73724586,
        "Question_title":"Azure ML - Error starting compute instance",
        "Question_body":"<p>A couple of days ago, when I tried to start the Azure ML compute instance linked to my user, I started receiving the following error message:<\/p>\n<pre><code>Services not ready for connections\nTimed out waiting for Jupyter to become ready\n<\/code><\/pre>\n<p>My role in this resource is <strong>AzureML Data Scientist<\/strong>, meaning I can perform all actions within an Azure Machine Learning workspace, <strong>except<\/strong> for creating or deleting compute resources and modifying the workspace itself. In other words, I can't delete the current instance and replace it with a new one.<\/p>\n<p>In the past few days, I have tried to restart, force restart, and follow any tutorial remotely related to this issue I could find online, but I wasn\u2019t able to find a solution for this problem.<\/p>\n<p><strong>My question:<\/strong> Does anyone know how I can fix the compute instance booting process, or why I'm encountering this issue (preferably without having to open a ticket and wait weeks for the IT department to help me)?<\/p>\n<h2>Additional Context<\/h2>\n<p>The day before the error started happening, I tried to install a custom package I am developing to the compute instance. The package has an extensive requirements list. I do not know if this could be somehow related, but is there a chance that the package installation is messing with the compute instance nodes?<\/p>\n<p>Additionally, the SSH access to the instance is disabled, therefore I cannot use SSH to directly access its nodes files.<\/p>\n<h3>Workspace diagnostics<\/h3>\n<p>Running the workspace diagnostics also returned the following error message:<\/p>\n<pre><code>ImageBuildComputeNotValid: If Container Registry is behind the virtual network,\nContainer Registry cannot build your image. Set the imageBuildCompute property\nto build your image.\nSee https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-secure-workspace-vnet#enable-azure-container-registry-acr\n<\/code><\/pre>\n<p>It also pointed out that the following categories have no problems:<\/p>\n<p>User defined routing<\/p>\n<ul>\n<li>Network security group<\/li>\n<li>Resource lock<\/li>\n<li>DNS resolution<\/li>\n<li>Storage account<\/li>\n<li>Key vault<\/li>\n<li>Application Insights<\/li>\n<li>Other<\/li>\n<\/ul>\n<p>The following image shows the error I am getting when trying to start the compute instance:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/H2HoP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/H2HoP.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Any help would be appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-09-15 01:07:12.65 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":44,
        "Owner_creation_date":"2021-12-04 10:04:27.883 UTC",
        "Owner_last_access_date":"2022-09-23 21:48:13.173 UTC",
        "Owner_reputation":436,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Rio de Janeiro",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73724586",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70772040,
        "Question_title":"How to fix Azure ml model deployment Error",
        "Question_body":"<p>I'm trying to deploy a RandomForest model using azure ML with ACI , but after i deploy my service i keep getting this error :<\/p>\n<pre><code>Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 2.9.2 (\/opt\/miniconda\/lib\/python3.6\/site-packages), Requirement.parse('cryptography&gt;=3.3.1; extra == &quot;crypto&quot;'), {'PyJWT'}).*\n<\/code><\/pre>\n<p>Here's a snapshot of the code and the error :\n<a href=\"https:\/\/i.stack.imgur.com\/BbhDT.png\" rel=\"nofollow noreferrer\">enter image description here<\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/llrGg.png\" rel=\"nofollow noreferrer\">enter image description here<\/a>\nCan you please tell me what should i do to fix this?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-01-19 14:06:33.557 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-01-28 17:56:30.833 UTC",
        "Question_score":0,
        "Question_tags":"python|dependencies|random-forest|azure-machine-learning-service",
        "Question_view_count":250,
        "Owner_creation_date":"2022-01-19 13:59:52.49 UTC",
        "Owner_last_access_date":"2022-08-17 17:16:47.24 UTC",
        "Owner_reputation":9,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70772040",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47021644,
        "Question_title":"Azure ML Workbench File from Blob",
        "Question_body":"<p>When trying to reference\/load a dsource or dprep file generated with a data source file from blob storage, I receive the error \"No files for given path(s)\".<\/p>\n\n<p>Tested with .py and .ipynb files.  Here's the code:<\/p>\n\n<pre><code># Use the Azure Machine Learning data source package\nfrom azureml.dataprep import datasource\n\ndf = datasource.load_datasource('POS.dsource') #Error generated here\n\n# Remove this line and add code that uses the DataFrame\ndf.head(10)\n<\/code><\/pre>\n\n<p>Please let me know what other information would be helpful. Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-10-30 18:09:10.993 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-11-22 00:28:16.38 UTC",
        "Question_score":4,
        "Question_tags":"azure|machine-learning|azure-blob-storage|azure-machine-learning-workbench",
        "Question_view_count":324,
        "Owner_creation_date":"2016-04-19 18:30:53.86 UTC",
        "Owner_last_access_date":"2019-04-30 19:00:43.91 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47021644",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60316009,
        "Question_title":"Authenticate With Workspace",
        "Question_body":"<p>I have a Pipeline registered in my AML workspace. Now I would like to trigger a pipeline run from an Azure Notebook in the same Workspace.\nIn order to get a reference object to the workspace in the notebook I need to authenticate, e.g. <\/p>\n\n<p><code>ws = Workspace.from_config()<\/code><\/p>\n\n<p>However, InteractiveLoginAthentication is blocked by my company's domain and MsiAuthentication throws an error as well. ServicePrincipalAuthentication works, but how do I keep the secret safe? What is the prefered way of dealing with secrets in the Azure Machine Learning Service Notebooks?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-20 08:50:30.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azure-notebooks",
        "Question_view_count":116,
        "Owner_creation_date":"2020-02-20 08:37:04.717 UTC",
        "Owner_last_access_date":"2021-04-11 10:00:37.967 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60316009",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66020144,
        "Question_title":"How can one download the outputs of historical Azure ML experiment Runs via the python API",
        "Question_body":"<p>I'm trying to write a script which can download the outputs from an Azure ML experiment Run after the fact.<\/p>\n<p>Essentially, I want to know how I can get a Run by its <code>runId<\/code> property (or some other identifier).<\/p>\n<p>I am aware that I have access to the Run object when I create it for the purposes of training. What I want is a way to recreate this Run object later in a separate script, possibly from a completely different environment.<\/p>\n<p>What I've found so far is a way to get a list of ScriptRun objects from an experiment via the <code>get_runs()<\/code> function. But I don't see a way to use one of these ScriptRun objects to create a Run object representing the original Run and allowing me to download the outputs.<\/p>\n<p>Any help appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-02-03 01:48:46.667 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":5,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":1402,
        "Owner_creation_date":"2021-02-03 01:39:44.927 UTC",
        "Owner_last_access_date":"2021-05-19 00:46:14.763 UTC",
        "Owner_reputation":53,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>I agree that this could probably be better documented, but fortunately, it's a simple implementation.<\/p>\n<p>this is how you get a run object for an already submitted run for <code>azureml-sdk&gt;=1.16.0<\/code> (for the older approach <a href=\"https:\/\/stackoverflow.com\/questions\/62949488\/amls-experiment-run-stuck-in-status-running\/62958369#62958369\">see my answer here<\/a>)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace\n\nws = Workspace.from_config()\nrun = ws.get_run('YOUR_RUN_ID')\n<\/code><\/pre>\n<p>once you have the <code>run<\/code> object, you can call methods like<\/p>\n<ul>\n<li><code>.get_file_names()<\/code> to see what files are available (the logs in <code>azureml-logs\/<\/code> and <code>logs\/azureml\/<\/code> will also be listed)<\/li>\n<li><code>.download_file()<\/code> to download an individual file<\/li>\n<li><code>.download_files()<\/code> to download all files that match a given prefix (or all the files)<\/li>\n<\/ul>\n<p>See the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py&amp;WT.mc_id=AI-MVP-5003930\" rel=\"noreferrer\">Run object docs<\/a> for more details.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2021-02-03 20:43:11.07 UTC",
        "Answer_score":7.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66020144",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70976353,
        "Question_title":"After installing scrubadub_spacy package, spacy.load(\"en_core_web_sm\") not working OSError: [E053] Could not read config.cfg",
        "Question_body":"<p>I am getting the below error when I'm trying to run the following line of code to load en_core_web_sm in the Azure Machine Learning instance.<\/p>\n<p>I debugged the issue and found out that once I install scrubadub_spacy, that seems is the issue causing the error.<\/p>\n<pre><code>spacy.load(&quot;en_core_web_sm&quot;)\n<\/code><\/pre>\n<pre><code>OSError                                   Traceback (most recent call last)\n&lt;ipython-input-2-c6e652d70518&gt; in &lt;module&gt;\n     1 # Load English tokenizer, tagger, parser and NER\n----&gt; 2 nlp = spacy.load(&quot;en_core_web_sm&quot;)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/__init__.py in load(name, vocab, disable, exclude, config)\n    50     &quot;&quot;&quot;\n    51     return util.load_model(\n---&gt; 52         name, vocab=vocab, disable=disable, exclude=exclude, config=config\n    53     )\n    54 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model(name, vocab, disable, exclude, config)\n   418             return get_lang_class(name.replace(&quot;blank:&quot;, &quot;&quot;))()\n   419         if is_package(name):  # installed as package\n--&gt; 420             return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]\n   421         if Path(name).exists():  # path to model data directory\n   422             return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_package(name, vocab, disable, exclude, config)\n   451     &quot;&quot;&quot;\n   452     cls = importlib.import_module(name)\n--&gt; 453     return cls.load(vocab=vocab, disable=disable, exclude=exclude, config=config)  # type: ignore[attr-defined]\n   454 \n   455 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/en_core_web_sm\/__init__.py in load(**overrides)\n    10 \n    11 def load(**overrides):\n---&gt; 12     return load_model_from_init_py(__file__, **overrides)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_init_py(init_file, vocab, disable, exclude, config)\n   619         disable=disable,\n   620         exclude=exclude,\n--&gt; 621         config=config,\n   622     )\n   623 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_path(model_path, meta, vocab, disable, exclude, config)\n   485     config_path = model_path \/ &quot;config.cfg&quot;\n   486     overrides = dict_to_dot(config)\n--&gt; 487     config = load_config(config_path, overrides=overrides)\n   488     nlp = load_model_from_config(config, vocab=vocab, disable=disable, exclude=exclude)\n   489     return nlp.from_disk(model_path, exclude=exclude, overrides=overrides)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_config(path, overrides, interpolate)\n   644     else:\n   645         if not config_path or not config_path.exists() or not config_path.is_file():\n--&gt; 646             raise IOError(Errors.E053.format(path=config_path, name=&quot;config.cfg&quot;))\n   647         return config.from_disk(\n   648             config_path, overrides=overrides, interpolate=interpolate\n\nOSError: [E053] Could not read config.cfg from \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/en_core_web_sm\/en_core_web_sm-2.3.1\/config.cfg\n<\/code><\/pre>\n<p>I installed the packages using the below three lines codes from <a href=\"https:\/\/spacy.io\/usage\" rel=\"nofollow noreferrer\">Spacy<\/a><\/p>\n<pre><code>pip install -U pip setuptools wheel\npip install -U spacy\npython -m spacy download en_core_web_sm\n<\/code><\/pre>\n<p>How should I fix this issue? thanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-03 18:19:43.59 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-04 18:12:19.103 UTC",
        "Question_score":2,
        "Question_tags":"python|python-3.6|spacy|azure-machine-learning-service|oserror",
        "Question_view_count":201,
        "Owner_creation_date":"2019-11-13 00:38:54.107 UTC",
        "Owner_last_access_date":"2022-06-23 16:56:21.83 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>Taking the path from your error message:<\/p>\n<pre><code>en_core_web_sm-2.3.1\/config.cfg\n<\/code><\/pre>\n<p>You have a model for v2.3, but it's looking for a <code>config.cfg<\/code>, which is only a thing in v3 of spaCy. It looks like you upgraded spaCy without realizing it.<\/p>\n<p>There are two ways to fix this. One is to reinstall the model with <code>spacy download<\/code>, which will get a version that matches your current spaCy version. If you are just starting something that is probably the best idea. Based on the release date of scrubadub, it seems to be intended for use with spaCy v3.<\/p>\n<p>However, note that v2 and v3 are pretty different - if you have a project with v2 of spaCy you might want to downgrade instead.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-02-06 04:46:54.723 UTC",
        "Answer_score":2.0,
        "Owner_location":"Saint Louis, MO, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70976353",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57397150,
        "Question_title":"Deploy Notebook VM via ARM Template?",
        "Question_body":"<p>Is it possible to deploy an AML Notebook VM via an ARM template? If so, is there an example or documentation somewhere?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-07 14:51:48.713 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-07 22:40:49.487 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":71,
        "Owner_creation_date":"2018-06-19 20:17:41.717 UTC",
        "Owner_last_access_date":"2022-09-21 12:31:28.057 UTC",
        "Owner_reputation":392,
        "Owner_up_votes":8,
        "Owner_down_votes":4,
        "Owner_views":39,
        "Answer_body":"<p>Unfortunately this is not supported today, but ARM support is in our roadmap<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-08-07 22:16:53.847 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57397150",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71858668,
        "Question_title":"How to use tensorflow hub in Azure ML",
        "Question_body":"<p>I am trying to use  TensorFlow Hub in Azure ML Studio<\/p>\n<p>I am using the kernel Python 3.8 PT and TF<\/p>\n<p>And I installed  a few modules:<\/p>\n<pre><code>!pip install bert-for-tf2\n!pip install sentencepiece\n!pip install &quot;tensorflow&gt;=2.0.0&quot;\n!pip install --upgrade tensorflow-hub\n<\/code><\/pre>\n<p>With pip list, I can see they are installed:<\/p>\n<pre><code>tensorflow                              2.8.0\ntensorflow-estimator                    2.3.0\ntensorflow-gpu                          2.3.0\ntensorflow-hub                          0.12.0\ntensorflow-io-gcs-filesystem            0.24.0\n<\/code><\/pre>\n<p>However when I try to use it as per the documentation (<a href=\"https:\/\/www.tensorflow.org\/hub\" rel=\"nofollow noreferrer\">https:\/\/www.tensorflow.org\/hub<\/a>)<\/p>\n<p>Then I get the classic:<\/p>\n<pre><code>ModuleNotFoundError: No module named 'tensorflow_hub'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-13 13:51:11.967 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|tensorflow|tensorflow-hub|azure-machine-learning-service",
        "Question_view_count":112,
        "Owner_creation_date":"2011-04-05 19:05:03.093 UTC",
        "Owner_last_access_date":"2022-09-16 12:42:27.473 UTC",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Answer_body":"<p>To resolve this <code>ModuleNotFoundError: No module named 'tensorflow_hub'<\/code>  error, try following ways:<\/p>\n<ul>\n<li>Try installing\/upgrading the latest version of <code>tensorflow<\/code> and <code>tensorflow-hub<\/code> and then import:<\/li>\n<\/ul>\n<pre><code>!pip install --upgrade tensorflow\n\n!pip install --upgrade tensorflow_hub\n\nimport tensorflow as tf\n\nimport tensorflow_hub as hub\n<\/code><\/pre>\n<ul>\n<li>Install the current environment as a new kernel:<\/li>\n<\/ul>\n<pre><code>python3 -m ipykernel install --user --name=testenvironment\n<\/code><\/pre>\n<p>You can refer to <a href=\"https:\/\/stackoverflow.com\/questions\/63884339\/modulenotfounderror-no-module-named-tensorflow-hub\">ModuleNotFoundError: No module named 'tensorflow_hub', No module named 'tensorflow_hub'<\/a> and <a href=\"https:\/\/github.com\/tensorflow\/hub\/issues\/767\" rel=\"nofollow noreferrer\">How to use Tensorflow Hub Model?<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-26 05:16:05.913 UTC",
        "Answer_score":1.0,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71858668",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66745404,
        "Question_title":"How to submit Dataset Input as a Parameter to AZ ML CLI run submit-pipeline command?",
        "Question_body":"<p>To submit a parameter in an az ml cli <code>run submit-pipeline<\/code> command we use the syntax:<\/p>\n<pre><code>az ml run submit-pipeline \u2013datapaths [DataPATHS Name=datastore\/datapath] --experiment-name [Experiment_Name] --parameters [String_parameters Name=Value] --pipeline-id [ID]--resource-group [RGP] --subscription-id [SUB_ID] --workspace-name [AML_WS_NAME]\n<\/code><\/pre>\n<p>This will submit Datapaths and some string parameters with the pipeline. How do we submit Dataset references using az ml cli <code>run submit-pipeline<\/code> command?<\/p>\n<p>For example, the Documentation Notebook: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-showcasing-dataset-and-pipelineparameter.ipynb\" rel=\"nofollow noreferrer\">aml-pipelines-showcasing-dataset-and-pipelineparameter<\/a><\/p>\n<p>To submit a Dataset Class reference we do:<\/p>\n<pre><code>iris_tabular_ds = Dataset.Tabular.from_delimited_files('link\/iris.csv')\npipeline_run_with_params = experiment.submit(pipeline, pipeline_parameters={'tabular_ds_param': iris_tabular_ds})\n<\/code><\/pre>\n<p>Using REST Call the syntax is:<\/p>\n<pre><code>response = requests.post(rest_endpoint, \n                         headers=aad_token, \n                         json={&quot;ExperimentName&quot;: &quot;MyRestPipeline&quot;,\n                               &quot;RunSource&quot;: &quot;SDK&quot;,\n                               &quot;DataSetDefinitionValueAssignments&quot;: { &quot;tabular_ds_param&quot;: {&quot;SavedDataSetReference&quot;: {&quot;Id&quot;: iris_tabular_ds.id}}}\n                              }\n                        )\n<\/code><\/pre>\n<p>What is the syntax to achieve this using <code>az ml cli<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-03-22 11:45:55.03 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-pipelines|azure-cli|azure-machine-learning-service",
        "Question_view_count":268,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p>To consume this from the AZ ML CLI we use the following syntax:<\/p>\n<pre><code>    curl -X POST [Pipeline_REST_Endpoint] -H &quot;Authorization: Bearer $(az account get-access-token --query accessToken -o tsv)&quot; -H &quot;Content-Type: application\/json&quot; --data-binary @- &lt;&lt;DATA\n{&quot;ExperimentName&quot;: &quot;[ExperimentName]&quot;,\n                               &quot;RunSource&quot;: &quot;SDK&quot;,\n                               &quot;DataSetDefinitionValueAssignments&quot;: {&quot;tabular_ds_param&quot;: \n                                                                     {&quot;SavedDataSetReference&quot;: \n                                                                      {&quot;Id&quot;:&quot;[Dataset_ID]&quot;}\n                                                                     }\n                                                                    }\n                              }\nDATA\n<\/code><\/pre>\n<p>We use the simple REST call because <code>az ml run submit-pipeline<\/code> does not have the dataset parameter and datapath does not achieve the desired result.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-02 06:43:35.33 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":"2021-04-08 10:22:03.067 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66745404",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64819766,
        "Question_title":"is there a way to export experiments from on azure ml designer workspace to another?",
        "Question_body":"<p>is there a way to export experiments from an azure ml designer workspace to another? Like moving changes from INT to QA to PROD<\/p>\n<p>Thanks in advance<\/p>\n<p>Regards,\nKiran<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-13 11:02:57.027 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":256,
        "Owner_creation_date":"2012-09-07 11:33:10.887 UTC",
        "Owner_last_access_date":"2022-09-03 07:44:05.233 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64819766",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67258917,
        "Question_title":"AzureML ParallelRunStep progress information",
        "Question_body":"<p>is there a way to know the progress percentage a ParallelRunStep has already computed on a pipeline?<\/p>\n<p>As the total number of inputs is known in advance, I think it should not be hard to get this information.<\/p>\n<p>This would be a great feedback for pipelines that takes long time to finish.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-25 22:43:37.157 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":23,
        "Owner_creation_date":"2012-08-01 13:43:34.45 UTC",
        "Owner_last_access_date":"2022-09-24 18:09:44.127 UTC",
        "Owner_reputation":359,
        "Owner_up_votes":265,
        "Owner_down_votes":1,
        "Owner_views":55,
        "Answer_body":"<p>Answer from python azure sdk: <em>In Studio, if you go to the step's Metrics tab, you will be able to see a chart\/table of execution progress, including remaining items, remaining mini batches, failed items, etc.<\/em><\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/18357\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/18357<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-29 10:46:49.26 UTC",
        "Answer_score":0.0,
        "Owner_location":"Seville, Spain",
        "Answer_last_edit_date":"2021-04-29 11:00:14.31 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67258917",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40028165,
        "Question_title":"Azure ML's web service asking for label?",
        "Question_body":"<p>I built a linear regression algorithm in Azure ML. On the &quot;Score Model&quot; module I can actually see the predictions and the rest of the features. However, when I deploy this project as a web service, the service is expecting the actual label of the data (e.g. I'm trying to predict a house's price and it asks me for the price of the house to make the prediction), which doesn't make any sense to me... What am I doing wrong? On the &quot;Train Model&quot; module I set that the label column is the HousePrice, which is what I'm trying to predict...<\/p>\n<p>This is my model:\n<a href=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I tried leaving that field blank but the prediction returns null...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2016-10-13 18:16:02.787 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_score":4,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1012,
        "Owner_creation_date":"2014-06-02 17:25:36.86 UTC",
        "Owner_last_access_date":"2022-09-12 15:39:08.48 UTC",
        "Owner_reputation":1102,
        "Owner_up_votes":390,
        "Owner_down_votes":25,
        "Owner_views":120,
        "Answer_body":"<p>The input schema (names\/types of required input) based on the location in the graph where you attach the \"Web Service Input\" module. To get the schema you want, you will need to find -- or if necessary, create -- a place in the experiment where the data has the column names\/types you desire.<\/p>\n\n<p>Consider this simple example experiment that predicts whether a field called \"income\" will be above or below $50k\/year:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When we click \"Set up web service\", the following graph is automatically generated:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Since the input dataset and \"Web service input\" modules are connected to the same port, the web service schema will perfectly match the schema of the input dataset. This is unfortunate because the input dataset contains a column called \"income\", which is what our web service is supposed to predict -- this is equivalent to the problem that you are having.<\/p>\n\n<p>To get around it, we need to create a place in our experiment graph where we've dropped the unneeded \"income\" field from the input dataset, and attach the \"Web service input\" module there:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>With this arrangement, the web service only requests the features actually needed to score the model. I'm sure you can use a similar method to create a predictive experiment with whatever input schema you need for your own work.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-10-17 18:55:27.013 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40028165",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63461131,
        "Question_title":"Deleting environments from azureml studio",
        "Question_body":"<p>How may I delete an environment from azure machine learning workspace? I can create and list them but could not figure out how I may delete them?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_creation_date":"2020-08-18 02:44:38.793 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":7,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":2566,
        "Owner_creation_date":"2020-08-18 02:37:03.227 UTC",
        "Owner_last_access_date":"2021-09-26 10:54:30.93 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63461131",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34990561,
        "Question_title":"Azure Machine Learning Request Response latency",
        "Question_body":"<p>I have made an Azure Machine Learning Experiment which takes a small dataset (12x3 array) and some parameters and does some calculations using a few Python modules (a linear regression calculation and some more). This all works fine.<\/p>\n\n<p>I have deployed the experiment and now want to throw data at it from the front-end of my application. The API-call goes in and comes back with correct results, but it takes up to 30 seconds to calculate a simple linear regression. Sometimes it is 20 seconds, sometimes only 1 second. I even got it down to 100 ms one time (which is what I'd like), but 90% of the time the request takes more than 20 seconds to complete, which is unacceptable.<\/p>\n\n<p>I guess it has something to do with it still being an experiment, or it is still in a development slot, but I can't find the settings to get it to run on a faster machine.<\/p>\n\n<p>Is there a way to speed up my execution?<\/p>\n\n<p>Edit: To clarify: The varying timings are obtained with the same test data, simply by sending the same request multiple times. This made me conclude it must have something to do with my request being put in a queue, there is some start-up latency or I'm throttled in some other way.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-01-25 10:40:39.993 UTC",
        "Question_favorite_count":5.0,
        "Question_last_edit_date":"2016-01-27 16:15:36.527 UTC",
        "Question_score":8,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":1128,
        "Owner_creation_date":"2015-10-29 11:07:20.793 UTC",
        "Owner_last_access_date":"2020-05-19 23:12:48.357 UTC",
        "Owner_reputation":311,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":34,
        "Answer_body":"<p>First, I am assuming you are doing your timing test on the published AML endpoint.<\/p>\n\n<p>When a call is made to the AML the first call must warm up the container. By default a web service has 20 containers. Each container is cold, and a cold container can cause a large(30 sec) delay. In the string returned by the AML endpoint, only count requests that have the <code>isWarm<\/code> flag set to true. By smashing the service with MANY requests(relative to how many containers you have running) can get all your containers warmed.<\/p>\n\n<p>If you are sending out dozens of requests a instance, the endpoint might be getting throttled. You can adjust the number of calls your endpoint can accept by going to manage.windowsazure.com\/<\/p>\n\n<ol>\n<li>manage.windowsazure.com\/<\/li>\n<li>Azure ML Section from left bar<\/li>\n<li>select your workspace<\/li>\n<li>go to web services tab<\/li>\n<li>Select your web service from list<\/li>\n<li>adjust the number of calls with slider<\/li>\n<\/ol>\n\n<p>By enabling debugging onto your endpoint you can get logs about the execution time for each of your modules to complete. You can use this to determine if a module is not running as you intended which may add to the time.<\/p>\n\n<p>Overall, there is an overhead when using the Execute python module, but I'd expect this request to complete in under 3 secs. <\/p>",
        "Answer_comment_count":11.0,
        "Answer_creation_date":"2016-01-26 18:20:06.127 UTC",
        "Answer_score":8.0,
        "Owner_location":"Antwerp, Belgium",
        "Answer_last_edit_date":"2016-01-27 16:10:48.927 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34990561",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71562804,
        "Question_title":"Automl object detection local filesystem",
        "Question_body":"<p>I have tried to create a azure automl model to find an object in the image.<\/p>\n<p>According to the tutorial it is required that you specify the labels in adataframe where on of the columns are mounted to a aml datastore.<\/p>\n<p>Question: Is it possible to link it to a local repository instead eg in a compute?<\/p>\n<p>Link:  <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-image-models\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-image-models<\/a><\/p>\n<p>I tried to use os path but it did not work.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-03-21 19:00:54.553 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|object-detection|azure-machine-learning-service|azure-auto-ml",
        "Question_view_count":21,
        "Owner_creation_date":"2018-05-13 14:47:24.17 UTC",
        "Owner_last_access_date":"2022-06-12 12:08:47.33 UTC",
        "Owner_reputation":101,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Pakis, Indonesia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71562804",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45057880,
        "Question_title":"Moving Azure ML predictive experiment to another tenant",
        "Question_body":"<p>I have Azure ML predictive experiment on my tenant, I just need to move it to another azure tenant.is it possible to move or copy to another tenant ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-07-12 12:35:55.25 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":108,
        "Owner_creation_date":"2015-01-05 14:04:56.24 UTC",
        "Owner_last_access_date":"2022-09-22 12:15:52.087 UTC",
        "Owner_reputation":458,
        "Owner_up_votes":56,
        "Owner_down_votes":1,
        "Owner_views":184,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45057880",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58816515,
        "Question_title":"Databricks UDF calling an external web service cannot be serialised (PicklingError)",
        "Question_body":"<p>I am using Databricks and have a column in a dataframe that I need to update for every record with an external web service call. In this case it is using the Azure Machine Learning Service SDK and does a service call. This code works fine when not run as a UDF in spark (ie. just python) however it throws a serialization error when I try to call it as a UDF. The same happens if I use a lambda and a map with an rdd.<\/p>\n\n<p>The model uses fastText and can be invoked fine from Postman or python via a normal http call or using the WebService SDK from AMLS - it's just when it is a UDF that it fails with this message:<\/p>\n\n<p>TypeError: can't pickle _thread._local objects<\/p>\n\n<p>The only workaround I can think of is to loop through each record in the dataframe sequentially and update the record with a call, however this is not very efficient. I don't know if this is a spark error or because the service is loading a fasttext model. When I use the UDF and mock a return value it works though.<\/p>\n\n<p>Error at bottom...<\/p>\n\n<pre><code>from azureml.core.webservice import Webservice, AciWebservice\nfrom azureml.core import Workspace\n\ndef predictModelValue2(summary, modelName, modelLabel):  \n    raw_data = '[{\"label\": \"' + modelLabel + '\", \"model\": \"' + modelName + '\", \"as_full_account\": \"' + summary + '\"}]'\n    prediction = service.run(raw_data)\n    return prediction\n\nfrom pyspark.sql.types import FloatType\nfrom pyspark.sql.functions import udf\n\npredictModelValueUDF = udf(predictModelValue2)\n\nDVIRCRAMFItemsDFScored1 = DVIRCRAMFItemsDF.withColumn(\"Result\", predictModelValueUDF(\"Summary\", \"ModelName\", \"ModelLabel\"))\n<\/code><\/pre>\n\n<blockquote>\n  <p>TypeError: can't pickle _thread._local objects<\/p>\n  \n  <p>During handling of the above exception, another exception occurred:<\/p>\n  \n  <p>PicklingError                             Traceback (most recent call\n  last)  in \n  ----> 2 x = df.withColumn(\"Result\", predictModelValueUDF(\"Summary\",\n  \"ModelName\", \"ModelLabel\"))<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in wrapper(*args)\n      194         @functools.wraps(self.func, assigned=assignments)\n      195         def wrapper(*args):\n  --> 196             return self(*args)\n      197 \n      198         wrapper.<strong>name<\/strong> = self._name<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in <strong>call<\/strong>(self, *cols)\n      172 \n      173     def <strong>call<\/strong>(self, *cols):\n  --> 174         judf = self._judf\n      175         sc = SparkContext._active_spark_context\n      176         return Column(judf.apply(_to_seq(sc, cols, _to_java_column)))<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in _judf(self)\n      156         # and should have a minimal performance impact.\n      157         if self._judf_placeholder is None:\n  --> 158             self._judf_placeholder = self._create_judf()\n      159         return self._judf_placeholder\n      160 <\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in _create_judf(self)\n      165         sc = spark.sparkContext\n      166 \n  --> 167         wrapped_func = _wrap_function(sc, self.func, self.returnType)\n      168         jdt = spark._jsparkSession.parseDataType(self.returnType.json())\n      169         judf = sc._jvm.org.apache.spark.sql.execution.python.UserDefinedPythonFunction(<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in _wrap_function(sc,\n  func, returnType)\n       33 def _wrap_function(sc, func, returnType):\n       34     command = (func, returnType)\n  ---> 35     pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)\n       36     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n       37                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/rdd.py in _prepare_for_python_RDD(sc,\n  command)    2461     # the serialized command will be compressed by\n  broadcast    2462     ser = CloudPickleSerializer()\n  -> 2463     pickled_command = ser.dumps(command)    2464     if len(pickled_command) >\n  sc._jvm.PythonUtils.getBroadcastThreshold(sc._jsc):  # Default 1M<br>\n  2465         # The broadcast will have same life cycle as created\n  PythonRDD<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/serializers.py in dumps(self, obj)\n      709                 msg = \"Could not serialize object: %s: %s\" % (e.<strong>class<\/strong>.<strong>name<\/strong>, emsg)\n      710             cloudpickle.print_exec(sys.stderr)\n  --> 711             raise pickle.PicklingError(msg)\n      712 \n      713 <\/p>\n  \n  <p>PicklingError: Could not serialize object: TypeError: can't pickle\n  _thread._local objects<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2019-11-12 10:18:14.003 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pyspark|user-defined-functions|pickle|azure-databricks|azure-machine-learning-service",
        "Question_view_count":931,
        "Owner_creation_date":"2009-10-21 01:51:25.5 UTC",
        "Owner_last_access_date":"2022-09-13 05:24:36.847 UTC",
        "Owner_reputation":4947,
        "Owner_up_votes":277,
        "Owner_down_votes":8,
        "Owner_views":531,
        "Answer_body":"<p>I am not expert in DataBricks or Spark, but pickling functions from the local notebook context is always problematic when you are touching complex objects like the <code>service<\/code> object. In this particular case, I would recommend removing the dependency on the azureML <code>service<\/code> object and just use <code>requests<\/code> to call the service. <\/p>\n\n<p>Pull the key from the service:<\/p>\n\n<pre><code># retrieve the API keys. two keys were generated.\nkey1, key2 = service.get_keys()\nscoring_uri = service.scoring_uri\n<\/code><\/pre>\n\n<p>You should be able to use these strings in the UDF directly without pickling issues -- <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/9233ce089afb81d466076e36e7e61c3ce4cfafec\/how-to-use-azureml\/ml-frameworks\/chainer\/deployment\/train-hyperparameter-tune-deploy-with-chainer\/train-hyperparameter-tune-deploy-with-chainer.ipynb\" rel=\"nofollow noreferrer\">here is an example<\/a> of  how you would call the service with just requests. Below applied to your UDF:<\/p>\n\n<pre><code>import requests, json\ndef predictModelValue2(summary, modelName, modelLabel):  \n  input_data = json.dumps({\"summary\": summary, \"modelName\":, ....})\n\n  headers = {'Content-Type':'application\/json', 'Authorization': 'Bearer ' + key1}\n\n  # call the service for scoring\n  resp = requests.post(scoring_uri, input_data, headers=headers)\n\n  return resp.text[1]\n\n<\/code><\/pre>\n\n<p>On a side node, though: your UDF will be called for each row in your data frame and each time it will make a network call -- that will be very slow. I would recommend looking for ways to batch the execution. As you can see from your constructed json <code>service.run<\/code> will accept an array of items, so you should call it in batches of 100s or so.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-11-15 18:06:07.917 UTC",
        "Answer_score":1.0,
        "Owner_location":"Sydney, Australia",
        "Answer_last_edit_date":"2019-11-15 19:06:25.32 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58816515",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70852922,
        "Question_title":"ModuleNotFoundError: No module named 'azureml' in Azure ML Studio",
        "Question_body":"<p>I am learning Azure ML from Microsoft tutorials, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data\" rel=\"nofollow noreferrer\">here<\/a>. The first two tutorials ran fine, but this one is giving me the following error.<\/p>\n<pre><code>[stderr]Traceback (most recent call last):\n[stderr]  File &quot;train.py&quot;, line 8, in &lt;module&gt;\n[stderr]    from azureml.core import Run\n[stderr]ModuleNotFoundError: No module named 'azureml'\n[stderr]\n<\/code><\/pre>\n<p>Working with Azure ML Studio and submitting the code to the environment, I am unable to find how to resolve this error.<\/p>\n<p>I have checked that the package is installed (running on Azure ML studio so this is basic assumption, but I have tested as well). Following is the code 'run-pytorch.py' which calls the script 'train.py'<\/p>\n<pre><code># run-pytorch.py\nfrom azureml.core import Workspace\nfrom azureml.core import Experiment\nfrom azureml.core import Environment\nfrom azureml.core import ScriptRunConfig\n\nif __name__ == &quot;__main__&quot;:\n    ws = Workspace.from_config()\n    experiment = Experiment(workspace=ws, name='day1-experiment-train')\n    config = ScriptRunConfig(source_directory='.\/src',\n                             script='train.py',\n                             compute_target='cpu-cluster')\n\n    # set up pytorch environment\n    env = Environment.from_conda_specification(\n        name='pytorch-env',\n        file_path='pytorch-env.yml'\n    )\n    config.run_config.environment = env\n\n    run = experiment.submit(config)\n\n    aml_url = run.get_portal_url()\n    print(aml_url)\n    print('Success...!!!')\n<\/code><\/pre>\n<p>Teh code snippet for train.py is as follows<\/p>\n<pre><code># train.py\nimport os\nimport argparse\nimport torch\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom model import Net\nfrom azureml.core import Run\n...\n...\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-01-25 17:16:49.297 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":838,
        "Owner_creation_date":"2013-12-24 06:50:56.557 UTC",
        "Owner_last_access_date":"2022-09-22 18:54:05.69 UTC",
        "Owner_reputation":453,
        "Owner_up_votes":91,
        "Owner_down_votes":2,
        "Owner_views":63,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70852922",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64546521,
        "Question_title":"Azure ML FileDataset registers, but cannot be accessed for Data Labeling project",
        "Question_body":"<p><strong>Objective<\/strong>: Generate a down-sampled FileDataset using random sampling from a larger FileDataset to be used in a Data Labeling project.<\/p>\n<hr \/>\n<p><strong>Details<\/strong>: I have a large FileDataset containing millions of images. Each filename contains details about the 'section' it was taken from. A section may contain thousands of images. I want to randomly select a specific number of <strong>sections<\/strong> and all the images associated with those sections. Then register the sample as a new dataset.<\/p>\n<p>Please note that the code below is not a direct copy and paste as there are elements such as filepaths and variables that have been renamed for confidentiality reasons.<\/p>\n<pre><code>import azureml.core\nfrom azureml.core import Dataset, Datastore, Workspace\n\n# Load in work space from saved config file\nws = Workspace.from_config()\n\n# Define full dataset of interest and retrieve it\ndataset_name = 'complete_2017'\ndata = Dataset.get_by_name(ws, dataset_name)\n\n# Extract file references from dataset as relative paths\nrel_filepaths = data.to_path()\n\n# Stitch back in base directory path to get a list of absolute paths\nsrc_folder = '\/raw-data\/2017'\nabs_filepaths = [src_folder + path for path in rel_filepaths]\n\n# Define regular expression pattern for extracting source section\nimport re\npattern = re.compile('\\\/(S.+)_image\\d+.jpg')\n\n# Create new list of all unique source sections\nsections = sorted(set([m.group(1) for m in map(pattern.match, rel_filepaths) if m]))\n\n# Randomly select sections\nnum_sections = 5\nset_seed = 221020\nrandom.seed(set_seed)   # for repeatibility\nsample_sections = random.choices(sections, k = num_sections)\n\n# Extract images related to the selected sections\nmatching_images = [filename for filename in abs_filepaths if any(section in filename for section in sample_sections)]\n\n# Define datastore of interest\ndatastore = Datastore.get(ws, 'ml-datastore')\n\n# Convert string paths to Azure Datapath objects and relate back to datastore\nfrom azureml.data.datapath import DataPath\ndatastore_path = [DataPath(datastore, filepath) for filepath in matching_images]\n\n# Generate new dataset using from_files() and filtered list of paths\nsample = Dataset.File.from_files(datastore_path)\n\nsample_name = 'random-section-sample'\nsample_dataset = sample.register(workspace = ws, name = sample_name, description = 'Sampled sections from full dataset using set seed.')\n<\/code><\/pre>\n<hr \/>\n<p><strong>Issue<\/strong>: The code I've written in Python SDK runs and the new FileDataset registers, but when I try to look at the dataset details or use it for a Data Labeling project I get the following error even as <em>Owner<\/em>.<\/p>\n<pre><code>Access denied: Failed to authenticate data access with Workspace system assigned identity. Make sure to add the identity as Reader of the data service.\n<\/code><\/pre>\n<p>Additionally, under the details tab <strong>Files in dataset<\/strong> is <em>Unknown<\/em> and <strong>Total size of files in dataset<\/strong> is <em>Unavailable<\/em>.<\/p>\n<p>I haven't come across this issue anywhere else. I'm able to generate datasets in other ways, so I suspect it's an issue with the code given that I'm working with the data in an unconventional way.<\/p>\n<hr \/>\n<p><strong>Additional Notes<\/strong>:<\/p>\n<ul>\n<li>Azure ML version is 1.15.0<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-10-26 23:50:26.34 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":801,
        "Owner_creation_date":"2020-10-26 22:17:36.893 UTC",
        "Owner_last_access_date":"2021-04-24 22:21:57.223 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>One of my colleagues discovered that the managed identities were preventing the preview functionality. Once this aspect of the identities was modified, we could examine the data and use it for a data labelling project.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-28 20:31:26.963 UTC",
        "Answer_score":1.0,
        "Owner_location":"New Zealand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64546521",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42081202,
        "Question_title":"Importing images Azure Machine Learning Studio",
        "Question_body":"<p>Is it possible to import images from your Azure storage account from within a Python script module as opposed to using the Import Images module that Azure ML Studio provides. Ideally I would like to use <code>cv2.imread()<\/code>. I only want to read in grayscale data but the Import Images module reads in RGB. \nCan I use the <code>BlockBlobService<\/code> library as if I were calling it from an external Python script?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-07 03:27:22.043 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-02-07 06:01:13.667 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-blob-storage|azure-machine-learning-studio",
        "Question_view_count":812,
        "Owner_creation_date":"2015-10-12 03:10:51.79 UTC",
        "Owner_last_access_date":"2022-09-22 00:25:05.207 UTC",
        "Owner_reputation":823,
        "Owner_up_votes":98,
        "Owner_down_votes":8,
        "Owner_views":48,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Sydney NSW, Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42081202",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64617637,
        "Question_title":"AttributeError: module 'tensorflow_core.python.keras.api._v2.keras.activations' has no attribute 'swish'",
        "Question_body":"<p>I'm using Azure ML studio to train a question answering ALBERT model with the SQuAD dataset. I'm getting the following error. Here is the code I execute.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># Clone transformers github repo\n!git clone https:\/\/github.com\/huggingface\/transformers \\\n&amp;&amp; cd transformers \\\n&amp;&amp; git checkout a3085020ed0d81d4903c50967687192e3101e770 \n\n# Install libraries\n# !pip install .\/transformers\n!pip install transformers\n!pip install tensorboardX\n\n# Get data\n! mkdir dataset \\\n&amp;&amp; cd dataset \\\n&amp;&amp; wget https:\/\/rajpurkar.github.io\/SQuAD-explorer\/dataset\/train-v2.0.json \\\n&amp;&amp; wget https:\/\/rajpurkar.github.io\/SQuAD-explorer\/dataset\/dev-v2.0.json\n\n# Train model\n!export SQUAD_DIR=\/content\/dataset \\\n&amp;&amp; python transformers\/examples\/run_squad.py \\\n    --model_type albert \\\n    --model_name_or_path albert-base-v2 \\\n    --do_train \\\n    --do_eval \\\n    --do_lower_case \\\n    --train_file $SQUAD_DIR\/train-v2.0.json \\\n    --predict_file $SQUAD_DIR\/dev-v2.0.json \\\n    --per_gpu_train_batch_size 12 \\\n    --learning_rate 3e-5 \\\n    --num_train_epochs 1.0 \\\n    --max_seq_length 384 \\\n    --doc_stride 128 \\\n    --output_dir \/content\/model_output \\\n    --save_steps 1000 \\\n    --threads 4 \\\n    --version_2_with_negative \n<\/code><\/pre>\n<p>I'm using an NVIDIA Tesla K80 GPU. When I execute the cell above to train the model, I get the following error:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>2020-10-31 01:31:45.732913: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n2020-10-31 01:31:45.733023: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n2020-10-31 01:31:45.733043: W tensorflow\/compiler\/tf2tensorrt\/utils\/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\nTraceback (most recent call last):\n    File &quot;transformers\/examples\/run_squad.py&quot;, line 32, in &lt;module&gt;\n    from transformers import (\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/transformers\/__init__.py&quot;, line 135, in &lt;module&gt;\n    from .pipelines import (\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/transformers\/pipelines.py&quot;, line 47, in &lt;module&gt;\n    from .modeling_tf_auto import (\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/transformers\/modeling_tf_auto.py&quot;, line 45, in &lt;module&gt;\n    from .modeling_tf_albert import (\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/transformers\/modeling_tf_albert.py&quot;, line 24, in &lt;module&gt;\n    from .activations_tf import get_tf_activation\n    File &quot;\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/transformers\/activations_tf.py&quot;, line 53, in &lt;module&gt;\n    &quot;swish&quot;: tf.keras.activations.swish,\nAttributeError: module 'tensorflow_core.python.keras.api._v2.keras.activations' has no attribute 'swish'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-31 01:40:23.14 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-11-01 10:41:29.517 UTC",
        "Question_score":4,
        "Question_tags":"python|azure|jupyter-notebook|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":9925,
        "Owner_creation_date":"2020-10-10 22:20:44.45 UTC",
        "Owner_last_access_date":"2020-11-19 01:42:31.69 UTC",
        "Owner_reputation":153,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64617637",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62623166,
        "Question_title":"Azure ML Error: TimeSeriesImputer object has no attribute '_known_df'",
        "Question_body":"<p>Running <a href=\"http:\/\/%20https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-orange-juice-sales\/auto-ml-forecasting-orange-juice-sales.ipynb\" rel=\"nofollow noreferrer\">this orange juice sales notebook<\/a> I get the below error with the <code>.forecast()<\/code> method.<\/p>\n<h3>code<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code># The featurized data, aligned to y, will also be returned.\n# This contains the assumptions that were made in the forecast\n# and helps align the forecast to the original data\ny_predictions, X_trans = fitted_model.forecast(X_test)\n<\/code><\/pre>\n<h3>Error (<a href=\"https:\/\/gist.github.com\/swanderz\/201819978b6719bbed1826a02bb2fb47\" rel=\"nofollow noreferrer\">full stacktrace<\/a>):<\/h3>\n<pre><code>**AttributeError: 'TimeSeriesImputer' object has no attribute '_known_df'**\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-28 13:28:01.953 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-07-07 17:16:36.017 UTC",
        "Question_score":1,
        "Question_tags":"time-series|azure-machine-learning-studio|forecast|azure-machine-learning-service",
        "Question_view_count":256,
        "Owner_creation_date":"2015-10-11 07:33:45.377 UTC",
        "Owner_last_access_date":"2022-01-12 11:43:12.04 UTC",
        "Owner_reputation":303,
        "Owner_up_votes":105,
        "Owner_down_votes":7,
        "Owner_views":60,
        "Answer_body":"<p>This is commonly fixed by upgrading to the latest SDK. You can do this by running <code>pip install --upgrade azureml-sdk[explain,automl]<\/code>.<\/p>\n<p>Thanks,\nSabina<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-06-30 18:43:45.63 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62623166",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63730264,
        "Question_title":"How to pass a DataPath PipelineParameter from AzureDatafactory to AzureMachineLearningExecutePipeline Activity?",
        "Question_body":"<BR>\n<ul>\n<li><p>I am trying to read a file from a Blob Storage, load to pandas and write it to a BlobStorage<\/p>\n<\/li>\n<li><p>I have an Azure Machine Learning Pipeline with a PythonScriptStep that takes 2 PipelineParameters and are DataPaths as below.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Datastore\nfrom azureml.data.datapath import DataPath, DataPathComputeBinding, DataReference\nfrom azureml.pipeline.core import PipelineParameter\n\ndatastore = Datastore(ws, &quot;SampleStore&quot;)\nin_raw_path_default = 'somefolder\/raw\/alerts\/2020\/08\/03\/default_in.csv'\nin_cleaned_path_default= 'somefolder\/cleaned\/alerts\/2020\/08\/03\/default_out.csv'\n\nin_raw_datapath = DataPath(datastore=datastore, path_on_datastore=in_raw_path_default)\nin_raw_path_pipelineparam = PipelineParameter(name=&quot;inrawpath&quot;, default_value=in_raw_datapath)\nraw_datapath_input = (in_raw_path_pipelineparam, DataPathComputeBinding(mode='mount'))\n\nin_cleaned_datapath = DataPath(datastore=datastore, path_on_datastore=in_cleaned_path_default)\nin_cleaned_path_pipelineparam = PipelineParameter(name=&quot;incleanedpath&quot;, default_value=in_cleaned_datapath)\ncleaned_datapath_input = (in_cleaned_path_pipelineparam, DataPathComputeBinding(mode='mount'))\n\nfrom azureml.pipeline.steps import PythonScriptStep\n\nsource_directory = script_folder + '\/pipeline_Steps'\ndataprep_step = PythonScriptStep(\n    script_name=&quot;SimpleTest.py&quot;, \n    arguments=[&quot;--input_data&quot;, raw_datapath_input, &quot;--cleaned_data&quot;, cleaned_datapath_input],\n    inputs=[raw_datapath_input, cleaned_datapath_input],    \n    compute_target=default_compute, \n    source_directory=source_directory,\n    runconfig=run_config,\n    allow_reuse=True\n)\n\nfrom azureml.pipeline.core import Pipeline\npipeline_test = Pipeline(workspace=ws, steps=[dataprep_step])\n\ntest_raw_path = DataPath(datastore=datastore, path_on_datastore='samplefolder\/raw\/alerts\/2017\/05\/31\/test.csv')\ntest_cleaned_path = DataPath(datastore=datastore, path_on_datastore='samplefolder\/cleaned\/alerts\/2020\/09\/03')\npipeline_run_msalerts = Experiment(ws, 'SampleExperiment').submit(pipeline_test, pipeline_parameters={&quot;inrawpath&quot;  : test_raw_path,\n                                                                                                        &quot;incleanedpath&quot; : test_cleaned_path})```\n\n<\/code><\/pre>\n<\/li>\n<\/ul>\n<p>This is the Script Used(SimpleTest.py):<BR><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport sys\nimport argparse\nimport pathlib\nimport azureml.core\nimport pandas as pd\n\nparser = argparse.ArgumentParser(&quot;datapreponly&quot;)\nparser.add_argument(&quot;--input_data&quot;, type=str)\nparser.add_argument(&quot;--cleaned_data&quot;, type=str)\n\nargs = parser.parse_args()\n\nprint(&quot;Argument 1: %s&quot; % args.input_data)\nprint(&quot;Argument 2: %s&quot; % args.cleaned_data)\n\ntestDf = pd.read_csv(args.input_data, error_bad_lines=False)\nprint('Total Data Shape' + str(testDf.shape))\n\nif not (args.cleaned_data is None):\n    output_path = args.cleaned_data\n    os.makedirs(output_path, exist_ok=True)\n    outdatapath = output_path + '\/alert.csv'    \n    testDf.to_csv(outdatapath, index=False)\n<\/code><\/pre>\n<p><strong>Triggering this AzureMLPipeline from AzureDataFactory :<\/strong><BR>\nThe above code works fine by executing the ML pipeline in AzureMLWorkspace\/PipelineSDK. I am trying to trigger the AzureMLpipeline from AzureDataFactory(AzureMachineLearningExecutePipeline) activity as follows<BR><\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/Jo0dD.png\" alt=\"enter image description here\" \/><\/p>\n<p>Tried a debug run as follows by passing 2 string input paths<BR>\nrawdatapath = &quot;samplefolder\/raw\/alerts\/2017\/05\/31\/test.csv&quot;<BR>\ncleaneddatapath = &quot;samplefolder\/raw\/cleaned\/2020\/09\/03\/&quot;<\/p>\n<p><img src=\"https:\/\/i.stack.imgur.com\/BByYd.png\" alt=\"enter image description here\" \/><\/p>\n<pre><code>Current directory:  \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/myazuremlworkspace\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\/mounts\/workspaceblobstore\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\nPreparing to call script [ SimpleTest.py ] \nwith arguments:\n ['--input_data', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/myazuremlworkspace\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\/mounts\/SampleStore\/somefolder\/raw\/alerts\/2020\/08\/03\/default_in.csv',\n '--cleaned_data', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/myazuremlworkspace\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\/mounts\/SampleStore\/somefolder\/cleaned\/alerts\/2020\/08\/03\/default_out.csv']\nAfter variable expansion, calling script [ SimpleTest.py ] with arguments:\n ['--input_data', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/myazuremlworkspace\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\/mounts\/SampleStore\/somefolder\/raw\/alerts\/2020\/08\/03\/default_in.csv',\n '--cleaned_data', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/myazuremlworkspace\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\/mounts\/SampleStore\/somefolder\/cleaned\/alerts\/2020\/08\/03\/default_out.csv']\n\nScript type = None\nArgument 1: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/myazuremlworkspace\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\/mounts\/SampleStore\/somefolder\/raw\/alerts\/2020\/08\/03\/default_in.csv\nArgument 2: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/myazuremlworkspace\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\/mounts\/SampleStore\/somefolder\/cleaned\/alerts\/2020\/08\/03\/default_out.csv\n.......................\nFileNotFoundError: [Errno 2] No such file or directory: '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/myazuremlworkspace\/azureml\/d8ee11ea-5838-46e5-a8ce-da2fbff5aade\/mounts\/SampleStore\/somefolder\/raw\/alerts\/2020\/08\/03\/default_in.csv'\n<\/code><\/pre>\n<p>It shows that the default path is taken instead of the pipeline parameter(<em>No such File or directory error is less important as the main point is the default path is taken instead of the pipeline parameters<\/em>). I doubt its because of pass the pipelineparameter as a string instead of a datapath.<BR>\n<BR><br \/>\n<strong>FINALLY THE QUESTION<\/strong> :  How to pass a datapath to an AzureMLPipelineActivity from Azure Data Factory?<\/p>\n<p><BR>Thanks.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-03 19:14:41.487 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-09-08 10:51:54.143 UTC",
        "Question_score":3,
        "Question_tags":"azure-data-factory|azure-data-factory-2|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1758,
        "Owner_creation_date":"2019-11-28 11:07:18.203 UTC",
        "Owner_last_access_date":"2022-09-23 21:26:15.933 UTC",
        "Owner_reputation":350,
        "Owner_up_votes":19,
        "Owner_down_votes":1,
        "Owner_views":34,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63730264",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61279914,
        "Question_title":"AzureML: ResolvePackageNotFound azureml-dataprep",
        "Question_body":"<p>I've got a basic ScriptStep in my AML Pipeline and it's just trying to read an attached dataset. When i execute this simple example, the pipeline fails with the following in the driver log:<\/p>\n\n<blockquote>\n  <p>ImportError: azureml-dataprep is not installed. Dataset cannot be used\n  without azureml-dataprep. Please make sure\n  azureml-dataprep[fuse,pandas] is installed by specifying it in the\n  conda dependencies. pandas is optional and should be only installed if\n  you intend to create a pandas DataFrame from the dataset.<\/p>\n<\/blockquote>\n\n<p>I then modified my step to include the conda package but then the driver fails with \"ResolvePackageNotFound: azureml-dataprep\". The entire log file can be accessed <a href=\"https:\/\/www.dropbox.com\/s\/372ht6jkvzu9loo\/conda.err.txt?dl=0\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<pre><code># create a new runconfig object\nrun_config = RunConfiguration()\nrun_config.environment.docker.enabled = True\nrun_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\nrun_config.environment.python.user_managed_dependencies = False\nrun_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['azureml-dataprep[pandas,fuse]'])\n\nsource_directory = '.\/read-step'\nprint('Source directory for the step is {}.'.format(os.path.realpath(source_directory)))\nstep2 = PythonScriptStep(name=\"read_step\",\n                         script_name=\"Read.py\", \n                         arguments=[\"--dataFilePath\", dataset.as_named_input('local_ds').as_mount() ],\n                         compute_target=aml_compute, \n                         source_directory=source_directory,\n                         runconfig=run_config,\n                         allow_reuse=False)\n<\/code><\/pre>\n\n<p>I'm out of ideas, would deeply appreciate any help here!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-17 20:12:14.353 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-10 21:48:11.63 UTC",
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":1244,
        "Owner_creation_date":"2012-02-23 16:54:25.41 UTC",
        "Owner_last_access_date":"2022-09-02 23:23:03.83 UTC",
        "Owner_reputation":1704,
        "Owner_up_votes":61,
        "Owner_down_votes":7,
        "Owner_views":232,
        "Answer_body":"<p>The <code>azureml-sdk<\/code> isn't available on conda, you need to install it with <code>pip<\/code>.<\/p>\n\n<pre><code>myenv = Environment(name=\"myenv\")\nconda_dep = CondaDependencies().add_pip_package(\"azureml-dataprep[pandas,fuse]\")\nmyenv.python.conda_dependencies=conda_dep\nrun_config.environment = myenv\n<\/code><\/pre>\n\n<p>For more information, about this error, the logs tab has a log named <code>20_image_build_log.txt<\/code> which Docker build logs. It contains the error where <code>conda<\/code> failed to failed to find <code>azureml-dataprep<\/code><\/p>\n\n<p>EDIT:<\/p>\n\n<p>Soon, you won't have to specify this dependency anymore. the Azure Data4ML team says <code>azureml-dataprep[pandas,fuse]<\/code> is getting added as a dependency for <code>azureml-defaults<\/code> which is automatically installed on all images. <\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-04-17 22:35:56.78 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-04-20 20:59:20.077 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61279914",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64869692,
        "Question_title":"TabularDataset \"topandasdataframe()\" - does not support pandas errorbadlines?",
        "Question_body":"<p>I am trying to skip lines that produces more columns than intended while loading to a pandas dataframe.<\/p>\n<p>Like this Pandas Option: When error_bad_lines = False, pandas will skip these lines.<\/p>\n<p>How to achieve this with to-pandas-dataframe()?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/aS9gF.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/aS9gF.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#to-pandas-dataframe-on-error--null---out-of-range-datetime--null--\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#to-pandas-dataframe-on-error--null---out-of-range-datetime--null--<\/a><\/p>\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-17 05:14:27.717 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":96,
        "Owner_creation_date":"2019-11-28 11:07:18.203 UTC",
        "Owner_last_access_date":"2022-09-23 21:26:15.933 UTC",
        "Owner_reputation":350,
        "Owner_up_votes":19,
        "Owner_down_votes":1,
        "Owner_views":34,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64869692",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69495213,
        "Question_title":"Not able to read model.pkl from output folder in Azure ML",
        "Question_body":"<p>I'm try to read the model.pkl file from the artifacts output folder like this<\/p>\n<pre><code>def init():\n    global model\n    # infile = open('model.pkl','rb') \n    # model = pickle.load(infile)\n    #model = joblib.load('model.pkl')\n    model_path = Model.get_model_path(model_name = '&lt;&lt;modelname&gt;&gt;')\n    model_path=&quot;outputs\/model.pkl&quot;\n    # deserialize the model file back into a sklearn model\n    model = joblib.load(model_path)\n<\/code><\/pre>\n<p>But still its not working please guide me how to read model.pkl file from artifacts output folder, because of this it is failing to deploy into Azure container instance<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_date":"2021-10-08 11:36:24.917 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":172,
        "Owner_creation_date":"2019-05-09 13:26:02.973 UTC",
        "Owner_last_access_date":"2022-09-23 21:02:49.36 UTC",
        "Owner_reputation":97,
        "Owner_up_votes":24,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69495213",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50334563,
        "Question_title":"Deployment of an Azure ML Experiment as a Web Service through Azure Machine Learning Studio",
        "Question_body":"<p>I used Machine learning tutorial: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/create-experiment\" rel=\"nofollow noreferrer\">Create your first data science experiment in Azure Machine Learning Studio<\/a> to create an <code>Experiment<\/code> and then converted it to a <code>predictive experiment<\/code>. Now I'm trying to deploy it as a Web Service by following this article that was referenced in the above article: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/publish-a-machine-learning-web-service#deploy-it-as-a-web-service\" rel=\"nofollow noreferrer\">Deploy it as a web service<\/a>. But when I click on <code>Run<\/code> and then on <code>Deploy Web Service<\/code>, I don't see the <code>Price Plan<\/code> dropdown and <code>Plan Name<\/code> input box etc as mentioned in the section <code>Machine Learning Web Service portal Deploy Experiment Page<\/code> of the second article above. After I clicked on Deploy Web Service link in ML studio, I got the page shown below.<strong>Question<\/strong>: What I may be doing wrong?<\/p>\n\n<p>Note: You can click on the picture to get a larger view.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/G3TKo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/G3TKo.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-14 16:00:05.237 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":330,
        "Owner_creation_date":"2012-02-25 04:28:19.34 UTC",
        "Owner_last_access_date":"2022-09-24 17:06:32.277 UTC",
        "Owner_reputation":19815,
        "Owner_up_votes":2703,
        "Owner_down_votes":22,
        "Owner_views":2272,
        "Answer_body":"<p>I think it depends on what workspace you're in. If you're in the free one then you get the screen that you already get, but if you create a workspace in the Azure portal and use that one, then you will get a screen like below.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/drRpa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/drRpa.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>To create a new workspace, in the Azure Portal, create a new \"Machine Learning Studio Workspace\" and when you go to Azure ML Studio select the new workspace from the top right.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2018-05-14 18:36:11.967 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50334563",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52294404,
        "Question_title":"R Server on Azure",
        "Question_body":"<p>I need to execute R code as webservice, so i tried MLS and it works ok. \nThe problem is that the packages are too old, and i need functions that are not implemented on old packages. \nI asked microsoft support about it, and they have no data up upgrade it, and the new packages require a upgrade of it.<\/p>\n\n<p>How can i do that using other resources, like webapi instead of MLS?\nAll solutions i found requires R installed on machine, wich is a problem for create an azure webapp, function, or api.\nI need an endpoint for forecast on-demand.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2018-09-12 11:47:27.56 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"r|azure-web-app-service|azure-functions|azure-machine-learning-studio",
        "Question_view_count":327,
        "Owner_creation_date":"2018-01-09 17:16:11.123 UTC",
        "Owner_last_access_date":"2022-07-06 14:56:48.507 UTC",
        "Owner_reputation":1108,
        "Owner_up_votes":33,
        "Owner_down_votes":2,
        "Owner_views":183,
        "Answer_body":"<p>I found one way to execute R on Azure functions.\nthe solutions is copy R-Portable in\n<a href=\"https:\/\/sourceforge.net\/projects\/rportable\/\" rel=\"nofollow noreferrer\">https:\/\/sourceforge.net\/projects\/rportable\/<\/a>\nunzip it using powershell and create a process on function code. In my case i used the code:<\/p>\n\n<pre><code>System.Diagnostics.Process process = new System.Diagnostics.Process();\n            process.StartInfo.WorkingDirectory = @\"D:\\home\\site\\tools\\R-Portable\\App\\R-Portable\\bin\\\";\n            process.StartInfo.FileName = @\"D:\\home\\site\\tools\\R-Portable\\App\\R-Portable\\bin\\Rscript.exe\";\n            process.StartInfo.Arguments = \"-e \\\"print('Hello world')\\\"\";\n            process.StartInfo.UseShellExecute = false;\n            process.StartInfo.RedirectStandardOutput = true;\n            process.StartInfo.RedirectStandardError = true;\n            process.Start();\n            string outputt = process.StandardOutput.ReadToEnd();\n            string err = process.StandardError.ReadToEnd();\n            process.WaitForExit();\n<\/code><\/pre>\n\n<p>On your script you can access csv files or write, and after on function read and return that file.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-09-18 09:53:44.307 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52294404",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71862126,
        "Question_title":"Volume mount failed with: DataAccessError(PermissionDenied) Azure-ML",
        "Question_body":"<p>I have created AzureML experiment where i am ingesting a dataset with azure SQL Server as source.\nbelow is the code.<\/p>\n<pre><code>from azureml.core import Experiment, ScriptRunConfig, Environment\n\ninput_data = ws.datasets.get('azure_sql_data')\n\nexperiment_folder = 'experiment'\nenv = Environment.from_conda_specification(&quot;env&quot;, &quot;environment.yml&quot;)\n\nscript_config = ScriptRunConfig(source_directory=experiment_folder,\n                                script='tranformer.py',\n                                arguments = ['--input-data', input_data.as_named_input('input_data')],\n                                environment=env)\n<\/code><\/pre>\n<p>When i run this experiment i am getting following error.\n<strong>Dataset initialization failed: DataAccessError(PermissionDenied)<\/strong><\/p>\n<p>Am i missing something here?<\/p>\n<p>I can access the azure SQL server data in while running it in aml notebook but when i run experiment i am getting above error.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-13 18:13:30.593 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":147,
        "Owner_creation_date":"2019-02-01 14:38:56.423 UTC",
        "Owner_last_access_date":"2022-09-18 05:00:16.3 UTC",
        "Owner_reputation":93,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71862126",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36127510,
        "Question_title":"How to use Azure Data Lake Store as an input data set for Azure ML?",
        "Question_body":"<p>I am moving data into Azure Data Lake Store and processing it using Azure Data Lake Analytics. Data is in form of XML and I am reading it through <a href=\"https:\/\/github.com\/Azure\/usql\/tree\/master\/Examples\/DataFormats\/Microsoft.Analytics.Samples.Formats\" rel=\"nofollow\">XML Extractor<\/a>. Now I want to access this data from Azure ML and it looks like Azure Data Lake store is not directly supported at the moment. <\/p>\n\n<p>What are the possible ways to use Azure Data Lake Store with Azure ML?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-03-21 09:42:18.21 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-data-lake",
        "Question_view_count":963,
        "Owner_creation_date":"2010-05-23 18:06:11.227 UTC",
        "Owner_last_access_date":"2022-09-23 09:27:27.487 UTC",
        "Owner_reputation":838,
        "Owner_up_votes":32,
        "Owner_down_votes":1,
        "Owner_views":101,
        "Answer_body":"<p>Right now, Azure Data Lake Store is not a supported source, as you note.  That said, Azure Data Lake Analytics can also be used to write data out to Azure Blob Store, and so you can use that as an approach to process the data in U-SQL and then stage it for Azure Machine Learning to process it from Blob store.  When Azure ML supports Data Lake store, then you can switch that over. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-03-23 16:22:08.12 UTC",
        "Answer_score":4.0,
        "Owner_location":"Pakistan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36127510",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61144788,
        "Question_title":"How to select a subset of Avro files from Azure Data Lake Gen2 by data content",
        "Question_body":"<p>I have lots of Avro files in an Azure Data Lake Gen2 storage sent by an Event Hub service with capture enabled. These Avro files contain data from different sensors and engines. The structure of the directory is organized in folders with the following path format (typical of Azure Blobs): <\/p>\n\n<p><code>namespace\/eventhub\/partition\/year\/month\/day\/hour\/minute\/file.avro<\/code><\/p>\n\n<p>I need to access to some of these files, in order to get data to 1) pre-process and 2) train or re-train a machine learning model. I'd like to know what procedure could I follow to download or mount just the files containing data of a particular engine and\/or sensor, given that not data from all of them are present in all Avro files. Let's assume I'm interested just in files containing data from:<\/p>\n\n<pre><code>Engine = engine_ID_4012\nSensor = sensor_engine_4012_ID_0114\n<\/code><\/pre>\n\n<p>I'm aware that Spark offers some advantages working with Avro files, so I could consider to carry out this task using Databricks. Otherwise the option is Azure Machine Learning service, but maybe there are other possiblities, for instance a combination. The goal is to speed up the data ingestion process, avoiding to read files with no needed data.<\/p>\n\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-10 16:45:07.233 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"avro|azure-data-lake|azure-eventhub|azure-databricks|azure-machine-learning-service",
        "Question_view_count":248,
        "Owner_creation_date":"2018-09-07 11:08:23.563 UTC",
        "Owner_last_access_date":"2022-09-20 13:21:15.58 UTC",
        "Owner_reputation":150,
        "Owner_up_votes":64,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61144788",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62780977,
        "Question_title":"Threshold for allowed amount of failed Hyperdrive runs",
        "Question_body":"<p>Because &quot;reasons&quot;, we know that when we use <code>azureml-sdk<\/code>'s <code>HyperDriveStep<\/code> we expect a number of <code>HyperDrive<\/code> runs to fail -- normally around 20%. How can we handle this without failing the entire <code>HyperDriveStep<\/code> (and then all downstream steps)? Below is an example of the pipeline.<\/p>\n<p>I thought there would be an <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.hyperdrive.hyperdriverunconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\"><code>HyperDriveRunConfig<\/code><\/a> param to allow for this, but it doesn't seem to exist. Perhaps this is controlled on the Pipeline itself with the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipeline(class)?view=azure-ml-py#remarks\" rel=\"nofollow noreferrer\"><code>continue_on_step_failure<\/code><\/a> param?<\/p>\n<p>The workaround we're considering is to catch the failed run within our <code>train.py<\/code> script and manually log the primary_metric as zero.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/U8iNL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/U8iNL.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-07 17:41:09.73 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-07 21:59:41.91 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":185,
        "Owner_creation_date":"2014-07-15 20:45:20.427 UTC",
        "Owner_last_access_date":"2022-09-23 15:42:13.1 UTC",
        "Owner_reputation":3359,
        "Owner_up_votes":1187,
        "Owner_down_votes":14,
        "Owner_views":555,
        "Answer_body":"<p>thanks for your question.<\/p>\n<p>I'm assuming that HyperDriveStep is one of the steps in your Pipeline and that you want the remaining Pipeline steps to continue, when HyperDriveStep fails, is that correct?\nEnabling continue_on_step_failure, should allow the rest of the pipeline steps to continue, when any single steps fails.<\/p>\n<p>Additionally, the HyperDrive run consists of multiple child runs, controlled by the HyperDriveConfig. If the first 3 child runs explored by HyperDrive fail (e.g. with user script errors), the system automatically cancels the entire HyperDrive run, in order to avoid further wasting resources.<\/p>\n<p>Are you looking to continue other Pipeline steps when the HyperDriveStep fails? or are you looking to continue other child runs within the HyperDrive run, when the first 3 child runs fail?<\/p>\n<p>Thanks!<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2020-07-07 20:47:43.553 UTC",
        "Answer_score":2.0,
        "Owner_location":"Seattle, WA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62780977",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57382555,
        "Question_title":"Grant workspace access for Datastore.register_azure_blob_container - Documentation?",
        "Question_body":"<p>Is there any documentation on the <code>grant_workspace_access<\/code> parameter in the <code>Datastore.register_azure_blob_container<\/code> method? I see it called out in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore(class)?view=azure-ml-py#register-azure-blob-container-workspace--datastore-name--container-name--account-name--sas-token-none--account-key-none--protocol-none--endpoint-none--overwrite-false--create-if-not-exists-false--skip-validation-false--grant-workspace-access-false--subscription-id-none--resource-group-none-\" rel=\"nofollow noreferrer\">SDK documentation<\/a>, but I'm getting an error when I try to call the service and I don't know how to troubleshoot.<\/p>\n\n<p>The error I'm getting is:<\/p>\n\n<pre><code>ERROR - Registering datastore failed with a 400 error code and error message \n'Cannot create resource using Workspace MSI access token. Please make sure Administrator\/ \nUser Access Administrator grants the Contributor RBAC role for the workspace.\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-06 19:10:58.51 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-07 22:41:24.37 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":678,
        "Owner_creation_date":"2018-06-19 20:17:41.717 UTC",
        "Owner_last_access_date":"2022-09-21 12:31:28.057 UTC",
        "Owner_reputation":392,
        "Owner_up_votes":8,
        "Owner_down_votes":4,
        "Owner_views":39,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57382555",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65245364,
        "Question_title":"how to include environment when submitting an automl experiment in azure machine learning",
        "Question_body":"<p>I use code like below to create an AutoML object to submit an experiment for classification training<\/p>\n<pre><code>automl_settings = {\n       &quot;n_cross_validations&quot;: 2,\n       &quot;primary_metric&quot;: 'accuracy',\n       &quot;enable_early_stopping&quot;: True,\n       &quot;experiment_timeout_hours&quot;: 1.0,\n       &quot;max_concurrent_iterations&quot;: 4,\n       &quot;verbosity&quot;: logging.INFO,\n   }\n\n   automl_config = AutoMLConfig(task = 'classification',\n                               compute_target = compute_target,\n                               training_data = train_data,\n                               label_column_name = label,\n                               **automl_settings\n                               )\n\n   ws = Workspace.from_config()\n   experiment = Experiment(ws, &quot;your-experiment-name&quot;)\n   run = experiment.submit(automl_config, show_output=True)\n<\/code><\/pre>\n<p>I want to include my conda yml file (like below) in my experiment submission.<\/p>\n<pre><code>env = Environment.from_conda_specification(name='myenv', file_path='conda_dependencies.yml')\n<\/code><\/pre>\n<p>However, I don't see any environment parameter in <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\">AutoMLConfig class documentation<\/a> (similar to what environment parameter does in <code>ScriptRunConfig<\/code>) or find any example how to do so.<\/p>\n<p>I notice after the experiment is submitted, I get message like this<\/p>\n<pre><code>Running on remote.\nNo run_configuration provided, running on aml-compute with default configuration\n<\/code><\/pre>\n<p>Is <code>run_configuration<\/code> used for specifying environment? If so, how do I provide run_configuration in my <strong>AutoML experiment run<\/strong>?<\/p>\n<p>Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2020-12-11 03:23:25.68 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service|azure-sdk-python",
        "Question_view_count":229,
        "Owner_creation_date":"2017-05-24 01:09:10.03 UTC",
        "Owner_last_access_date":"2020-12-16 08:24:08.143 UTC",
        "Owner_reputation":127,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65245364",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40018320,
        "Question_title":"Is it secure to pass the DB query to AzureML as a global parameter?",
        "Question_body":"<p>When using AzureMLBatchExecution activity in Azure Data Factory, is it secure to pass the DB query as a global parameter to the AzureML web service? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-13 10:21:23.45 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-data-factory|azure-machine-learning-studio",
        "Question_view_count":68,
        "Owner_creation_date":"2016-01-12 14:22:43.363 UTC",
        "Owner_last_access_date":"2019-07-02 21:45:24.25 UTC",
        "Owner_reputation":105,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":"<p>When you talk about \"secure\", are you worried about secure transmission between AML and ADF, or secure storage of your DB query information? For the former, all communication between these two services will be done with HTTPS. For the latter, our production storage has its strict access control. Besides, we only log the count of the global parameters and never the values. I believe it's secure to pass your DB query as a global parameter to the AzureML web service.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-10-14 07:46:39.48 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40018320",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58181917,
        "Question_title":"How can I use GPUs on Azure ML with a NVIDIA CUDA custom docker base image?",
        "Question_body":"<p>In my dockerfile to build the custom docker base image, I specify the following base image:<\/p>\n\n<pre><code>FROM nvidia\/cuda:10.1-cudnn7-devel-ubuntu16.04\n<\/code><\/pre>\n\n<p>The dockerfile corresponding to the nvidia-cuda base image is found here: <a href=\"https:\/\/gitlab.com\/nvidia\/container-images\/cuda\/blob\/master\/dist\/ubuntu16.04\/10.1\/devel\/cudnn7\/Dockerfile\" rel=\"nofollow noreferrer\">https:\/\/gitlab.com\/nvidia\/container-images\/cuda\/blob\/master\/dist\/ubuntu16.04\/10.1\/devel\/cudnn7\/Dockerfile<\/a><\/p>\n\n<p>Now when I print the AzureML log:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>run = Run.get_context()\n# setting device on GPU if available, else CPU\nrun.log(\"Using device: \", torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n<\/code><\/pre>\n\n<p>I get  <\/p>\n\n<pre><code>device(type='cpu')\n<\/code><\/pre>\n\n<p>but I would like to have a GPU and not a CPU. What am I doing wrong?<\/p>\n\n<p>EDIT: I do not know exactly what you need.\nBut I can give you the following information:\nazureml.core VERSION is 1.0.57.\nThe compute_target is defined via:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def compute_target(ws, cluster_name):\n    try:\n        cluster = ComputeTarget(workspace=ws, name=cluster_name)\n    except ComputeTargetException:\n        compute_config=AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',min_nodes=0,max_nodes=4)\n        cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n<\/code><\/pre>\n\n<p>The experiment is run via:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    ws = workspace(os.path.join(\"azure_cloud\", 'config.json'))\n    exp = experiment(ws, name=&lt;name&gt;)\n    c_target = compute_target(ws, &lt;name&gt;)\n    est = Estimator(source_directory='.',\n                   script_params=script_params,\n                   compute_target=c_target,\n                   entry_script='azure_cloud\/azure_training_wrapper.py',\n                   custom_docker_image=image_name,\n                   image_registry_details=img_reg_details,\n                   user_managed = True,\n                   environment_variables = {\"SYSTEM\": \"azure_cloud\"})\n\n    # run the experiment \/ train the model\n    run = exp.submit(config=est)\n<\/code><\/pre>\n\n<p>The yaml file contains:<\/p>\n\n<pre><code>dependencies:\n  - conda-package-handling=1.3.10\n  - python=3.6.2\n  - cython=0.29.10\n  - scikit-learn==0.21.2\n  - anaconda::cloudpickle==1.2.1\n  - anaconda::cffi==1.12.3\n  - anaconda::mxnet=1.5.0\n  - anaconda::psutil==5.6.3\n  - anaconda::pycosat==0.6.3\n  - anaconda::pip==19.1.1\n  - anaconda::six==1.12.0\n  - anaconda::mkl==2019.4\n  - anaconda::cudatoolkit==10.1.168\n  - conda-forge::pycparser==2.19\n  - conda-forge::openmpi=3.1.2\n  - pytorch::pytorch==1.2.0\n  - tensorboard==1.13.1\n  - tensorflow==1.13.1\n  - tensorflow-estimator==1.13.0\n  - pip:\n      - pytorch-transformers==1.2.0\n      - azure-cli==2.0.72\n      - azure-storage-nspkg==3.1.0\n      - azureml-sdk==1.0.57\n      - pandas==0.24.2\n      - tqdm==4.32.1\n      - numpy==1.16.4\n      - matplotlib==3.1.0\n      - requests==2.22.0\n      - setuptools==41.0.1\n      - ipython==7.8.0\n      - boto3==1.9.220\n      - botocore==1.12.220\n      - cntk==2.7\n      - ftfy==5.6\n      - gensim==3.8.0\n      - horovod==0.16.4\n      - keras==2.2.5\n      - langdetect==1.0.7\n      - langid==1.1.6\n      - nltk==3.4.5\n      - ptvsd==4.3.2\n      - pytest==5.1.2\n      - regex==2019.08.19\n      - scipy==1.3.1\n      - scikit_learn==0.21.3\n      - spacy==2.1.8\n      - tensorpack==0.9.8\n<\/code><\/pre>\n\n<p>EDIT 2: I tried <code>use_gpu = True<\/code> as well as upgrading to <code>azureml-sdk=1.0.65<\/code> but to no avail. Some people suggest additionally installing cuda-drivers via <code>apt-get install cuda-drivers<\/code>, but this does not work and I cannot build a docker image with that.\nThe output of <code>nvcc --version<\/code> on the docker image yields:<\/p>\n\n<pre><code>nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2019 NVIDIA Corporation\nBuilt on Sun_Jul_28_19:07:16_PDT_2019\nCuda compilation tools, release 10.1, V10.1.243\n<\/code><\/pre>\n\n<p>So I think that should be o.k. The docker image itself of course has no GPU, so command <code>nvidia-smi<\/code> is not found and <\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>python -i\n<\/code><\/pre>\n\n<p>and then<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import torch\nprint(torch.cuda.is_available())\n<\/code><\/pre>\n\n<p>will print False.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2019-10-01 09:31:41.213 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-10-03 11:12:30.17 UTC",
        "Question_score":0,
        "Question_tags":"docker|gpu|azure-machine-learning-service",
        "Question_view_count":1389,
        "Owner_creation_date":"2018-04-25 15:32:23.37 UTC",
        "Owner_last_access_date":"2022-09-21 14:08:46.433 UTC",
        "Owner_reputation":460,
        "Owner_up_votes":668,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Z\u00fcrich, Schweiz",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58181917",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67734831,
        "Question_title":"Does a AzureML webservice overwrite reset the Data Collection Dataset?",
        "Question_body":"<p>If we have an AzureML web service endpoint that is collecting data (for Data Drift Monitoring), does overwriting the web service endpoint with a new version of the model break links with the Dataset registered for collecting data.<\/p>\n<p>The relative path to this dataset is:\n<code>&lt;Subscription-ID&gt;\/&lt;Resource-Group&gt;\/&lt;Workspace&gt;\/&lt;Webservice-Name&gt;\/&lt;model-name&gt;\/&lt;version&gt;\/inputs\/**\/inputs*.csv<\/code><\/p>\n<p>If we redeploy a new version using <code>az ml model deploy ..... --overwrite<\/code>, will we need a new reference to a new Dataset for detecting Data Drift?<\/p>\n<p>If we use <code>az ml service update ..<\/code>, will the Dataset reference be kept intact?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-05-28 07:46:07.13 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":44,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p>Since the Dataset Asset is a simple reference to a location in a Datastore. Assuming the model version and service name does not change, the Dataset reference also will not change. If however, with every Service Update - The model version changes then adding a Dataset with Relative Path:<\/p>\n<pre><code>&lt;Subscription-ID&gt;\/&lt;Resource-Group&gt;\/&lt;Workspace&gt;\/&lt;Webservice-Name&gt;\/&lt;model-name&gt;\/*\/inputs\/**\/inputs*.csv\n<\/code><\/pre>\n<p>Will solve the problem. Since Data Drift is another service referencing this Dataset asset, it will keep working as expected.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-06-18 10:40:50.2 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67734831",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45302957,
        "Question_title":"How to import Basemap (mpl) in Azure ML (section Notebooks)",
        "Question_body":"<p>how can I import Basemap (from mpl_toolkits.basemap) in Azure ML (in section Notebooks)? \nIs there a general way to import libraries in Azure ML? \n(current version is shown as Python 3.4.5 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:47:47) IPython: 5.1.0)<\/p>\n\n<p>pip installs the GEOS package but there are missing dependencies (and I could export the GEOS_DIR)<\/p>\n\n<blockquote>\n  <p><i> Please install the corresponding packages using your\n      systems software management system (e.g. for Debian Linux do:\n      'apt-get install libgeos-3.3.3 libgeos-c1 libgeos-dev' and\/or\n      set the environment variable GEOS_DIR to point to the location\n      where geos is installed (for example, if geos_c.h\n      is in \/usr\/local\/include, and libgeos_c is in \/usr\/local\/lib,\n      set GEOS_DIR to \/usr\/local), or edit the setup.py script\n      manually and set the variable GEOS_dir (right after the line\n      that says \"set GEOS_dir manually here\". <\/i><\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-07-25 12:13:19.823 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-07-26 10:25:17.697 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|matplotlib-basemap|azure-machine-learning-studio",
        "Question_view_count":321,
        "Owner_creation_date":"2016-10-28 08:02:58.503 UTC",
        "Owner_last_access_date":"2022-09-19 11:29:05.033 UTC",
        "Owner_reputation":2386,
        "Owner_up_votes":397,
        "Owner_down_votes":7,
        "Owner_views":614,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45302957",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73226069,
        "Question_title":"How to save\/register a model using the \"Execute Python Script\" component in ML Designer?",
        "Question_body":"<p>The out-of-the-box Azure ML Designer components do not allow enough customization for building\/scoring my scikit-learn model. I am trying to save the ML model into the <code>outputs<\/code> folder so I can register it. The <code>outputs<\/code> folder is not being displayed after running the pipeline nor is the pickle formatted model file.<\/p>\n<p>Error Output:<\/p>\n<pre><code>Got exception when invoking script at line 112 in function azureml_main: \n'FileNotFoundError: [Errno 2] No such file or directory: '.\/outputs\/knn_model.pkl''\n<\/code><\/pre>\n<p>Snippet of relevant code:<\/p>\n<pre><code>run=Run.get_context()\nclf_model.fit(train_x,train_y)\n\noutput_dir = Path('.\/outputs\/')\n    if not output_dir.exists():\n        output_dir.mkdir()\n        \njoblib.dump(value=clf_model , filename='.\/outputs\/knn_model.pkl')\n\nrun.register_model(model_name='knn_model_security_roles',\n                                path='.\/outputs\/knn_model.pkl')\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-03 18:20:44.567 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-03 21:02:31.49 UTC",
        "Question_score":0,
        "Question_tags":"python|scikit-learn|azure-machine-learning-service|azureml-python-sdk|azure-ml-pipelines",
        "Question_view_count":44,
        "Owner_creation_date":"2019-07-03 18:52:49.727 UTC",
        "Owner_last_access_date":"2022-09-01 15:34:07.773 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73226069",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59412213,
        "Question_title":"Error: \"Make sure to create your workspace using a client which support MSI\" when deploying Azure ARM template for Machine Learning Services Workpsace",
        "Question_body":"<p>I'm currently trying to script our Azure Machine Learning infrastructure, using ARM templates and running through Terraform.  In order to ensure that the template works, I'm first running it from a file using the Az CLI.<\/p>\n\n<p>I'm running this on Ubuntu, with the below version of the Az CLI:-<\/p>\n\n<pre><code>azure-cli                         2.0.78\n\ncommand-modules-nspkg              2.0.3\ncore                              2.0.78\nnspkg                              3.0.4\ntelemetry                          1.0.4\n\nPython location '\/opt\/az\/bin\/python3'\nExtensions directory '\/home\/blah\/.azure\/cliextensions'\n\nPython (Linux) 3.6.5 (default, Dec 12 2019, 11:11:33) \n[GCC 8.3.0]\n<\/code><\/pre>\n\n<p>I have already created the Storage Account, App Insights and Key Vault using terraform.<\/p>\n\n<p>When trying to run the template using the Az CLI with the command:-<\/p>\n\n<pre><code>az group deployment create --name MachineLearning --resource-group data-science --template-file ML_ARM.json --parameters appInsightsName=machine-learning-dev storageAccountName=machinelearningdev keyVaultName=data-science-dev mlApiVersion=2018-11-19 mlWorkspaceName=machine-learning-dev location=uksouth\n<\/code><\/pre>\n\n<p>I receive the following error:-<\/p>\n\n<p><code>Make sure to create your workspace using a client which support MSI<\/code><\/p>\n\n<p>The ARM template is below:-<\/p>\n\n<pre><code>{\n    \"$schema\": \"https:\/\/schema.management.azure.com\/schemas\/2015-01-01\/deploymentTemplate.json#\",\n    \"contentVersion\": \"1.0.0.0\",\n    \"parameters\": {\n        \"storageAccountName\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The name of the storage account\"\n            }\n        },\n        \"appInsightsName\" : {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The name of the app insights account\"\n            }\n        },\n        \"keyVaultName\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The name of the keyvault resource\"\n            }\n        },\n        \"mlApiVersion\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The api version of the ML workspace\"\n            }\n        },\n        \"mlWorkspaceName\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"The name of the Machine Learning Workspace\"\n            }\n        },\n        \"location\": {\n            \"type\": \"string\",\n            \"metadata\": {\n                \"description\": \"Resource location\"\n            }\n        }\n    },\n  \"resources\": [\n        {\n            \"apiVersion\": \"[parameters('mlApiVersion')]\",\n            \"type\": \"Microsoft.MachineLearningServices\/workspaces\",\n            \"name\": \"[parameters('mlWorkspaceName')]\",\n            \"location\": \"[parameters('location')]\",\n            \"sku\": {\n              \"tier\": \"enterprise\",\n              \"name\": \"enterprise\"\n            },\n            \"properties\": {\n                \"storageAccount\": \"[resourceId('Microsoft.Storage\/storageAccounts',parameters('storageAccountName'))]\",\n                \"applicationInsights\": \"[resourceId('Microsoft.Insights\/components',parameters('appInsightsName'))]\",\n                \"keyVault\": \"[resourceId('Microsoft.KeyVault\/vaults',parameters('keyVaultName'))]\"\n            }\n        }\n    ]\n}\n<\/code><\/pre>\n\n<p>Some rudimentary googling hasn't really been enlightening into what the issue might be with this; the documentation and guide templates for the Machine Learning Service are linked below:-<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-workspace-template\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-workspace-template<\/a>\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/2019-11-01\/workspaces\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/templates\/microsoft.machinelearningservices\/2019-11-01\/workspaces<\/a><\/p>\n\n<p>Any idea what the issue might be?  Thanks in advance for any pointers!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-12-19 14:58:08.223 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|terraform|azure-resource-manager|terraform-provider-azure|azure-machine-learning-service",
        "Question_view_count":422,
        "Owner_creation_date":"2019-07-09 20:45:35.403 UTC",
        "Owner_last_access_date":"2022-02-24 07:03:27.06 UTC",
        "Owner_reputation":327,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":38,
        "Answer_body":"<p>I am not familar with Terraform or that robust on ML Services; however, the error you provided lends itself to needing to have MSI authentication configured which is configured in the link you provided.<\/p>\n\n<p>Try updating your ARM to include the identity section like this:<\/p>\n\n<pre><code>   ...  },\n\"identity\": {\n        \"type\": \"systemAssigned\"\n      },\n                \"properties\": {\n                    \"storageAccount\": \"[resourceId('Microsoft.Storage\/storageAccounts',parameters('storageAccountName'))]\",\n                    \"applicationInsights\": \"[resourceId('Microsoft.Insights\/components',parameters('appInsightsName'))]\",\n                    \"keyVault\": \"[resourceId('Microsoft.KeyVault\/vaults',parameters('keyVaultName'))]\"\n                }\n<\/code><\/pre>\n\n<p>This will create the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/active-directory\/managed-identities-azure-resources\/overview\" rel=\"nofollow noreferrer\">Managed Service Identity<\/a>.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-12-19 18:19:55.737 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59412213",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56450223,
        "Question_title":"Image Classification in Azure Machine Learning",
        "Question_body":"<p>I'm preparing for the Azure Machine Learning exam, and here is a question confuses me.<\/p>\n<blockquote>\n<p>You are designing an Azure Machine Learning workflow. You have a\ndataset that contains two million large digital photographs. You plan\nto detect the presence of trees in the photographs. You need to ensure\nthat your model supports the following:<\/p>\n<p>Solution: You create a Machine\nLearning experiment that implements the Multiclass Decision Jungle\nmodule. Does this meet the goal?<\/p>\n<p>Solution: You create a Machine Learning experiment that implements the\nMulticlass Neural Network module. Does this meet the goal?<\/p>\n<\/blockquote>\n<p>The answer for the first question is No while for second is Yes, but I cannot understand why Multiclass Decision Jungle doesn't meet the goal since it is a classifier. Can someone explain to me the reason?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2019-06-04 19:33:42.253 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_score":1,
        "Question_tags":"machine-learning|azure-machine-learning-studio|azure-machine-learning-workbench|azure-machine-learning-service",
        "Question_view_count":538,
        "Owner_creation_date":"2015-12-07 02:00:13.69 UTC",
        "Owner_last_access_date":"2022-06-01 02:54:45.017 UTC",
        "Owner_reputation":388,
        "Owner_up_votes":84,
        "Owner_down_votes":2,
        "Owner_views":322,
        "Answer_body":"<p>I suppose that this is part of a series of questions that present the same scenario. And there should be definitely some constraints in the scenario. \nMoreover if you have a look on the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/multiclass-neural-network\" rel=\"nofollow noreferrer\">Azure documentation<\/a>:<\/p>\n\n<blockquote>\n  <p>However, recent research has shown that deep neural networks (DNN)\n  with many layers can be very effective in complex tasks such as image\n  or speech recognition. The successive layers are used to model\n  increasing levels of semantic depth.<\/p>\n<\/blockquote>\n\n<p>Thus, Azure recommends using Neural Networks for image classification. Remember, that the goal of the exam is to test your capacity to design data science solution <strong>using Azure<\/strong> so better to use their official documentation as a reference.<\/p>\n\n<p>And comparing to the other solutions:<\/p>\n\n<ol>\n<li>You create an Azure notebook that supports the Microsoft Cognitive\nToolkit.<\/li>\n<li>You create a Machine Learning experiment that implements\nthe Multiclass Decision Jungle module.<\/li>\n<li>You create an endpoint to the\nComputer vision API. <\/li>\n<li>You create a Machine Learning experiment that\nimplements the Multiclass Neural Network module.<\/li>\n<li>You create an Azure\nnotebook that supports the Microsoft Cognitive Toolkit.<\/li>\n<\/ol>\n\n<p>There are only 2 Azure ML Studio modules, and as the question is about constructing a <strong>workflow<\/strong> I guess we can only choose between them. (CNTK is actually the best solution as it allows constructing a deep neural network with ReLU whereas AML Studio doesn't, and API call is not about data science at all). <\/p>\n\n<p>Finally, I do agree with the other contributors that the question is absurd. Hope this helps.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-06-07 08:15:14.607 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56450223",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73650046,
        "Question_title":"Populating environment variables with secret values in AzureML",
        "Question_body":"<p>I'm setting up an AzureML pipeline which runs a command-line application using <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.commandstep?view=azure-ml-py\" rel=\"nofollow noreferrer\"><code>CommandStep<\/code><\/a>. The command-line application expects to receive some credentials in the form of environment variables.<\/p>\n<p>At the moment the best solution I can find is to wrap the command-line application in a <code>PythonScriptStep<\/code>, where the Python script will:<\/p>\n<ol>\n<li>Retrieve the credentials from the AzureML Keyvault as described <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.keyvault.keyvault?view=azure-ml-py\" rel=\"nofollow noreferrer\">here<\/a>;<\/li>\n<li>Set the environment variables; then<\/li>\n<li>Use a subprocess call to run the command-line application.<\/li>\n<\/ol>\n<p>Is there a simpler way to do this without requiring a Python script? For example, is it possible to configure the AzureML environment to populate environment variables directly from the Keyvault?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-08 13:42:45.577 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":45,
        "Owner_creation_date":"2014-06-25 12:11:55.16 UTC",
        "Owner_last_access_date":"2022-09-24 10:12:50.483 UTC",
        "Owner_reputation":1534,
        "Owner_up_votes":171,
        "Owner_down_votes":3,
        "Owner_views":56,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"London, UK",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73650046",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35851851,
        "Question_title":"How to delete all non-numeric rows in R?",
        "Question_body":"<p>I have a dataframe like bellow, where <code>ID<\/code> is numeric value, and <code>comment1<\/code> and <code>comment2<\/code> string that I am importing as a csv. But the data frame is giving result something like this bellow, where <code>fifth comment<\/code> should be in the <code>comment2<\/code> and the original <code>ID<\/code> value is replaced by this. This is happening randomly for only few rows. Moreover, this problem is only occurring when I am importing my <strong>R<\/strong> code in <strong>Azure ML<\/strong> studio, in <strong>RStudio<\/strong> no data misplace is occurring. So what I was thinking, just delete the entire row where the first column <code>ID<\/code> is not a numeric value. As the misplace string value is random long sentence, I can not do string matching to delete the row. And the dataframe is big enough that I just cannot delete the rows manually. Suggestion please. <\/p>\n\n<pre><code>  ID                 Comment1                  comment2\n 123             This is first comment        this is second\n 234              third comment               fourth comment\nfifth comment                                                  \n 345               sixth comment              seventh comment\n<\/code><\/pre>\n\n<p>You will find a sample of the dataframe here,<\/p>\n\n<pre><code>    df &lt;-\n  read.csv(\n    \"https:\/\/docs.google.com\/spreadsheets\/d\/171YXjzm3FsapXSkqgOSos6UGXNRcd1yxmLyvaRnCX5E\/pub?output=csv\"\n  )\ndf &lt;- df[-1,]\ndf &lt;- df[, 1:12]\ncolnames(df) &lt;-\n  c(\n    \"ID\",\"Created\",\"Comments\",\"Liked_By\",\"Disliked_By\", \"Recipient_Number\",\n    \"Sender\",\"Recipients\",\"Read_By\", \"Subject\",\"Introduction\",\"Body\"\n  )\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":5,
        "Question_creation_date":"2016-03-07 19:03:43.877 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2017-01-04 08:35:11.967 UTC",
        "Question_score":1,
        "Question_tags":"r|dataframe|delete-row|azure-machine-learning-studio",
        "Question_view_count":5339,
        "Owner_creation_date":"2016-02-17 01:35:51.607 UTC",
        "Owner_last_access_date":"2022-09-24 22:13:14.407 UTC",
        "Owner_reputation":473,
        "Owner_up_votes":289,
        "Owner_down_votes":7,
        "Owner_views":67,
        "Answer_body":"<p>Subset to numeric IDs:<\/p>\n\n<pre><code>subset(df, grepl('^\\\\d+$', df$ID))\n<\/code><\/pre>\n\n<p>The pattern should match values of ID that start and end with digits, and only contain digits.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-03-07 19:12:12.163 UTC",
        "Answer_score":3.0,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35851851",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44416344,
        "Question_title":"Azure Machine Learning Studio Custom Module Upload Error 0114 : An item with the same key has already been added",
        "Question_body":"<p>When trying to upload a custom R module to Azure Machine Learning Studio what causes the following error.<\/p>\n\n<blockquote>\n  <p>[ModuleOutput]<\/p>\n<\/blockquote>\n\n<pre><code>\"ErrorId\":\"BuildCustomModuleFailed\",\"ErrorCode\":\"0114\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 0114: Custom module build failed with error(s): An item with the same key has already been added.\"}} [ModuleOutput] Error: Error 0114: Custom module build failed with error(s): An item with the same key has already been added. \n<\/code><\/pre>\n\n<p>I have tried renaming the module so a name that does not exists.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-06-07 15:03:41.797 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":75,
        "Owner_creation_date":"2011-09-26 15:52:22.823 UTC",
        "Owner_last_access_date":"2022-09-22 19:57:35.203 UTC",
        "Owner_reputation":8183,
        "Owner_up_votes":598,
        "Owner_down_votes":2,
        "Owner_views":727,
        "Answer_body":"<p>The duplicate key exception is a red herring. <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn962112.aspx\" rel=\"nofollow noreferrer\" title=\"MSDN Module Error Code 0114\">Build error 0114<\/a> is a general error that occurs if there is a system exception while building the custom module. The real issue my module was compressed using the built in compress folder option in the Mac Finder. To fix this compress the file using the command line interface for <code>zip<\/code> in Terminal in the following very specific manner.<\/p>\n\n<blockquote>\n  <p>The following example:<\/p>\n<\/blockquote>\n\n<pre><code>cd ScoredDatasetMetadata\/\nzip ScoredDatasetMetadata *\nmv ScoredDatasetMetadata.zip ..\/\n<\/code><\/pre>\n\n<p>Builds a zip file with the correct file structure.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-06-07 15:03:41.797 UTC",
        "Answer_score":0.0,
        "Owner_location":"Franklin, TN",
        "Answer_last_edit_date":"2017-06-07 16:01:12.47 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44416344",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60391230,
        "Question_title":"Azure 504 DeploymentTimedOut ERROR - Service deployment polling reached non-successful terminal state, current service state",
        "Question_body":"<p>I am trying to deploy my machine learning model in Azure's AciWebservice to expose endpoints for further usage. But, it is showing me status 504 error with DeploymentTimedOut.  Locally, My Model is running fine. This is my prediction.py<\/p>\n\n<pre><code>%%writefile prediction.py\nimport json\nimport numpy as np\nimport os\nimport pickle\nfrom sklearn.externals import joblib\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.model import Model\nfrom azureml.core.environment import Environment\nfrom azureml.core.webservice import LocalWebservice, Webservice\n\ndef init():\n    global model\n    # retrieve the path to the model file using the model name\n    model_path = Model.get_model_path('prediction_model')\n    model = joblib.load(model_path)\n\ndef run(raw_data):\n    data = np.array(json.loads(raw_data)['data'])\n    # make prediction\n    y_hat = model.predict(data)\n    return json.dumps(y_hat.tolist())\n<\/code><\/pre>\n\n<p>and here goes the environment<\/p>\n\n<pre><code>myenv = Environment(name=\"myenv\")\nmyenv.docker.enabled = True\nmyenv.docker.base_image = \"mcr.microsoft.com\/azureml\/o16n-sample-user-base\/ubuntu-miniconda\"\n\n\nmyenv.docker.base_image_registry.address = \"shohozds.azurecr.io\"\nmyenv.docker.base_image_registry.username = \"farhad\"\nmyenv.docker.base_image_registry.password = \"*********************\"\n\nmyenv.inferencing_stack_version = \"latest\" \n\n\nconda_dep = CondaDependencies()\n\nconda_dep.add_pip_package(\"azureml-defaults\")\nmyenv.python.conda_dependencies=conda_dep\nmyenv.register(workspace=ws)\n<\/code><\/pre>\n\n<p>Using this environment in InferenceConfig<\/p>\n\n<pre><code>inference_config = InferenceConfig(entry_script=\"prediction.py\",\n                                   environment=envs['myenv'])\n<\/code><\/pre>\n\n<p>AciWebservice Configuration <\/p>\n\n<pre><code>deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n<\/code><\/pre>\n\n<p>And now the model deployment<\/p>\n\n<pre><code>service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n\n<p>But I am facing this error<\/p>\n\n<pre><code>\"code\": \"DeploymentTimedOut\",\n\"statusCode\": 504,\n<\/code><\/pre>\n\n<p>This is the full trace<\/p>\n\n<pre><code>ERROR - Service deployment polling reached non-successful terminal state, current service state: Unhealthy\nOperation ID: 0e37b930-2707-4d6b-92b0-2203d1c45978\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"DeploymentTimedOut\",\n  \"statusCode\": 504,\n  \"message\": \"The deployment operation polling has TimedOut. The service creation is taking longer than our normal time. We are still trying to achieve the desired state for the web service. Please check the webservice state for the current webservice health. You can run print(service.state) from the python SDK to retrieve the current state of the webservice.\"\n}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-02-25 09:23:43.55 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-03 21:42:53.2 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":1437,
        "Owner_creation_date":"2012-05-25 15:24:04.69 UTC",
        "Owner_last_access_date":"2022-09-22 03:04:03.037 UTC",
        "Owner_reputation":6262,
        "Owner_up_votes":68,
        "Owner_down_votes":6,
        "Owner_views":988,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Dhaka, Dhaka Division, Bangladesh",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60391230",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73279905,
        "Question_title":"Saving Azure ML pipelines in GIT or backup somewhere",
        "Question_body":"<p>I have 2 queries.<\/p>\n<p>I am creating a Pipelines with Azure ML Designer. Most of them are in Pipeline Draft state. Accidentally the workspace was deleted by one of the Azure tech team.<\/p>\n<p>Will the pipeline draft will also be saved in the Azure Storage account or only the pipelines which are run\/submitted only be saved in the Storage container. If the drafts also saved in the storage, could you share the folder where it is stored so that I could use it for restoration.<\/p>\n<h2>Query 2<\/h2>\n<p>How to save the Azure ML Pipelines created using the Azure ML designer to be saved in the GIT or some other backup device for future restoration purpose incase of any mishap.<\/p>\n<p>Is it possible to backup pipeline drafts in GIT?<\/p>\n<p>Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-08 14:55:18.303 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-25 05:43:56.227 UTC",
        "Question_score":0,
        "Question_tags":"git|pipeline|azure-machine-learning-service",
        "Question_view_count":54,
        "Owner_creation_date":"2022-08-08 14:43:38.977 UTC",
        "Owner_last_access_date":"2022-09-21 11:21:59.357 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73279905",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68437320,
        "Question_title":"How do you use ADF PipelineParameters with ML studio to change output location instead of input location",
        "Question_body":"<p>I want to parameterise my ML studio pipeline such that it outputs to a different blob store depending on which ADF environment it is being run from - the dev or prod ADF instance. This is so that the data engineers can have an output on their dev blob storage so they can avoid developing in live, while still using the exact same ML Studio pipeline as would be used in live.<\/p>\n<p>I have followed the instructions in <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-showcasing-datapath-and-pipelineparameter.ipynb\" rel=\"nofollow noreferrer\">this notebook<\/a> to change the input data source on blob dynamically using PipelineParameters.<\/p>\n<p>Can I \/ how do I do the same for output locations?<\/p>\n<p>Below is the code I used. I have used .\/outputs as the output folder. I want to change this to a location in blob storage dynamically set via a PipelineParameter that can be called from ADF. (Or another way if you have other suggestions!)<\/p>\n<p>Thanks in advance for any suggestions!<\/p>\n<pre class=\"lang-python prettyprint-override\"><code>\nfrom azureml.data.datapath import DataPath, DataPathComputeBinding\nfrom azureml.pipeline.core import PipelineParameter\n\ndefault_data_path = DataPath(\n    datastore=Datastore(workspace, &quot;prod_data_science&quot;), \n    path_on_datastore='path\/to\/data\/')\n\ninput_datapath_pipeline_param = PipelineParameter(name=&quot;input_datapath&quot;, default_value=default_data_path)\n\ninput_data_consumption = (\n    input_datapath_pipeline_param, \n    DataPathComputeBinding(\n        mode='mount',\n        overwrite = True\n    )\n)\n\ntoy_step = PythonScriptStep(\n    script_name=&quot;toy_code.py&quot;,\n    source_directory=&quot;.\/&quot;,\n    arguments=[\n        '--input_folder', input_data_consumption,\n        '--output_folder', '.\/outputs',\n    ],\n    inputs=[input_data_consumption],\n    runconfig=runconfig,\n)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2021-07-19 08:24:34.713 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-07-20 08:35:12.297 UTC",
        "Question_score":2,
        "Question_tags":"python|azure-data-factory|azure-machine-learning-service",
        "Question_view_count":127,
        "Owner_creation_date":"2021-07-15 13:16:19.493 UTC",
        "Owner_last_access_date":"2022-09-23 10:51:43.91 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68437320",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67988138,
        "Question_title":"Azure ML Tutorial - Failed to load entrypoint automl",
        "Question_body":"<p>I'm doing following tutorial. I failed to run &quot;Create a control script&quot;.<\/p>\n<p>What could be wrong?<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world<\/a><\/p>\n<pre><code>azureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$ python run-hello.py \nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = \nazureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 4.0.0 \n(\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), \nRequirement.parse('pyarrow&lt;4.0.0,&gt;=0.17.0'), {'azureml-dataset-runtime'}).\nhttps:\/\/ml.azure.com\/runs\/day1-experiment-hello_1623766747_073126f5? \nwsid=\/subscriptions\/1679753a-501e-4e46-9bff- \n6120ed5694cf\/resourcegroups\/kensazuremlrg\/workspaces\/kensazuremlws&amp;tid=94fe1041-ba47-4f49- \n866b- \n06c297c116cc\nazureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-15 14:22:54.453 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1241,
        "Owner_creation_date":"2016-11-04 09:17:30.693 UTC",
        "Owner_last_access_date":"2022-09-22 08:39:28.943 UTC",
        "Owner_reputation":1519,
        "Owner_up_votes":116,
        "Owner_down_votes":0,
        "Owner_views":375,
        "Answer_body":"<p>I think the error indicates that your environment is using pyarrow package which is of version 4.0.0 whereas azureml-dataset-runtime requires the package to be &gt;=0.17.0 but &lt;4.0.0<\/p>\n<p>It would be easier for you to uninstall the package and install a specific version. The list of releases of pyarrow are available here.<\/p>\n<p>Since you are using a notebook create new cells and run these commands.<\/p>\n<pre><code> !pip uninstall pyarrow\n !pip install -y pyarrow==3.0.0\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-06-16 16:35:31.177 UTC",
        "Answer_score":1.0,
        "Owner_location":"Finland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67988138",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71747263,
        "Question_title":"\"list index out of range\" error in AzureML inference schema",
        "Question_body":"<p>I've deployed a model using AzureML's inference cluster. I recently found that some of the requests to the model's API endpoint resulted in a 404 HTTP error involving a missing swagger.json file.<\/p>\n<p>So I followed <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\" rel=\"nofollow noreferrer\">this guide<\/a> in order to auto-generate the swagger.json file. But now all the requests to the endpoint result in a &quot;list index out of range&quot; error and it's something to do with the <code>input_schema<\/code> decorator. I just can't seem to pinpoint what the problem is exactly.<\/p>\n<p>Here is a minimal recreation of my scoring script:<\/p>\n<pre><code>from inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n\n\ndef inference(args):\n    # inference logic here\n    return model_output\n\n\ndef init():\n    global model\n    model = get_model()\n\n\ninput_sample = StandardPythonParameterType({\n    'input_1': 'some text',\n    'input_2': 'some other text',\n    'input_3': 'other text'\n})\n\nsample_global_parameters = StandardPythonParameterType(1.0)\n\noutput_sample = StandardPythonParameterType({\n    'Results': {\n        'text': 'some text',\n        'model_output': [\n             {\n                 'entity_type': 'date',\n                 'value': '05\/04\/2022'\n             }\n        ]\n    }\n})\n\n@input_schema('Inputs', input_sample)\n@input_schema('GlobalParameters', sample_global_parameters)\n@output_schema(output_sample)\n\ndef run(Inputs, GlobalParameters):\n    try:\n        return inference(Inputs['input_1'], Inputs['input_2'], Inputs['input_3'])\n    except Exception as e:\n        error = str(e)\n        return error\n\n<\/code><\/pre>\n<p>I've checked out <a href=\"https:\/\/stackoverflow.com\/questions\/64315239\/azure-ml-inference-schema-list-index-out-of-range-error\">this<\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/442305\/swagger-file-not-present-azure-machine-learning.html\" rel=\"nofollow noreferrer\">this<\/a> question but it didn't seem to help.<\/p>\n<p>I tried looking at the <a href=\"https:\/\/github.com\/Azure\/InferenceSchema\" rel=\"nofollow noreferrer\">code on GitHub<\/a> as well but I still can't triangulate on the exact problem.<\/p>\n<p>I'm calling the API from Postman with the default headers (I'm not adding anything). The request body looks like this:<\/p>\n<pre><code>{\n    &quot;Inputs&quot;: {\n        &quot;input_1&quot;: &quot;some text&quot;,\n        &quot;input_2&quot;: &quot;some other text&quot;,\n        &quot;input_3&quot;: &quot;different text&quot;\n    },\n    &quot;GlobalParameters&quot;: 1.0\n}\n<\/code><\/pre>\n<p>This is the error message from the endpoint logs:<\/p>\n<pre><code>2022-04-05 06:33:22,536 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 65, in run_scoring\n    response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 110, in invoke_user_with_timer\n    result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 92, in timer\n    result = func(*args, **kwargs)\n  File &quot;\/var\/azureml-app\/main.py&quot;, line 21, in run\n    return_obj = driver_module.run(**arguments)\n  File &quot;\/azureml-envs\/azureml_e63c7c0baf9bf3d861ce5992975a467b\/lib\/python3.7\/site-packages\/inference_schema\/schema_decorators.py&quot;, line 61, in decorator_input\n    return user_run(*args, **kwargs)\n  File &quot;\/azureml-envs\/azureml_e63c7c0baf9bf3d861ce5992975a467b\/lib\/python3.7\/site-packages\/inference_schema\/schema_decorators.py&quot;, line 55, in decorator_input\n    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\nIndexError: list index out of range\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_e63c7c0baf9bf3d861ce5992975a467b\/lib\/python3.7\/site-packages\/flask\/app.py&quot;, line 1832, in full_dispatch_request\n    rv = self.dispatch_request()\n  File &quot;\/azureml-envs\/azureml_e63c7c0baf9bf3d861ce5992975a467b\/lib\/python3.7\/site-packages\/flask\/app.py&quot;, line 1818, in dispatch_request\n    return self.view_functions[rule.endpoint](**req.view_args)\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 44, in score_realtime\n    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n  File &quot;\/var\/azureml-server\/synchronous\/routes.py&quot;, line 74, in run_scoring\n    raise RunFunctionException(str(exc))\nrun_function_exception.RunFunctionException\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-04-05 06:40:03.77 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|azure|azure-devops|azure-machine-learning-service",
        "Question_view_count":191,
        "Owner_creation_date":"2022-04-04 10:46:28.377 UTC",
        "Owner_last_access_date":"2022-07-22 12:18:06.723 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71747263",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51541328,
        "Question_title":"Updating pandas in Azure ML Studio results in an Error",
        "Question_body":"<p>This question is based on the solution of an other question the user user4446237 asked: <a href=\"https:\/\/stackoverflow.com\/questions\/46222606\/updating-pandas-to-version-0-19-in-azure-ml-studio\">Updating pandas to version 0.19 in Azure ML Studio<\/a><\/p>\n\n<p>I have followed the steps provided in the answer and I also get the information at the end, that I have imported the new version of pandas (0.23.3) instead of pandas (0.18.0). However after retrieving the version of the packages the code runs into an error:<\/p>\n\n<pre><code>Caught exception while executing function: Traceback (most recent call last):\n  File \"C:\\server\\invokepy.py\", line 192, in batch\n    idfs = [parameter for infile in infiles\n  File \"C:\\server\\invokepy.py\", line 194, in &lt;listcomp&gt;\n    infile, is_buffer=False)]\n  File \"C:\\server\\XDRReader\\xdrutils.py\", line 47, in XDRToPyObjects\n    return XDRBridge.xdr_to_py_positional(attrList)\n  File \"C:\\server\\XDRReader\\xdrbridge.py\", line 216, in xdr_to_py_positional\n    retList.append(XDRBridge.xdrobject_to_dataframe(key, value))\n  File \"C:\\server\\XDRReader\\xdrbridge.py\", line 155, in xdrobject_to_dataframe\n    }, index=np.arange(len(columns[0].values())), copy=False)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\frame.py\", line 223, in __init__\n    mgr = self._init_dict(data, index, columns, dtype=dtype)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\frame.py\", line 356, in _init_dict\n    columns = data_names = Index(keys)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\indexes\\base.py\", line 129, in __new__\n    from .range import RangeIndex\nSystemError: Parent module 'pandas.indexes' not loaded, cannot perform relative import\n<\/code><\/pre>\n\n<p>The code I am using is pretty much the same from Jay Gong:<\/p>\n\n<pre><code>import sys\nimport pandas as pd\nprint(pd.__version__)\ndel sys.modules['pandas']\ndel sys.modules['numpy']\ndel sys.modules['pytz']\ndel sys.modules['six']\ndel sys.modules['dateutil']\nsys.path.insert(0, '.\\\\Script Bundle')\nfor td in [m for m in sys.modules if m.startswith('pandas.') or m.startswith('numpy.') or m.startswith('pytz.') or m.startswith('dateutil.') or m.startswith('six.')]:\n    del sys.modules[td]\nimport pandas as pd\nprint(pd.__version__)\n# The entry point function can contain up to two input arguments:\n#   Param&lt;dataframe1&gt;: a pandas.DataFrame\n#   Param&lt;dataframe2&gt;: a pandas.DataFrame\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n<\/code><\/pre>\n\n<p>Is there anything I can do about this problem or am I reaching the limitations of Azure ML Studio's Python Script Module.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2018-07-26 14:31:06.37 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|pandas|azure|anaconda|azure-machine-learning-studio",
        "Question_view_count":267,
        "Owner_creation_date":"2018-04-23 11:33:08.917 UTC",
        "Owner_last_access_date":"2019-12-13 18:11:43.36 UTC",
        "Owner_reputation":75,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51541328",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64869372,
        "Question_title":"Azure ML Python SDK mini_batch_size not working as expected on ParallelRunConfig for TabularDataset",
        "Question_body":"<p>I am using Azure ML Python SDK for building custom experiment pipeline. I am trying to run the training on my tabular dataset in parallel on a cluster of 4 VMs with GPUs. I am following the documentation available on this link <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-contrib-pipeline-steps\/azureml.contrib.pipeline.steps.parallelrunconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-contrib-pipeline-steps\/azureml.contrib.pipeline.steps.parallelrunconfig?view=azure-ml-py<\/a><\/p>\n<p>The issue I am facing is that no matter what value I set for <code>mini_batch_size<\/code>, the individual runs get all rows. I am using EntryScript().logger to check the number of rows passed on to each process. What I see is that my data is being processed 4 times by 4 VMs and not getting split into 4 parts. I have tried setting value of <code>mini_batch_size<\/code> to <code>1KB<\/code>,<code>10KB<\/code>,<code>1MB<\/code>, but nothing seems to make a difference.<\/p>\n<p>Here is my code for ParallelRunConfig and ParallelRunStep. Any hints are appreciated. Thanks<\/p>\n<pre><code>#------------------------------------------------#\n# Step 2a - Batch config for parallel processing #\n#------------------------------------------------#\nfrom azureml.pipeline.steps import ParallelRunConfig\n\n# python script step for batch processing\ndataprep_source_dir = &quot;.\/src&quot;\nentry_point = &quot;batch_process.py&quot;\nmini_batch_size = &quot;1KB&quot;\ntime_out = 300\n\nparallel_run_config = ParallelRunConfig(\n    environment=custom_env,\n    entry_script=entry_point,\n    source_directory=dataprep_source_dir,\n    output_action=&quot;append_row&quot;,\n    mini_batch_size=mini_batch_size,\n    error_threshold=1,\n    compute_target=compute_target,\n    process_count_per_node=1,\n    node_count=vm_max_count,\n    run_invocation_timeout=time_out\n)\n\n\n#-------------------------------#\n# Step 2b - Run Processing Step #\n#-------------------------------#\nfrom azureml.pipeline.core import PipelineData\nfrom azureml.pipeline.steps import PythonScriptStep\nfrom azureml.pipeline.steps import ParallelRunStep\nfrom datetime import datetime\n\n# create upload dataset output for processing\noutput_datastore_name = processed_set_name\noutput_datastore = Datastore(workspace, output_datastore_name)\n\nprocessed_output = PipelineData(name=&quot;scores&quot;, \n                          datastore=output_datastore, \n                          output_path_on_compute=&quot;outputs\/&quot;)\n\n# pipeline step for parallel processing\nparallel_step_name = &quot;batch-process-&quot; + datetime.now().strftime(&quot;%Y%m%d%H%M&quot;)\n\nprocess_step = ParallelRunStep(\n    name=parallel_step_name,\n    inputs=[data_input],\n    output=processed_output,\n    parallel_run_config=parallel_run_config,\n    allow_reuse=False\n)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-17 04:29:21.1 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":625,
        "Owner_creation_date":"2013-12-02 09:25:07.69 UTC",
        "Owner_last_access_date":"2021-06-04 03:15:48.793 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Auckland, New Zealand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64869372",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67438154,
        "Question_title":"Getting error Missing required package \"azureml-dataset-runtime\" in VSCode",
        "Question_body":"<p>I am trying to setup my virtual environment for Azure in VS Code. I have installed the required packages, e.g., <code>azureml-core<\/code> and <code>azureml-widgets<\/code> and <code>azureml-dataset-runtime<\/code>. Both <code>azureml-core<\/code> and <code>azureml-widget<\/code> work fine, however, I keep getting an error missing required package for <code>azureml-dataset-runtime<\/code> although I installed it.<\/p>\n<p>I have Python 3.7 and Python 3.8 installed, both 64 bit and I tried both of them in my virtual environment, still no luck.<\/p>\n<p>Any suggestions?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-05-07 15:53:49.14 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":7,
        "Question_tags":"azure|visual-studio-code|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":433,
        "Owner_creation_date":"2020-09-12 17:36:28.727 UTC",
        "Owner_last_access_date":"2022-09-22 00:17:59.883 UTC",
        "Owner_reputation":105,
        "Owner_up_votes":52,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67438154",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57500954,
        "Question_title":"Automatically delete files in storage",
        "Question_body":"<p>So I've noticed that whenever I do a machine learning train\/retrain (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/retrain-machine-learning-model\" rel=\"nofollow noreferrer\">from here<\/a>), it generates a lot of files in my Azure blob storage as shown here<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/QN08i.png\" alt=\"Screenshot\"><\/p>\n\n<p>I wanted to ask if it was possible to automatically delete all these files or prevent them from ever being generated?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-14 19:33:41.207 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-15 01:26:33.773 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-storage|azure-machine-learning-studio",
        "Question_view_count":2077,
        "Owner_creation_date":"2018-05-21 00:50:14.91 UTC",
        "Owner_last_access_date":"2020-09-11 03:56:16.18 UTC",
        "Owner_reputation":45,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Answer_body":"<p>For automatically delete all these files in blob storage, you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/storage-lifecycle-management-concepts#azure-portal-list-view\" rel=\"nofollow noreferrer\">Lifecycle Management<\/a> of blob storage.<\/p>\n<p>It's easy to set up a rule and filter, after the rule is set up, all the files will be deleted as per the rule you defined.<\/p>\n<p>Simple steps:<\/p>\n<p>1.Nav to azure portal -&gt; your storage account -&gt; Blob services -&gt; Lifecycle Management, then click &quot;Add rule&quot;.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/n2Wne.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/n2Wne.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>2.In the &quot;Action set&quot; tab, select Delete blob and fill in the textbox; Then in &quot;Filter set&quot; tab, select a path.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/a2cdQ.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/a2cdQ.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>For more details\/instructions, please follow this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/storage-lifecycle-management-concepts#azure-portal-list-view\" rel=\"nofollow noreferrer\">article<\/a>.<\/p>\n<p>Also note that the rule runs once per day, and for the first time, it may take 24 hours to take effect.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_date":"2019-08-15 01:23:49.083 UTC",
        "Answer_score":4.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57500954",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63770171,
        "Question_title":"\"ImportError: No module named seaborn\" in Azure ML",
        "Question_body":"<p>Created a new compute instance in Azure ML and trained a model with out any issue. I wanted to draw a pairplot using <code>seaborn<\/code> but I keep getting the error <code>&quot;ImportError: No module named seaborn&quot;<\/code><\/p>\n<p>I ran <code>!conda list<\/code> and I can see seaborn in the list<\/p>\n<pre><code># packages in environment at \/anaconda:\n#\n# Name                    Version                   Build  Channel\n_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0  \nalabaster                 0.7.12                   py37_0  \nanaconda                  2018.12                  py37_0  \nanaconda-client           1.7.2                    py37_0  \nanaconda-navigator        1.9.6                    py37_0  \nanaconda-project          0.8.2                    py37_0  \napplicationinsights       0.11.9                    &lt;pip&gt;\nasn1crypto                0.24.0                   py37_0  \nastroid                   2.1.0                    py37_0  \nastropy                   3.1              py37h7b6447c_0  \natomicwrites              1.2.1                    py37_0  \nattrs                     18.2.0           py37h28b3542_0  \nbabel                     2.6.0                    py37_0  \nbackcall                  0.1.0                    py37_0  \nbackports                 1.0                      py37_1  \nbackports.os              0.1.1                    py37_0  \nbackports.shutil_get_terminal_size 1.0.0                    py37_2  \nbeautifulsoup4            4.6.3                    py37_0  \nbitarray                  0.8.3            py37h14c3975_0  \nbkcharts                  0.2                      py37_0  \nblas                      1.0                         mkl  \nblaze                     0.11.3                   py37_0  \nbleach                    3.0.2                    py37_0  \nblosc                     1.14.4               hdbcaa40_0  \nbokeh                     1.0.2                    py37_0  \nboto                      2.49.0                   py37_0  \nbottleneck                1.2.1            py37h035aef0_1  \nbzip2                     1.0.6                h14c3975_5  \nca-certificates           2020.7.22                     0    anaconda\ncairo                     1.14.12              h8948797_3  \ncertifi                   2020.6.20                py37_0    anaconda\ncffi                      1.11.5           py37he75722e_1  \nchardet                   3.0.4                    py37_1  \nclick                     7.0                      py37_0  \ncloudpickle               0.6.1                    py37_0  \nclyent                    1.2.2                    py37_1  \ncolorama                  0.4.1                    py37_0  \nconda                     4.5.12                   py37_0  \nconda-build               3.17.6                   py37_0  \nconda-env                 2.6.0                         1  \nconda-verify              3.1.1                    py37_0  \ncontextlib2               0.5.5                    py37_0  \ncryptography              2.4.2            py37h1ba5d50_0  \ncurl                      7.63.0            hbc83047_1000  \ncycler                    0.10.0                   py37_0    anaconda\ncython                    0.29.2           py37he6710b0_0  \ncytoolz                   0.9.0.1          py37h14c3975_1  \ndask                      1.0.0                    py37_0  \ndask-core                 1.0.0                    py37_0  \ndatashape                 0.5.4                    py37_1  \ndbus                      1.13.12              h746ee38_0    anaconda\ndecorator                 4.3.0                    py37_0  \ndefusedxml                0.5.0                    py37_1  \ndistributed               1.25.1                   py37_0  \ndocutils                  0.14                     py37_0  \nentrypoints               0.2.3                    py37_2  \net_xmlfile                1.0.1                    py37_0  \nexpat                     2.2.9                he6710b0_2    anaconda\nfastcache                 1.0.2            py37h14c3975_2  \nfilelock                  3.0.10                   py37_0  \nflask                     1.0.2                    py37_1  \nflask-cors                3.0.7                    py37_0  \nfontconfig                2.13.0               h9420a91_0    anaconda\nfreetype                  2.10.2               h5ab3b9f_0    anaconda\nfribidi                   1.0.5                h7b6447c_0  \nfuture                    0.17.1                   py37_0  \nget_terminal_size         1.0.0                haa9412d_0  \ngevent                    1.3.7            py37h7b6447c_1  \nglib                      2.56.2               hd408876_0    anaconda\nglob2                     0.6                      py37_1  \ngmp                       6.1.2                h6c8ec71_1  \ngmpy2                     2.0.8            py37h10f8cd9_2  \ngraphite2                 1.3.12               h23475e2_2  \ngreenlet                  0.4.15           py37h7b6447c_0  \ngst-plugins-base          1.14.0               hbbd80ab_1    anaconda\ngstreamer                 1.14.0               hb453b48_1    anaconda\nh5py                      2.8.0            py37h989c5e5_3  \nharfbuzz                  1.8.8                hffaf4a1_0  \nhdf5                      1.10.2               hba1933b_1  \nheapdict                  1.0.0                    py37_2  \nhtml5lib                  1.0.1                    py37_0  \nicu                       58.2                 he6710b0_3    anaconda\nidna                      2.8                      py37_0  \nimageio                   2.4.1                    py37_0  \nimagesize                 1.1.0                    py37_0  \nimportlib_metadata        0.6                      py37_0  \nintel-openmp              2019.1                      144  \nipykernel                 5.1.0            py37h39e3cac_0  \nipython                   7.2.0            py37h39e3cac_0  \nipython_genutils          0.2.0                    py37_0  \nipywidgets                7.4.2                    py37_0  \nisort                     4.3.4                    py37_0  \nitsdangerous              1.1.0                    py37_0  \njbig                      2.1                  hdba287a_0  \njdcal                     1.4                      py37_0  \njedi                      0.13.2                   py37_0  \njeepney                   0.4                      py37_0  \njinja2                    2.10                     py37_0  \njpeg                      9b                   habf39ab_1    anaconda\njsonschema                2.6.0                    py37_0  \njupyter                   1.0.0                    py37_7  \njupyter_client            5.2.4                    py37_0  \njupyter_console           6.0.0                    py37_0  \njupyter_core              4.4.0                    py37_0  \njupyterlab                0.35.3                   py37_0  \njupyterlab_server         0.2.0                    py37_0  \nkeyring                   17.0.0                   py37_0  \nkiwisolver                1.2.0            py37hfd86e86_0    anaconda\nkrb5                      1.16.1               h173b8e3_7  \nlazy-object-proxy         1.3.1            py37h14c3975_2  \nlcms2                     2.11                 h396b838_0    anaconda\nld_impl_linux-64          2.33.1               h53a641e_7    anaconda\nlibarchive                3.3.3                h5d8350f_5  \nlibcurl                   7.63.0            h20c2e04_1000  \nlibedit                   3.1.20191231         h14c3975_1    anaconda\nlibffi                    3.3                  he6710b0_2    anaconda\nlibgcc-ng                 9.1.0                hdf63c60_0    anaconda\nlibgfortran-ng            7.3.0                hdf63c60_0  \nliblief                   0.9.0                h7725739_1  \nlibpng                    1.6.37               hbc83047_0    anaconda\nlibsodium                 1.0.16               h1bed415_0  \nlibssh2                   1.8.0                h1ba5d50_4  \nlibstdcxx-ng              8.2.0                hdf63c60_1  \nlibtiff                   4.1.0                h2733197_1    anaconda\nlibtool                   2.4.6                h7b6447c_5  \nlibuuid                   1.0.3                h1bed415_2    anaconda\nlibxcb                    1.14                 h7b6447c_0    anaconda\nlibxml2                   2.9.10               he19cac6_1    anaconda\nlibxslt                   1.1.32               h1312cb7_0  \nllvmlite                  0.26.0           py37hd408876_0  \nlocket                    0.2.0                    py37_1  \nlxml                      4.2.5            py37hefd8a0e_0  \nlz4-c                     1.9.2                he6710b0_1    anaconda\nlzo                       2.10                 h49e0be7_2  \nmarkupsafe                1.1.0            py37h7b6447c_0  \nmatplotlib                3.3.1                         0    anaconda\nmatplotlib-base           3.3.1            py37h817c723_0    anaconda\nmccabe                    0.6.1                    py37_1  \nmistune                   0.8.4            py37h7b6447c_0  \nmkl                       2019.1                      144  \nmkl-service               1.1.2            py37he904b0f_5  \nmkl_fft                   1.0.10           py37ha843d7b_0    anaconda\nmkl_random                1.0.2            py37hd81dba3_0    anaconda\nmore-itertools            4.3.0                    py37_0  \nmpc                       1.1.0                h10f8cd9_1  \nmpfr                      4.0.1                hdf1c602_3  \nmpmath                    1.1.0                    py37_0  \nmsgpack-python            0.5.6            py37h6bb024c_1  \nmultipledispatch          0.6.0                    py37_0  \nnavigator-updater         0.2.1                    py37_0  \nnbconvert                 5.4.0                    py37_1  \nnbformat                  4.4.0                    py37_0  \nncurses                   6.2                  he6710b0_1    anaconda\nnetworkx                  2.2                      py37_1  \nnltk                      3.4                      py37_1  \nnose                      1.3.7                    py37_2  \nnotebook                  5.7.4                    py37_0  \nnumba                     0.41.0           py37h962f231_0  \nnumexpr                   2.6.8            py37h9e4a6bb_0  \nnumpy                     1.16.2           py37h7e9f1db_0    anaconda\nnumpy-base                1.16.2           py37hde5b4d6_0    anaconda\nnumpydoc                  0.8.0                    py37_0  \nodo                       0.5.1                    py37_0  \nolefile                   0.46                       py_0    anaconda\nopenpyxl                  2.5.12                   py37_0  \nopenssl                   1.1.1g               h7b6447c_0    anaconda\npackaging                 18.0                     py37_0  \npandas                    1.1.1            py37he6710b0_0    anaconda\npandoc                    1.19.2.1             hea2e7c5_1  \npandocfilters             1.4.2                    py37_1  \npango                     1.42.4               h049681c_0  \nparso                     0.3.1                    py37_0  \npartd                     0.3.9                    py37_0  \npatchelf                  0.9                  he6710b0_3  \npath.py                   11.5.0                   py37_0  \npathlib2                  2.3.3                    py37_0  \npatsy                     0.5.1                    py37_0  \npcre                      8.44                 he6710b0_0    anaconda\npep8                      1.7.1                    py37_0  \npexpect                   4.6.0                    py37_0  \npickleshare               0.7.5                    py37_0  \npillow                    7.2.0            py37hb39fc2d_0    anaconda\npip                       20.2.2                   py37_0    anaconda\npixman                    0.34.0               hceecf20_3  \npkginfo                   1.4.2                    py37_1  \npluggy                    0.8.0                    py37_0  \nply                       3.11                     py37_0  \nprometheus_client         0.5.0                    py37_0  \nprompt_toolkit            2.0.7                    py37_0  \npsutil                    5.4.8            py37h7b6447c_0  \nptyprocess                0.6.0                    py37_0  \npy                        1.7.0                    py37_0  \npy-lief                   0.9.0            py37h7725739_1  \npycodestyle               2.4.0                    py37_0  \npycosat                   0.6.3            py37h14c3975_0  \npycparser                 2.19                     py37_0  \npycrypto                  2.6.1            py37h14c3975_9  \npycurl                    7.43.0.2         py37h1ba5d50_0  \npyflakes                  2.0.0                    py37_0  \npygments                  2.3.1                    py37_0  \npylint                    2.2.2                    py37_0  \npyodbc                    4.0.25           py37he6710b0_0  \npyopenssl                 18.0.0                   py37_0  \npyparsing                 2.4.7                      py_0    anaconda\npyqt                      5.9.2            py37h22d08a2_1    anaconda\npysocks                   1.6.8                    py37_0  \npytables                  3.4.4            py37ha205bf6_0  \npytest                    4.0.2                    py37_0  \npytest-arraydiff          0.3              py37h39e3cac_0  \npytest-astropy            0.5.0                    py37_0  \npytest-doctestplus        0.2.0                    py37_0  \npytest-openfiles          0.3.1                    py37_0  \npytest-remotedata         0.3.1                    py37_0  \npython                    3.7.9                h7579374_0    anaconda\npython-dateutil           2.8.1                      py_0    anaconda\npython-libarchive-c       2.8                      py37_6  \npytz                      2020.1                     py_0    anaconda\npywavelets                1.0.1            py37hdd07704_0  \npyyaml                    3.13             py37h14c3975_0  \npyzmq                     17.1.2           py37h14c3975_0  \nqt                        5.9.7                h5867ecd_1    anaconda\nqtawesome                 0.5.3                    py37_0  \nqtconsole                 4.4.3                    py37_0  \nqtpy                      1.5.2                    py37_0  \nreadline                  8.0                  h7b6447c_0    anaconda\nrequests                  2.21.0                   py37_0  \nrope                      0.11.0                   py37_0  \nruamel_yaml               0.15.46          py37h14c3975_0  \nscikit-image              0.14.1           py37he6710b0_0  \nscikit-learn              0.20.1           py37hd81dba3_0  \nscipy                     1.2.1            py37h7c811a0_0    anaconda\nseaborn                   0.10.1                     py_0    anaconda\nsecretstorage             3.1.0                    py37_0  \nsend2trash                1.5.0                    py37_0  \nsetuptools                49.6.0                   py37_0    anaconda\nsimplegeneric             0.8.1                    py37_2  \nsingledispatch            3.4.0.3                  py37_0  \nsip                       4.19.24          py37he6710b0_0    anaconda\nsix                       1.15.0                     py_0    anaconda\nsnappy                    1.1.7                hbae5bb6_3  \nsnowballstemmer           1.2.1                    py37_0  \nsortedcollections         1.0.1                    py37_0  \nsortedcontainers          2.1.0                    py37_0  \nsphinx                    1.8.2                    py37_0  \nsphinxcontrib             1.0                      py37_1  \nsphinxcontrib-websupport  1.1.0                    py37_1  \nspyder                    3.3.2                    py37_0  \nspyder-kernels            0.3.0                    py37_0  \nsqlalchemy                1.2.15           py37h7b6447c_0  \nsqlite                    3.33.0               h62c20be_0    anaconda\nstatsmodels               0.9.0            py37h035aef0_0  \nsympy                     1.3                      py37_0  \ntblib                     1.3.2                    py37_0  \nterminado                 0.8.1                    py37_1  \ntestpath                  0.4.2                    py37_0  \ntk                        8.6.10               hbc83047_0    anaconda\ntoolz                     0.9.0                    py37_0  \ntornado                   6.0.4            py37h7b6447c_1    anaconda\ntqdm                      4.28.1           py37h28b3542_0  \ntraitlets                 4.3.2                    py37_0  \nunicodecsv                0.14.1                   py37_0  \nunixodbc                  2.3.7                h14c3975_0  \nurllib3                   1.24.1                   py37_0  \nwcwidth                   0.1.7                    py37_0  \nwebencodings              0.5.1                    py37_1  \nwerkzeug                  0.14.1                   py37_0  \nwheel                     0.35.1                     py_0    anaconda\nwidgetsnbextension        3.4.2                    py37_0  \nwrapt                     1.10.11          py37h14c3975_2  \nwurlitzer                 1.0.2                    py37_0  \nxlrd                      1.2.0                    py37_0  \nxlsxwriter                1.1.2                    py37_0  \nxlwt                      1.3.0                    py37_0  \nxz                        5.2.5                h7b6447c_0    anaconda\nyaml                      0.1.7                had09818_2  \nzeromq                    4.2.5                hf484d3e_1  \nzict                      0.1.3                    py37_0  \nzlib                      1.2.11               h7b6447c_3    anaconda\nzstd                      1.4.4                h0b5b093_3    anaconda\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-07 00:52:41.223 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-10-22 16:57:23.29 UTC",
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1167,
        "Owner_creation_date":"2009-06-23 03:11:55.29 UTC",
        "Owner_last_access_date":"2022-09-25 03:45:28.337 UTC",
        "Owner_reputation":77230,
        "Owner_up_votes":2724,
        "Owner_down_votes":43,
        "Owner_views":6359,
        "Answer_body":"<p>I just did the following and wasn't able to reproduce your error:<\/p>\n<ol>\n<li>make a new compute instance<\/li>\n<li>open it up using JupyterLab<\/li>\n<li>open a new terminal<\/li>\n<li><code>conda activate azureml_py36<\/code><\/li>\n<li><code>conda install seaborn -y<\/code><\/li>\n<li>open a new notebook and run <code>import seaborn as sns<\/code><\/li>\n<\/ol>\n<h3>Spitballing<\/h3>\n<ol>\n<li>Are you using the kernel, <code>Python 3.6 - AzureML<\/code> (i.e. the <code>azureml_py36<\/code> conda env)?<\/li>\n<li>Have you tried restarting the kernel and\/or creating a new compute instance?<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/kPbLH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kPbLH.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-09-07 04:17:19.417 UTC",
        "Answer_score":2.0,
        "Owner_location":"Cumming, GA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63770171",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70985091,
        "Question_title":"Time difference reading files from Blob-Storage-Container",
        "Question_body":"<p>We are using <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/storage-how-to-mount-container-linux\" rel=\"nofollow noreferrer\">Blobfuse<\/a> for &quot;mounting&quot; our blob-storage-container to an Azure virtual machine as well as to Azure ML Studio.<br>In our blob-storage-container there are around 400 files each about 1.5MB\n<br>\n<br>\nWith the Azure VM, the algorithm needs 45 seconds to read all files.<br>\nWith Azure ML Studio, the <strong>same<\/strong> algorithm needs 5 minutes to read all files.\n<br>\n<br>\nThe Azure VM resource as well as the Azure ML Studio resource are in the same tenant.<br>\nThese resources use two different computes but have the <strong>same<\/strong> specifications.\n<br>\n<br>\nWhy does it take so much longer to read all the files when using Azure ML Studio compared to Azure VM?<br>\nIs it possible to reduce the time needed for reading all files when using Azure ML Studio without changing the storage file hierarchy in any way?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-04 10:46:04.24 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-blob-storage|azure-virtual-machine|mount|azure-machine-learning-studio",
        "Question_view_count":190,
        "Owner_creation_date":"2021-09-29 07:06:53.153 UTC",
        "Owner_last_access_date":"2022-09-23 08:06:23.973 UTC",
        "Owner_reputation":139,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70985091",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67255397,
        "Question_title":"What is real-time inference pipeline?",
        "Question_body":"<p>From Azure Machine Learning designer, to deploy a real-time inference pipeline as a service for others to consume, you must deploy the model to an Azure Kubernetes Service (AKS).\nWhat is real-time inference pipeline ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-25 15:56:05.967 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":211,
        "Owner_creation_date":"2021-01-15 12:54:54.93 UTC",
        "Owner_last_access_date":"2022-04-03 14:59:06.363 UTC",
        "Owner_reputation":306,
        "Owner_up_votes":200,
        "Owner_down_votes":2,
        "Owner_views":53,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67255397",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71185505,
        "Question_title":"XGBClassifer, when de-serialized, gives 'XGBModel' object has no attribute 'enable_categorical'",
        "Question_body":"<p>I have a serialized XGBClassifier object, trained and generated using xgboost=1.5.2.<\/p>\n<pre><code>XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.5,\n              colsample_bynode=1, colsample_bytree=0.30140958911801474,\n              eval_metric='logloss', gamma=0.1203484640861413, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_bin=368, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=6, num_parallel_tree=1, random_state=42,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n              single_precision_histogram=True, subsample=0.976171515775659,\n              tree_method='gpu_hist', use_label_encoder=False,\n              validate_parameters=1, verbosity=None)\n<\/code><\/pre>\n<p>I load the object using:<\/p>\n<pre><code>clf_model = joblib.load(model_path)\n<\/code><\/pre>\n<p>I want to use the object to predict on some data I am using Azure environment which also has xgboost=1.5.2. but it gives error:<\/p>\n<pre><code>File &quot;score.py&quot;, line 78, in score_execution\n[stderr]    clf_preds = clf_model.predict(clf_data_transformed)\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 1284, in predict\n[stderr]    class_probs = super().predict(\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 879, in predict\n[stderr]    if self._can_use_inplace_predict():\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 811, in _can_use_inplace_predict\n[stderr]    predictor = self.get_params().get(&quot;predictor&quot;, None)\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 505, in get_params\n[stderr]    params.update(cp.__class__.get_params(cp, deep))\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/xgboost\/sklearn.py&quot;, line 502, in get_params\n[stderr]    params = super().get_params(deep)\n[stderr]  File &quot;\/opt\/miniconda\/lib\/python3.8\/site-packages\/sklearn\/base.py&quot;, line 210, in get_params\n[stderr]    value = getattr(self, key)\n[stderr]AttributeError: 'XGBModel' object has no attribute 'enable_categorical'\n<\/code><\/pre>\n<p>We have same version in pipelines that produce\/serialize the model and in the pipeline that deserialize the model to predict on new data.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-19 13:36:38.68 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":358,
        "Owner_creation_date":"2015-09-23 14:11:04.707 UTC",
        "Owner_last_access_date":"2022-09-23 08:54:35.743 UTC",
        "Owner_reputation":644,
        "Owner_up_votes":33,
        "Owner_down_votes":1,
        "Owner_views":126,
        "Answer_body":"<p>Here are some possible solutions :<\/p>\n<ul>\n<li>Save the model in some other way, e.g. the JSON specified here <a href=\"https:\/\/xgboost.readthedocs.io\/en\/latest\/tutorials\/saving_model.html\" rel=\"nofollow noreferrer\">https:\/\/xgboost.readthedocs.io\/en\/latest\/tutorials\/saving_model.html<\/a><\/li>\n<li>Limit the allowed range of xgboost versions to those that are known to work with our model. This could lead to issues in the future, for example if the aging version of xgboost we require is no longer supported by newer versions of Python.<\/li>\n<li>Using <code>save_model<\/code> to save in JSON is worth a shot to try.<\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-02-21 07:06:52.643 UTC",
        "Answer_score":0.0,
        "Owner_location":"Sweden",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71185505",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46450439,
        "Question_title":"Installing additional R package (ImputeTS R Package) in Azure ML",
        "Question_body":"<p>I referred the below stack overflow query regarding installing additional R package in Azure ML. However I'am getting the error <\/p>\n\n<p>Trail 1 : Installing miniCRAN package for windows (<a href=\"https:\/\/cran.r-project.org\/web\/packages\/imputeTS\/index.html\" rel=\"nofollow noreferrer\">https:\/\/cran.r-project.org\/web\/packages\/imputeTS\/index.html<\/a>)<\/p>\n\n<p>Trail 2:  Installing ImputeTS package for windows (<a href=\"https:\/\/cran.r-project.org\/web\/packages\/miniCRAN\/index.html\" rel=\"nofollow noreferrer\">https:\/\/cran.r-project.org\/web\/packages\/miniCRAN\/index.html<\/a>)<\/p>\n\n<p><strong>I double zipped and tried as per the below stack overflow query question. But, still facing the same issue<\/strong><\/p>\n\n<p>R version i'm using : <code>CRAN 3.1.0<\/code><\/p>\n\n<p>I need to use the <code>package ImputeTS.<\/code><\/p>\n\n<p><strong>Stack overflow query link :<\/strong>\n<a href=\"https:\/\/stackoverflow.com\/questions\/27568624\/installing-additional-r-package-on-azure-ml\">Installing additional R Package on Azure ML<\/a><\/p>\n\n<p><strong>Error 1:<\/strong> <\/p>\n\n<pre><code>    Error 0063: The following error occurred during evaluation of R script:\n\n    ---------- Start of error message from R ----------\n\n    zip file 'src\/miniCRAN.zip' not found\n<\/code><\/pre>\n\n<p><strong>Error 2:<\/strong> <\/p>\n\n<pre><code>     Error 0063: The following error occurred during evaluation of R script:\n\n     ---------- Start of error message from R ----------\n\n     zip file 'src\/imputeTS.zip' not found\n<\/code><\/pre>\n\n<p><strong>R script :<\/strong><\/p>\n\n<pre><code>JCI_CO2  &lt;- maml.mapInputPort(1)\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(lubridate)\n\n#install.packages(\"src\/imputeTS.zip\", lib = \".\", repos = NULL, verbose = TRUE)\n#(success &lt;- library(\"imputeTS\", lib.loc = \".\", logical.return = TRUE, verbose = TRUE))\n\n #library(imputeTS)\n #library(imputeTS,lib.loc = \".\")\n\n\ninstall.packages(\"src\/miniCRAN.zip\", lib = \".\", repos = NULL, verbose = TRUE)\n(success &lt;- library(\"miniCRAN\", lib.loc = \".\", logical.return = TRUE, verbose = TRUE))\n\nlibrary(miniCRAN)\nlibrary(miniCRAN,lib.loc = \".\")\n\nlibrary(imputeTS)\n\ndt2 &lt;- JCI_CO2 %&gt;%\n  mutate(Date.Time = mdy_hm(Date.Time)) %&gt;%\n  filter(Date.Time %in% seq(min(Date.Time), max(Date.Time), by = \"15 min\")) %&gt;%\n  complete(Date.Time = seq(min(Date.Time), max(Date.Time), by = \"15 min\")) %&gt;%\n  mutate(RA.CO2 = na.interpolation(RA.CO2)) %&gt;%\n  arrange(desc(Date.Time))\n\n\n  JCI_CO2 &lt;- data.frame(dt2)\n\n  maml.mapOutputPort(\"JCI_CO2\");\n<\/code><\/pre>\n\n<p><strong>Note :<\/strong> <em>All the rest of the packages in the code i.e dplyr, tidyr, lubridate are already part of the azure ml R package. <strong>Except ImputeTS which i am trying to install.<\/em><\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-09-27 14:26:00.287 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-01-21 16:15:03.19 UTC",
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-studio|imputets",
        "Question_view_count":797,
        "Owner_creation_date":"2016-11-15 07:23:47.133 UTC",
        "Owner_last_access_date":"2018-07-12 09:45:50.387 UTC",
        "Owner_reputation":2713,
        "Owner_up_votes":26,
        "Owner_down_votes":2,
        "Owner_views":358,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46450439",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52898555,
        "Question_title":"Azure Machine Learning Studio, Python script input format",
        "Question_body":"<p>I am execute a python script in Azure ML studio. The python script will take a single string input, process the string and then return the processed result.<\/p>\n\n<p>I am using \"Enter Data Manually\" as input(connect to \"Dataset1\" on \"Execute Python Script\" module), and the input format is CSV. This input is also my \"Web Service Input\". So, in the python script, I will get the input text like following,<\/p>\n\n<pre><code>         input_text = dataframe1.iat[0, 0]\n<\/code><\/pre>\n\n<p>But, I found that I have to enter the text start from the 2nd row, like the follow picture. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/y6SUS.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/y6SUS.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>If I put the text in the first row, then the python script won't execute. From the error message, seems its' index out of bound error. But I did put data at the first row and first column, the only column. Why I still get this error? I am not very clear on the input scheme. Can someone explain? Thanks.<\/p>\n\n<pre><code>[Error]         Caught exception while executing function: Traceback (most recent call last):\n[Error]           File \"C:\\server\\invokepy.py\", line 199, in batch\n[Error]             odfs = mod.azureml_main(*idfs)\n[Error]           File \"C:\\temp\\b792c87679e1424fb3300c65b0231c07.py\", line 43, in azureml_main\n[Error]             input_text = dataframe1.iat[0, 0]\n[Error]           File \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1610, in __getitem__\n[Error]             return self.obj.get_value(*key, takeable=self._takeable)\n[Information]         theano\/typed_list\/type.py                      2016-09-06 14:31:24         3870\n[Information]         theano\/typed_list\/type.pyc                     2016-09-06 14:31:26         6025\n[Information]         theano\/typed_list\/__init__.py                  2016-09-06 14:31:24           71\n[Information]         theano\/typed_list\/__init__.pyc                 2016-09-06 14:31:26          287\n[Information]         theano\/updates.py                              2016-09-06 14:31:24         3405\n[Information]         theano\/updates.pyc                             2016-09-06 14:31:26         3317\n[Information]         theano\/version.py                              2016-09-06 14:31:24          208\n[Information]         theano\/version.pyc                             2016-09-06 14:31:26          380\n[Information]         theano\/__init__.py                             2016-09-06 14:31:24         6675\n[Information]         theano\/__init__.pyc                            2016-09-06 14:31:26         6689\n[Information]         [ READING ] 0:00:00\n[Information]         Input pandas.DataFrame #1:\n[Information]         Empty DataFrame\n[Information]         Columns: [Text start from here.]\n[Information]         Index: []\n[Error]           File \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\frame.py\", line 1832, in get_value\n[Error]             return _maybe_box_datetimelike(series._values[index])\n[Error]         IndexError: index 0 is out of bounds for axis 0 with size 0\n[Error]         Process returned with non-zero exit code 1\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2018-10-19 19:07:57.973 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|csv|azure-machine-learning-studio",
        "Question_view_count":145,
        "Owner_creation_date":"2012-05-18 17:27:03.537 UTC",
        "Owner_last_access_date":"2022-09-23 21:14:32.923 UTC",
        "Owner_reputation":581,
        "Owner_up_votes":51,
        "Owner_down_votes":0,
        "Owner_views":49,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52898555",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37418265,
        "Question_title":"Azure Machine Learning using Javascript Ajax call",
        "Question_body":"<p>I wanted to know if there is a way to call the Azure Machine Learning webservice using JavaScript Ajax.<\/p>\n\n<p>The Azure ML gives sample code for C#, Python and R.<\/p>\n\n<p>I did try out to call the webservice using JQuery Ajax but it returns a failure.<\/p>\n\n<p>I am able to call the same service using a python script.<\/p>\n\n<p>Here is my Ajax code : <\/p>\n\n<pre><code>  $.ajax({\n        url: webserviceurl,\n        type: \"POST\",           \n        data: sampleData,            \n        dataType:'jsonp',                        \n        headers: {\n        \"Content-Type\":\"application\/json\",            \n        \"Authorization\":\"Bearer \" + apiKey                       \n        },\n        success: function (data) {\n          console.log('Success');\n        },\n        error: function (data) {\n           console.log('Failure ' +  data.statusText + \" \" + data.status);\n        },\n  });\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_date":"2016-05-24 15:45:29.493 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2018-05-11 14:09:52.277 UTC",
        "Question_score":2,
        "Question_tags":"javascript|ajax|azure|azure-machine-learning-studio",
        "Question_view_count":1607,
        "Owner_creation_date":"2016-04-14 20:13:43.627 UTC",
        "Owner_last_access_date":"2017-09-07 19:59:44.707 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>Well after a lot of RnD, I was able to finally call Azure ML using some workarounds.<\/p>\n\n<p>Wrapping Azure ML webservice on Azure API is one option.<\/p>\n\n<p>But, what I did was that I created a python webservice which calls the Azure webservice.<\/p>\n\n<p>So now my HTML App calls the python webservice which calls Azure ML and returns data to the HTML App.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-05-31 18:10:10.4 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37418265",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47908925,
        "Question_title":"RPackage library exception (error 1000)",
        "Question_body":"<p>I have the following code in an Execute R Module.<\/p>\n\n<hr>\n\n<pre><code># Input\ndata1 &lt;- maml.mapInputPort(1) # Qualitative with 8 variables\n\ninstall.packages(\"src\/graphics.zip\", lib.loc = \".\", repos = NULL, verbose = \nTRUE)\ninstall.packages(\"src\/grDevices.zip\", lib.loc = \".\", repos = NULL, verbose = \nTRUE)\ninstall.packages(\"src\/stats.zip\", lib.loc = \".\", repos = NULL, verbose = \nTRUE)\ninstall.packages(\"src\/utils.zip\", lib.loc = \".\", repos = NULL, verbose = \nTRUE)\ninstall.packages(\"src\/MASS.zip\", lib.loc = \".\", repos = NULL, verbose = \nTRUE)\nsuccess &lt;- library(\"MASS\", lib.loc = \".\", logical.return = TRUE, verbose = \nTRUE)\nlibrary(MASS)\n\nmca &lt;- mca(data1, nf = 10)\n\nmca1 &lt;- data.frame(mca$rs)\n\n# Output\nmaml.mapOutputPort(\"mca1\");\n<\/code><\/pre>\n\n<hr>\n\n<p>When I execute I am getting the following error:<\/p>\n\n<p>RPackage library exception: Attempting to obtain R output before invoking execution process. (Error 1000)<\/p>\n\n<p>But it is working fine in RStudio.<\/p>\n\n<p>I also have a node that does the same process and it works without errors. I have executed it several times, sometimes it has worked for me and then it has returned error.<\/p>\n\n<p>Please let me know what the issue is.<\/p>\n\n<p>With regards,<\/p>\n\n<p>Celia<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2017-12-20 15:03:35.72 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":255,
        "Owner_creation_date":"2017-12-20 14:56:57.75 UTC",
        "Owner_last_access_date":"2017-12-20 14:56:57.75 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47908925",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62189103,
        "Question_title":"Azure ML Compute Instance: How can I safely upgrade the default Azure Ubuntu 16.04 LTS to the latest LTS?",
        "Question_body":"<p>I want to upgrade the default Ubuntu version that comes with the Compute Instance in Azure ML.<\/p>\n\n<p>Anyone has any guide on safely upgrading to the latest LTS?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-04 07:30:49.48 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|ubuntu|azure-machine-learning-service",
        "Question_view_count":312,
        "Owner_creation_date":"2015-12-08 02:47:47.717 UTC",
        "Owner_last_access_date":"2022-05-17 06:44:21.4 UTC",
        "Owner_reputation":1302,
        "Owner_up_votes":115,
        "Owner_down_votes":1,
        "Owner_views":157,
        "Answer_body":"<p>Any specific reason you want to do this?<\/p>\n\n<p>Since there are some heavy dependencies (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#contents\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#contents<\/a>), my guess is you have to try it yourself.<\/p>\n\n<p>Create a new one and run:<\/p>\n\n<pre><code>$ sudo apt update \n$ sudo apt upgrade\n$ sudo apt dist-upgrade\n<\/code><\/pre>\n\n<p>Let us know what happened.<\/p>\n\n<p>BTW: Are Compute Instance also Docker images? If so, the upgrade might be working, if not, there might be many drivers that need to be upgraded too. The ones from the GPU would be the easiest...<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-06-07 12:02:00.41 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62189103",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69906308,
        "Question_title":"my Azure ML api rest return an empty object",
        "Question_body":"<p><strong>My issue<\/strong><\/p>\n<p>I try using REST API for machine learning. The following PowerShell doesn't fail, but return an empty objet, whatever the API I am testing.\nmy SPN has contributor permission, I made grant consent and I checked I get a token.<\/p>\n<p>the doc I was using:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/fr-fr\/rest\/api\/azureml\/quotas\/list\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/fr-fr\/rest\/api\/azureml\/quotas\/list<\/a><\/p>\n<p>I tested several other GET API as well.<\/p>\n<p>I don't know what to do more. Any idea?<\/p>\n<p><strong>My Powershell code<\/strong><\/p>\n<pre><code>$tenant_id = &quot;XXXXXXXXXXXXXXXXXXX&quot;\n$ApplicationId = &quot;XXXXXXXXXXXXXXX&quot;\n$spn_client_secret = &quot;XXXXXXXXXXXXX&quot;\n$subscriptionid=&quot;XXXXXXXXXXXX&quot;\n$uri = &quot;https:\/\/login.microsoftonline.com\/$tenant_id\/oauth2\/token&quot;\n\n$BodyText = &quot;grant_type=client_credentials&amp;client_id=$ApplicationId&amp;resource=https:\/\/management.azure.com&amp;client_secret=$spn_client_secret&quot;\n\n# GET TOKEN\n$Response = Invoke-RestMethod -Method POST -Body $BodyText -Uri $URI -ContentType application\/x-www-form-urlencoded        \n$aad_access_token = $Response.access_token\n\n# tested, I effectively have a token\n\n# READ ml\n\n$urllist = &quot;https:\/\/management.azure.com\/subscriptions\/$subscriptionid\/providers\/Microsoft.MachineLearningServices\/locations\/westeurope\/quotas?api-version=2021-03-01-preview&quot;\n\n$headers = @{&quot;Authorization&quot; = &quot;Bearer &quot; + $aad_access_token}\n\nInvoke-RestMethod -Method GET -HEADERS $headers -Uri $urllist -ContentType application\/x-www-form-urlencoded  \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-09 23:29:10.737 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|oauth-2.0|azure-machine-learning-service",
        "Question_view_count":81,
        "Owner_creation_date":"2013-11-16 22:05:12.687 UTC",
        "Owner_last_access_date":"2022-09-24 17:30:05.067 UTC",
        "Owner_reputation":511,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":158,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69906308",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73193412,
        "Question_title":"Azure Machine Learning Compute Instance Not Creating using Azure CLI and Azure DevOps Pipeline",
        "Question_body":"<p>I create my Azure Machine Learning Workspace using Azure CLI:<\/p>\n<pre><code>$env=&quot;prd&quot;\n$instance=&quot;001&quot;\n$location=&quot;uksouth&quot;\n$suffix=&quot;predict-$env-$location-$instance&quot;\n\n$rg=&quot;rg-$suffix&quot;\n$ws=&quot;mlw-$suffix&quot;\n$computeinstance=&quot;vm-$suffix&quot;.Replace('-','')\n$computeinstance\naz group create --name $rg --location $location\naz configure --defaults group=$rg\naz ml workspace create --name $ws\naz configure --defaults workspace=$ws\naz ml compute create --name $computeinstance --size Standard_DS11_v2 --type ComputeInstance\n<\/code><\/pre>\n<p>I run the above code manually in Visual Studio Code, and everything works properly.<\/p>\n<p>However, when I integrate the above into an Azure DevOps pipeline via the YAML:<\/p>\n<pre><code>steps:\n - bash: az extension add -n ml\n    displayName: 'Install Azure ml extension'\n - task: AzureCLI@2\n    inputs:\n      azureSubscription: &quot;$(AZURE_RM_SVC_CONNECTION)&quot;\n      scriptType: 'ps'\n      scriptLocation: 'scriptPath'\n      scriptPath: '.\/environment_setup\/aml-cli.ps1'\n<\/code><\/pre>\n<ul>\n<li>The pipeline creates the Azure Machine Learning workspace as expected.<\/li>\n<li>The pipeline creates the compute instance, which has the status <strong>&quot;Running&quot;<\/strong> and green status.<\/li>\n<li>However, the compute instance has all applications <strong>greyed out<\/strong>. This means I cannot connect to the compute instance using a terminal, notebook or otherwise, essentially making it useless. The application links in the following screenshot are not clickable:<\/li>\n<\/ul>\n<p><a href=\"https:\/\/i.stack.imgur.com\/OUzpx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/OUzpx.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I attempted:<\/p>\n<ul>\n<li>Specifying brand new resource names.<\/li>\n<li>Creating the workspace and compute in separate pipelines in case of a timing issue.<\/li>\n<li>Deleting the resource group first using:<\/li>\n<\/ul>\n<pre><code>az group delete -n rg-predict-prd-uksouth-001 --force-deletion-types Microsoft.Compute\/virtualMachines --yes\n<\/code><\/pre>\n<p>All to no avail.<\/p>\n<p>How do I create a useable Azure Machine Learning compute instance using Azure CLI and Azure DevOps pipelines?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-01 12:07:07.063 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2022-08-01 12:17:25.777 UTC",
        "Question_score":0,
        "Question_tags":"yaml|continuous-integration|azure-pipelines|azure-machine-learning-service",
        "Question_view_count":105,
        "Owner_creation_date":"2008-09-07 20:25:12.6 UTC",
        "Owner_last_access_date":"2022-09-08 13:05:19.957 UTC",
        "Owner_reputation":1462,
        "Owner_up_votes":65,
        "Owner_down_votes":6,
        "Owner_views":285,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Wales, United Kingdom",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73193412",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":43278593,
        "Question_title":"evaluating linear regression (in microsoft machine learning",
        "Question_body":"<p>Im playing with linear regression in azure machine learning and evaluating a model. <\/p>\n\n<p>Im still a bit unsure what the various metrics for evaluation mean and show, so would appreciate some correction if i am incorrect.<\/p>\n\n<ol>\n<li><strong>Mean Absolute Error:<\/strong> Mean of the residuals (errors).<\/li>\n<li><strong>Root Mean Squared Error:<\/strong> Std Dev of the residuals. With this i can see how far from the mean\/median my absolute error is.<\/li>\n<li><strong>Relative absolute error<\/strong>: a percentage value that shows the percentage difference between relative error and absolute error. lower values are better, indicating lower difference.<\/li>\n<li><strong>relative squared error:<\/strong> square of the error relative to the square of the absolute. Unsure what this gives me over the relative absolute error.<\/li>\n<li><strong>coefficient of determination:<\/strong> indication of correlation between inputs. +1 or -1 indicate perfect correlation, 0 indicates none.<\/li>\n<li>The histogram is showing the frequency of various buckets of error magnitudes. this shows a lot of small errors. with frequency decreasing as the value of error increases, indicating, when taken along with the poor metrics above that there are probably some sku or outliers having a large influence on the model, making it less accurate.<\/li>\n<\/ol>\n\n<p>Are these definitions and assumptions correct?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/dJqJr.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/dJqJr.jpg\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-04-07 12:47:29.22 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-04-07 13:20:06.763 UTC",
        "Question_score":0,
        "Question_tags":"r|machine-learning|statistics|azure-machine-learning-studio",
        "Question_view_count":289,
        "Owner_creation_date":"2015-11-16 13:58:07.793 UTC",
        "Owner_last_access_date":"2018-11-15 18:44:42.427 UTC",
        "Owner_reputation":194,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":44,
        "Answer_body":"<p>You are almost correct on most points. To make sure we are talking in the same terms, a little bit of background:<\/p>\n\n<p>A linear regression uses data on some outcome variable <code>y<\/code> and independent variables <code>x1, x2, ..<\/code> and tries to find the linear combination of <code>x1, x2, ..<\/code> that best predicts <code>y<\/code>. Once this \"best linear combination\" is established, you can assess the quality of the fit (i.e. quality of the model) in multiple ways. The six points you mention are all key metrics for the quality of a regression equation. <\/p>\n\n<p>Running a regression gives you multiple \"ingredients\". For example, every observation will get a <em>predicted value<\/em> for the outcome variable. The difference between the observed value of <code>y<\/code> and the predicted value is called the residual or error. Residuals can be negative (if the <code>y<\/code> is overestimated) and positive (if <code>y<\/code> is underestimated). The closer the residuals are to zero, the better. But, what is \"close\"? The metrics you present are supposed to give an insight in this.<\/p>\n\n<ul>\n<li><strong>Mean absolute error<\/strong>: takes the <em>absolute value<\/em>  of the residuals and takes the mean of that. <\/li>\n<li><strong>Root Mean Square Error<\/strong>: is the standard deviation of your residuals. This will help you see, how large the <em>spread<\/em>  is of your residuals. The residuals are squared and therefore, high residuals will count in more than small residuals. A low RMSE is good. <\/li>\n<li><p><strong>Relative Absolute Error<\/strong>: The absolute error as a fraction of the real value of the outcome variable <code>y<\/code>. In your case, the predictions are on average 75% higher\/lower than the actual value of <code>y<\/code>.<\/p><\/li>\n<li><p><strong>Relative Squared Error<\/strong>: The squared error (<code>residual^2<\/code>) as a fraction of the real value. <\/p><\/li>\n<li><strong>Coefficient of Determination<\/strong>: Almost correct. This ranges between 0 and 1 and can be interpreted as the explanatory power of the independent variables in explaining <code>y<\/code>. In fact, in your case the independent variables can model 38,15% of the variation in <code>y<\/code>.  Also, if you have only one independent variable, this coefficient is equal to the squared correlation coefficient. <\/li>\n<\/ul>\n\n<p>Root Mean Squared Error and Coefficient of Determination are the most important metrics in nearly all situations. To be honest, I've never really seen the other metrics being reported.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-04-07 14:37:48.1 UTC",
        "Answer_score":1.0,
        "Owner_location":"Nairobi, Kenya",
        "Answer_last_edit_date":"2017-04-07 14:45:06.82 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/43278593",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72700460,
        "Question_title":"streamlit not running from Azure ML 20.108.222.62 took too long to respond python",
        "Question_body":"<p>I have a very lightweight streamlit app and am using Azure ML to try and run it. My app looks as such:<\/p>\n<pre><code>import pandas as pd\nimport streamlit as st\nimport plotly.express as px\n\n@st.cache\ndef get_data():\n    url = &quot;http:\/\/data.insideairbnb.com\/united-states\/ny\/new-york-city\/2019-09-12\/visualisations\/listings.csv&quot;\n    return pd.read_csv(url)\ndf = get_data()\n\nst.title(&quot;Streamlit 101: An in-depth introduction&quot;)\nst.markdown(&quot;Welcome to this in-depth introduction to [...].&quot;)\nst.header(&quot;Customary quote&quot;)\nst.markdown(&quot;&gt; I just love to go home, no matter where I am [...]&quot;)\n\nst.dataframe(df.head())\n\ncols = [&quot;name&quot;, &quot;host_name&quot;, &quot;neighbourhood&quot;, &quot;room_type&quot;, &quot;price&quot;]\nst_ms = st.multiselect(&quot;Columns&quot;, df.columns.tolist(), default=cols)\n\nst.table(df.groupby(&quot;room_type&quot;).price.mean().reset_index().round(2).sort_values(&quot;price&quot;, ascending=False).assign(avg_price=lambda x: x.pop(&quot;price&quot;).apply(lambda y: &quot;%.2f&quot; % y)))\n<\/code><\/pre>\n<p>However when trying to run the app using <code>streamlit run app.py<\/code>, nothing happens and I get <code>20.108.222.62 took too long to respond.<\/code><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/CqeeH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/CqeeH.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Does anyone know why this is? Thanks<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-06-21 12:03:56.563 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|pandas|streamlit|azure-machine-learning-service",
        "Question_view_count":58,
        "Owner_creation_date":"2018-10-29 10:21:00.91 UTC",
        "Owner_last_access_date":"2022-09-23 13:19:48.58 UTC",
        "Owner_reputation":1221,
        "Owner_up_votes":117,
        "Owner_down_votes":26,
        "Owner_views":187,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72700460",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71013850,
        "Question_title":"Azure ML File Dataset mount() is slow & downloads data twice",
        "Question_body":"<p>I have created a Fie Dataset using Azure ML python API. Data under question is bunch of parquet files (~10K parquet files each of size of 330 KB) residing in Azure Data Lake Gen 2 spread across multiple partitions. Then, I tried to mount the dataset in AML compute instance. During this mounting process, I have observed that each parquet file has been downloaded twice under the \/tmp directory of the compute instance with the following message printed as the console logs:<\/p>\n<pre><code>Downloaded path: \/tmp\/tmp_3qwqu9u\/c2c69fd1-9ded-4d69-b75a-c19e1694b7aa\/&lt;blob_path&gt;\/20211203.parquet is different from target path: \/tmp\/tmp_3qwqu9u\/c2c69fd1-9ded-4d69-b75a-c19e1694b7aa\/&lt;container_name&gt;\/&lt;blob_path&gt;\/20211203.parquet\n<\/code><\/pre>\n<p>This log message gets printed for each parquet file which is part of the dataset.<\/p>\n<p>Also, the process of mounting the dataset is very slow: 44 minutes for for ~10K parquet files each of size of 330 KB.<\/p>\n<p>&quot;%%time&quot; command in the Jupyter Lab shows most of the time has been used for IO process?<\/p>\n<pre><code>CPU times: user 4min 22s, sys: 51.5 s, total: 5min 13s\nWall time: 44min 15s\n<\/code><\/pre>\n<p>Note: Both the Data Lake Gen 2 and Azure ML compute instance are under the same virtual network.<\/p>\n<p><strong>Here are my questions:<\/strong><\/p>\n<ol>\n<li><strong>How to avoid downloading the parquet file twice?<\/strong><\/li>\n<li><strong>How to make the mounting process faster?<\/strong><\/li>\n<\/ol>\n<p>I have gone through <a href=\"https:\/\/stackoverflow.com\/questions\/68556675\/azureml-dataset-file-from-files-creation-extremely-slow-even-with-4-files\">this thread<\/a>, but the discussion there didn't conclude<\/p>\n<p>The Python code I have used is as followed:<\/p>\n<pre><code>data = Dataset.File.from_files(path=list_of_blobs, validate=True)\ndataset = data.register(workspace=ws, name=dataset_name, create_new_version=create_new_version)\nmount_context = None\ntry:\n    mount_context = dataset.mount(path_to_mount)\n    # Mount the file stream\n    mount_context.start()\nexcept Exception as ex:\n    raise(ex)\n\ndf = pd.read_parquet(path_to_mount)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-07 05:18:51.203 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-09 07:15:25.88 UTC",
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":559,
        "Owner_creation_date":"2010-07-30 15:52:19.753 UTC",
        "Owner_last_access_date":"2022-09-23 12:22:17.867 UTC",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bangalore, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71013850",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63383400,
        "Question_title":"ERROR: Cannot uninstall 'ruamel-yaml' while creating docker image for azure ML ACI deployment",
        "Question_body":"<p><strong>I am trying to deploy machine learning model in azure ACI but i am getting following error while creating a docker image<\/strong><\/p>\n<pre><code>Pip subprocess error:\nERROR: Cannot uninstall 'ruamel-yaml'. It is a distutils installed project and thus we cannot \naccurately determine which files belong to it which would lead to only a partial uninstall.\n<\/code><\/pre>\n<p>Below is my yml file for pip dependencies<\/p>\n<pre><code>name: project_environment\ndependencies:\n# The python interpreter version.\n\n# Currently Azure ML only supports 3.5.2 and later.\n\n\n- pip:\n  # Required packages for AzureML execution, history, and data preparation.\n  - pandas\n  - azureml-defaults\n  - azureml-sdk\n  - azureml-widgets\n  - numpy\n  - tensorflow-gpu\n  - keras\n  - azureml-defaults\n  - torch==1.4.0\n  - scikit-learn==0.22.2.post1\n<\/code><\/pre>\n<p>and if i use conda instead of pip then i am getting following error<\/p>\n<pre><code>Step 11\/13 : RUN CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; if [ -n \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; ]; then conda env update -p \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; -f '\/var\/azureml-app\/binary_2.yml'; else \nconda env update -n base -f '\/var\/azureml-app\/binary_2.yml'; fi &amp;&amp; conda \nclean -aqy &amp;&amp; rm -rf \/root\/.cache\/pip &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; \nfind &quot;$CONDA_ROOT_DIR&quot; -type d -name __pycache__ -exec rm -rf {} +\n---&gt; Running in 9e6eb7278bfc  \n[91mUnable to install package for Conda.\n\nPlease double check and ensure you dependencies file has\nthe correct spelling.  You might also try installing the\nconda-env-Conda package to see if provides the required\ninstaller. \n[0mThe command '\/bin\/sh -c CONDA_ROOT_DIR=$(conda info --root) &amp;&amp; if [ -n \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; ]; then conda env update -p \n&quot;$AZUREML_CONDA_ENVIRONMENT_PATH&quot; -f '\/var\/azureml-app\/binary_2.yml'; else \n conda env update -n base -f '\/var\/azureml-app\/binary_2.yml'; fi &amp;&amp; conda \nclean \n-aqy &amp;&amp; rm -rf \/root\/.cache\/pip &amp;&amp; rm -rf &quot;$CONDA_ROOT_DIR\/pkgs&quot; &amp;&amp; find \n&quot;$CONDA_ROOT_DIR&quot; -type d -name __pycache__ -exec rm -rf {} +' returned a \nnon- \n zero code: 255\n 2020\/08\/12 19:36:09 Container failed during run: acb_step_0. No retries \n remaining.\n failed to run step ID: acb_step_0: exit status 255\n<\/code><\/pre>\n<p>**Can anyone please help me **<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":6,
        "Question_creation_date":"2020-08-12 19:19:19.573 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-08-12 19:48:49.537 UTC",
        "Question_score":9,
        "Question_tags":"python|azure|docker|machine-learning|azure-machine-learning-service",
        "Question_view_count":9743,
        "Owner_creation_date":"2015-03-14 04:45:18.63 UTC",
        "Owner_last_access_date":"2022-02-14 04:44:37.81 UTC",
        "Owner_reputation":179,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":44,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63383400",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48821417,
        "Question_title":"Saved Experiment missing after 24h in Azure ML free workspace",
        "Question_body":"<p>I had created a free Azure machine learning workspace. \nCreated an experiment while following a tutorial.\nSaved the experiment multiple times through the process.\nNext day when i came back to the workspace, i no longer see the saved experiment.<\/p>\n\n<p>Is this expected? Is it a limitation of a free workspace?\ni could not see it mentioned anywhere.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-02-16 06:47:21.74 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":128,
        "Owner_creation_date":"2013-02-20 14:38:46.787 UTC",
        "Owner_last_access_date":"2022-04-22 12:22:51.547 UTC",
        "Owner_reputation":123,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48821417",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57597351,
        "Question_title":"Running Ludwig on AML Compute: docker image failing to build on gmpy",
        "Question_body":"<p>I'm currently trying to create a TensorFlow estimator to run Ludwig's training model on Azure ML Compute with various pip and conda packages like so:<\/p>\n\n<pre><code>estimator= TensorFlow(source_directory= project_folder,\ncompute_target=compute_target, script_params=script_params, \nentry_script='.\/train.py', pip_packages=dependencies, conda_packages = \n[\"tensorflow\"], use_gpu =True)\n<\/code><\/pre>\n\n<p>One of the pip packages is gmpy, but it will not install and throws an <code>error: fatal error: gmp.h: No such file or directory compilation terminated. error: command 'gcc' failed with exit status 1<\/code>.<\/p>\n\n<p>This prevents Ludwig from installing and causes the imagine to fail to build<\/p>\n\n<p>When I run Ludwig locally in a python virtual environment on Ubuntu, I'm able to work around this issue by running \u201csudo apt-get install libgmp3-dev\u201d instead of <code>pip install gmpy<\/code>. When I try adding Gmpy2 as a library to the estimator, it throws the same error, and it seems that libgmp3-dev doesn't have a pip or conda equivalent. I tried adding the gmpy and gmpy2 .whl files directly to the environment but the wheel files were not recognized as compatible.<\/p>\n\n<p>Is there some way to add <code>RUN sudo apt-get install libgmp3-dev<\/code> to the dockerfile so that the docker container made by the estimator has this already installed without needing to create a custom dockerfile? I noticed that the TensorFlow estimator class has an \"environment_definition\" flag that can take a DockerSection but I can't find any examples of how they work.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-21 18:27:45.597 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-21 20:09:00.743 UTC",
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|ludwig",
        "Question_view_count":161,
        "Owner_creation_date":"2019-08-21 18:06:55.65 UTC",
        "Owner_last_access_date":"2019-09-03 22:45:28.813 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57597351",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68647731,
        "Question_title":"Access to Azure Keyvault inside Azure Container Instance",
        "Question_body":"<p>I have a machine learning model deployed on azure container instance and I need to access to key vault. When i use command below<\/p>\n<pre><code>credential = DefaultAzureCredential()\n<\/code><\/pre>\n<p>It can't authenticate thus i cannot reach my secrets.<\/p>\n<p>How can i reach keyvault inside azure container instance?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-08-04 08:16:00.597 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-keyvault|azure-machine-learning-studio|azure-container-instances",
        "Question_view_count":306,
        "Owner_creation_date":"2021-03-24 10:00:57.473 UTC",
        "Owner_last_access_date":"2022-09-10 14:40:32.643 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68647731",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61130625,
        "Question_title":"Horovod Timeline and MPI Tracing in Azure Machine Learning Workspace(MPI Configuration)",
        "Question_body":"<p>All,<BR>\nI am trying to train a distributed model using Horovod on Azure Machine Learning Service as shown below.<\/p>\n\n<pre><code>estimator = TensorFlow(source_directory=script_folder,\n                       entry_script='train_script.py',\n                       script_params=script_params,\n                       compute_target=compute_target_gpu_4,\n                       conda_packages=['scikit-learn'],                       \n                       node_count=2,                        \n                       distributed_training=MpiConfiguration(),\n                       framework_version = '1.13',\n                       use_gpu=True\n                      )\nrun = exp.submit(estimator)\n<\/code><\/pre>\n\n<ul>\n<li>How to enable Horovod timeline?<\/li>\n<li>How to enable more detailed MPI tracing to see the communication between the nodes?<\/li>\n<\/ul>\n\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-09 21:37:53.727 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-04-09 22:05:16.22 UTC",
        "Question_score":1,
        "Question_tags":"distributed-computing|azure-machine-learning-studio|azure-machine-learning-service|horovod",
        "Question_view_count":149,
        "Owner_creation_date":"2019-11-28 11:07:18.203 UTC",
        "Owner_last_access_date":"2022-09-23 21:26:15.933 UTC",
        "Owner_reputation":350,
        "Owner_up_votes":19,
        "Owner_down_votes":1,
        "Owner_views":34,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61130625",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54003442,
        "Question_title":"Azure Machine Learning Studio training 24 hour timeout",
        "Question_body":"<p>I'm a newbie trying out Azure's Machine Learning (ML) Studio module. I own a standard subscription level account which grants me an experimental duration of \"Up to 7 days per experiment with a maximum of 24 hours per module\" according to the <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning-studio\/\" rel=\"nofollow noreferrer\">ML Studio's pricing site<\/a>.<\/p>\n\n<p>However, since my dataset is extremely large, I would need a much longer training duration than the allocated 24 hours (I have tried and it timeout-ed even with the simplest NN architecture). Is there workaround for this issue? <\/p>\n\n<p>Thank you in advance. <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-01-02 08:47:44.137 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":228,
        "Owner_creation_date":"2016-02-17 08:01:02.413 UTC",
        "Owner_last_access_date":"2022-06-12 13:02:55.067 UTC",
        "Owner_reputation":327,
        "Owner_up_votes":2,
        "Owner_down_votes":1,
        "Owner_views":46,
        "Answer_body":"<p>I would suggest to stop using <code>Azure Machine Learning Studio<\/code> and switch to \"real\" Azure ML with <code>Azure Machine Learning Services<\/code>, where you will have much more control on your compute needs.<\/p>\n\n<p>Azure ML Studio roadmap is really limited and the purpose of this solution was to help people coming to Machine Learning. If you have a real use-case, use Azure Machine Learning Services.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2019-01-02 10:00:09.8 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54003442",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63471973,
        "Question_title":"The client with object id does not have authorization to perform action over scope or the scope is invalid",
        "Question_body":"<p><strong>What I'm doing:<\/strong><\/p>\n<p>My machine learning developer is trying to manually provision a ML Workspace in Azure.<\/p>\n<p><strong>Error:<\/strong><\/p>\n<p><code>{&quot;message&quot;:&quot;The client 'name@company.com' with object id 'xxxxxxx-xxxxxx-xxxxx-xxxxxxetc.' does not have authorization to perform action 'Microsoft.MachineLearningServices\/register\/action' over scope '\/subscriptions\/'xxxxxxx-xxxxxx-xxxxx-xxxxxxetc.'' or the scope is invalid. If access was recently granted, please refresh your credentials. (Code: AuthorizationFailed)&quot;} <\/code><\/p>\n<p><strong>What I've tried:<\/strong><\/p>\n<p>I see two existing discussions on this error from azure <a href=\"https:\/\/stackoverflow.com\/questions\/58302209\/the-client-with-object-id-does-not-have-authorization-to-perform-action-microso\">here<\/a> and <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/95ed9e71-a11b-49d5-b292-252b1e850acf\/getting-error-in-using-azure-management-libraries-to-create-a-vm?forum=windowsazurepack\" rel=\"nofollow noreferrer\">here<\/a>.  In both cases the users are using a service account with an API, and the gist of the solutions offered are to grant the service account the proper role assignments in access control.  In my case, however, the user is trying to create the resource <em>manually<\/em> via the portal, and the user already has 'owner' role over the resource group.  What more could I grant them?  How does she refresh her credentials?  Any pointers?  THANKS!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2020-08-18 15:36:19.433 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-08-18 15:50:29.843 UTC",
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":3759,
        "Owner_creation_date":"2017-12-02 02:46:30.373 UTC",
        "Owner_last_access_date":"2022-09-15 21:43:48.81 UTC",
        "Owner_reputation":1082,
        "Owner_up_votes":312,
        "Owner_down_votes":1,
        "Owner_views":220,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Idaho, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63471973",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":54164588,
        "Question_title":"Why Azure ML , scored probability response greater than 1?",
        "Question_body":"<p>I have setup an Azure ML experiment,using \"Boosted Decision Tree Regression\".<\/p>\n\n<p>My evaluation results are as follows:<\/p>\n\n<pre><code>\"Scored Labels\": \"N\",\n\"Scored Probabilities\": \"0.023*************\"\n<\/code><\/pre>\n\n<p>While testing the deployed web service with data, I am sometimes seeing a scored probability that is greater than 1!<\/p>\n\n<pre><code>\"Scored Labels\": \"N\", \n\"Scored Probabilities\": \"1.144*************\"\n<\/code><\/pre>\n\n<p>As per my understanding, probability of anything can never be grater than 1.\nWhat does a scored probability > 1 in this case mean? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-01-12 22:49:45.617 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-02-26 23:13:53.957 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":476,
        "Owner_creation_date":"2013-03-03 12:17:22.61 UTC",
        "Owner_last_access_date":"2022-07-18 12:20:11.297 UTC",
        "Owner_reputation":1666,
        "Owner_up_votes":199,
        "Owner_down_votes":13,
        "Owner_views":172,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54164588",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60301487,
        "Question_title":"Delete and list out the all models and deployment service from Azure Machine Learning Service using python",
        "Question_body":"<p>How to get all models and deployment service from Azure Machine Learning Service and how to delete it using python.<\/p>\n\n<p>Is there any way to list, delete all models and deployment services from Azure ML Service using python?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-19 13:28:37.907 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|python-3.x|azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1425,
        "Owner_creation_date":"2019-07-23 11:12:07.64 UTC",
        "Owner_last_access_date":"2021-07-09 12:30:12.43 UTC",
        "Owner_reputation":157,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":46,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60301487",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65275846,
        "Question_title":"How to retrieve compute cluster name from ComputeTarget.list(workspace=ws) in Azure ML",
        "Question_body":"<p>I use <code>clist=<\/code><a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.computetarget?view=azure-ml-py#list-workspace-\" rel=\"nofollow noreferrer\">ComputeTarget.list(workspace=ws)<\/a> to find a list of compute target in the workspace, which looks like this:<\/p>\n<pre><code>[{\n   &quot;id&quot;: &quot;\/subscriptions\/94e14ad4-bf97-47e8-aae0-f9b85a7befa8\/resourceGroups\/...\/providers\/Microsoft.MachineLearningServices\/workspaces\/...\/computes\/std-ds3-v2&quot;,\n   &quot;name&quot;: &quot;std-ds3-v2&quot;,\n   &quot;location&quot;: &quot;southcentralus&quot;,\n   &quot;tags&quot;: null,\n   &quot;properties&quot;: {\n     &quot;description&quot;: null,\n     &quot;computeType&quot;: &quot;ComputeInstance&quot;,\n     &quot;computeLocation&quot;: &quot;southcentralus&quot;,\n     &quot;resourceId&quot;: null,\n     &quot;provisioningErrors&quot;: null,\n     &quot;provisioningState&quot;: &quot;Succeeded&quot;,\n     &quot;properties&quot;: {\n       &quot;vmSize&quot;: &quot;STANDARD_DS3_V2&quot;,\n       &quot;applications&quot;: [\n         {\n           &quot;displayName&quot;: &quot;Jupyter&quot;,\n           &quot;endpointUri&quot;: &quot;https:\/\/std-ds3-v2.southcentralus.instances.azureml.ms&quot;\n         },\n         {\n           &quot;displayName&quot;: &quot;Jupyter Lab&quot;,\n           &quot;endpointUri&quot;: &quot;https:\/\/std-ds3-v2.southcentralus.instances.azureml.ms\/lab&quot;\n         },\n         {\n           &quot;displayName&quot;: &quot;RStudio&quot;,\n           &quot;endpointUri&quot;: &quot;https:\/\/std-ds3-v2-8787.southcentralus.instances.azureml.ms&quot;\n         }\n       ],\n     ...\n     ...\n   }\n }]\n<\/code><\/pre>\n<p>The <code>clist<\/code> object looks like a list of dictionary elements. I want to retrieve the dictionary element <code>&quot;name&quot;: &quot;std-ds3-v2&quot;<\/code> dynamically, so I tried <code>clist[0]['name']<\/code> but got this error:<\/p>\n<pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-101-df855b4d0107&gt; in &lt;module&gt;\n----&gt; 1 clist[0]['name']\n\nTypeError: 'ComputeInstance' object is not subscriptable\n<\/code><\/pre>\n<p>How to retrieve <code>&quot;name&quot;: &quot;std-ds3-v2&quot;<\/code> from the <code>clist<\/code> object?<\/p>\n<p>Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-13 12:56:31.72 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service|azure-sdk-python",
        "Question_view_count":244,
        "Owner_creation_date":"2017-05-24 01:09:10.03 UTC",
        "Owner_last_access_date":"2020-12-16 08:24:08.143 UTC",
        "Owner_reputation":127,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65275846",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53774570,
        "Question_title":"Not able to view files created in Azure Notebooks",
        "Question_body":"<p>I am trying to create a new file using Azure notebooks (notebooks.azure.com) and executing the Jupyter notebooks itself doesn't have any challenges or errors, but the actual file is missing in the path <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/T4aHu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/T4aHu.png\" alt=\"Jupyter notebook script\"><\/a><\/p>\n\n<p>The files list after executing the script is below (I should have seen test.txt file which is missing now)<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/suHCp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/suHCp.png\" alt=\"File structure\"><\/a><\/p>\n\n<p>Does anyone has inputs?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2018-12-14 06:33:17.453 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|jupyter-notebook|azure-machine-learning-studio|azure-machine-learning-workbench|azure-notebooks",
        "Question_view_count":178,
        "Owner_creation_date":"2012-11-19 09:24:15.073 UTC",
        "Owner_last_access_date":"2020-02-05 16:47:07.973 UTC",
        "Owner_reputation":773,
        "Owner_up_votes":33,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53774570",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51587956,
        "Question_title":"Activation function of Regression Neural Net in Azure ML Studio?",
        "Question_body":"<p>I am not able to find activation function for Regression Neural Network in Azure Machine Learning Studio. I am not able to identify what is the activation function taken for my NN. Followed this document also-<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/neural-network-regression\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/neural-network-regression<\/a><\/p>\n\n<p>Can someone suggest where to mention it\/ what is the default activation function used?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-07-30 06:15:31.77 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":352,
        "Owner_creation_date":"2015-08-11 08:00:53.903 UTC",
        "Owner_last_access_date":"2022-08-11 16:11:14.593 UTC",
        "Owner_reputation":541,
        "Owner_up_votes":457,
        "Owner_down_votes":6,
        "Owner_views":269,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bangalore, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51587956",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50189497,
        "Question_title":"How to use datasets uploaded in azureml to pandas to analyse it?",
        "Question_body":"<p>I have uploaded a dataset to the AzureMl by microsoft . Now the problem is I want to use that dataset(.csv) in the notebook (also provided by azureml)  . But I can't find a way to do it .\nIt provides a way to access it by :<\/p>\n\n<pre><code>from azureml import Workspace\n\nws = Workspace(\n    workspace_id='777902b8d48a449091a57d13bfcdfdec',\n    authorization_token='c05837974f984e4eb6a4df85a97642dd',\n    endpoint='https:\/\/studioapi.azureml.net'\n)\nds = ws.datasets['temp.csv']\nframe = ds.to_dataframe()\n<\/code><\/pre>\n\n<p>And when I do a :<\/p>\n\n<pre><code>type(frame)\n<\/code><\/pre>\n\n<p>It shows: <code>pandas.core.frame.DataFrame<\/code><\/p>\n\n<p>But I want it in a form of CSV . So that I start from beginning . SO, I use :\n<code>frame.to_csv('temp.csv')<\/code><\/p>\n\n<p>Is there any other way to use the uploaded dataset in pandas in azureml?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2018-05-05 12:36:43.993 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|python-3.x|pandas|azure|azure-machine-learning-studio",
        "Question_view_count":3674,
        "Owner_creation_date":"2015-09-23 15:30:33.287 UTC",
        "Owner_last_access_date":"2021-08-02 08:03:00.647 UTC",
        "Owner_reputation":49,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50189497",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73734047,
        "Question_title":"Deploying a databricks model as a scoring webservice failed in Azure Machine Learning",
        "Question_body":"<p>I am doing an Azure Databricks lab 04. Integrating Azure Databricks and Azure Machine Learning -&gt; 2. Deploying Models in Azure Machine Learning. The idea is to 1. train a  model 2) deploy that model in an Azure Container Instance (ACI) in AML and 3) make predictions via HTTPS. However, I get an error when deploying the model.<\/p>\n<p>The full code from the notebook is displayed at the bottom or can be found here: <a href=\"https:\/\/adb-4934989010098757.17.azuredatabricks.net\/?o=4934989010098757#notebook\/4364513836468644\/command\/4364513836468645\" rel=\"nofollow noreferrer\">https:\/\/adb-4934989010098757.17.azuredatabricks.net\/?o=4934989010098757#notebook\/4364513836468644\/command\/4364513836468645<\/a> .<\/p>\n<p>I run the actual model deployment in the following way:<\/p>\n<pre><code>aci_service_name='nyc-taxi-service'\n\nservice = Model.deploy(workspace=ws,\n                       name=aci_service_name,\n                       models=[registered_model],\n                       inference_config=inference_config,\n                       deployment_config= aci_config, \n                       overwrite=True)\n\nservice.wait_for_deployment(show_output=True)\nprint(service.state)\n<\/code><\/pre>\n<p>After running the model deployment, the cell runs for over 25 minutes and breaks when checking the status of the inference endpoint. It gives the following error: &quot;<\/p>\n<pre><code>&quot;Service deployment polling reached non-successful terminal state, current service state: Failed \ncode&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\n<\/code><\/pre>\n<p>The scoring script looks like this:<\/p>\n<pre><code>script_dir = 'scripts'\ndbutils.fs.mkdirs(script_dir)\nscript_dir_path = os.path.join('\/dbfs', script_dir)\nprint(&quot;Script directory path:&quot;, script_dir_path)\n\n%%writefile $script_dir_path\/score.py\nimport json\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport joblib\nfrom azureml.core.model import Model\n\ncolumns = ['passengerCount', 'tripDistance', 'hour_of_day', 'day_of_week', \n           'month_num', 'normalizeHolidayName', 'isPaidTimeOff', 'snowDepth', \n           'precipTime', 'precipDepth', 'temperature']\n\ndef init():\n    global model\n    model_path = Model.get_model_path('nyc-taxi-fare')\n    model = joblib.load(model_path)\n    print('model loaded')\n\ndef run(input_json):\n    # Get predictions and explanations for each data point\n    inputs = json.loads(input_json)\n    data_df = pd.DataFrame(np.array(inputs).reshape(-1, len(columns)), columns = columns)\n    # Make prediction\n    predictions = model.predict(data_df)\n    # You can return any data type as long as it is JSON-serializable\n    return {'predictions': predictions.tolist()}\n\n<\/code><\/pre>\n<p>Does someone know how I could fix this potentially? Thanks in advance!<\/p>\n<p>The full code is displayed below:<\/p>\n<pre><code>\n**Required Libraries**: \n* `azureml-sdk[databricks]` via PyPI\n* `sklearn-pandas==2.1.0` via PyPI\n* `azureml-mlflow` via PyPI\nimport os\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport sklearn\nimport joblib\nimport math\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport azureml\nfrom azureml.core import Workspace, Experiment, Run\nfrom azureml.core.model import Model\n\nprint('The azureml.core version is {}'.format(azureml.core.VERSION))\n%md\n\n### Connect to the AML workspace\n%md\n\nIn the following cell, be sure to set the values for `subscription_id`, `resource_group`, and `workspace_name` as directed by the comments. Please note, you can copy the subscription ID and resource group name from the **Overview** page on the blade for the Azure ML workspace in the Azure portal.\n#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = &quot; ..... &quot;\n\n#Replace the name below with the name of your resource group\nresource_group = &quot;RG_1&quot;\n\n#Replace the name below with the name of your Azure Machine Learning workspace\nworkspace_name = &quot;aml-ws&quot;\n\nprint(&quot;subscription_id:&quot;, subscription_id)\nprint(&quot;resource_group:&quot;, resource_group)\nprint(&quot;workspace_name:&quot;, workspace_name)\n%md\n\n**Important Note**: You will be prompted to login in the text that is output below the cell. Be sure to navigate to the URL displayed and enter the code that is provided. Once you have entered the code, return to this notebook and wait for the output to read `Workspace configuration succeeded`.\n\n*Also note that the sign-on link and code only appear the first time in a session. If an authenticated session is already established, you won't be prompted to enter the code and authenticate when creating an instance of the Workspace.*\nws = Workspace(subscription_id, resource_group, workspace_name)\nprint(ws)\nprint('Workspace region:', ws.location)\nprint('Workspace configuration succeeded')\n%md\n### Load the training data\n\nIn this notebook, we will be using a subset of NYC Taxi &amp; Limousine Commission - green taxi trip records available from [Azure Open Datasets]( https:\/\/azure.microsoft.com\/en-us\/services\/open-datasets\/). The data is enriched with holiday and weather data. Each row of the table represents a taxi ride that includes columns such as number of passengers, trip distance, datetime information, holiday and weather information, and the taxi fare for the trip.\n\nRun the following cell to load the table into a Spark dataframe and reivew the dataframe.\ndataset = spark.sql(&quot;select * from nyc_taxi_1_csv&quot;).toPandas()\ndisplay(dataset)\n%md \n\n### Use MLflow with Azure Machine Learning for Model Training\n\nIn the subsequent cells you will learn to do the following:\n- Set up MLflow tracking URI so as to use Azure ML\n- Create MLflow experiment \u2013 this will create a corresponding experiment in Azure ML Workspace\n- Train a model on Azure Databricks cluster while logging metrics and artifacts using MLflow\n- Save the trained model to Databricks File System (DBFS)\nimport mlflow\nmlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\nexperiment_name = 'MLflow-AML-Exercise'\nmlflow.set_experiment(experiment_name)\n\nprint(&quot;Training model...&quot;)\noutput_folder = 'outputs'\nmodel_file_name = 'nyc-taxi.pkl'\ndbutils.fs.mkdirs(output_folder)\nmodel_file_path = os.path.join('\/dbfs', output_folder, model_file_name)\n\nwith mlflow.start_run() as run:\n  df = dataset.dropna(subset=['totalAmount'])\n  x_df = df.drop(['totalAmount'], axis=1)\n  y_df = df['totalAmount']\n\n  X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=0)\n\n  numerical = ['passengerCount', 'tripDistance', 'snowDepth', 'precipTime', 'precipDepth', 'temperature']\n  categorical = ['hour_of_day', 'day_of_week', 'month_num', 'normalizeHolidayName', 'isPaidTimeOff']\n\n  numeric_transformations = [([f], Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])) for f in numerical]\n    \n  categorical_transformations = [([f], OneHotEncoder(handle_unknown='ignore', sparse=False)) for f in categorical]\n\n  transformations = numeric_transformations + categorical_transformations\n\n  clf = Pipeline(steps=[('preprocessor', DataFrameMapper(transformations, df_out=True)), \n                        ('regressor', GradientBoostingRegressor())])\n\n  clf.fit(X_train, y_train)\n  \n  y_predict = clf.predict(X_test)\n  y_actual = y_test.values.flatten().tolist()\n  \n  rmse = math.sqrt(mean_squared_error(y_actual, y_predict))\n  mlflow.log_metric('rmse', rmse)\n  mae = mean_absolute_error(y_actual, y_predict)\n  mlflow.log_metric('mae', mae)\n  r2 = r2_score(y_actual, y_predict)\n  mlflow.log_metric('R2 score', r2)\n  \n  plt.figure(figsize=(10,10))\n  plt.scatter(y_actual, y_predict, c='crimson')\n  plt.yscale('log')\n  plt.xscale('log')\n\n  p1 = max(max(y_predict), max(y_actual))\n  p2 = min(min(y_predict), min(y_actual))\n  plt.plot([p1, p2], [p1, p2], 'b-')\n  plt.xlabel('True Values', fontsize=15)\n  plt.ylabel('Predictions', fontsize=15)\n  plt.axis('equal')\n  \n  results_graph = os.path.join('\/dbfs', output_folder, 'results.png')\n  plt.savefig(results_graph)\n  mlflow.log_artifact(results_graph)\n  \n  joblib.dump(clf, open(model_file_path,'wb'))\n  mlflow.log_artifact(model_file_path)\n%md \n\nRun the cell below to list the experiment run in Azure Machine Learning Workspace that you just completed.\naml_run = list(ws.experiments[experiment_name].get_runs())[0]\naml_run\n%md \n\n## Exercise 1: Register a databricks-trained model in AML\n\nAzure Machine Learning provides a Model Registry that acts like a version controlled repository for each of your trained models. To version a model, you use the SDK as follows. Run the following cell to register the model with Azure Machine Learning.\nmodel_name = 'nyc-taxi-fare'\nmodel_description = 'Model to predict taxi fares in NYC.'\nmodel_tags = {&quot;Type&quot;: &quot;GradientBoostingRegressor&quot;, \n              &quot;Run ID&quot;: aml_run.id, \n              &quot;Metrics&quot;: aml_run.get_metrics()}\n\nregistered_model = Model.register(model_path=model_file_path, #Path to the saved model file\n                                  model_name=model_name, \n                                  tags=model_tags, \n                                  description=model_description, \n                                  workspace=ws)\n\nprint(registered_model)\n%md\n\n## Exercise 2: Deploy a service that uses the model\n%md\n\n### Create the scoring script\nscript_dir = 'scripts'\ndbutils.fs.mkdirs(script_dir)\nscript_dir_path = os.path.join('\/dbfs', script_dir)\nprint(&quot;Script directory path:&quot;, script_dir_path)\n%%writefile $script_dir_path\/score.py\nimport json\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport joblib\nfrom azureml.core.model import Model\n\ncolumns = ['passengerCount', 'tripDistance', 'hour_of_day', 'day_of_week', \n           'month_num', 'normalizeHolidayName', 'isPaidTimeOff', 'snowDepth', \n           'precipTime', 'precipDepth', 'temperature']\n\ndef init():\n    global model\n    model_path = Model.get_model_path('nyc-taxi-fare')\n    model = joblib.load(model_path)\n    print('model loaded')\n\ndef run(input_json):\n    # Get predictions and explanations for each data point\n    inputs = json.loads(input_json)\n    data_df = pd.DataFrame(np.array(inputs).reshape(-1, len(columns)), columns = columns)\n    # Make prediction\n    predictions = model.predict(data_df)\n    # You can return any data type as long as it is JSON-serializable\n    return {'predictions': predictions.tolist()}\n%md\n\n### Create the deployment environment\nfrom azureml.core import Environment\nfrom azureml.core.environment import CondaDependencies\n\nmy_env_name=&quot;nyc-taxi-env&quot;\nmyenv = Environment.get(workspace=ws, name='AzureML-Minimal').clone(my_env_name)\nconda_dep = CondaDependencies()\nconda_dep.add_pip_package(&quot;numpy==1.18.1&quot;)\nconda_dep.add_pip_package(&quot;pandas==1.1.5&quot;)\nconda_dep.add_pip_package(&quot;joblib==0.14.1&quot;)\nconda_dep.add_pip_package(&quot;scikit-learn==0.24.1&quot;)\nconda_dep.add_pip_package(&quot;sklearn-pandas==2.1.0&quot;)\nconda_dep.add_pip_package(&quot;azure-ml-api-sdk&quot;)\n\nmyenv.python.conda_dependencies=conda_dep\n\nprint(&quot;Review the deployment environment.&quot;)\nmyenv\n%md\n\n### Create the inference configuration\nfrom azureml.core.model import InferenceConfig\ninference_config = InferenceConfig(entry_script='score.py', source_directory=script_dir_path, environment=myenv)\nprint(&quot;InferenceConfig created.&quot;)\n%md\n\n### Create the deployment configuration\n\nIn this exercise we will use the Azure Container Instance (ACI) to deploy the model\nfrom azureml.core.webservice import AciWebservice, Webservice\n\ndescription = 'NYC Taxi Fare Predictor Service'\n\naci_config = AciWebservice.deploy_configuration(\n                        cpu_cores=3, \n                        memory_gb=15, \n                        location='eastus', \n                        description=description, \n                        auth_enabled=True, \n                        tags = {'name': 'ACI container', \n                                'model_name': registered_model.name, \n                                'model_version': registered_model.version\n                                }\n                        )\n\nprint(&quot;AciWebservice deployment configuration created.&quot;)\n%md\n\n### Deploy the model as a scoring webservice\n\nPlease note that it can take **10-15 minutes** for the deployment to complete.\naci_service_name='nyc-taxi-service'\n\nservice = Model.deploy(workspace=ws,\n                       name=aci_service_name,\n                       models=[registered_model],\n                       inference_config=inference_config,\n                       deployment_config= aci_config, \n                       overwrite=True)\n\nservice.wait_for_deployment(show_output=True)\nprint(service.state)\n%md\n\n## Exercise 3: Consume the deployed service\n%md\n\n**Review the webservice endpoint URL and API key**\napi_key, _ = service.get_keys()\nprint(&quot;Deployed ACI test Webservice: {} \\nWebservice Uri: {} \\nWebservice API Key: {}&quot;.\n      format(service.name, service.scoring_uri, api_key))\n%md\n\n**Prepare test data**\n#['passengerCount', 'tripDistance', 'hour_of_day', 'day_of_week', 'month_num', \n# 'normalizeHolidayName', 'isPaidTimeOff', 'snowDepth', 'precipTime', 'precipDepth', 'temperature']\n\ndata1 = [2, 5, 9, 4, 5, 'Memorial Day', True, 0, 0.0, 0.0, 65]\ndata2 = [[3, 10, 15, 4, 7, 'None', False, 0, 2.0, 1.0, 80], \n         [2, 5, 9, 4, 5, 'Memorial Day', True, 0, 0.0, 0.0, 65]]\n\nprint(&quot;Test data prepared.&quot;)\ndataset.head()\n%md\n\n### Consume the deployed webservice over HTTP\nimport requests\nimport json\n\nheaders = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}\nresponse = requests.post(service.scoring_uri, json.dumps(data1), headers=headers)\nprint('Predictions for data1')\nprint(response.text)\nprint(&quot;&quot;)\nresponse = requests.post(service.scoring_uri, json.dumps(data2), headers=headers)\nprint('Predictions for data2')\nprint(response.text)\n%md\n\n### Clean-up\n\nWhen you are done with the exercise, delete the deployed webservice by running the cell below.\nservice.delete()\nprint(&quot;Deployed webservice deleted.&quot;)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-09-15 15:47:30.727 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-15 15:48:42.017 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|deployment|databricks|azure-machine-learning-studio",
        "Question_view_count":45,
        "Owner_creation_date":"2021-06-11 13:17:50.14 UTC",
        "Owner_last_access_date":"2022-09-21 19:40:01.61 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73734047",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58040933,
        "Question_title":"Error in connecting Azure SQL database from Azure Machine Learning Service using python",
        "Question_body":"<p>I am trying to connect <strong>Azure SQL Database<\/strong> from <strong>Azure Machine Learning service<\/strong>, but I got the below error.<\/p>\n\n<p><strong>Please check Error: -<\/strong><\/p>\n\n<pre><code>**('IM002', '[IM002] [unixODBC][Driver Manager]Data source name not found and no default driver specified (0) (SQLDriverConnect)')**\n<\/code><\/pre>\n\n<p>Please Check the below code that I have used for database connection: -<\/p>\n\n<pre><code>import pyodbc\n\nclass DbConnect:\n    # This class is used for azure database connection using pyodbc\n    def __init__(self):\n        try:\n            self.sql_db = pyodbc.connect(SERVER=&lt;servername&gt;;PORT=1433;DATABASE=&lt;databasename&gt;;UID=&lt;username&gt;;PWD=&lt;password&gt;')\n\n            get_name_query = \"select name from contacts\"\n            names = self.sql_db.execute(get_name_query)\n            for name in names:\n                print(name)\n\n        except Exception as e:\n            print(\"Error in azure sql server database connection : \", e)\n            sys.exit()\n\nif __name__ == \"__main__\":\n    class_obj = DbConnect()\n<\/code><\/pre>\n\n<p>Is there any way to solve the above error? Please let me know if there is any way.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-21 13:49:49.15 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|sql|azure|azure-sql-database|azure-machine-learning-service",
        "Question_view_count":1013,
        "Owner_creation_date":"2019-04-05 12:07:30.937 UTC",
        "Owner_last_access_date":"2020-01-07 14:57:03.53 UTC",
        "Owner_reputation":219,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Answer_body":"<p>I'd consider using <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-dataprep\/azureml.dataprep?view=azure-dataprep-py\" rel=\"nofollow noreferrer\"><code>azureml.dataprep<\/code><\/a> over pyodbc for this task (the API may change, but this worked last time I tried):<\/p>\n\n<pre><code>import azureml.dataprep as dprep\n\nds = dprep.MSSQLDataSource(server_name=&lt;server-name,port&gt;,\n                           database_name=&lt;database-name&gt;,\n                           user_name=&lt;username&gt;,\n                           password=&lt;password&gt;)\n<\/code><\/pre>\n\n<p>You should then be able to collect the result of an SQL query in pandas e.g. via<\/p>\n\n<pre><code>dataflow = dprep.read_sql(ds, \"SELECT top 100 * FROM [dbo].[MYTABLE]\")\ndataflow.to_pandas_dataframe()\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2019-09-21 23:35:21.71 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2019-09-22 10:05:09.727 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58040933",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67648580,
        "Question_title":"deploy web service for registered R model in Azure ML",
        "Question_body":"<p>I have an absolute nightmare to use <a href=\"https:\/\/github.com\/Azure\/azureml-sdk-for-r\" rel=\"nofollow noreferrer\">azureml-sdk-for-r<\/a>. So I try to achieve everything via the UI (<a href=\"https:\/\/ml.azure.com\/\" rel=\"nofollow noreferrer\">https:\/\/ml.azure.com\/<\/a>). I trained a model locally like so in R 4.0.5<\/p>\n<pre><code>library(datasets)\nlibrary(caret)\n\ndata(iris)\n\nsetwd(&quot;C:\/Data&quot;)\n\nindex &lt;- createDataPartition(iris$Species, p=0.80, list=FALSE)\ntestset &lt;- iris[-index,]\ntrainset &lt;- iris[index,]\n\nmodel = train(Species ~ ., \n                  data=trainset, \n                  method=&quot;rpart&quot;, \n                  trControl = trainControl(method = &quot;cv&quot;))\n\nsaveRDS(model, &quot;model.rds&quot;)\n<\/code><\/pre>\n<p>I deployed\/registered it via the UI, no issue. The &quot;scoring script&quot; I try to use to remove the model dependency is as follows (the only dependency is really jsonlite).<\/p>\n<pre><code>library(jsonlite)\n\ninit &lt;- function()\n{\n  message(&quot;model is loaded&quot;)\n  \n  function(data)\n  {\n    prediction_data &lt;- as.data.frame(fromJSON(data))\n    return('{&quot;result&quot;: &quot;Hello world&quot;}')\n  }\n}\n<\/code><\/pre>\n<p>I use the following yml file as my conda dependency file for this screen:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ZFv3i.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZFv3i.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<pre><code>name: scoring_environment\nchannels:\n  - defaults\ndependencies:\n  - r-base=4.0.5\n  #- r-essentials=4.0.5\n  # whatever other dependencies you have\n  - jsonlite=1.7.2 \n<\/code><\/pre>\n<p>But get immediately this:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Dz7Fd.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Dz7Fd.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>How can I debug what's going on? Is the conda dependency file wrong? As it stand, Azure ML is absolutely useless for me as an R user with locally trained models )-:<\/p>\n<p>PS:<\/p>\n<p>I also try to deploy this locally like so:<\/p>\n<pre><code>library(azuremlsdk)\n\ninteractive_auth &lt;- interactive_login_authentication(tenant_id=&quot;296bf094-bdb4-488f-8ebd-92b2dd1464c2&quot;)\n\nws &lt;- get_workspace(\n        name = &quot;xxx&quot;, \n        subscription_id = &quot;xxx&quot;, \n        resource_group =&quot;xxx&quot;, \n        auth = interactive_auth\n)\n\nmodel &lt;- get_model(ws, name = &quot;iris&quot;)\n\nr_env &lt;- r_environment(name = &quot;r_env&quot;)\n\n# Create inference config\ninference_config &lt;- inference_config(\n  entry_script = &quot;score1.R&quot;,\n  source_directory = &quot;.&quot;,\n  environment = r_env)\n\nlocal_deployment_config &lt;- local_webservice_deployment_config()\n\nservice &lt;- deploy_model(ws, \n                        'rservice-local', \n                        list(model), \n                        inference_config, \n                        local_deployment_config)\n# Wait for deployment\nwait_for_deployment(service, show_output = TRUE)\n\n# Show the port of local service\nmessage(service$port)\n<\/code><\/pre>\n<p>It downloads registred model to my local machine. So this bit works but then there is this error:<\/p>\n<pre><code>\/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad\/lib\/python3.6\/site-packages\/rpy2\/rinterface\/__init__.py:146: RRuntimeWarning:  cannot open file '\/var\/azureml-app\/iris\/score1.R': No such file or directory\n<\/code><\/pre>\n<p>So I tried to deliberately created a relative folder:<\/p>\n<p>\/var\/azureml-app\/iris\/<\/p>\n<p>where the above script lives and place score1.r (see above) there. Still same error. I am lost!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-05-22 10:42:55.607 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-05-22 10:57:22.873 UTC",
        "Question_score":3,
        "Question_tags":"r|azure-machine-learning-studio|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":163,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Somewhere",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67648580",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51643168,
        "Question_title":"Azure ML Studio: How to change input value with Python before it goes through data process",
        "Question_body":"<p>I am currently attempting to change the value of input as it goes through data process in Azure ML. However, I cannot find a clue about how to access to the input data with python.<\/p>\n\n<p>For example, if you were to use python, you can access to the column of data with<\/p>\n\n<pre><code>print(dataframe1[\"Hello World\"])\n<\/code><\/pre>\n\n<p>I tried to change the name of Web Service Input and tried to do it like how I did for other dataframe (e.g. sample)<\/p>\n\n<pre><code>print(dataframe[\"sample\"])\n<\/code><\/pre>\n\n<p>But it returns an error with no luck, and from what I read from an error, it's not compatible to dataframe:<\/p>\n\n<pre><code>object of type 'NoneType' has no len()\n<\/code><\/pre>\n\n<p>I tried to look up a solution with Nonetype error, but there is no good solution.\nThe whole error message:<\/p>\n\n<pre><code>requestId = 1f0f621f1d8841baa7862d5c05154942 errorComponent=Module. taskStatusCode=400. {\"Exception\":{\"ErrorId\":\"FailedToEvaluateScript\",\"ErrorCode\":\"0085\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 0085: The following error occurred during script evaluation, please view the output log for more information:\\r\\n---------- Start of error message from Python interpreter ----------\\r\\nCaught exception while executing function: Traceback (most recent call last):\\r\\n File \\\"C:\\\\server\\\\invokepy.py\\\", line 211, in batch\\r\\n xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True)\\r\\n File \\\"C:\\\\server\\\\XDRReader\\\\xdrutils.py\\\", line 51, in DataFrameToRFile\\r\\n attributes = XDRBridge.DataFrameToRObject(dataframe)\\r\\n File \\\"C:\\\\server\\\\XDRReader\\\\xdrbridge.py\\\", line 40, in DataFrameToRObject\\r\\n if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):\\r\\nTypeError: object of type 'NoneType' has no len()\\r\\nProcess returned with non-zero exit code 1\\r\\n\\r\\n---------- End of error message from Python interpreter ----------\"}}Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:---------- Start of error message from Python interpreter ----------Caught exception while executing function: Traceback (most recent call last): File \"C:\\server\\invokepy.py\", line 211, in batch xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True) File \"C:\\server\\XDRReader\\xdrutils.py\", line 51, in DataFrameToRFile attributes = XDRBridge.DataFrameToRObject(dataframe) File \"C:\\server\\XDRReader\\xdrbridge.py\", line 40, in DataFrameToRObject if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):TypeError: object of type 'NoneType' has no len()Process returned with non-zero exit code 1---------- End of error message from Python interpreter ---------- Process exited with error code -2\n<\/code><\/pre>\n\n<p>I have also tried to <a href=\"https:\/\/i.stack.imgur.com\/DWZK6.png\" rel=\"nofollow noreferrer\">a way to pass python script in data<\/a>, but it is not able to make any change to Web Service Input value as I want it to be.<\/p>\n\n<p>I have tried to look on forums like msdn or SO, but it's been difficult to find any information about it. Please let me know if you need any more information if needed. I would greatly appreciate your help!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-08-01 22:38:50.393 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|web-services|input|azure-machine-learning-studio",
        "Question_view_count":309,
        "Owner_creation_date":"2017-10-17 22:57:27.96 UTC",
        "Owner_last_access_date":"2019-05-07 20:40:51.74 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51643168",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73253865,
        "Question_title":"Azure machine learning - data set contains NA but it is not showing as missing value",
        "Question_body":"<p>I am new to azure machine learning, I am working on house price prediction data set.\nThis data set contain NA values in multiple columns both numeric and categorical but when I am trying to clean it, it is not getting cleaned, because azure is not considering it as missing value. Please let me know how to treat NA missing values.<\/p>\n<p><strong>What I tried :<\/strong>\ni tried 'convert dataset' to replace NA with 0 but it is replacing all NA's in categorical as well as numeric columns which i don't want. I want to replace NA in numeric column with only mean not 0.<\/p>\n<p><strong>What I want<\/strong> : I want to replace NA in categorical columns with 'Not available' string and in numeric columns with mean.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-05 18:17:46.45 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-pipelines|azure-machine-learning-studio",
        "Question_view_count":47,
        "Owner_creation_date":"2017-11-22 18:48:57.9 UTC",
        "Owner_last_access_date":"2022-09-06 08:04:12.87 UTC",
        "Owner_reputation":1180,
        "Owner_up_votes":164,
        "Owner_down_votes":4,
        "Owner_views":88,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73253865",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55443270,
        "Question_title":"Separators in data file for azure ml studio",
        "Question_body":"<p>I have csv file news.csv with such data:<\/p>\n\n<pre><code>ID \\t TITLE \\t URL \\t PUBLISHER \\t CATEGORY \\t STORY \\t HOSTNAME \\t TIMESTAMP\n<\/code><\/pre>\n\n<p>But Azure ML studio experiments dont see Separators \\t and when I try to select column I cant do it. How to fix it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-03-31 17:00:28.587 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":109,
        "Owner_creation_date":"2019-03-22 07:26:07.403 UTC",
        "Owner_last_access_date":"2019-05-06 15:32:30.967 UTC",
        "Owner_reputation":67,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55443270",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66711458,
        "Question_title":"How do we do Batch Inferencing on Azure ML Service with Parameterized Dataset\/DataPath input?",
        "Question_body":"<p>The ParallelRunStep Documentation suggests the following:<\/p>\n<p>A named input Dataset (<code>DatasetConsumptionConfig<\/code> class)<\/p>\n<pre><code>path_on_datastore = iris_data.path('iris\/')\ninput_iris_ds = Dataset.Tabular.from_delimited_files(path=path_on_datastore, validate=False)\nnamed_iris_ds = input_iris_ds.as_named_input(iris_ds_name)\n<\/code><\/pre>\n<p>Which is just passed as an Input:<\/p>\n<pre><code>distributed_csv_iris_step = ParallelRunStep(\n    name='example-iris',\n    inputs=[named_iris_ds],\n    output=output_folder,\n    parallel_run_config=parallel_run_config,\n    arguments=['--model_name', 'iris-prs'],\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>The Documentation to submit Dataset Inputs as Parameters suggests the following:\nThe Input is a <code>DatasetConsumptionConfig<\/code> class element<\/p>\n<pre><code>tabular_dataset = Dataset.Tabular.from_delimited_files('https:\/\/dprepdata.blob.core.windows.net\/demo\/Titanic.csv')\ntabular_pipeline_param = PipelineParameter(name=&quot;tabular_ds_param&quot;, default_value=tabular_dataset)\ntabular_ds_consumption = DatasetConsumptionConfig(&quot;tabular_dataset&quot;, tabular_pipeline_param)\n<\/code><\/pre>\n<p>Which is passed in <code>arguments<\/code> as well in <code>inputs<\/code><\/p>\n<pre><code>train_step = PythonScriptStep(\n    name=&quot;train_step&quot;,\n    script_name=&quot;train_with_dataset.py&quot;,\n    arguments=[&quot;--param2&quot;, tabular_ds_consumption],\n    inputs=[tabular_ds_consumption],\n    compute_target=compute_target,\n    source_directory=source_directory)\n<\/code><\/pre>\n<p>While submitting with new parameter we create a new <code>Dataset<\/code> class:<\/p>\n<pre><code>iris_tabular_ds = Dataset.Tabular.from_delimited_files('some_link')\n<\/code><\/pre>\n<p>And submit it like this:<\/p>\n<pre><code>pipeline_run_with_params = experiment.submit(pipeline, pipeline_parameters={'tabular_ds_param': iris_tabular_ds})\n<\/code><\/pre>\n<p>However, how do we combine this: How do we pass a Dataset Input as a Parameter to the ParallelRunStep?<\/p>\n<p>If we create a <code>DatasetConsumptionConfig<\/code> class element like so:<\/p>\n<pre><code>tabular_dataset = Dataset.Tabular.from_delimited_files('https:\/\/dprepdata.blob.core.windows.net\/demo\/Titanic.csv')\ntabular_pipeline_param = PipelineParameter(name=&quot;tabular_ds_param&quot;, default_value=tabular_dataset)\ntabular_ds_consumption = DatasetConsumptionConfig(&quot;tabular_dataset&quot;, tabular_pipeline_param)\n<\/code><\/pre>\n<p>And pass it as an argument in the ParallelRunStep, it will throw an error.<\/p>\n<p>References:<\/p>\n<ol>\n<li><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-showcasing-dataset-and-pipelineparameter.ipynb\" rel=\"nofollow noreferrer\">Notebook with Dataset Input Parameter<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/tabular-dataset-inference-iris.ipynb\" rel=\"nofollow noreferrer\">ParallelRunStep Notebook<\/a><\/li>\n<\/ol>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-19 15:51:52.093 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":664,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p>For the inputs we create Dataset class instances:<\/p>\n<pre><code>tabular_ds1 = Dataset.Tabular.from_delimited_files('some_link')\ntabular_ds2 = Dataset.Tabular.from_delimited_files('some_link')\n<\/code><\/pre>\n<p>ParallelRunStep produces an output file, we use the PipelineData class to create a folder which will store this output:<\/p>\n<pre><code>from azureml.pipeline.core import Pipeline, PipelineData\n\noutput_dir = PipelineData(name=&quot;inferences&quot;, datastore=def_data_store)\n<\/code><\/pre>\n<p>The ParallelRunStep depends on ParallelRunConfig Class to include details about the environment, entry script, output file name and other necessary definitions:<\/p>\n<pre><code>from azureml.pipeline.core import PipelineParameter\nfrom azureml.pipeline.steps import ParallelRunStep, ParallelRunConfig\n\nparallel_run_config = ParallelRunConfig(\n    source_directory=scripts_folder,\n    entry_script=script_file,\n    mini_batch_size=PipelineParameter(name=&quot;batch_size_param&quot;, default_value=&quot;5&quot;),\n    error_threshold=10,\n    output_action=&quot;append_row&quot;,\n    append_row_file_name=&quot;mnist_outputs.txt&quot;,\n    environment=batch_env,\n    compute_target=compute_target,\n    process_count_per_node=PipelineParameter(name=&quot;process_count_param&quot;, default_value=2),\n    node_count=2\n)\n<\/code><\/pre>\n<p>The input to ParallelRunStep is created using the following code<\/p>\n<pre><code>tabular_pipeline_param = PipelineParameter(name=&quot;tabular_ds_param&quot;, default_value=tabular_ds1)\ntabular_ds_consumption = DatasetConsumptionConfig(&quot;tabular_dataset&quot;, tabular_pipeline_param)\n<\/code><\/pre>\n<p>The PipelineParameter helps us run the pipeline for different datasets.\nParallelRunStep consumes this as an input:<\/p>\n<pre><code>parallelrun_step = ParallelRunStep(\n    name=&quot;some-name&quot;,\n    parallel_run_config=parallel_run_config,\n    inputs=[ tabular_ds_consumption ],\n    output=output_dir,\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>To consume with another dataset:<\/p>\n<pre><code>pipeline_run_2 = experiment.submit(pipeline, \n                                   pipeline_parameters={&quot;tabular_ds_param&quot;: tabular_ds2}\n)\n<\/code><\/pre>\n<p>There is an error currently: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1312\" rel=\"nofollow noreferrer\">DatasetConsumptionConfig and PipelineParameter cannot be reused<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-02 06:41:28.81 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66711458",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72566227,
        "Question_title":"I built a azureml pipeline while triggering the pipeline I encountered \"cannot import name 'SerializationError'\"",
        "Question_body":"<p>Full error log<\/p>\n<pre><code>{\n    &quot;error&quot;: {\n        &quot;message&quot;: &quot;Activity Failed:\\n{\\n    \\&quot;error\\&quot;: {\\n        \\&quot;code\\&quot;: \\&quot;ServiceError\\&quot;,\\n       \n     \\&quot;message\\&quot;: \\&quot;RunHistory initialization failed: cannot import name 'SerializationError' from 'azure.core.exceptions' \n    (\/azureml-envs\/azureml_30df433ffc7340ddb6e1ab224c5d7dab\/lib\/python3.7\/site-packages\/azure\/core\/exceptions.py)\\&quot;,\\n      \n      \\&quot;messageParameters\\&quot;: {},\\n       \n     \\&quot;details\\&quot;: []\\n    },\\n    \\&quot;time\\&quot;: \\&quot;0001-01-01T00:00:00.000Z\\&quot;\\n}&quot;\n    }\n}\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-09 20:21:38.12 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-21 06:43:16.35 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|machine-learning|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":72,
        "Owner_creation_date":"2016-02-06 08:25:58.427 UTC",
        "Owner_last_access_date":"2022-09-16 20:28:10.967 UTC",
        "Owner_reputation":414,
        "Owner_up_votes":56,
        "Owner_down_votes":17,
        "Owner_views":159,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"California, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72566227",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67065023,
        "Question_title":"Max R version of Machine Learning Server",
        "Question_body":"<p>Having used <a href=\"https:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/sql-server-machine-learning-services?view=sql-server-ver15\" rel=\"nofollow noreferrer\">SQL Server Machine Learning Services<\/a> and realised that it only supports R up to version 3.5.2, I am exploring options to be able to deploy models for later versions of R. The experts (or more like sales people) at Microsoft told me about <a href=\"https:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/what-is-machine-learning-server\" rel=\"nofollow noreferrer\">Machine Learning Server<\/a>. However, I am suspicious that it has similar issues as:<\/p>\n<blockquote>\n<p>R support is built on a legacy of Microsoft R Server 9.x and Revolution R Enterprise products.<\/p>\n<\/blockquote>\n<p>I am pretty sure that this implies the same as above reg. the max R version (i.e. 3.5.2). Can someone confirm this please? I did many searches but could not find a definite answer.<\/p>\n<p>I know this is looking for an opinion and people will vote for closure, but I reckon containerisation is the only way forward to avoid issues like the above?<\/p>\n<p>Thanks!<\/p>\n<p>PS:<\/p>\n<p>I just installed Machine Learning Server version 9.4.7 as detailed here:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/install\/machine-learning-server-windows-install#howtoinstall\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/install\/machine-learning-server-windows-install#howtoinstall<\/a><\/p>\n<p>If I run:<\/p>\n<pre><code>R.Version()\n<\/code><\/pre>\n<p>I get:<\/p>\n<p>$version.string\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/sql-server-machine-learning-services?view=sql-server-ver15\" rel=\"nofollow noreferrer\">1<\/a> &quot;R version 3.5.2 (2018-12-20)&quot;<\/p>\n<p>I was told by Microsoft that it should be version 4.x. Maybe I am just thick. Can I upgrade to version 4.x.x and if so how please? Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-12 20:07:08.743 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-04-15 14:34:03.43 UTC",
        "Question_score":1,
        "Question_tags":"r|sql-server|azure|azure-machine-learning-service",
        "Question_view_count":58,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Somewhere",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67065023",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64137409,
        "Question_title":"How can I create an Azure dataset in Azure ML studio (through the GUI) from a parquet file created with Azure Spark",
        "Question_body":"<p>I'm trying to load files as a dataset in the GUI of Azure ML Studio. These parquet files have been created through Spark.<\/p>\n<p>In my folder, Spark creates files such as &quot;_SUCCESS&quot; or &quot;_committed_8998000&quot;.<\/p>\n<p>Azure ML Studio is not able to read them or ignore them and tells me:<\/p>\n<pre><code>The provided file(s) have invalid byte(s) for the specified file encoding.\n{\n  &quot;message&quot;: &quot; &quot;\n}\n<\/code><\/pre>\n<p>I selected &quot;Ignore unmatched files path&quot; and yet, it still does not work.<\/p>\n<p>If I remove the &quot;_SUCCESS&quot; and other Spark files, it works.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-30 12:18:12.143 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure|apache-spark|parquet|azure-machine-learning-studio",
        "Question_view_count":178,
        "Owner_creation_date":"2015-02-11 07:34:40.283 UTC",
        "Owner_last_access_date":"2022-09-23 14:32:37.963 UTC",
        "Owner_reputation":457,
        "Owner_up_votes":19,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Answer_body":"<p>Thanks for the feedback. You can use globing in path. e.g. path = '**\/*.parquet' to select only the parquet files<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-09-30 16:39:04.07 UTC",
        "Answer_score":2.0,
        "Owner_location":"Lyon, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64137409",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61324600,
        "Question_title":"Second `ParallelRunStep` in pipeline times out at start",
        "Question_body":"<p>Im trying to run a sequence of more than one <code>ParallelRunStep<\/code> in an AzureML pipeline. To do so, I create a step with the following helper:<\/p>\n\n<pre><code>def create_step(name, script, inp, inp_ds):\n    out = pip_core.PipelineData(name=f\"{name}_out\", datastore=dstore, is_directory=True)\n    out_ds = out.as_dataset()\n    out_ds_named = out_ds.as_named_input(f\"{name}_out\")\n\n    config = cont_steps.ParallelRunConfig(\n        source_directory=\"src\",\n        entry_script=script,\n        mini_batch_size=\"1\",\n        error_threshold=0,\n        output_action=\"summary_only\",\n        compute_target=compute_target,\n        environment=component_env,\n        node_count=2,\n        logging_level=\"DEBUG\"\n    )\n\n    step = cont_steps.ParallelRunStep(\n        name=name,\n        parallel_run_config=config,\n        inputs=[inp_ds],\n        output=out,\n        arguments=[],\n        allow_reuse=False,\n    )\n\n    return step, out, out_ds_named\n<\/code><\/pre>\n\n<p>As an example I create two steps like this<\/p>\n\n<pre><code>step1, out1, out1_ds_named = create_step(\"step1\", \"demo_s1.py\", input_ds, named_input_ds)\nstep2, out2, out2_ds_named = create_step(\"step2\", \"demo_s2.py\", out1, out1_ds_named)\n<\/code><\/pre>\n\n<p>Creating an experiment and submitting it to an existing workspace and Azure ML compute cluster works. Also the first step <code>step1<\/code> uses the <code>input_ds<\/code> runs its script <code>demo_s1.py<\/code> (which produces its output files, and finishes successfully. <\/p>\n\n<p>However the second step <code>step2<\/code> never get started. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/JPnPI.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/JPnPI.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And there is a final exception<\/p>\n\n<pre><code>The experiment failed. Finalizing run...\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n2 items cleaning up...\nCleanup took 0.16968441009521484 seconds\nStarting the daemon thread to refresh tokens in background for process with pid = 394\nTraceback (most recent call last):\n  File \"driver\/amlbi_main.py\", line 52, in &lt;module&gt;\n    main()\n  File \"driver\/amlbi_main.py\", line 44, in main\n    JobStarter().start_job()\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/mounts\/workspaceblobstore\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/driver\/job_starter.py\", line 48, in start_job\n    job.start()\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/mounts\/workspaceblobstore\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/driver\/job.py\", line 70, in start\n    master.start()\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/mounts\/workspaceblobstore\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/driver\/master.py\", line 174, in start\n    self._start()\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/mounts\/workspaceblobstore\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/driver\/master.py\", line 149, in _start\n    self.wait_for_input_init()\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/pipeline\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/mounts\/workspaceblobstore\/azureml\/08a1e1e1-7c3f-4c5a-84ad-ca99b8a6cb31\/driver\/master.py\", line 124, in wait_for_input_init\n    raise exc\nexception.FirstTaskCreationTimeout: Unable to create any task within 600 seconds.\nLoad the datasource and read the first row locally to see how long it will take.\nSet the advanced argument '--first_task_creation_timeout' to a larger value in arguments in ParallelRunStep.\n\n<\/code><\/pre>\n\n<p>I have the impression, that the second step is waiting for some data. However the first step creates the supplied output directory and also a file. <\/p>\n\n<pre><code>import argparse\nimport os\n\ndef init():\n    pass\n\ndef run(parallel_input):\n    print(f\"*** Running {os.path.basename(__file__)} with input {parallel_input}\")\n\n    parser = argparse.ArgumentParser(description=\"Data Preparation\")\n    parser.add_argument('--output', type=str, required=True)\n    args, unknown_args = parser.parse_known_args()\n\n    out_path = os.path.join(args.output, \"1.data\")\n    os.makedirs(args.output, exist_ok=True)\n    open(out_path, \"a\").close()\n\n    return [out_path]\n<\/code><\/pre>\n\n<p>I have no idea how to debug further. Has anybody an idea?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2020-04-20 14:13:15.177 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":287,
        "Owner_creation_date":"2009-07-24 11:35:14.983 UTC",
        "Owner_last_access_date":"2022-03-09 06:40:42.81 UTC",
        "Owner_reputation":1269,
        "Owner_up_votes":76,
        "Owner_down_votes":10,
        "Owner_views":194,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Ulm, Deutschland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61324600",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42097946,
        "Question_title":"Azure Machine Learning in dynamics",
        "Question_body":"<p>I just started to work with Azure Machine Learning using Microsoft Azure Machine Learning Studio.<\/p>\n\n<p>Could you please advise the proper way of using Classification Model so that the Model can analyze the window\/interval with series of information before it reaches the target\/class which should be predicted further on by Model?<\/p>\n\n<p>Our problem could be solved only by analyzing all the previous information in it's dynamic\/evolution (e.g. depending on the dynamical change of the Patient's medical results it could be found out some sickness including it's current stage and the stage which we could expect in medium term).<\/p>\n\n<p>For example in an input file we do not provide in each row together with the variables the target info, it is shown only at the row\/moment when the situation is matured to reach such target.  <\/p>\n\n<p>If it is already available some materials\/tutorials on this subject in Azure ML or somewhere else I would highly appreciate such info and links.<\/p>\n\n<p>Thanks in advance for your kind support!<\/p>\n\n<p>Best regards,\nBerik<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-07 19:07:12.343 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":87,
        "Owner_creation_date":"2017-02-07 18:28:54.547 UTC",
        "Owner_last_access_date":"2017-02-23 09:12:35.727 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42097946",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51940106,
        "Question_title":"What is the best practice to develop CD\/CI when you use ML studio APIs?",
        "Question_body":"<p>In our backend development process, we have two environments: testing and production. We develop our code, and then we push the code into the testing repository. Then on the release date, we push everything into production. <\/p>\n\n<p>Now that we are going to use ML studio, I'm struggling with setting up testing and production environments for my ML studio experiments.<\/p>\n\n<p>I created two identical experiments with independent APIs; one experiment for testing and the other experiment is used by the production. When it comes to moving the trained experiment from testing to production, I make all the changes I made in the testing environment to the production environment, which is a very time demanding process. <\/p>\n\n<p>Do you know any better solution so we can deploy and test our changes and then deploy the latest changes to the production? How people use ML studio in their CD\/CI process?<\/p>\n\n<p>The attached image shows the design that I have now. I'd appreciate if you can help me in improving this process. Maybe ML studio has some features to manage this scenario that I don't know.<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/eBcuP.jpg\" alt=\"\"><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-08-21 00:33:31.857 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-08-21 03:35:00.183 UTC",
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|ml-studio",
        "Question_view_count":51,
        "Owner_creation_date":"2017-07-27 00:12:26.137 UTC",
        "Owner_last_access_date":"2020-11-19 13:36:00.497 UTC",
        "Owner_reputation":37,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51940106",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73138388,
        "Question_title":"Please set the default workspace with MLClient",
        "Question_body":"<p>Getting error &quot;Please set the default workspace with MLClient&quot;. How do I set the default workspace with MLClient? Trying to use data asset\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-data-assets?tabs=Python-SDK\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-data-assets?tabs=Python-SDK<\/a><\/p>\n<pre><code>from azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\nfrom azure.ai.ml import MLClient\n\n#Enter details of your AzureML workspace\nsubscription_id = &quot;&lt;SUBSCRIPTION_ID&gt;&quot;\nresource_group = &quot;&lt;RESOURCE_GROUP&gt;&quot;\nworkspace = &quot;&lt;AZUREML_WORKSPACE_NAME&gt;&quot;\nml_client = MLClient(subscription_id, resource_group, workspace)\ndata_location='path'\n\nmy_data = Data(\n    path=data_loacation,\n    type=AssetTypes.URI_FOLDER,\n    description=&quot;Data&quot;,\n    name=&quot;Data_test&quot;)\n\nml_client.data.create_or_update(my_data)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-27 12:57:12.167 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-27 13:18:32.743 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":167,
        "Owner_creation_date":"2020-11-30 17:06:44.663 UTC",
        "Owner_last_access_date":"2022-08-31 08:48:49.383 UTC",
        "Owner_reputation":49,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73138388",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71407308,
        "Question_title":"Azure ML model to a container instance, call to the model fails when using the code provided in the \"Consume\" section of the endpoint (Python and C#)",
        "Question_body":"<p>After deploying an Azure ML model to a container instance, call to the model fails when using the code provided in the &quot;Consume&quot; section of the endpoint (Python and C#).<\/p>\n<p>I have trained a model in Azure Auto-ML and deployed the model to a container instance.<\/p>\n<p><strong>Now when I am try to use the Python code provided in the Endpoint's &quot;Consume&quot; section I get the following error:<\/strong><\/p>\n<pre><code>The request failed with status code: 502\nContent-Length: 55\nContent-Type: text\/html; charset=utf-8\nDate: Mon, 07 Mar 2022 12:32:07 GMT\nServer: nginx\/1.14.0 (Ubuntu)\nX-Ms-Request-Id: 768c2eb5-10f3-4e8a-9412-3fcfc0f6d648\nX-Ms-Run-Function-Failed: True\nConnection: close\n\n---------------------------------------------------------------------------\nJSONDecodeError Traceback (most recent call last)\n&lt;ipython-input-1-6eeff158e915&gt; in &lt;module&gt;\n48 # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n49 print(error.info())\n---&gt; 50 print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/init.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\n352 parse_int is None and parse_float is None and\n353 parse_constant is None and object_pairs_hook is None and not kw):\n--&gt; 354 return _default_decoder.decode(s)\n355 if cls is None:\n356 cls = JSONDecoder\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in decode(self, s, _w)\n337\n338 &quot;&quot;&quot;\n--&gt; 339 obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n340 end = _w(s, end).end()\n341 if end != len(s):\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in raw_decode(self, s, idx)\n355 obj, end = self.scan_once(s, idx)\n356 except StopIteration as err:\n--&gt; 357 raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None\n358 return obj, end\n\nJSONDecodeError: Expecting value: line 1 column 1 (char 0)\n<\/code><\/pre>\n<p><strong>If I use C# code provided in the Endpoint's &quot;Consume&quot; section I get the following error:<\/strong><\/p>\n<pre><code>The request failed with status code: BadGateway\nConnection: keep-alive\nX-Ms-Request-Id: 5c3543cf-29ac-46a3-a9fb-dcb6a0041b08\nX-Ms-Run-Function-Failed: True\nDate: Mon, 07 Mar 2022 12:38:32 GMT\nServer: nginx\/1.14.0 (Ubuntu)\n\n'&lt;=' not supported between instances of 'str' and 'int'\n<\/code><\/pre>\n<p><strong>The Python code I am using:<\/strong><\/p>\n<pre><code> import urllib.request\n import json\n import os\n import ssl\n    \n def allowSelfSignedHttps(allowed):\n     # bypass the server certificate verification on client side\n     if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n         ssl._create_default_https_context = ssl._create_unverified_context\n    \n allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n    \n data = {\n     &quot;Inputs&quot;: {\n         &quot;data&quot;:\n         [\n             {\n                 &quot;SaleDate&quot;: &quot;2022-02-08T00:00:00.000Z&quot;,\n                 &quot;OfferingGroupId&quot;: &quot;0&quot;,\n                 &quot;week_of_year&quot;: &quot;7&quot;,\n                 &quot;month_of_year&quot;: &quot;2&quot;,\n                 &quot;day_of_week&quot;: &quot;1&quot;\n             },\n         ]\n     },\n     &quot;GlobalParameters&quot;: {\n         &quot;quantiles&quot;: &quot;0.025,0.975&quot;\n     }\n }\n    \n body = str.encode(json.dumps(data))\n    \n url = 'http:\/\/4a0427c2-30d4-477e-85f5-dfdfdfdfdsfdff623f.uksouth.azurecontainer.io\/score'\n api_key = '' # Replace this with the API key for the web service\n headers = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}\n    \n req = urllib.request.Request(url, body, headers)\n    \n try:\n     response = urllib.request.urlopen(req)\n    \n     result = response.read()\n     print(result)\n except urllib.error.HTTPError as error:\n     print(&quot;The request failed with status code: &quot; + str(error.code))\n    \n     # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n     print(error.info())\n     print(json.loads(error.read().decode(&quot;utf8&quot;, 'ignore')))\n<\/code><\/pre>\n<p><strong>The C# code I have tried<\/strong>:<\/p>\n<pre><code> using System;\n using System.Collections.Generic;\n using System.IO;\n using System.Net.Http;\n using System.Net.Http.Headers;\n using System.Text;\n using System.Threading.Tasks;\n using Newtonsoft.Json;\n    \n namespace MLModelAPICall\n {\n     class Program\n     {\n         static void Main(string[] args)\n         {\n             InvokeRequestResponseService().Wait();\n         }\n    \n         static async Task InvokeRequestResponseService()\n         {\n             var handler = new HttpClientHandler()\n             {\n                 ClientCertificateOptions = ClientCertificateOption.Manual,\n                 ServerCertificateCustomValidationCallback =\n                         (httpRequestMessage, cert, cetChain, policyErrors) =&gt; { return true; }\n             };\n             using (var client = new HttpClient(handler))\n             {\n                 \/\/ Request data goes here\n                 var scoreRequest = new\n                 {\n                     Inputs = new Dictionary&lt;string, List&lt;Dictionary&lt;string, string&gt;&gt;&gt;()\n                     {\n                         {\n                             &quot;data&quot;,\n                             new List&lt;Dictionary&lt;string, string&gt;&gt;()\n                             {\n                                 new Dictionary&lt;string, string&gt;()\n                                 {\n                                     {\n                                         &quot;SaleDate&quot;, &quot;2022-02-08T00:00:00.000Z&quot;\n                                     },\n                                     {\n                                         &quot;OfferingGroupId&quot;, &quot;0&quot;\n                                     },\n                                     {\n                                         &quot;week_of_year&quot;, &quot;7&quot;\n                                     },\n                                     {\n                                         &quot;month_of_year&quot;, &quot;2&quot;\n                                     },\n                                     {\n                                         &quot;day_of_week&quot;, &quot;1&quot;\n                                     }\n                                 }\n                             }\n                         }\n                     },\n                     GlobalParameters = new Dictionary&lt;string, string&gt;()\n                     {\n                         {\n                             &quot;quantiles&quot;, &quot;0.025,0.975&quot;\n                         }\n                     }\n                 };\n    \n    \n                 const string apiKey = &quot;&quot;; \/\/ Replace this with the API key for the web service\n                 client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(&quot;Bearer&quot;, apiKey);\n                 client.BaseAddress = new Uri(&quot;http:\/\/4a0427c2-30d4-477e-85f5-xxxxxxxxxxxxx.uksouth.azurecontainer.io\/score&quot;);\n    \n                 \/\/ WARNING: The 'await' statement below can result in a deadlock\n                 \/\/ if you are calling this code from the UI thread of an ASP.Net application.\n                 \/\/ One way to address this would be to call ConfigureAwait(false)\n                 \/\/ so that the execution does not attempt to resume on the original context.\n                 \/\/ For instance, replace code such as:\n                 \/\/      result = await DoSomeTask()\n                 \/\/ with the following:\n                 \/\/      result = await DoSomeTask().ConfigureAwait(false)\n    \n                 var requestString = JsonConvert.SerializeObject(scoreRequest);\n                 var content = new StringContent(requestString);\n    \n                 content.Headers.ContentType = new MediaTypeHeaderValue(&quot;application\/json&quot;);\n    \n                 HttpResponseMessage response = await client.PostAsync(&quot;&quot;, content);\n    \n                 if (response.IsSuccessStatusCode)\n                 {\n                     string result = await response.Content.ReadAsStringAsync();\n                     Console.WriteLine(&quot;Result: {0}&quot;, result);\n                 }\n                 else\n                 {\n                     Console.WriteLine(string.Format(&quot;The request failed with status code: {0}&quot;, response.StatusCode));\n    \n                     \/\/ Print the headers - they include the requert ID and the timestamp,\n                     \/\/ which are useful for debugging the failure\n                     Console.WriteLine(response.Headers.ToString());\n    \n                     string responseContent = await response.Content.ReadAsStringAsync();\n                     Console.WriteLine(responseContent);\n                     Console.ReadLine();\n                 }\n             }\n         }\n     }\n }\n<\/code><\/pre>\n<p>Could you please help me with this issue? I am not sure what do to if Microsoft's provided code is erroring out, don't know what else to do.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-09 09:47:27.667 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":89,
        "Owner_creation_date":"2013-02-04 21:33:28.22 UTC",
        "Owner_last_access_date":"2022-09-23 11:51:21.363 UTC",
        "Owner_reputation":65842,
        "Owner_up_votes":1661,
        "Owner_down_votes":333,
        "Owner_views":4569,
        "Answer_body":"<p>After much more digging I found out that the &quot;Consume&quot; scripts provided with the endpoint are wrong (Python and C#) .<\/p>\n<p>When making a call to the endpoint the GlobalParameters expects an integer value, but the provided scripts have wrapped the values in double quotes hence making it a string:<\/p>\n<pre><code> },\n &quot;GlobalParameters&quot;: {\n     &quot;quantiles&quot;: &quot;0.025,0.975&quot;\n }\n<\/code><\/pre>\n<p>If you are using Python to consume the model, when making call to the endpoint your GlobalParameters should be define as this:<\/p>\n<pre><code> },\n &quot;GlobalParameters&quot;: {\n     &quot;quantiles&quot;: [0.025,0.975]\n }\n<\/code><\/pre>\n<p>wrapped in square brackets<\/p>\n<blockquote>\n<p>[0.025,0.975]<\/p>\n<\/blockquote>\n<p>and not in double quotes &quot;<\/p>\n<blockquote>\n<p><em>I have also opened a ticket with microsoft so hopefully they will fix the code provided in the &quot;consume&quot; section of every endpoint<\/em><\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-03-09 14:14:58.18 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bolton, United Kingdom",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71407308",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58203287,
        "Question_title":"Using `inference_schema.schema_decorators` with dynamic `numpy` array shape",
        "Question_body":"<p><strong>Question summary<\/strong><\/p>\n\n<p>I'm deploying a model to an Azure Container Instance, using the Azure Machine Learning Service API. Specifically, the model is a PyTorch (fastai) model classifying images of varying shapes.<\/p>\n\n<p>Microsoft provides some nice decoraters to handle input and output data schemas in the scoring script. However, I am unable to figure out, if it's possible to use the <code>NumpyParameterType<\/code> with dynamic shape for the input.<\/p>\n\n<p><strong>Scoring script<\/strong><\/p>\n\n<p>A sample of the scoring script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pickle\nimport json\nimport numpy as np\nimport time\nimport os\n\nfrom PIL import Image as PilImage\nfrom azureml.core.model import Model\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef preprocess_inference(img):\n    # Preprocessing handled here\n\ndef make_prediction(data_preprocessed):\n    # Model prediction handled here\n\ndef init():\n    global model\n\n    model_path = Model.get_model_path(model_name='my_pytorch_model',\n                                      version=1)\n\n    # Get paths\n    split_path = model_path.split('\/')\n\n    model = fastai.load_learner(path = '\/'.join(split_path[:-1]), file = split_path[-1])\n\n# How to use the schema decoraters with dynamic size?\ninput_sample = np.array(PilImage.open('src\/deployment\/test\/test_image.png'))\noutput_sample = np.array([0, None], dtype=np.object)\n\n@input_schema('raw_data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\ndef run(raw_data):\n\n    try:\n\n        data_preprocessed = preprocess_inference(raw_data)\n\n        prediction = make_prediction(data_preprocessed)\n\n        return prediction\n\n    except Exception as e:\n        error = str(e)\n        print (error + time.strftime(\"%H:%M:%S\"))\n        return error\n\n<\/code><\/pre>\n\n<p>Which only works if the image uploaded has the exact same shape as 'src\/deployment\/test\/test_image.png'. Right now my solution is to avoid the decoraters and do the data interpretation myself.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>\ndef run(raw_data):\n\n    try:\n\n        img = np.array(json.loads(raw_data)['raw_data'], dtype=np.uint8)\n        img = np.expand_dims(img, axis=2)\n\n        data_preprocessed = preprocess_inference(img)\n\n        prediction = make_prediction(data_preprocessed)\n\n        return prediction\n\n    except Exception as e:\n        error = str(e)\n        print (error + time.strftime(\"%H:%M:%S\"))\n        return error\n\n<\/code><\/pre>\n\n<p>But it would be nice to be able to use the decorators, such that endusers can benefit from the nice warning messages as well.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-02 14:11:24.313 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":971,
        "Owner_creation_date":"2013-08-22 07:20:04.257 UTC",
        "Owner_last_access_date":"2019-10-15 07:09:47.553 UTC",
        "Owner_reputation":26,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58203287",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34335483,
        "Question_title":"Uniquely identify instances of VMs (Azure ML - web services)",
        "Question_body":"<p>I'm posting this more as a 'probe' question and plan to expand the discussion in case some interest shows up. The reason behind this is that in my experience, the SO community on <code>azure-ml<\/code> (and related) is still developing and there is not much feedback - but I would be happy to help it grow stronger. <\/p>\n\n<p>My situation is as follows: I have an experiment in Azure ML which does all its work inside an <code>R<\/code> module. I published this as a web service and set the 'max concurrent calls' slider to 10 - which I believe guarantees me that there will be at most 10 instances of my web service up and running at any time, to serve requests (please correct me if i am wrong). <\/p>\n\n<p>Now, I am trying to do some performance testing by firing 10 parallel calls to my webservice, but get unexpected results...<\/p>\n\n<p>I am trying to run the load tests and log where each of them actually goes to (which instance). My idea is to get a glimpse into how these calls are actually distributed to the instances by the load balancer, under certain max number of concurrent calls = X. I am doing this by firing a call to \"bot.whatismyipaddress.com\" from inside the <code>R<\/code> script. Here is the important snip of the code:<\/p>\n\n<pre><code>library(rjson)\nmachine.ip &lt;- readLines(\"http:\/\/bot.whatismyipaddress.com\/\", warn=F)\nresult$MachineIP &lt;- machine.ip\n<\/code><\/pre>\n\n<p>Additionally, I am using the sample <code>R<\/code> code from the web service RRS help page to fire up to 70 (sequential) calls to my web service. This sample code returns some info back to the console : the results of my web service as well as some info on to which hostname the call goes through. Here is a sample :<\/p>\n\n<pre><code>* Hostname was NOT found in DNS cache\n*   Trying 40.114.242.9...\n* Connected to europewest.services.azureml.net (40.114.242.9) port 443 (#0)\n<\/code><\/pre>\n\n<p>The difficulty that I am facing is that I cannot <strong>uniquely identify<\/strong> the different instances of my web service. The info out to console from the call (the second snippet) often shows a different IP address than the one from inside-<code>R<\/code>-code logs (<code>result$MachineIP<\/code>)...<\/p>\n\n<p>Can someone point out what am i doing wrong, and how could i uniquely identify the different instances that are serving the calls? Any help would be really appreciated. Thanks!<\/p>\n\n<p>P.S. I've tried <a href=\"https:\/\/stackoverflow.com\/questions\/14357219\/function-for-retrieving-own-ip-address-from-within-r\">this<\/a> as well, but the first apporach does not work when calling it from inside the <code>R<\/code> script and I'm using a modified version of the second apporach (the one suggested there does not work). <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/93f07abf-f0ec-4baa-8225-1ca1a072ca2d\/system-call-from-inside-r-script-does-not-work?forum=MachineLearning\" rel=\"nofollow noreferrer\">Here<\/a> are also my <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/ee6ff5a6-2995-4f3f-b4db-0229b1d9d1d3\/lifetime-of-azure-ml-web-service-container?forum=MachineLearning\" rel=\"nofollow noreferrer\">questions<\/a> on the Azure forum, in case someone is interested.<\/p>\n\n<p>If anyone could help or point me to some source of info I would be really grateful! <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-12-17 13:13:29.79 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-05-23 11:51:59.593 UTC",
        "Question_score":1,
        "Question_tags":"r|web-services|azure|azure-machine-learning-studio",
        "Question_view_count":61,
        "Owner_creation_date":"2015-05-28 16:10:15.467 UTC",
        "Owner_last_access_date":"2018-11-18 20:44:24.587 UTC",
        "Owner_reputation":501,
        "Owner_up_votes":184,
        "Owner_down_votes":0,
        "Owner_views":76,
        "Answer_body":"<p>This question was resolved thanks to some people on the Azure ML forum so \nI'm going to post an answer for anyone landing here in search for some answers...<\/p>\n\n<p>The short answer is no, this is not possible. The more detailed version is:<br>\n\"From within the R script you cannot identify the internal AzureML IP addresses or the unique web service instances. When you make an external network call from the R script to an outside URL, that URL will see one of the AzureML public virtual IP's as the source IP. These are IP's of the load balancers, and not of the machines that are physically running the web service. AzureML dynamically allocates the instances of R engine in the backend, handles failures, and uses multiple nodes for running the web service for high availability. The exact layout of these for a given web service is not programmatically discoverable.\"<br>\nHere is also the <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/dd1f0658-7b0b-46d8-8e32-3fe4e96ec4be\/uniquely-identify-instances-of-vms-web-services?forum=MachineLearning#cde28631-828d-4d83-9c93-1a1cf0dfb6fb\" rel=\"nofollow\">link<\/a> to the original discussion. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-01-08 09:07:08.967 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34335483",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60752300,
        "Question_title":"Matchbox recommender in azure machine learning workspace",
        "Question_body":"<p>The matchbox recommender available in <a href=\"http:\/\/studio.azureml.net\" rel=\"nofollow noreferrer\">http:\/\/studio.azureml.net<\/a> doesn't seem to have a counterpart in <a href=\"http:\/\/ml.azure.com\" rel=\"nofollow noreferrer\">http:\/\/ml.azure.com<\/a> (which it appears is the newer portal for azure ml). Here only the plain SVD recommender is available, which doesn't take user or item features. This is a feature takeaway from the matchbox.<\/p>\n\n<p>Is there an ETA when matchbox would be made available in the azure machine learning services? Either via SDK or designer.\nThanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-19 07:03:07.617 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":189,
        "Owner_creation_date":"2019-11-05 04:45:11.23 UTC",
        "Owner_last_access_date":"2021-11-25 09:34:42.707 UTC",
        "Owner_reputation":63,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60752300",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42010405,
        "Question_title":"The way to pass input for azure machine experiment from app ( for example console app )",
        "Question_body":"<p>I'm trying to do some kind of web job application that can run for period time and make prediction on azure machine learning studio. After that i want get the result of this experiment and do something with that in my console application. What is the best way to do this in azure with machine learning or maybe some similiar stuff to prediction data from data series ? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-02 19:08:28.683 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|prediction|azure-machine-learning-studio",
        "Question_view_count":62,
        "Owner_creation_date":"2015-05-20 17:04:26.93 UTC",
        "Owner_last_access_date":"2020-06-04 15:43:22.75 UTC",
        "Owner_reputation":327,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":78,
        "Answer_body":"<p>You can try using Azure Data Factory to create a Machine Learning pipeline or use Azure ML Studio's Predictive Web Services.<\/p>\n\n<ol>\n<li><p>With Azure Data Factory\nFollow <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/data-factory\/data-factory-azure-ml-batch-execution-activity\" rel=\"nofollow noreferrer\">this link<\/a> for details. Azure Data Factory implementations would seem difficult at first but they do work great with Azure ML experiments. <\/p>\n\n<p>Azure Data Factory can run your ML Experiment on a schedule or one-off at a specified time (I guess you can set only for UTC Timezone right now) and monitor it through a dashboard (which is pretty cool).<\/p>\n\n<p>As an example you can look @ <a href=\"https:\/\/github.com\/Microsoft\/azure-docs\/blob\/master\/articles\/data-factory\/data-factory-azure-ml-batch-execution-activity.md\" rel=\"nofollow noreferrer\">ML Batch Execution<\/a>. I used this in one of our implementations (we do have latency issues, but trying to solve that).<\/p><\/li>\n<li><p>If you directly want to use the experiment in your console (assuming it is a web application), use create a Predictive Web service out of your ML Experiment, details <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-walkthrough-5-publish-web-service\" rel=\"nofollow noreferrer\">here<\/a><\/p><\/li>\n<\/ol>\n\n<p>I couldn't exactly understand your use case so I posted two alternatives that should help you. Hope this might lead you to a better solution\/approach.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-02-08 06:58:00.117 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2017-02-08 07:03:37.793 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42010405",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64358636,
        "Question_title":"Azure ML pipeline runs slowly due to AppInsights",
        "Question_body":"<p>I have set up an Azure ML pipeline with a single Python script step. Provided that the compute has already been spun up, initially the pipeline took around 2 minutes with an <code>executionlogs.txt<\/code> like so:<\/p>\n<pre><code>[2020-09-23 22:36:14Z] Experiment: &lt;EXPERIMENT&gt;\n[2020-09-23 22:36:14Z] Run Id:     &lt;RUN_ID&gt;\n[2020-09-23 22:36:14Z] Run target: &lt;RUN_TARGET&gt;\n[2020-09-23 22:36:14Z] Starting run in Execution Service\n[2020-09-23 22:36:17Z] RunId:[&lt;RUN_ID&gt;] ParentRunId:[&lt;PARENT_RUN_ID&gt;] ComputeTarget:[AmlCompute]\n[2020-09-23 22:36:19Z] Job is running, job runstatus is Queued\n[2020-09-23 22:36:30Z] Job is running, job runstatus is Running\n[2020-09-23 22:38:19Z] Job is running, job runstatus is Running\n[2020-09-23 22:38:31Z] Job is running, job runstatus is Finalizing\n[2020-09-23 22:38:40Z] Job finished, job RunId is &lt;RUN_ID&gt;\n<\/code><\/pre>\n<p>Now, with the same spun-up compute and code, I'm finding a run time that is 3 times larger:<\/p>\n<pre><code>[2020-10-14 17:14:23Z] Experiment: &lt;EXPERIMENT&gt;\n[2020-10-14 17:14:23Z] Run Id:     &lt;RUN_ID&gt;\n[2020-10-14 17:14:23Z] Run target: &lt;RUN_TARGET&gt;\n[2020-10-14 17:14:23Z] Starting run in Execution Service\n[2020-10-14 17:14:26Z] RunId:[&lt;RUN_ID&gt;] ParentRunId:[&lt;PARENT_RUN_ID&gt;] ComputeTarget:[AmlCompute]\n[2020-10-14 17:14:31Z] Job is running, job runstatus is Queued\n[2020-10-14 17:14:40Z] Job is running, job runstatus is Running\n[2020-10-14 17:16:26Z] Job is running, job runstatus is Running\n[2020-10-14 17:18:27Z] Job is running, job runstatus is Running\n[2020-10-14 17:19:08Z] Job is running, job runstatus is Finalizing\n[2020-10-14 17:20:28Z] Job is running, job runstatus is Finalizing\n[2020-10-14 17:21:10Z] Job finished, job RunId is &lt;RUN_ID&gt;\n<\/code><\/pre>\n<p>Even 'Finalize' to 'Finish' takes over 2 minutes now! The run times for <code>70_driver_log.txt<\/code> are similar for both runs.<\/p>\n<p>I identified a difference in the <code>55_azureml-execution-tvmps_....txt<\/code> log. My slow runs contain the following line related to application insights:<\/p>\n<pre><code>appinsightlogger.go:42: Time Out after 20 second retries for flushing the logs, doing another retry before exiting\n<\/code><\/pre>\n<p>How can I fix this?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2020-10-14 17:33:18.58 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-10-14 21:36:56.277 UTC",
        "Question_score":1,
        "Question_tags":"azure-application-insights|azure-machine-learning-service",
        "Question_view_count":222,
        "Owner_creation_date":"2020-05-17 18:00:51.347 UTC",
        "Owner_last_access_date":"2022-06-27 19:36:47.687 UTC",
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64358636",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40337201,
        "Question_title":"scikit-learn SGDClassifier object of type 'NoneType' has no len()",
        "Question_body":"<p>I am just trying out training a simple logistic regression model using SGD in python in Azure ML, but when I run the code it keep getting an error. What is more confusing is that the error shows up in Epoch 8  only and not in any of the epochs. I ll appreciate if anyone and can let me know why I would get an error like this and how to avoid it. I have included the code and error below. <\/p>\n\n<pre><code>from sklearn.linear_model import SGDClassifier\n    #Import data\n    cadd_dir = '.\\\\Script Bundle\\\\theano\\\\data\\\\'\n    ClinVar_ESP_dir = '.\\\\Script Bundle\\\\theano\\\\data\\\\'\n    #load data    \n    X_tr = numpy.load(os.path.join(cadd_dir, 'training.X.npz'))\n    X_tr = scipy.sparse.csr_matrix((X_tr['data'], X_tr['indices'], X_tr['indptr']), shape=X_tr['shape'])\n    y_tr = numpy.load(os.path.join(cadd_dir, 'training.y.npy'))\n    #Train model\n    print('Train SGD Logistic Regression')\n    alpha = 1e-2\n    clf = SGDClassifier(loss=\"log\", penalty='l2', alpha=alpha, random_state=None, shuffle=False, n_iter=10, verbose=1, n_jobs=1)\n    clf.fit(X_tr, y_tr)\n\n\n\n\n#Error\n\"[Information]         -- Epoch 7\n[Information]         Norm: 0.40, NNZs: 641, Bias: 0.000623, T: 186214000, Avg. loss: 0.670200\n[Information]         Total training time: 43.97 seconds.\n\n[Information]         -- Epoch 8\n[Error]         Caught exception while executing function: Traceback (most recent call last):\n[Error]           File \"C:\\server\\invokepy.py\", line 211, in batch\n[Error]             xdrutils.XDRUtils.DataFrameToRFile(outlist[i], outfiles[i], True)\n[Error]           File \"C:\\server\\XDRReader\\xdrutils.py\", line 51, in DataFrameToRFile\n[Error]             attributes = XDRBridge.DataFrameToRObject(dataframe)\n[Error]           File \"C:\\server\\XDRReader\\xdrbridge.py\", line 40, in DataFrameToRObject\n[Error]             if (len(dataframe) == 1 and type(dataframe[0]) is pd.DataFrame):\n[Error]         TypeError: object of type 'NoneType' has no len()\n[Information]         Norm: 0.40, NNZs: 641, Bias: 0.000623, T: 212816000, Avg. loss: 0.669797\n[Information]         Total training time: 50.21 seconds.\n\n[Information]         -- Epoch 9\n[Information]         Norm: 0.40, NNZs: 641, Bias: 0.000622, T: 239418000, Avg. loss: 0.669482\n[Information]         Total training time: 56.46 seconds.\"\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-31 05:51:05.637 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-10-31 13:51:10.857 UTC",
        "Question_score":1,
        "Question_tags":"python-2.7|scikit-learn|azure-machine-learning-studio",
        "Question_view_count":305,
        "Owner_creation_date":"2012-06-04 00:21:56.713 UTC",
        "Owner_last_access_date":"2017-03-14 20:23:24.443 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40337201",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46902487,
        "Question_title":"Installation of Azure Machine Learning Workbench fails on Windows 10",
        "Question_body":"<p>I tried to install the azure machine learning workbench from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/preview\/quickstart-installation\" rel=\"nofollow noreferrer\">here<\/a>. Once I double click on the downloaded MSI file, it shows the first screen about licensing terms. Once I click on Continue, it shows dependencies. When I click Install, it starts installation. It downloads Miniconda with Python 3.5.2. While trying to install asn1crypto 0.23.0, it suddenly stops and displays 'Installation fails'. I tried running the MSI file with log option but no error is reported in the log.<\/p>\n\n<p>Here are my machine details:\nWindows 10\nVersion 1709 (OS Build 17017.1000)<\/p>\n\n<p>How can I troubleshoot this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-10-24 04:54:27.387 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-11-22 00:32:00.17 UTC",
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":497,
        "Owner_creation_date":"2011-08-11 06:01:44.323 UTC",
        "Owner_last_access_date":"2022-09-23 18:22:07.947 UTC",
        "Owner_reputation":2727,
        "Owner_up_votes":45,
        "Owner_down_votes":1,
        "Owner_views":227,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46902487",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72376401,
        "Question_title":"Making predictions with Azure Machine learning with new data that contains headers (like pd.Dataframe)",
        "Question_body":"<p>My question is somehow related to <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html<\/a> - however, the provided solution does not seem to work.<\/p>\n<p>I am constructing a simple model with heart-disease dataset but I wrap it into Pipeline as I use some featurization steps (scaling, encoding etc.) The full script below:<\/p>\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nimport pickle\n\n# data input\ndf = pd.read_csv('heart.csv')\n\n# numerical variables\nnum_cols = ['age',\n            'trestbps',\n            'chol',\n            'thalach',\n            'oldpeak'\n]\n\n# categorical variables\ncat_cols = ['sex',\n            'cp',\n            'fbs',\n            'restecg',\n            'exang',\n            'slope',\n            'ca',\n            'thal']\n\n# changing format of the categorical variables\ndf[cat_cols] = df[cat_cols].apply(lambda x: x.astype('object'))\n\n# target variable\ny = df['target']\n\n# features\nX = df.drop(['target'], axis=1)\n\n# data split:\n\n# random seed\nnp.random.seed(42)\n\n# splitting the data\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.2,\n                                                    stratify=y)\n\n# double check\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n\n# pipeline for numerical data\nnum_preprocessing = Pipeline([('num_imputer', SimpleImputer(strategy='mean')), # imputing with mean\n                                                   ('minmaxscaler', MinMaxScaler())]) # scaling\n\n# pipeline for categorical data\ncat_preprocessing = Pipeline([('cat_imputer', SimpleImputer(strategy='constant', fill_value='missing')), # filling missing values\n                                                ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))]) # One Hot Encoding\n\n# preprocessor - combining pipelines\npreprocessor = ColumnTransformer([\n                                  ('categorical', cat_preprocessing, cat_cols),\n                                  ('numerical', num_preprocessing, num_cols)\n                                                           ])\n\n# initial model parameters\nlog_ini_params = {'penalty': 'l2', \n                  'tol': 0.0073559740277086005, \n                  'C': 1.1592424247511928, \n                  'fit_intercept': True, \n                  'solver': 'liblinear'}\n\n# model - Pipeline\nlog_clf = Pipeline([('preprocessor', preprocessor),\n                  ('clf', LogisticRegression(**log_ini_params))])\n\nlog_clf.fit(X_train, y_train)\n\n# dumping the model\nf = 'model\/log.pkl'\nwith open(f, 'wb') as file:\n    pickle.dump(log_clf, file)\n\n# loading it\nloaded_model = joblib.load(f)\n\n# double check on a single datapoint\nnew_data = pd.DataFrame({'age': 71,\n                         'sex': 0,\n                         'cp': 0,\n                         'trestbps': 112,\n                         'chol': 203,\n                         'fbs': 0,\n                         'restecg': 1,\n                         'thalach': 185,\n                         'exang': 0,\n                         'oldpeak': 0.1,\n                         'slope': 2,\n                         'ca': 0,\n                          'thal': 2}, index=[0])\n\nloaded_model.predict(new_data)\n\n<\/code><\/pre>\n<p>...and it works just fine.  Then I deploy the model to the Azure Web Service using these steps:<\/p>\n<ol>\n<li>I create the score.py file<\/li>\n<\/ol>\n<pre><code>import joblib\nfrom azureml.core.model import Model\nimport json\n\ndef init():\n    global model\n    model_path = Model.get_model_path('log') # logistic\n    print('Model Path is  ', model_path)\n    model = joblib.load(model_path)\n\n\ndef run(data):\n    try:\n        data = json.loads(data)\n        result = model.predict(data['data'])\n        # any data type, as long as it is JSON serializable.\n        return {'data' : result.tolist() , 'message' : 'Successfully classified heart diseases'}\n    except Exception as e:\n        error = str(e)\n        return {'data' : error , 'message' : 'Failed to classify heart diseases'}\n<\/code><\/pre>\n<ol>\n<li>I deploy the model:<\/li>\n<\/ol>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.environment import Environment\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.conda_dependencies import CondaDependencies\n\nws = Workspace.from_config()\n\nmodel = Model.register(workspace = ws,\n              model_path ='model\/log.pkl',\n              model_name = 'log',\n              tags = {'version': '1'},\n              description = 'Heart disease classification',\n              )\n\n# to install required packages\nenv = Environment('env')\ncd = CondaDependencies.create(pip_packages=['pandas==1.1.5', 'azureml-defaults','joblib==0.17.0'], conda_packages = ['scikit-learn==0.23.2'])\nenv.python.conda_dependencies = cd\n\n# Register environment to re-use later\nenv.register(workspace = ws)\nprint('Registered Environment')\n\nmyenv = Environment.get(workspace=ws, name='env')\n\nmyenv.save_to_directory('.\/environ', overwrite=True)\n\naciconfig = AciWebservice.deploy_configuration(\n            cpu_cores=1,\n            memory_gb=1,\n            tags={'data':'heart disease classifier'},\n            description='Classification of heart diseases',\n            )\n\ninference_config = InferenceConfig(entry_script='score.py', environment=myenv)\n\nservice = Model.deploy(workspace=ws,\n                name='hd-model-log',\n                models=[model],\n                inference_config=inference_config,\n                deployment_config=aciconfig, \n                overwrite = True)\n\nservice.wait_for_deployment(show_output=True)\nurl = service.scoring_uri\nprint(url)\n<\/code><\/pre>\n<p>The deployment is fine:<\/p>\n<blockquote>\n<p>Succeeded\nACI service creation operation finished, operation &quot;Succeeded&quot;<\/p>\n<\/blockquote>\n<p>But I can not make any predictions with the new data. I try to use:<\/p>\n<pre><code>import pandas as pd\n\nnew_data = pd.DataFrame([[71, 0, 0, 112, 203, 0, 1, 185, 0, 0.1, 2, 0, 2],\n                         [80, 0, 0, 115, 203, 0, 1, 185, 0, 0.1, 2, 0, 0]],\n                         columns=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'])\n<\/code><\/pre>\n<p>Following the answer from this topic (<a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html<\/a>) I transform the data:<\/p>\n<pre><code>test_sample = json.dumps({'data': new_data.to_dict(orient='records')})\n<\/code><\/pre>\n<p>And try to make some predictions:<\/p>\n<pre><code>import json\nimport requests\ndata = test_sample\nheaders = {'Content-Type':'application\/json'}\nr = requests.post(url, data=data, headers = headers)\nprint(r.status_code)\nprint(r.json())\n<\/code><\/pre>\n<p>However, I encounter an error:<\/p>\n<blockquote>\n<p>200\n{'data': &quot;Expected 2D array, got 1D array instead:\\narray=[{'age': 71, 'sex': 0, 'cp': 0, 'trestbps': 112, 'chol': 203, 'fbs': 0, 'restecg': 1, 'thalach': 185, 'exang': 0, 'oldpeak': 0.1, 'slope': 2, 'ca': 0, 'thal': &gt; 2}\\n {'age': 80, 'sex': 0, 'cp': 0, 'trestbps': 115, 'chol': 203, 'fbs': 0, 'restecg': 1, 'thalach': 185, 'exang': 0, 'oldpeak': 0.1, 'slope': 2, 'ca': 0, 'thal': 0}].\\nReshape your data either using array.reshape(-1, &gt; 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.&quot;, 'message': 'Failed to classify heart diseases'}<\/p>\n<\/blockquote>\n<p>How is it possible to adjust the input data to this form of predictions and add other output like predict_proba so I could store them in a separate output dataset?<\/p>\n<p>I know this error is somehow related either with the &quot;run&quot; part of the score.py file or the last code cell that calls the webservice, but I'm unable to find it.<\/p>\n<p>Would really appreciate some help.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-25 11:00:27.16 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-05-25 19:12:28.283 UTC",
        "Question_score":1,
        "Question_tags":"json|python-3.x|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":280,
        "Owner_creation_date":"2017-12-12 10:30:41.863 UTC",
        "Owner_last_access_date":"2022-09-24 18:54:14.457 UTC",
        "Owner_reputation":155,
        "Owner_up_votes":25,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":"<p>I believe I managed to solve the problem - even though I encountered some serious issues. :)<\/p>\n<ol>\n<li>As described here <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\" rel=\"nofollow noreferrer\">here<\/a> - I edited the <code>score.py<\/code> script:<\/li>\n<\/ol>\n<pre><code>import joblib\nfrom azureml.core.model import Model\nimport numpy as np\nimport json\nimport pandas as pd\nimport numpy as np\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\nfrom inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n    \ndata_sample = PandasParameterType(pd.DataFrame({'age': pd.Series([0], dtype='int64'),\n                                                'sex': pd.Series(['example_value'], dtype='object'),\n                                                'cp': pd.Series(['example_value'], dtype='object'),\n                                                'trestbps': pd.Series([0], dtype='int64'),\n                                                'chol': pd.Series([0], dtype='int64'),\n                                                'fbs': pd.Series(['example_value'], dtype='object'),\n                                                'restecg': pd.Series(['example_value'], dtype='object'),\n                                                'thalach': pd.Series([0], dtype='int64'),\n                                                'exang': pd.Series(['example_value'], dtype='object'),\n                                                'oldpeak': pd.Series([0.0], dtype='float64'),\n                                                'slope': pd.Series(['example_value'], dtype='object'),\n                                                'ca': pd.Series(['example_value'], dtype='object'),\n                                                'thal': pd.Series(['example_value'], dtype='object')}))\n\ninput_sample = StandardPythonParameterType({'data': data_sample})\nresult_sample = NumpyParameterType(np.array([0]))\noutput_sample = StandardPythonParameterType({'Results':result_sample})\n\ndef init():\n    global model\n    # Example when the model is a file\n    model_path = Model.get_model_path('log') # logistic\n    print('Model Path is  ', model_path)\n    model = joblib.load(model_path)\n\n@input_schema('Inputs', input_sample)\n@output_schema(output_sample)\ndef run(Inputs):\n    try:\n        data = Inputs['data']\n        result = model.predict_proba(data)\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<ol start=\"2\">\n<li>In the deployment step I adjusted the <code>CondaDependencies<\/code>:<\/li>\n<\/ol>\n<pre><code># to install required packages\nenv = Environment('env')\ncd = CondaDependencies.create(pip_packages=['pandas==1.1.5', 'azureml-defaults','joblib==0.17.0', 'inference-schema==1.3.0'], conda_packages = ['scikit-learn==0.22.2.post1'])\nenv.python.conda_dependencies = cd\n# Register environment to re-use later\nenv.register(workspace = ws)\nprint('Registered Environment')\n<\/code><\/pre>\n<p>as<\/p>\n<p>a) It is necessary to include <code>inference-schema<\/code> in the <code>Dependencies<\/code> file\nb) I downgraded <code>scikit-learn<\/code> to <code>scikit-learn==0.22.2.post1<\/code> version because of <a href=\"https:\/\/github.com\/hyperopt\/hyperopt\/issues\/668\" rel=\"nofollow noreferrer\">this issue<\/a><\/p>\n<p>Now, when I feed the model with new data:<\/p>\n<pre><code>new_data = {\n  &quot;Inputs&quot;: {\n    &quot;data&quot;: [\n      {\n        &quot;age&quot;: 71,\n        &quot;sex&quot;: &quot;0&quot;,\n        &quot;cp&quot;: &quot;0&quot;,\n        &quot;trestbps&quot;: 112,\n        &quot;chol&quot;: 203,\n        &quot;fbs&quot;: &quot;0&quot;,\n        &quot;restecg&quot;: &quot;1&quot;,\n        &quot;thalach&quot;: 185,\n        &quot;exang&quot;: &quot;0&quot;,\n        &quot;oldpeak&quot;: 0.1,\n        &quot;slope&quot;: &quot;2&quot;,\n        &quot;ca&quot;: &quot;0&quot;,\n        &quot;thal&quot;: &quot;2&quot;\n      }\n    ]\n  }\n}\n<\/code><\/pre>\n<p>And use it for prediction:<\/p>\n<pre><code>import json\nimport requests\ndata = new_data\nheaders = {'Content-Type':'application\/json'}\nr = requests.post(url, str.encode(json.dumps(data)), headers = headers)\nprint(r.status_code)\nprint(r.json())\n<\/code><\/pre>\n<p>I get:<\/p>\n<p><code>200 [[0.02325369841858338, 0.9767463015814166]]<\/code><\/p>\n<p>Uff! Maybe someone will benefit from my painful learning path! :)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-05-26 09:48:08.393 UTC",
        "Answer_score":0.0,
        "Owner_location":"Antarctica",
        "Answer_last_edit_date":"2022-05-26 10:03:56.59 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72376401",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72379718,
        "Question_title":"Install and load Tidymodels package in AML",
        "Question_body":"<p>I'm trying install and load some R packages in the Execute R Script in Azure Machine Learning for to run models, such as <strong>tidymodels, timetk, modeltime, modeltime.ensemble<\/strong>.<\/p>\n<pre><code>library(forecast)\nlibrary(tidyverse)\nlibrary(lubridate)\ninstall.packages(&quot;quantdates&quot;,repos = &quot;https:\/\/cloud.r-project.org&quot;)\ninstall.packages(&quot;tidymodels&quot;,repos = &quot;https:\/\/cloud.r-project.org&quot;)\nlibrary(quantdates)\nlibrary(tidymodels) \nlibrary(timetk) \nlibrary(modeltime) \nlibrary(modeltime.resample) \nlibrary(modeltime.ensemble)\n<\/code><\/pre>\n<p>However I get the following error:<\/p>\n<pre><code>Error: package or namespace load failed for \u2018tidymodels\u2019 in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\nnamespace \u2018rlang\u2019 0.4.5 is already loaded, but &gt;= 1.0.2 is required\n\nazureml_main(input_dataframe_1), library(tidymodels), tryCatch({\n    attr(package, &quot;LibPath&quot;) &lt;- which.lib.loc\n    ns &lt;- loadNamespace(package, lib.loc)\n    env &lt;- attachNamespace(ns, pos = pos, deps)\n}, error = function(e) {\n    P &lt;- if (!is.null(cc &lt;- conditionCall(e))) \n        paste(&quot; in&quot;, deparse(cc)[1])\n    else &quot;&quot;\n    msg &lt;- gettextf(&quot;package or namespace load failed for %s%s:\\n %s&quot;, sQuote(package), P, conditionMessage(e))\n    if (logical.return) \n        message(paste(&quot;Error:&quot;, msg), domain = NA)\n    else stop(msg, call. = FALSE, domain = NA)\n}), tryCatchList(expr, classes, parentenv, handlers), tryCatchOne(expr, names, parentenv, handlers[[1]]), value[[3]](cond), stop(msg, call. = FALSE, domain = NA), .handleSimpleError(function (e) \n{\n    error_msg &lt;&lt;- paste(toString(e), toString(sys.calls()[-c(1:3)]), sep = &quot;\\n&quot;)\n    stop(e)\n}, &quot;package or namespace load failed for \u2018tidymodels\u2019 in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\\n namespace \u2018rlang\u2019 0.4.5 is already loaded, but &gt;= 1.0.2 is required&quot;, quote(NULL)), h(simpleError(msg, call))\n'.\n---------- End of error message from R  interpreter  ----------\n<\/code><\/pre>\n<p>I have also tried with devtools package for install a particular version but I keep getting the same error with the <strong>rlang package<\/strong>. Sometimes, I get the same error with the <strong>cli package<\/strong>.<\/p>\n<p>In my local machine, the R code runs fine. I have the R version 4.1.3 and the Azure Machine Learning has the R version 3.5.1.<\/p>\n<p>Does anyone know how I can solve this problem?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-05-25 14:41:58.947 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"r|azure|r-package|azure-machine-learning-service|tidymodels",
        "Question_view_count":80,
        "Owner_creation_date":"2022-04-22 20:44:26.457 UTC",
        "Owner_last_access_date":"2022-09-22 14:37:18.33 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72379718",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71024584,
        "Question_title":"How give azure machine learning dataset path in an inference script?",
        "Question_body":"<p>I am using azureml sdk in Azure Databricks.<\/p>\n<p>When I write the script for inference model (%%writefile script.py) in a databricks cell,\nI try to load a .bin file that I loaded in Azure Machine Learning Datasets.<\/p>\n<p>I would like to do this in the script.py:<\/p>\n<pre><code>fasttext.load_model(azuremldatasetpath)\n<\/code><\/pre>\n<p>How can I do to give good dataset path of my .bin file in azuremldatasetpath variable ? (Without calling workspace in the script).<\/p>\n<p>Something like:<\/p>\n<pre><code>dataset_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'file.bin')\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-07 19:54:10.353 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-databricks|azure-machine-learning-service",
        "Question_view_count":172,
        "Owner_creation_date":"2021-11-29 12:42:01.32 UTC",
        "Owner_last_access_date":"2022-09-21 11:05:53.383 UTC",
        "Owner_reputation":151,
        "Owner_up_votes":54,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Answer_body":"<p>You can use your model name with the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#azureml-core-model-model-get-model-path\" rel=\"nofollow noreferrer\">Model.get_model_path()<\/a> method to retrieve the path of the model file or files on the local file system. If you register a folder or a collection of files, this API returns the path of the directory that contains those files.<\/p>\n<p>More info you may want to refer: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#azureml_model_dir\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#azureml_model_dir<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-02-24 17:26:19.037 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71024584",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40234432,
        "Question_title":"Create a model that predicts an event based on other time series events and properties of an object",
        "Question_body":"<p>I have the following data:<\/p>\n\n<ul>\n<li>Identifier of a person<\/li>\n<li>Days in location (starts at 1 and runs until event)<\/li>\n<li>Age of person in months at that time (so this increases as the days in location increase too).<\/li>\n<li>Smoker (boolean), doesn't change over time in our case<\/li>\n<li>Sex, doesn't change over time<\/li>\n<li>Fall (boolean) this is an event that may never happen, or can happen multiple times during the complete period for a certain person<\/li>\n<li>Number of wounds: (this can go from 0 to 8), a wound mostly doesn't heal immediately so it mostly stays open for a certain period of time<\/li>\n<li>Event we want to predict (boolean), only the last row of a person will have value true for this<\/li>\n<\/ul>\n\n<p>I have this data for 1500 people (in total 1500000 records so on average about 1000 records per person). For some people the event I want to predict takes place after a couple of days, for some after 10 years.  For everybody in the dataset the event will take place, so the last record for a certain identifier will always have the event we want to predict as 1.<\/p>\n\n<p>I'm new to this and all the documentation I have found so far doesn't demonstrate time series for multiple persons or objects. When I for example split the data in the machine learning studio, I want to keep records of the same person over time together.<\/p>\n\n<p>Would it be possible to feed the system after the model is trained with new records and for each day that passes it would give the estimate of the event taking place in the next 5 days?<\/p>\n\n<p>Edit: sample data of 2 persons: <a href=\"http:\/\/pastebin.com\/KU4bjKwJ\" rel=\"nofollow\">http:\/\/pastebin.com\/KU4bjKwJ<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2016-10-25 07:58:48.947 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2016-10-25 12:58:24.01 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|prediction|azure-machine-learning-studio",
        "Question_view_count":596,
        "Owner_creation_date":"2012-08-19 21:59:16.18 UTC",
        "Owner_last_access_date":"2022-09-24 10:22:06.74 UTC",
        "Owner_reputation":1946,
        "Owner_up_votes":256,
        "Owner_down_votes":7,
        "Owner_views":211,
        "Answer_body":"<p>sounds like very similar to this sample:<\/p>\n\n<p><a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/df7c518dcba7407fb855377339d6589f\" rel=\"nofollow\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/df7c518dcba7407fb855377339d6589f<\/a><\/p>\n\n<p>Unfortunately there is going to be a bit of R code involved. Yes you should be able to retrain the model with new data.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-10-25 14:00:12.397 UTC",
        "Answer_score":0.0,
        "Owner_location":"Belgium",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40234432",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68303285,
        "Question_title":"'MSIAuthentication' object has no attribute 'get_token'",
        "Question_body":"<p>On Azure ML Workspace Notebook, I'm trying to get my workspace instance, as seen at<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-models#configure-workspace.<\/a><\/p>\n<p>I have a config file and I am running the notebook in an Azure compute instance.<\/p>\n<p>I tried to execute Workspace.from_config().<\/p>\n<p>As a result, I'm getting the 'MSIAuthentication' object has no attribute 'get_token' error.<\/p>\n<p>I tried to submit both <code>MsiAuthentication<\/code> and <code>InteractiveLoginAuthentication<\/code>, as suggested in<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb.<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-07-08 14:10:50.15 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":1670,
        "Owner_creation_date":"2020-05-12 14:25:08.567 UTC",
        "Owner_last_access_date":"2022-09-20 13:49:41.073 UTC",
        "Owner_reputation":833,
        "Owner_up_votes":9,
        "Owner_down_votes":9,
        "Owner_views":55,
        "Answer_body":"<p><strong>There are 2 solutions I've found:<\/strong><\/p>\n<p>1.- Use the kernel &quot;Python 3.6 - AzureML&quot;<\/p>\n<p>2.- <code>pip install azureml-core --upgrade<\/code><\/p>\n<p>This will <strong>upgrade<\/strong><\/p>\n<blockquote>\n<p>azureml-core to 1.32.0<\/p>\n<\/blockquote>\n<p>But will <strong>downgrade<\/strong>:<\/p>\n<blockquote>\n<p>azure-mgmt-resource to 13.0.0 (was 18.0.0)<\/p>\n<\/blockquote>\n<blockquote>\n<p>azure-mgmt-storage down to 11.2.0 (was 18.0.0)<\/p>\n<\/blockquote>\n<blockquote>\n<p>urllib3 to 1.26.5 (was 1.26.6)<\/p>\n<\/blockquote>\n<p>This upgrade \/ downgrade allows the same package versions as in the python 3.6 anaconda install<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-07-08 14:10:50.15 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68303285",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60319141,
        "Question_title":"How to create a Azure Hosted web interface for Azure ML Pipeline Endpoints",
        "Question_body":"<p>This is my simple Azure Machine Learning Pipeline, where the model is written in Python.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/loL5k.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/loL5k.png\" alt=\"enter image description here\"><\/a> <\/p>\n\n<p>This is the endpoint based on the model, where I can pass my dataset as parameter inside this model to run the experiment and save the outputs in the blob storage. Here, the input datasets are also stored in Azure blob storage<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/BzDi8.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BzDi8.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And this is how we access the endpoint from other client. So, creating models (both simple and complex), publishing them as endpoints and accessing the endpoints from other clients is done.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/3mUTL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3mUTL.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Now, the scenario is, we want to create a web interface\/form for the business people so that they can upload their dataset in blob, pass it to our model to run the model and see the outputs. We don't want to give them access to ml.azure.com service.<\/p>\n\n<p>So, is there any Azure hosted web app or service to match my requirements (access endpoints within azure hosted service)? And is there any alternate way to solve it?  I am a beginner in the Azure world.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-20 11:41:20.137 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-19 14:56:11.853 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":104,
        "Owner_creation_date":"2012-05-25 15:24:04.69 UTC",
        "Owner_last_access_date":"2022-09-22 03:04:03.037 UTC",
        "Owner_reputation":6262,
        "Owner_up_votes":68,
        "Owner_down_votes":6,
        "Owner_views":988,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Dhaka, Dhaka Division, Bangladesh",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60319141",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50087905,
        "Question_title":"Azure ML R script to choose labels with highest score in web service",
        "Question_body":"<p>I have an Azure Machine Learning experiment with thousands of labels.  When I run the web service I get a table with two rows (label name and label probability) but thousands of columns.  I would like to select just the 5 labels with the highest probability (and preferably sorted descending).  Anyone now an Azure ML Studio component or R script that can do this please? Thanks!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2018-04-29 14:55:13.367 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2018-05-11 14:50:54.003 UTC",
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":53,
        "Owner_creation_date":"2015-06-27 10:40:25.343 UTC",
        "Owner_last_access_date":"2022-04-22 16:50:07.507 UTC",
        "Owner_reputation":168,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"London",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50087905",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65232059,
        "Question_title":"Action on error in Azure Machine Learning pipeline",
        "Question_body":"<p>I have a published and scheduled pipeline running at regular intervals. Some times, the pipeline may fail (for example if the datastore is offline for maintenance). Is there a way to specify the scheduled pipeline to perform a certain action if the pipeline fails for any reason? Actions could be to send me an email, try to run again in a few hours later or invoke a webhook. As it is now, I have to manually check the status of our production pipeline at regular intervals, and this is sub-optimal for obvious reasons. I could of course instruct every script in my pipeline to perform certain actions if they fail for whatever reason, but it would be cleaner and easier to specify it globally for the pipeline schedule (or the pipeline itself).<\/p>\n<p>Possible sub-optimal solutions could be:<\/p>\n<ul>\n<li>Setting up an Azure Logic App to invoke the pipeline<\/li>\n<li>Setting a cron job or Azure Scheduler<\/li>\n<li>Setting up a second Azure Machine Learning pipeline on a schedule that triggers the pipeline, monitors the output and performs relevant actions if errors are encountered<\/li>\n<\/ul>\n<p>All the solutions above suffers from being convoluted and not very clean - surely there must exist a simple, clean solution for this problem?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-10 09:45:31.447 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":357,
        "Owner_creation_date":"2011-06-07 10:27:10.757 UTC",
        "Owner_last_access_date":"2022-09-22 07:49:12.447 UTC",
        "Owner_reputation":2042,
        "Owner_up_votes":80,
        "Owner_down_votes":0,
        "Owner_views":80,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65232059",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58188104,
        "Question_title":"Azure Machine Learning REST API: why is the prediction included in the Sample Request?",
        "Question_body":"<p>I followed Microsoft's tutorial on the German credit card risk model, step by step and without mistakes. The algorithm runs, it is deployed successfully, etc.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/tuyDt.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/tuyDt.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I am using the <code>Select Columns in Dataset<\/code> to select the columns to input, and I do the same to select the output columns. <\/p>\n\n<p>I noticed that when I look at the <code>Request\/Response<\/code> tab of the deployed model, the Sample Request includes <em>all<\/em> columns, ignoring the selection I provided. This includes the field to be predicted, which is column 21:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"Col1\",\n        \"Col2\",\n        \"Col3\",\n        \"Col4\",\n        \"Col5\",\n        \"Col6\",\n        \"Col7\",\n        \"Col8\",\n        \"Col9\",\n        \"Col10\",\n        \"Col11\",\n        \"Col12\",\n        \"Col13\",\n        \"Col14\",\n        \"Col15\",\n        \"Col16\",\n        \"Col17\",\n        \"Col18\",\n        \"Col19\",\n        \"Col20\",\n        \"Col21\"\n<\/code><\/pre>\n\n<p><strong>The problem<\/strong>: column 21 is the credit risk itself, so the API is expecting to receive that value. Instead, <strong>that is the value that should be predicted!<\/strong><\/p>\n\n<p>There clearly is a problem with the input schema, but how can I change that? How can I make sure that field is not requested by the API?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-01 15:31:40.453 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|rest|schema|postman|azure-machine-learning-studio",
        "Question_view_count":119,
        "Owner_creation_date":"2015-10-26 16:55:20.94 UTC",
        "Owner_last_access_date":"2022-07-29 13:54:20.753 UTC",
        "Owner_reputation":1271,
        "Owner_up_votes":1079,
        "Owner_down_votes":0,
        "Owner_views":171,
        "Answer_body":"<p>Don't worry about the input schema for the <code>Col21<\/code> field. The <code>Col21<\/code> field in the input data just adapt for the <code>Edit Metadata<\/code> module which requires the <code>Col21<\/code> data in the training stage.<\/p>\n\n<p>You just fill an invalid value like <code>0<\/code> (<code>0<\/code> is an invalid classified value for risk) into <code>Col21<\/code> field, and then the web service will return a prediction classified value to replace the <code>Col21<\/code> value of your input data.<\/p>\n\n<p>At here, I use the first data record of the sample data with the <code>Col21<\/code> value <code>0<\/code> for testing via the link of <code>Test<\/code> feature on portal, it works fine and return <code>1<\/code> for <code>Credit risk<\/code><\/p>\n\n<p>Fig 1. To click <code>Test<\/code> link to test for <code>Col21<\/code> with <code>0<\/code><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/9jqyo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9jqyo.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 2. Use the first record of sample to test<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/lIUiP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/lIUiP.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 3. The <code>Col21<\/code> value of <code>input1<\/code> is <code>0<\/code>, and the <code>Credit risk<\/code> value of <code>output1<\/code> is <code>1<\/code><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/h5OEH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/h5OEH.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-10-08 17:04:23.83 UTC",
        "Answer_score":1.0,
        "Owner_location":"Humboldt, Saskatchewan, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58188104",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71747545,
        "Question_title":"Commands in the Azure ML yml files",
        "Question_body":"<p>When reading the examples from Microsoft on azure ML CLI v2, they use the symbols:\n&quot;|&quot;, &quot;&gt;&quot;, etc., in their yml files.<\/p>\n<p>What do they mean, and where can I find explanations of possible syntax for the Azure CLI v2 engine?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-05 07:07:09.25 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"yaml|command-line-interface|azure-machine-learning-studio",
        "Question_view_count":100,
        "Owner_creation_date":"2021-05-03 13:44:35.61 UTC",
        "Owner_last_access_date":"2022-09-23 09:41:27.86 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>| - This pipe symbol in YAML document is used for <em><strong>&quot;Multiple line statements&quot;<\/strong><\/em><\/p>\n<pre><code>description: |\n  # Azure Machine Learning &quot;hello world&quot; job\n\n  This is a &quot;hello world&quot; job running in the cloud via Azure Machine Learning!\n\n  ## Description\n\n  Markdown is supported in the studio for job descriptions! You can edit the description there or via CLI.\n<\/code><\/pre>\n<p>in the above example, we need to write some multiple line description. So, we need to use &quot;|&quot; symbol<\/p>\n<p>&quot;&gt;&quot; - This symbol is used to save some content directly to a specific location document.<\/p>\n<pre><code>command: echo &quot;hello world&quot; &gt; .\/outputs\/helloworld.txt\n<\/code><\/pre>\n<p>In this above command, we need to post <strong>&quot;hello world&quot;<\/strong> to <em><strong>&quot;helloworld.txt&quot;<\/strong><\/em><\/p>\n<p>Check the below link for complete documentation regarding YAML files.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-job-command\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-job-command<\/a><\/p>\n<p>All these symbols are the YAML job commands which are used to accomplish a specific task through CLI.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-06 07:55:01.843 UTC",
        "Answer_score":0.0,
        "Owner_location":"Denmark",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71747545",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62938710,
        "Question_title":"Can I create a new Azure ML-workspace when creating an ACI from cloud shell",
        "Question_body":"<p>How can I create a new Azure Machine Learning workspace when creating a new Azure Container Instance from Azure cloud shell.<\/p>\n<p>Here is a sample of the command am using to create the ACI.<\/p>\n<p><code>az container create --name dev-container \u2013resource-group XXX \u2013location eastus \u2013image mcr.microsoft.com\/XXX \u2013cpu 2 \u2013memory 6 \u2013environment-variables WORKSPACE_NAME=XXX<\/code><\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-07-16 15:57:38.743 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-container-service|azure-machine-learning-service|azure-container-instances|azure-container-registry|azure-machine-learning-workbench",
        "Question_view_count":101,
        "Owner_creation_date":"2018-09-18 19:45:24.587 UTC",
        "Owner_last_access_date":"2022-09-14 17:20:52.613 UTC",
        "Owner_reputation":359,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Laurel, MD, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62938710",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40302499,
        "Question_title":"Recommendation API: what is the difference between null results and empty results",
        "Question_body":"<p>In the Azure Recommendation API sample there is a snippet like this:<\/p>\n\n<pre><code>     if (itemSets.RecommendedItemSetInfo != null)\n        {\n            ...\n        }\n        else\n        {\n            Console.WriteLine(\"No recommendations found.\");\n        }\n<\/code><\/pre>\n\n<p>So I assume that nullable recommended set means no recommendations. But what is the case with this set being not nullable but still empty ( as I am having it running the example)?<\/p>\n\n<p>I provided my own usages and catalog files. I have not too many entries there however for i2i recommendations I have results and for u2i there is an empty set.\nAllowColdItemPlacement doesn't change a think here.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-28 09:51:28.96 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|microsoft-cognitive|azure-machine-learning-studio",
        "Question_view_count":130,
        "Owner_creation_date":"2012-11-28 16:00:34.117 UTC",
        "Owner_last_access_date":"2021-02-19 16:07:20.957 UTC",
        "Owner_reputation":393,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Answer_body":"<p>We did not mean to convey a difference in meaning between null recommendations and empty recommendations. I will check why we may be sending two different types of results. Either way, don't treat those two cases as different cases. <\/p>\n\n<p>If you are not getting results for user-to-item recommendations, most likely there was no data for that user when the build was created or the items that the user interacted with do not have enough co-occurrences with other items in the usage.<\/p>\n\n<p>What to do when you get empty recommendations is up to you, you may decide to not show any recommendations, or back-fill with popular items you may want to promote.<\/p>\n\n<p>Thanks!<\/p>\n\n<p>Luis Cabrera\nProgram Manager - Recommendations API.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-11-03 15:27:31.717 UTC",
        "Answer_score":1.0,
        "Owner_location":"Wroc\u0142aw, Poland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40302499",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36125274,
        "Question_title":"Refresh the dataset in Azure machine learning",
        "Question_body":"<p>I have an experiment (exp) which is published as a web service (exp [Predictive Exp.])  in the azure machine learning studio, the data used by this experiment was pushed by R using AzureML package<\/p>\n\n<pre><code>library(AzureML)\n\nws &lt;- workspace(\n  id = 'xxxxxxxxx',\n  auth = 'xxxxxxxxxxx'\n)\n\nupload.dataset(data_for_azure, ws, \"data_for_azure\")\n<\/code><\/pre>\n\n<p>The above thing worked, but lets say I want to update the dataset(same schema just added more rows)<\/p>\n\n<p>I tired this but this does not work:<\/p>\n\n<pre><code>delete.datasets(ws, \"data_for_azure\")\n\nrefresh(ws, what = c(\"everything\", \"data_for_azure\", \"exp\", \"exp [Predictive Exp.]\")) \n<\/code><\/pre>\n\n<p>I get the error stating the following:<\/p>\n\n<pre><code>Error: AzureML returns error code:\nHTTP status code : 409\nUnable to delete dataset due to lingering dependants\n<\/code><\/pre>\n\n<p>I went through the documentation, and I know that a simple refresh is not possible(same name), the only alternative I see is to delete the web service and perform everything again<\/p>\n\n<p>Any solution will be greatly helped!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-03-21 07:29:33.34 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-03-21 13:32:55.057 UTC",
        "Question_score":1,
        "Question_tags":"r|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":1196,
        "Owner_creation_date":"2014-07-25 05:27:39.94 UTC",
        "Owner_last_access_date":"2022-09-15 08:56:29.147 UTC",
        "Owner_reputation":1677,
        "Owner_up_votes":82,
        "Owner_down_votes":2,
        "Owner_views":221,
        "Answer_body":"<p>From the R doc.<\/p>\n\n<blockquote>\n  <p>The AzureML API does not support uploads for <em>replacing<\/em> datasets with\n  new data by re-using a name. If you need to do this, first delete the\n  dataset from the AzureML Studio interface, then upload a new version.<\/p>\n<\/blockquote>\n\n<p>Now, I think this is particular for the R sdk, as the Python SDK, and the AzureML Studio UI lets you upload a new dataset. Will check in with the R team about this.<\/p>\n\n<p>I would recommend uploading it as a new dataset with a new name, and then replacing the dataset in your experiment with this new dataset. Sorry this seem's round about, but I think is the easier option.<\/p>\n\n<p>Unless you want to upload the new version using the AzureML Studio, in which case go to +NEW, Dataset, select your file and select the checkbox that says this is an existing dataset. The filename should be the same. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-03-21 13:32:42.307 UTC",
        "Answer_score":1.0,
        "Owner_location":"Link\u00f6ping, Sweden",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36125274",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":43561934,
        "Question_title":"Microsoft Azure Machine Learning Studio from Visual Studio?",
        "Question_body":"<p>Is there a way to use the same ML-realizations as used in Microsoft Azure Machine Learning Studio but on my computer without their visual interface?<\/p>\n\n<p>I love Azure ML studio when I play with my \"trial\" models, but it would be great if I could store the sequence of the commands as a code on my machine. <\/p>\n\n<p>I mean whether there is some reference in C# or library in Python that enables to do that? Or is there an API for that? <\/p>\n\n<p>Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-04-22 16:51:24.06 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"c#|python|machine-learning|azure-machine-learning-studio",
        "Question_view_count":774,
        "Owner_creation_date":"2017-01-30 17:50:34.893 UTC",
        "Owner_last_access_date":"2017-04-22 20:25:02.717 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"St. Louis, MO, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/43561934",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40379325,
        "Question_title":"R Script in AzureML",
        "Question_body":"<p>I am trying to develop a survey App and using R Script with Azure ML for same.<\/p>\n\n<p>I have developed below code for the same and it works perfectly fine on Local Machine:<\/p>\n\n<pre><code>dataset1 &lt;-maml.mapInputPort(2)\ndataset3 &lt;-maml.mapInputPort(1)\nZ &lt;- as.numeric((dataset3),stringsAsFactors=TRUE)\nY &lt;- mdBinaryDesign(Z,4,dataset1)\nY.aggregate=mdBinaryToAggregateDesign(Y)\nsurvey.design=mdDesignNames(Y.aggregate, dataset1)\ndata.set &lt;- as.data.frame(survey.design)\nmaml.mapOutputPort(\"data.set\")\n<\/code><\/pre>\n\n<p>Now we plan to deploy this Application on server , for which we are using Azure MIL .<\/p>\n\n<p>Now my Dataset1 and Dataset3 are coming using Input port in R Model , by using the above code , I get error \"missing value where TRUE\/FALSE needed\". My Dataset3 contains a simple number eg: \"5\" .<\/p>\n\n<p>Since my model will only run having three dynamic inputs (e.g. a, b, c), is there a way I can call a web service which will give me three output parameters via JSON and I can assign same to my model?<\/p>\n\n<p>The part where I want to dynamically apply parameters are:<\/p>\n\n<pre><code>Y &lt;- mdBinaryDesign(parameter_1,parameter_2,parameters3)\n<\/code><\/pre>\n\n<p>Since I am new to R , Please suggest we what library to use as well how to assigns value to parameter_1 and so on.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-11-02 11:54:24.743 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2017-01-04 12:05:17.737 UTC",
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":203,
        "Owner_creation_date":"2015-02-02 08:45:49.097 UTC",
        "Owner_last_access_date":"2021-10-13 14:11:20.567 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40379325",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49604773,
        "Question_title":"Azure Machine Learning Studio vs. Workbench",
        "Question_body":"<p>What is the difference between <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-studio\/\" rel=\"noreferrer\">Azure Machine Learning Studio<\/a> and <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-services\/\" rel=\"noreferrer\">Azure Machine Learning Workbench<\/a>?  What is the <em>intended<\/em> difference? And is it expected that Workbench is heading towards deprecation in favor of Studio?<\/p>\n\n<p>I have gathered an assorted collection of differences:<\/p>\n\n<ul>\n<li>Studio has a hard limit of 10 GB total input of training data per module, whereas Workbench has a variable limit by price.<\/li>\n<li>Studio appears to have a more fully-featured GUI and user-friendly deployment tools, whereas Workbench appears to have more powerful \/ customizable deployment tools.<\/li>\n<li>etc.<\/li>\n<\/ul>\n\n<p>However, I have also found several scattered references claiming that Studio is a renamed updated of Workbench, even though both services appear to still be offered.<\/p>\n\n<p>For a fresh Data Scientist looking to adopt the Microsoft stack (potentially on an enterprise scale within the medium-term and for the long-term), which offering should I prefer?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2018-04-02 03:01:39.293 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":8,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":3387,
        "Owner_creation_date":"2015-06-19 17:48:28.84 UTC",
        "Owner_last_access_date":"2022-09-15 11:30:21.093 UTC",
        "Owner_reputation":2045,
        "Owner_up_votes":1074,
        "Owner_down_votes":66,
        "Owner_views":166,
        "Answer_body":"<p>Azure Machine Learning Workbench is a preview downloadable application. It provides a UI for many of the Azure Machine Learning CLI commands, particularly around experimentation submission for Python based jobs to DSVM or HDI. The Azure Machine Learning CLI is made up of many key functions, such as job submisison, and creation of real time web services. The workbench installer provided a way to install everything required to participate in the preview. <\/p>\n\n<p>Azure Machine Learning Studio is an older product, and provides a drag and drop interface for creating simply machine learning processes. It has limitations about the size of the data that can be handled (about 10gigs of processing). Learning and customer requests have based on this service have contributed to the design of the new Azure Machine Learning CLI mentioned above.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2018-04-27 05:25:01.633 UTC",
        "Answer_score":6.0,
        "Owner_location":"Dallas, TX, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49604773",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":29000199,
        "Question_title":"Can an organizational account (office 365) be used for live\/Microsoft services?",
        "Question_body":"<p>I understand that Office 365 is on separate domain and live id (Microsoft account) is used for consumer applications.<\/p>\n\n<p>But can an Office 365 account get live\/Microsoft services?<\/p>\n\n<p>The issue is we trying to SSO Office 365 applications and Azure ML (used with Microsoft account) but as the domains are different I am unable to find any proper help or process on the web.<\/p>\n\n<p>We can create a live account with our company domain but can we create a federation on Live account ? For e.g. on Office 365 we created a @.com federation and were able to SSO it, how can we do the same with a live account ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-03-12 01:01:17.52 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-03-13 20:00:22.12 UTC",
        "Question_score":1,
        "Question_tags":"azure|single-sign-on|office365|microsoft-account|azure-machine-learning-studio",
        "Question_view_count":292,
        "Owner_creation_date":"2013-03-14 18:30:03.303 UTC",
        "Owner_last_access_date":"2019-10-09 19:03:09.4 UTC",
        "Owner_reputation":203,
        "Owner_up_votes":2,
        "Owner_down_votes":1,
        "Owner_views":27,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29000199",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41136102,
        "Question_title":"Perform batch execution without using BLOB",
        "Question_body":"<p>Can I perform batch execution against Azure ML web service without using BLOB?<\/p>\n\n<p>I'm reading the data from SQL database into a CSV file stream. Can I stream this directly to the service without actually saving in and reading back the result from the BLOB?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-12-14 06:24:46.017 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":180,
        "Owner_creation_date":"2013-08-20 11:57:52.723 UTC",
        "Owner_last_access_date":"2022-09-06 11:40:53.407 UTC",
        "Owner_reputation":998,
        "Owner_up_votes":162,
        "Owner_down_votes":6,
        "Owner_views":136,
        "Answer_body":"<p>BES doesn't work with streams. The data needs to be stored somewhere for AML to access the data. Take a look at: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-consume-web-services#batch-execution-service-bes\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-consume-web-services#batch-execution-service-bes<\/a> for more information.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-12-14 09:40:21.107 UTC",
        "Answer_score":1.0,
        "Owner_location":"Malaysia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41136102",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30214698,
        "Question_title":"How to schedule Batch Execution Service of Azure Machine Learning in Azure Scheduler",
        "Question_body":"<p>In Batch execution API help page of Azure Machine Learning there are three different URI\u2019s <\/p>\n\n<ul>\n<li>Submit Job (Response is Job ID)<\/li>\n<li>Start Job ( we need to use the above Job ID in this URI)<\/li>\n<li>Get Status or Result (we need to use the above Job ID in this URI)<\/li>\n<\/ul>\n\n<p>How do I automate these jobs in the Azure Scheduler? (i.e. if I want to execute the BES on the particular date<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-05-13 12:25:15.817 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2015-05-14 07:23:39.033 UTC",
        "Question_score":0,
        "Question_tags":"azure|machine-learning|batch-processing|azure-scheduler|azure-machine-learning-studio",
        "Question_view_count":759,
        "Owner_creation_date":"2014-06-23 16:37:06.413 UTC",
        "Owner_last_access_date":"2020-06-18 08:44:47.883 UTC",
        "Owner_reputation":191,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":"<p>You would use Azure Data Factory instead of the scheduler. This would allow you to schedule the BES call into the future while identifying where the result file will end up. <\/p>\n\n<p>There are lots of examples online on how to do that.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-05-14 12:10:11.263 UTC",
        "Answer_score":1.0,
        "Owner_location":"Bengaluru, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30214698",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70586850,
        "Question_title":"Python Azure SDK - Incorrect datetime format inferred when reading tabular data from blobstore with from_delimited_files()",
        "Question_body":"<p>I am using the Azure Python SDK to read a tabular dataset from a Blob Store as follows:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df = Dataset.Tabular.from_delimited_files(path=[DataPath(ds, blobstore_dir + 'tabular_data.csv')],\n                                          separator=',', header=True)\n<\/code><\/pre>\n<p>The data has four datetime columns, one of the columns reads in with no problem because there are instances where the month-day order is not ambiguous, but the other three are being inferred incorrectly as &quot;month-day&quot; instead of &quot;day-month&quot;.<\/p>\n<p>When reading in the data I get the following warning:<\/p>\n<blockquote>\n<p>UserWarning: Ambiguous datetime formats inferred for columns ['Period Start', 'Period End', 'Extracted At'] are resolved as &quot;month-day&quot;. Desired format can be specified by <code>set_column_types<\/code>.<\/p>\n<\/blockquote>\n<p>I have attempted to set the column types as below, and have tried a few different formats but all I end up with is NULL in place of all the values.<\/p>\n<pre><code>df = Dataset.Tabular.from_delimited_files(\n        path=[DataPath(ds, blobstore_dir + 'tabular_data.csv')], separator=',', header=True,\n        set_column_types={'Period Start': DataType.to_datetime(&quot;%d-%m-%Y %H:%M:%S&quot;),\n                          'Period End': DataType.to_datetime(&quot;%d-%m-%Y %H:%M:%S&quot;),\n                          'Extracted At': DataType.to_datetime(&quot;%d-%m-%Y %H:%M:%S&quot;)})\n<\/code><\/pre>\n<p>The documentation for <code>from_delimited_files()<\/code> is <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.dataset_factory.tabulardatasetfactory?view=azure-ml-py#from-delimited-files-path--validate-true--include-path-false--infer-column-types-true--set-column-types-none--separator------header-true--partition-format-none--support-multi-line-false--empty-as-string-false--encoding--utf8--\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n<p>Can anyone tell me how to force <code>from_delimited_files()<\/code> to resolve the ambiguous datetimes as day-month or tell me how to use <code>set_column_types<\/code> correctly? I've worked around it temporarily by inserting a dummy row with a non-ambiguous datetime.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-05 01:25:31.55 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-01-05 01:48:06.407 UTC",
        "Question_score":1,
        "Question_tags":"python|azure|azure-sdk-python|azure-machine-learning-service",
        "Question_view_count":131,
        "Owner_creation_date":"2021-05-14 02:29:49.16 UTC",
        "Owner_last_access_date":"2022-06-08 04:31:31.727 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70586850",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73467442,
        "Question_title":"What is the importance of Azure ML dataset versioning?",
        "Question_body":"<p>I created an Azure ML dataset with a single file inside a storage blob container. Azure ML studio portal then showed 1 file in the dataset version 1.<\/p>\n<p>I wanted to add 2 more files and create a new dataset version. So I copied 2 more files to the same blob container folder. Surprisingly even before I created a new dataset version, the ML studio portal UI shows the number of files in the same dataset as 3. (image below).<\/p>\n<p>I then went through Azure ML <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-version-track-datasets\" rel=\"nofollow noreferrer\">versioning<\/a> docs which tell datasets are just references to original data. I also see a suggestion to create new folders for new data and I agree that the new files were not copied to a new folder here as recommended.<\/p>\n<p>But still, the metadata (e.g. files in dataset, total size of dataset etc) of a previously created dataset version is getting updated. What is the importance of Azure ML dataset versioning if <strong>metadata<\/strong> of dataset version itself is being updated?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/tqX4e.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/tqX4e.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><sub>A related <a href=\"https:\/\/stackoverflow.com\/q\/70380861\">question<\/a> was in SO, but closed as a bug.<\/sub><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-24 04:29:38.573 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-04 21:55:07.287 UTC",
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":52,
        "Owner_creation_date":"2012-01-31 10:49:21.457 UTC",
        "Owner_last_access_date":"2022-09-21 08:34:40.283 UTC",
        "Owner_reputation":10421,
        "Owner_up_votes":815,
        "Owner_down_votes":94,
        "Owner_views":856,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Kochi, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73467442",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42017727,
        "Question_title":"Upload Saved ML Model in R (local) to Azure Machine Learning Studio",
        "Question_body":"<p>I am trying to reduce my development headaches for creating a ML Webservice on Azure ML Studio. One of the things that stuck me was can we just upload .rda files in the workbench and load it via an RScript (like in the figure below). <\/p>\n\n<p><img src=\"https:\/\/raw.githubusercontent.com\/pratos\/pratos.github.io\/master\/images\/stackb1model.png\" alt=\"Do\"><\/p>\n\n<p>But can't connect directly to the R Script block. There's another way to do it (works to upload packages that aren't available in Azure's R directories) -- using zip. But there isn't really any resource out there that I found to access the .rda file in .zip.<\/p>\n\n<p>I have 2 options here, make the .zip work or any other work around where I can directly use my .rda model. If someone could guide me about how to go forward it would appreciate it.<\/p>\n\n<p>Note: Currently, I'm creating models via the \"Create RModel\" block, training them and saving it, so that I can use it to make a predictive web service. But for models like Random Forest, not sure how the randomness might create models (local versions and Azure versions are different, the setting of seed also isn't very helpful). A bit tight on schedule, Azure ML seems boxed for creating iterations and automating the ML workflow (or maybe I'm doing it wrong).<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-03 06:00:42.917 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":730,
        "Owner_creation_date":"2016-11-17 06:17:48.55 UTC",
        "Owner_last_access_date":"2018-10-22 11:25:03.6 UTC",
        "Owner_reputation":108,
        "Owner_up_votes":125,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Answer_body":"<p>Here is an example of uploading a .rda file for scoring:\n<a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Womens-Health-Risk-Assessment-using-the-XGBoost-classification-algorithm-1\" rel=\"nofollow noreferrer\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/Womens-Health-Risk-Assessment-using-the-XGBoost-classification-algorithm-1<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-02-03 06:47:19.2 UTC",
        "Answer_score":2.0,
        "Owner_location":"Pune, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42017727",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69495475,
        "Question_title":"How to add private packages in azure ml environment?",
        "Question_body":"<p>I have python script (train_pipeline.py) which creates and runs an azure ml pipeline. It uses environment.yml to create the conda environment. This works, except for one private library (utils) which is referenced in the yml file through it's relative path. When I create the conda environment locally, everything works as expected. However when azure ml creates the environment, it is not able to find the utils folder.<\/p>\n<p>How can I include private packages to azure ml environment?<\/p>\n<p>Directory structure:<\/p>\n<pre><code>| azure_pipelines\n|--- train_pipeline.py\n| projects\n|--- project_1\n|---|--- script.py\n|---|--- environment.yml\n| utils\n|--- database_utils\n|---|---__init__.py\n|---|---connection.py\n|--- setup.py\n<\/code><\/pre>\n<p>environment.yml content:<\/p>\n<pre><code>name: env_name\nchannels:\n  - defaults\ndependencies:\n  - python=3.8\n  - pyodbc\n  - pandas\n  - pip:\n    - azureml-core\n    - ..\/..\/utils\nprefix: \/Users\/username\/opt\/anaconda3\/envs\/env_name\n<\/code><\/pre>\n<p>train_pipeline.py:<\/p>\n<pre><code>...\nenvironment = Environment.from_conda_specification('env_name', '..\/projects\/project_1\/environment.yml')\n...\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-10-08 11:57:22.217 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pip|yaml|azure-pipelines|conda|azure-machine-learning-service",
        "Question_view_count":252,
        "Owner_creation_date":"2013-06-06 19:10:53.277 UTC",
        "Owner_last_access_date":"2021-12-15 14:55:10.763 UTC",
        "Owner_reputation":1357,
        "Owner_up_votes":250,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69495475",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72775967,
        "Question_title":"R, pins and AzureStor: unused argument (azure_storage_progress_bar = progress)",
        "Question_body":"<pre><code>pins 1.0.1\nAzureStor 3.7.0\n<\/code><\/pre>\n<p>I'm getting this error<\/p>\n<pre><code>Error in withr::local_options(azure_storage_progress_bar = progress, .local_envir = env) : \n  unused argument (azure_storage_progress_bar = progress)\nCalls: %&gt;% ... pin_meta.pins_board_azure -&gt; azure_download -&gt; local_azure_progress\nExecution halted\n<\/code><\/pre>\n<p>when running <code>pin_read()<\/code> in the following code (<code>pin_list()<\/code> works fine)<\/p>\n<pre><code>bl_endp_key &lt;- storage_endpoint(endpoint = &lt;endpoint URL&gt;, key =&lt;endpoint key&gt;&quot;)\ncontainer &lt;- storage_container(endpoint = bl_endp_key, name = &lt;blob name&gt;)\nboard &lt;- board_azure(container = container, path = &quot;accidentsdata&quot;)\ncat(&quot;Testing pins:\\n&quot;)\nprint(board %&gt;% pin_list())\naccidents2 &lt;- board %&gt;% pins::pin_read('accidents') %&gt;% as_tibble()\n<\/code><\/pre>\n<p>My goal is to &quot;pin_read&quot; a dataset located on a Azure Blob Storage from an R script being run from <strong>pipelineJoB (YAML)<\/strong> including a <code>command: Rscript script.R ...<\/code> and an <code>environment:<\/code> based on a dockerfile installing <strong>R version 4.0.0<\/strong> (2020-04-24) -- &quot;Arbor Day&quot;<\/p>\n<p>The pipelineJob is being called from an Azure DevOps Pipeline task with <code>az ml job create &lt;pipelineJob YAML&gt; &lt;resource grp&gt; &lt;aml workspace name&gt;<\/code>.<\/p>\n<p>Note: the R script runs fine on my Windows RStudio desktop, with R version 4.1.3 (2022-03-10) -- &quot;One Push-Up&quot;.<\/p>\n<p>I've already tried with<\/p>\n<p><code>options(azure_storage_progress_bar=FALSE)<\/code> or<\/p>\n<p><code>withr::local_options(azure_storage_progress_bar=FALSE)<\/code><\/p>\n<p>but I'm getting the same <code>unused argument (azure_storage_progress_bar ...<\/code> error.<\/p>\n<p>FYI: <code>local_azure_progress<\/code> is defined here <a href=\"https:\/\/rdrr.io\/github\/rstudio\/pins\/src\/R\/board_azure.R#sym-local_azure_progress\" rel=\"nofollow noreferrer\">here<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-06-27 17:12:54.407 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-01 13:04:22.49 UTC",
        "Question_score":0,
        "Question_tags":"r|azure-devops|azure-pipelines|azure-machine-learning-service|pins",
        "Question_view_count":80,
        "Owner_creation_date":"2013-11-17 23:23:07.84 UTC",
        "Owner_last_access_date":"2022-07-14 14:55:39.597 UTC",
        "Owner_reputation":717,
        "Owner_up_votes":143,
        "Owner_down_votes":0,
        "Owner_views":112,
        "Answer_body":"<p>Issue has been filed in <a href=\"https:\/\/github.com\/rstudio\/pins\/issues\/624\" rel=\"nofollow noreferrer\">pins<\/a>, it seems that is not an AzureStor issue.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-04 12:10:59.777 UTC",
        "Answer_score":0.0,
        "Owner_location":"France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72775967",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69135872,
        "Question_title":"How to install R packages into Azure Machine Learning",
        "Question_body":"<p>I have trained a model locally using the R package locfit. I am now trying to run this in Azure Machine Learning.<\/p>\n<p>Most guides\/previous questions appear to be in relation to Azure Machine Learning (classic). Although I believe the process outlined in similar posts will be similar (e.g. <a href=\"https:\/\/stackoverflow.com\/questions\/43176442\/install-r-packages-in-azure-ml\">here<\/a>, <a href=\"https:\/\/stackoverflow.com\/questions\/27568624\/installing-additional-r-package-on-azure-ml\">here<\/a>, I am still unable to get it to work.<\/p>\n<p>I have outlined the steps I have followed below:<\/p>\n<ol>\n<li><p>Download locfit R package for windows Zip file from <a href=\"https:\/\/cran.r-project.org\/web\/packages\/locfit\/index.html\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n<\/li>\n<li><p>Put this downloaded Zip file into a new Zip file entitled &quot;locfit_package&quot;<\/p>\n<\/li>\n<li><p>I upload this &quot;locfit_package&quot; zip folder to AML as a dataset (Create Dataset &gt; From Local Files &gt; <strong>name<\/strong>: locfit_package <strong>dataset<\/strong> <strong>type<\/strong>: file &gt; Upload the zip (&quot;locfit_package&quot;) &gt; Confirm upload is correct<\/p>\n<\/li>\n<li><p>In the R terminal I then execute the following code:<\/p>\n<p>install.packages(&quot;src\/locfit_package.zip&quot;, lib = &quot;.&quot;, repos = NULL, verbose = TRUE)<\/p>\n<p>library(locfit_package, lib.loc=&quot;.&quot;, verbose=TRUE)<\/p>\n<p>library(locfit)<\/p>\n<\/li>\n<li><p>The following error message is then returned:<\/p>\n<p>system (cmd0): \/usr\/lib\/R\/bin\/R CMD INSTALL<\/p>\n<p>Warning: invalid package \u2018src\/locfit_package.zip\u2019\nError: ERROR: no packages specified\nWarning message:<\/p>\n<p>In install.packages(&quot;src\/locfit_package.zip&quot;, lib = &quot;.&quot;, repos = NULL,  : installation of package \u2018src\/locfit_package.zip\u2019 had non-zero exit status\nError in library(locfit_package, lib.loc = &quot;.&quot;, verbose = TRUE) : there is no package called \u2018locfit_package\u2019\nExecution halted<\/p>\n<\/li>\n<\/ol>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2021-09-10 17:24:03.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":411,
        "Owner_creation_date":"2021-06-24 10:29:22.66 UTC",
        "Owner_last_access_date":"2021-12-15 15:44:15.45 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69135872",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67387249,
        "Question_title":"How to use azureml.core.runconfig.DockerConfiguration class in azureml.core.Environment or azureml.core.ScriptRunConfig class",
        "Question_body":"<p>I use Microsoft Azure Machine Learning (Azure-ml) to run my (python) experiments.<\/p>\n<p>For specifying the VM and python environment I use:<\/p>\n<pre><code>from azureml.core import Environment\nfrom azureml.core import ScriptRunConfig\n\n# Other imports and code...\n\n# Specify VM and Python environment:\nvm_env = Environment.from_conda_specification(name='my-test-env', file_path=PATH_TO_YAML_FILE)\nvm_env.docker.enabled = True\nvm_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.2-cudnn7-ubuntu18.04'\n\n# Finally, use the environment in the ScriptRunConfig:\nsrc = ScriptRunConfig(source_directory=DEPLOY_CONTAINER_FOLDER_PATH,\n                      script=SCRIPT_FILE_TO_EXECUTE,\n                      arguments=EXECUTE_ARGUMENTS,\n                      compute_target=compute_target,\n                      environment=vm_env)\n<\/code><\/pre>\n<p>I get the following warning for the line <code>vm_env.docker.enabled = True<\/code>:<\/p>\n<pre><code>'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n<\/code><\/pre>\n<p>The documentation about the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.environment.dockersection?view=azure-ml-py\" rel=\"noreferrer\"><code>DockerSection Class<\/code><\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.runconfig.dockerconfiguration?view=azure-ml-py\" rel=\"noreferrer\"><code>DockerConfiguration Class<\/code><\/a> is not very clear about applying the <code>DockerConfiguration Class<\/code>.<\/p>\n<p><strong>I can't figure out how to use the <code>azureml.core.runconfig.DockerConfiguration<\/code> object. Can someone provide me with an example? Thank you!<\/strong><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-04 14:59:03.337 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2021-05-10 07:10:19.49 UTC",
        "Question_score":8,
        "Question_tags":"python|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":2662,
        "Owner_creation_date":"2017-02-15 12:44:09.613 UTC",
        "Owner_last_access_date":"2022-09-24 19:22:12.82 UTC",
        "Owner_reputation":755,
        "Owner_up_votes":3010,
        "Owner_down_votes":0,
        "Owner_views":245,
        "Answer_body":"<p>The <code>ScriptRunConfig<\/code> class now accepts a <code>docker_runtime_config<\/code> argument, which is where you pass the <code>DockerConfiguration<\/code> object.<\/p>\n<p>So, the code would look something like this:<\/p>\n<pre><code>from azureml.core import Environment\nfrom azureml.core import ScriptRunConfig\nfrom azureml.core.runconfig import DockerConfiguration\n\n# Other imports and code...\n\n# Specify VM and Python environment:\nvm_env = Environment.from_conda_specification(name='my-test-env', file_path=PATH_TO_YAML_FILE)\nvm_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.2-cudnn7-ubuntu18.04'\n\ndocker_config = DockerConfiguration(use_docker=True)\n\n# Finally, use the environment in the ScriptRunConfig:\nsrc = ScriptRunConfig(source_directory=DEPLOY_CONTAINER_FOLDER_PATH,\n                      script=SCRIPT_FILE_TO_EXECUTE,\n                      arguments=EXECUTE_ARGUMENTS,\n                      compute_target=compute_target,\n                      environment=vm_env,\n                      docker_runtime_config=docker_config)\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2021-05-06 14:23:42.35 UTC",
        "Answer_score":12.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-05-10 09:22:15.88 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67387249",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47620404,
        "Question_title":"Azure machine learning webservice deployment failed",
        "Question_body":"<p>Deployment error to ACS - BadRequestFormat. How do I get past this? This is my nth attempt to make the tutorial work end to end <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/preview\/tutorial-classifying-iris-part-1\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/preview\/tutorial-classifying-iris-part-1<\/a>.<\/p>\n\n<p>az ml env setup -n gopenv --location westcentralus -c<\/p>\n\n<p>Subscription set to Visual Studio Premium with MSDN<\/p>\n\n<p>Continue with this subscription (Y\/n)? y<\/p>\n\n<p>Resource group gopenvrg already exists, skipping creation.<\/p>\n\n<p>creating service principal.........done<\/p>\n\n<p>Created a service principal: %s 96f6dd9e-c9d6-4856-9f8b-5426c7a757ea<\/p>\n\n<p>waiting for AAD role to propagate.done<\/p>\n\n<p>Provisioning compute resources...<\/p>\n\n<p>BadRequestFormat: The request format was invalid. Details: Updating clusters with cluster type Local is not supported<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-12-03 16:17:18.663 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":149,
        "Owner_creation_date":"2013-08-27 06:22:15.203 UTC",
        "Owner_last_access_date":"2022-09-19 18:05:53.57 UTC",
        "Owner_reputation":1853,
        "Owner_up_votes":168,
        "Owner_down_votes":0,
        "Owner_views":315,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47620404",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66592313,
        "Question_title":"Get local workspace in azureml",
        "Question_body":"<p>I am trying to run a machine learning experiment in azureml.<\/p>\n<p>I can't figure out how to get the workspace context from the control script.  Examples like <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data#control-script\" rel=\"nofollow noreferrer\">this one<\/a> in the microsoft docs use Workspace.from_config().  When I use this in the control script I get the following error:<\/p>\n<blockquote>\n<p>&quot;message&quot;: &quot;We could not find config.json in: [path] or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;<\/p>\n<\/blockquote>\n<p>I've also tried including my subscription id and the resource specs like so:<\/p>\n<pre><code>subscription_id = 'id'\nresource_group = 'name'\nworkspace_name = 'name'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n<\/code><\/pre>\n<p>In this case I have to monitor the log and authenticate on each run as I would locally.<\/p>\n<p>How do you get the local workspace from a control script for azureml?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-12 00:03:37.267 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":333,
        "Owner_creation_date":"2017-12-06 00:36:24.493 UTC",
        "Owner_last_access_date":"2022-09-22 22:49:47.607 UTC",
        "Owner_reputation":868,
        "Owner_up_votes":109,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Answer_body":"<p>This had no answers for 10 months, and now they are coming in :).  I figuerd this out quite a while ago but haven't gotten around to posting the answer.  Here it is.<\/p>\n<p>From the training script, you can get the workspace from the run context as follows:<\/p>\n<pre><code>from azureml.core import Run\nRun.get_context()\nws = run.experiment.workspace\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-12 03:28:12.267 UTC",
        "Answer_score":0.0,
        "Owner_location":"Bloomington, IN, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66592313",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55064123,
        "Question_title":"Unable to register an ONNX model in azure machine learning service workspace",
        "Question_body":"<p>I was trying to register an ONNX model to Azure Machine Learning service workspace in two different ways, but I am getting errors I couldn't solve.<\/p>\n\n<p><strong>First method: Via Jupyter Notebook and python Script<\/strong><\/p>\n\n<pre><code>model = Model.register(model_path = MODEL_FILENAME,\n                       model_name = \"MyONNXmodel\",\n                       tags = {\"onnx\":\"V0\"},\n                       description = \"test\",\n                       workspace = ws)\n<\/code><\/pre>\n\n<p>The error is : <strong>HttpOperationError: Operation returned an invalid status code 'Service invocation failed!Request: GET <a href=\"https:\/\/cert-westeurope.experiments.azureml.net\/rp\/workspaces\" rel=\"nofollow noreferrer\">https:\/\/cert-westeurope.experiments.azureml.net\/rp\/workspaces<\/a>'<\/strong><\/p>\n\n<p><strong>Second method: Via Azure Portal<\/strong>\n<a href=\"https:\/\/i.stack.imgur.com\/0BJrO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0BJrO.png\" alt=\"Error: Create model &quot;MyONNXmodel&quot;: ajax error 413.\"><\/a><\/p>\n\n<p>Anyone can help please?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2019-03-08 13:22:25.573 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-04-08 01:32:28.163 UTC",
        "Question_score":1,
        "Question_tags":"azure|onnx|azure-machine-learning-service",
        "Question_view_count":244,
        "Owner_creation_date":"2017-01-10 13:34:39.08 UTC",
        "Owner_last_access_date":"2022-09-22 15:43:10.21 UTC",
        "Owner_reputation":54,
        "Owner_up_votes":44,
        "Owner_down_votes":0,
        "Owner_views":55,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Sfax, Tunisie",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55064123",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53525147,
        "Question_title":"Azure ML vs Azure function for running R-Script",
        "Question_body":"<p>The stats team has developed an R-Script that takes an array of variables and returns an array of integers (calculations). I want to build this as a stand alone function that I can call with HTTP requests from various apps. A lot of the stuff I am reading is out dated. Should I use Azure ML or Azure functions for this? <\/p>\n\n<p>Note: The R-Script does not contain any machine learning.\nThe R-Script contains a package that is not listed on azure.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-11-28 17:37:40.437 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"r|azure-functions|azure-machine-learning-studio",
        "Question_view_count":1280,
        "Owner_creation_date":"2012-01-10 08:24:51.227 UTC",
        "Owner_last_access_date":"2021-10-20 16:48:33.707 UTC",
        "Owner_reputation":979,
        "Owner_up_votes":71,
        "Owner_down_votes":1,
        "Owner_views":108,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53525147",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68170867,
        "Question_title":"Deploy Azure ML to custom kubernetes",
        "Question_body":"<p>Is it possible to deploy image produced by Azure ML to Self managed Kubernetes using helm charts? we just want to consume the image and model.<\/p>\n<p>I see that when it is deployed to an inferencecluster in AKS, there are certain ENV variables being set by Azure ML. So, want to understand if anyone has done this setup manually on custom kubernetes cluster and what are the challenges?<\/p>\n<p>The reason is to deploy to cluster which is managed already by production team.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2021-06-28 23:03:37.413 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service|azure-machine-learning-workbench|azureml-python-sdk",
        "Question_view_count":169,
        "Owner_creation_date":"2021-01-29 16:16:26.203 UTC",
        "Owner_last_access_date":"2021-10-20 13:38:24.5 UTC",
        "Owner_reputation":55,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"United Kingdom",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68170867",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73760033,
        "Question_title":"How to transfer a csv file from notebook folder to a datastore",
        "Question_body":"<p>I want to transfer a generated csv file <code>test_df.csv<\/code> from my Azure ML notebook folder which has a path <code>\/Users\/Ankit19.Gupta\/test_df.csv<\/code> to a datastore which has a web path <code>https:\/\/abc.blob.core.windows.net\/azureml\/LocalUpload\/f3db18b6<\/code>. I have written the python code as<\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.from_config()\ndatastore = ws.get_default_datastore()\n    \ndatastore.upload_files('\/Users\/Ankit19.Gupta\/test_df.csv',\n                  target_path='https:\/\/abc.blob.core.windows.net\/azureml\/LocalUpload\/f3db18b6',\n                  overwrite=True)\n<\/code><\/pre>\n<p>But it is showing the following error message:<\/p>\n<pre><code>UserErrorException: UserErrorException:\n    Message: '\/' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;'\/' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.&quot;\n    }\n}\n<\/code><\/pre>\n<p>I have tried <a href=\"https:\/\/stackoverflow.com\/questions\/67897947\/how-to-transfer-data-from-azure-ml-notebooks-to-a-storage-container\">this<\/a> but it is not working for me. Can anyone please help me to resolve this issue. Any help would be appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-18 04:00:33.117 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|file-upload|azure-machine-learning-service|movefile",
        "Question_view_count":43,
        "Owner_creation_date":"2018-10-21 20:43:54.483 UTC",
        "Owner_last_access_date":"2022-09-24 14:48:13.903 UTC",
        "Owner_reputation":237,
        "Owner_up_votes":60,
        "Owner_down_votes":0,
        "Owner_views":173,
        "Answer_body":"<p>The way the path was mentioned is not accurate. The datastore path will be different manner.\nReplace the below code for the small change in the calling path.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4o1WU.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4o1WU.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.from_config()\ndatastore = ws.get_default_datastore()\n    \ndatastore.upload_files('.\/Users\/foldername\/filename.csv',\n                  target_path=\u2019your targetfolder',\n                  overwrite=True)\n<\/code><\/pre>\n<p>We need to call all the parent folders before the folder.  <strong><code>\u201c.\/\u201d<\/code><\/strong> is the way we can call the dataset from datastore.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-09-20 07:20:53.173 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73760033",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67552090,
        "Question_title":"Delete and recreate the registry for an azure machine learning workspace",
        "Question_body":"<p>Our azure machine learning workspace container registry has grown extremely large (4Tb) and has many obsolete entries. I would like to delete the registry and simply create a new one. We do not need any entries from the old one.<\/p>\n<p>If I delete the current registry, create a new one, how do I attach it to the workspace?  I dont want to create a new workspace.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-15 23:43:11.18 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":172,
        "Owner_creation_date":"2019-08-14 14:48:38.45 UTC",
        "Owner_last_access_date":"2022-09-25 02:16:40.673 UTC",
        "Owner_reputation":113,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67552090",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61270842,
        "Question_title":"Azure ML SDK to DataIKU (python Recepie) integration",
        "Question_body":"<p>WE are installing Azure Machine Learning SDK in Python Code Recipe in DataIKU.<\/p>\n\n<p>The Model coding is more manual when using SDK, Is there a way where we can create models in ML Studio (Drag and Drop) and use it's service in Python to get the output. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-17 11:44:49.007 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":62,
        "Owner_creation_date":"2020-01-10 09:44:37.907 UTC",
        "Owner_last_access_date":"2020-06-01 07:52:26.847 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61270842",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42105549,
        "Question_title":"Azure Machine Learning Studio and OpenCV",
        "Question_body":"<p>Has anyone successfully used the entire opencv library with Azure ML Studio and the Python Module? I know to use a python module that is not included in the ananconda version it must be uploaded in as a zip and from there you can use the entire library. Could someone explain to me exactly what to upload as a zip and then how to access specific functions of the opencv library once uploaded.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_creation_date":"2017-02-08 05:42:56.98 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":2112,
        "Owner_creation_date":"2015-10-12 03:10:51.79 UTC",
        "Owner_last_access_date":"2022-09-22 00:25:05.207 UTC",
        "Owner_reputation":823,
        "Owner_up_votes":98,
        "Owner_down_votes":8,
        "Owner_views":48,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Sydney NSW, Australia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42105549",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58019308,
        "Question_title":"ScriptRunConfig with datastore reference on AML",
        "Question_body":"<p>When trying to run a ScriptRunConfig, using :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>src = ScriptRunConfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', ds.as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>\n\n<p>It doesn't work and breaks with this when I submit the job : <\/p>\n\n<pre><code>... lots of things... and then\nTypeError: Object of type 'DataReference' is not JSON serializable\n<\/code><\/pre>\n\n<p>However if I run it with the Estimator, it works. One of the differences is the fact that with a <code>ScriptRunConfig<\/code> we're using a list for parameters and the other is a dictionary.<\/p>\n\n<p>Thanks for any pointers!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-19 21:48:40.367 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":1541,
        "Owner_creation_date":"2018-09-30 02:52:40.603 UTC",
        "Owner_last_access_date":"2022-07-22 02:57:21.83 UTC",
        "Owner_reputation":381,
        "Owner_up_votes":75,
        "Owner_down_votes":2,
        "Owner_views":50,
        "Answer_body":"<p>Being able to use <code>DataReference<\/code> in <code>ScriptRunConfig<\/code> is a bit more involved than doing just <code>ds.as_mount()<\/code>. You will need to convert it into a string in <code>arguments<\/code> and then update the <code>RunConfiguration<\/code>'s <code>data_references<\/code> section with the <code>DataReferenceConfiguration<\/code> created from <code>ds<\/code>. Please <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-remote-vm\/train-on-remote-vm.ipynb\" rel=\"nofollow noreferrer\">see here<\/a> for an example notebook on how to do that.<\/p>\n<p>If you are just reading from the input location and not doing any writes to it, please check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-register-datasets\" rel=\"nofollow noreferrer\"><code>Dataset<\/code><\/a>. It allows you to do exactly what you are doing without doing anything extra. <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/train-with-datasets.ipynb\" rel=\"nofollow noreferrer\">Here is an example notebook<\/a> that shows this in action.<\/p>\n<p>Below is a short version of the notebook<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Dataset\n\n# more imports and code\n\nds = Datastore(workspace, 'mydatastore')\ndataset = Dataset.File.from_files(path=(ds, 'path\/to\/input-data\/within-datastore'))\n\nsrc = ScriptRunConfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', dataset.as_named_input('input').as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-09-20 02:14:46.667 UTC",
        "Answer_score":4.0,
        "Owner_location":"Montreal, QC, Canada",
        "Answer_last_edit_date":"2020-07-28 22:14:22.437 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58019308",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51966899,
        "Question_title":"In Azure Stream Analytics Bad Request results when calling Azure Machine Learning function even though Azure ML service is called fine from C#",
        "Question_body":"<p>We have an Azure Machine Learning web service that is called fine from a C# program.  And it works fine when called as an HTML post (with Headers and a JSON string in the body).  However, in Azure Stream Analytics you have to create a Function to call an ML service.  And when this function is called in ASA, it fails with Bad Request.<\/p>\n\n<p>The documentation for the ML service gives the following documentation:<\/p>\n\n<p>Request Body\nSample Request<\/p>\n\n<pre><code>{\n   \"Inputs\":{\n      \"input\":[\n         {\n            \"device\":\"60-1-94-49-36-c5\",\n            \"uid\":\"5f4736aabfc1312385ea09805cc922\",\n            \"weight\":\"9-9-9-9-9-8-9-8-9-9-9-9-9-9-9-9-9-8-9-9-8-8-9-9-9-9-9- \n9-9-9-9-9-9-9-8-9-9-9-9-9-9-9-9-9-9-9-9-9-8-9-9-9-9-9-9-9-9-9-9-9-9-9-9-9-9- \n9-9-8-9-9-9-9-8-9-9-9-8-9-9-9-9-9-9-9-9-9-8-9-9-9-9-8-8-16-16-15-16-16-15- \n15-16-15-15-15-15-16-15-15-16-15-15-9-15-15-15-15-15-15-15-9-15-16-15-15-9- \n15-16-16-16-15-15-15-15-15-15-15-15-16-16-15-9-15-15-15-16-15-16-15-15-15- \n15-15-16-15-15-16-16-15-15-15\"\n         }\n      ]\n   },\n   \"GlobalParameters\":{\n\n   }\n}\n<\/code><\/pre>\n\n<p>The Azure Stream Analytics function (that calls the ML service above) has this signature:<\/p>\n\n<pre><code>FUNCTION SIGNATURE\nSmartStokML2018Aug17 ( device NVARCHAR(MAX) , \n                       uid    NVARCHAR(MAX) , \n                       weight NVARCHAR(MAX) ) RETURNS RECORD\n<\/code><\/pre>\n\n<p>Here the function is expecting 3 string arguments and NOT a full JSON string.  The 3 parameters are strings (NVARCHAR as shown).<\/p>\n\n<p>The 3 parameters have been passed in: device, uid and weight.  And in different string formats.  This includes passing the string arguments as JSON strings, using JSON.stringify() in a UDF, or sending in arguments with just data, no headers (\"device\", \"uid\", \"weight\").  But all calls to the ML service fail.<\/p>\n\n<pre><code>WITH QUERY1 AS ( \nSELECT DEVICE, UID, WEIGHT, \n       udf.jsonstringify( concat('{\"device\": \"',try_cast(device as nvarchar(max)), '\"}')) jsondevice,\n       udf.jsonstringify( concat('{\"uid\": \"',try_cast(uid as nvarchar(max)), '\"}')) jsonuid,\n       udf.jsonstringify( concat('{\"weight\": \"',try_cast(weight as nvarchar(max)), '\"}')) jsonweight\nFROM iothubinput2018aug21 ),\n\nQUERY2 AS (\nSELECT IntellistokML2018Aug21(JSONDEVICE, JSONUID, JSONWEIGHT) AS RESULT\nFROM QUERY1\n)\n\nSELECT *    \nINTO OUT2BLOB20                \nFROM QUERY2\n<\/code><\/pre>\n\n<p>Most of the errors are:\n    ValueError: invalid literal for int() with base 10: '\\\\\" {weight:9'\\n\\r\\n\\r\\n<\/p>\n\n<blockquote>\n  <blockquote>\n    <p>In what format does the ML Service expect these parameters to be passed in?<\/p>\n  <\/blockquote>\n<\/blockquote>\n\n<p>Note: the queries have been tried with ASA Compatibility Level 1 and 1.1.<\/p>",
        "Question_answer_count":6,
        "Question_comment_count":1,
        "Question_creation_date":"2018-08-22 12:27:17.563 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-stream-analytics",
        "Question_view_count":588,
        "Owner_creation_date":"2016-03-08 00:17:14.213 UTC",
        "Owner_last_access_date":"2021-09-29 09:12:54.74 UTC",
        "Owner_reputation":326,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":25,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Stuttgart, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51966899",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":33229576,
        "Question_title":"Arduino Uno - WebService (AzureML)",
        "Question_body":"<p>I'd like to connect to an AzureML Web Service. I have looked into the POST Method on the Arduino Homepage and also here <a href=\"https:\/\/iotguys.wordpress.com\/2014\/12\/25\/communicating-with-microsoft-azure-eventhub-using-arduino\/\" rel=\"nofollow\">https:\/\/iotguys.wordpress.com\/2014\/12\/25\/communicating-with-microsoft-azure-eventhub-using-arduino\/<\/a><\/p>\n\n<p>Here is my Setup method:<\/p>\n\n<pre><code>    void setup()\n    {\n      Serial.begin(9600);\n      while (!Serial) {\n      ; \/\/ wait for serial port to connect.\n      }\n\n     Serial.println(\"ethernet\");\n\n     if (Ethernet.begin(mac) == 0) {\n       Serial.println(\"ethernet failed\");\n       for (;;) ;\n     }\n    \/\/ give the Ethernet shield a second to initialize:\n    delay(1000);\n }\n<\/code><\/pre>\n\n<p>The Post Method is based on this: <a href=\"http:\/\/playground.arduino.cc\/Code\/WebClient\" rel=\"nofollow\">http:\/\/playground.arduino.cc\/Code\/WebClient<\/a><\/p>\n\n<p>I just added <code>sprintf(outBuf, \"Authorization: Bearer %s\\r\\n\", api_key);<\/code> to the header, with <code>char* api_key = \"the ML Web Service API KEY\"<\/code><\/p>\n\n<p>Also, unlike specified in the WebClient I use the whole WebService URI as url and do not specify a page name.<\/p>\n\n<p>This doesn't work.<\/p>\n\n<p>The Network to which I am connecting has Internet Access.<\/p>\n\n<p>What am I doing wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-10-20 06:34:30.153 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2016-03-29 22:25:44.957 UTC",
        "Question_score":0,
        "Question_tags":"web-services|azure|arduino-uno|azure-machine-learning-studio",
        "Question_view_count":154,
        "Owner_creation_date":"2013-05-21 15:47:19.453 UTC",
        "Owner_last_access_date":"2022-05-20 18:01:02.22 UTC",
        "Owner_reputation":516,
        "Owner_up_votes":5,
        "Owner_down_votes":1,
        "Owner_views":57,
        "Answer_body":"<p>Machine Learning Studio services that you create needs to receive requests from a device that has SSL capabilities to perform HTTPS requests. AFAIK, Arduino doesn't support SSL capabilities.<\/p>\n\n<p>One usual scenario is to attach the Arduino to a third device like Raspberry Pi 2 etc to use it as a gateway and do the call from the Pi itself.<\/p>\n\n<p>Here's a sample <a href=\"https:\/\/github.com\/Azure\/connectthedots\/blob\/master\/GettingStarted.md\" rel=\"nofollow\">project<\/a> from Microsoft Open Technologies team that utilizes Arduino Uno, Raspberry pi and Azure stuff.<\/p>\n\n<p>Hope this helps!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2015-12-17 07:27:41.483 UTC",
        "Answer_score":0.0,
        "Owner_location":"Germany",
        "Answer_last_edit_date":"2015-12-17 10:04:05.647 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/33229576",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56240481,
        "Question_title":"Can I import data from On-Premises SQL Server Database to Azure Machine Learning virtual machine?",
        "Question_body":"<p>On the limited Azure Machine Learning Studio, one can import data from an On-Premises SQL Server Database.\nWhat about the ability to do the exact same thing on a python jupyter notebook on a virtual machine from the Azure Machine Learning Services workspace ?<\/p>\n\n<p>It does not seem possible from what I've found in the documentation.\nData sources would be limited in Azure ML Services : \"Currently, the list of supported Azure storage services that can be registered as datastores are Azure Blob Container, Azure File Share, Azure Data Lake, Azure Data Lake Gen2, Azure SQL Database, Azure PostgreSQL, and Databricks File System\"<\/p>\n\n<p>Thank you in advance for your assistance<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-21 14:26:44.447 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|sql|azure|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":1147,
        "Owner_creation_date":"2019-05-21 14:13:07.353 UTC",
        "Owner_last_access_date":"2022-04-20 09:16:53.527 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>As of today, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-load-data#load-sql-data\" rel=\"nofollow noreferrer\">you can load SQL data, but only a MS SQL Server source (also on-premise) is supported<\/a>.<\/p>\n\n<p>Using <code>azureml.dataprep<\/code>, code would read along the lines of<\/p>\n\n<pre><code>import azureml.dataprep as dprep\n\nsecret = dprep.register_secret(value=\"[SECRET-PASSWORD]\", id=\"[SECRET-ID]\")\n\nds = dprep.MSSQLDataSource(server_name=\"[SERVER-NAME]\",\n                           database_name=\"[DATABASE-NAME]\",\n                           user_name=\"[DATABASE-USERNAME]\",\n                           password=secret)\n\ndflow = dprep.read_sql(ds, \"SELECT top 100 * FROM [YourDB].[ATable]\")\n# print first records\ndflow.head(5)\n<\/code><\/pre>\n\n<p>As far as I understand the APIs are under heavy development and <code>azureml.dataprep<\/code> may be soon superseded by functionality provided by the <a href=\"https:\/\/aka.ms\/azureml\/concepts\/datasets\" rel=\"nofollow noreferrer\">Dataset class<\/a>.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-05-21 22:53:14.14 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56240481",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73455846,
        "Question_title":"Error in deploying model on azure kubernetes service",
        "Question_body":"<p>I am deploying a model on Azure Machine Learning studio using azure kubernetes service<\/p>\n<pre><code>env = Environment(name='ocr')\naks_name = 'ocr-compute-2'\n# Create the cluster\naks_target = AksCompute(ws, aks_name)\n\n\n\n\nenv.python.conda_dependencies.add_pip_package('google-cloud-vision')\nenv.python.conda_dependencies.add_pip_package('Pillow')\nenv.python.conda_dependencies.add_pip_package('Flask == 2.2.2')\n\nenv.python.conda_dependencies.add_pip_package('azureml-defaults')\n\n\ninference_config = InferenceConfig(environment=env, source_directory='.\/', entry_script='.\/run1.py')\n\ndeployment_config = AksWebservice.deploy_configuration(autoscale_enabled=True, \n                                                autoscale_target_utilization=20,\n                                                autoscale_min_replicas=1,\n                                                autoscale_max_replicas=4)\n<\/code><\/pre>\n<p>I am getting this error<\/p>\n<pre><code>  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Kubernetes Deployment failed&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,\n      &quot;message&quot;: &quot;Your container application crashed as it does not have AzureML serving stack.\nMake sure you have 'azureml-defaults&gt;=1.0.45' package in your pip dependencies, it contains requirements for the AzureML serving stack.&quot;\n    }\n<\/code><\/pre>\n<p>Will be great if I can know what I am missing here.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2022-08-23 08:59:16.733 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|kubernetes|azure-devops|azure-machine-learning-service|azure-container-instances",
        "Question_view_count":81,
        "Owner_creation_date":"2019-09-07 18:22:12.003 UTC",
        "Owner_last_access_date":"2022-08-28 17:07:56.487 UTC",
        "Owner_reputation":137,
        "Owner_up_votes":22,
        "Owner_down_votes":0,
        "Owner_views":100,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Lahore, Pakistan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73455846",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":47488544,
        "Question_title":"Using Azure Storage libraries in AzureML - Custom python library",
        "Question_body":"<p>I am sort of new to Python, so I probably don't understand fully how to exactly import the libraries correctly into Azure ML.<\/p>\n\n<p>I have a bunch of data stored in Table storage which I have local Python code to successfully join all of them as a preparation for the ML experiment. I learned that AzureML environment does not have the Azure-Storage libraries installed, and therefore procceded the steps according <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn955437.aspx\" rel=\"nofollow noreferrer\">this<\/a> to upload a ZIP file containing the Azure-storage libraries that I found under anaconda3\\lib\\site-packages. I took all of the azure directories and shoved them under one single zip file and followed the bottom of the document in the link to upload the zip file as a DataSet and attach the dataset to an Execute Python script node in ML.<\/p>\n\n<p>I am getting errors like this when I try to run the node:<\/p>\n\n<pre><code>requestId = 825883c7ccb74f7e869e68e60d3cd919 errorComponent=Module. taskStatusCode=400. e \"C:\\pyhome\\lib\\ssl.py\", line 856, in send return self._sslobj.write(data) File \"C:\\pyhome\\lib\\ssl.py\", line 581, in write return self._sslobj.write(data)socket.timeout: The write operation timed outDuring handling of the above exception, another exception occurred:Traceback (most recent call last): File \"C:\\pyhome\\lib\\site-packages\\requests\\adapters.py\", line 376, in send timeout=timeout File \"C:\\pyhome\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 609, in urlopen _stacktrace=sys.exc_info()[2]) File \"C:\\pyhome\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\", line 247, in increment raise six.reraise(type(error), error, _stacktrace) File \"C:\\pyhome\\lib\\site-packages\\requests\\packages\\urllib3\\packages\\six.py\", line 309, in reraise raise value.with_traceback(tb) File \"C:\\pyhome\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 559, in urlopen body=body, headers=headers) File \"C:\\pyhome\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 353, in _make_request conn.request(method, url, **httplib_request_kw) File \"C:\\pyhome\\lib\\http\\client.py\", line 1083, in request self._send_request(method, url, body, headers) File \"C:\\pyhome\\lib\\http\\client.py\", line 1128, in _send_request self.endheaders(body) File \"C:\\pyhome\\lib\\http\\client.py\", line 1079, in endheaders self._send_output(message_body) File \"C:\\pyhome\\lib\\http\\client.py\", line 911, in _send_output self.send(msg) File \"C:\\pyhome\\lib\\http\\client.py\", line 885, in send self.sock.sendall(data) File \"C:\\pyhome\\lib\\ssl.py\", line 886, in sendall v = self.send(data[count:]) File \"C:\\pyhome\\lib\\ssl.py\", line 856, in send return self._sslobj.write(data) File \"C:\\pyhome\\lib\\ssl.py\", line 581, in write return self._sslobj.write(data)requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', timeout('The write operation timed out',))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"c:\\temp\\script bundle\\azure\\storage\\storageclient.py\", line 221, in _perform_request response = self._httpclient.perform_request(request) File \"c:\\temp\\script bundle\\azure\\storage\\_http\\httpclient.py\", line 114, in perform_request proxies=self.proxies) File \"C:\\pyhome\\lib\\site-packages\\requests\\sessions.py\", line 468, in request resp = self.send(prep, **send_kwargs) File \"C:\\pyhome\\lib\\site-packages\\requests\\sessions.py\", line 576, in send r = adapter.send(request, **kwargs) File \"C:\\pyhome\\lib\\site-packages\\requests\\adapters.py\", line 426, in send raise ConnectionError(err, request=request)requests.exceptions.ConnectionError: ('Connection aborted.', timeout('The write operation timed out',))During handling of the above exception, another exception occurred:Traceback (most recent call last): File \"C:\\server\\invokepy.py\", line 199, in batch odfs = mod.azureml_main(*idfs) File \"C:\\temp\\fa22884a19884f658d411dc0bdf05715.py\", line 33, in azureml_main data = table_service.query_entities(table_name) File \"c:\\temp\\script bundle\\azure\\storage\\table\\tableservice.py\", line 728, in query_entities resp = self._query_entities(*args, **kwargs) File \"c:\\temp\\script bundle\\azure\\storage\\table\\tableservice.py\", line 795, in _query_entities operation_context=_context) File \"c:\\temp\\script bundle\\azure\\storage\\table\\tableservice.py\", line 1093, in _perform_request return super(TableService, self)._perform_request(request, parser, parser_args, operation_context) File \"c:\\temp\\script bundle\\azure\\storage\\storageclient.py\", line 279, in _perform_request raise ex File \"c:\\temp\\script bundle\\azure\\storage\\storageclient.py\", line 251, in _perform_request raise AzureException(ex.args[0])azure.common.AzureException: ('Connection aborted.', timeout('The write operation timed out',))Process returned with non-zero exit code \n<\/code><\/pre>\n\n<p>I am not sure what I am doing wrong<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-11-25 17:10:02.23 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure-storage|azure-machine-learning-studio",
        "Question_view_count":150,
        "Owner_creation_date":"2012-06-22 16:00:52.68 UTC",
        "Owner_last_access_date":"2022-09-16 22:49:38.86 UTC",
        "Owner_reputation":73,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>In Azure ML Studio, Python scripts (and R scripts for that matter) run in a sandbox so cannot access resources over the network. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/execute-python-scripts?#limitations\" rel=\"nofollow noreferrer\">limitations<\/a>:<\/p>\n<blockquote>\n<p>The Execute Python Script currently has the following limitations:<\/p>\n<ol>\n<li>Sandboxed execution. The Python runtime is currently sandboxed and, as\na result, does not allow access to the network...<\/li>\n<\/ol>\n<\/blockquote>\n<p>So if you want to read from a blob use the separate Import Data module and if you want to write to a blob use the separate Export Data module.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-11-26 02:00:20.62 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-02-27 08:14:43.923 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/47488544",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68799689,
        "Question_title":"400 bad request when running the pipeline",
        "Question_body":"<p>I am new to azure and I'm creating a simple hellow world pipeline. Here is how I create tasks:<\/p>\n<pre><code>data_import_step = PythonScriptStep(\n      script_name=&quot;Data_Load_Preprocessing.py&quot;,\n      arguments=['--process_output',data_step_output],\n      allow_reuse=False,\n      outputs=[data_step_output],\n      runconfig=RunConfiguration(),\n      compute_target=aml_compute,\n      source_directory=process_directory\n   )\n<\/code><\/pre>\n<p>I am declaring aml_compute like this:<\/p>\n<pre><code>aml_compute = AmlCompute(ws, clustername)\n<\/code><\/pre>\n<p>and getting workspace like this<\/p>\n<pre><code>ws = Workspace.from_config(path=&quot;.\/config.json&quot;, auth=interactive_auth)\n<\/code><\/pre>\n<p>and data_load_preprocessing.py looks like this:<\/p>\n<pre><code>def main():\n    print(&quot;hellow world&quot;)\nif __name__ == '__main__':\n    main()\n<\/code><\/pre>\n<p>I get following error:\nervice invocation failed!\nRequest: GET ....\nStatus Code: 400 BadRequest\nError Code: ValidationError\nReason Phrase: Bad Request<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-16 08:33:24.663 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-08-16 09:16:01.94 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":316,
        "Owner_creation_date":"2021-07-03 19:42:10.163 UTC",
        "Owner_last_access_date":"2021-12-10 16:25:29.973 UTC",
        "Owner_reputation":63,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68799689",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69907928,
        "Question_title":"How to dump and utilize multiple ML algorithm objects in one single pickle file in Azure ML workspace?",
        "Question_body":"<p>I am trying to create a ML model in Azure ML Workspace using Jupyter notebook. I am not using AutoML feature or Designer provided by Azure, and want to run the complete code prepared locally.<\/p>\n<p>There are 3 different algorithms used in my ML Model. I am confused how can I save all the objects in one single pickle file, which I can utilize later in &quot;Inference configuration&quot; and &quot;Score.py&quot; file? Also, once saved how can I access them in &quot;Score.py&quot; file (which is the main file that contains the driver code)?<\/p>\n<p>Currently I am using following method:<\/p>\n<pre><code>import pickle\nf= 'prediction.pkl'\nall_models=[Error_Message_countvector, ErrorMessage_tfidf_fit, model_naive]\nwith open(f, 'wb') as files:\n    pickle.dump(all_models, files)\n<\/code><\/pre>\n<p>and to access the objects:<\/p>\n<pre><code>cv_output = loaded_model[0].transform(input_series)\ntfidf_output = loaded_model[1].transform(cv_output)\nloaded_model_prediction = loaded_model[2].predict(tfidf_output)\n<\/code><\/pre>\n<p>Somehow, this method works fine when I run in the same cell as the entire code. But it throws error when I deploy the complete model.<\/p>\n<p>My &quot;Score.py&quot; file looks something like this:<\/p>\n<pre><code>import json\nfrom azureml.core.model import Model\nimport joblib\nimport pandas as pd\n\ndef init():\n    global prediction_model \n    prediction_model_path = Model.get_model_path(&quot;prediction&quot;)    \n    prediction_model = joblib.load(prediction_model_path)     \n\ndef run(data):\n    try:\n        data = json.loads(data)     \n        input_string= str(data['errorMsg']).strip()             \n        input_series=pd.Series(input_string)            \n        cv_output= prediction_model[0].transform(input_series)\n        tfidf_output = prediction_model[1].transform(cv_output) \n        result = prediction_model[2].predict(tfidf_output)           \n        return {'response' : result }\n\n    except Exception as e:\n        error = str(e)\n        return {'response' : error }\n<\/code><\/pre>\n<p>and the error received on deployment is:<\/p>\n<pre><code>Error:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Error in entry script, AttributeError: module '__main__' has no attribute 'text_cleaning', please run print(service.get_logs()) to get details.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,\n      &quot;message&quot;: &quot;Error in entry script, AttributeError: module '__main__' has no attribute 'text_cleaning', please run print(service.get_logs()) to get details.&quot;\n    }\n  ]\n}\n<\/code><\/pre>\n<p>Can anyone help me understand the issue or figure out if there is something missing\/wrong in the code?<\/p>\n<p>What is the right way of saving multiple algorithm objects in one single pickle file?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-11-10 04:14:17.44 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-10 12:01:47.607 UTC",
        "Question_score":0,
        "Question_tags":"python|machine-learning|pickle|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":182,
        "Owner_creation_date":"2021-08-05 12:26:08.503 UTC",
        "Owner_last_access_date":"2021-11-12 03:49:15.457 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69907928",
        "Question_exclusive_tag":"Azure Machine Learning"
    }
]