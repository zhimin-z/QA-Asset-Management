[
    {
        "Question_title":"Acessing Tensorboard on AzureML during training",
        "Question_body":"<p>How to use view Tensorboard during an AzureML training run on in the Cloud.<\/p>\n<p>Followed this tutorial:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-tensorboard#launch-tensorboard\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-tensorboard#launch-tensorboard<\/a><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.tensorboard import Tensorboard\n\ntb = Tensorboard([run])\n\n# If successful, start() returns a string with the URI of the instance.\ntb.start()\n\n# After your job completes, be sure to stop() the streaming otherwise it will continue to run. \ntb.stop()\n<\/code><\/pre>\n<p>The logs contains the url <code>http:\/\/localhost:6006\/<\/code> printed by the <code>tb.start()<\/code> statement.\nThis is somehow silly as it runs in the cloud.<\/p>\n<p>How to get the full url to the node in the cluster where Tensorboard was launched?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-06 09:06:52.76 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"tensorboard|azure-machine-learning-service",
        "Question_view_count":122,
        "Owner_creation_date":"2016-09-22 08:48:50.87 UTC",
        "Owner_last_access_date":"2022-02-18 09:44:31.3 UTC",
        "Owner_location":"Germany",
        "Owner_reputation":975,
        "Owner_up_votes":52,
        "Owner_down_votes":0,
        "Owner_views":122,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Register on-prem db as Dataset in Azure ML Studio UI",
        "Question_body":"<p>how can I connect the new Azure Machine Learning Studio UI to an on-premise SQL DB via an on-premise data Gateway?<\/p>\n<p>In the classic version, once the gateway was installed and registered the Import data module offered it as a dataset type. In the new UI however it doesn't seem to be available.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-30 14:09:06.513 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":76,
        "Owner_creation_date":"2020-02-02 16:59:57.867 UTC",
        "Owner_last_access_date":"2021-11-30 14:25:41.327 UTC",
        "Owner_location":"Prague, Czechia",
        "Owner_reputation":23,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-11-30 19:41:04.397 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Issues Formatting Azure Cognitive skill set input correctly for ML integration",
        "Question_body":"<p>I am attempting to integrate Azure machine learning with Azure Cognitive Search. I am using a Skill Set and currently the schema for the real-time ML endpoint is this:<\/p>\n<pre><code>&quot;Inputs&quot;: {\n        &quot;WebServiceInput0&quot;:\n        [\n            {\n\n                &quot;CompanyName&quot;: &quot;Apple Inc&quot;,\n            }\n        ]\n    }\n\n<\/code><\/pre>\n<p>When using a debugging session to determine if the skill set setup is correct, I get an error saying that the input data doesn't follow the schema.<\/p>\n<p>This is what the skill set outputs:<\/p>\n<pre><code>&quot;Inputs&quot;: {\n          &quot;WebServiceInput0&quot;: {\n            &quot;CompanyName&quot;: &quot;Apple Inc&quot;,\n          }\n        }\n<\/code><\/pre>\n<p>I have noticed in the schema that the <strong>WebServiceInput0<\/strong> property is an array and therefore this is potentially causing the issue.<\/p>\n<p>I am wondering how I could format the input and add &quot;[&quot; to make <strong>WebServiceInput0<\/strong> an array.<\/p>\n<p>I have tried the Shaper Skill although this wasn't helpful.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-10 02:42:53.743 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-cognitive-search|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":30,
        "Owner_creation_date":"2013-12-02 00:49:21.683 UTC",
        "Owner_last_access_date":"2021-08-10 04:48:22.717 UTC",
        "Owner_location":"Sydney NSW, Australia",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Endpoint error 'GradientBoostingRegressor' object has no attribute 'n_features_'",
        "Question_body":"<p>While running the endpoint testing in Azure ML, I am experiencing one error related to the reading of input data.<\/p>\n<p>Steps followed :<\/p>\n<ol>\n<li>Running Gradient boost model\n2.Train and test the data and save it in the model. pkl file<\/li>\n<li>Registering the model on azure ML and deploying the configuration with the code<\/li>\n<li>Reading score.py for the init() and run()<\/li>\n<\/ol>\n<p>Train.py code<\/p>\n<pre><code>%%writefile $script_folder\/train.py\n\nimport argparse\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.svm import SVC\nimport joblib\nimport pickle\nfrom azureml.core import Workspace, Dataset, Experiment\nfrom azureml.core import Run\nimport re\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer\nimport seaborn as sns\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import chi2\nimport math\nimport pickle\n#ws = Workspace.from_config()\n#az_dataset = Dataset.get_by_name(ws, 'pricing')\n\n# let user feed in 2 parameters, the location of the data files (from datastore), and the regularization rate of the logistic regression model\n#parser = argparse.ArgumentParser()\n#parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n#parser.add_argument('--regularization', type=float, dest='reg', default=0.01, help='regularization rate')\n#args = parser.parse_args()\n\ntrain_data = pd.read_csv(&quot;C:\\\\Users\\\\abhay\\\\Downloads\\\\Projects_DataScience\\\\Ensemble_Machine_Learning\\\\dataset\\\\train_update.csv&quot;)\n\ncolumn_datatypes = train_data.dtypes\ncategorical_columns = list(column_datatypes[column_datatypes==&quot;object&quot;].index.values)\ncontinuous_columns = list(column_datatypes[column_datatypes==&quot;float64&quot;].index.values)\ncontinuous_columns.remove('loss')\n\n\n\ntotal_rows = train_data.shape[0]\ncolumns_with_blanks_cat = np.random.randint(1,116,2)\ncolumns_with_blanks_cont = np.random.randint(117,130,3)\ncolumns_with_blank = np.append(columns_with_blanks_cat,columns_with_blanks_cont)\n\n#for every column insert 5 blanks at random locations\nfor col in columns_with_blank:\n    rows_with_blanks = np.random.randint(1,total_rows,5)\n    train_data.iloc[rows_with_blanks,col] = np.nan\n    \nclass Data_preprocessing:\n    def __init__(self,train_data):\n        self.train_data = train_data\n    \n    def missing_value_continuous(self,column_names_with_specific_type,imputation_type=&quot;mean&quot;): # null value imputation with mean value\n        if imputation_type==&quot;mean&quot;: # mean imputation \n            mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n            mean_imputer.fit(self.train_data[column_names_with_specific_type])\n            self.train_data[column_names_with_specific_type]=mean_imputer.transform(self.train_data[column_names_with_specific_type])\n        if imputation_type==&quot;median&quot;: # median imputation\n            median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n            median_imputer.fit(self.train_data[column_names_with_specific_type])\n            self.train_data[column_names_with_specific_type]=median_imputer.transform(self.train_data[column_names_with_specific_type])\n        return self.train_data\n    \n    def missing_value_categorical(self,column_names_with_specific_type,imputation_type=&quot;most_frequent&quot;): # check for missing categorical column values\n        most_frequent = SimpleImputer(strategy=&quot;most_frequent&quot;)\n        most_frequent.fit(self.train_data[column_names_with_specific_type])\n        self.train_data[column_names_with_specific_type] = most_frequent.transform(train_data[column_names_with_specific_type])\n        return self.train_data\n    \n    def outlier_treatment(self,Q1,Q3,IQR,columns_with_outlier,action): # outlier treatmenr\n        if action==&quot;median&quot;:\n            for i in range(len(columns_with_outlier)):\n                column_name = columns_with_outlier[i]\n                meadian_outlier = np.median(self.train_data[column_name])\n                self.train_data.loc[self.train_data[((self.train_data[column_name]&lt;(Q1[column_name]-(1.5*IQR[column_name])))|(self.train_data[column_name]&gt;(Q3[column_name]+(1.5*IQR[column_name]))))].index,column_name]=meadian_outlier\n        if action==&quot;mean&quot;:\n            for i in range(len(columns_with_outlier)):\n                column_name = columns_with_outlier[i]\n                mean_outlier = np.mean(self.train_data[column_name])\n                self.train_data.loc[self.train_data[((self.train_data[column_name]&lt;(Q1[column_name]-(1.5*IQR[column_name])))|(self.train_data[column_name]&gt;(Q3[column_name]+(1.5*IQR[column_name]))))].index,column_name]=mean_outlier\n        if action==&quot;remove&quot;:\n            for i in range(len(columns_with_outlier)):\n                column_name = columns_with_outlier[i]\n                self.train_data = self.train_data[~((self.train_data[column_name]&lt;(Q1[column_name]-(1.5*IQR[column_name])))|(self.train_data[column_name]&gt;(Q3[column_name]+(1.5*IQR[column_name]))))]\n        return self.train_data    \n    \n    \ncolumn_names = np.array(train_data.columns)\nData_preprocessing_obj = Data_preprocessing(train_data)\ntrain_data = Data_preprocessing_obj.missing_value_continuous(continuous_columns,&quot;median&quot;)\ntrain_data = Data_preprocessing_obj.missing_value_categorical(categorical_columns)\ncolumns_with_outlier = ['cont7','cont9','cont10']\nQ1 = train_data[continuous_columns].quantile(0.25)\nQ3 = train_data[continuous_columns].quantile(0.75)\nIQR = (Q3-Q1)\ntrain_data = Data_preprocessing_obj.outlier_treatment(Q1,Q3,IQR,columns_with_outlier,&quot;median&quot;)\ndef feature_selection_numerical_variables(train_data,qthreshold,corr_threshold,exclude_numerical_cols_list):\n    num_colums = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    numerical_columns = list(train_data.select_dtypes(include=num_colums).columns)\n    numerical_columns = [column for column in numerical_columns if column not in exclude_numerical_cols_list]\n    \n    #remove variables with constant variance\n    constant_filter = VarianceThreshold(threshold=0)\n    constant_filter.fit(train_data[numerical_columns])\n    constant_columns = [column for column in train_data[numerical_columns].columns \n                    if column not in train_data[numerical_columns].columns[constant_filter.get_support()]]\n    if len(constant_columns)&gt;0:\n        train_data.drop(labels=constant_columns, axis=1, inplace=True)\n\n    #remove deleted columns from dataframe\n    numerical_columns = [column for column in numerical_columns if column not in constant_columns]\n        \n    #remove variables with qconstant variance\n    #Remove quasi-constant variables\n    qconstant_filter = VarianceThreshold(threshold=qthreshold)\n    qconstant_filter.fit(train_data[numerical_columns])\n    qconstant_columns = [column for column in train_data[numerical_columns].columns \n                         if column not in train_data[numerical_columns].columns[constant_filter.get_support()]]\n    if len(qconstant_columns)&gt;0:\n        train_data.drop(labels=qconstant_columns, axis=1, inplace=True)\n    \n    #remove deleted columns from dataframe\n    numerical_columns = [column for column in numerical_columns if column not in qconstant_columns]\n    \n    #remove correlated variables\n    correlated_features = set()\n    correlation_matrix = train_data[numerical_columns].corr()\n    ax = sns.heatmap(\n    correlation_matrix, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True)\n    ax.set_xticklabels(\n        ax.get_xticklabels(),\n        rotation=45,\n        horizontalalignment='right');\n    #print(correlation_matrix)\n    \n    for i in range(len(correlation_matrix.columns)):\n        for j in range(i):\n            if abs(correlation_matrix.iloc[i, j]) &gt; corr_threshold:\n                colname = correlation_matrix.columns[i]\n                colcompared = correlation_matrix.columns[j]\n                #check if the column compared against is not in the columns excluded list\n                if colcompared not in correlated_features:\n                    correlated_features.add(colname)\n    train_data.drop(labels=correlated_features, axis=1, inplace=True)\n    \n    return train_data,constant_columns,qconstant_columns,correlated_features\ntrain_data,constant_columns,qconstant_columns,correlated_features =feature_selection_numerical_variables(train_data,0.01,0.75,['loss','id'],)\n\nfor cf1 in categorical_columns:\n    le = LabelEncoder()\n    le.fit(train_data[cf1].unique())\n    filename = cf1+&quot;.sav&quot;\n    pickle.dump(le, open(filename, 'wb'))\n    train_data[cf1] = le.transform(train_data[cf1])\n\n#snippet to calculate the unique values with a categorical columns\ndf = pd.DataFrame(columns=[&quot;Column_Name&quot;,&quot;Count&quot;])\nfor cat in categorical_columns:\n    unique_value_count = len(train_data[cat].unique())\n    df = df.append({'Column_Name': cat, &quot;Count&quot;:int(unique_value_count)}, ignore_index=True)\ncolumns_unique_value = np.array(df.Count.value_counts().index)\n\n#snippet to identify the dependent\/correlated categorical variables and drop them\ncolumns_to_drop_cat = set()\ncorrelated_columns = dict()\nfor unique_value_count in columns_unique_value:\n    if unique_value_count&gt;1:\n        categorical_columns = df.loc[df.Count==unique_value_count,'Column_Name']\n        categorical_columns = categorical_columns.reset_index(drop=True)\n        columns_length=len(categorical_columns)\n        for col in range(columns_length-1):\n            column_to_compare = categorical_columns[col]\n            columns_compare_against = categorical_columns[(col+1):columns_length]\n            chi_scores = chi2(train_data[columns_compare_against],train_data[column_to_compare])\n            if column_to_compare not in columns_to_drop_cat:\n                columns_to_be_dropped = [i for i in range(len(columns_compare_against)) if chi_scores[1][i]&lt;=0.05]\n                columns_to_drop_array = np.array(columns_compare_against)[columns_to_be_dropped]\n                correlated_columns[column_to_compare]=columns_to_drop_array\n                columns_to_drop_cat.update(columns_to_drop_array)\n                \ntrain_data = train_data.drop(columns_to_drop_cat,axis=1)\ncorrelated_features = list(correlated_features)\ncolumns_to_drop_cat = list(columns_to_drop_cat)\ncolumns_to_drop_cat.extend(correlated_features)\ncolumns_to_drop = columns_to_drop_cat.copy()\n\n#output the columns_to_drop file to a csv\ncolumns_to_drop_df=pd.DataFrame(columns_to_drop,columns=['colnames'])\n#columns_to_drop_df.to_csv(&quot;\/model\/columns_to_drop.csv&quot;,index=False)\n\ntrain_data['loss'] = np.log(train_data['loss'])\n\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\n#convert the int64 columns categorical\nColumn_datatypes= train_data.dtypes\nInteger_columns = list(Column_datatypes.where(lambda x: x ==&quot;int64&quot;).dropna().index.values)\ntrain_data[Integer_columns] = train_data[Integer_columns].astype('category',copy=False)\nX,y = train_data.drop(['id','loss'],axis=1),train_data['loss']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) # perform train test split\n\nref_cols=X_train.columns\n\n\nfrom sklearn.ensemble import GradientBoostingRegressor  #GBM algorithm\ngbm_base = GradientBoostingRegressor(\n    max_depth=2,\n    n_estimators=3,\n    learning_rate=1.0)\n\ntrained_model=gbm_base.fit(X_train,y_train)\n\n\n\n# Predict the outcome using Test data - Score Model \nY_test_predict_tuned = gbm_base.predict(X_test)\n\n# Get the probability score - Scored Probabilities\n#Y_prob = gbm_base.predict_proba(X_test)[:, 1]\n\n# Get Confusion matrix and the accuracy\/score - Evaluate\n\nscore =np.sqrt(mean_squared_error(y_test, Y_test_predict_tuned))\n\n#print('Export the model to model.pkl')\n#f = open('fwrk2.pkl', 'wb')\n#pickle.dump(trained_model, f)\n#f.close()\n\n#print('Import the model from model.pkl')\n#f2 = open('fwrk2.pkl', 'rb')\n#clf2 = pickle.load(f2)\n\n#X_new = [[154, 54, 35]]\n#print('New Sample:', X_new)\n#print('Predicted class:', clf2.predict(X_new))\n\n#os.makedirs('outputs', exist_ok=True)\n# note file saved in the outputs folder is automatically uploaded into experiment record\n#joblib.dump(value=trained_model, filename='outputs\/fwrk2.pkl')\n<\/code><\/pre>\n<p>Reading the score.py<\/p>\n<pre><code>%%writefile score.py\nimport json\nimport numpy as np\nimport os\nimport pickle\nimport pandas as pd\nimport joblib\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n\nfrom azureml.core.model import Model\n\ndef init():\n    global model\n    #model = joblib.load('recommender.pkl')\n    model_path = Model.get_model_path('fwrk2')\n    model = joblib.load(model_path)\n\ninput_sample = pd.DataFrame(data=[{&quot;cat1&quot;:0, &quot;cat4&quot;: 0, &quot;cat14&quot;: 0, &quot;cat15&quot;: 0, &quot;cat18&quot;: 0, &quot;cat19&quot;: 0, &quot;cat20&quot;: 0, &quot;cat21&quot;: 0\n                                   , &quot;cat22&quot;: 0, &quot;cat35&quot;: 0, &quot;cat42&quot;:0, &quot;cat47&quot;: 0, &quot;cat48&quot;: 0, &quot;cat55&quot;: 0\n                                   , &quot;cat56&quot;: 0, &quot;cat58&quot;: 0, &quot;cat59&quot;: 0, &quot;cat60&quot;: 0, &quot;cat61&quot;: 0, &quot;cat62&quot;: 0\n                                   , &quot;cat63&quot;: 0, &quot;cat64&quot;: 0, &quot;cat68&quot;: 0, &quot;cat70&quot;: 0, &quot;cat76&quot;: 0, &quot;cat77&quot;:0\n                                   , &quot;cat78&quot;: 0, &quot;cat82&quot;: 0, &quot;cat85&quot;: 0, &quot;cat86&quot;: 0, &quot;cat89&quot;: 0, &quot;cat91&quot;: 0\n                                   , &quot;cat92&quot;: 0, &quot;cat93&quot;: 0, &quot;cat94&quot;:0, &quot;cat96&quot;: 0, &quot;cat97&quot;: 0, &quot;cat99&quot;: 0\n                                   , &quot;cat100&quot;: 0, &quot;cat101&quot;: 0, &quot;cat103&quot;: 0, &quot;cat105&quot;: 0, &quot;cat107&quot;: 0, &quot;cat109&quot;:0\n                                   , &quot;cat110&quot;: 0, &quot;cat111&quot;: 0, &quot;cat112&quot;: 0, &quot;cat113&quot;: 0, &quot;cat116&quot;: 0, &quot;cont1&quot;: 0\n                                   , &quot;cont2&quot;: 0, &quot;cont3&quot;: 0, &quot;cont4&quot;: 0, &quot;cont5&quot;: 0\n                                   , &quot;cont6&quot;: 0, &quot;cont7&quot;: 0, &quot;cont8&quot;: 0, &quot;cont14&quot;: 0}])\n\noutput_sample = np.array([0])              # This is a integer type sample. Use the data type that reflects the expected result\n\n@input_schema('data', PandasParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\n\ndef run(data):\n    try:\n        result = model.predict(data)\n        # you can return any datatype as long as it is JSON-serializable\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<p>The endpoint publish is succeeded, and I can see the test feature on the azure portal to enter values, post entering the values.<\/p>\n<pre><code>[{&quot;cat1&quot;:0, &quot;cat4&quot;: 0, &quot;cat14&quot;: 0, &quot;cat15&quot;: 0, &quot;cat18&quot;: 0, &quot;cat19&quot;: 0, &quot;cat20&quot;: 0, &quot;cat21&quot;: 0\n                                   , &quot;cat22&quot;: 0, &quot;cat35&quot;: 0, &quot;cat42&quot;:0, &quot;cat47&quot;: 0, &quot;cat48&quot;: 0, &quot;cat55&quot;: 0\n                                   , &quot;cat56&quot;: 0, &quot;cat58&quot;: 0, &quot;cat59&quot;: 0, &quot;cat60&quot;: 0, &quot;cat61&quot;: 0, &quot;cat62&quot;: 0\n                                   , &quot;cat63&quot;: 0, &quot;cat64&quot;: 0, &quot;cat68&quot;: 0, &quot;cat70&quot;: 0, &quot;cat76&quot;: 0, &quot;cat77&quot;:0\n                                   , &quot;cat78&quot;: 0, &quot;cat82&quot;: 0, &quot;cat85&quot;: 0, &quot;cat86&quot;: 0, &quot;cat89&quot;: 0, &quot;cat91&quot;: 0\n                                   , &quot;cat92&quot;: 0, &quot;cat93&quot;: 0, &quot;cat94&quot;:0, &quot;cat96&quot;: 0, &quot;cat97&quot;: 0, &quot;cat99&quot;: 0\n                                   , &quot;cat100&quot;: 0, &quot;cat101&quot;: 0, &quot;cat103&quot;: 0, &quot;cat105&quot;: 0, &quot;cat107&quot;: 0, &quot;cat109&quot;:0\n                                   , &quot;cat110&quot;: 0, &quot;cat111&quot;: 0, &quot;cat112&quot;: 0, &quot;cat113&quot;: 0, &quot;cat116&quot;: 0, &quot;cont1&quot;: 0\n                                   , &quot;cont2&quot;: 0, &quot;cont3&quot;: 0, &quot;cont4&quot;: 0, &quot;cont5&quot;: 0\n                                   , &quot;cont6&quot;: 0, &quot;cont7&quot;: 0, &quot;cont8&quot;: 0, &quot;cont14&quot;: 0}])\n<\/code><\/pre>\n<p>Error: &quot;'GradientBoostingRegressor' object has no attribute 'n_features&quot;<\/p>\n<p>Please can someone guide what could be the problem in executing the above input sample? Is it related to the version of the package, and if yes, then how to update it and solve it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-22 09:18:55.573 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":21,
        "Owner_creation_date":"2018-02-01 08:16:36.617 UTC",
        "Owner_last_access_date":"2022-09-23 06:55:53.343 UTC",
        "Owner_location":"Mumbai",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to enable authentication for an ACI webservice in Azure Machine Learning service?",
        "Question_body":"<p>I am able to deploy a Azure Machine learning prediction service in my workspace <code>ws<\/code> using the syntax<\/p>\n\n<pre><code>aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=8, \n                                               tags={\"method\" : \"some method\"}, \n                                               description='Predict something')\n<\/code><\/pre>\n\n<p>and then<\/p>\n\n<pre><code>service = Webservice.deploy_from_image(deployment_config = aciconfig,\n                                       image = image,\n                                       name = service_name,\n                                       workspace = ws)\n<\/code><\/pre>\n\n<p>as described in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#aci\" rel=\"nofollow noreferrer\">documentation<\/a>.<br>\nHowever, this exposes a service publicly and this is not really optimal.<\/p>\n\n<p>What's the easiest way to shield the ACI service? I understand that passing an <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.webservice.aciwebservice?view=azure-ml-py#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none-\" rel=\"nofollow noreferrer\"><code>auth_enabled=True<\/code><\/a> parameter may do the job, but then how can I instruct a client (say, using <code>curl<\/code> or Postman) to use the service afterwards? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-04-24 19:55:31.34 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azure-container-instances",
        "Question_view_count":676,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_location":"Verona, VR, Italy",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":"<p>See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service#call-the-service-c\" rel=\"nofollow noreferrer\">here<\/a> for an example (in C#). When you enable auth, you will need to send the API key in the \"Authorization\" header in the HTTP request:<\/p>\n\n<pre><code>client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", authKey);\n<\/code><\/pre>\n\n<p>See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service#authentication-key\" rel=\"nofollow noreferrer\">here<\/a> how to retrieve the key.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2019-04-25 08:49:30.523 UTC",
        "Answer_last_edit_date":"2019-04-25 09:06:44.093 UTC",
        "Answer_score":2.0,
        "Question_last_edit_date":"2019-04-25 10:02:27.293 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML's web service asking for label?",
        "Question_body":"<p>I built a linear regression algorithm in Azure ML. On the &quot;Score Model&quot; module I can actually see the predictions and the rest of the features. However, when I deploy this project as a web service, the service is expecting the actual label of the data (e.g. I'm trying to predict a house's price and it asks me for the price of the house to make the prediction), which doesn't make any sense to me... What am I doing wrong? On the &quot;Train Model&quot; module I set that the label column is the HousePrice, which is what I'm trying to predict...<\/p>\n<p>This is my model:\n<a href=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I tried leaving that field blank but the prediction returns null...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2016-10-13 18:16:02.787 UTC",
        "Question_favorite_count":null,
        "Question_score":4,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1012,
        "Owner_creation_date":"2014-06-02 17:25:36.86 UTC",
        "Owner_last_access_date":"2022-09-12 15:39:08.48 UTC",
        "Owner_location":null,
        "Owner_reputation":1102,
        "Owner_up_votes":390,
        "Owner_down_votes":25,
        "Owner_views":120,
        "Answer_body":"<p>The input schema (names\/types of required input) based on the location in the graph where you attach the \"Web Service Input\" module. To get the schema you want, you will need to find -- or if necessary, create -- a place in the experiment where the data has the column names\/types you desire.<\/p>\n\n<p>Consider this simple example experiment that predicts whether a field called \"income\" will be above or below $50k\/year:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When we click \"Set up web service\", the following graph is automatically generated:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Since the input dataset and \"Web service input\" modules are connected to the same port, the web service schema will perfectly match the schema of the input dataset. This is unfortunate because the input dataset contains a column called \"income\", which is what our web service is supposed to predict -- this is equivalent to the problem that you are having.<\/p>\n\n<p>To get around it, we need to create a place in our experiment graph where we've dropped the unneeded \"income\" field from the input dataset, and attach the \"Web service input\" module there:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>With this arrangement, the web service only requests the features actually needed to score the model. I'm sure you can use a similar method to create a predictive experiment with whatever input schema you need for your own work.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-10-17 18:55:27.013 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":3.0,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Using R to extract specific column in Azure ML",
        "Question_body":"<p>I have created a forecasting causal model in Azure ML studio that determines an organization's hiring needs for every month for 2015. Since it is a causal model, I individually forecast all parameters for 2015 and supply them to my model.<\/p>\n\n<p>One such factor is previous 9 months Hire value. It means that if I am forecasting a hire value for Jan-2015, the previous 9 month hire values will be considered (Dec - April 2014).<\/p>\n\n<p>The following is my parameter set:<\/p>\n\n<pre><code>Year    Month   Factor A    Factor B    Factor C    Factor D    Prev. Month-1   Prev. Month-2   Prev. Month-3   Prev. Month-4   Prev. Month-5   Prev. Month-6   Prev. Month-7   Prev. Month-8   Prev. Month-9\n<\/code><\/pre>\n\n<p>Sample Input:<\/p>\n\n<pre><code>Year    Month   Factor A    Factor B    Factor C    Factor D    Prev. Month-1   Prev. Month-2   Prev. Month-3   Prev. Month-4   Prev. Month-5   Prev. Month-6   Prev. Month-7   Prev. Month-8   Prev. Month-9\n2015    1       2           4           6           8           10              11              12              13              14              15              16              17              18\n<\/code><\/pre>\n\n<p>Once I run the model, I get the Forecasted hire (Score Labels) as my output:<\/p>\n\n<pre><code>Year    Month   Factor A    Factor B    Factor C    Factor D    Prev. Month-1   Prev. Month-2   Prev. Month-3   Prev. Month-4   Prev. Month-5   Prev. Month-6   Prev. Month-7   Prev. Month-8   Prev. Month-9   Score Labels\n2015    1       2           4           6           8           10              11              12              13              14              15              16              17              18              19\n<\/code><\/pre>\n\n<p>For forecasting for February-2015, the forecasted value for January becomes Prev. Month-1 value. <\/p>\n\n<pre><code>Year    Month   Factor A    Factor B    Factor C    Factor D    Prev. Month-1   Prev. Month-2   Prev. Month-3   Prev. Month-4   Prev. Month-5   Prev. Month-6   Prev. Month-7   Prev. Month-8   Prev. Month-9\n2015    1       2           4           6           8           10              11              12              13              14              15              16              17              18\n2015    2       3           5           7           9           19              10              11              12              13              14              15              16              17\n<\/code><\/pre>\n\n<p>This becomes a bit tedious as I have to repeat it 12 times - one for each month. Can someone suggest how do I solve it using R script? Here is what I have written so far:<\/p>\n\n<pre><code>dataset &lt;- maml.mapInputPort(1) \n\nprevious &lt;- 9\norig_names &lt;- names(dataset)\nn_rows &lt;- dim(dataset)[1]\n\nbase &lt;- 9\nfor (i in 1:previous) {\n  dataset[(i+1):n_rows,base+i] &lt;- dataset[1:(n_rows-i),base]\n  dataset[1:i,base+i] &lt;- dataset[1:i,base+i-1]\n}\n\na &lt;- -1:-previous\nnew_names &lt;- paste(\"Prev. Month\",a)\nnames(dataset) &lt;- c(orig_names,new_names)\n\nmaml.mapOutputPort(\"dataset\")\n<\/code><\/pre>\n\n<p>Thanks.<\/p>\n\n<p><strong>Update 1<\/strong><\/p>\n\n<p>I have managed to execute my model in a loop in Azure. For each iteration, I need to provide the input parameters (like for February). <\/p>\n\n<p>Can someone help me on how to obtain the forecast under \"Score Labels\" and append that as a parameter under \"Prev. Month-1\" to my input for next month in R? <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2015-07-08 04:15:12.023 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"r|azure|dataframe|azure-machine-learning-studio",
        "Question_view_count":305,
        "Owner_creation_date":"2015-01-31 04:53:22.7 UTC",
        "Owner_last_access_date":"2022-01-29 02:50:58.853 UTC",
        "Owner_location":"San Jose, CA, USA",
        "Owner_reputation":1221,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":163,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2016-03-11 22:29:17.553 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML v2 Pipeline Yaml : Steps not running in the specified Conda Environment",
        "Question_body":"<p>I am trying to build an azure ML pipeline using the Azureml cli v2 but the steps in the  pipeline are not running in the specified conda environment because I am getting a dependency error (which is already installed in the specified environment). Here is the yaml I am writing to generate the pipeline:<\/p>\n<pre><code>$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/pipelineJob.schema.json\ntype: pipeline\nexperiment_name: my_training\ndescription: Training Pipeline to train a model for binary classification\ninputs:\n training_images:\n    type: uri_folder\n    mode: download # pick ro_mount, rw_mount or download\n    path: azureml:\/\/datastores\/mydatastore\/paths\/my_data\/dummy_dataset\/**\n\noutputs:\n  step_output_train:\n    type: uri_folder\nsettings:\n  default_datastore: azureml:mydatastore\n  continue_on_step_failure: false\n\njobs:\n  train:\n    name: training\n    display_name: Model-training\n    environment: azureml:training_env@latest\n    code: ..\/..\/my_code\/training\n    command: &gt;-\n      python train.py\n      --step_output ${{outputs.step_output}}\n      --epochs ${{inputs.epochs}}\n    inputs:\n      epochs: 1  \n    outputs:\n      step_output: ${{parent.outputs.step_output_train}}\n    compute: azureml:mycomputeclust\n    resources:\n      instance_count: 1 \n\n<\/code><\/pre>\n<p>Please guide me how we can tackle this issue.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-05 05:48:40.017 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-pipelines|azure-machine-learning-service",
        "Question_view_count":86,
        "Owner_creation_date":"2018-08-19 06:02:24.467 UTC",
        "Owner_last_access_date":"2022-09-01 13:39:30.257 UTC",
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Can you create new directories in azure ml designer",
        "Question_body":"<p>So I'm creating a web service using the azure machine learning designer, I can safely import libraries from the Script Bundle and load files from it. But I can't seem to create new directories in it and save files inside this new directory. Tried using os.mkdirs and pathlib but didn't manage to do it. Is there any way to do so? Or in the current version this is not supported yet<\/p>\n<p>Edit: So to reproduce the problem i'm facing wrote two python scripts connected to a test Script Bundle in the Azure designer, now this zip file only contains a test txt file to make sure the script bundle isn't empty.\nAs follows in the images the first script creates a new directory in the bundle and creates a DataFrame containing the directories in the root of the zip file, the next script is responsible for creating and saving a txt file inside this newly created directory. What follows are screenshots of the problem and the scripts used:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/DsyPL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DsyPL.png\" alt=\"How the pipline structure looks like\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/vXfxN.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vXfxN.png\" alt=\"The first py script creating the new dir\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9xfjQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9xfjQ.png\" alt=\"Trying to save a txt file to this new dir\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2021-07-02 20:02:36.07 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|azure|azure-web-app-service|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":428,
        "Owner_creation_date":"2021-07-02 19:59:07.257 UTC",
        "Owner_last_access_date":"2022-09-24 00:47:37.17 UTC",
        "Owner_location":null,
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-07-05 13:30:19.783 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"1 minute Service timeout for AMLS models deployed on ACI or AKS",
        "Question_body":"<p>We have created an image scoring model on Machine learning Service and deployed using AMLS portal on ACI and AKS both.\nThough it runs on smaller images , for larger images it gets timed-out after exactly 1 minute on both ACI and AKS.\nIt is expected that an image scoring can take few minutes.<\/p>\n\n<p>Wanted to know , if it\u2019s a limitation on using AMLS deployment,  or on ACI and AKS that they timeout the deployed webservice after 60 seconds??\nAny workaround would be welcomed<\/p>\n\n<p>ACI Error :-\n Post <a href=\"http:\/\/localhost:5001\/score\" rel=\"nofollow noreferrer\">http:\/\/localhost:5001\/score<\/a>: net\/http: request canceled (Client.Timeout exceeded while awaiting headers)<\/p>\n\n<p>AKS Error :-\n Replica closed connection before replying<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2019-09-23 15:04:16.157 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"azure|azure-aks|azure-container-instances|azure-machine-learning-service",
        "Question_view_count":1976,
        "Owner_creation_date":"2017-10-22 09:05:10.973 UTC",
        "Owner_last_access_date":"2020-11-06 16:28:37.523 UTC",
        "Owner_location":null,
        "Owner_reputation":55,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"MLFlow creates a new experiment run when logging manually along with autolog",
        "Question_body":"<p>I am using MLFlow to log metrics and artefacts in the AzureML workspace. With <code>autolog<\/code>, tensorflow training metrics are available in the experiment run in the AzureML workspace. Along with auto-logging of metrics - I want to log extra metrics and plots in the same experiment run. Doing it with MLFlow - it is creating a new experiment run.<\/p>\n<p><strong>Auto logging:<\/strong><\/p>\n<p><code>mlflow.autolog()<\/code><\/p>\n<p><strong>Manual logging:<\/strong><\/p>\n<p><code>mlflow.log_metric(f&quot;label-A&quot;, random.randint(80, 90))<\/code><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/DC8S4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DC8S4.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>Expected:<\/strong>\nManually logged metrics are available in the same experiment run.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-03-09 12:19:22.673 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"metrics|mlflow|azure-machine-learning-service",
        "Question_view_count":316,
        "Owner_creation_date":"2015-02-16 15:05:31.103 UTC",
        "Owner_last_access_date":"2022-09-11 17:21:50.487 UTC",
        "Owner_location":"London, UK",
        "Owner_reputation":3982,
        "Owner_up_votes":171,
        "Owner_down_votes":17,
        "Owner_views":577,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Automl object detection local filesystem",
        "Question_body":"<p>I have tried to create a azure automl model to find an object in the image.<\/p>\n<p>According to the tutorial it is required that you specify the labels in adataframe where on of the columns are mounted to a aml datastore.<\/p>\n<p>Question: Is it possible to link it to a local repository instead eg in a compute?<\/p>\n<p>Link:  <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-image-models\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-image-models<\/a><\/p>\n<p>I tried to use os path but it did not work.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-03-21 19:00:54.553 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|object-detection|azure-machine-learning-service|azure-auto-ml",
        "Question_view_count":21,
        "Owner_creation_date":"2018-05-13 14:47:24.17 UTC",
        "Owner_last_access_date":"2022-06-12 12:08:47.33 UTC",
        "Owner_location":"Pakis, Indonesia",
        "Owner_reputation":101,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning - Memory Error while creating dataframe",
        "Question_body":"<p>I am getting memory error while creating simple dataframe read from CSV file on Azure Machine Learning using notebook VM as compute instance. The VM has config of DS 13 56gb RAM, 8vcpu, 112gb storage on Ubuntu (Linux (ubuntu 16.04). CSV file is 5gb file. <\/p>\n\n<pre><code>blob_service = BlockBlobService(account_name,account_key)\nblobstring = blob_service.get_blob_to_text(container,filepath).content\ndffinaldata = pd.read_csv(StringIO(blobstring), sep=',')\n<\/code><\/pre>\n\n<p>What I am doing wrong here ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-20 18:25:49.467 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":507,
        "Owner_creation_date":"2017-07-22 17:26:15.327 UTC",
        "Owner_last_access_date":"2022-08-09 00:17:13.3 UTC",
        "Owner_location":null,
        "Owner_reputation":255,
        "Owner_up_votes":20,
        "Owner_down_votes":0,
        "Owner_views":130,
        "Answer_body":"<p>you need to provide the right encoding when calling get_blob_to_text, please refer to the <a href=\"https:\/\/github.com\/Azure\/azure-storage-python\/blob\/master\/samples\/blob\/block_blob_usage.py#L390\" rel=\"nofollow noreferrer\">sample<\/a>.<\/p>\n\n<p>The code below is what  normally use for reading data file in blob storages. Basically, you can use blob\u2019s url along with sas token and use a request method. However, You might want to edit the \u2018for loop\u2019 depending what types of data you have (e.g. csv, jpg, and etc).<\/p>\n\n<p>-- Python code below --<\/p>\n\n<pre><code>import requests\nfrom azure.storage.blob import BlockBlobService, BlobPermissions\nfrom azure.storage.blob.baseblobservice import BaseBlobService\nfrom datetime import datetime, timedelta\n\naccount_name = '&lt;account_name&gt;'\naccount_key = '&lt;account_key&gt;'\ncontainer_name = '&lt;container_name&gt;'\n\nblob_service=BlockBlobService(account_name,account_key)\ngenerator = blob_service.list_blobs(container_name)\n\nfor blob in generator:\n    url = f\"https:\/\/{account_name}.blob.core.windows.net\/{container_name}\"\n    service = BaseBlobService(account_name=account_name, account_key=account_key)\n    token = service.generate_blob_shared_access_signature(container_name, img_name, permission=BlobPermissions.READ, expiry=datetime.utcnow() + timedelta(hours=1),)\n    url_with_sas = f\"{url}?{token}\"\n    response = requests.get(url_with_sas)\n<\/code><\/pre>\n\n<p>Please follow the below link to read data on Azure Blob Storage.\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-01-21 05:17:29.897 UTC",
        "Answer_last_edit_date":"2020-01-21 05:56:40.473 UTC",
        "Answer_score":0.0,
        "Question_last_edit_date":"2020-01-20 21:35:26.093 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to import custom functions on my experiment script for Azure ML?",
        "Question_body":"<p>I can successfully submit an experiment to processing on a remote compute target on Azure ML.<\/p>\n\n<p>In my notebook, for submitting the experiment, I have:<\/p>\n\n<pre><code># estimator\nestimator = Estimator(\n    source_directory='scripts',\n    entry_script='exp01.py',\n    compute_target='pc2',\n    conda_packages=['scikit-learn'],\n    inputs=[data.as_named_input('my_dataset')],\n    )\n\n# Submit\nexp = Experiment(workspace=ws, name='my_exp')\n\n# Run the experiment based on the estimator\nrun = exp.submit(config=estimator)\nRunDetails(run).show()\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n\n<p>However, in order to keep things clean, I want to define my general use functions on an auxiliary script, so the first will import it.<\/p>\n\n<p>On my script experiment file exp01.py, I wanted:<\/p>\n\n<pre><code>import custom_functions as custom\n\n# azure experiment start\nrun = Run.get_context()\n\n# the data from azure datasets\/datastorage\ndf = run.input_datasets['my_dataset'].to_pandas_dataframe()\n\n# prepare data\ndf_transformed = custom.prepare_data(df)\n\n# split data\nX_train, X_test, y_train, y_test = custom.split_data(df_transformed)\n\n# run my models.....\nmodel_name = 'RF'\nmodel = custom.model_x(model_name, a_lot_of_args)\n\n# log the results\nrun.log(model_name, results)\n\n# azure finish\nrun.complete()\n<\/code><\/pre>\n\n<p>The thing is: Azure wont let me import the custom_functions.py.<\/p>\n\n<p>How are you doing it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-04 16:58:30.473 UTC",
        "Question_favorite_count":1.0,
        "Question_score":2,
        "Question_tags":"python-3.x|azure|scikit-learn|azure-machine-learning-service",
        "Question_view_count":428,
        "Owner_creation_date":"2016-07-21 23:22:07.747 UTC",
        "Owner_last_access_date":"2022-09-23 16:54:04.637 UTC",
        "Owner_location":"Brazil",
        "Owner_reputation":914,
        "Owner_up_votes":791,
        "Owner_down_votes":5,
        "Owner_views":100,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Having a problem calling the function AudioConfig.FromWavFileInput through python library",
        "Question_body":"<p>I am trying to process a .wav file with the Azure Cognitive Speech Service. I am using the script below. I get an exception that says \"type object 'AudioConfig' has no attribute 'FromWavFileInput'\" when I try to setup the wav file by calling <a href=\"https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/microsoft.cognitiveservices.speech.audio.audioconfig.fromwavfileinput\" rel=\"nofollow noreferrer\">AudioConfig.FromWavFileInput()<\/a>. The documentation says the function exists, at least in the .net library. Does FromWaveFileInput exist for the <a href=\"https:\/\/pypi.org\/project\/azure-cognitiveservices-speech\/\" rel=\"nofollow noreferrer\">cognitiveservices-speech python library<\/a>? How can I process an audio file with python?<\/p>\n\n<pre><code>import azure.cognitiveservices.speech as speechsdk\n\nspeechKey = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\nservice_region = 'eastus2'\n\n#### # Creates an instance of a speech config with specified subscription key and service region.\n#### # Replace with your own subscription key and service region (e.g., \"westus\").\nspeech_config = speechsdk.SpeechConfig(subscription=speechKey, region=service_region)\n\naudioInput = speechsdk.AudioConfig.FromWavFileInput('RainSpain.wav')\n\n#### # Creates a recognizer with the given settings\nspeech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_input=audioInput)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2018-12-27 23:47:26.91 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|speech-recognition|azure-machine-learning-studio",
        "Question_view_count":1136,
        "Owner_creation_date":"2015-05-29 21:19:32.58 UTC",
        "Owner_last_access_date":"2021-11-03 17:53:17.473 UTC",
        "Owner_location":null,
        "Owner_reputation":5,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>Indeed as you said. I searched for the keywords <code>AudioConfig<\/code> &amp; <code>FromWavFileInput<\/code> on GitHub repo <a href=\"https:\/\/github.com\/Azure-Samples\/cognitive-services-speech-sdk\" rel=\"nofollow noreferrer\"><code>Azure-Samples\/cognitive-services-speech-sdk<\/code><\/a>, there is not any Python codes about it except for Java, C#, and <a href=\"https:\/\/github.com\/Azure-Samples\/cognitive-services-speech-sdk\/blob\/3131ab75577116fe9359242d6d86321808601e19\/samples\/cpp\/windows\/console\/samples\/speech_recognition_samples.cpp#L116\" rel=\"nofollow noreferrer\">C++<\/a>.<\/p>\n\n<p>So per my experience, there are two workaround ways to do it.<\/p>\n\n<ol>\n<li>Wrap the C++ codes as a <a href=\"https:\/\/docs.python.org\/3\/c-api\/index.html\" rel=\"nofollow noreferrer\">Python extension module<\/a>, or communicate with C++\/Java codes.<\/li>\n<li>Directly using <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/rest-apis\" rel=\"nofollow noreferrer\">Speech service REST APIs<\/a> with <a href=\"http:\/\/docs.python-requests.org\/en\/master\/\" rel=\"nofollow noreferrer\"><code>requests<\/code><\/a>, it's simple for Python and Azure Speech Service.<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-12-31 09:44:01.007 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2018-12-31 06:19:34.287 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to trigger a process based on an Azure ML model predictions?",
        "Question_body":"<p>It is possible to trigger, let's say, a process to send emails or SMS based on an Azure ML prediction?<\/p>\n<p>I have a customer segmentation model, and my goal is to contact a customer based on their segment. For example:<\/p>\n<ul>\n<li>All customers group A -&gt; phone call.<\/li>\n<li>All customers group B -&gt; SMS.<\/li>\n<\/ul>\n<p>And so on...<\/p>\n<p>How can I achieve this? How would be the recommended approach?\nI was reading this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-event-grid\" rel=\"nofollow noreferrer\">Microsoft docs<\/a> but these event driven actions are not what I need.<\/p>\n<p>Another thing that I was considering is what about saving the model response on a storage account and create a event action with Logic Apps or Azure Functions when adding data in this storage. This could work? Perhaps, it is important to mention that the model predictions are considered to be done once a month by a scheduled python script.<\/p>\n<p>Can someone give me an advice to what path can I follow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-09 21:02:58.86 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-functions|azure-logic-apps|azure-machine-learning-studio|azure-eventgrid",
        "Question_view_count":91,
        "Owner_creation_date":"2019-04-12 08:41:48.927 UTC",
        "Owner_last_access_date":"2022-08-24 20:37:09.997 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-06-09 21:14:37.6 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Compute Instance: Best practice for custom Anaconda env",
        "Question_body":"<p>I'd like to use a compute instance as my develop machine.\nAre there any best practices on how to handle custom Anaconda enviroments on these machines?<\/p>\n\n<p>So far, I do it this way:<\/p>\n\n<pre><code>conda create --name testenv python=3\nconda activate testenv\nconda install ipykernel\nipython kernel install --user --name=testenv\nsudo systemctl restart jupyter.service\n<\/code><\/pre>\n\n<p>--> Reload the JupyterHub in your browser.<\/p>\n\n<p>Do you see any drawbacks by doing it this way? I know, some special package combinations in the standard env are lost, but I'd like to know what I've installed in my system.\nOf course, one could combine it with an <code>environment.yml<\/code>.<\/p>\n\n<p>What do you think?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-03 10:04:21.87 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":116,
        "Owner_creation_date":"2020-05-11 13:50:20.747 UTC",
        "Owner_last_access_date":"2022-09-15 09:14:33.43 UTC",
        "Owner_location":"Germany",
        "Owner_reputation":163,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<p>Your workaround is the best option as of now. But I know that the Azure ML product group has been working on exactly this problem, but I can't make any promises as to timeline.<\/p>\n\n<p>I share your dream of an easily configurable data science cloud development environment that allows for Git repo cloning and environment creation w\/ a conda yml. We're so close especially given all the press &amp; announcements around Visual Studio Codespaces!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-06-04 17:04:16.907 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2020-06-11 08:51:17.773 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"azure machine learning workbench - High accuracy but very low confidence score",
        "Question_body":"<p>Im am new to Machine Learning, so please have that in mind before answering. \nI came across challenge trying to train a neural network in workbench using CNTK with ResNet model. \nI followed this tutorial provided from azure \n[1] <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/desktop-workbench\/scenario-image-classification-using-cntk\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/desktop-workbench\/scenario-image-classification-using-cntk<\/a><\/p>\n\n<p>My first dataset a subset from ImageNet consisting of 900 images with 4 different classes car, bus, van and truck. Afterwards I used a subset of the dataset provided from the link underneath.\n[2] <a href=\"http:\/\/podoce.dinf.usherbrooke.ca\/challenge\/dataset\/\" rel=\"nofollow noreferrer\">http:\/\/podoce.dinf.usherbrooke.ca\/challenge\/dataset\/<\/a><\/p>\n\n<p>I used 9000 images of the dataset divided equally into four different into the same classes as with ImageNet and started training my network.<\/p>\n\n<p>The classifier I used for this was the DNN classifier with the following configuration: <\/p>\n\n<pre><code> rf_pretrainedModelFilename = \"ResNet_50.model\" \n rf_inputResoluton = 224                \n rf_dropoutRate    = 0.5                 \n rf_mbSize         = 10               \n rf_maxEpochs      = 30                \n rf_maxTrainImages = float('inf')        \n rf_lrPerMb        = [0.01] * 10 + [0.001] * 10 + [0.0001] \n rf_momentumPerMb  = 0.9                 \n rf_l2RegWeight    = 0.0005              \n rf_boFreezeWeights      = False         \n rf_boBalanceTrainingSet = False          images\n<\/code><\/pre>\n\n<p>After training the model i got a overall accuracy of 96.80% with all classes having a accuracy > 92% . All well and done, but when I tested various other test images, my confidence score was 12.9895 at its highest peak. I  got a JSON object returned like this:\nImage classified as 'Bus' with confidence score 12.9895.<\/p>\n\n<pre><code>     {\\\"score\\\": \\\"12.9895\\\", \\\"Id2Labels\\\": \\\"{0: 'Bus', 1: 'Truck', 2: ' \n  Car', 3: 'Van'}\\\", \\\"label\\\": \\\"Bus\\\", \\\"executionTimeMs\\\": \\\"128.749\\\", \n  \\\"allScores\\\": \\\"[ 12.98949814   3.51014233  -6.96435881  -6.89878178]\\\"}\"\n<\/code><\/pre>\n\n<ul>\n<li>The value 12.9895 must mean <strong>12.9895% possibility<\/strong> for the image being a bus, right? and why is it not returned as a value between 0 and 1 ? Please correct me if i am wrong, as I do get confused over the various terms being used in Machine Learning for the same thing. <\/li>\n<li>Why are the minus values there, I thought the activation function took care of the minus values?<\/li>\n<li>Should I include a even larger dataset or maybe better image quality to improve my score?<\/li>\n<li>Any other suggestions to how I can improve my score?<\/li>\n<\/ul>\n\n<p>The score where low on both dataset mentioned, (Subset from ImageNet and MIO).\nA humble thank you, for taking the time answering these questions.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2018-07-30 23:38:25.73 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-studio|cntk",
        "Question_view_count":263,
        "Owner_creation_date":"2016-01-17 20:02:07.863 UTC",
        "Owner_last_access_date":"2019-06-21 12:44:01 UTC",
        "Owner_location":null,
        "Owner_reputation":53,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-07-31 02:41:19.573 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How azure ML give an output for a value which is not used when training the model?",
        "Question_body":"<p>I am trying to predict the price of a house. Therefore I added no-of-rooms as one variable to get the prediction. Previous values for that variable was (3,2,1) when I was training the model. Now I am adding no-of-rooms as \"6\" to get an output(which was not use before to get the predicted value). How will it give the output for a new value?<br>Is it only consider the variables except no-of-rooms ? I used Boosted decision tree regression as the model. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-01-31 05:03:20.357 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":47,
        "Owner_creation_date":"2018-02-17 05:42:48.43 UTC",
        "Owner_last_access_date":"2019-11-11 14:47:41.843 UTC",
        "Owner_location":"Colombo, Sri Lanka",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-01-31 06:54:07.137 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"\"Entry Point Not Found\" Error LightGBM R package in Azure",
        "Question_body":"<p>When using a LightGBM R package in Azure ML I get the following error:<\/p>\n\n<pre><code>[Error]         +++ NT HARD ERROR (0xc0000139) +++\n[Error]             Parameter 0: 0x4ad4bc8 [log2f]\n[Error]             Parameter 1: 0x4b5e2e8 [C:\\src\\lightgbm\\libs\\x64\\lib_lightgbm.dll]\n[Error]             Parameter 2: 0xffffffffc0000139\n[Error]         [FATAL] Exception: 0xc0000139 (!! HARD ERROR !!) {Params: 0x4ad4bc8, 0x4b5e2e8, 0xffffffffc0000139, 0x0}\n[Error]         [ERROR] A fatal error occurred in the running application. The application will be terminated. Code: 0xc0000139.\n<\/code><\/pre>\n\n<p>on <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/cc704588.aspx\" rel=\"nofollow noreferrer\">page<\/a> <code>0xc0000139<\/code> is described as \"Entry Point Not Found\". What does this error mean and how can I solve it?<\/p>\n\n<p>I used XGBoost in the same way in Azure ML and it worked. And it did not ask for external libraries (dlls). LightGBM on the contrary asks lots of libraries (dlls) and I think the problem is connected with the dlls, but this error does not indicate what is actually missing.<\/p>\n\n<p><strong>What I did:<\/strong> <br>Installed LightGBM R package  on a Virtual Machine with Windows Server 2016. For this I used:<\/p>\n\n<ul>\n<li>CMake<\/li>\n<li>C++ Development kit (installed almost all packages)<\/li>\n<li>RTools<\/li>\n<\/ul>\n\n<p>Included in lightgbm\\libs\\x64 are the following packages because I previously got error <code>0xc0000135<\/code> with the names of these libraries:<\/p>\n\n<ul>\n<li>msvcp140.dll<\/li>\n<li>vcomp140.dll<\/li>\n<li>vcruntime140.dll<\/li>\n<li>all api-ms-win-core-*.dll and all api-ms-win-crt-*.dll<\/li>\n<\/ul>\n\n<p>I tried to change the R version from Microsoft R Open 3.2.2 to CRAN R 3.1.0. It executes witout errors but does not execute code after library import.<\/p>\n\n<p>The full output of Azure ML R script:<\/p>\n\n<pre><code>Record Starts at UTC 08\/03\/2017 12:28:27:\n\nRun the job:\"\/dll \"LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS;RunRSNR\" \/Output0 \"..\\..\\Result Dataset\\Result Dataset.dataset\" \/Output1 \"..\\..\\R Device\\R Device.dataset\"  \/dataset1 \"..\\..\\Dataset1\\Dataset1.csv\"    \/bundlePath \"..\\..\\Script Bundle\\Script Bundle.zip\"  \/rStreamReader \"script.R\"  \/rLibVersion \"Microsoft R Open 3.2.2\"  \/ContextFile \"..\\..\\_context\\ContextFile.txt\"\"\n[Start] Program::Main\n[Start]     DataLabModuleDescriptionParser::ParseModuleDescriptionString\n[Stop]     DataLabModuleDescriptionParser::ParseModuleDescriptionString. Duration = 00:00:00.0045866\n[Start]     DllModuleMethod::DllModuleMethod\n[Stop]     DllModuleMethod::DllModuleMethod. Duration = 00:00:00.0000221\n[Start]     DllModuleMethod::Execute\n[Start]         DataLabModuleBinder::BindModuleMethod\n[Verbose]             moduleMethodDescription LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS;RunRSNR\n[Verbose]             assemblyFullName LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca\n[Start]             DataLabModuleBinder::LoadModuleAssembly\n[Verbose]                 Loaded moduleAssembly LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca\n[Stop]             DataLabModuleBinder::LoadModuleAssembly. Duration = 00:00:00.0093763\n[Verbose]             moduleTypeName Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS\n[Verbose]             moduleMethodName RunRSNR\n[Information]             Module FriendlyName : Execute R Script\n[Information]             Module Release Status : Release\n[Stop]         DataLabModuleBinder::BindModuleMethod. Duration = 00:00:00.0125213\n[Start]         ParameterArgumentBinder::InitializeParameterValues\n[Verbose]             parameterInfos count = 6\n[Verbose]             parameterInfos[0] name = dataset1 , type = Microsoft.Numerics.Data.Local.DataTable\n[Start]             DataTableCsvHandler::HandleArgumentString\n[Stop]             DataTableCsvHandler::HandleArgumentString. Duration = 00:00:00.2364734\n[Verbose]             parameterInfos[1] name = dataset2 , type = Microsoft.Numerics.Data.Local.DataTable\n[Verbose]             Set optional parameter dataset2 value to NULL\n[Verbose]             parameterInfos[2] name = bundlePath , type = System.String\n[Verbose]             parameterInfos[3] name = rStreamReader , type = System.IO.StreamReader\n[Verbose]             parameterInfos[4] name = seed , type = System.Nullable`1[System.Int32]\n[Verbose]             Set optional parameter seed value to NULL\n[Verbose]             parameterInfos[5] name = rLibVersion , type = Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS+ExecuteRScriptRVersion\n[Verbose]             Converted string 'Microsoft R Open 3.2.2' to enum of type Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS+ExecuteRScriptRVersion\n[Stop]         ParameterArgumentBinder::InitializeParameterValues. Duration = 00:00:00.3175225\n[Verbose]         Begin invoking method RunRSNR ... \n[ModuleOutput] Executing Against R 3.2.2.0\n[ModuleOutput] Executing Against R 3.2.2.0\n[Information]         Microsoft Drawbridge Console Host [Version 1.0.2108.0]\n[Error]         +++ NT HARD ERROR (0xc0000139) +++\n[Error]             Parameter 0: 0x4ad4bc8 [log2f]\n[Error]             Parameter 1: 0x4b5e2e8 [C:\\src\\lightgbm\\libs\\x64\\lib_lightgbm.dll]\n[Error]             Parameter 2: 0xffffffffc0000139\n[Error]         [FATAL] Exception: 0xc0000139 (!! HARD ERROR !!) {Params: 0x4ad4bc8, 0x4b5e2e8, 0xffffffffc0000139, 0x0}\n[Error]         [ERROR] A fatal error occurred in the running application. The application will be terminated. Code: 0xc0000139.\n[Information]         [1] 56000\n[Information]         The following files have been unzipped for sourcing in path=[\"src\"]:\n[Information]                            Name  Length                Date\n[Information]         1 data.table_1.10.4.zip 1487417 2017-07-07 16:48:00\n[Information]         2            lgb1.model   45142 2017-08-02 17:38:00\n[Information]         3            lgb2.model   83455 2017-08-02 17:38:00\n[Information]         4    lightgbm_2.0.4.zip 1350111 2017-08-03 14:26:00\n[Information]         5      magrittr_1.5.zip  152732 2017-07-07 15:34:00\n[Information]         6                R6.zip  317766 2017-08-03 10:33:00\n[Information]         Loading objects:\n[Information]           port1\n[Information]         [1] \"Loading variable port1...\"\n[Information]         package 'magrittr' successfully unpacked and MD5 sums checked\n[Information]         package 'R6' successfully unpacked and MD5 sums checked\n[Information]         package 'data.table' successfully unpacked and MD5 sums checked\n[Information]         package 'lightgbm' successfully unpacked and MD5 sums checked\n[Information]         data.table 1.10.4\n[Information]           The fastest way to learn (by data.table authors): https:\/\/www.datacamp.com\/courses\/data-analysis-the-data-table-way\n[Information]           Documentation: ?data.table, example(data.table) and browseVignettes(\"data.table\")\n[Information]           Release notes, videos and slides: http:\/\/r-datatable.com\n[Error]         Process returned with non-zero exit code -1073741511\n[Stop]     DllModuleMethod::Execute. Duration = 00:00:14.8676292\n[Critical]     Error: Error 1000: RPackage library exception: Attempting to obtain R output before invoking execution process\n[Critical]     {\"InputParameters\":{\"DataTable\":[{\"Rows\":50,\"Columns\":131,\"estimatedSize\":16928768,...........\"Errors\":\"Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 1000: RPackage library exception: Attempting to obtain R output before invoking execution process ---&gt; Microsoft.Analytics.Modules.R.ErrorHandling.RInvalidOperationException: Attempting to obtain R output before invoking execution process\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.NewRWorker.GetProcessOutputs(Boolean scrub) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\TempWorkers\\\\NewRWorker.cs:line 459\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.ExecuteR(NewRWorker worker, DataTable dataset1, DataTable dataset2, IEnumerable`1 bundlePath, StreamReader rStreamReader, Nullable`1 seed) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 278\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS._RunImpl(NewRWorker worker, DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable`1 seed, ExecuteRScriptExternalResource source, String url, ExecuteRScriptGitHubRepositoryType githubRepoType, SecureString accountToken) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 207\\r\\n   at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.RunRSNR(DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable`1 seed, ExecuteRScriptRVersion rLibVersion) in d:\\\\_Bld\\\\8831\\\\7669\\\\Sources\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\REntryPoint.cs:line 105\\r\\n   --- End of inner exception stack trace ---\",\"Warnings\":[],\"Duration\":\"00:00:14.8605990\"}\nModule finished after a runtime of 00:00:15.3186157 with exit code -2\nModule failed due to negative exit code of -2\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-08-03 13:09:04.79 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"c++|r|azure|dll|azure-machine-learning-studio",
        "Question_view_count":245,
        "Owner_creation_date":"2014-05-02 13:15:11.573 UTC",
        "Owner_last_access_date":"2022-09-23 13:52:40.84 UTC",
        "Owner_location":"Moscow, Russia",
        "Owner_reputation":2853,
        "Owner_up_votes":1981,
        "Owner_down_votes":6,
        "Owner_views":228,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-08-03 14:12:27.343 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML: experiment working for a subset and not for the whole dataset",
        "Question_body":"<p>some times ago I had written a code in AzureML meeting \"out of memory\" issues. So I tried to split the code in three different codes and that partially worked. It remains a part that (I think) is affected by memory issues too.<\/p>\n\n<p>I have created an experiment that I have published in this <a href=\"http:\/\/gallery.cortanaintelligence.com\/Experiment\/TextMining-sample-NA-v1-1\" rel=\"nofollow noreferrer\">link<\/a>.<\/p>\n\n<p>There is a module that considers only a sample of my dataset, and it does work. This means that the code is supposed to work correctly. If you remove the sampling code (the second module starting from the top) <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Cbzhj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Cbzhj.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>and you connect directly the original dataset you have the following situation<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/XOo8e.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XOo8e.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>producing the following error:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/mRSSQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mRSSQ.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Does someone have some way to understand where Azure crashes?<\/p>\n\n<p>Thanks you,<\/p>\n\n<p>Andrea<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-08-31 13:58:35.23 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":102,
        "Owner_creation_date":"2015-07-09 09:05:28.61 UTC",
        "Owner_last_access_date":"2022-09-19 17:14:25.487 UTC",
        "Owner_location":"Colleferro, Italy",
        "Owner_reputation":809,
        "Owner_up_votes":109,
        "Owner_down_votes":0,
        "Owner_views":361,
        "Answer_body":"<p>Thanks so much for publishing the example -- this really helped to understand the issue. I suspect that you want to modify the <code>gsub()<\/code> calls in your script by adding the argument \"<code>fixed=TRUE<\/code>\" to each. (The documentation for this function is <a href=\"https:\/\/stat.ethz.ch\/R-manual\/R-devel\/library\/base\/html\/grep.html\" rel=\"nofollow\">here<\/a>.)<\/p>\n\n<p>What appears to have happened is that somewhere in your full dataset -- but not in the subsampled dataset -- there is some text that winds up being included in <code>df[i, \"names\"]<\/code> as \"<code>(art.<\/code>\".  Your script pads this into \"<code>\\\\b(art.\\\\b<\/code>\". The <code>gsub()<\/code> function tries to interpret this as a regular expression instead of a simple string, then throws an error because it is not a valid regular expression: it contains an opening parenthesis but no closing parenthesis. I believe that you actually did not want <code>gsub()<\/code> to interpret the input as a regular expression in the first place, and specifying <code>gsub(..., fixed=TRUE)<\/code> will correct that.<\/p>\n\n<p>I believe the reason why this error disappears when you add the sample\/partition module is because, by chance, the problematic input value was dropped on subsampling. I do not think it is an issue of available resources on Azure ML. (Caveat: I cannot confirm the fix works yet; I made the suggested update and started running the experiment, but it has not yet completed successfully.)<\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_date":"2016-08-31 20:53:32.497 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Cannot debug code with Azure ML workspace + VS Code",
        "Question_body":"<p>I am trying to remotely debug Python code in an Azure ML workspace using VS Code 1.64.2. I have Azure ML extension installed in VS Code.<\/p>\n<p>I can connect to Azure ML workspace and most of the features work ok. I'd like to start remote debugging following a tutorial on youtube. However I cannot do it because when I right-click a python file, there is no <code>Azure ML: Run as Experiment in Azure<\/code> menu which I can see in the video.<\/p>\n<p>What am I doing wrong?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/BYfcQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BYfcQ.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-11 16:04:11.957 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|visual-studio-code|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":142,
        "Owner_creation_date":"2013-10-03 09:39:21.493 UTC",
        "Owner_last_access_date":"2022-09-23 14:17:28.327 UTC",
        "Owner_location":null,
        "Owner_reputation":2522,
        "Owner_up_votes":1691,
        "Owner_down_votes":15,
        "Owner_views":274,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-03-12 08:07:20.037 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Erro InvalidInputDatatype: Input of type 'Unknown' is not supported in azure (azureml.train.automl)",
        "Question_body":"<p>I have a pandas's DataFrame created by:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>TB_HISTORICO_MODELO = pd.read_sql(&quot;&quot;&quot;select DAT_INICIO_SEMANA_PLAN\n,COD_NEGOCIO\n,VENDA\n,LUCRO\n,MODULADO\n,RUPTURA\n,QTD_ESTOQUE_MEDIO\n,PECAS from TB&quot;&quot;&quot;, cursor)\n\nTB_HISTORICO_MODELO[&quot;DAT_INICIO_SEMANA_PLAN&quot;] = pd.to_datetime(TB_HISTORICO_MODELO[&quot;DAT_INICIO_SEMANA_PLAN&quot;])\n\ndataset = TB_HISTORICO_MODELO[TB_HISTORICO_MODELO['COD_NEGOCIO']=='A101'].drop(columns=['COD_NEGOCIO']) .reset_index(drop=True)\n<\/code><\/pre>\n<p>Everything look like right.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; dataset.dtypes\nDAT_INICIO_SEMANA_PLAN    datetime64[ns]\nVENDA                            float64\nLUCRO                            float64\nMODULADO                           int64\nRUPTURA                            int64\nQTD_ESTOQUE_MEDIO                  int64\nPECAS                            float64\ndtype: object\n<\/code><\/pre>\n<p>But when I rum this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>#%% Create the AutoML Config file and run the experiment on Azure\n\nfrom azureml.train.automl import AutoMLConfig\n\ntime_series_settings = {\n   'time_column_name': 'DAT_INICIO_SEMANA_PLAN',\n   'max_horizon': 14,\n   'country_or_region': 'BR',\n   'target_lags': 'auto'\n}\n\nautoml_config = AutoMLConfig(task='forecasting',\n                            primary_metric='normalized_root_mean_squared_error',\n                            blocked_models=['ExtremeRandomTrees'],\n                            experiment_timeout_minutes=30,\n                            training_data=dataset,\n                            label_column_name='VENDA',\n                            compute_target = compute_cluster,\n                            enable_early_stopping=True,\n                            n_cross_validations=3,\n                            # max_concurrent_iterations=4,\n                            # max_cores_per_iteration=-1,\n                            verbosity=logging.INFO,\n                            **time_series_settings)\n\nremote_run = Experimento.submit(automl_config, show_output=True)\n<\/code><\/pre>\n<p>I get the message<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; remote_run = Experimento.submit(automl_config, show_output=True)\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/core\/experiment.py&quot;, line 219, in submit\n    run = submit_func(config, self.workspace, self.name, **kwargs)\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 92, in _automl_static_submit\n    automl_config_object._validate_config_settings(workspace)\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 1775, in _validate_config_settings\n    supported_types=&quot;, &quot;.join(SupportedInputDatatypes.REMOTE_RUN_SCENARIO)\nazureml.train.automl.exceptions.ConfigException: ConfigException:\n        Message: Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset]\n        InnerException: None\n        ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset]&quot;,\n        &quot;details_uri&quot;: &quot;https:\/\/aka.ms\/AutoMLConfig&quot;,\n        &quot;target&quot;: &quot;training_data&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;BadArgument&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;ArgumentInvalid&quot;,\n                &quot;inner_error&quot;: {\n                    &quot;code&quot;: &quot;InvalidInputDatatype&quot;\n                }\n            }\n        }\n    }\n}\n\n<\/code><\/pre>\n<p>Where is wrong?<\/p>\n<p>documentation:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train<\/a>\n<a href=\"https:\/\/docs.microsoft.com\/pt-br\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/pt-br\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-16 18:36:27.197 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|pandas|azure|azure-machine-learning-service",
        "Question_view_count":382,
        "Owner_creation_date":"2018-04-02 02:01:36.793 UTC",
        "Owner_last_access_date":"2022-09-23 14:36:15.803 UTC",
        "Owner_location":"Rio de Janeiro, RJ, Brasil",
        "Owner_reputation":264,
        "Owner_up_votes":276,
        "Owner_down_votes":2,
        "Owner_views":23,
        "Answer_body":"<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#data-source-and-format?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">Configure AutoML Doc<\/a> says:<\/p>\n<blockquote>\n<p>For remote experiments, training data must be accessible from the remote compute. AutoML only accepts Azure Machine Learning TabularDatasets when working on a remote compute.<\/p>\n<\/blockquote>\n<p>It looks as if your <code>dataset<\/code> object is a Pandas DataFrame, when it should really be an Azure ML <code>Dataset<\/code>. Check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">this doc<\/a> on creating Datasets.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-10-18 07:07:46.533 UTC",
        "Answer_last_edit_date":"2020-10-18 07:14:19.15 UTC",
        "Answer_score":3.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to retrieve auth keys for an ACI deployment in Azure Portal (or Cloud Shell)?",
        "Question_body":"<p>I have created a <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#aci\" rel=\"nofollow noreferrer\">deployment on ACI with Azure ML service<\/a>, and its status is healthy.<br>\nWhen deploying, I set <code>auth_enabled=True<\/code>, so that the service requires authorization keys to respond.<\/p>\n\n<p>I can get the service auth keys for that deployment in my Azure ML service workspace <code>ws<\/code> in a Python console via<\/p>\n\n<pre><code>from azureml.core.webservice import Webservice\nservices = Webservice.list(ws)\nservices[0].get_keys()\n<\/code><\/pre>\n\n<p>However, it would be convenient to access to this information through Azure Portal or the Cloud Shell. <\/p>\n\n<p>In Azure Portal (differently to what happens for AKS) there's no auth fields shown, also when accessing Advanced Settings by trying to edit the deployment:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/3Qudh.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3Qudh.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Can you suggest ways to access those credentials?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-31 10:58:22.887 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azureportal|azure-aks|azure-container-instances|azure-cloud-shell|azure-machine-learning-service",
        "Question_view_count":169,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_location":"Verona, VR, Italy",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-05-31 17:32:04.667 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning - authorization error despite having maximum permissions",
        "Question_body":"<p>I am trying to build a machine learning model on Azure for my company. The IT team at the company I work at has given me maximum permissions for our Azure Machine Learning account since I am doing all the setup part (we started using it only last month). However, I checked the portal and realized that I am not authorized to access any of the modules within Azure ML, namely Experiment, Models, Endpoints, Datasets, etc. Is there something I am missing that is giving me this error? The error message has this <a href=\"https:\/\/go.microsoft.com\/fwlink\/?linkid=2161335\" rel=\"nofollow noreferrer\">link<\/a> but I am not sure it serves the purpose.<\/p>\n<p><strong>Note:<\/strong> I am new to Azure so please forgive me if this is a very basic doubt.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oPvpP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oPvpP.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-06-09 08:32:39.873 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":251,
        "Owner_creation_date":"2017-12-13 05:40:29.087 UTC",
        "Owner_last_access_date":"2022-09-25 04:16:20.11 UTC",
        "Owner_location":"Seattle, Washington",
        "Owner_reputation":53,
        "Owner_up_votes":108,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Online Endpoint deployment DriverFileNotFound Error",
        "Question_body":"<p>When running the Azure ML Online endpoint commands, it works locally. But when I try to deploy it to Azure I get this error.\nCommand - <code>az ml online-deployment create --name blue --endpoint &quot;unique-name&quot; -f endpoints\/online\/managed\/sample\/blue-deployment.yml --all-traffic<\/code><\/p>\n<pre><code>{\n    &quot;status&quot;: &quot;Failed&quot;,\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;DriverFileNotFound&quot;,\n        &quot;message&quot;: &quot;Driver file with name score.py not found in provided dependencies. Please check the name of your file.&quot;,\n        &quot;details&quot;: [\n            {\n                &quot;code&quot;: &quot;DriverFileNotFound&quot;,\n                &quot;message&quot;: &quot;Driver file with name score.py not found in provided dependencies. Please check the name of your file.\\nThe build log is available in the workspace blob store \\&quot;coloraiamlsa\\&quot; under the path \\&quot;\/azureml\/ImageLogs\/1673692e-e30b-4306-ab81-2eed9dfd4020\/build.log\\&quot;&quot;,\n                &quot;details&quot;: [],\n                &quot;additionalInfo&quot;: []\n            }\n        ],\n        \n<\/code><\/pre>\n<p>This is the deployment YAML taken straight from <a href=\"https:\/\/github.com\/Azure\/azureml-examples\" rel=\"nofollow noreferrer\">azureml-examples<\/a> repo<\/p>\n<pre><code>$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json\nname: blue\nendpoint_name: my-endpoint\nmodel:\n  local_path: ..\/..\/model-1\/model\/sklearn_regression_model.pkl\ncode_configuration:\n  code: \n    local_path: ..\/..\/model-1\/onlinescoring\/\n  scoring_script: score.py\nenvironment: \n  conda_file: ..\/..\/model-1\/environment\/conda.yml\n  image: mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:20210727.v1\ninstance_type: Standard_F2s_v2\ninstance_count: 1\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-13 06:25:50.693 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"endpoint|azure-machine-learning-service",
        "Question_view_count":130,
        "Owner_creation_date":"2010-05-24 09:36:42.127 UTC",
        "Owner_last_access_date":"2022-09-23 09:14:38.26 UTC",
        "Owner_location":"Hyderabad, India",
        "Owner_reputation":1561,
        "Owner_up_votes":61,
        "Owner_down_votes":1,
        "Owner_views":243,
        "Answer_body":"<p>Finally after lot of head banging, I have been able to consistently repro this bug in another Azure ML Workspace.<\/p>\n<p>I tried deploying the same sample in a brand new Azure ML workspace created and it went smoothly.<\/p>\n<p>At this point I remembered that I had upgraded the Storage Account of my previous AML Workspace to DataLake Gen2.<\/p>\n<p>So I did the same upgrade in this new workspace\u2019s storage account. After the upgrade, when I try to deploy the same endpoint, I get the same <code>DriverFileNotFoundError<\/code>!<\/p>\n<p>It seems Azure ML does not support Storage Account with DataLake Gen2 capabilities although the support page says otherwise. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#supported-data-storage-service-types\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#supported-data-storage-service-types<\/a>.<\/p>\n<p>At this point my only option is to recreate a new workspace and deploy my code there. Hope Azure team fixes this soon.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-17 04:15:13.59 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML: TabularDataset.to_pandas_dataframe() hangs when parquet file is empty",
        "Question_body":"<p>I have created a Tabular Dataset using Azure ML python API. Data under question is a bunch of parquet files (~10K parquet files each of size of 330 KB) residing in Azure Data Lake Gen 2 spread across multiple partitions. When I try to load the dataset using the API <code>TabularDataset.to_pandas_dataframe()<\/code>, it continues forever (hangs), if there are empty parquet files included in the Dataset. If the tabular dataset doesn't include those empty parquet files, <code>TabularDataset.to_pandas_dataframe()<\/code> completes within few minutes.<\/p>\n<p>By empty parquet file, I mean that the if I read the individual parquet file using pandas (pd.read_parquet()), it results in an empty DF (df.empty == True).<\/p>\n<p>I discovered the root cause while working on another issue mentioned <code>[here][1]<\/code>.<\/p>\n<p><strong>My question is how can make <code>TabularDataset.to_pandas_dataframe()<\/code> work even when there are empty parquet files?<\/strong><\/p>\n<p><strong>Update<\/strong>\nThe issue has been fixed in the following version:<\/p>\n<ul>\n<li>azureml-dataprep : 3.0.1<\/li>\n<li>azureml-core :  1.40.0<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-11 04:14:23.947 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":300,
        "Owner_creation_date":"2010-07-30 15:52:19.753 UTC",
        "Owner_last_access_date":"2022-09-23 12:22:17.867 UTC",
        "Owner_location":"Bangalore, India",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Answer_body":"<p>Thanks for reporting it.\nThis is a bug in handling of the parquet files with columns but empty row set. This has been fixed already and will be included in next release.<\/p>\n<p>I could not repro the hang on multiple files, though, so if you could provide more info on that would be nice.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2022-03-04 22:25:24.77 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2022-03-30 12:30:47.773 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to deploy a ML model as a local iot edge module",
        "Question_body":"<p>I have a machine learning model registered in the model registry of my Azure Machine Learning workspace.<\/p>\n<p>Now I want to containerize such model inside a <strong>Linux docker image<\/strong> exposing a rest api; then, I have to deploy it as an IoT Edge module to an edge PC, where other modules will invoke it locally and receive predictions.<\/p>\n<p>I have searched in Microsoft documentation, but I haven't found a solution to my problem, since the suggested examples and tutorials talk about deploying entire iot edge solutions or using azure ml cli to deploy models, instead I have to add this module to an existing deployment manifest where other modules are already present.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-04-12 16:37:35.04 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-iot-edge|azure-machine-learning-service",
        "Question_view_count":151,
        "Owner_creation_date":"2014-04-28 18:41:03.007 UTC",
        "Owner_last_access_date":"2022-09-21 20:57:33.44 UTC",
        "Owner_location":"Milano, MI, Italia",
        "Owner_reputation":53,
        "Owner_up_votes":128,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"azure machine learning studio \"execute R script\" is unable to load ggplot2 library from scriptbundle.zip",
        "Question_body":"<p>Rscript:<\/p>\n\n<p>install.packages(\"src\/Rpackages\/Rcpp.zip\", lib = \".\", repos = NULL, verbose = TRUE)<br>\nlibrary(Rcpp, lib.loc=\".\", verbose=TRUE) \ninstall.packages(\"src\/Rpackages\/ggplot2_2.2.1.zip\", lib = \".\", repos = NULL, verbose = TRUE)<br>\nlibrary(ggplot2, lib.loc=\".\", verbose=TRUE) <\/p>\n\n<p>Error :<\/p>\n\n<p>requestId = 2719717d8d5b4a479547886c19b0bcb4 errorComponent=Module. taskStatusCode=400. {\"Exception\":{\"ErrorId\":\"FailedToEvaluateRScript\",\"ErrorCode\":\"0063\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 0063: The following error occurred during evaluation of R script:\\r\\n---------- Start of error message from R ----------\\r\\npackage or namespace load failed for 'ggplot2'\\r\\n\\r\\n\\r\\npackage or namespace load failed for 'ggplot2'\\r\\n----------- End of error message from R -----------\"}}Error: Error 0063: The following error occurred during evaluation of R script:---------- Start of error message from R ----------package or namespace load failed for 'ggplot2'package or namespace load failed for 'ggplot2'----------- End of error message from R ----------- Process exited with error code -2<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/JDbHN.png\" rel=\"nofollow noreferrer\">azuremlstudio snapshot<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2017-03-22 23:34:01.677 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":272,
        "Owner_creation_date":"2015-11-06 21:52:07.553 UTC",
        "Owner_last_access_date":"2017-10-05 19:18:14.97 UTC",
        "Owner_location":"Seattle, WA, United States",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to access files stored in AzureDataLake and use this file as input to AzureBatchStep in azure.pipleline.step?",
        "Question_body":"<p>I registered an Azure data lake datastore as in the <a href=\"https:\/\/docs.microsoft.com\/zh-cn\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py#register-azure-data-lake-workspace--datastore-name--store-name--tenant-id--client-id--client-secret--resource-url-none--authority-url-none--subscription-id-none--resource-group-none--overwrite-false-\" rel=\"nofollow noreferrer\">documentation<\/a> in order to access the files stored in it. <\/p>\n\n<p>I used <\/p>\n\n<pre><code>DataReference(datastore, data_reference_name=None, path_on_datastore=None, mode='mount', path_on_compute=None, overwrite=False) \n<\/code><\/pre>\n\n<p>and used it as input to azure pipeline step in <a href=\"https:\/\/docs.microsoft.com\/zh-cn\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.azurebatch_step.azurebatchstep?view=azure-ml-py\" rel=\"nofollow noreferrer\"><code>AzureBatchStep<\/code><\/a> method. <\/p>\n\n<p>But I got an issue: that datastore name could not be fetched in input.<br>\nIs Azure Data Lake not accessible in Azure ML or am I getting it wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-04-23 08:48:32.173 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":106,
        "Owner_creation_date":"2019-04-22 10:04:08.197 UTC",
        "Owner_last_access_date":"2022-09-23 06:42:26.117 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":23,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-04-24 05:47:09.317 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Microsoft packages revoscalepy and microsoftml source code",
        "Question_body":"<p>Does anybody know how to find the source code for Microsoft packages for R\/Python called <code>revoscalepy<\/code> and <code>microsoftml<\/code> (also <code>azure-machine-learning-sdk<\/code> would be great). These packages contain implementation of different machine learning algos and could be installed by SQL Server installer. Model serialized by <code>revoscalepy<\/code> could be used directly in SQL script.<\/p>\n<p>Packages seem to be proprietary, but the documentation is confusing because parameters in different methods are not used, algorithms versions are not known definetely. Moreover, results differ too much with well-known <code>scikit-learn<\/code> library.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-02 08:13:24.983 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|sql-server|machine-learning|azure-machine-learning-studio",
        "Question_view_count":23,
        "Owner_creation_date":"2017-08-27 14:11:32.62 UTC",
        "Owner_last_access_date":"2022-09-22 10:47:17.127 UTC",
        "Owner_location":"Kaz\u00e1n, \u0420\u043e\u0441\u0441\u0438\u044f",
        "Owner_reputation":1683,
        "Owner_up_votes":155,
        "Owner_down_votes":9,
        "Owner_views":116,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Trying to work on R using Azure ML Studio Notebook and facing challenges with ODBC package",
        "Question_body":"<p>I am trying to work on R notebook on ML Studio. Using regular python is easy and works as expected but with R i am facing challenges.<\/p>\n<p>While trying to connect to MS SQL database using odbc() :<\/p>\n<pre><code>library(odbc)\ncon &lt;- dbConnect(odbc(),\n                 Driver = &quot;SQL Server&quot;,\n                 Server = &quot;server&quot;,\n                 Database = &quot;db&quot;,\n                 UID = &quot;user&quot;,\n                 PWD = &quot;password&quot;,\n                 Port = 1433)\n\n\n\nError: nanodbc\/nanodbc.cpp:1021: 00000: [unixODBC][Driver Manager]Can't open lib 'SQL Server' : file not found\n<\/code><\/pre>\n<p>As suggested in some posts, i have also tried replacing  Driver = &quot;SQL Server&quot;, with Driver = &quot;ODBC Driver 11 for SQL Server&quot;. But i see similar error<\/p>\n<pre><code>Error: nanodbc\/nanodbc.cpp:1021: 00000: [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 11 for SQL Server' : file not found \nTraceback:\n<\/code><\/pre>\n<p>Please suggest a work around.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-08-04 10:54:35.93 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-service",
        "Question_view_count":52,
        "Owner_creation_date":"2017-06-02 12:27:30.497 UTC",
        "Owner_last_access_date":"2022-09-20 06:48:21.12 UTC",
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Dependency missing when running AzureML Estimator in docker environment",
        "Question_body":"<h3>Scenario description<\/h3>\n\n<p>I'm trying to submit a training script to AzureML (want to use AmlCompute, but I'm starting\/testing locally first, for debugging purposes).<\/p>\n\n<p>The <code>train.py<\/code> script I have uses a custom package (<code>arcus.ml<\/code>) and I believe I have specified the right settings and dependencies, but still I get the error: <\/p>\n\n<p><code>User program failed with ModuleNotFoundError: No module named 'arcus.ml'<\/code><\/p>\n\n<h3>Code and reproduction<\/h3>\n\n<p>This the python code I have:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>name='test'\nscript_params = {\n    '--test-par': 0.2\n}\n\nest = Estimator(source_directory='.\/' + name,\n                   script_params=script_params,\n                   compute_target='local',\n                   entry_script='train.py',\n                   pip_requirements_file='requirements.txt',\n                   conda_packages=['scikit-learn','tensorflow', 'keras'])\n\nrun = exp.submit(est)\nprint(run.get_portal_url())\n<\/code><\/pre>\n\n<p>This is the (fully simplified) train.py script in the <code>test<\/code>directory:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from arcus.ml import dataframes as adf\nfrom azureml.core import Workspace, Dataset, Datastore, Experiment, Run\n\n# get hold of the current run\nrun = Run.get_context()\nws = run.get_environment()\n\nprint('training finished')\n<\/code><\/pre>\n\n<p>And this is my requirements.txt file<\/p>\n\n<pre><code>arcus-azureml\narcus-ml\nnumpy\npandas\nazureml-core\ntqdm\njoblib\nscikit-learn\nmatplotlib\ntensorflow\nkeras\n<\/code><\/pre>\n\n<h3>Logs<\/h3>\n\n<p>In the logs file of the run, I can see this section, sot it seems the external module is being installed anyhow.<\/p>\n\n<pre><code>Collecting arcus-azureml\n  Downloading arcus_azureml-1.0.3-py3-none-any.whl (3.1 kB)\nCollecting arcus-ml\n  Downloading arcus_ml-1.0.6-py3-none-any.whl (2.1 kB)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-01 20:24:14.577 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":208,
        "Owner_creation_date":"2013-02-12 07:50:30.743 UTC",
        "Owner_last_access_date":"2022-09-21 18:28:12.907 UTC",
        "Owner_location":"Belgium",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Answer_body":"<p>I think this error isn't necessarily about Azure ML. I think the error has to do w\/ the difference b\/w using a hyphen and a period in your package name. But I'm a python packaging newb. \nIn a new conda environment on my laptop, I ran the following<\/p>\n\n<pre><code>&gt; conda create -n arcus python=3.6 -y\n&gt; conda activate arcus\n&gt; pip install arcus-ml\n&gt; python\n&gt;&gt;&gt; from arcus.ml import dataframes as adf\nModuleNotFoundError: No module named 'arcus'\n<\/code><\/pre>\n\n<p>When I look in the env's site packages folder, I didn't see the <code>arcus\/ml<\/code> folder structure I was expecting. There's no arcus code there at all, only the <code>.dist-info<\/code> file<\/p>\n\n<h3><code>~\/opt\/anaconda3\/envs\/arcus\/lib\/python3.6\/site-packages<\/code><\/h3>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/caExn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/caExn.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-06-01 20:37:38.447 UTC",
        "Answer_last_edit_date":"2020-06-01 20:47:51.11 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure CLI ML Throws TypeError: __init__() takes 2 positional arguments but 3 were given",
        "Question_body":"<p>I'm attempting to follow this <a href=\"https:\/\/github.com\/microsoft\/recommenders\/blob\/master\/notebooks\/05_operationalize\/als_movie_o16n.ipynb\" rel=\"nofollow noreferrer\">tutorial<\/a> and am getting the following error. I'm working in jupyter notebook with python 3. I am trying to build a recommendation engine using Azure tools and the Microsoft doc I attached.<\/p>\n\n<p>TypeError: <strong>init<\/strong>() takes 2 positional arguments but 3 were given<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/gnzza.png\" rel=\"nofollow noreferrer\">I have attached an image of code from jupyter notebook to demonstrate proper formatting<\/a><\/p>\n\n<p>I've tried solutions to roll back my Azure Python SDK using Pip. I run pip install --upgrade azureml-sdk and all looks good. Thanks very much for any and all help!<\/p>\n\n<p>The code appears below: <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    print(workspace_name)\n    ws = Workspace.create(\n        name=workspace_name,\n        subscription_id=subscription_id,\n        resource_group=resource_group, \n        location=location,\n        exist_ok=True\n    )\n\nThe full error appears below:\n'''\n   TypeError                                 Traceback (most recent call last)\n    &lt;ipython-input-11-25e04e55f419&gt; in &lt;module&gt;\n      5     resource_group=resource_group,\n      6     location=location,\n----&gt; 7     exist_ok=True\n      8 )\n\n~\\.conda\\envs\\reco_pyspark\\lib\\site-packages\\azureml\\core\\workspace.py in create(name, auth, subscription_id, resource_group, location, create_resource_group, sku, friendly_name, storage_account, key_vault, app_insights, container_registry, cmk_keyvault, resource_cmk_uri, hbi_workspace, default_cpu_compute_target, default_gpu_compute_target, private_endpoint_config, private_endpoint_auto_approval, exist_ok, show_output)\n    437 \n    438         if location:\n--&gt; 439             available_locations = _available_workspace_locations(subscription_id, auth)\n    440             available_locations = [x.lower().replace(' ', '') for x in available_locations]\n    441             location = location.lower().replace(' ', '')\n\n~\\.conda\\envs\\reco_pyspark\\lib\\site-packages\\azureml\\core\\workspace.py in _available_workspace_locations(subscription_id, auth)\n   1556     if not auth:\n   1557         auth = InteractiveLoginAuthentication()\n-&gt; 1558     return _commands.available_workspace_locations(auth, subscription_id)\n\n~\\.conda\\envs\\reco_pyspark\\lib\\site-packages\\azureml\\_project\\_commands.py in available_workspace_locations(auth, subscription_id)\n    334     :rtype: list[str]\n    335     \"\"\"\n--&gt; 336     response = auth._get_service_client(ResourceManagementClient, subscription_id).providers.get(\n    337         \"Microsoft.MachineLearningServices\")\n    338     for resource_type in response.resource_types:\n\n~\\.conda\\envs\\reco_pyspark\\lib\\site-packages\\azureml\\core\\authentication.py in _get_service_client(self, client_class, subscription_id, subscription_bound, base_url)\n    150         return _get_service_client_using_arm_token(self, client_class, subscription_id,\n    151                                                    subscription_bound=subscription_bound,\n--&gt; 152                                                    base_url=base_url)\n    153 \n    154     def signed_session(self, session=None):\n\n~\\.conda\\envs\\reco_pyspark\\lib\\site-packages\\azureml\\core\\authentication.py in _get_service_client_using_arm_token(auth, client_class, subscription_id, subscription_bound, base_url)\n   1620     else:\n   1621         # converting subscription_id, which is string, to string because of weird python 2.7 errors.\n-&gt; 1622         client = client_class(adal_auth_object, str(subscription_id), base_url=base_url)\n   1623     return client\n   1624 \n\nTypeError: __init__() takes 2 positional arguments but 3 were given\n'''\n\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2020-06-06 07:22:42.517 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-cognitive-services|azure-machine-learning-service",
        "Question_view_count":328,
        "Owner_creation_date":"2020-06-06 07:09:32.487 UTC",
        "Owner_last_access_date":"2020-07-27 02:51:58.363 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-06-06 22:02:00.067 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML - Error starting compute instance",
        "Question_body":"<p>A couple of days ago, when I tried to start the Azure ML compute instance linked to my user, I started receiving the following error message:<\/p>\n<pre><code>Services not ready for connections\nTimed out waiting for Jupyter to become ready\n<\/code><\/pre>\n<p>My role in this resource is <strong>AzureML Data Scientist<\/strong>, meaning I can perform all actions within an Azure Machine Learning workspace, <strong>except<\/strong> for creating or deleting compute resources and modifying the workspace itself. In other words, I can't delete the current instance and replace it with a new one.<\/p>\n<p>In the past few days, I have tried to restart, force restart, and follow any tutorial remotely related to this issue I could find online, but I wasn\u2019t able to find a solution for this problem.<\/p>\n<p><strong>My question:<\/strong> Does anyone know how I can fix the compute instance booting process, or why I'm encountering this issue (preferably without having to open a ticket and wait weeks for the IT department to help me)?<\/p>\n<h2>Additional Context<\/h2>\n<p>The day before the error started happening, I tried to install a custom package I am developing to the compute instance. The package has an extensive requirements list. I do not know if this could be somehow related, but is there a chance that the package installation is messing with the compute instance nodes?<\/p>\n<p>Additionally, the SSH access to the instance is disabled, therefore I cannot use SSH to directly access its nodes files.<\/p>\n<h3>Workspace diagnostics<\/h3>\n<p>Running the workspace diagnostics also returned the following error message:<\/p>\n<pre><code>ImageBuildComputeNotValid: If Container Registry is behind the virtual network,\nContainer Registry cannot build your image. Set the imageBuildCompute property\nto build your image.\nSee https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-secure-workspace-vnet#enable-azure-container-registry-acr\n<\/code><\/pre>\n<p>It also pointed out that the following categories have no problems:<\/p>\n<p>User defined routing<\/p>\n<ul>\n<li>Network security group<\/li>\n<li>Resource lock<\/li>\n<li>DNS resolution<\/li>\n<li>Storage account<\/li>\n<li>Key vault<\/li>\n<li>Application Insights<\/li>\n<li>Other<\/li>\n<\/ul>\n<p>The following image shows the error I am getting when trying to start the compute instance:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/H2HoP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/H2HoP.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Any help would be appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-09-15 01:07:12.65 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":44,
        "Owner_creation_date":"2021-12-04 10:04:27.883 UTC",
        "Owner_last_access_date":"2022-09-23 21:48:13.173 UTC",
        "Owner_location":"Rio de Janeiro",
        "Owner_reputation":436,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning compute cluster - avoid using docker?",
        "Question_body":"<p>I would like to use an Azure Machine Learning Compute Cluster as a compute target but do not want it to containerize my project. Is there a way to deactivate this &quot;feature&quot; ?<\/p>\n<p>The main reasons behind this request is that :<\/p>\n<ol>\n<li>I already set up a docker-compose file that is used to specify 3 containers for Apache Airflow and want to avoid a Docker-in-Docker situation. Especially that I already tried to do so but failed so far (here's the <a href=\"https:\/\/stackoverflow.com\/questions\/72380590\/airflow-docker-compose-from-another-docker-container-on-azure-machine-learning-c?noredirect=1#comment127881455_72380590\">link<\/a> my other related SO question).<\/li>\n<li>I prefer not to use a Compute Instance as it is tied to an Azure account which is not ideal for automation purposes.<\/li>\n<\/ol>\n<p>Thanks in advance !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-30 11:30:19.71 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|docker|docker-compose|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":116,
        "Owner_creation_date":"2020-04-10 11:23:52.39 UTC",
        "Owner_last_access_date":"2022-08-12 18:19:53.33 UTC",
        "Owner_location":null,
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-05-31 10:04:12.6 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Load testing of endpoint in Azure ML",
        "Question_body":"<p>I wanted to load test a deployed model endpoint and add it to an MLOps framework, so that new deployed models can go through load testing. I tried Azure load testing resource for web app but I think it is just for static content. Also, I saw a python package - locust which seems promising. Is there any other approach?\u00a0<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-19 06:44:33.553 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"deployment|endpoint|azure-machine-learning-service|azure-deployment",
        "Question_view_count":35,
        "Owner_creation_date":"2019-07-05 09:43:42.373 UTC",
        "Owner_last_access_date":"2022-09-23 15:01:08.727 UTC",
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-08-24 05:22:11.123 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"azure cli not recognizing the following command az ml data create -f <file-name>.yml",
        "Question_body":"<p>got a folder called data-asset which contains a yaml file with the following<\/p>\n<pre><code>type: uri_folder\nname: &lt;name_of_data&gt;\ndescription: &lt;description goes here&gt;\npath: &lt;path&gt;\n<\/code><\/pre>\n<p>In a pipeline am referencing this using azure cli inline script using the following command az ml data create -f .yml but getting error<\/p>\n<p>full error-D:\\a\\1\\s\\ETL\\data-asset&gt;az ml data create -f data-asset.yml\nERROR: 'ml' is misspelled or not recognized by the system.<\/p>\n<p>Examples from AI knowledge base:\naz extension add --name anextension\nAdd extension by name<\/p>\n<p>trying to implement this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-data-assets?tabs=CLI\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-data-assets?tabs=CLI<\/a><\/p>\n<p>how can a resolve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-01 10:02:24.177 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|yaml|azure-cli|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":112,
        "Owner_creation_date":"2020-11-30 17:06:44.663 UTC",
        "Owner_last_access_date":"2022-08-31 08:48:49.383 UTC",
        "Owner_location":null,
        "Owner_reputation":49,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":"<p>One of the workaround you can follow to resolve the above issue;<\/p>\n<p>Based on this <a href=\"https:\/\/github.com\/Azure\/azure-cli\/issues\/21390#issuecomment-1161782243\" rel=\"nofollow noreferrer\"><em><strong>GitHub issue<\/strong><\/em><\/a> as suggested by @<em>adba-msft<\/em> .<\/p>\n<blockquote>\n<p><strong>Please make sure that you have upgraded your azure cli to latest and<\/strong>\n<strong>Azure CLI ML extension v2 is being used.<\/strong><\/p>\n<\/blockquote>\n<p>To check and upgrade the cli we can use the below <code>cmdlts<\/code>:<\/p>\n<pre><code>az version\n\naz upgrade\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Uopde.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Uopde.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>For more information please refer this similar <a href=\"https:\/\/stackoverflow.com\/questions\/73110661\/create-is-misspelled-or-not-recognized-by-the-system-on-az-ml-dataset-create\"><em><strong>SO THREAD|'create' is misspelled or not recognized by the system on az ml dataset create<\/strong><\/em><\/a> .<\/p>\n<p>I did observe the same issue after trying the aforementioned suggestion by @<em>Dor Lugasi-Gal<\/em> it works for me with (in my case <code>az ml -h<\/code>) after installed the extension with  <code>az extension add -n ml -y<\/code> can able to get the result of <code>az ml -h<\/code> without any error.<\/p>\n<p><em><strong>SCREENSHOT FOR REFERENCE:-<\/strong><\/em><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/39LHa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/39LHa.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-08-01 13:39:44.08 UTC",
        "Answer_last_edit_date":"2022-08-01 14:09:07.923 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Serialise objects in azure ML pipeline runs",
        "Question_body":"<p>I have Python package for pre-processing the data for train and scoring\/inference purpose. I am using it as a python step in a pipeline. The entry script (which is in package) takes argument i.e task argument choices=(train,score) and does the pre-processing. Here is the step code:<\/p>\n<pre><code># Pipeline parameter: task, config_path\nparam_task = PipelineParameter(name='task', default_value='train')\nparam_config_path = PipelineParameter(name=&quot;config_path&quot;, default_value='Preprocess\/preprocess_config.json')\n\n\n# Define pipeline steps\nStepPreprocessing = PythonScriptStep(\n    name=&quot;Preprocessing&quot;,\n    script_name=e.preprocess_script_path,\n    arguments=[\n        &quot;--config_path&quot;, param_config_path, \n        &quot;--task&quot;, param_task,\n    ], \n    inputs=None,\n    compute_target=aml_compute,\n    runconfig=run_config,\n    source_directory=e.sources_directory,\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p><strong>With argument task=='train'<\/strong> it loads data and does pre-processing according to steps mentioned in a config file. During this process it creates StandardScaler, SimpleImpute objects (sklearn objects) and stores the sklearn objects in a data\/output folder inside the package, and the processed data on azure storage.<\/p>\n<p>The problem is, when the pipeline is run again with <strong>task =='score'<\/strong> it is unable to find the sklearn objects with error.<\/p>\n<pre><code>User program failed with FileNotFoundError: [Errno 2] No such file or directory: 'data\/output\/StandardScaler.joblib'\n<\/code><\/pre>\n<p>What is the best way to save the sklearn objects so that these can be accessed by pipeline when pipeline in run again but with argument task=='score'.<\/p>\n<p>I don't want to register these objects in model registry and don't want to save them in datastores as well.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-10 16:34:32.937 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"python|azure|azure-pipelines|azure-machine-learning-service",
        "Question_view_count":50,
        "Owner_creation_date":"2015-09-23 14:11:04.707 UTC",
        "Owner_last_access_date":"2022-09-23 08:54:35.743 UTC",
        "Owner_location":"Sweden",
        "Owner_reputation":644,
        "Owner_up_votes":33,
        "Owner_down_votes":1,
        "Owner_views":126,
        "Answer_body":"<p>The way to do that is either:<\/p>\n<ol>\n<li><p>Register the artifacts in model registry and get them in scoring.<\/p>\n<\/li>\n<li><p>Configure output of pipeline step as PipelineData or OutputFileDatasetConfig, write artifacts to configured output. While scoring, get run of the train pipeline, get its outputs, retrieve the artifacts. This involves experiment name to get run of the pipeline.<\/p>\n<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-02-22 09:32:16.52 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"What is real-time inference pipeline?",
        "Question_body":"<p>From Azure Machine Learning designer, to deploy a real-time inference pipeline as a service for others to consume, you must deploy the model to an Azure Kubernetes Service (AKS).\nWhat is real-time inference pipeline ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-25 15:56:05.967 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":211,
        "Owner_creation_date":"2021-01-15 12:54:54.93 UTC",
        "Owner_last_access_date":"2022-04-03 14:59:06.363 UTC",
        "Owner_location":"United States",
        "Owner_reputation":306,
        "Owner_up_votes":200,
        "Owner_down_votes":2,
        "Owner_views":53,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"What does \"Number of points\" mean when you select the Parameter Range option",
        "Question_body":"<p>What does \"Number of points\" mean on the various models when you select the Parameter Range option for Create Trainer Mode.  Can anyone shed light on what this parameter means.<\/p>\n\n<p>The Azure ML Studio documentation does not mention this parameter, either in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/two-class-logistic-regression\" rel=\"nofollow noreferrer\">the documentation for the model<\/a> or in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/tune-model-hyperparameters\" rel=\"nofollow noreferrer\">documentation to tune hyperparameters<\/a>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/6De7r.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6De7r.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2018-12-04 03:07:05.22 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"machine-learning|logistic-regression|azure-machine-learning-studio",
        "Question_view_count":72,
        "Owner_creation_date":"2018-09-30 02:23:26.613 UTC",
        "Owner_last_access_date":"2021-08-13 13:02:53.707 UTC",
        "Owner_location":null,
        "Owner_reputation":798,
        "Owner_up_votes":21,
        "Owner_down_votes":2,
        "Owner_views":64,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-12-06 07:16:03.543 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Studio: cannot create Datastore from Azure SQL Database",
        "Question_body":"<p>I am trying to connect to an Azure SQL Database from inside Azure Machine Learning Studio. Based on <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py<\/a>, it seems that the recommended pattern is to create a Datastore using the Datastore.register_azure_sql_database method as follows:<\/p>\n<pre><code>import os\nfrom azureml.core import Workspace, Datastore\n\nws = Workspace.from_config() # asks for interactive authentication the first time\n\nsql_datastore_name  = &quot;datastore_test_01&quot; # any name should be fine\nserver_name         = os.getenv(&quot;SQL_SERVERNAME&quot;    , &quot;{SQL_SERVERNAME}&quot;) # Name of the Azure SQL server\ndatabase_name       = os.getenv(&quot;SQL_DATABASENAME&quot;  , &quot;{SQL_DATABASENAME}&quot;) # Name of the Azure SQL database\nusername            = os.getenv(&quot;SQL_USER_NAME&quot;     , &quot;{SQL_USER_NAME}&quot;) # The username of the database user.\npassword            = os.getenv(&quot;SQL_USER_PASSWORD&quot; , &quot;{SQL_USER_PASSWORD}&quot;) # The password of the database user.\n\nsql_datastore = Datastore.register_azure_sql_database(workspace      = ws,\n                                                      datastore_name = sql_datastore_name,\n                                                      server_name    = server_name,\n                                                      database_name  = database_name,\n                                                      username       = username,\n                                                      password       = password)\n<\/code><\/pre>\n<p>I am pretty sure I have set all parameters right, having copied them from the ADO.NET connection string at my SQL Database resource --&gt; Settings --&gt; Connection strings:<\/p>\n<pre><code>Server=tcp:{SQL_SERVERNAME}.database.windows.net,1433;Initial Catalog={SQL_DATABASENAME};Persist Security Info=False;User ID={SQL_USER_NAME};Password={SQL_USER_PASSWORD};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;\n<\/code><\/pre>\n<p>However, I get the following error:<\/p>\n<pre><code>Registering datastore failed with a 400 error code and error message 'Azure SQL Database Error -2146232060: Please check the correctness of the datastore information.'\n<\/code><\/pre>\n<p>Am I missing something? E.g., a firewall rule? I have also tried adding the Azure ML compute resource's public IP address to the list of allowed IP addresses in my SQL Database resource, but still no success.<\/p>\n<hr \/>\n<p><strong>UPDATE<\/strong>: adding <code>skip_validation = True<\/code> to <code>Datastore.register_azure_sql_database<\/code> solves the issue. I can then query the data with<\/p>\n<pre><code>from azureml.core import Dataset\nfrom azureml.data.datapath import DataPath\n\nquery   = DataPath(sql_datastore, 'SELECT * FROM my_table')\ntabular = Dataset.Tabular.from_sql_query(query, query_timeout = 10)\ndf = tabular.to_pandas_dataframe()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-01 16:13:13.243 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-sql-database|azure-machine-learning-studio|azure-machine-learning-service|azure-sdk-python",
        "Question_view_count":793,
        "Owner_creation_date":"2017-08-11 12:35:17.96 UTC",
        "Owner_last_access_date":"2021-01-27 09:52:25.2 UTC",
        "Owner_location":"Milano, MI, Italia",
        "Owner_reputation":132,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":"<p>is the datastore behind vnet? where are you running the registration code above? On a compute instance behind the same vnet?\nhere is the doc that describe what you need to do to connect to data behind vnet:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#use-datastores-and-datasets\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#use-datastores-and-datasets<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-09-01 16:53:06.26 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2020-09-02 07:46:58.923 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"how to write to Azure PipelineData properly?",
        "Question_body":"<p>Im trying to learn Azure, with little luck (yet). All the tutorials show using PipelineData just as a file, when configured in &quot;upload&quot; mode. However, im getting &quot;FileNotFoundError: [Errno 2] No such file or directory: ''&quot; error. I would love to ask a more specific question, but i just can't see what im doing wrong.<\/p>\n<pre><code>from azureml.core import Workspace, Datastore,Dataset,Environment\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.pipeline.steps import PythonScriptStep\nfrom azureml.pipeline.core import Pipeline, PipelineData\nimport os\n\nws = Workspace.from_config()\ndatastore = ws.get_default_datastore()\n\ncompute_name = &quot;cpucluster&quot;\ncompute_target = ComputeTarget(workspace=ws, name=compute_name)\naml_run_config = RunConfiguration()\naml_run_config.target = compute_target\naml_run_config.environment.python.user_managed_dependencies = False\naml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n    conda_packages=['pandas','scikit-learn'], \n    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n    pin_sdk_version=False)\n\noutput1 = PipelineData(&quot;processed_data1&quot;,datastore=datastore, output_mode=&quot;upload&quot;)\nprep_step = PythonScriptStep(\n    name=&quot;dataprep&quot;,\n    script_name=&quot;dataprep.py&quot;,\n    source_directory=os.path.join(os.getcwd(),'dataprep'),\n    arguments=[&quot;--output&quot;, output1],\n    outputs = [output1],\n    compute_target=compute_target,\n    runconfig=aml_run_config,\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>In the dataprep.py i hve the following:<\/p>\n<pre><code>import numpy, argparse, pandas\nfrom azureml.core import Run\nrun = Run.get_context()\nparser = argparse.ArgumentParser()\nparser.add_argument('--output', dest='output', required=True)\nargs = parser.parse_args()\ndf = pandas.DataFrame(numpy.random.rand(100,3))\ndf.iloc[:, 2] = df.iloc[:,0] + df.iloc[:,1]\nprint(df.iloc[:5,:])\ndf.to_csv(args.output)\n\n<\/code><\/pre>\n<p>So, yeah. pd is supposed to write to the output, but my compute cluster says the following:<\/p>\n<pre><code>&quot;User program failed with FileNotFoundError: [Errno 2] No such file or directory: ''\\&quot;.\n<\/code><\/pre>\n<p>When i dont include the to_csv() function, the cluster does not complain<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-07-17 17:11:28.29 UTC",
        "Question_favorite_count":null,
        "Question_score":4,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":404,
        "Owner_creation_date":"2020-05-02 13:08:31.653 UTC",
        "Owner_last_access_date":"2022-09-25 01:27:33.107 UTC",
        "Owner_location":null,
        "Owner_reputation":59,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>Here is an <a href=\"https:\/\/github.com\/james-tn\/highperformance_python_in_azure\/blob\/master\/parallel_python_processing\/pipeline_definition.ipynb\" rel=\"nofollow noreferrer\">example<\/a> for PRS.\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipelinedata?view=azure-ml-py\" rel=\"nofollow noreferrer\">PipelineData<\/a> was intended to represent &quot;transient&quot; data from one step to the next one, while OutputDatasetConfig was intended for capturing the final state of a dataset (and hence why you see features like lineage, ADLS support, etc). PipelineData always outputs data in a folder structure like {run_id}{output_name}. OutputDatasetConfig allows to decouple the data from the run and hence it allows you to control where to land the data (although by default it will produce similar folder structure). The OutputDatasetConfig allows even to register the output as a Dataset, where getting rid of such folder structure makes sense. From the docs itself: &quot;Represent how to copy the output of a run and be promoted as a FileDataset. The OutputFileDatasetConfig allows you to specify how you want a particular local path on the compute target to be uploaded to the specified destination&quot;.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-batch-scoring-classification#create-dataset-objects\" rel=\"nofollow noreferrer\">OutFileDatasetConfig<\/a> is a control plane concept to pass data between pipeline steps.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-07-19 04:05:19.373 UTC",
        "Answer_last_edit_date":"2021-07-19 04:14:27.887 UTC",
        "Answer_score":2.0,
        "Question_last_edit_date":"2021-07-17 22:09:08.577 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"filter TabularDataset in azure ML",
        "Question_body":"<p>My Dataset is huge. I am using Azure ML notebooks and using azureml.core to read dateset and convert to azureml.data.tabular_dataset.TabularDataset. Is there anyway i would filter the data in the tabularDataset with out converting to pandas data frame.\nI am using below code to read the data. as the data is huge pandas data-frame is running out of memory. I don't have to load complete data into the program. Only subset is required. is there any way i could filter the records before converting to pandas data frame<\/p>\n<pre><code>def read_Dataset(dataset):\n    ws = Workspace.from_config()\n    ds = ws.datasets\n    tab_dataset = ds.get(dataset)\n    dataframe = tab_dataset.to_pandas_dataframe()\n    return dataframe\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-06 14:11:22.227 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"pandas|azure-machine-learning-studio|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":1003,
        "Owner_creation_date":"2020-05-13 19:38:36.837 UTC",
        "Owner_last_access_date":"2022-09-21 10:55:50.367 UTC",
        "Owner_location":null,
        "Owner_reputation":273,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Service dump logs",
        "Question_body":"<p>With the AzureML service, how can I dump the correct Loss curve or Accuracy curve for different epochs for keras deep learning on multiple nodes with Horovod?<\/p>\n\n<p>The Loss vs epochs plt from Keras deep learning using Horovod and AzureML appears to have issues.<\/p>\n\n<p>Training CNN with Keras\/Horovod (2 GPUs) and AMLS SDK generates weird graphs\n<a href=\"https:\/\/i.stack.imgur.com\/iKusU.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/iKusU.jpg\" alt=\"enter image description here\"><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/loJTI.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/loJTI.jpg\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-09 15:16:11.4 UTC",
        "Question_favorite_count":2.0,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":168,
        "Owner_creation_date":"2019-08-09 15:00:34.96 UTC",
        "Owner_last_access_date":"2022-09-12 18:07:07.963 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-08-09 18:24:58.713 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Error while defining sampling algorithm in hyper parameter tuning using random sampling - Version V1",
        "Question_body":"<p>I am trying to perform the random sampling to accomplish the hyper parameter tuning and tuning parameter version 1 (v1). I would like to get the chance to define the algorithm as sampling algorithm explicitly.<\/p>\n<p>Currently using the below code block and is there any chance of implementing explicitly defining sampling in V1? If not, any specific procedure to solve the issue is helpful.<\/p>\n<pre><code>from azureml.train.hyperdrive import RandomParameterSampling\nfrom azureml.train.hyperdrive import normal, uniform, choice\nparam_sampling = RandomParameterSampling( {\n        &quot;learning_rate&quot;: normal(10, 3),\n        &quot;keep_probability&quot;: uniform(0.05, 0.1),\n        &quot;batch_size&quot;: choice(16, 32, 64, 128)\n    }\n)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-29 12:13:14.043 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":34,
        "Owner_creation_date":"2022-04-27 21:21:09.217 UTC",
        "Owner_last_access_date":"2022-08-17 18:50:07.473 UTC",
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Answer_body":"<p>There is an explicit procedure called a <strong>sweep job<\/strong>. This sweep job in <strong>hyperparameter value<\/strong>. We can mention the random sampling using the sweep job explicitly.<\/p>\n<p>From azure.ai.ml.sweep import Normal, Uniform, RandomParameterSampling<\/p>\n<pre><code>Command_job_for_sweep = command_job(\n    learning_rate = Normal(mu=value, sigma=value),\n    keep_probability=Uniform(min_value= your value, max_value= value),\n    batch_size = Choice(value=[.your values in list]),\n)\n\nSweep_job = command_job_sweep.sweep(\n    Computer =\u201dcluster\u201d,\n    sampling_algorithm=\u201drandom\u201d,\n    ....\n)\n<\/code><\/pre>\n<p>This will be available in <strong>version 2 (v2)<\/strong> of hyperparameter tuning in random sampling.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-29 13:07:07.59 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Add run id when registering ml.azure model via python (pipeline)",
        "Question_body":"<p>I have registed a model in this way:<\/p>\n<pre><code>from azureml.core.model import Model\nmodel = Model.register(model_path=&quot;sklearn_regression_model.pkl&quot;,\n                      model_name=&quot;sklearn_regression_model&quot;,\n                      tags={'area': &quot;diabetes&quot;, 'type': &quot;regression&quot;},\n                      description=&quot;Ridge regression model to predict diabetes&quot;,\n                      workspace=ws)\n<\/code><\/pre>\n<p>However I would like to add run id, from the experiment, so I can always back-track the model to the experiment that created the model. In azure ml there is a column indicating that it is possible to add run id to a registered model, however the model class doesn't have this parameter.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2021-11-04 11:17:06.163 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":391,
        "Owner_creation_date":"2021-11-04 10:17:16.363 UTC",
        "Owner_last_access_date":"2022-06-20 09:09:39.263 UTC",
        "Owner_location":"Denmark",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Value changed after Azure ML Studio Web Service",
        "Question_body":"<p>I am using Azure ML Studio in order to predict some values. I have noticed that one of my value was changed when I receive the result from the Web Service. Indeed, I have the following array <strong>[27,7,2018,11,2,4,1]<\/strong> which become <strong>[27,7,2018,11,2,4,0]<\/strong>. It is the first time I notice a such comportment. I did not see other value changed in my csv. It occurs all the time with my actual input. I do not know where to start to find the source of the issue.<\/p>\n\n<p>I tried to read the response that way :<\/p>\n\n<pre><code>HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\nif (response.IsSuccessStatusCode)\n{\n    string result = await response.Content.ReadAsStringAsync();\n}\n<\/code><\/pre>\n\n<p>And that way :<\/p>\n\n<pre><code>HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\n\nif (response.IsSuccessStatusCode)\n{\n    var tmp3 = await response.Content.ReadAsStreamAsync();\n    var tmp4 = ReadFully(tmp3);\n    var tmp5 = System.Text.Encoding.UTF8.GetString(tmp4);\n}\n\npublic static byte[] ReadFully(Stream input)\n    {\n        byte[] buffer = new byte[16 * 1024];\n        using (MemoryStream ms = new MemoryStream())\n        {\n            int read;\n            while ((read = input.Read(buffer, 0, buffer.Length)) &gt; 0)\n            {\n                ms.Write(buffer, 0, read);\n            }\n            return ms.ToArray();\n        }\n    }\n<\/code><\/pre>\n\n<p>This is the shape of my model on Azure ML (In the top left, top right and bottom python scripts random forest is applied) :\n<a href=\"https:\/\/i.stack.imgur.com\/XfIq9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XfIq9.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2018-07-18 07:03:10.873 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"c#|web-services|azure-machine-learning-studio",
        "Question_view_count":24,
        "Owner_creation_date":"2016-07-17 08:43:00.41 UTC",
        "Owner_last_access_date":"2022-09-23 16:04:38.85 UTC",
        "Owner_location":null,
        "Owner_reputation":334,
        "Owner_up_votes":108,
        "Owner_down_votes":1,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-07-19 06:57:56.933 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Endpoints cost on Azure Machine Learning",
        "Question_body":"<p>I have been following the learning path for <a href=\"https:\/\/docs.microsoft.com\/en-us\/learn\/certifications\/exams\/ai-900\" rel=\"nofollow noreferrer\">Microsoft Azure AI 900<\/a>. In the second module, I have deployed my model as an endpoint. It says Container instances for compute type. How much will this cost me. Azure doesn't seem to show any pricing for this. Is this endpoint always active? If yes how much does it cost?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-10-29 05:36:40.157 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"azure|azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":633,
        "Owner_creation_date":"2019-08-17 21:44:53.737 UTC",
        "Owner_last_access_date":"2022-09-23 16:11:06.117 UTC",
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":449,
        "Owner_up_votes":370,
        "Owner_down_votes":2,
        "Owner_views":77,
        "Answer_body":"<p>The price depends on the number of <strong>vCPU<\/strong> and <strong>GBs<\/strong> of memory requested for the container group. You are charged based on the <strong>vCPU request<\/strong> for your container group rounded up to the nearest whole number for the duration (measured in seconds) <strong>your instance is running<\/strong>. You are also charged for the <strong>GB request<\/strong> for your container group rounded up to the nearest tenths place for the duration (measured in seconds) your <strong>container group is running<\/strong>. There is an additional charge of $0.000012 per vCPU second for Windows software duration on Windows container groups. Check here <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/container-instances\/\" rel=\"nofollow noreferrer\">Pricing - Container Instances | Microsoft Azure<\/a> for details<\/p>\n<ul>\n<li>After Deployed the Azure Machine Learning managed online endpoint (preview).<\/li>\n<li>Have at least <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/role-based-access-control\/role-assignments-portal.md\" rel=\"nofollow noreferrer\">Billing Reader<\/a> access on the subscription where the endpoint is deployed<\/li>\n<\/ul>\n<p>To know the costs estimation<\/p>\n<ol>\n<li><p>In the <a href=\"https:\/\/portal.azure.com\/\" rel=\"nofollow noreferrer\">Azure portal<\/a>, Go to your subscription<\/p>\n<\/li>\n<li><p>Select <strong>Cost Analysis<\/strong> for your subscription.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/W2eaRIO.png\" alt=\"enter image description here\" \/><\/p>\n<p>Create a filter to scope data to your Azure Machine learning workspace resource:<\/p>\n<ol>\n<li><p>At the top navigation bar, select <strong>Add filter<\/strong>.<\/p>\n<\/li>\n<li><p>In the first filter dropdown, select <strong>Resource<\/strong> for the filter type.<\/p>\n<\/li>\n<li><p>In the second filter dropdown, select your Azure Machine Learning workspace.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/HEvprph.png\" alt=\"enter image description here\" \/><\/p>\n<p>Create a tag filter to show your managed online endpoint and\/or managed online deployment:<\/p>\n<ol>\n<li><p>Select <strong>Add filter<\/strong> &gt; <strong>Tag<\/strong> &gt; <strong>azuremlendpoint<\/strong>: &quot;&lt; your endpoint name&gt;&quot;<\/p>\n<\/li>\n<li><p>Select <strong>Add filter<\/strong> &gt; <strong>Tag<\/strong> &gt; <strong>azuremldeployment<\/strong>: &quot;&lt; your deployment name&gt;&quot;.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/1aapYGB.png\" alt=\"enter image description here\" \/><\/p>\n<p>Refer  <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-view-online-endpoints-costs.md\" rel=\"nofollow noreferrer\">here <\/a> for more detailed steps<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-29 11:05:01.917 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"azure ml experiment return different results than webservice",
        "Question_body":"<p>same input is used in two cases, but different result is returned from python module<\/p>\n\n<p>here is the python script that return the result to the webservice:<\/p>\n\n<pre><code>import pandas as pd\nimport sys\n\n\n  def get_segments(dataframe):\n     dataframe['segment']=dataframe['segment'].astype('str')\n     segments = dataframe.loc[~dataframe['segment'].duplicated()]['segment']\n     return segments\n\n\n  def azureml_main(dataframe1 = None, dataframe2 = None):\n\n   df = dataframe1\n   segments = get_segments(df)\n   segmentCount =segments.size\n\n   if (segmentCount &gt; 0) :\n      res = pd.DataFrame(columns=['segmentId','recommendation'],index=[range(segmentCount)])\n    i=0    \n    for seg in segments:\n        d= df.query('segment ==[\"{}\"]'.format(seg)).sort(['count'],ascending=[0])\n\n        res['segmentId'][i]=seg\n        recommendation='['\n        for index, x in d.iterrows():\n            item=str(x['ItemId'])\n            recommendation = recommendation + item + ','\n        recommendation = recommendation[:-1] + ']'\n        res['recommendation'][i]= recommendation\n        i=i+1\n   else:\n\n      res = pd.DataFrame(columns=[seg,pdver],index=[range(segmentCount)])\n\nreturn res,\n<\/code><\/pre>\n\n<p>when in experiment it returnd the actual itemIds, when in webservice it returns some numbers<\/p>\n\n<p>the purpose of this code is to pivot some table by segment column for recommendation<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2016-07-04 16:57:16.41 UTC",
        "Question_favorite_count":1.0,
        "Question_score":3,
        "Question_tags":"python|web-services|azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":264,
        "Owner_creation_date":"2011-10-31 11:53:18.253 UTC",
        "Owner_last_access_date":"2022-06-28 13:56:00.827 UTC",
        "Owner_location":null,
        "Owner_reputation":778,
        "Owner_up_votes":176,
        "Owner_down_votes":6,
        "Owner_views":89,
        "Answer_body":"<p>After discussion with the product team from Microsoft. the issue was resolved.\nthe product team rolled out an update to the web service first, and only later to the ML-Studio, which fixed an issue with categorical attributes in \"Execute python script\".\nthe issue was in a earlier stage of the flow and has nothing to do with the python code above.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2016-07-10 08:30:23.743 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2016-07-10 08:52:51.38 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"azure ML on AKS memory and CPU parameters",
        "Question_body":"<p>When specifying the memory and core for the AksWebService (deploying Azure ML as a service in AKS), do the values for cpu_cores and memory_gb apply to each replica OR all replicas combined?<\/p>\n<pre><code>AksWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, auth_enabled=True, autoscale_enabled=True, autoscale_min_replicas=4, autoscale_max_replicas=10)\n<\/code><\/pre>\n<p>I am assuming its per replica but just wanted to confirm.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-05 16:31:15.127 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-aks|azure-machine-learning-service",
        "Question_view_count":32,
        "Owner_creation_date":"2013-08-15 14:39:30.773 UTC",
        "Owner_last_access_date":"2022-09-23 17:28:32.673 UTC",
        "Owner_location":null,
        "Owner_reputation":301,
        "Owner_up_votes":27,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Mounting Dataset created from Azure data lake in aml service",
        "Question_body":"<p>I am having a problem with mounting a dataset (created from an azure data lake datastore). I download the dataset by name and am trying to pass it as input to a Tensorflow estimator. The script parameter I provide is as below:<\/p>\n\n<pre><code>'--data-folder': dataset.as_named_input('trainigdata').as_mount('tmp\/dataset')\n<\/code><\/pre>\n\n<p>But I get the following exception:<\/p>\n\n<pre><code>Mounting trainigdata to tmp\/dataset\nERROR - Uncaught exception from FUSE operation opendir, returning errno.EINVAL.\nTraceback (most recent call last):\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/fuse.py\", line 734, in _wrapper\n    return func(*args, **kwargs) or 0\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/fuse.py\", line 954, in opendir\n    path.decode(self.encoding))\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/fuse.py\", line 1076, in __call__\n    return getattr(self, op)(*args)\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/fuse\/dprepfuse.py\", line 297, in opendir\n    self._open_dirs[path] = self._list_entries(path)\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/fuse\/dprepfuse.py\", line 145, in _list_entries\n    .to_pandas_dataframe(extended_types=True)\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/_loggerfactory.py\", line 131, in wrapper\n    return func(*args, **kwargs)\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/dataflow.py\", line 706, in to_pandas_dataframe\n    ExecuteAnonymousActivityMessageArguments(anonymous_activity=Dataflow._dataflow_to_anonymous_activity_data(dataflow_to_execute)))\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/_aml_helper.py\", line 38, in wrapper\n    return send_message_func(op_code, message, cancellation_token)\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py\", line 88, in execute_anonymous_activity\n    response = self._message_channel.send_message('Engine.ExecuteActivity', message_args, cancellation_token)\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py\", line 74, in send_message\n    raise_engine_error(response['error'])\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/errorhandlers.py\", line 22, in raise_engine_error\n    raise ExecutionError(error_response)\nazureml.dataprep.api.errorhandlers.ExecutionError: Could not execute the specified transform.|session_id=101b574b-cdd2-4975-a5bd-0e57c9fc061f\nLogging warning in history service: ERROR:: Dataset  failed. . Exception Details:Traceback (most recent call last):\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/env\/azureml\/trainprediction_aks_1571941512_8d9344d7\/mounts\/workspaceblobstore\/azureml\/trainprediction_AKS_1571941512_8d9344d7\/azureml-setup\/context_managers.py\", line 208, in __enter__\n    self.datasets.__enter__()\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/data\/context_managers.py\", line 119, in __enter__\n    context_manager.__enter__()\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/fuse\/daemon.py\", line 92, in __enter__\n    self._wait_until_mounted()\n  File \"\/azureml-envs\/azureml_f73412f070d144d39c8a826b53bde771\/lib\/python3.6\/site-packages\/azureml\/dataprep\/fuse\/daemon.py\", line 142, in _wait_until_mounted\n    while not os.path.exists(self.mount_point) or len(os.listdir(self.mount_point)) == 0:\nOSError: [Errno 22] Invalid argument: '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/env\/azureml\/trainprediction_aks_1571941512_8d9344d7\/mounts\/workspaceblobstore\/azureml\/trainprediction_AKS_1571941512_8d9344d7\/tmp\/dataset'\n<\/code><\/pre>\n\n<p>Can someone help with this.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-24 19:17:42.667 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":552,
        "Owner_creation_date":"2019-10-24 18:22:22.07 UTC",
        "Owner_last_access_date":"2020-03-05 23:33:15.29 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-10-24 21:53:22.88 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"SSL Error accessing azure datastore for Azure Auto ML",
        "Question_body":"<p>I am implementing Azure AutoML dashboard in a docker container.\nWhen I access container without Docker it works. But in docker it gives SSL Error.<\/p>\n<pre><code>def upload_dataset_to_blob(ws):\n\n    datastore = ws.get_default_datastore()\n    datastore.upload_files(files=[\n                           '\/usr\/src\/mediafiles\/train.csv'], target_path='beeeerrr-dataset\/tabular\/', overwrite=True, show_progress=True)\n    datastore.upload_files(files=[\n                           '\/usr\/src\/mediafiles\/valid.csv'], target_path='beeeerrr-dataset\/tabular\/', overwrite=True, show_progress=True)\n    datastore.upload_files(files=[\n                           '\/usr\/src\/mediafiles\/test.csv'], target_path='beeeerrr-dataset\/tabular\/', overwrite=True, show_progress=True)\n\n    train_dataset = Dataset.Tabular.from_delimited_files(\n        validate=False,\n        path=[(datastore, 'beeree-dataset\/tabular\/train.csv')])\n    valid_dataset = Dataset.Tabular.from_delimited_files(\n        validate=False,\n        path=[(datastore, 'beeree-dataset\/tabular\/valid.csv')])\n    test_dataset = Dataset.Tabular.from_delimited_files(\n\n        path=[(datastore, 'beeree-dataset\/tabular\/test.csv')])\n\n    return train_dataset, valid_dataset, test_dataset\n<\/code><\/pre>\n<p>This is the error I am getting<\/p>\n<pre><code>Uploading an estimated of 1 files\napp_1     | Uploading \/usr\/src\/mediafiles\/train.csv\napp_1     | Uploaded \/usr\/src\/mediafiles\/train.csv, 1 files out of an estimated total of 1\napp_1     | Uploaded 1 files\napp_1     | Uploading an estimated of 1 files\napp_1     | Uploading \/usr\/src\/mediafiles\/valid.csv\napp_1     | Uploaded \/usr\/src\/mediafiles\/valid.csv, 1 files out of an estimated total of 1\napp_1     | Uploaded 1 files\napp_1     | Uploading an estimated of 1 files\napp_1     | Uploading \/usr\/src\/mediafiles\/test.csv\napp_1     | Uploaded \/usr\/src\/mediafiles\/test.csv, 1 files out of an estimated total of 1\napp_1     | Uploaded 1 files\napp_1     | &lt;bound method DataReference._get_normalized_path of $AZUREML_DATAREFERENCE_blob_test_data&gt;\napp_1     | Internal Server Error: \/azureml\/train\/\napp_1     | Traceback (most recent call last):\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/data\/dataset_error_handling.py&quot;, line 65, in _validate_has_data        \napp_1     |     dataflow.verify_has_data()\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/dataprep\/api\/_loggerfactory.py&quot;, line 206, in wrapper\napp_1     |     return func(*args, **kwargs)\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/dataprep\/api\/dataflow.py&quot;, line 875, in verify_has_data\napp_1     |     if len(self.take(1)._to_pyrecords()) == 0:\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/dataprep\/api\/dataflow.py&quot;, line 792, in _to_pyrecords\napp_1     |     self._engine_api.execute_anonymous_activity(\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/dataprep\/api\/_aml_helper.py&quot;, line 38, in wrapper\napp_1     |     return send_message_func(op_code, message, cancellation_token)\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 120, in execute_anonymous_activity\napp_1     |     response = self._message_channel.send_message('Engine.ExecuteActivity', message_args, cancellation_token)\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py&quot;, line 291, in send_message\napp_1     |     raise_engine_error(response['error'])\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/dataprep\/api\/errorhandlers.py&quot;, line 10, in raise_engine_error\napp_1     |     raise ExecutionError(error_response)\napp_1     | azureml.dataprep.api.errorhandlers.ExecutionError:\napp_1     | Error Code: ScriptExecution.DatastoreResolution.Unexpected\napp_1     | Failed Step: XXXXXXXXXXXXXXXXXXXXXXXXX\napp_1     | Error Message: ScriptExecutionException was caused by DatastoreResolutionException.\napp_1     |   DatastoreResolutionException was caused by UnexpectedException.\napp_1     |     Unexpected failure making request to fetching info for Datastore 'workspaceblobstore' in subscription: 'XXXXXXXXXXXXXXXXXXXXXXXXX', resource group: 'django-env', workspace: 'ml-demo-main'. Using base service url: https:\/\/centralus.experiments.azureml.net. HResult: 0x80131501.\napp_1     |       The SSL connection could not be established, see inner exception.\napp_1     | | session_id=XXXXXXXXXXXXXXXXXXXXXXXXX\napp_1     |\napp_1     | During handling of the above exception, another exception occurred:\napp_1     |\napp_1     | Traceback (most recent call last):\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/django\/core\/handlers\/exception.py&quot;, line 47, in inner\napp_1     |     response = get_response(request)\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/django\/core\/handlers\/base.py&quot;, line 181, in _get_response\napp_1     |     response = wrapped_callback(request, *callback_args, **callback_kwargs)\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/django\/views\/generic\/base.py&quot;, line 70, in view\napp_1     |     return self.dispatch(request, *args, **kwargs)\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/django\/views\/generic\/base.py&quot;, line 98, in dispatch\napp_1     |     return handler(request, *args, **kwargs)\napp_1     |   File &quot;\/usr\/src\/app\/azure_ml\/views.py&quot;, line 50, in get\napp_1     |     azureml_train1()\napp_1     |   File &quot;\/usr\/src\/app\/azure_ml\/rough.py&quot;, line 39, in azureml_train1\napp_1     |     train_dataset, valid_dataset, test_dataset = upload_dataset_to_blob(ws)\napp_1     |   File &quot;\/usr\/src\/app\/utils\/azure_ml\/dataset.py&quot;, line 28, in upload_dataset_to_blob\napp_1     |     train_dataset = Dataset.Tabular.from_delimited_files(\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/data\/_loggerfactory.py&quot;, line 126, in wrapper\napp_1     |     return func(*args, **kwargs)\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/data\/dataset_factory.py&quot;, line 322, in from_delimited_files\napp_1     |     dataflow = _transform_and_validate(\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/data\/dataset_factory.py&quot;, line 966, in _transform_and_validate\napp_1     |     _validate_has_data(dataflow, 'Cannot load any data from the specified path. '\napp_1     |   File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/azureml\/data\/dataset_error_handling.py&quot;, line 68, in _validate_has_data\napp_1     |     raise DatasetValidationError(error_message + '\\n' + e.compliant_message, exception=e)\napp_1     | azureml.data.dataset_error_handling.DatasetValidationError: DatasetValidationError:\napp_1     |     Message: Cannot load any data from the specified path. Make sure the path is accessible and contains data.\napp_1     | ScriptExecutionException was caused by DatastoreResolutionException.\napp_1     |   DatastoreResolutionException was caused by UnexpectedException.\napp_1     |     Unexpected failure making request to fetching info for Datastore 'workspaceblobstore' in subscription: 'XXXXXXXXXXXXXXXXXXXXXXXXX', resource group: 'django-env', workspace: 'ml-demo-main'. Using base service url: https:\/\/centralus.experiments.azureml.net. HResult: 0x80131501.\napp_1     |       Failed due to inner exception of type: HttpRequestException\napp_1     | | session_id=XXXXXXXXXXXXXXXXXXXXXXXXX\napp_1     |     InnerException None\napp_1     |     ErrorResponse\napp_1     | {\napp_1     |     &quot;error&quot;: {\napp_1     |         &quot;code&quot;: &quot;UserError&quot;,\napp_1     |         &quot;message&quot;: &quot;Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by DatastoreResolutionException.\\n  DatastoreResolutionException was caused by UnexpectedException.\\n    Unexpected failure making request to fetching info for Datastore 'workspaceblobstore' in subscription: 'XXXXXXXXXXXXXXXXXXXXXXXXX', resource group: 'django-env', workspace: 'ml-demo-main'. Using base service url: https:\/\/centralus.experiments.azureml.net. HResult: 0x80131501.\\n      Failed due to inner exception of type: HttpRequestException\\n| session_id=XXXXXXXXXXXXXXXXXXXXXXXXX&quot;\napp_1     |     }\napp_1     | }\n<\/code><\/pre>\n<p>It uploads the file successfully but while accessing back it gives following error<\/p>\n<p>I am using Service Principal for authentication.<\/p>\n<pre><code>def get_workspace():\n\n    svr_pr = ServicePrincipalAuthentication(\n        tenant_id=settings.TENANT_ID,\n        service_principal_id=settings.SERVICE_PRINCIPAL_ID,\n        service_principal_password=settings.SERVICE_PRINCIPAL_PASSWORD\n    )\n\n    ws = Workspace(\n        subscription_id=settings.SUBSCRIPTION_ID,\n        resource_group=settings.RESOURCE_GROUP,\n        workspace_name=settings.WORKSPACE_NAME,\n        auth=svr_pr\n    )\n\n    return ws\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-06-02 13:54:59.657 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"python-3.x|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":264,
        "Owner_creation_date":"2021-06-02 13:43:04.583 UTC",
        "Owner_last_access_date":"2022-01-03 08:28:58.35 UTC",
        "Owner_location":null,
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-12-17 13:28:37.35 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Volume mount failed with: DataAccessError(PermissionDenied) Azure-ML",
        "Question_body":"<p>I have created AzureML experiment where i am ingesting a dataset with azure SQL Server as source.\nbelow is the code.<\/p>\n<pre><code>from azureml.core import Experiment, ScriptRunConfig, Environment\n\ninput_data = ws.datasets.get('azure_sql_data')\n\nexperiment_folder = 'experiment'\nenv = Environment.from_conda_specification(&quot;env&quot;, &quot;environment.yml&quot;)\n\nscript_config = ScriptRunConfig(source_directory=experiment_folder,\n                                script='tranformer.py',\n                                arguments = ['--input-data', input_data.as_named_input('input_data')],\n                                environment=env)\n<\/code><\/pre>\n<p>When i run this experiment i am getting following error.\n<strong>Dataset initialization failed: DataAccessError(PermissionDenied)<\/strong><\/p>\n<p>Am i missing something here?<\/p>\n<p>I can access the azure SQL server data in while running it in aml notebook but when i run experiment i am getting above error.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-13 18:13:30.593 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":147,
        "Owner_creation_date":"2019-02-01 14:38:56.423 UTC",
        "Owner_last_access_date":"2022-09-18 05:00:16.3 UTC",
        "Owner_location":null,
        "Owner_reputation":93,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"After installing scrubadub_spacy package, spacy.load(\"en_core_web_sm\") not working OSError: [E053] Could not read config.cfg",
        "Question_body":"<p>I am getting the below error when I'm trying to run the following line of code to load en_core_web_sm in the Azure Machine Learning instance.<\/p>\n<p>I debugged the issue and found out that once I install scrubadub_spacy, that seems is the issue causing the error.<\/p>\n<pre><code>spacy.load(&quot;en_core_web_sm&quot;)\n<\/code><\/pre>\n<pre><code>OSError                                   Traceback (most recent call last)\n&lt;ipython-input-2-c6e652d70518&gt; in &lt;module&gt;\n     1 # Load English tokenizer, tagger, parser and NER\n----&gt; 2 nlp = spacy.load(&quot;en_core_web_sm&quot;)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/__init__.py in load(name, vocab, disable, exclude, config)\n    50     &quot;&quot;&quot;\n    51     return util.load_model(\n---&gt; 52         name, vocab=vocab, disable=disable, exclude=exclude, config=config\n    53     )\n    54 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model(name, vocab, disable, exclude, config)\n   418             return get_lang_class(name.replace(&quot;blank:&quot;, &quot;&quot;))()\n   419         if is_package(name):  # installed as package\n--&gt; 420             return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]\n   421         if Path(name).exists():  # path to model data directory\n   422             return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_package(name, vocab, disable, exclude, config)\n   451     &quot;&quot;&quot;\n   452     cls = importlib.import_module(name)\n--&gt; 453     return cls.load(vocab=vocab, disable=disable, exclude=exclude, config=config)  # type: ignore[attr-defined]\n   454 \n   455 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/en_core_web_sm\/__init__.py in load(**overrides)\n    10 \n    11 def load(**overrides):\n---&gt; 12     return load_model_from_init_py(__file__, **overrides)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_init_py(init_file, vocab, disable, exclude, config)\n   619         disable=disable,\n   620         exclude=exclude,\n--&gt; 621         config=config,\n   622     )\n   623 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_path(model_path, meta, vocab, disable, exclude, config)\n   485     config_path = model_path \/ &quot;config.cfg&quot;\n   486     overrides = dict_to_dot(config)\n--&gt; 487     config = load_config(config_path, overrides=overrides)\n   488     nlp = load_model_from_config(config, vocab=vocab, disable=disable, exclude=exclude)\n   489     return nlp.from_disk(model_path, exclude=exclude, overrides=overrides)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_config(path, overrides, interpolate)\n   644     else:\n   645         if not config_path or not config_path.exists() or not config_path.is_file():\n--&gt; 646             raise IOError(Errors.E053.format(path=config_path, name=&quot;config.cfg&quot;))\n   647         return config.from_disk(\n   648             config_path, overrides=overrides, interpolate=interpolate\n\nOSError: [E053] Could not read config.cfg from \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/en_core_web_sm\/en_core_web_sm-2.3.1\/config.cfg\n<\/code><\/pre>\n<p>I installed the packages using the below three lines codes from <a href=\"https:\/\/spacy.io\/usage\" rel=\"nofollow noreferrer\">Spacy<\/a><\/p>\n<pre><code>pip install -U pip setuptools wheel\npip install -U spacy\npython -m spacy download en_core_web_sm\n<\/code><\/pre>\n<p>How should I fix this issue? thanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-03 18:19:43.59 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|python-3.6|spacy|azure-machine-learning-service|oserror",
        "Question_view_count":201,
        "Owner_creation_date":"2019-11-13 00:38:54.107 UTC",
        "Owner_last_access_date":"2022-06-23 16:56:21.83 UTC",
        "Owner_location":"Saint Louis, MO, USA",
        "Owner_reputation":25,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>Taking the path from your error message:<\/p>\n<pre><code>en_core_web_sm-2.3.1\/config.cfg\n<\/code><\/pre>\n<p>You have a model for v2.3, but it's looking for a <code>config.cfg<\/code>, which is only a thing in v3 of spaCy. It looks like you upgraded spaCy without realizing it.<\/p>\n<p>There are two ways to fix this. One is to reinstall the model with <code>spacy download<\/code>, which will get a version that matches your current spaCy version. If you are just starting something that is probably the best idea. Based on the release date of scrubadub, it seems to be intended for use with spaCy v3.<\/p>\n<p>However, note that v2 and v3 are pretty different - if you have a project with v2 of spaCy you might want to downgrade instead.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-02-06 04:46:54.723 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2022-02-04 18:12:19.103 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML Model Register",
        "Question_body":"<p>I was trying to register a model using the <code>Run<\/code> Class like this:<\/p>\n<pre><code>model = run.register_model(\n    model_name=model_name,\n    model_path=model_path)\n<\/code><\/pre>\n<p>Errors with message: <code>Could not locate the provided model_path ... in the set of files uploaded to the run...<\/code><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-31 15:43:57.027 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":319,
        "Owner_creation_date":"2020-05-12 14:25:08.567 UTC",
        "Owner_last_access_date":"2022-09-20 13:49:41.073 UTC",
        "Owner_location":null,
        "Owner_reputation":833,
        "Owner_up_votes":9,
        "Owner_down_votes":9,
        "Owner_views":55,
        "Answer_body":"<p>The only way I found to fix the issue was to use the <code>Model<\/code> Class instead:<\/p>\n<pre><code>        model = Model.register(\n            workspace=ws,\n            model_name=model_name,\n            model_path=model_path,\n            model_framework=Model.Framework.SCIKITLEARN,\n            model_framework_version=sklearn.__version__,\n            description='Model Deescription',\n            tags={'Name' : 'ModelName', 'Type' : 'Production'},\n            model_framework=Model.Framework.SCIKITLEARN,\n            model_framework_version='1.0'\n            )\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-31 15:43:57.027 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Studio Local Environment \u2014 Numpy package import failure using the Azure ML Python SDK",
        "Question_body":"<p>I am trying to create a local environment for the ML Studio using the Python SDK, following\n<a href=\"https:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/environment\/\" rel=\"nofollow noreferrer\">this official cheatsheet<\/a>. The result should be a conda-like environment that can be used for local testing. However, I am running into an error when importing the Numpy package with the <code>add_conda_package()<\/code> method of the <code>CondaDependencies()<\/code> class. Where I've tried not specifying, as well as specifying package versions, like:\n<code>add_conda_package('numpy')<\/code> or <code>add_conda_package('numpy=1.21.2')<\/code>, but it does not seem to make a difference.<\/p>\n<p>Numpy's error message is extensive, and I've tried many of the suggestions, without success nonetheless. I'm grateful for any tips on what might resolve my issues!<\/p>\n<hr \/>\n<h2>Full code<\/h2>\n<pre><code>from azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\n\n\ndef get_env() -&gt; Environment:\n    conda = CondaDependencies()\n\n    # add channels\n    conda.add_channel('defaults')\n    conda.add_channel('conda-forge')\n    conda.add_channel('pytorch')\n\n    # Python\n    conda.add_conda_package('python=3.8')\n\n    # Other conda packages\n    conda.add_conda_package('cudatoolkit=11.3')\n    conda.add_conda_package('pip')\n    conda.add_conda_package('python-dateutil')\n    conda.add_conda_package('python-dotenv')\n    conda.add_conda_package('pytorch=1.10')\n    conda.add_conda_package('torchaudio')\n    conda.add_conda_package('torchvision')\n    conda.add_conda_package('wheel')\n    conda.add_conda_package('numpy=1.21.2') # &lt;--- Error with this import \n\n    # create environment\n    env = Environment('test_env')\n    env.python.conda_dependencies = conda\n\n    return env\n<\/code><\/pre>\n<hr \/>\n<h2>Detailed error message:<\/h2>\n<p>User program failed with ImportError:<\/p>\n<p>IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!<\/p>\n<p>Importing the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.<\/p>\n<p>We have compiled some common reasons and troubleshooting tips at:<\/p>\n<pre><code>https:\/\/numpy.org\/devdocs\/user\/troubleshooting-importerror.html\n<\/code><\/pre>\n<p>Please note and check the following:<\/p>\n<ul>\n<li>The Python version is: Python3.8 from &quot;&lt;LOCAL_DIR&gt;.azureml\\envs\\azureml_&gt;\\python.exe&quot;<\/li>\n<li>The NumPy version is: &quot;1.19.1&quot;<\/li>\n<\/ul>\n<p>and make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.<\/p>\n<p>Original error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.<\/p>\n<hr \/>\n<h2>System specifications:<\/h2>\n<ul>\n<li>Local OS: Windows 10<\/li>\n<li>ML studio OS: Linux Ubuntu 18<\/li>\n<li>Python version: 3.8<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-24 08:26:47.11 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|numpy|azure-machine-learning-studio|azureml-python-sdk",
        "Question_view_count":135,
        "Owner_creation_date":"2021-03-08 15:18:01.047 UTC",
        "Owner_last_access_date":"2022-09-23 14:50:23.32 UTC",
        "Owner_location":null,
        "Owner_reputation":43,
        "Owner_up_votes":17,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":"<p>I was finally able to resolve the issue by using the pip method instead of the conda method:\n<code>add_pip_package('numpy')<\/code> instead of <code>add_conda_package('numpy')<\/code>\nI can imagine this being the reason for other packages as well.<\/p>\n<hr \/>\n<h2>Full solution<\/h2>\n<pre><code>from azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\n\n\ndef get_env() -&gt; Environment:\n    conda = CondaDependencies()\n\n    # add channels\n    conda.add_channel('defaults')\n    conda.add_channel('conda-forge')\n    conda.add_channel('pytorch')\n\n    # Python\n    conda.add_conda_package('python=3.8')\n\n    # Other conda packages\n    conda.add_conda_package('cudatoolkit=11.3')\n    conda.add_conda_package('pip')\n    conda.add_conda_package('python-dateutil')\n    conda.add_conda_package('python-dotenv')\n    conda.add_conda_package('pytorch=1.10')\n    conda.add_conda_package('torchaudio')\n    conda.add_conda_package('torchvision')\n    conda.add_conda_package('wheel')\n    #conda.add_conda_package('numpy=1.21.2') # &lt;--- Error with this import \n\n    # Add pip packages\n    conda.add_pip_package('numpy') # &lt;--- Fixes import error\n\n    # create environment\n    env = Environment('test_env')\n    env.python.conda_dependencies = conda\n\n    return env\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-24 08:37:13.89 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Weird color scheme in Azure ML Studio notebooks",
        "Question_body":"<p>I am getting this weird color scheme in Azure ML Studio. The code runs fine, but the excessive use of red makes it look like I have errors on every line. Anyone know how to change the theme?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/zIiR4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zIiR4.png\" alt=\"Printscreen\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-28 08:58:07.043 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|jupyter-notebook|azure-machine-learning-service|ml-studio",
        "Question_view_count":46,
        "Owner_creation_date":"2016-05-21 16:01:40.89 UTC",
        "Owner_last_access_date":"2022-08-24 14:21:04.223 UTC",
        "Owner_location":null,
        "Owner_reputation":646,
        "Owner_up_votes":29,
        "Owner_down_votes":4,
        "Owner_views":26,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Unpickling error when running fairseq on AML using multiple GPUs",
        "Question_body":"<p>I am trying to run fairseq translation task on AML using 4 GPUs (P100)and it fails with the following error:<\/p>\n\n<blockquote>\n  <p>-- Process 2 terminated with the following error: Traceback (most recent call last):   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/distributed_utils.py\",\n  line 174, in all_gather_list\n      result.append(pickle.loads(bytes(out_buffer[2 : size + 2].tolist())))\n  _pickle.UnpicklingError: invalid load key, '\\xad'.<\/p>\n  \n  <p>During handling of the above exception, another exception occurred:<\/p>\n  \n  <p>Traceback (most recent call last):   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/torch\/multiprocessing\/spawn.py\",\n  line 19, in _wrap\n      fn(i, *args)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 272, in distributed_main\n      main(args, init_distributed=True)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 82, in main\n      train(args, trainer, task, epoch_itr)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 123, in train\n      log_output = trainer.train_step(samples)   File \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/trainer.py\",\n  line 305, in train_step\n      [logging_outputs, sample_sizes, ooms, self._prev_grad_norm],   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/distributed_utils.py\",\n  line 178, in all_gather_list\n      'Unable to unpickle data from other workers. all_gather_list requires all ' Exception: Unable to unpickle data from other workers.\n  all_gather_list requires all workers to enter the function together,\n  so this error usually indicates that the workers have fallen out of\n  sync somehow. Workers can fall out of sync if one of them runs out of\n  memory, or if there are other conditions in your training script that\n  can cause one worker to finish an epoch while other workers are still\n  iterating over their portions of the data.<\/p>\n  \n  <p> 2019-09-18\n  17:28:44,727|azureml.WorkerPool|DEBUG|[STOP]<\/p>\n  \n  <p>Error occurred: User program failed with Exception: <\/p>\n  \n  <p>-- Process 2 terminated with the following error: Traceback (most recent call last):   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/distributed_utils.py\",\n  line 174, in all_gather_list\n      result.append(pickle.loads(bytes(out_buffer[2 : size + 2].tolist())))\n  _pickle.UnpicklingError: invalid load key, '\\xad'.<\/p>\n  \n  <p>During handling of the above exception, another exception occurred:<\/p>\n  \n  <p>Traceback (most recent call last):   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/torch\/multiprocessing\/spawn.py\",\n  line 19, in _wrap\n      fn(i, *args)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 272, in distributed_main\n      main(args, init_distributed=True)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 82, in main\n      train(args, trainer, task, epoch_itr)   File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/nlx-ml-neuralrewrite\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/mounts\/workspacefilestore\/azureml\/pytorch-fairseq_1568826205_6846ecb6\/train.py\",\n  line 123, in train\n      log_output = trainer.train_step(samples)   File \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/trainer.py\",\n  line 305, in train_step\n      [logging_outputs, sample_sizes, ooms, self._prev_grad_norm],   File\n  \"\/azureml-envs\/azureml_8ef3d311fd9072540e3352d9621cca49\/lib\/python3.6\/site-packages\/fairseq\/distributed_utils.py\",\n  line 178, in all_gather_list\n      'Unable to unpickle data from other workers. all_gather_list requires all ' Exception: Unable to unpickle data from other workers.\n  all_gather_list requires all workers to enter the function together,\n  so this error usually indicates that the workers have fallen out of\n  sync somehow. Workers can fall out of sync if one of them runs out of\n  memory, or if there are other conditions in your training script that\n  can cause one worker to finish an epoch while other workers are still\n  iterating over their portions of the data.<\/p>\n<\/blockquote>\n\n<p>The same code with same param runs fine on a single local GPU. How do I resolve this issue?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_date":"2019-09-18 18:01:47.947 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":216,
        "Owner_creation_date":"2019-09-18 17:54:14.257 UTC",
        "Owner_last_access_date":"2019-11-15 22:49:28.58 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML: How to save and process CSV files with semicolon as delimiter?",
        "Question_body":"<p>Azure ML support says to me that delimiter must be comma, this would cause too much hassle with data having semicolon as separator and with a lot of commas in the cell values. <\/p>\n\n<p>So how to process semicolon separated CSV files in Azure ML? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2017-01-25 15:26:11.913 UTC",
        "Question_favorite_count":0.0,
        "Question_score":5,
        "Question_tags":"csv|azure|azure-machine-learning-studio|escaping",
        "Question_view_count":2908,
        "Owner_creation_date":"2009-08-27 11:33:59.053 UTC",
        "Owner_last_access_date":"2022-05-27 10:56:29.307 UTC",
        "Owner_location":null,
        "Owner_reputation":48616,
        "Owner_up_votes":1240,
        "Owner_down_votes":41,
        "Owner_views":3348,
        "Answer_body":"<p>Azure ML only accepts the comma <code>,<\/code> separated CSV. Do a little work around.\nOpen your data file using a text editor. (Notepad will do the trick). Find and replace all semicolons with 'tab' (Make it a TSV) and the commas in data values may not occur a problem then. Make sure to define that the input is a TSV; not a CSV. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-01-31 04:59:31.543 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":7.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Use a Dask Cluster in a PythonScriptStep",
        "Question_body":"<p>Is it possible to have a multi-node Dask cluster be the compute for a <code>PythonScriptStep<\/code> with AML Pipelines?<\/p>\n<p>We have a <code>PythonScriptStep<\/code> that uses <code>featuretools<\/code>'s, deep feature synthesis (<code>dfs<\/code>) (<a href=\"https:\/\/docs.featuretools.com\/en\/stable\/generated\/featuretools.dfs.html\" rel=\"nofollow noreferrer\">docs<\/a>). <code>ft.dfs()<\/code> has a param, <code>n_jobs<\/code> which allows for parallelization. When we run on a single machine, the job takes three hours, and runs much faster on a Dask. How can I operationalize this within an Azure ML pipeline?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-07 17:43:21.793 UTC",
        "Question_favorite_count":2.0,
        "Question_score":4,
        "Question_tags":"dask|azure-machine-learning-service",
        "Question_view_count":362,
        "Owner_creation_date":"2014-07-15 20:45:20.427 UTC",
        "Owner_last_access_date":"2022-09-23 15:42:13.1 UTC",
        "Owner_location":"Seattle, WA, USA",
        "Owner_reputation":3359,
        "Owner_up_votes":1187,
        "Owner_down_votes":14,
        "Owner_views":555,
        "Answer_body":"<p>We've been working and recently released a <code>dask_cloudprovider.AzureMLCluster<\/code> that might be of interest to you: <a href=\"https:\/\/github.com\/dask\/dask-cloudprovider\" rel=\"noreferrer\">link to repo<\/a>. You can install it via <code>pip install dask-cloudprovider<\/code>.<\/p>\n<p>The <code>AzureMLCluster<\/code> instantiates Dask cluster on AzureML service with elasticity of scaling up to 100s of nodes should you require that. The only required parameter is the <code>Workspace<\/code> object, but you can pass your own <code>ComputeTarget<\/code> should you choose to.<\/p>\n<p>An example of how to use it you can <a href=\"https:\/\/github.com\/drabastomek\/GTC\/blob\/master\/SJ_2020\/workshop\/1_Setup\/Setup.ipynb\" rel=\"noreferrer\">found here<\/a>. In this example I use my custom GPU\/RAPIDS docker image but you can use any images within the <code>Environment<\/code> class.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-08-07 18:08:34.437 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":6.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Submitting multiple runs to the same node on AzureML",
        "Question_body":"<p>I want to perform hyperparameter search using AzureML. My models are small (around 1GB) thus I would like to run multiple models on the same GPU\/node to save costs but I do not know how to achieve this.<\/p>\n<p>The way I currently submit jobs is the following (resulting in one training run per GPU\/node):<\/p>\n<pre><code>experiment = Experiment(workspace, experiment_name)\nconfig = ScriptRunConfig(source_directory=&quot;.\/src&quot;,\n                         script=&quot;train.py&quot;,\n                         compute_target=&quot;gpu_cluster&quot;,\n                         environment=&quot;env_name&quot;,\n                         arguments=[&quot;--args args&quot;])\nrun = experiment.submit(config)\n<\/code><\/pre>\n<p><code>ScriptRunConfig<\/code> can be provided with a <code>distributed_job_config<\/code>. I tried to use <code>MpiConfiguration<\/code> there but if this is done the run fails due to an MPI error that reads as if the cluster is configured to only allow one run per node:<\/p>\n<blockquote>\n<pre><code>Open RTE detected a bad parameter in hostfile: [...]\nThe max_slots parameter is less than the slots parameter:\nslots = 3\nmax_slots = 1\n[...] ORTE_ERROR_LOG: Bad Parameter in file util\/hostfile\/hostfile.c at line 407\n<\/code><\/pre>\n<\/blockquote>\n<p>Using <code>HyperDriveConfig<\/code> also defaults to submitting one run to one GPU and additionally providing a <code>MpiConfiguration<\/code> leads to the same error as shown above.<\/p>\n<p>I guess I could always rewrite my train script to train multiple models in parallel, s.t. each <code>run<\/code> wraps multiple trainings. I would like to avoid this option though, because then logging and checkpoint writes become increasingly messy and it would require a large refactor of the train pipeline. Also this functionality seems so basic that I hope there is a way to do this gracefully. Any ideas?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-28 09:09:02.523 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"azure|mpi|cluster-computing|azure-machine-learning-service",
        "Question_view_count":364,
        "Owner_creation_date":"2014-04-04 10:29:38.877 UTC",
        "Owner_last_access_date":"2022-07-08 15:24:09.527 UTC",
        "Owner_location":null,
        "Owner_reputation":107,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Answer_body":"<p>Use Run.create_children method which will start child runs that are \u201clocal\u201d to the parent run, and don\u2019t need authentication.<\/p>\n<p>For AMLcompute max_concurrent_runs map to maximum number of nodes that will be used to run  a hyperparameter tuning run.\nSo there would be 1 execution per node.<\/p>\n<p>single service deployed but you can load multiple model versions in the init then the score function, depending on the request\u2019s param, uses particular model version to score.\nor with the new ML Endpoints (Preview).\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-endpoints\" rel=\"nofollow noreferrer\">What are endpoints (preview) - Azure Machine Learning | Microsoft Docs<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-29 12:53:19.763 UTC",
        "Answer_last_edit_date":"2021-10-29 13:08:00.997 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Proper way to make a request to a model, deployed via Azure ML Designer",
        "Question_body":"<p>I am trying to make the POST request to the Azure ML Designer endpoint (model, I have deployed).\nHere is my code:<\/p>\n<pre><code>import requests\n\nscoring_uri = 'http:some-url\/score'\nkey = 'someKey'\n\nheaders = {'Content-Type': 'application\/json'}\nheaders['Authorization'] = f'Bearer {key}'\n\nresponse = requests.get('https:\/\/www.okino.ua\/media\/var\/news\/2019\/12\/04\/Quentin_Tarantino.jpg')\n\ninput_data = &quot;{\\&quot;data\\&quot;: [&quot; + str(response.content) + &quot;]}&quot;\nresp = requests.post(scoring_uri, data=response.content, headers=headers)\nprint(resp.text)\n<\/code><\/pre>\n<p>And I receive and error:<\/p>\n<pre><code>{&quot;error&quot;: {&quot;code&quot;: 400, &quot;message&quot;: &quot;Input Data Error. Input data are inconsistent with schema.\\nSchema: {'WebServiceInput0': {'columnAttributes': [{'name': 'image', 'type': 'Bytes', 'isFeature': True, 'elementType': {'typeName': 'bytes', 'isNullable': False}, 'properties': {'mime_type': 'image\/png', 'image_ref': 'image_info'}}, {'name': 'id', 'type': 'Numeri\\nData: b'\\\\xff\\\\xd8\\\\xff\\\\xe0\\\\x00\\\\x10JFIF\\\\x00\\\\x01\\\\x01\\\\x01\\\\x01,\\\\x01,\\\\x00\\\\x00\\\\xff\\\\xfe\\\\x00[Copyright Shutterstock 2019;82139424;3600;2400;1563865756;Tue, 23 Jul 2019 07:09:16 GMT;0\\\\xff\\\\xed\\\\x04\\\\x16Photoshop 3.0\\\\x008BIM\\\\x04\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x03\\\\xf9\\\\x1c\\\\x02\\\\x05\\\\x00\\\\n103\\nTraceback (most recent call last):\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/site-packages\/azureml\/designer\/serving\/dagengine\/processor.py\\&quot;, line 18, in run\\n    webservice_input, global_parameters = self.pre_process(raw_data)\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/site-packages\/azureml\/designer\/serving\/dagengine\/processor.py\\&quot;, line 45, in pre_process\\n    json_data = json.loads(raw_data)\\n  File \\&quot;\/azureml-envs\/azureml_c1330288c44b762b0282b6f129c5292f\/lib\/python3.6\/json\/__init__.py\\&quot;, line 349, in loads\\n    s = s.decode(detect_encoding(s), 'surrogatepass')\\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\\n&quot;, &quot;details&quot;: &quot;&quot;}}\n\n<\/code><\/pre>\n<p>Is anyone aware of how I should pass image data to the exposed by Azure ML endpoint?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-11-27 22:56:08.417 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|computer-vision|classification|azure-machine-learning-service",
        "Question_view_count":264,
        "Owner_creation_date":"2019-08-05 20:53:55.857 UTC",
        "Owner_last_access_date":"2020-11-29 08:50:37.553 UTC",
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-12-01 01:17:47.36 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Another Azure ML bug caused by new Compute Common Runtime",
        "Question_body":"<p>Many of my Azure ML Studio Designer pipelines began failing today.  I was able to make a minimum repro:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2mXzI.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2mXzI.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Simply excluding columns with the <code>Select Columns In Dataset<\/code> node will fail with a <code>JobConfigurationMaxSizeExceeded<\/code> error.<\/p>\n<p>This appears to be a bug introduced by Microsoft's rollout of their new Compute Common Runtime.<\/p>\n<p>If I go into any nodes failing with the <code>JobConfigurationMaxSizeExceeded<\/code> exception and manually set <code>AZUREML_COMPUTE_USE_COMMON_RUNTIME:false<\/code> in their  <code>Environment JSON<\/code> field, then they will subsequently work correctly.  This is not documented anywhere that I could find, I stumbled over this fix through trial-and-error, and I wasted many hours trying to fix our failing pipelines today.<\/p>\n<p>Does anyone know where I can find a list of possible effects of the Compute Common Runtime migration in Azure ML? I could not find any documentation on this and\/or how it might affect existing Azure ML pipelines.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-12-07 04:43:33.613 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":256,
        "Owner_creation_date":"2012-06-27 21:51:16.13 UTC",
        "Owner_last_access_date":"2022-09-21 21:19:20.11 UTC",
        "Owner_location":null,
        "Owner_reputation":751,
        "Owner_up_votes":68,
        "Owner_down_votes":5,
        "Owner_views":73,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Run independent `PythonScriptStep` steps in parallel",
        "Question_body":"<p>In my pipeline multiple steps are independent and so I would like them to run in parallel based on input dependencies.<\/p>\n<p>As the compute I use has multiple nodes I would have expected this to be the default.<\/p>\n<p>For example:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Iye85.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Iye85.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>All 3 upper steps should run in parallel, then both <code>finetune<\/code> steps in parallel as soon as their inputs are satisfied and the same for <code>rgb_test<\/code>.<\/p>\n<p>Currently only 1 step runs at a time, the other are <code>Queued<\/code>.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2021-09-02 19:49:26.28 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":156,
        "Owner_creation_date":"2012-01-26 14:27:40.553 UTC",
        "Owner_last_access_date":"2022-09-24 16:26:41.58 UTC",
        "Owner_location":null,
        "Owner_reputation":802,
        "Owner_up_votes":288,
        "Owner_down_votes":0,
        "Owner_views":91,
        "Answer_body":"<p>It ended up being because of vCPU quota.<\/p>\n<p>After increasing the quota, parallel tasks can run at the same time as expected.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-09-27 19:02:52.63 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Import ML Model from ADLS to Azure ML using Databricks",
        "Question_body":"<p>I have stored one ml model in my ADLS and I want to register the model to Azure ML using databricks. Tried to use the following codes to register my ml model but keep encountering an error that the path cannot be found. I have mount the storage to my databricks.<\/p>\n<pre><code>import urllib.request\nfrom azureml.core.model import Model\n\n# Register a model \nmodel = Model.register(model_path = 'dbfs:\/mnt\/machinelearning\/classifier.joblib',\n                      model_name = &quot;pretrained-classifier&quot;,\n                      description = &quot;Pretrained Classifier&quot;,\n                       workspace=ws)\n\n\n<\/code><\/pre>\n<p>Thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-01-17 10:23:40.303 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|databricks|azure-databricks|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":113,
        "Owner_creation_date":"2019-04-12 07:33:39.33 UTC",
        "Owner_last_access_date":"2022-02-08 09:29:56.247 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How do you reference the models repository in Azure Machine Learning from within side a python script step?",
        "Question_body":"<p>I know there's a $MODEL_VERSION variable when you create a scoring script using AKS but how about for a script task (example python script task) but I can't find documentation on how to deserialize a model into object from within script step running on a Linux AML computer cluster.<\/p>\n<p>Is there a way to use models I've published to models tab in Workspace (say name is my model) from within a python script step?<\/p>\n<p>For example in this code snippet:<\/p>\n<pre><code>import job lib\nmodel = joblib.load(file_path + &quot;mymodel&quot;)\n<\/code><\/pre>\n<p>I'm looking for what relative or absolute NIX path to use for file_path during a run where mymodel has already been published to the Workspace.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-07-05 00:33:42.417 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":362,
        "Owner_creation_date":"2021-07-05 00:28:29.467 UTC",
        "Owner_last_access_date":"2021-08-17 03:11:59.333 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Python Module failing to Execute Calls to Cognitive Services",
        "Question_body":"<p>I have created a Pipeline in Azure ML which makes calls to Azure Cognitive Services Text Analytics using its Python API. When I run the code I have written locally, it executes without error, but when run it in the pipeline it fails to perform the Sentiment Analysis and Key Phrase Extraction calls with a strange error message:<\/p>\n<blockquote>\n<p>Got exception when invoking script at line 243 in function azureml_main: 'ServiceRequestError: &lt;urllib3.connection.HTTPSConnection object at 0x7ff4dc727588&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'.<\/p>\n<\/blockquote>\n<p>Upon further testing, it appears that it is able to open the Text Analytics Client correctly (Or at least without throwing an error), but when it gets to the line that actually makes the call out using the Python API it throws the above error.<\/p>\n<p>I wondered if it was an Open SSL issue, but when I checked the version it had access to TLS 1.2: <code>OpenSSL 1.1.1k  25 Mar 2021<\/code><\/p>\n<p>It does not appear to be a temporary issue; I started seeing the issue last week, and I have seen it over a number of environments and with different input datasets.<\/p>\n<p>Has anyone seen a similar issue before? Any ideas on how it could be resolved?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-09-06 02:19:05.58 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|azure|azure-cognitive-services|azure-machine-learning-service|azure-python-sdk",
        "Question_view_count":299,
        "Owner_creation_date":"2021-01-20 22:28:36.003 UTC",
        "Owner_last_access_date":"2021-12-13 22:49:59.46 UTC",
        "Owner_location":null,
        "Owner_reputation":119,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>After speaking with Microsoft Support, it turns out this error was a platform error introduced in a recent update of Azure ML. Their product team are currently investigating a solution.<\/p>\n<p>As a temporary fix, if you see this issue, you can try switching between using your personal endpoint and the generic regional endpoint; In this case, the error was only introduced for using personal endpoints. The endpoints in question have the following formats:<\/p>\n<ul>\n<li>Personal: <code>https:\/\/&lt;COGNITIVE-SERVICES-INSTANCE&gt;.cognitiveservices.azure.com\/<\/code><\/li>\n<li>Regional: <code>https:\/\/&lt;REGION&gt;.api.cognitive.microsoft.com\/<\/code><\/li>\n<\/ul>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-09-14 00:52:58.54 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":3.0,
        "Question_last_edit_date":"2021-09-06 23:43:04.78 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Can SAC be used instead PPO in Cartpole example?",
        "Question_body":"<p>I'm studying AzureML RL with example codes.<\/p>\n<p>I could run cartpole example (cartpole_ci.ipynb) which trains\nthe PPO model on compute instance.<\/p>\n<p>I tried SAC instead of PPO by changing training_algorithm = &quot;PPO&quot; to training_algorithm = &quot;SAC&quot;\nbut it failed with the message below.<\/p>\n<blockquote>\n<p>ray.rllib.utils.error.UnsupportedSpaceException: Action space Discrete(2) is not supported for SAC.<\/p>\n<\/blockquote>\n<p>Has someone tried SAC algorithm on AzureML RL and did it work?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-07 05:33:33.16 UTC",
        "Question_favorite_count":1.0,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":494,
        "Owner_creation_date":"2020-09-07 05:21:32.003 UTC",
        "Owner_last_access_date":"2022-09-21 07:07:32.31 UTC",
        "Owner_location":null,
        "Owner_reputation":31,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Deploying from AzureML into AKS - Set Taints & Tolerations",
        "Question_body":"<p>We are attempting to deploy a model from AzureML into an AKS Kluster which has been configured to use taints and tolerations.<\/p>\n<p>When we try to deploy, we receive the below error message...<\/p>\n<p><strong>&quot;details&quot;: [ { &quot;code&quot;: &quot;Unschedulable&quot;, &quot;message&quot;: &quot;0\/15 nodes are available: 12 node(s) had taint {Workload: MachineLearning}, that the pod didn't tolerate, 3 node(s) didn't match Pod's node affinity\/selector.&quot; }, { &quot;code&quot;: &quot;DeploymentFailed&quot;, &quot;message&quot;: &quot;Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00. You can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service. Please refer to https:\/\/aka.ms\/debugimage#container-cannot-be-scheduled for more information.&quot; }, { &quot;code&quot;: &quot;DeploymentFailed&quot;, &quot;message&quot;: &quot;Your container endpoint is not available. Please follow the steps to debug: 1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information. 2. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information. 3. For AKS deployment with custom certificate, you need to update your DNS record to point to the IP address of scoring endpoint. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-secure-web-service#update-your-dns for more information. 4. View the diagnostic events to check status of container, it may help you to debug the issue. {&quot;InvolvedObject&quot;:&quot;am-prod-app-c88d8d49c-vbxsv&quot;,&quot;InvolvedKind&quot;:&quot;Pod&quot;,&quot;Type&quot;:&quot;Warning&quot;,&quot;Reason&quot;:&quot;FailedScheduling&quot;,&quot;Message&quot;:&quot;0\/15 nodes are available: 15 pod has unbound immediate PersistentVolumeClaims.&quot;,&quot;LastTimestamp&quot;:null} {&quot;InvolvedObject&quot;:&quot;am-prod-app-c88d8d49c-vbxsv&quot;,&quot;InvolvedKind&quot;:&quot;Pod&quot;,&quot;Type&quot;:&quot;Warning&quot;,&quot;Reason&quot;:&quot;FailedScheduling&quot;,&quot;Message&quot;:&quot;0\/15 nodes are available: 15 pod has unbound immediate PersistentVolumeClaims.&quot;,&quot;LastTimestamp&quot;:null} {&quot;InvolvedObject&quot;:&quot;am-prod-app-c88d8d49c-vbxsv&quot;,&quot;InvolvedKind&quot;:&quot;Pod&quot;,&quot;Type&quot;:&quot;Warning&quot;,&quot;Reason&quot;:&quot;FailedScheduling&quot;,&quot;Message&quot;:&quot;0\/15 nodes are available: 12 node(s) had taint {Workload: MachineLearning}, that the pod didn't tolerate, 3 node(s) didn't match Pod's node affinity\/selector.&quot;,&quot;LastTimestamp&quot;:null} {&quot;InvolvedObject&quot;:&quot;am-prod-app-c88d8d49c-vbxsv&quot;,&quot;InvolvedKind&quot;:&quot;Pod&quot;,&quot;Type&quot;:&quot;Normal&quot;,&quot;Reason&quot;:&quot;NotTriggerScaleUp&quot;,&quot;Message&quot;:&quot;pod didn't trigger scale-up: 5 pod has unbound immediate PersistentVolumeClaims&quot;,&quot;LastTimestamp&quot;:&quot;2022-04-05T14:33:02Z&quot;} &quot; } ] }<\/strong><\/p>\n<p>Is there any way to specify the taints and tolerations from the deployment?<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-06 13:28:20.4 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|kubernetes|azure-machine-learning-service",
        "Question_view_count":87,
        "Owner_creation_date":"2022-04-06 13:22:52.747 UTC",
        "Owner_last_access_date":"2022-07-13 10:36:26.563 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Disk I\/O extremely slow on P100-NC6s-V2",
        "Question_body":"<p>I am training an image segmentation model on azure ML pipeline. During the testing step, I'm saving the output of the model to the associated blob storage. Then I want to find the IOU (Intersection over Union) between the calculated output and the ground truth. Both of these set of images lie on the blob storage. However, IOU calculation is extremely slow, and I think it's disk bound. In my IOU calculation code, I'm just loading the two images (commented out other code), still, it's taking close to 6 seconds per iteration, while training and testing were fast enough. <\/p>\n\n<p>Is this behavior normal? How do I debug this step?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-17 09:50:01.943 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"tensorflow|azure-machine-learning-service",
        "Question_view_count":415,
        "Owner_creation_date":"2014-08-15 23:27:51.463 UTC",
        "Owner_last_access_date":"2021-05-13 06:30:45.853 UTC",
        "Owner_location":"India",
        "Owner_reputation":65,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>A few notes on the drives that an AzureML remote run has available:<\/p>\n\n<p>Here is what I see when I run <code>df<\/code> on a remote run (in this one, I am using a blob <code>Datastore<\/code> via <code>as_mount()<\/code>):<\/p>\n\n<pre><code>Filesystem                             1K-blocks     Used  Available Use% Mounted on\noverlay                                103080160 11530364   86290588  12% \/\ntmpfs                                      65536        0      65536   0% \/dev\ntmpfs                                    3568556        0    3568556   0% \/sys\/fs\/cgroup\n\/dev\/sdb1                              103080160 11530364   86290588  12% \/etc\/hosts\nshm                                      2097152        0    2097152   0% \/dev\/shm\n\/\/danielscstorageezoh...-620830f140ab 5368709120  3702848 5365006272   1% \/mnt\/batch\/tasks\/...\/workspacefilestore\nblobfuse                               103080160 11530364   86290588  12% \/mnt\/batch\/tasks\/...\/workspaceblobstore\n<\/code><\/pre>\n\n<p>The interesting items are <code>overlay<\/code>, <code>\/dev\/sdb1<\/code>, <code>\/\/danielscstorageezoh...-620830f140ab<\/code> and <code>blobfuse<\/code>:<\/p>\n\n<ol>\n<li><code>overlay<\/code> and <code>\/dev\/sdb1<\/code> are both the mount of the <strong>local SSD<\/strong> on the machine (I am using a STANDARD_D2_V2 which has a 100GB SSD).<\/li>\n<li><code>\/\/danielscstorageezoh...-620830f140ab<\/code> is the mount of the <strong>Azure File Share<\/strong> that contains the project files (your script, etc.). It is also the <em>current working directory<\/em> for your run.<\/li>\n<li><strong><code>blobfuse<\/code><\/strong> is the blob store that I had requested to mount in the <code>Estimator<\/code> as I executed the run.<\/li>\n<\/ol>\n\n<p>I was curious about the performance differences between these 3 types of drives. My mini benchmark was to download and extract this file: <a href=\"http:\/\/download.tensorflow.org\/example_images\/flower_photos.tgz\" rel=\"nofollow noreferrer\">http:\/\/download.tensorflow.org\/example_images\/flower_photos.tgz<\/a> (it is a 220 MB tar file that contains about 3600 jpeg images of flowers).<\/p>\n\n<p>Here the results:<\/p>\n\n<pre><code>Filesystem\/Drive         Download_and_save       Extract\nLocal_SSD                               2s            2s  \nAzure File Share                        9s          386s\nPremium File Share                     10s          120s\nBlobfuse                               10s          133s\nBlobfuse w\/ Premium Blob                8s          121s\n<\/code><\/pre>\n\n<p>In summary, writing small files is much, much slower on the network drives, so it is highly recommended to use \/tmp or Python <code>tempfile<\/code> if you are writing smaller files. <\/p>\n\n<p>For reference, here the script I ran to measure: <a href=\"https:\/\/gist.github.com\/danielsc\/9f062da5e66421d48ac5ed84aabf8535\" rel=\"nofollow noreferrer\">https:\/\/gist.github.com\/danielsc\/9f062da5e66421d48ac5ed84aabf8535<\/a><\/p>\n\n<p>And this is how I ran it: <a href=\"https:\/\/gist.github.com\/danielsc\/6273a43c9b1790d82216bdaea6e10e5c\" rel=\"nofollow noreferrer\">https:\/\/gist.github.com\/danielsc\/6273a43c9b1790d82216bdaea6e10e5c<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-09-17 15:56:27.297 UTC",
        "Answer_last_edit_date":"2019-10-29 00:19:27.397 UTC",
        "Answer_score":4.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Access to Azure Keyvault inside Azure Container Instance",
        "Question_body":"<p>I have a machine learning model deployed on azure container instance and I need to access to key vault. When i use command below<\/p>\n<pre><code>credential = DefaultAzureCredential()\n<\/code><\/pre>\n<p>It can't authenticate thus i cannot reach my secrets.<\/p>\n<p>How can i reach keyvault inside azure container instance?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-08-04 08:16:00.597 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-keyvault|azure-machine-learning-studio|azure-container-instances",
        "Question_view_count":306,
        "Owner_creation_date":"2021-03-24 10:00:57.473 UTC",
        "Owner_last_access_date":"2022-09-10 14:40:32.643 UTC",
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to run Python script over result generated with U-SQL script in Azure Machine Learning Pipelines?",
        "Question_body":"<p>I want to process large tables stored in an Azure Data Lake Storage (Gen 1), first running on them a U-SQL script, then a Python script, and finally output the result.<\/p>\n\n<p>Conceptually this is pretty simple:<\/p>\n\n<ol>\n<li>Run a .usql script to generate intermediate data (two tables, <code>intermediate_1<\/code> and <code>intermediate_2<\/code>) from a large <code>initial_table<\/code><\/li>\n<li>Run a Python script over the intermediate data to generate the final result <code>final<\/code><\/li>\n<\/ol>\n\n<p>What should be the Azure Machine Learning Pipeline steps to do this?<\/p>\n\n<p>I thought the following plan would work:<\/p>\n\n<ol>\n<li><p>Run the .usql query on a <code>adla_compute<\/code> using an <code>AdlaStep<\/code> like   <\/p>\n\n<pre><code>int_1 = PipelineData(\"intermediate_1\", datastore=adls_datastore)\nint_2 = PipelineData(\"intermediate_2\", datastore=adls_datastore)\n\nadla_step = AdlaStep(script_name='script.usql',\n                     source_directory=sample_folder,\n                     inputs=[initial_table],\n                     outputs=[intermediate_1, intermediate_2],\n                     compute_target=adla_compute)          \n<\/code><\/pre><\/li>\n<li><p>Run a Python step on a compute target <code>aml_compute<\/code> like<\/p>\n\n<pre><code>python_step = PythonScriptStep(script_name=\"process.py\",\n                               arguments=[\"--input1\", intermediate_1, \"--input2\", intermediate_2, \"--output\", final],\n                               inputs=[intermediate_1, intermediate_2],\n                               outputs=[final],    \n                               compute_target=aml_compute, \n                               source_directory=source_directory)\n<\/code><\/pre><\/li>\n<\/ol>\n\n<p>This however fails <em>at the Python step<\/em> with an error of the kind <\/p>\n\n<blockquote>\n  <p>StepRun(process.py) Execution Summary  <\/p>\n  \n  <p>======================================<br>\n  StepRun(process.py) Status: Failed<\/p>\n  \n  <p>Unable to mount data store mydatastore because it does not specify a\n  storage account key.<\/p>\n<\/blockquote>\n\n<p>I don't really understand the error complaining about 'mydatastore', which the name tied to the <code>adls_datastore<\/code> Azure Data Lake data store reference on which I am running the U-SQL queries against.  <\/p>\n\n<p>Can someone smell if I am doing something really wrong here? \nShould I move the intermediate data (<code>intermediate_1<\/code> and <code>intermediate_2<\/code>) to a <em>storage account<\/em>, e.g. with a <code>DataTransferStep<\/code>, before the <code>PythonScriptStep<\/code>?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-07-10 16:52:04.07 UTC",
        "Question_favorite_count":0.0,
        "Question_score":1,
        "Question_tags":"python|azure-storage|azure-data-lake|u-sql|azure-machine-learning-service",
        "Question_view_count":217,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_location":"Verona, VR, Italy",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-07-11 11:47:19.263 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Register Azure ML Model from DatabricksStep",
        "Question_body":"<p>I'm calculating a model while executing a DatabricksStep in an Azure ML Pipeline, save it on my Blob Storage as .pkl file and upload it to the current Azure ML Run using Run.upload_file (). All this works without any problems.<\/p>\n<p>But as soon as I try to register the model to the Azure ML Workspace using Run.register_model (), the script throws the following error:<\/p>\n<p>UserErrorException: UserErrorException:\nMessage:\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:<\/p>\n<ol>\n<li>You are not authorized to access this resource, or directory listing denied.<\/li>\n<li>you may not login your azure service, or use other subscription, you can check your\ndefault account by running azure cli commend:\n'az account list -o table'.<\/li>\n<li>You have multiple objects\/login session opened, please close all session and try again.<\/li>\n<\/ol>\n<p>InnerException None\nErrorResponse\n{\n&quot;error&quot;: {\n&quot;code&quot;: &quot;UserError&quot;,\n&quot;message&quot;: &quot;\\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\\n1. You are not authorized to access this resource, or directory listing denied.\\n2. you may not login your azure service, or use other subscription, you can check your\\ndefault account by running azure cli commend:\\n'az account list -o table'.\\n3. You have multiple objects\/login session opened, please close all session and try again.\\n                &quot;\n}\n}<\/p>\n<p>with the following call stack<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/models_client.py in register_model(self, name, tags, properties, description, url, mime_type, framework, framework_version, unpack, experiment_name, run_id, datasets, sample_input_data, sample_output_data, resource_requirements)\n70         return self.<br \/>\n71             _execute_with_workspace_arguments(self._client.ml_models.register, model,\n---&gt; 72                                               custom_headers=ModelsClient.get_modelmanagement_custom_headers())\n73\n74     @error_with_model_id_handling<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/workspace_client.py in _execute_with_workspace_arguments(self, func, *args, **kwargs)\n65\n66     def _execute_with_workspace_arguments(self, func, *args, **kwargs):\n---&gt; 67         return self._execute_with_arguments(func, copy.deepcopy(self._workspace_arguments), *args, **kwargs)\n68\n69     def get_or_create_experiment(self, experiment_name, is_async=False):<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)\n536                 return self._call_paginated_api(func, *args_list, **kwargs)\n537             else:\n--&gt; 538                 return self._call_api(func, *args_list, **kwargs)\n539         except ErrorResponseException as e:\n540             raise ServiceException(e)<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, *args, **kwargs)\n234                 return AsyncTask(future, _ident=ident, _parent_logger=self._logger)\n235             else:\n--&gt; 236                 return self._execute_with_base_arguments(func, *args, **kwargs)\n237\n238     def _call_paginated_api(self, func, *args, **kwargs):<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, *args, **kwargs)\n323         total_retry = 0 if self.retries &lt; 0 else self.retries\n324         return ClientBase._execute_func_internal(\n--&gt; 325             back_off, total_retry, self._logger, func, _noop_reset, *args, **kwargs)\n326\n327     @classmethod<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n343                 return func(*args, **kwargs)\n344             except Exception as error:\n--&gt; 345                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n346\n347             reset_func(*args, **kwargs)  # reset_func is expected to undo any side effects from a failed func call.<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n384 3. You have multiple objects\/login session opened, please close all session and try again.\n385                 &quot;&quot;&quot;\n--&gt; 386                 raise_from(UserErrorException(error_msg), error)\n387\n388             elif error.response.status_code == 429:<\/p>\n<p>\/databricks\/python\/lib\/python3.7\/site-packages\/six.py in raise_from(value, from_value)<\/p>\n<p>Did anybody experience the same error and knows what is its cause and how to solve it?<\/p>\n<p>Best,\nJonas<\/p>\n<p>UPDATE:<\/p>\n<pre><code> model = sklearn.linear_model.LinearRegression ( )\n model_path = &quot;&lt;path to 'model.pkl' in my blob storage&gt;&quot;\n joblib.dump(model, model_path)\n aml_run = azureml.core.get_context ( )\n aml_run.upload_file (name = &quot;model.pkl&quot;, path_or_stream = model_path)\n # Until this point, everything works fine\n    \n aml_run.register_model (model_name = &quot;model.pkl&quot;)\n # This throws the posted &quot;Forbidden&quot;-Error\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-11-13 10:58:44.633 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure-databricks|azure-machine-learning-studio",
        "Question_view_count":620,
        "Owner_creation_date":"2020-07-16 05:39:33.727 UTC",
        "Owner_last_access_date":"2022-01-24 09:55:29.407 UTC",
        "Owner_location":"Germany",
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-11-16 07:57:08.203 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Label encoding in Azure Machine Learning Studio",
        "Question_body":"<p>I'm trying to find the equivalent of the sklearn <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html\" rel=\"nofollow noreferrer\">LabelEncoder<\/a> or the <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder\" rel=\"nofollow noreferrer\">OrdinalEncoder<\/a> in Azure ML Studio. I understand the Convert to Indicator Values module performs One-hot encoding but I can't find anything that would do label encoding. <\/p>\n\n<p>What I have is a column with six unique string values and what I need is to represent that data with integers from 0 to 6.<\/p>\n\n<p>Right now, I'm using the Execute Python Script module to do it but I was wondering if there's a built-in module to do it.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-05-10 11:00:34.313 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":786,
        "Owner_creation_date":"2015-12-16 10:02:46.773 UTC",
        "Owner_last_access_date":"2022-09-23 17:46:43.357 UTC",
        "Owner_location":null,
        "Owner_reputation":1587,
        "Owner_up_votes":123,
        "Owner_down_votes":8,
        "Owner_views":540,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning execute R script - Could not find function \"rowid\" error",
        "Question_body":"<p>I am trying to run R script in <strong>Azure ML studio<\/strong> that transposes\/reshapes the dataframe from long to wide format (<a href=\"https:\/\/stackoverflow.com\/questions\/11322801\/transpose-reshape-dataframe-without-timevar-from-long-to-wide-format\">example<\/a>). My script runs very fine in Rstudio. But the same does not run in Azure ML studio and throws the following error - could not find function &quot;rowid&quot;. It would be great to know how can I get rid of this and what exactly is causing this error despite it being good enough to run neatly in Rstudio.<\/p>\n<pre><code>#Error: Error 0063: The following error occurred during evaluation of R script:\n# ---------- Start of error message from R ----------\n      could not find function &quot;rowid&quot;\n# ----------- End of error message from R -----------\n<\/code><\/pre>\n<p>I've tried the code in both R versions <em>CRAN R 3.1.0<\/em> &amp; <em>Microsoft R open 3.2.2<\/em>.\nThank you very much in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_date":"2017-12-12 17:13:52.883 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"r|dplyr|data.table|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":803,
        "Owner_creation_date":"2017-08-23 11:09:17.67 UTC",
        "Owner_last_access_date":"2022-09-23 12:22:16.48 UTC",
        "Owner_location":null,
        "Owner_reputation":533,
        "Owner_up_votes":119,
        "Owner_down_votes":6,
        "Owner_views":163,
        "Answer_body":"<p>Hi I had the same problem 2 days ago with the function <code>pull()<\/code>, always of the package <code>dplyr<\/code>.\nThe problem is that the both version of R (CRAN R 3.1.0 and Microsoft R open 3.2.2) supported by Azure Machine Learning Studio, does not support the version <code>0.7.4<\/code> of package <code>dplyr<\/code>.\nIf you read the <a href=\"https:\/\/cran.r-project.org\/web\/packages\/dplyr\/dplyr.pdf\" rel=\"nofollow noreferrer\">documentation<\/a> related to the package <code>dplyr<\/code> you can see that the package is installable only for R versions >= 3.1.2.<\/p>\n\n<p>Then you must wait for the R version used by Azure Machine Learning Studio be updated, or find an alternative solution to your function.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-12-22 17:07:27.063 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2021-02-04 20:44:47.53 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Sales prediction in Azure ML",
        "Question_body":"<p>I am very new to Azure Machine Learning things, one of our client use to sell some fresh products to business people. They have a 'suggested buy' system, a feature will suggest some quantities to buy based on customer's sales history.<\/p>\n\n<p>After client came to know about Microsoft's Azure ML, they want to use that prediction system to suggest quantities to customers.<\/p>\n\n<p>We have sales data with these columns,<\/p>\n\n<ul>\n<li>CustomerName <\/li>\n<li>ItemName <\/li>\n<li>OrderDate <\/li>\n<li>QuantityPurchased <\/li>\n<li>QuantitySold<\/li>\n<\/ul>\n\n<p>We would like customers have suggested quantity should come from Azure ML using the Sales Data.<\/p>\n\n<p>Can some one please suggest me how can I do this?<\/p>\n\n<p>Thanks much in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2016-04-11 11:33:27.933 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"azure|prediction|azure-machine-learning-studio",
        "Question_view_count":2649,
        "Owner_creation_date":"2014-08-25 04:55:03.18 UTC",
        "Owner_last_access_date":"2021-06-03 01:18:34.777 UTC",
        "Owner_location":"Online",
        "Owner_reputation":722,
        "Owner_up_votes":35,
        "Owner_down_votes":5,
        "Owner_views":178,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to split Azure ML pipeline steps to debug",
        "Question_body":"<p>I have created an Azure ML pipeline with different steps (data preprocess, train, validation ...). And for pass data from one step to the next I have used the PipelineData object.<\/p>\n<p><em>Example passing the model from train step to validate one:<\/em><\/p>\n<pre><code>    # Create a PipelineData to pass model from train to register\n    model_path = PipelineData('model')\n\n    # Step 2\n    train_step = PythonScriptStep(\n        name = 'Train the Model',\n        script_name = 'TrainStepScript.py',\n        source_directory = source_folder,\n        arguments = ['--training_data', prepped_data,\n                     '--model_name', model_name,\n                     '--model_path', model_path],\n        outputs = [model_path],\n        compute_target = compute_target,\n        runconfig = aml_run_config,\n        allow_reuse = True\n    )\n\n    # Step 3\n    third_step = PythonScriptStep(\n        name = 'Evaluate &amp; register the Model',\n        script_name = 'ValidateStepScript.py',\n        source_directory = source_folder,\n        arguments = ['--model_name', model_name,\n                     '--model_path', model_path],\n        inputs = [model_path],\n        compute_target = compute_target,\n        runconfig = aml_run_config,\n        allow_reuse = True\n    )\n<\/code><\/pre>\n<p>Now for debugging and development purposes I want to create a script to run separately the different steps using a ScriptRunConfig (with the same environment and arguments of the StepScript in the pipeline). But the problem is I don't know how to simulate the data input\/output of each step, because the DataPipeline object is not working for this purpose.<\/p>\n<p>Just for clarification, my goal is to NOT modify the original pipeline StepScripts, so I can use them after debugging in the final pipeline. To sum up, my question is: how can I emulate the DataPipeline object (if possible) in this case?<\/p>\n<p><em>Example of what I'm trying to build:<\/em><\/p>\n<pre><code># Passing in some way the model path (from local)\nmodel_path = PipelineData('model')\n\n# Create a script config for validate step\nvalidate_script_config = ScriptRunConfig(\n    source_directory = source_folder,\n    script = 'ValidateStepScript.py',\n    arguments = ['--model_name', model_name,\n                 '--model_path', model_path],\n    environment = experiment_env,\n    docker_runtime_config = DockerConfiguration(use_docker=True)\n)\n\nexperiment = Experiment(workspace=ws, name=experiment_name)\ndata_run = experiment.submit(config=data_script_config)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-13 12:23:49.967 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":41,
        "Owner_creation_date":"2022-08-31 10:33:38.833 UTC",
        "Owner_last_access_date":"2022-09-23 10:52:24.05 UTC",
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":"<p>We can download the output of the model in a repository and make them as the source file for the later steps as required. The below code block can be incorporated in the same pipeline which is being used now.<\/p>\n<p>To download the model output:<\/p>\n<pre><code>train_step = pipeline_run1.find_step_run('train.py')\n\nif train_step:\n    train_step_obj = train_step[0] \n    train_step_obj.get_output_data('processed_data1').download(&quot;.\/outputs&quot;) # download the output to current directory\n<\/code><\/pre>\n<p>after downloading the model, then use that as the parent source directory in source_directory<\/p>\n<pre><code>from azureml.core import ScriptRunConfig, Experiment\n   # create or load an experiment\n   experiment = Experiment(workspace, 'MyExperiment')\n   # create or retrieve a compute target\n   cluster = workspace.compute_targets['MyCluster']\n   # create or retrieve an environment\n   env = Environment.get(ws, name='MyEnvironment')\n   # configure and submit your training run\n   config = ScriptRunConfig(source_directory='.',\n                            command=['python', 'train.py'],\n                            compute_target=cluster,\n                            environment=env)\n   script_run = experiment.submit(config)\n<\/code><\/pre>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2022-09-14 11:50:02.29 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How do I use Service Principal authentication with an Azure Machine Learning Pipeline Endpoint in C#?",
        "Question_body":"<p>I'm trying to call an Azure Machine Learning Pipeline Endpoint I've set up using C# &amp; the Machine Learning REST api.<\/p>\n<p>I am certain that I have the Service Principal configured correctly, as I can successfully authenticate &amp; hit the endpoint using the <code>azureml-core<\/code> python sdk:<\/p>\n<pre><code>sp = ServicePrincipalAuthentication(\n    tenant_id=tenant_id,\n    service_principal_id=service_principal_id,\n    service_principal_password=service_principal_password)\nws =Workspace.get(\n    name=workspace_name, \n    resource_group=resource_group, \n    subscription_id=subscription_id, \n    auth=sp)\n\nendpoint = PipelineEndpoint.get(ws, name='MyEndpoint')\nendpoint.submit('Test_Experiment')\n<\/code><\/pre>\n<p>I'm using the following example in C# to attempt to run my endpoint: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-pipelines#run-a-published-pipeline-using-c\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-pipelines#run-a-published-pipeline-using-c<\/a><\/p>\n<p>I'm attempting to fill <code>auth_key<\/code> with the following code:<\/p>\n<pre><code>var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\nvar clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\nvar tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\nvar cred = new ClientSecretCredential(tenantId, clientId, clientSecret);\nvar auth_key = cred.GetToken(new Azure.Core.TokenRequestContext(new string[] {&quot;.default&quot; }));\n<\/code><\/pre>\n<p>I receive a 401 (unauthorized).<\/p>\n<p>What am I am doing wrong?<\/p>\n<ul>\n<li>UPDATE *<\/li>\n<\/ul>\n<p>I changed the 'scopes' param in the <code>TokenRequestContext<\/code> to look like:<\/p>\n<pre><code>var auth_key = cred.GetToken(new Azure.Core.TokenRequestContext(new string[] { &quot;http:\/\/DataTriggerApp\/.default&quot; }));\n<\/code><\/pre>\n<p><code>http:\/\/DataTriggerApp<\/code> is one of the <code>servicePrincipalNames<\/code> that shows up when i query my Service Principal from the azure CLI.<\/p>\n<p>Now, when I attempt to use the returned token to call the Machine Learning Pipeline Endpoint, I receive a 403 instead of a 401.  Maybe some progress?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-13 19:37:07.71 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"c#|azure|asp.net-core-3.1|azure-machine-learning-service|azure-service-principal",
        "Question_view_count":752,
        "Owner_creation_date":"2012-06-27 21:51:16.13 UTC",
        "Owner_last_access_date":"2022-09-21 21:19:20.11 UTC",
        "Owner_location":null,
        "Owner_reputation":751,
        "Owner_up_votes":68,
        "Owner_down_votes":5,
        "Owner_views":73,
        "Answer_body":"<p>Ok, through a lot of trial-and-error I was able to come up with two ways of acquiring a token that allows me to hit my Azure Machine Learning Pipeline Endpoint through the REST api.  One uses Microsoft.Identity.Client &amp; one uses Azure.Identity.<\/p>\n<pre><code>using Microsoft.Identity.Client;\n\n...\n\npublic static async Task&lt;string&gt; GetAccessToken()\n{\n      var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\n      var clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\n      var tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\n   \n      var app = ConfidentialClientApplicationBuilder.Create(clientId)\n                                                .WithClientSecret(clientSecret)                                                \n                                                .WithAuthority(AzureCloudInstance.AzurePublic, tenantId)\n                                                .Build();\n      var result = await app.AcquireTokenForClient(new string[] { &quot;https:\/\/ml.azure.com\/.default&quot; }).ExecuteAsync();\n      return result.AccessToken;\n}\n<\/code><\/pre>\n<p>Or:<\/p>\n<pre><code>using Azure.Identity;\n...\n\npublic static async Task&lt;string&gt; GetAccessToken()\n{\n      var clientId = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_ID&quot;);\n      var clientSecret = Environment.GetEnvironmentVariable(&quot;AZURE_CLIENT_SECRET&quot;);\n      var tenantId = Environment.GetEnvironmentVariable(&quot;AZURE_TENANT_ID&quot;);\n\n\n      var cred = new ClientSecretCredential(tenantId, clientId, clientSecret);\n      var token =  await cred.GetTokenAsync(new Azure.Core.TokenRequestContext(new string[] { &quot;https:\/\/ml.azure.com\/.default&quot; }));\n      return token.Token;\n}\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-13 21:20:31.173 UTC",
        "Answer_last_edit_date":"2021-10-13 21:27:39.93 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":"2021-10-13 20:21:13.113 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Register model from Azure Machine Learning run without downloading to local file",
        "Question_body":"<p>A model was trained on a remote compute using azureml.core Experiment as follows:<\/p>\n<pre><code>experiment = Experiment(ws, name=experiment_name)\nsrc = ScriptRunConfig(&lt;...&gt;)\nrun = experiment.submit(src)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>How can a model trained in this run be registered with Azure Machine Learning workspace without being downloaded to a local file first?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-02 18:41:36.993 UTC",
        "Question_favorite_count":1.0,
        "Question_score":4,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1141,
        "Owner_creation_date":"2020-12-02 18:29:10.397 UTC",
        "Owner_last_access_date":"2021-05-18 19:31:00.157 UTC",
        "Owner_location":"Bellevue, WA, USA",
        "Owner_reputation":81,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Using `inference_schema.schema_decorators` with dynamic `numpy` array shape",
        "Question_body":"<p><strong>Question summary<\/strong><\/p>\n\n<p>I'm deploying a model to an Azure Container Instance, using the Azure Machine Learning Service API. Specifically, the model is a PyTorch (fastai) model classifying images of varying shapes.<\/p>\n\n<p>Microsoft provides some nice decoraters to handle input and output data schemas in the scoring script. However, I am unable to figure out, if it's possible to use the <code>NumpyParameterType<\/code> with dynamic shape for the input.<\/p>\n\n<p><strong>Scoring script<\/strong><\/p>\n\n<p>A sample of the scoring script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pickle\nimport json\nimport numpy as np\nimport time\nimport os\n\nfrom PIL import Image as PilImage\nfrom azureml.core.model import Model\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\ndef preprocess_inference(img):\n    # Preprocessing handled here\n\ndef make_prediction(data_preprocessed):\n    # Model prediction handled here\n\ndef init():\n    global model\n\n    model_path = Model.get_model_path(model_name='my_pytorch_model',\n                                      version=1)\n\n    # Get paths\n    split_path = model_path.split('\/')\n\n    model = fastai.load_learner(path = '\/'.join(split_path[:-1]), file = split_path[-1])\n\n# How to use the schema decoraters with dynamic size?\ninput_sample = np.array(PilImage.open('src\/deployment\/test\/test_image.png'))\noutput_sample = np.array([0, None], dtype=np.object)\n\n@input_schema('raw_data', NumpyParameterType(input_sample))\n@output_schema(NumpyParameterType(output_sample))\ndef run(raw_data):\n\n    try:\n\n        data_preprocessed = preprocess_inference(raw_data)\n\n        prediction = make_prediction(data_preprocessed)\n\n        return prediction\n\n    except Exception as e:\n        error = str(e)\n        print (error + time.strftime(\"%H:%M:%S\"))\n        return error\n\n<\/code><\/pre>\n\n<p>Which only works if the image uploaded has the exact same shape as 'src\/deployment\/test\/test_image.png'. Right now my solution is to avoid the decoraters and do the data interpretation myself.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>\ndef run(raw_data):\n\n    try:\n\n        img = np.array(json.loads(raw_data)['raw_data'], dtype=np.uint8)\n        img = np.expand_dims(img, axis=2)\n\n        data_preprocessed = preprocess_inference(img)\n\n        prediction = make_prediction(data_preprocessed)\n\n        return prediction\n\n    except Exception as e:\n        error = str(e)\n        print (error + time.strftime(\"%H:%M:%S\"))\n        return error\n\n<\/code><\/pre>\n\n<p>But it would be nice to be able to use the decorators, such that endusers can benefit from the nice warning messages as well.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-02 14:11:24.313 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":971,
        "Owner_creation_date":"2013-08-22 07:20:04.257 UTC",
        "Owner_last_access_date":"2019-10-15 07:09:47.553 UTC",
        "Owner_location":null,
        "Owner_reputation":26,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to delete an experiment from an azure machine learning workspace",
        "Question_body":"<p>I create experiments in my workspace using the python sdk (azureml-sdk). I now have a lot of 'test' experiments littering our workspace. How can I delete individual experiments either through the api or on the portal. I know I can delete the whole workspace but there are some good experiments we don't want to delete<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-export-delete-data#delete-visual-interface-assets\" rel=\"noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-export-delete-data#delete-visual-interface-assets<\/a> suggests it is possible but my workspace view does not look anything like what is shown there<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-14 15:02:15.187 UTC",
        "Question_favorite_count":3.0,
        "Question_score":9,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":3890,
        "Owner_creation_date":"2019-08-14 14:48:38.45 UTC",
        "Owner_last_access_date":"2022-09-25 02:16:40.673 UTC",
        "Owner_location":null,
        "Owner_reputation":113,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Parallelization issue with Azure Machine Learning Studio",
        "Question_body":"<p>I have a web service published through azure ML studio written in R.\nI call this web service from a C# web api endpoint passing the content of a CosmosDb document.<\/p>\n\n<p>When I call the Azure ML 100 times sequentially using the same document, I always got the same result (0.07152444869) which is the desired result. This is also the result I get when I import 100 documents from CosmosDb in Azure ML studio and run the code.<\/p>\n\n<p>When I store 100 jobs in Hangfire, the calls are sent in parallel and the Azure ML webservice responds with two different results (0.04541421681 or 0.07152444869) randomly.<\/p>\n\n<p>The Azure ML webservice is hosted in the West Europe region.\nSince I cannot debug the azure ML webservice, I don't know how to fix this issue. Any tip ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2018-10-16 06:45:10.787 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":39,
        "Owner_creation_date":"2014-05-17 09:03:30.913 UTC",
        "Owner_last_access_date":"2022-09-22 06:52:07.417 UTC",
        "Owner_location":"Paris, France",
        "Owner_reputation":2540,
        "Owner_up_votes":875,
        "Owner_down_votes":2,
        "Owner_views":303,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Web Service request not working in C#",
        "Question_body":"<p>I have created an Azure ML Web service which outputs JSON response on request, and the structure of the sample request is as following:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"gender\",\n        \"age\",\n        \"income\"\n      ],\n      \"Values\": [\n        [\n          \"value\",\n          \"0\",\n          \"0\"\n        ],\n        [\n          \"value\",\n          \"0\",\n          \"0\"\n        ]\n      ]\n    }\n  },\n  \"GlobalParameters\": {}\n}\n<\/code><\/pre>\n\n<p>And the input parameters are supposedly like this:<\/p>\n\n<p>gender  String<br>\nage Numeric<br>\nincome  Numeric     <\/p>\n\n<p>My Post method looks like this:<\/p>\n\n<pre><code>    [HttpPost]\n        public ActionResult GetPredictionFromWebService()\n        {\n            var gender = Request.Form[\"gender\"];\n            var age = Request.Form[\"age\"];\n\n\n            if (!string.IsNullOrEmpty(gender) &amp;&amp; !string.IsNullOrEmpty(age))\n            {\n                var resultResponse = _incomeWebService.InvokeRequestResponseService&lt;ResultOutcome&gt;(gender, age).Result;\n\n\n                if (resultResponse != null)\n                {\n                    var result = resultResponse.Results.Output1.Value.Values;\n                    PersonResult = new Person\n                    {\n                        Gender = result[0, 0],\n                        Age = Int32.Parse(result[0, 1]),\n                        Income = Int32.Parse(result[0, 2])\n                    };\n                }\n            }\n\n\n\n\n            return RedirectToAction(\"index\");\n        }\n<\/code><\/pre>\n\n<p>But for whatever reason; the Azure ML Webservice doesn\u2019t seem to respond anything to my request.\nDoes anyone know what the reason might be? I see no error or anything, just an empty response.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-02-24 11:28:13.347 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"c#|asp.net|azure|azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":480,
        "Owner_creation_date":"2016-02-24 10:28:58.853 UTC",
        "Owner_last_access_date":"2016-08-22 12:20:52.243 UTC",
        "Owner_location":null,
        "Owner_reputation":39,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>The answer to your problem is that the \u201cNumeric\u201d datatype which is written in the input parameters in Azure ML is in fact a float and not an integer for your income measure. So when trying to request a response from Azure ML, you are not providing it the \u201cadequate\u201d information needed in the right format for it to respond correctly, resulting in it not giving you any response.<\/p>\n\n<p>I believe your model would look something similar to this based on your input parameters:<\/p>\n\n<pre><code>public class Person\n    {\n        public string Gender { get; set; }\n        public int Age { get; set; }\n        public int Income { get; set; }\n\n\n        public override string ToString()\n        {\n            return Gender + \",\" + Age + \",\" + Income;\n        }\n    }\n<\/code><\/pre>\n\n<p>You would have to change your Income datatype into float like so:<\/p>\n\n<pre><code>public class Person\n{\n    public string Gender { get; set; }\n    public int Age { get; set; }\n    public float Income { get; set; }\n\n    public override string ToString()\n    {\n        return Gender + \",\" + Age + \",\" + Income;\n    }\n}\n<\/code><\/pre>\n\n<p>And then your post-method would look something like this:<\/p>\n\n<pre><code>    [HttpPost]\n    public ActionResult GetPredictionFromWebService()\n    {\n        var gender = Request.Form[\"gender\"];\n        var age = Request.Form[\"age\"];\n\n        if (!string.IsNullOrEmpty(gender) &amp;&amp; !string.IsNullOrEmpty(age))\n        {\n            var resultResponse = _incomeWebService.InvokeRequestResponseService&lt;ResultOutcome&gt;(gender, age).Result;\n\n                if (resultResponse != null)\n                {\n                    var result = resultResponse.Results.Output1.Value.Values;\n                    PersonResult = new Person\n                    {\n                        Gender = result[0, 0],\n                        Age = Int32.Parse(result[0, 1]),\n                        Income = float.Parse(result[0, 3], CultureInfo.InvariantCulture.NumberFormat)\n                };\n            }\n        }\n\n        ViewBag.myData = PersonResult.Income.ToString();\n        return View(\"Index\");\n    }\n<\/code><\/pre>\n\n<p>The key here is simply:<\/p>\n\n<pre><code>Income = float.Parse(result[0, 3], CultureInfo.InvariantCulture.NumberFormat)\n<\/code><\/pre>\n\n<p>Rather than your legacy <\/p>\n\n<pre><code>Income = Int32.Parse(result[0, 2])\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-02-24 11:42:31.45 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2016-03-01 13:45:08.307 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to load an external pickle file contents as a data frame in azure ml studio in the 'execute python script' section?",
        "Question_body":"<p>This is script which I am using:<\/p>\n\n<pre><code> import warnings\n warnings.filterwarnings('ignore') \n import pandas as pd\n import sys\n import pickle\n def azureml_main(dataframe1 = None, dataframe2 = None):\n sys.path.append('.\\\\Script Bundle')\n dataframe1 = pickle.load(open(r'\/Script Bundle\/descript.pkl', 'rb'))\n return dataframe1,\n<\/code><\/pre>\n\n<p>but when I execute it , getting below error <\/p>\n\n<pre><code> FileNotFoundError: [Errno 2] No such file or directory: '\/Script \n Bundle\/descript.pkl'\n Process returned with non-zero exit code 1\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-03-08 10:03:59.273 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":1085,
        "Owner_creation_date":"2019-02-11 11:39:40.047 UTC",
        "Owner_last_access_date":"2020-01-02 09:14:20.78 UTC",
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-03-08 13:12:33.543 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML PipelineData with DataTransferStep results in 0 bytes file",
        "Question_body":"<p>I am building an Azure ML pipeline with the azureml Python SDK. The pipeline calls a PythonScriptStep which stores data on the workspaceblobstore of the AML workspace. <\/p>\n\n<p>I would like to extend the pipeline to export the pipeline data to an Azure Data Lake (Gen 1). Connecting the output of the PythonScriptStep directly to Azure Data Lake (Gen 1) is not supported by Azure ML as far as I understand. Therefore, I added an extra DataTransferStep to the pipeline, which takes the output from the PythonScriptStep as input directly into the DataTransferStep. According to the Microsoft documentation this should be possible.<\/p>\n\n<p>So far I have built this solution, only this results in a file of 0 bytes on the Gen 1 Data Lake. I think the output_export_blob PipelineData does not correctly references the test.csv, and therefore the DataTransferStep cannot find the input. How can I connect the DataTransferStep correctly with the PipelineData output from the PythonScriptStep?<\/p>\n\n<p>Example I followed:\n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-with-data-dependency-steps.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-with-data-dependency-steps.ipynb<\/a><\/p>\n\n<p>pipeline.py<\/p>\n\n<pre><code>input_dataset = delimited_dataset(\n    datastore=prdadls_datastore,\n    folderpath=FOLDER_PATH_INPUT,\n    filepath=INPUT_PATH\n)\n\noutput_export_blob = PipelineData(\n    'export_blob',\n    datastore=workspaceblobstore_datastore,\n)\n\ntest_step = PythonScriptStep(\n    script_name=\"test_upload_stackoverflow.py\",\n    arguments=[\n        \"--output_extract\", output_export_blob,\n    ],\n    inputs=[\n        input_dataset.as_named_input('input'),\n    ],\n    outputs=[output_export_blob],\n    compute_target=aml_compute,\n    source_directory=\".\"\n)\n\noutput_export_adls = DataReference(\n    datastore=prdadls_datastore, \n    path_on_datastore=os.path.join(FOLDER_PATH_OUTPUT, 'test.csv'),\n    data_reference_name='export_adls'        \n)\n\nexport_to_adls = DataTransferStep(\n    name='export_output_to_adls',\n    source_data_reference=output_export_blob,\n    source_reference_type='file',\n    destination_data_reference=output_export_adls,\n    compute_target=adf_compute\n)\n\npipeline = Pipeline(\n    workspace=aml_workspace, \n    steps=[\n        test_step, \n        export_to_adls\n    ]\n)\n<\/code><\/pre>\n\n<p>test_upload_stackoverflow.py<\/p>\n\n<pre><code>import os\nimport pathlib\nfrom azureml.core import Datastore, Run\n\nparser = argparse.ArgumentParser(\"train\")\nparser.add_argument(\"--output_extract\", type=str)\nargs = parser.parse_args() \n\nrun = Run.get_context()\ndf_data_all = (\n    run\n    .input_datasets[\"input\"]\n    .to_pandas_dataframe()\n)\n\nos.makedirs(args.output_extract, exist_ok=True)\ndf_data_all.to_csv(\n    os.path.join(args.output_extract, \"test.csv\"), \n    index=False\n)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-10 17:54:20.073 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":917,
        "Owner_creation_date":"2017-10-30 18:18:09.89 UTC",
        "Owner_last_access_date":"2022-09-08 06:29:56.133 UTC",
        "Owner_location":null,
        "Owner_reputation":73,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":"<p>The code example is immensely helpful. Thanks for that. You're right that it can be confusing to get <code>PythonScriptStep -&gt; PipelineData<\/code>. Working initially even without the <code>DataTransferStep<\/code>.<\/p>\n\n<p>I don't know 100% what's going on, but I thought I'd spitball some ideas:<\/p>\n\n<ol>\n<li>Does your <code>PipelineData<\/code>,  <code>export_blob<\/code>, contain the \"test.csv\" file? I would verify that before troubleshooting the <code>DataTransferStep<\/code>. You can verify this using the SDK, or more easily with the UI.\n\n<ol>\n<li>Go to the PipelineRun page, click on the <code>PythonScriptStep<\/code> in question.<\/li>\n<li>On \"Outputs + Logs\" page, there's a \"Data Outputs\" Section (that is slow to load initially)<\/li>\n<li>Open it and you'll see the output PipelineDatas then click on \"View Output\"<\/li>\n<li>Navigate to given path either in the Azure Portal or Azure Storage Explorer.\n<a href=\"https:\/\/i.stack.imgur.com\/9LaEq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9LaEq.png\" alt=\"enter image description here\"><\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/XbnhC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XbnhC.png\" alt=\"enter image description here\"><\/a><\/li>\n<\/ol><\/li>\n<li>In <code>test_upload_stackoverflow.py<\/code> you are treating the <code>PipelineData<\/code> as a directory when call <code>.to_csv()<\/code> as opposed to a file which would be you just calling <code>df_data_all.to_csv(args.output_extract, index=False)<\/code>. Perhaps try defining the <code>PipelineData<\/code> with <code>is_directory=True<\/code>. Not sure if this is required though.<\/li>\n<\/ol>",
        "Answer_comment_count":7.0,
        "Answer_creation_date":"2020-06-10 18:21:40.647 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2020-06-10 18:10:59.793 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"MLPClassifier in Azure ML webservice call",
        "Question_body":"<p>I have a model using MLPClassifier from scikitlearn. I pkl, zip it and uploaded to Azure ML. The process works fine with no errors when I run it, but once I call it from a WebService I get the following error. I also added the scikit learn files to the model so I can use MLPClassifier.<\/p>\n\n<pre><code>$ \"C:\\pyhome\\lib\\pickle.py\", line 1384, in find_class __import__(module, level=0) ImportError: No module named 'sklearn.neural_network.multilayer_perceptron' $\n<\/code><\/pre>\n\n<p>\u00a0\nThis is my python code in Azure ML<\/p>\n\n<pre><code>$ import sys\nsys.path.insert(0, \".\\\\Script Bundle\")\u00a0\u00a0\u00a0 \nimport os\nos.environ['PATH'] = os.path.dirname(\".\\\\Script Bundle\\\\DLLs\\\\\")+ ';' + os.environ['PATH']\nimport pandas as pd\nimport sklearn as sk\nfrom sklearn.externals import joblib\n#from sklearn.neural_network import MLPClassifier\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n\u00a0\u00a0\u00a0 \n\u00a0\u00a0\u00a0 #print (\"sklearn version :\", sk.__version__)\n\u00a0\u00a0\u00a0 model = joblib.load('.\/Script Bundle\/RNNmodel.pkl')\n\u00a0\u00a0\u00a0 y_train = model.predict(dataframe1)\n\u00a0\u00a0\u00a0 dataframe1 = pd.DataFrame(y_train)\n\u00a0\u00a0\u00a0 return dataframe1,\n$\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2017-05-16 20:55:33.857 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":161,
        "Owner_creation_date":"2011-08-04 21:03:32.233 UTC",
        "Owner_last_access_date":"2017-11-05 21:29:50.297 UTC",
        "Owner_location":"Vancouver, BC, Canada",
        "Owner_reputation":43,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Cannot access registered dataset in AMLS pipeline",
        "Question_body":"<p>I have a service principal for my AMLS workspace that has been granted a storage blob contributor role to ADLS Gen 2. ADLS Gen 2 is behind a vnet, but using the service principal, I was able to register it as a datastore and register a csv file in ADLS Gen 2 as a dataset in my AMLS workspace. I am using azureml.core version 1.16.0<\/p>\n<p>Within my workspace, running<\/p>\n<pre><code>data = ws.datasets.get(&quot;csv data&quot;)\ndata.take(5).to_pandas_dataframe()\n<\/code><\/pre>\n<p>works with no issue. I would like to use this csv data as input into an ML pipeline run with a PythonScriptStep with inputs = [data.as_named_input('data')] after running data = ws.datasets.get(&quot;csv data&quot;). However, when I run the code<\/p>\n<pre><code>run = Run.get_context()\nrun.input_datasets['data'].to_pandas_dataframe()\n<\/code><\/pre>\n<p>in my pipeline script, it fails with an error<\/p>\n<pre><code>StreamAccessException was caused by AuthenticationException.\n'AdlsGen2-ReadHeaders' for '[REDACTED]' on storage failed with status code 'Forbidden' (This request is\nnot authorized to perform this operation.)\n<\/code><\/pre>\n<p>Where am I going wrong?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2020-11-04 00:54:59.12 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|vnet",
        "Question_view_count":185,
        "Owner_creation_date":"2020-05-17 18:00:51.347 UTC",
        "Owner_last_access_date":"2022-06-27 19:36:47.687 UTC",
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-11-04 02:04:44.397 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"'MSSQL' encountered unexpected exception of type 'InvalidOperationException' with HResult 'x80131509' while opening connection",
        "Question_body":"<p>When I am trying to load a query into a tabular dateset (from a devops docker image) I will get the following error:<\/p>\n<pre><code>raise DatasetValidationError(error_message + '\\n' + str(e), e)\nazureml.data.dataset_error_handling.DatasetValidationError: Cannot load any data from the datastore using the SQL query &quot;&lt;azureml.data.datapath.DataPath object at 0x&gt;&quot;. Please make sure the datastore and query is correct.\n\nError Code: ScriptExecution.DatabaseConnection.Unexpected\nFailed Step: 9ad57100-4870-49d2-a32f-1c9c15c244e0\nError Message: ScriptExecutionException was caused by DatabaseConnectionException.\n  DatabaseConnectionException was caused by UnexpectedException.\n    'MSSQL' encountered unexpected exception of type 'InvalidOperationException' with HResult 'x80131509' while opening connection.\n      Internal connection fatal error.\n<\/code><\/pre>\n<p>I believe that I have allowed the connection in firewall (I might not have done it quite right).<\/p>\n<p>I don't get the error when I am running it from the notebook (on the compute instance).<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-18 05:42:27.383 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":156,
        "Owner_creation_date":"2020-08-18 02:37:03.227 UTC",
        "Owner_last_access_date":"2021-09-26 10:54:30.93 UTC",
        "Owner_location":null,
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Download a trained ML Model from Azure ML studio to deploy on a standalone computer",
        "Question_body":"<p>I have setup a ML model in Azure ML <strong>studio<\/strong> and I am able to use the ML Studio's Web API to obtain predictions.<\/p>\n<p>The key challenge with keeping the model hosted within Azure ML Studio is client computer's internet dependency and latency associated with each prediction.<\/p>\n<p>I wanted to understand if there was any way to download a model created in Azure ML studio and consume it locally(say using a local .Net application).<\/p>\n<p>This question was asked few years <a href=\"https:\/\/stackoverflow.com\/questions\/41236871\/how-to-download-the-trained-models-from-azure-machine-studio\">back<\/a>, some people believed it was possible but without much details.<\/p>\n<p>When a model has been trained, I do see the option of 'Save as Trained Model' as shown in the snapshot but I am not sure how this could eventually be downloaded to a local computer and consumed locally\n<a href=\"https:\/\/i.stack.imgur.com\/LgqRC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LgqRC.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Looking forward to hearing potential solutions.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-24 06:08:01.623 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":639,
        "Owner_creation_date":"2018-07-06 13:16:27.36 UTC",
        "Owner_last_access_date":"2022-09-14 06:40:15.18 UTC",
        "Owner_location":"Dubai - United Arab Emirates",
        "Owner_reputation":233,
        "Owner_up_votes":48,
        "Owner_down_votes":3,
        "Owner_views":46,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML: Getting Error 503: NoMoreResources to any web service API even when I only make 1 request",
        "Question_body":"<p>Getting the following response even when I make one request (concurrency set to 200) to a web service. <\/p>\n\n<p>{ status: 503, headers: '{\"content-length\":\"174\",\"content-type\":\"application\/json; charset=utf-8\",\"etag\":\"\\\"8ce068bf420a485c8096065ea3e4f436\\\"\",\"server\":\"Microsoft-HTTPAPI\/2.0\",\"x-ms-request-id\":\"d5c56cdd-644f-48ba-ba2b-6eb444975e4c\",\"date\":\"Mon, 15 Feb 2016 04:54:01 GMT\",\"connection\":\"close\"}',  body: '{\"error\":{\"code\":\"ServiceUnavailable\",\"message\":\"Service is temporarily unavailable.\",\"details\":[{\"code\":\"NoMoreResources\",\"message\":\"No resources available for request.\"}]}}' }<\/p>\n\n<p>The request-response web service is a recommender retraining web service with the training set containing close to 200k records. The training set is already present in my ML studio dataset, only 10-15 extra records are passed in the request. The same experiment was working flawlessly till 13th Feb 2016. I have already tried increasing the concurrency but still the same issue. I even reduced the size of the training set to 20 records, still didn't work.<\/p>\n\n<p>I have two web service both doing something similar and both aren't working since 13th Feb 2016. <\/p>\n\n<p>Finally, I created a really small experiment ( skill.csv --> split row ---> web output )   which doesn't take any input. It just has to return some part of the dataset. Did not work, response code 503.<\/p>\n\n<p>The logs I got are as follows<\/p>\n\n<p>{\n  \"version\": \"2014-10-01\",\n  \"diagnostics\": [{\n    .....\n    {\n      \"type\": \"GetResourceEndEvent\",\n      \"timestamp\": 13.1362,\n      \"resourceId\": \"5e2d653c2b214e4dad2927210af4a436.865467b9e7c5410e9ebe829abd0050cd.v1-default-111\",\n      \"status\": \"Failure\",\n      \"error\": \"The Uri for the target storage location is not specified. Please consider changing the request's location mode.\"\n    },\n    {\n      \"type\": \"InitializationSummary\",\n      \"time\": \"2016-02-15T04:46:18.3651714Z\",\n      \"status\": \"Failure\",\n      \"error\": \"The Uri for the target storage location is not specified. Please consider changing the request's location mode.\"\n    }\n  ]\n}<\/p>\n\n<p>What am I missing? Or am I doing it completely wrong?<\/p>\n\n<p>Thank you in advance.<\/p>\n\n<p>PS: Data is stored in mongoDB and then imported as CSV<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-02-15 14:18:09.5 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":283,
        "Owner_creation_date":"2015-03-08 08:21:30.213 UTC",
        "Owner_last_access_date":"2022-09-02 03:13:25.513 UTC",
        "Owner_location":"Boston, MA, USA",
        "Owner_reputation":41,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":"<p>This was an Azure problem. I quote the Microsoft guy, <\/p>\n\n<blockquote>\n  <p>We believe we have isolated the issue impacting tour service and we are currently working on a fix. We will be able to deploy this in the next couple of days. The problem is impacting only the ASIA AzureML region at this time, so if this is an option for you, might I suggest using a workspace in either the US or EU region until the fix gets rolled out here.<\/p>\n<\/blockquote>\n\n<p>To view the complete discussion, click <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/985e253e-5e54-45a5-a359-5c501152c445\/getting-error-503-nomoreresources-to-any-web-service-api-even-when-i-only-make-1-request?forum=MachineLearning&amp;prof=required\" rel=\"nofollow\">here<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-02-16 04:37:02.633 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2016-03-01 16:33:30.663 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Web service output - Azure ML Studio",
        "Question_body":"<p>I am new to Azure ML Studio. I tried creating an experiment that takes a numeric value as input and a gives a data table type output. I works fine when I run it in the portal , but not when I run it as a web service. It shows a single value numeric output , when it has to be a data table type.<\/p>\n\n<p>Is there a way to change the output type of web service output? <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/oq5Xb.png\" rel=\"nofollow noreferrer\">Visualizing output in portal<\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/wUmN7.png\" rel=\"nofollow noreferrer\">Test RRS output(web service)<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_date":"2017-01-27 22:22:04.117 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":587,
        "Owner_creation_date":"2015-12-03 06:14:28.407 UTC",
        "Owner_last_access_date":"2022-08-09 17:04:50.44 UTC",
        "Owner_location":"East Newark, NJ, United States",
        "Owner_reputation":33,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Answer_body":"<p>Make is a classic web service and see the JSON output getting from it. If it's providing all data you need.. go for it.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-02-02 04:24:46.973 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2017-01-27 23:03:20.66 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Where does Azure Machine Learning Service cache data?",
        "Question_body":"<p>I am looking to use Azure Machine Learning Services (the one with the new drag and drop feature; still in preview) in a new data science project. <\/p>\n\n<p>I have realised that I can preview the data when I connect a data set; I am able to do this using the option 'Dataset output' which is available as part of the dataset.<\/p>\n\n<p>To be able to see this data, the data needs to be cached some where. <\/p>\n\n<p>Can someone advise where this is cached? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-21 01:53:42.01 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service|data-caching",
        "Question_view_count":397,
        "Owner_creation_date":"2016-02-26 11:19:26 UTC",
        "Owner_last_access_date":"2022-09-23 07:19:03.243 UTC",
        "Owner_location":"Canberra, Australian Capital Territory, Australia",
        "Owner_reputation":214,
        "Owner_up_votes":21,
        "Owner_down_votes":2,
        "Owner_views":54,
        "Answer_body":"<p>Data is cached by default in a storage account that is created along with the the ML service workspace. It has the same name as the workspace plus some numbers. Inside the account there is a blobstore called <code>azureml-blobstore-{GUID}<\/code> Inside of that container your data is cached,  organized by runs.<\/p>\n\n<p>This data is made available to ML service as a <code>Datastore<\/code> that you can navigate to in the UI by clicking \"Datastores\" in the blade on the left-hand of the Studio.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YVwPl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YVwPl.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-02-21 03:38:14.053 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":3.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Use Neo4j in Azure Devops or Azure Machine learning",
        "Question_body":"<p>I have a project in python. My goal is to create an article recommendation with Neo4j.<\/p>\n<p>Here is what I did:<\/p>\n<ol>\n<li>Web scraping articles<\/li>\n<li>Clean the data<\/li>\n<li>Insert the data into Neo4j<\/li>\n<li>Use Neo4j algorithms (graph data science library)<\/li>\n<\/ol>\n<p>Everything is working, but only on my laptop.<\/p>\n<p>I would like to migrate my project on Azure devops and azure machine learning in order to have a web app.<\/p>\n<p>I have an Azure account and I have created Azure ML and Azure Devops for this project but I don't know how I can use Neo4j in azure devops and azure machine learning. Maybe with a VM or a container ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2020-09-11 08:30:49.167 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"python|azure|neo4j|azure-machine-learning-service",
        "Question_view_count":206,
        "Owner_creation_date":"2020-05-04 19:50:13.21 UTC",
        "Owner_last_access_date":"2021-11-25 09:41:09.417 UTC",
        "Owner_location":null,
        "Owner_reputation":197,
        "Owner_up_votes":34,
        "Owner_down_votes":0,
        "Owner_views":82,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-09-14 08:22:04.443 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Run failed: User program failed with ModuleNotFoundError: No module named 'amlrun' in Azure ML Experiment",
        "Question_body":"<p>I'm using VS Code to submit a Machine Learning experiment in Azure Portal. When running the experiment I'm obtaining the following error:<\/p>\n\n<p>Run failed: User program failed with ModuleNotFoundError: No module named 'amlrun'<\/p>\n\n<p>This is the code structure:<\/p>\n\n<p>.vscode (json configuration file)<\/p>\n\n<p>aml_config<\/p>\n\n<p>scripts<\/p>\n\n<p>----- amlrun.py (a script with some functions)<\/p>\n\n<p>----- model_training.py (a script creating and saving the model)<\/p>\n\n<p>This is the configuration file:<\/p>\n\n<pre><code>{\n    \"script\": \"model_training.py\",\n    \"framework\": \"Python\",\n    \"communicator\": \"None\",\n    \"target\": \"testazure\",\n    \"environment\": {\n        \"python\": {\n            \"userManagedDependencies\": false,\n            \"condaDependencies\": {\n                \"dependencies\": [\n                    \"python=3.6.2\",\n                    \"scikit-learn\",\n                    \"numpy\",\n                    \"pandas\",\n                    {\n                        \"pip\": [\n                            \"azureml-defaults\"\n                        ]\n                    }\n                ]\n            }\n        },\n        \"docker\": {\n            \"baseImage\": \"mcr.microsoft.com\/azureml\/base:0.2.4\",\n            \"enabled\": true,\n            \"baseImageRegistry\": {\n                \"address\": null,\n                \"username\": null,\n                \"password\": null\n            }\n        }\n    },\n    \"history\": {\n        \"outputCollection\": true,\n        \"snapshotProject\": false,\n        \"directoriesToWatch\": [\n            \"logs\"\n        ]\n    }\n}\n<\/code><\/pre>\n\n<p>Am I missing something?\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-22 09:10:33.2 UTC",
        "Question_favorite_count":0.0,
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":901,
        "Owner_creation_date":"2019-01-10 16:33:51.703 UTC",
        "Owner_last_access_date":"2020-12-14 18:08:49.513 UTC",
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>When your training script is running in azure, it's not able to find all your local imports i.e. <code>amlrun.py<\/code> script. <\/p>\n\n<p>The submitted training job to azure builds a docker image with your files first and runs the experiment; but in this case the extension hasn't included <code>amlrun.py<\/code>. <\/p>\n\n<p>This is probably because when you have submit the training job with the extension, the visual studio code window opened is not pointing to be in <code>scripts<\/code> folder.<\/p>\n\n<p>Taken from one of the replies to a <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/24032\" rel=\"nofollow noreferrer\">previously raised github issue<\/a>:<\/p>\n\n<blockquote>\n  <p>The extension currently requires the script you are working on to be\n  in the folder that is open in VS Code and not in a sub-directory.<\/p>\n<\/blockquote>\n\n<hr>\n\n<p>To fix this you can do <strong>either<\/strong> of the following:<\/p>\n\n<ol>\n<li><p>You would need to re-open Visual Studio Code in <code>scripts<\/code> folder instead of parent directory.<\/p><\/li>\n<li><p>Move all files in <code>script<\/code> directory to be in it's parent directory.<\/p><\/li>\n<\/ol>\n\n<hr>\n\n<p>If you're looking for more flexible way to submit training jobs and managing aml - you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/intro?view=azure-ml-py\" rel=\"nofollow noreferrer\">azure machine learning sdk<\/a> for python.<\/p>\n\n<p>Some examples of using the SDK to manage expirements can be found in the links below:<\/p>\n\n<ol>\n<li><p><a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/service\/tutorial-train-models-with-aml.md\" rel=\"nofollow noreferrer\">Scikit Learn Model Training Docs<\/a> <\/p><\/li>\n<li><p><a href=\"https:\/\/github.com\/rithinch\/heartfulness-similar-content-service\" rel=\"nofollow noreferrer\">Basic Pytorch Model Training and Deployment Example Repo<\/a><\/p><\/li>\n<\/ol>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-10-23 13:25:18.727 UTC",
        "Answer_last_edit_date":"2019-10-23 13:46:12.44 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML: What means reconnecting terminal?",
        "Question_body":"<p>I am a newbie in this, and I am facing some problems with the Azure ML workspace. I ran a python code from the terminal, and then I opened another terminal to check the process. I got the following message in the terminal that checked the process:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9XLPw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9XLPw.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What does this mean? It keeps running, but I don't know if it is a bad message. It takes soo long, and I don't want to lose the processing time.<\/p>\n<p>I appreciate any tips.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-05 20:12:30.743 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azure-python-sdk",
        "Question_view_count":48,
        "Owner_creation_date":"2019-11-30 18:16:16.887 UTC",
        "Owner_last_access_date":"2022-09-23 17:51:17.98 UTC",
        "Owner_location":null,
        "Owner_reputation":45,
        "Owner_up_votes":21,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":"<blockquote>\n<p>What does this mean? It keeps running, but I don't know if it is a bad message. It takes soo long, and I don't want to lose the processing time.<\/p>\n<\/blockquote>\n<ul>\n<li><code>Reconnecting terminal<\/code> message can appear for multiple reasons like intermittent connectivity issues, unused active terminal sessions, processing of different size\/format of data.<\/li>\n<li>Make sure you close any unused terminal sessions to preserve your compute instance's resources. Idle terminals may impact the performance of compute instances.<\/li>\n<\/ul>\n<p>You can refer to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#manage-terminal-sessions\" rel=\"nofollow noreferrer\">Access a compute instance terminal in your workspace<\/a>, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-optimize-data-processing\" rel=\"nofollow noreferrer\">Optimize data processing with Azure Machine Learning<\/a> and <a href=\"https:\/\/www.youtube.com\/watch?v=kiScfw9i4FM\" rel=\"nofollow noreferrer\">Azure ML: Speed up processing time<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-05-06 08:27:02.423 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to do Multiprocessing within deployed Azure ACI for inference?",
        "Question_body":"<p>I want to do multiprocessing within my script. Azure ML has some requirements regarding deployment. The <strong>init()<\/strong> function loads model and other parameters and <strong>run<\/strong> will receive your request from rest-endpoint to process it.<\/p>\n<p>Here is my script for deployed ML model from azure ml:<\/p>\n<pre><code># import libraries \nimport os\nimport json\nimport joblib \nimport numpy as np\nimport pandas as pd \n\n\nfrom itertools import product\nfrom functools import partial\nimport multiprocessing as mp\n\n\n# ##################################################\ndef init():\n    global regression_model\n\n    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n    # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)\n    azure_ml_outputs_dir_path = os.path.join(os.getenv(&quot;AZUREML_MODEL_DIR&quot;), &quot;outputs&quot;)\n\n    # load registered regression model\n    model_path = os.path.join(azure_ml_outputs_dir_path, &quot;model.pkl&quot;)\n    regression_model = joblib.load(model_path)\n    \n    \ndef func(params: tuple, example_df: pd.DataFrame, example_list: list):\n\n    example_df.loc[:, ['col_1']] = params[0]\n    example_df.loc[:, ['col_2']] = params[1]\n\n    y_predict = regression_model.predict(example_df)\n\n    return y_predict\n\n\ndef apply_inverse_func(example_df: pd.DataFrame, initial_param_0_range: list, initial_param_1_range: list):\n\n    example_list = ['a', 'b', 'c']\n\n    paramlist = list(product(initial_param_0_range, initial_param_1_range))\n\n    prediction_error_list = list()\n    with mp.Pool(mp.cpu_count()) as pool:\n        prediction_error_list = pool.map(partial(func, \n                                                example_df = example_df, \n                                                example_list = example_list),\n                                        paramlist)\n\n    result = pd.concat(prediction_error_list)\n\n    return result\n\n\ndef parse_json(json_data, schema):\n    table = json.loads(json_data)\n\n    return table\n\n\ndef run(example_request_df):\n    \n\n    example_df = parse_json(example_request_df)\n\n    # possible initial params values \n    initial_param_0_range = np.round(np.arange(100, 100.25, 0.01), 3).tolist()\n    initial_param_1_range = np.round(np.arange(100, 100.15, 0.01), 3).tolist()\n\n\n    # print(preprocessed_aufbau_df_encoded.shape)\n    response = apply_inverse_func(example_df, initial_param_0_range, initial_param_1_range)\n\n    return response\n<\/code><\/pre>\n<p>passing the Tuple <strong>paramlist<\/strong>  to the <strong>func<\/strong> supposed to be parallelized and the way my code works, it must be passed exactly within <strong>apply_reverse_func<\/strong>. The code works locally without problem and also can be deployed successfully, however, I get the following error when I send a request to the rest-endpoint:<\/p>\n<blockquote>\n<p>prediction: Can't pickle &lt;function func at 0x7f7b5e2768b0&gt;: import of\nmodule 'service_driver' failed<\/p>\n<\/blockquote>\n<p>I know this is cause because of, functions are only picklable if they are defined at the top-level of a module.<\/p>\n<p>How can I solve this problem?<\/p>\n<p>With many thanks in advance!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-05 12:05:58.447 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python-3.x|deployment|multiprocessing|azure-machine-learning-service",
        "Question_view_count":50,
        "Owner_creation_date":"2017-01-16 23:04:42.44 UTC",
        "Owner_last_access_date":"2022-09-23 06:48:12.703 UTC",
        "Owner_location":null,
        "Owner_reputation":83,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":48,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"POST request fails with large data send to model deployed on Azure Container",
        "Question_body":"<p><strong>Summary<\/strong><\/p>\n\n<p>I have a PyTorch model deployed on an Azure Container instance via the Azure Machine Learning Service SDK. The model takes (large) images for classification in standard numpy formatting.<\/p>\n\n<p>It seems, I'm hitting a HTTP request size limit on the server side. Requests to the model succeeds with PNG images of a size in the 8-9mb range and fails with images of the 15mb+ size. Specifically, it fails with 413 Request Entity Too Large.<\/p>\n\n<p>I assume, the limit is set in Nginx in the Docker image being build, as part of the deployment process. My question: <em>Given that the issue is due to the HTTP request size limit, is there any way to increase this limit in the azureml API?<\/em><\/p>\n\n<p><strong>Deployment process<\/strong><\/p>\n\n<p>The deployment process succeeds as expected.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace\nfrom azureml.core.model import InferenceConfig, Model\nfrom azureml.core.webservice import AciWebservice, Webservice\nfrom azureml.exceptions import WebserviceException\nfrom pathlib import Path\n\nPATH = Path('\/data\/home\/azureuser\/my_project')\n\nws = Workspace.from_config()\nmodel = ws.models['my_pytorch_model']\n\ninference_config = InferenceConfig(source_directory=PATH\/'src',\n                                   runtime='python',\n                                   entry_script='deployment\/scoring\/scoring.py',\n                                   conda_file='deployment\/environment\/env.yml')\n\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores=2, memory_gb=4)\naci_service_name = 'azure-model'\n\ntry:\n    service = Webservice(ws, name=aci_service_name)\n    if service:\n        service.delete()\nexcept WebserviceException as e:\n    print()\n\nservice = Model.deploy(ws, aci_service_name, [model], inference_config, deployment_config)\n\nservice.wait_for_deployment(True)\nprint(service.state)\n<\/code><\/pre>\n\n<p><strong>Testing via <code>requests<\/code><\/strong><\/p>\n\n<p>A simple test using requests:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport json\nimport numpy as np\nimport requests\nfrom PIL import Image as PilImage\n\ntest_data = np.array(PilImage.open(PATH\/'src\/deployment\/test\/test_image.png')).tolist()\ntest_sample = json.dumps({'raw_data': \n    test_data\n})\ntest_sample_encoded = bytes(test_sample, encoding='utf8')\n\nheaders = {\n    'Content-Type': 'application\/json'\n}\n\nresponse = requests.post(\n    service.scoring_uri,\n    data=test_sample_encoded,\n    headers=headers,\n    verify=True,\n    timeout=10\n)\n<\/code><\/pre>\n\n<p>Produces the following error in <code>requests<\/code> for larger files:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>ConnectionError: ('Connection aborted.', BrokenPipeError(32, 'Broken pipe'))\n<\/code><\/pre>\n\n<p>Which I guess is a known error in requests, when a connection is closed from the server before data upload is completed.<\/p>\n\n<p><strong>Testing via <code>pycurl<\/code><\/strong><\/p>\n\n<p>Using the curl wrapper, I get a more interpretable response.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import pycurl\nfrom io import BytesIO\n\nc = pycurl.Curl()\nb = BytesIO()\n\nc.setopt(c.URL, service.scoring_uri)\nc.setopt(c.POST, True)\nc.setopt(c.HTTPHEADER,['Content-Type: application\/json'])\nc.setopt(pycurl.WRITEFUNCTION, b.write)\nc.setopt(c.POSTFIELDS, test_sample)\nc.setopt(c.VERBOSE, True)\nc.perform()\n\nout = b.getvalue()\n\nb.close()\nc.close()\n\nprint(out)\n\n<\/code><\/pre>\n\n<p>For large files, this yields the following error:<\/p>\n\n<pre class=\"lang-html prettyprint-override\"><code>&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;\n            413 Request Entity Too Large\n        &lt;\/title&gt;\n    &lt;\/head&gt;\n    &lt;body bgcolor=\"white\"&gt;\n        &lt;center&gt;\n            &lt;h1&gt;\n                413 Request Entity Too Large\n            &lt;\/h1&gt;\n        &lt;\/center&gt;\n        &lt;hr&gt;\n        &lt;center&gt;\n                nginx\/1.10.3 (Ubuntu)\n        &lt;\/center&gt;\n    &lt;\/body&gt;\n&lt;\/html&gt;\n<\/code><\/pre>\n\n<p>Leading me to believe this is an issue in the Nginx configuration. Specifically, I guess that client_max_body_size is set to 10mb.<\/p>\n\n<p><strong>Question summarised<\/strong><\/p>\n\n<p>Given that I am indeed hitting an issue with the Nginx configuration, can I change it somehow? If not using the Azure Machine Learning Service SDK, then maybe by overwriting the <code>\/etc\/nginx\/nginx.conf<\/code> file?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-02 11:52:14.097 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":574,
        "Owner_creation_date":"2013-08-22 07:20:04.257 UTC",
        "Owner_last_access_date":"2019-10-15 07:09:47.553 UTC",
        "Owner_location":null,
        "Owner_reputation":26,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"swagger.json example json for forecast model doesn't seem to return predictions",
        "Question_body":"<p>When trying to make predictions for forecasting models using Azure ML Service, the swagger.json includes the following schema for input:<\/p>\n\n<pre><code>\"example\": {\"data\": [{\"date\": \"2019-08-30T00:00:00.000Z\", \"y_query\": 1.0}]}\n<\/code><\/pre>\n\n<p>However, when I feed this as an input to generate predictions, I receive the following error:<\/p>\n\n<pre><code>data= {\"data\": [{\"date\": \"2019-08-30T00:00:00.000Z\", \"y_query\": 1 }]}\n# Convert to JSON string\ninput_data = json.dumps(data)\n\n# Set the content type\nheaders = {'Content-Type': 'application\/json'}\n# If authentication is enabled, set the authorization header\n#headers['Authorization'] = f'Bearer {key}'\n\n# Make the request and display the response\nresp = requests.post(scoring_uri, input_data, headers=headers)\nprint(resp.text)\n\n<\/code><\/pre>\n\n<pre><code>\"{\\\"error\\\": \\\"DataException:\\\\n\\\\tMessage: y values are present for each date. Nothing to forecast.\\\\n\\\\tInnerException None\\\\n\\\\tErrorResponse \\\\n{\\\\n    \\\\\\\"error\\\\\\\": {\\\\n        \\\\\\\"code\\\\\\\": \\\\\\\"UserError\\\\\\\",\\\\n        \\\\\\\"inner_error\\\\\\\": {\\\\n            \\\\\\\"code\\\\\\\": \\\\\\\"InvalidData\\\\\\\"\\\\n        },\\\\n        \\\\\\\"message\\\\\\\": \\\\\\\"y values are present for each date. Nothing to forecast.\\\\\\\"\\\\n    }\\\\n}\\\"}\"\n<\/code><\/pre>\n\n<p>I have tried not passing a y value, which causes an 'expected two axis got one' and passing 0 as the y_query. Any guidance on how to make predictions using this approach would be greatly appreciated. <\/p>\n\n<p>The documentation for web services is here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":6,
        "Question_creation_date":"2019-10-14 13:01:11.523 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":530,
        "Owner_creation_date":"2016-06-03 10:19:29.833 UTC",
        "Owner_last_access_date":"2022-07-13 18:55:59.383 UTC",
        "Owner_location":null,
        "Owner_reputation":25,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Answer_body":"<p>Try using nan as the value for y_query. and make sure the date is the next time unit after the one that was used in the training set.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-10-18 16:52:16.483 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Workbench File from Blob",
        "Question_body":"<p>When trying to reference\/load a dsource or dprep file generated with a data source file from blob storage, I receive the error \"No files for given path(s)\".<\/p>\n\n<p>Tested with .py and .ipynb files.  Here's the code:<\/p>\n\n<pre><code># Use the Azure Machine Learning data source package\nfrom azureml.dataprep import datasource\n\ndf = datasource.load_datasource('POS.dsource') #Error generated here\n\n# Remove this line and add code that uses the DataFrame\ndf.head(10)\n<\/code><\/pre>\n\n<p>Please let me know what other information would be helpful. Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-10-30 18:09:10.993 UTC",
        "Question_favorite_count":null,
        "Question_score":4,
        "Question_tags":"azure|machine-learning|azure-blob-storage|azure-machine-learning-workbench",
        "Question_view_count":324,
        "Owner_creation_date":"2016-04-19 18:30:53.86 UTC",
        "Owner_last_access_date":"2019-04-30 19:00:43.91 UTC",
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-11-22 00:28:16.38 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"NLTK in Azure ML",
        "Question_body":"<p>Folks,<\/p>\n\n<p>I have the below code to create pos tagger in nltk implemented as an \"Execute Python Script\" in Azure ML. The problem is the script has to download <em>maxent_treebank_pos_tagger<\/em> every time. Commenting the line would throw the below error. I even tried downloading using nltk.download('all') but still it did not help.<\/p>\n\n<pre><code>\"C:\\\\pyhome\\\\lib\\\\site-packages\\\\nltk\\\\data.py\\\", line 467, in find\\r\\n raise LookupError(resource_not_found)\\r\\nLookupError: \\r\\n**********************************************************************\\r\\n Resource 'taggers\/maxent_treebank_pos_tagger\/english.pickle' not\\r\\n found. Please use the NLTK Downloader to obtain the resource:\\r\\n &gt;&gt;&gt; nltk.download()\\r\\n Searched in:\\r\\n - 'C:\\\\\\\\Users\\\\\\\\Client\/nltk_data'\\r\\n - 'C:\\\\\\\\nltk_data'\\r\\n - 'D:\\\\\\\\nltk_data'\\r\\n - 'E:\\\\\\\\nltk_data'\\r\\n - 'C:\\\\\\\\pyhome\\\\\\\\nltk_data'\\r\\n - 'C:\\\\\\\\pyhome\\\\\\\\lib\\\\\\\\nltk_data'\\r\\n - 'C:\\\\\\\\Users\\\\\\\\Client\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\nltk_data'\\r\\n**********************************************************************\\r\\nProcess returned with non-zero exit code 1\\r\\n\\r\\n---------- End of error message from Python interpreter ----------\"}}Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:---------- Start of error message from Python interpreter ----------Caught exception while executing function: Traceback (most recent call last): File \"C:\\server\\invokepy.py\", line 199, in batch odfs = mod.azureml_main(*idfs) File \"C:\\temp\\febff15ac9584d978d04d40f0c7bd565.py\", line 32, in azureml_main tagged = nltk.pos_tag(tokens) File \"C:\\pyhome\\lib\\site-packages\\nltk\\tag\\__init__.py\", line 99, in pos_tag tagger = load(_POS_TAGGER) File \"C:\\pyhome\\lib\\site-packages\\nltk\\data.py\", line 605, in load resource_val = pickle.load(_open(resource_url)) File \"C:\\pyhome\\lib\\site-packages\\nltk\\data.py\", line 686, in _open return find(path).open() File \"C:\\pyhome\\lib\\site-packages\\nltk\\data.py\", line 467, in find raise LookupError(resource_not_found)LookupError: ********************************************************************** Resource 'taggers\/maxent_treebank_pos_tagger\/english.pickle' not found. Please use the NLTK Downloader to obtain the resource: &gt;&gt;&gt; nltk.download() Searched in: - 'C:\\\\Users\\\\Client\/nltk_data' - 'C:\\\\nltk_data' - 'D:\\\\nltk_data' - 'E:\\\\nltk_data' - 'C:\\\\pyhome\\\\nltk_data' - 'C:\\\\pyhome\\\\lib\\\\nltk_data' - 'C:\\\\Users\\\\Client\\\\AppData\\\\Roaming\\\\nltk_data'**********************************************************************Process returned with non-zero exit code 1---------- End of error message from Python interpreter ---------- Process exited with error code -2\n<\/code><\/pre>\n\n<p>Below is my code in Azure ml<\/p>\n\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n# import required packages\nimport pandas as pd\nimport nltk\nimport numpy as np\n# tokenize the review text and store the word corpus\nword_dict = {}\ntoken_list = []\n#nltk.download('all')\n#nltk.download(info_or_id='punkt', download_dir='C:\/users\/client\/nltk_data')\n#nltk.download(info_or_id='maxent_treebank_pos_tagger', download_dir='C:\/users\/client\/nltk_data')\nfor text in dataframe1[\"tweet_text\"]:\n    tokens = nltk.word_tokenize(text.decode('utf8'))\n    tagged = nltk.pos_tag(tokens)\n\n\n  # convert feature vector to dataframe object\ndataframe_output = pd.DataFrame(tagged, columns=['Word', 'Type'])\nreturn [dataframe_output]\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2016-09-26 15:30:09.613 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|nltk|azure-machine-learning-studio",
        "Question_view_count":989,
        "Owner_creation_date":"2013-06-11 04:20:18.39 UTC",
        "Owner_last_access_date":"2022-09-18 05:28:20.357 UTC",
        "Owner_location":"Toronto, ON, Canada",
        "Owner_reputation":1748,
        "Owner_up_votes":136,
        "Owner_down_votes":55,
        "Owner_views":339,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML batch execution latency",
        "Question_body":"<p>After reading this post here: <a href=\"https:\/\/stackoverflow.com\/questions\/34990561\/azure-machine-learning-request-response-latency\/35020997#35020997?newreg=18fbd305056d4e6ba239783ebefb9629\">Azure Machine Learning Request Response latency<\/a>\nand the article mentioned in the comments I was wondering if this behavior is also true when a published webservice is called in batch mode. \nEspecially since I have read somewhere (sorry, can't find the link at the moment) that the batch calls are not influenced by the \"concurrent calls\" config...<\/p>\n\n<p>In our scenario we have a custom R module uploaded to our workspace which includes some libraries that are not available on aML by default. The module takes a dataset, trains a binary tree, creates some plots and encodes them in base64 before returning those as a dataset. Locally that does not take more than 5s. But in the aML webservice it takes approx. 90s and it seems that the runtime in batchmode does not improve when calling the service multiple times.<\/p>\n\n<p>Additionally it would be nice to know for how long the containers, mentioned in the linked post, will stay warm.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_creation_date":"2016-01-28 09:10:29.01 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"r|batch-processing|azure-machine-learning-studio",
        "Question_view_count":212,
        "Owner_creation_date":"2016-01-28 08:51:11.07 UTC",
        "Owner_last_access_date":"2016-03-21 13:18:04.11 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-05-23 11:59:15.23 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How can I change the version of my model in Azure Machine Learning service?",
        "Question_body":"<p>When registering a model into Azure Machine Learning, it keeps increments the version number. Can i set the version number to a specific number? Or even stop it from increments every time? <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/EB4wN.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EB4wN.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-28 13:42:24.563 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":124,
        "Owner_creation_date":"2017-02-07 16:37:56.78 UTC",
        "Owner_last_access_date":"2021-03-11 21:08:08.63 UTC",
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to Add Column (script) transform that queries another column for content",
        "Question_body":"<p>I\u2019m looking for a simple expression that puts a \u20181\u2019 in column E if \u2018SomeContent\u2019 is contained in column D.  I\u2019m doing this in Azure ML Workbench through their Add Column (script) function.  Here\u2019s some examples they give.<\/p>\n\n<pre><code>row.ColumnA + row.ColumnB is the same as row[\"ColumnA\"] + row[\"ColumnB\"] \n1 if row.ColumnA &lt; 4 else 2 \ndatetime.datetime.now() \nfloat(row.ColumnA) \/ float(row.ColumnB - 1) \n'Bad' if pd.isnull(row.ColumnA) else 'Good'\n<\/code><\/pre>\n\n<p>Any ideas on a 1 line script I could use for this?  Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-07-26 20:10:53.827 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-workbench",
        "Question_view_count":32,
        "Owner_creation_date":"2016-05-25 10:42:44.16 UTC",
        "Owner_last_access_date":"2021-10-01 14:46:28.737 UTC",
        "Owner_location":"Brevard, NC, USA",
        "Owner_reputation":111,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Can decision tree learning be \"semi-supervised\"",
        "Question_body":"<p>I have a dataset that includes three types of variables: states of nature, human decisions, response variable. I'm trying to predict the response variable using the other variables using decision tree learning.<\/p>\n\n<p>My mental model is that people are looking at the states of nature and making decisions. Hence, I strongly prefer to have my decision trees start by partitioning according to the state of nature variables, and subsequently partition based on the human decision variables. I would prefer not to just chuck all the variables in a decision tree model and see what pops out.<\/p>\n\n<p>Is that mental model valid and if so how would I implement something like this using, say, Azure ML? I don't even know the right words to describe this problem - is this \"semi-supervised\" decision tree learning?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-04-26 19:27:29.52 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"machine-learning|tree|decision-tree|azure-machine-learning-studio",
        "Question_view_count":300,
        "Owner_creation_date":"2011-12-04 16:34:01.853 UTC",
        "Owner_last_access_date":"2016-09-03 22:01:44.703 UTC",
        "Owner_location":null,
        "Owner_reputation":225,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-01-04 09:20:42.23 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How can I include the \"source\" field from the Microsoft Azure Custom Question Answer API?",
        "Question_body":"<p>I am leveraging the latest iteration of Azure's Custom question answering module in language studio in an external app that I've created, and I cannot figure out how to receive the actual source when the question is answered. I don't know if that's because you just can't right now or what, but in the actual API docs for the request\/answer sample, the answer sample includes the source field - no matter what I've tried, I can't get it to show up.\nPage where API doc is found - <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/cognitiveservices\/questionanswering\/question-answering\/get-answers#knowledgebaseanswer\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/rest\/api\/cognitiveservices\/questionanswering\/question-answering\/get-answers#knowledgebaseanswer<\/a><\/p>\n<p>Quick example snippet of how I've adapted the API:<\/p>\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-js lang-js prettyprint-override\"><code>{\n  \"question\": \"&lt;question&gt;\",\n  \"top\": 3,\n  \"userId\": \"&lt;user&gt;\",\n  \"confidenceScoreThreshold\": 0.2,\n  \"rankerType\": \"Default\",\n  \"filters\": {\n    \"metadataFilter\": {\n      \"metadata\": [\n        \n      ],\n    },\n  },\n  \"answerSpanRequest\": {\n    \"enable\": true,\n    \"confidenceScoreThreshold\": 0.2,\n    \"topAnswersWithSpan\": 1\n  },\n  \n  },\n  \"includeUnstructuredSources\": true\n}<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n<p>I understand the metadata bit has nothing there, I may add something later but as of now I'm not messing with the metadata aspect in language studio sources themselves.<\/p>\n<p>At any rate, the bottom line is I don't see an option to display a source, and I don't get it back in the body of the request - yet I see it in the sample response in the API doc, so what gives, am I missing something?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-03 19:50:48.097 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|nlp|azure-machine-learning-studio|nlp-question-answering",
        "Question_view_count":54,
        "Owner_creation_date":"2014-06-30 20:03:00.68 UTC",
        "Owner_last_access_date":"2022-08-09 16:35:54.487 UTC",
        "Owner_location":"Austin, TX, USA",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"how to add the column names to the input dataset using R script in Machine Learning model",
        "Question_body":"<p>I am trying to add the column names to the input dataset using below R script.<\/p>\n\n<pre><code>dataset1 &lt;- maml.mapInputPort(1)#class: data.frame\n# Sample operation\ncols &lt;- c(\"age\",\n    \"workclass\",\n    \"fnlwgt\",\n    \"education\",\n    \"education-num\",\n    \"marital-status\",\n    \"occupation\",\n    \"relationship\",\n    \"race\",\n    \"sex\",\n    \"capital-gain\",\n    \"capital-loss\",\n    \"hours-per-week\",\n    \"native-country\",\n    \"income\")\n colnames(data.frame) &lt;- cols\n data.set = dataset1;\n maml.mapOutputPort(\"data.set\");\n<\/code><\/pre>\n\n<p>But I am getting the error like below figure.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/m4vwp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/m4vwp.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Can you please tell me how to add the column names to the input dataset using R script in Machine Learning model?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-07-27 12:36:30.353 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":224,
        "Owner_creation_date":"2015-10-21 11:13:32.267 UTC",
        "Owner_last_access_date":"2022-09-07 05:24:44.26 UTC",
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":4594,
        "Owner_up_votes":240,
        "Owner_down_votes":22,
        "Owner_views":1089,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure machine learning endpoints with different column count",
        "Question_body":"<p>I would like to automatically set up Azure machine learning endpoints that don't necessarily have the same amount of variables. I am able to programmatically add new endpoints that are trained on different data as long as they have the same column and variable names (headers).<\/p>\n\n<p>When I try to create a new endpoint using a different column count it works. But when I try to call it it gives me errors.<\/p>\n\n<p>I set up an experiment where the default endpoint is accepting two parameters 'x' and 'y'. Then I trained it on a dataset using three columns 'x1', 'x2' and 'y'. The 'Train Model' module in the training experiment is picking out column 1.<\/p>\n\n<p>Calling the endpoint that was trained using three variables with three input columns:<\/p>\n\n<pre><code>{\n\"error\": {\n    \"code\": \"LibraryExecutionError\",\n    \"message\": \"Module execution encountered an internal library error.\",\n    \"details\": [\n        {\n            \"code\": \"TableSchemaColumnCountMismatch\",\n            \"target\": \" (AFx Library)\",\n            \"message\": \"data: The table column count (3) must match the schema column count (2).\"\n        }\n    ]\n}\n<\/code><\/pre>\n\n<p>}<\/p>\n\n<p>Calling the endpoint that was trained using three variables with ony two input columns:<\/p>\n\n<pre><code>{\n\"error\": {\n    \"code\": \"LibraryExecutionError\",\n    \"message\": \"Module execution encountered an internal library error.\",\n    \"details\": [\n        {\n            \"code\": \"ScoredFeaturesMustMatchTrainingFeatures\",\n            \"target\": \"Score Model (AFx Library)\",\n            \"message\": \"table: The data set being scored must contain all features used during training, missing feature(s): 'x2'.\"\n        }\n    ]\n}\n<\/code><\/pre>\n\n<p>}<\/p>\n\n<p>It seems to be remembering the setup of the default endpoint and expects all other endpoints to conform to it's metadata. Is there any way around this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-12-01 10:13:37.76 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":975,
        "Owner_creation_date":"2015-02-17 11:45:39.343 UTC",
        "Owner_last_access_date":"2022-09-23 09:18:42.033 UTC",
        "Owner_location":"Malm\u00f6, Sweden",
        "Owner_reputation":794,
        "Owner_up_votes":1478,
        "Owner_down_votes":2,
        "Owner_views":136,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"get workspace failed azuremlsdk - AuthenticationException",
        "Question_body":"<p>I have created a workspace in our azure environment and try to run this code:<\/p>\n<pre><code>library(azuremlsdk)\n\nws &lt;- get_workspace(\n    name = &quot;someworkspace&quot;, \n    subscription_id = &quot;si1&quot;, \n    resource_group =&quot;rg1&quot;\n)\n<\/code><\/pre>\n<p>Some interactive authenticator opens in my browser, which I think is intended behaviour as I have no tenantdid. However, I get this:<\/p>\n<pre><code>Performing interactive authentication. Please follow the instructions on the terminal.\nNote, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\nPerforming interactive authentication. Please follow the instructions on the terminal.\nNote, we have launched a browser for you to login. For old experience with device code, use &quot;az login --use-device-code&quot;\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\nAuthenticationException: AuthenticationException:\n        Message: Could not retrieve user token. Please run 'az login'\n        InnerException It is required that you pass in a value for the &quot;algorithms&quot; argument when calling decode().\n        ErrorResponse\n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;Authentication&quot;\n        },\n        &quot;message&quot;: &quot;Could not retrieve user token. Please run 'az login'&quot;\n    }\n}\n<\/code><\/pre>\n<p>I also tried:<\/p>\n<pre><code>az login\n<\/code><\/pre>\n<p>This works fine. So for me all this is very confusing!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-11 13:45:09.577 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":530,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":"<p>So I tried the same in Python and had a similar error and came across this:<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/16035\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/16035<\/a><\/p>\n<p>Downgrading:<\/p>\n<pre><code> PyJWT \n<\/code><\/pre>\n<p>helped. The bizarre world of open source and its web of interdependencies!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-05-11 16:55:59.74 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2021-05-11 16:39:46.967 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure POST request redirect using Azure services",
        "Question_body":"<p>Hello I am trying to deploy my Azure Machine Learning pipeline with a REST endpoint. My problem is that I was able to generate an endpoint but has some sensitive information in it (ex: subscription id, resource group, etc). How can I generate a URL that forwards the request body to my Azure ML REST endpoint?<\/p>\n<p>also, here is an approach I've done:<\/p>\n<ul>\n<li>Used Application Gateway Redirect (this approach didn't forward the request body. It instead turned my POST request into a GET request when it redirected to the correct URL.)<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-04 17:54:49.963 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|rest|web-deployment|azure-machine-learning-service",
        "Question_view_count":58,
        "Owner_creation_date":"2020-04-27 17:52:14.69 UTC",
        "Owner_last_access_date":"2022-06-24 17:21:40.043 UTC",
        "Owner_location":"Los Angeles, CA, USA",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Internal Error",
        "Question_body":"<p>When I try to test my Azure ML model, I get the following error: \u201cError code: InternalError, Http status code: 500\u201d, so it appears something is failing inside of the machine learning service. How do I get around this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-08-17 21:44:21.947 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":1408,
        "Owner_creation_date":"2015-08-17 21:40:18.3 UTC",
        "Owner_last_access_date":"2016-04-28 08:03:01.207 UTC",
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>I've run into this error before, and unfortunately, the only workaround I found was to create a new ML workspace backed by a storage account that you know is online. Then copy your experiment over to the new workspace, and things should work. It can be a bit cumbersome, but it should get rid of your error message. With the service being relatively new, things sometimes get corrupted as updates are being made, so I recommend checking the box labeled \"disable updates\" within your experiment.  Hope that helps!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-08-17 21:47:56.38 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2015-08-18 13:57:02.223 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Not all data Stores (workspaceblobstore) specified in the run configuration exist",
        "Question_body":"<p>I am submitting a run to an AML workspace programmatically, and it is failing with the error message:<\/p>\n\n<pre><code>\"error\": {\n\"code\": \"UserError\",\n            \"message\": \"Not all data Stores (workspaceblobstore) specified in the run configuration exist.\" }\n\n<\/code><\/pre>\n\n<p>Inspecting the run configuration object, the <code>sourceDirectoryDataStore<\/code> is set to null, and the other two data-related properties are empty.  <\/p>\n\n<pre><code>\"dataReferences\": {},\n\"data\": {},\n\"sourceDirectoryDataStore\": null \n<\/code><\/pre>\n\n<p>The script that I am submitting does not make use of any datastores registered through aml, it is just the simple diabetes regression, using the <code>sklearn<\/code> diabetes dataset. \nThe training script is copied to the <code>snapshots<\/code> container of the storage account linked with the AML workspace.  <\/p>\n\n<p>What would be the next steps on troubleshooting this?<\/p>\n\n<p>SDK Version: 1.0.85. <\/p>\n\n<p>When retrieving the datastores, through ws.datastores (suggested in the comments), I get another exception about the storage service missing name or key, but there is a storage account that got deployed with the AML workspace. Inspecting the ARM template of the AML workspace the storage account id is in the properties of the AML template, and the usual containers (revisions, snapshots, snapshotzips, azureml-bloblstore-GUID) are created and the *.py files that I am attempting to run are being uploaded. <\/p>\n\n<pre><code>    print(ws.datastores)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\core\\workspace.py\", line 789, in datastores\n    return {datastore.name: datastore for datastore in _DatastoreClient.list(self)}\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\data\\datastore_client.py\", line 486, in list\n    dss, ct = _DatastoreClient._list(workspace, ct, 100)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\data\\datastore_client.py\", line 688, in _list\n    return list(datastores), datastore_dtos.continuation_token\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\data\\datastore_client.py\", line 687, in &lt;lambda&gt;\n    map(lambda dto: _DatastoreClient._dto_to_datastore(ws, dto), datastore_dtos.value))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\data\\datastore_client.py\", line 760, in _dto_to_datastore\n    as_section.sas_token, as_section.account_key, as_section.protocol, as_section.endpoint)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\data\\azure_storage_datastore.py\", line 390, in __init__\n    endpoint_suffix=endpoint\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\_vendor\\azure_storage\\file\\fileservice.py\", line 184, in __init__\n    raise ValueError(_ERROR_STORAGE_MISSING_INFO)\nValueError: You need to provide an account name and either an account_key or sas_token when creating a storage service.\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2020-01-27 20:08:34.563 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":717,
        "Owner_creation_date":"2012-08-02 23:01:34.333 UTC",
        "Owner_last_access_date":"2022-09-02 23:21:30.913 UTC",
        "Owner_location":"Seattle, WA, USA",
        "Owner_reputation":1390,
        "Owner_up_votes":122,
        "Owner_down_votes":2,
        "Owner_views":121,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-01-28 17:01:55.747 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Using the Environment Class with Pipeline Runs",
        "Question_body":"<p>I am using an estimator step for a pipeline using the Environment class, in order to have a custom Docker image as I need some <code>apt-get<\/code> packages to be able to install a specific pip package. It appears from the logs that it's completely ignoring, unlike the non-pipeline version of the estimator, the docker portion of the environment variable. Very simply, this seems broken : <\/p>\n\n<p>I'm running on SDK v1.0.65, and my dockerfile is completely ignored, I'm using <\/p>\n\n<pre><code>FROM mcr.microsoft.com\/azureml\/base:latest\\nRUN apt-get update &amp;&amp; apt-get -y install freetds-dev freetds-bin vim gcc\n<\/code><\/pre>\n\n<p>in the base_dockerfile property of my code. \nHere's a snippet of my code : <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Environment\nfrom azureml.core.environment import CondaDependencies\nconda_dep = CondaDependencies()\nconda_dep.add_pip_package('pymssql==2.1.1')\nmyenv = Environment(name=\"mssqlenv\")\nmyenv.python.conda_dependencies=conda_dep\nmyenv.docker.enabled = True\nmyenv.docker.base_dockerfile = 'FROM mcr.microsoft.com\/azureml\/base:latest\\nRUN apt-get update &amp;&amp; apt-get -y install freetds-dev freetds-bin vim gcc'\nmyenv.docker.base_image = None\n<\/code><\/pre>\n\n<p>This works well when I use an Estimator by itself, but if I insert this estimator in a Pipeline, it fails. Here's my code to launch it from a Pipeline run: <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.pipeline.steps import EstimatorStep\n\nsql_est_step = EstimatorStep(name=\"sql_step\", \n                         estimator=est, \n                         estimator_entry_script_arguments=[],\n                         runconfig_pipeline_params=None, \n                         compute_target=cpu_cluster)\nfrom azureml.pipeline.core import Pipeline\nfrom azureml.core import Experiment\npipeline = Pipeline(workspace=ws, steps=[sql_est_step])\npipeline_run = exp.submit(pipeline)\n<\/code><\/pre>\n\n<p>When launching this, the logs for the container building service reveal:<\/p>\n\n<pre><code>FROM continuumio\/miniconda3:4.4.10... etc.\n<\/code><\/pre>\n\n<p>Which indicates it's ignoring my <code>FROM mcr....<\/code> statement in the Environment class I've associated with this Estimator, and my <code>pip install<\/code> fails.<\/p>\n\n<p>Am I missing something? Is there a workaround?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-08 19:53:08.707 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":751,
        "Owner_creation_date":"2018-09-30 02:52:40.603 UTC",
        "Owner_last_access_date":"2022-07-22 02:57:21.83 UTC",
        "Owner_location":"Montreal, QC, Canada",
        "Owner_reputation":381,
        "Owner_up_votes":75,
        "Owner_down_votes":2,
        "Owner_views":50,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Unable to receive proper predicted data from Dynamics 365 Customer Insights platform",
        "Question_body":"<p>I am new to the microsoft customer insights API. we are trying to train a model with customer dataset and created the entity by prediction. we are trying to consume the churn prediction scores using the API from below<\/p>\n<p><a href=\"https:\/\/home.ci.ai.dynamics.com\/\" rel=\"nofollow noreferrer\">https:\/\/home.ci.ai.dynamics.com\/<\/a><\/p>\n<p>We have tried almost all the api requests present there to get the churnscore for a user. we are not getting anything. is there any way to fetch those.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-22 10:45:15.027 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-active-directory|microsoft-graph-api|dynamics-365|azure-machine-learning-studio",
        "Question_view_count":44,
        "Owner_creation_date":"2021-01-22 10:23:52.957 UTC",
        "Owner_last_access_date":"2021-08-23 13:06:12.053 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"difference between start_logging and run.get_context",
        "Question_body":"<p>I just wanted to know the difference between  start_logging and run.get_context in azure ml.\nwhen they are used? what is the purpose of each function??<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-10 16:04:20.933 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-functions|azure-machine-learning-service",
        "Question_view_count":206,
        "Owner_creation_date":"2020-01-10 04:31:18.2 UTC",
        "Owner_last_access_date":"2021-07-13 08:43:48.77 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Pulling data from Stream Analytics to Azure Machine Learning",
        "Question_body":"<p>Working on a IoT telemetry project that receives humidity and weather pollution data from different sites on the field. I will then apply Machine Learning on the collected data. I'm using Event Hubs and Stream Analytics. Is there a way of pulling the data to Azure Machine Learning without the hassle of writing an application to get it from Stream Analytics and push to AML web service?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-30 09:29:18.85 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|iot|azure-stream-analytics|azure-machine-learning-studio",
        "Question_view_count":627,
        "Owner_creation_date":"2011-07-18 19:31:54.58 UTC",
        "Owner_last_access_date":"2022-09-24 13:50:28.383 UTC",
        "Owner_location":"Beirut, Lebanon",
        "Owner_reputation":408,
        "Owner_up_votes":88,
        "Owner_down_votes":6,
        "Owner_views":32,
        "Answer_body":"<p>Stream Analytics has a functionality called the \u201c<a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/\" rel=\"nofollow\">Functions<\/a>\u201d. You can call any web service you\u2019ve published using AML from within Stream Analytics and apply it within your Stream Analytics query. Check this <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/stream-analytics-machine-learning-integration-tutorial\/\" rel=\"nofollow\">link for a tutorial<\/a>.\nExample workflow in your case would be like the following;<\/p>\n\n<ul>\n<li>Telemetry arrives and reaches Stream Analytics<\/li>\n<li>Streaming Analytics (SA) calls the Machine Learning function to apply it on the data<\/li>\n<li>SA redirects it to the output accordingly, here you can use the PowerBI to create a predictions dashboards.<\/li>\n<\/ul>\n\n<p>Another way would be using R, and here\u2019s a good tutorial showing that <a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/\" rel=\"nofollow\">https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/<\/a> . \nIt is more work of course but can give you more control as you control the code.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-06-30 11:00:56.457 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":3.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"I am trying to create a job in azure ML and after giving the correct inputs the job is failing with the following error:",
        "Question_body":"<p><code>Invalid config parameters<\/code>\n<code>error[Errno 2] No such file or directory: '\/opt\/ml\/input\/config\/hyperparameters.json'<\/code><\/p>\n<p>How can I solve this issue? I have tried to use python sdk to upload the config.json file according to the client request but I am not sure how to achieve that since there's very less material online. Please help me with this issue.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-06-01 06:15:21.797 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":71,
        "Owner_creation_date":"2022-06-01 06:08:13.23 UTC",
        "Owner_last_access_date":"2022-07-16 12:29:24.333 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-06-05 19:15:34.08 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML TabularDatasetFactory.from_parquet_files() error handling column types",
        "Question_body":"<p>I'm reading in a folder of parquet files using azureml's TabularDatasetFactory method:<\/p>\n<pre><code>dataset = TabularDatasetFactory.from_parquet_files(path=[(datastore_instance, &quot;path\/to\/files\/*.parquet&quot;)])\n<\/code><\/pre>\n<p>but am running into the issue that one of the columns is typed 'List' in the parquet files, and it seems <code>TabularDatasetFactory.from_parquet_files()<\/code> can't handle that typing?<\/p>\n<pre><code>ExecutionError: \nError Code: ScriptExecution.StreamAccess.Validation\nValidation Error Code: NotSupported\nValidation Target: ParquetType\nFailed Step: xxxxxx\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by ValidationException.\n    No conversion exists for column: '[REDACTED COLUMN NAME]', from Parquet SchemaType: 'List' to DataPrep ValueKind\n<\/code><\/pre>\n<p>So I'm wondering if there's a way to tell <code>TabularDatasetFactory.from_parquet_files()<\/code> specifically which columns to pull in, or a way to tell it to fall back on any unsupported column types to just use object\/string. Or maybe there's a work around by first reading in the files as a FileDataset, then selecting which columns in the files to use?<\/p>\n<p>I do see the <code>set_column_types<\/code> parameter, but I don't know the columns until I read it into a dataset since I'm using datasets to explore what data is available in the folder paths in the first place<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-16 18:35:34.26 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":67,
        "Owner_creation_date":"2014-02-17 14:58:19.183 UTC",
        "Owner_last_access_date":"2022-07-29 16:31:19.67 UTC",
        "Owner_location":null,
        "Owner_reputation":173,
        "Owner_up_votes":26,
        "Owner_down_votes":2,
        "Owner_views":83,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-06-16 19:28:48.81 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to connect Azure Data lake storage to Azure ML?",
        "Question_body":"<p>Hi i am started to learning the azure data lake and azure machine learning ,i need to use the azure data lake storage as a azure machine learning studio input data .There have a any options are there, i gone through the azure data lake and machine learning documentation but i can't reach that,finally i got one solution on this \n<a href=\"https:\/\/stackoverflow.com\/questions\/36127510\/how-to-use-azure-data-lake-store-as-an-input-data-set-for-azure-ml\">link<\/a> but they are mentioning there is no option for it,but this post is old one,so might be the Microsoft people added the future  on it if it's please let me know, let me know Thank you. <\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2017-03-07 15:16:16.04 UTC",
        "Question_favorite_count":2.0,
        "Question_score":5,
        "Question_tags":"azure|azure-stream-analytics|azure-data-lake|azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":4966,
        "Owner_creation_date":"2017-02-18 10:18:54.923 UTC",
        "Owner_last_access_date":"2020-12-03 12:57:12.34 UTC",
        "Owner_location":"Gurugram, Haryana, India",
        "Owner_reputation":321,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":65,
        "Answer_body":"<p>I recommend the following:<\/p>\n\n<ul>\n<li>Get a tenant ID, client ID, and client secret for your ADLS using the tutorial <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/data-lake-store\/data-lake-store-authenticate-using-active-directory#step-2-get-client-id-client-secret-and-tenant-id\" rel=\"nofollow noreferrer\">here<\/a>.<\/li>\n<li>Install the <a href=\"https:\/\/github.com\/Azure\/azure-data-lake-store-python\" rel=\"nofollow noreferrer\"><code>azure-datalake-store<\/code><\/a> Python package on AML Studio by attaching it as a Script Bundle to an Execute Python Script module.<\/li>\n<li>In the Execute Python Script module, import the <code>azure-datalake-store<\/code> package and connect to the ADLS with your tenant ID, client ID, and client secret.<\/li>\n<li>Download the data you need from ADLS and convert it into a dataframe within the Python Script module; return that dataframe to make the data available in the rest of AML Studio.<\/li>\n<\/ul>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-03-21 19:59:41.093 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":4.0,
        "Question_last_edit_date":"2017-05-23 10:29:58.003 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to call an azure ml pipeline from logic apps?",
        "Question_body":"<p>I'm looking for an example of logic apps calling a published Azure ML Pipeline. By just copy pasting the URL I get an 415 error: UnsupportedMediaType. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-11-05 11:39:27.17 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":295,
        "Owner_creation_date":"2016-02-24 12:37:06.73 UTC",
        "Owner_last_access_date":"2021-11-25 09:56:59.237 UTC",
        "Owner_location":null,
        "Owner_reputation":57,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Letter Recognition Error in Azure ML Studio",
        "Question_body":"<p>I'm having troubles with a Letter Recognition model I'm creating in Azure ML Studio.<\/p>\n<p>I'm running a few algorithms - Decision Jungle, Neural Network, Decision Forest, Logistic Regression, One vs. All Multiclass, and then I append them using the Add rows method (Neural Network and Desicion Jungle\/ Decision Forest and Logistic Regression), until I append them all.<\/p>\n<p>However, appending Decision Forest and Logistic Regression I get the following error:<\/p>\n<pre><code>requestId = 9292bc066f51404eb5e0d0d219d3a072 errorComponent=Module. taskStatusCode=400. {&quot;Exception&quot;:{&quot;ErrorId&quot;:&quot;NotInRangeValue&quot;,&quot;ErrorCode&quot;:&quot;0008&quot;,&quot;ExceptionType&quot;:&quot;ModuleException&quot;,&quot;Message&quot;:&quot;Error 0008: Parameter \\&quot;Dataset2(number of columns)\\&quot; value should be in the range of [3, 3].&quot;}}Error: Error 0008: Parameter &quot;Dataset2(number of columns)&quot; value should be in the range of [3, 3]. Process exited with error code -2\n<\/code><\/pre>\n<p>Any advice what should I do? Huge thanks in advance<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-09 08:43:00.777 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":37,
        "Owner_creation_date":"2020-09-09 08:40:56.987 UTC",
        "Owner_last_access_date":"2022-02-20 15:55:02.427 UTC",
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":"<p>This error occurs when there is a mismatch of number of columns of the two dataset you are appending.<\/p>\n<p>Looking at the error :<\/p>\n<p>The output of one model is returning rows with 3 columns and other one is having either more or less than 3 columns.<\/p>\n<p>Before this step &quot;Add Rows&quot; step -&gt; Do quick Visualize<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/PsYQT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PsYQT.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>This will give a view of the dataset that you are planning to append.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/x442d.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/x442d.png\" alt=\"![enter image description here\" \/><\/a><\/p>\n<p>Ensure for both, the columns numbers are same.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-09-09 12:17:08.45 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2020-09-09 09:02:30.897 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How import 'html5lib' package to Python 3.5 Script in Azure Machine Learning Studio?",
        "Question_body":"<p>I'm trying to import the package <code>html5lib<\/code> to <code>Azure Machine Learning<\/code>, into a <code>Execute Python Script<\/code> module. It's a similar question as <a href=\"https:\/\/stackoverflow.com\/questions\/44593469\/how-can-certain-python-libraries-be-imported-in-azure-mllike-the-line-import-hu\">here<\/a>, but same solution didn't work... :\/<\/p>\n\n<p>My steps until now:<\/p>\n\n<ol>\n<li>I got the latest version of <code>HTML5LIB<\/code> package from the <a href=\"https:\/\/pypi.org\/project\/html5lib\/\" rel=\"nofollow noreferrer\">project website<\/a>;<\/li>\n<li>Unzip tar.gz file and re-zip as .ZIP file;<\/li>\n<li>Upload the file in Azure Studio as a Dataset named as 'html5lib.zip';\n<a href=\"https:\/\/i.stack.imgur.com\/o3UvI.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/li>\n<li>Add the zip file as dataset into my Experiment and connected to Script Bundle Input;\n<a href=\"https:\/\/i.stack.imgur.com\/thDfa.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/li>\n<li>Run the following script:\n<a href=\"https:\/\/i.stack.imgur.com\/4cj91.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/li>\n<\/ol>\n\n<p>Then, I got the error:<\/p>\n\n<pre><code>Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nCaught exception while executing function: Traceback (most recent call last):\nFile \"C:\\server\\invokepy.py\", line 189, in batch\nmod = import_module(moduleName)\nFile \"C:\\pyhome\\lib\\importlib\\__init__.py\", line 126, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\nFile \"&lt;frozen importlib._bootstrap&gt;\", line 986, in _gcd_import\nFile \"&lt;frozen importlib._bootstrap&gt;\", line 969, in _find_and_load\nFile \"&lt;frozen importlib._bootstrap&gt;\", line 958, in _find_and_load_unlocked\nFile \"&lt;frozen importlib._bootstrap&gt;\", line 673, in _load_unlocked\nFile \"&lt;frozen importlib._bootstrap_external&gt;\", line 662, in exec_module\nFile \"&lt;frozen importlib._bootstrap&gt;\", line 222, in _call_with_frames_removed\nFile \"C:\\temp\\6d718116a1f549e59a5b96c5d6360911.py\", line 22, in &lt;module&gt;\nimport html5lib\nImportError: No module named 'html5lib'\nProcess returned with non-zero exit code 1\n<\/code><\/pre>\n\n<p>Any idea how can I fix this?<\/p>\n\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-12-09 01:16:08.193 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|python-import|azure-machine-learning-studio",
        "Question_view_count":144,
        "Owner_creation_date":"2015-12-26 11:56:59.26 UTC",
        "Owner_last_access_date":"2021-12-07 15:26:40.09 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Image Data passed to automl_classifier in Azure Machine Learning python SDK runs into EmptyDataException Error",
        "Question_body":"<p>I am trying to run <strong>azure automl on my local PC<\/strong> (MacOS Catalina: 10.15.6) in conda environment with the setup mentioned in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-environment#local\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-environment#local<\/a><\/p>\n<p>The aim is to find the best model and parameters using azure automl for binary <strong>color<\/strong> image classification.<\/p>\n<p><strong>Training Data Sample:<\/strong><\/p>\n<pre><code>train_data_img = train_data.copy()\nfor index in tqdm(train_data.index):\n    img_file = train_data_img['image_file'][index]\n    image = cv2.imread(img_file)\n    img_resized = cv2.resize(image, (256, 256))\n    img_numpy = np.array(img_resized)\n    train_data_img['np_image'][index] = img_numpy\n\nprint(train_data_img.head())\ntype(train_data_img)\n<\/code><\/pre>\n<blockquote>\n<pre><code>                                               np_image  y\n474   [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  0\n2121  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  0\n1836  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  1\n94    [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  0\n663   [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  0\n<\/code><\/pre>\n<p>pandas.core.frame.DataFrame<\/p>\n<\/blockquote>\n<p><strong>Code to run automl in local PC:<\/strong><\/p>\n<pre><code>automl_classifier=AutoMLConfig(\n    task='classification',\n    primary_metric='AUC_weighted',\n    experiment_timeout_minutes=5,\n    blocked_models=['XGBoostClassifier'],\n    training_data=train_data_img,\n    label_column_name=label,\n    n_cross_validations=2)\n\nfrom azureml.core.experiment import Experiment\n\nws = Workspace.from_config()\n\n# Choose a name for the experiment and specify the project folder.\nexperiment_name = 'automl-classification'\nproject_folder = '.\/sample_projects\/automl-classification'\n\nexperiment = Experiment(ws, experiment_name)\n\nrun = experiment.submit(automl_config, show_output=True)\n<\/code><\/pre>\n<blockquote>\n<pre><code>~\/.conda\/envs\/myenv\/lib\/python3.7\/site-packages\/azureml\/automl\/runtime\/training_utilities.py\n<\/code><\/pre>\n<p>in _extract_user_data(user_script)\n2211         raise EmptyDataException(\n2212             &quot;Get data script was not defined and X,&quot;\n-&gt; 2213             &quot; y inputs were not provided.&quot;, has_pii=False)\n2214     try:\n2215         output = user_script.get_data()         # type: Union[Dict[str, Any], Tuple[Any, Any, Any, Any]]<\/p>\n<pre><code>EmptyDataException: EmptyDataException:\n  Message: Get data script was not defined and X, y inputs were not provided.\n  InnerException: None\n  ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;InvalidData&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;EmptyData&quot;\n            }\n        },\n        &quot;message&quot;: &quot;Get data script was not defined and X, y inputs were not provided.&quot;\n    }\n}\n<\/code><\/pre>\n<\/blockquote>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2020-08-19 08:57:37.83 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python-3.x|azure|azure-machine-learning-studio|azure-sdk-python",
        "Question_view_count":146,
        "Owner_creation_date":"2018-12-20 13:04:14.09 UTC",
        "Owner_last_access_date":"2022-09-23 06:56:23.127 UTC",
        "Owner_location":null,
        "Owner_reputation":170,
        "Owner_up_votes":113,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-08-20 05:23:15.527 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML webservice columns returned no as expected",
        "Question_body":"<p>I have created an experiment to help categorise a description, this all works fine. However it does not tell me the weightings. When on the studio website I click test on the experiment and call the service I get back a JSON blob including lots of useful data such as the column names and weightings. When I actually use the web service from my app using C# the returned json does not include this information?<\/p>\n\n<p>Any reason for this?<\/p>\n\n<p>thanks\nAndy<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-03 12:10:20.837 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":94,
        "Owner_creation_date":"2011-03-18 10:47:07.763 UTC",
        "Owner_last_access_date":"2021-11-24 21:38:12.78 UTC",
        "Owner_location":"East Midlands, UK",
        "Owner_reputation":1627,
        "Owner_up_votes":59,
        "Owner_down_votes":8,
        "Owner_views":150,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Unable to register an ONNX model in azure machine learning service workspace",
        "Question_body":"<p>I was trying to register an ONNX model to Azure Machine Learning service workspace in two different ways, but I am getting errors I couldn't solve.<\/p>\n\n<p><strong>First method: Via Jupyter Notebook and python Script<\/strong><\/p>\n\n<pre><code>model = Model.register(model_path = MODEL_FILENAME,\n                       model_name = \"MyONNXmodel\",\n                       tags = {\"onnx\":\"V0\"},\n                       description = \"test\",\n                       workspace = ws)\n<\/code><\/pre>\n\n<p>The error is : <strong>HttpOperationError: Operation returned an invalid status code 'Service invocation failed!Request: GET <a href=\"https:\/\/cert-westeurope.experiments.azureml.net\/rp\/workspaces\" rel=\"nofollow noreferrer\">https:\/\/cert-westeurope.experiments.azureml.net\/rp\/workspaces<\/a>'<\/strong><\/p>\n\n<p><strong>Second method: Via Azure Portal<\/strong>\n<a href=\"https:\/\/i.stack.imgur.com\/0BJrO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0BJrO.png\" alt=\"Error: Create model &quot;MyONNXmodel&quot;: ajax error 413.\"><\/a><\/p>\n\n<p>Anyone can help please?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2019-03-08 13:22:25.573 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"azure|onnx|azure-machine-learning-service",
        "Question_view_count":244,
        "Owner_creation_date":"2017-01-10 13:34:39.08 UTC",
        "Owner_last_access_date":"2022-09-22 15:43:10.21 UTC",
        "Owner_location":"Sfax, Tunisie",
        "Owner_reputation":54,
        "Owner_up_votes":44,
        "Owner_down_votes":0,
        "Owner_views":55,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-04-08 01:32:28.163 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Installing textshape package for Microsoft R Open 3.4.4 on Azure ML Studio",
        "Question_body":"<p>I'm trying to use the R <code>sentimentr<\/code> package on Azure ML Studio. As this package is not supported, I'm trying to install it and its dependencies as described <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/execute-r-script#bkmk_AddingANewPackage\" rel=\"nofollow noreferrer\">in the documentation<\/a>.<\/p>\n\n<p>The steps that I have performed are:<\/p>\n\n<ul>\n<li><p>downloaded Windows binaries from the R Open 3.4.4 snapshot at <a href=\"https:\/\/mran.microsoft.com\/timemachine\" rel=\"nofollow noreferrer\">CRAN time machine<\/a><\/p>\n\n<ul>\n<li><code>sentimentr_2.2.3.zip<\/code><\/li>\n<li><code>syuzhet_1.0.4.zip<\/code><\/li>\n<li><code>textclean_0.6.3.zip<\/code><\/li>\n<li><code>lexicon_0.7.4.zip<\/code><\/li>\n<li><code>textshape_1.5.0.zip<\/code> <\/li>\n<\/ul><\/li>\n<li><p>zipped those zip files into a zipped folder <code>packages.zip<\/code><\/p><\/li>\n<li>uploaded <code>packages.zip<\/code> as a dataset to Microsoft Azure ML Studio<\/li>\n<\/ul>\n\n<p>In my ML experiment I connect the <code>packages.zip<\/code> dataset to the \"Script Bundle (Zip)\" input port on \"Execute R Script\" and include this code:<\/p>\n\n<pre><code># install R package contained in src  \ninstall.packages(\"src\/lexicon_0.7.4.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/textclean_0.6.3.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/textshape_1.5.0.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/syuzhet_1.0.4.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\ninstall.packages(\"src\/sentimentr_2.2.3.zip\", \n                 lib = \".\", \n                 repos = NULL, \n                 verbose = TRUE)  \n\n# load libraries\nlibrary(sentimentr, lib.loc = \".\", verbose = TRUE)\n<\/code><\/pre>\n\n<p>The experiment runs successfully, until I include a function from <code>sentimentr<\/code>:<\/p>\n\n<pre><code>mydata &lt;- mydata %&gt;%\n  get_sentences() %&gt;%\n  sentiment()\n<\/code><\/pre>\n\n<p>This gives the error:<\/p>\n\n<blockquote>\n  <p>there is no package called 'textshape'<\/p>\n<\/blockquote>\n\n<p>Which is difficult to understand given that the output log does not indicate an issue with the packages:<\/p>\n\n<pre><code>[Information]         The following files have been unzipped for sourcing in path=[\"src\"]:\n[Information]                           Name  Length                Date\n[Information]         1 sentimentr_2.2.3.zip 3366245 2019-08-07 14:57:00\n[Information]         2    syuzhet_1.0.4.zip 2918474 2019-08-07 15:05:00\n[Information]         3  textclean_0.6.3.zip 1154814 2019-08-07 15:13:00\n[Information]         4    lexicon_0.7.4.zip 4551995 2019-08-07 15:17:00\n[Information]         5  textshape_1.5.0.zip  463095 2019-08-07 15:42:00\n[Information]         Loading objects:\n[Information]           port1\n[Information]         [1] \"Loading variable port1...\"\n[Information]         package 'lexicon' successfully unpacked and MD5 sums checked   \n[Information]         package 'textclean' successfully unpacked and MD5 sums checked\n[Information]         package 'textshape' successfully unpacked and MD5 sums checked\n[Information]         package 'syuzhet' successfully unpacked and MD5 sums checked\n[Information]         package 'sentimentr' successfully unpacked and MD5 sums checked\n<\/code><\/pre>\n\n<p>Has anyone seen this, or similar issues? Is it possible that \"successfully unpacked\" is not the same as successfully installed and usable?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-07 23:12:10.07 UTC",
        "Question_favorite_count":0.0,
        "Question_score":2,
        "Question_tags":"r|package|azure-machine-learning-studio",
        "Question_view_count":157,
        "Owner_creation_date":"2009-04-10 14:49:12.693 UTC",
        "Owner_last_access_date":"2022-09-23 09:38:34.63 UTC",
        "Owner_location":"Sydney, Australia",
        "Owner_reputation":30129,
        "Owner_up_votes":685,
        "Owner_down_votes":51,
        "Owner_views":2937,
        "Answer_body":"<p>I can now answer my own question thanks to <a href=\"https:\/\/twitter.com\/bryan_hepworth\/status\/1159432174225055749\" rel=\"nofollow noreferrer\">a hint on Twitter<\/a> from @bryan_hepworth.<\/p>\n\n<p>The R packages were installed correctly, but not in the standard library location. So when a function from <code>sentimentr<\/code> runs, R tries to load the dependency package <code>textshape<\/code>:<\/p>\n\n<pre><code>library(textshape)\n<\/code><\/pre>\n\n<p>Which of course does not exist <em>in the standard location<\/em> as Azure ML does not support it.<\/p>\n\n<p>The solution is to load <code>textshape<\/code> explicitly from its installed location:<\/p>\n\n<pre><code>library(textshape, lib.loc = \".\")\n<\/code><\/pre>\n\n<p>So the solution is: explicitly load packages that you installed at the start of your R code, rather than letting R try to load them as dependencies, which will fail.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-08-08 22:14:34.167 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Error when deploying Azure ML model to modelmanagement",
        "Question_body":"<p>When executing the command below: <\/p>\n\n<p><code>az ml model register -m &lt;pkl name&gt;.pkl -n &lt;model name&gt; -d \"dummy model\" --debug --verbose<\/code><\/p>\n\n<p>I get the error stating that the URL cannot be connected to. The verbose message does not show any error before the one below. I can confirm that the model management account and environments have been set. <\/p>\n\n<p>I am using the Visual Studio subscription to test out some functionality. Any help is appreciated!<\/p>\n\n<pre><code>{\n    \"Azure-cli-ml Version\": \"0.1.0a27.post3\",\n    \"Error\": \"Error connecting to https:\/\/australiaeast.modelmanagement.azureml.net\/api\/subscriptions\/ad19a4a2-ed65-4574-aec3-e247c4d96efd\/resourceGroups\/rcity-rg-bi-001-azureml-3797f\/accounts\/rcity-bi-mlexpmgmt-002\/models.\"\n}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-23 01:00:22.223 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":129,
        "Owner_creation_date":"2017-12-22 08:33:21.027 UTC",
        "Owner_last_access_date":"2021-03-10 06:45:27.53 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-05-23 08:34:02.137 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"TabularDataset \"topandasdataframe()\" - does not support pandas errorbadlines?",
        "Question_body":"<p>I am trying to skip lines that produces more columns than intended while loading to a pandas dataframe.<\/p>\n<p>Like this Pandas Option: When error_bad_lines = False, pandas will skip these lines.<\/p>\n<p>How to achieve this with to-pandas-dataframe()?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/aS9gF.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/aS9gF.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#to-pandas-dataframe-on-error--null---out-of-range-datetime--null--\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#to-pandas-dataframe-on-error--null---out-of-range-datetime--null--<\/a><\/p>\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-17 05:14:27.717 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":96,
        "Owner_creation_date":"2019-11-28 11:07:18.203 UTC",
        "Owner_last_access_date":"2022-09-23 21:26:15.933 UTC",
        "Owner_location":null,
        "Owner_reputation":350,
        "Owner_up_votes":19,
        "Owner_down_votes":1,
        "Owner_views":34,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"how to predict more multiple values in azure ml?",
        "Question_body":"<p>I am creating Azure ML experienment to predict multiple values. but in azure ml we can not train a model to predict multiple values. my question is how to bring multiple trained models in single experienment and create webout put that gives me multiple prediction.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-02-01 10:13:16.49 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":666,
        "Owner_creation_date":"2018-02-01 09:59:53.607 UTC",
        "Owner_last_access_date":"2018-05-07 08:02:09.147 UTC",
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-02-07 09:27:38.06 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"is it possible to use service principal for authentication to access ml_client?",
        "Question_body":"<p>The documentation <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk<\/a> shows that you can use DefaultAzureCredential and InteractiveBrowserCredential for\nml_client. is there a way I can use service principal instead?<\/p>\n<pre><code>#code from docs\n# Handle to the workspace\nfrom azure.ai.ml import MLClient\n\n# Authentication package\nfrom azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n\ntry:\n    credential = DefaultAzureCredential()\n    # Check if given credential can get token successfully.\n    credential.get_token(&quot;https:\/\/management.azure.com\/.default&quot;)\nexcept Exception as ex:\n    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n    credential = InteractiveBrowserCredential()\n\n# Get a handle to the workspace\nml_client = MLClient(\n    credential=credential,\n    subscription_id=&quot;&lt;SUBSCRIPTION_ID&gt;&quot;,\n    resource_group_name=&quot;&lt;RESOURCE_GROUP&gt;&quot;,\n    workspace_name=&quot;&lt;AML_WORKSPACE_NAME&gt;&quot;,\n)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-27 15:26:01.283 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":129,
        "Owner_creation_date":"2020-01-14 14:47:36.57 UTC",
        "Owner_last_access_date":"2022-09-21 12:27:07.623 UTC",
        "Owner_location":null,
        "Owner_reputation":129,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How can I predict the next result?",
        "Question_body":"<p>I've been playing around with Azure ML for \u00e5 couple of days... but I can't seem to get to a point with the right algorithms to predict the <em>next value<\/em> in a sorted list.<\/p>\n\n<p>In Excel I made this simple list of 2000 points:<\/p>\n\n<pre><code>ITERATION,DATA,LABEL\n1,1,SMALLER\n2,2,SMALLER\n3,3,BIGGER\n4,4,BIGGER\n5,5,BIGGER\n6,6,BIGGER\n7,7,BIGGER\n8,1,SMALLER\n9,2,SMALLER\n10,3,BIGGER\n11,4,BIGGER\n12,5,BIGGER\n13,6,BIGGER\n14,7,BIGGER\n...\n<\/code><\/pre>\n\n<p>Where label is defined as<\/p>\n\n<pre><code>If ITERATION &lt; 500 then LABEL &lt; 3 = \"SMALLER\", else \"BIGGER\"\nIf ITERATION &lt; 1000 then LABEL &lt; 4 = \"SMALLER\", else \"BIGGER\"\nIf ITERATION &lt; 1500 then LABEL &lt; 5 = \"SMALLER\", else \"BIGGER\"\nIf ITERATION &lt; 2000 then LABEL &lt; 6 = \"SMALLER\", else \"BIGGER\"\n<\/code><\/pre>\n\n<p>I've got a decent prediction and published a web service, but the service wants the input ITERATION and DATA to \"predict\" LABEL.<\/p>\n\n<p>Is there a way I can train the model and at \"runtime\" pass in a data series and get the predicted next value?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2016-12-14 20:36:59.913 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":110,
        "Owner_creation_date":"2010-03-04 13:38:58.32 UTC",
        "Owner_last_access_date":"2017-10-20 15:38:01.653 UTC",
        "Owner_location":"Norway",
        "Owner_reputation":13032,
        "Owner_up_votes":516,
        "Owner_down_votes":8,
        "Owner_views":1004,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2016-12-15 07:14:30.107 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to set learner type for Python Model in Azure Machine Learning Designer?",
        "Question_body":"<p>I am testing Azure Machine Learning Designer by having a custom Python Model (a simple kNN classification). I would like to tune the value of 'k' and get the best performing model but \"Tune Model Hyperparameters\" module gives following error when giving output from my \"Create Python Model\" as input.<\/p>\n\n<pre><code>ModuleExceptionMessage:LearnerTypesNotCompatible: Got incompatible learner type: \"None\". Expected learner types are: \"(&lt;TaskType.BinaryClassification: 1&gt;, &lt;TaskType.MultiClassification: 2&gt;, &lt;TaskType.Regression: 3&gt;)\".\n<\/code><\/pre>\n\n<p>How I can set the learner type of my own Python model? Is it even possible? Should I just code the parameter tuning myself with \"Execute Python Script\"-module?<\/p>\n\n<p>My \"Create Python model\"-module script:<\/p>\n\n<pre><code>import pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclass AzureMLModel:\n    def __init__(self, k = 3):\n        self.model = KNeighborsClassifier(n_neighbors = k)\n        self.feature_column_names = list()\n\n    def train(self, df_train, df_label):\n        self.feature_column_names = df_train.columns.tolist()\n        self.model.fit(df_train, df_label)\n\n    def predict(self, df):\n        return pd.DataFrame({'Scored Labels': self.model.predict(df[self.feature_column_names])})\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-16 11:17:27.567 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":108,
        "Owner_creation_date":"2020-06-16 10:55:49.617 UTC",
        "Owner_last_access_date":"2020-06-25 14:16:32.02 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-06-16 11:22:11.683 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Service writing to AzureDataLakeGen2Datastore",
        "Question_body":"<p>I registered an azure storage account gen2 where datalake filesystem enabled as a datastore as<\/p>\n<pre><code>    _ = Datastore.register_azure_data_lake_gen2(workspace='xxx',\n                                                datastore_name='store-identifier',\n                                                filesystem= 'container',\n                                                account_name= 'xxx',\n                                                subscription_id= 'xxx',\n                                                resource_group= 'xxx',\n                                                overwrite=1)\n<\/code><\/pre>\n<p>I tried uploading files to this using<\/p>\n<pre><code> destination_store = Datastore.get(workspace, 'store-identifier');\n destination_store.upload(\n     src='data\/', target_path=&quot;data_science\/&quot;, overwrite=True\n )\n<\/code><\/pre>\n<blockquote>\n<p>AzureDataLakeGen2Datastore' object has no attribute 'upload'<\/p>\n<\/blockquote>\n<p>When i opened the underlying <code>AzureDataLakeGen2Datastore<\/code> it mentions that the class does not support an upload and asks users to use a <code>Dataset<\/code> instance to upload data. However  I tried both <code>Dataset.Tabular.upload<\/code> and <code>Dataset.Files.upload<\/code> however neither of them support support this functionality<\/p>\n<p>How should i proceed further. Is this functionality not yet supported via azure machine learning ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-19 04:00:07.487 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":500,
        "Owner_creation_date":"2010-04-12 17:27:26.887 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:17.55 UTC",
        "Owner_location":"United States",
        "Owner_reputation":9826,
        "Owner_up_votes":1723,
        "Owner_down_votes":15,
        "Owner_views":1238,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-07-19 04:05:21.25 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"In Azure ML Studio, score model doesn't return predicted values from an R model",
        "Question_body":"<p>I built a multiclass SVM model in R and used Create R model module from azure to train and predict my testing dataset. Here are the trainer and the score R scripts.<\/p>\n\n<p><strong>Trainer R script:<\/strong> <\/p>\n\n<pre><code>library(e1071)\nfeatures &lt;- get.feature.columns(dataset)\nlabels   &lt;- as.factor(get.label.column(dataset))\ntrain.data &lt;- data.frame(features, labels)\nfeature.names &lt;- get.feature.column.names(dataset)\nnames(train.data) &lt;- c(feature.names, \"Class\")\nmodel &lt;- svm(Class ~ . , train.data)\n<\/code><\/pre>\n\n<p><strong>Scores R script:<\/strong><\/p>\n\n<pre><code>library(e1071)    \nclasses &lt;- predict(model, dataset)\nclasses &lt;- as.factor(classes)\nres &lt;- data.frame(classes, probabilities = 0.5)\nprint(str(res))\nprint(res)\nscores &lt;- res\n<\/code><\/pre>\n\n<p>Note in my code, I hardcoded the probability values to simplify the code.<\/p>\n\n<p>Here is my component design in Azure: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/hjMC4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/hjMC4.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When I run the experiment, all the components work fine. However, in the score model, the scored dataset port does not show the predicted values. It only shows feature values from the testing dataset. I checked the output log of <em>Score model<\/em> and I could see the model has nicely predicted the testing data (note I added print commands in the Scores R script). But this is not enough and I need the prediction returned from the score model so I can pass it via API.<\/p>\n\n<p>Has anyone faced this issue before?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-08-06 07:14:53.247 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio|ml-studio",
        "Question_view_count":657,
        "Owner_creation_date":"2017-07-27 00:12:26.137 UTC",
        "Owner_last_access_date":"2020-11-19 13:36:00.497 UTC",
        "Owner_location":"Australia",
        "Owner_reputation":37,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>I found an answer for this. In fact, I cannot see the result in the outcome of the scoring model but when I linked it to a <em>select column in the dataset<\/em> module, I see the predicted columns there.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-08-15 00:59:57.823 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2018-08-06 13:07:27.647 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Access files in blob storage in R scripts in Azure Machine Learning?",
        "Question_body":"<p>What is the easy way to access (read and write) files in blob storage in R scripts in Azure Machine Learning?<\/p>\n\n<p>I can access files in blob storage in python scripts using azure modules, but there seems no easy way to access by R scripts.<\/p>\n\n<p>I tried to import Azure SMR as a zip file in the R script, but the importing all dependencies is very tough work,<\/p>\n\n<p><a href=\"https:\/\/github.com\/Microsoft\/AzureSMR\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Microsoft\/AzureSMR<\/a><\/p>\n\n<p>Any suggestion and help is appreciated.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-06-19 10:06:52.267 UTC",
        "Question_favorite_count":1.0,
        "Question_score":3,
        "Question_tags":"r|azure|azure-blob-storage|azure-machine-learning-studio",
        "Question_view_count":3803,
        "Owner_creation_date":"2017-06-16 06:45:45.243 UTC",
        "Owner_last_access_date":"2022-09-23 12:05:18.207 UTC",
        "Owner_location":null,
        "Owner_reputation":49,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Unable to upload statsmodels 0.9rc1 python package in Azure ML studio",
        "Question_body":"<p>I'm not able to upload statsmodels 0.9rc1 python package in Azure ML studio for Time series analysis.<\/p>\n\n<p>I have downloaded <a href=\"https:\/\/files.pythonhosted.org\/packages\/df\/6f\/df6cf5faecd8082ee23916ff45d396dfee5a1f17aa275da7bab4f5c8926a\/statsmodels-0.9.0rc1-cp36-cp36m-win_amd64.whl\" rel=\"nofollow noreferrer\">statsmodels 0.9rc1<\/a>, unzipped contents and added statsmodels folder and model.pkl file to zip folder.<\/p>\n\n<p>But, while uploading to Microsoft Azure ML studio it says <strong>failed to build schema and visualization<\/strong><\/p>\n\n<p>I'm using this external package in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/execute-python-scripts\" rel=\"nofollow noreferrer\">Execute Python script<\/a><\/p>\n\n<p>PS: I have succesfully uploaded packages like Adal, dateutils etc.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-09 10:14:06.857 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|azure|machine-learning|statsmodels|azure-machine-learning-studio",
        "Question_view_count":141,
        "Owner_creation_date":"2019-01-24 14:52:36.52 UTC",
        "Owner_last_access_date":"2022-09-23 08:24:06.773 UTC",
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":2907,
        "Owner_up_votes":354,
        "Owner_down_votes":2,
        "Owner_views":238,
        "Answer_body":"<p>I have switched to Azure Jupyter Notebook where I installed package using pip<\/p>\n\n<pre><code>!pip install statsmodels==0.9.0rc1\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-11-07 16:37:35.863 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2019-10-09 11:15:08.227 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to deploy multiple models to an endpoint using Azure Machine Learning CLI v2?",
        "Question_body":"<p>At the GA of <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/azure-machine-learning-release-notes-cli-v2#2022-05-24\" rel=\"nofollow noreferrer\">az ml cli v2<\/a>, we've been working on some POC using <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-deployment-managed-online\" rel=\"nofollow noreferrer\">yml online deployment<\/a> on top of managed endpoint and it all went well for single model, until when there's certain scenario where there is requirement to deploy multiple trained and registered models to one managed endpoint, it seems there is no documentations on how to achieve that.<\/p>\n<p>Previously using Python SDK, it was able to deploy list of models to AKS cluster.<\/p>\n<p>Checking if there's any limitation or could be some docs I might have missed?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-02 06:34:23.59 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-cli|azure-machine-learning-service",
        "Question_view_count":181,
        "Owner_creation_date":"2019-09-11 07:07:53.007 UTC",
        "Owner_last_access_date":"2022-09-15 16:01:06.153 UTC",
        "Owner_location":"Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia",
        "Owner_reputation":383,
        "Owner_up_votes":70,
        "Owner_down_votes":1,
        "Owner_views":35,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Read multiple CSV files in Azure ML Python Script",
        "Question_body":"<p>I have 4 csv files that are inputs to the python script in azure ML, but the widget has only 2 inputs for dataframes and the third for a zip file. I tried to put the csv files in a zipped folder and connect it to the third input for the script but that also did not work :\n<a href=\"https:\/\/i.stack.imgur.com\/FkxRE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FkxRE.png\" alt=\"Image of workspace\"><\/a><\/p>\n\n<p>I would like to know how to read multiple csv files in the python script.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2017-07-12 07:25:54.733 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|csv|azure|azure-machine-learning-studio",
        "Question_view_count":944,
        "Owner_creation_date":"2016-08-05 06:00:15.797 UTC",
        "Owner_last_access_date":"2022-08-19 20:38:01.503 UTC",
        "Owner_location":null,
        "Owner_reputation":596,
        "Owner_up_votes":72,
        "Owner_down_votes":3,
        "Owner_views":57,
        "Answer_body":"<p>Here's some more detail on the approach others have outlined above. Try replacing the code currently in the \"Execute Python Script\" module with the following:<\/p>\n\n<pre><code>import pandas as pd\nimport os\ndef azureml_main(dataframe1=None, dataframe2=None):\n    print(os.listdir('.'))\n    return(pd.DataFrame([]))\n<\/code><\/pre>\n\n<p>After running the experiment, click on the module. There should be a \"View output log\" link now in the right-hand bar. I get something like the following:<\/p>\n\n<pre><code>[Information]         Started in [C:\\temp]\n[Information]         Running in [C:\\temp]\n[Information]         Executing 4af67c05ba02417a980f6a16e84e61dc with inputs [] and generating outputs ['.maml.oport1']\n[Information]         Extracting Script Bundle.zip to .\\Script Bundle\n[Information]         File Name                                             Modified             Size\n[Information]         temp.csv                                       2016-05-06 13:16:56           52\n[Information]         [ READING ] 0:00:00\n[Information]         ['4af67c05ba02417a980f6a16e84e61dc.py', 'Script Bundle', 'Script Bundle.zip']\n<\/code><\/pre>\n\n<p>This tells me that the contents of my zip file have been extracted to the <code>C:\\temp\\Script Bundle<\/code> folder. In my case the zip file contained just one CSV file, <code>temp.csv<\/code>: your output would probably have four files. You may also have zipped a folder containing your four files, in which case the filepath would be one layer deeper. You can use the <code>os.listdir()<\/code> to explore your directory structure further if necessary.<\/p>\n\n<p>Once you think you know the full filepaths for your CSV files, edit your Execute Python Script module's code to load them, e.g.:<\/p>\n\n<pre><code>import pandas as pd\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    df = pd.read_csv('C:\/temp\/Script Bundle\/temp.csv')\n    # ...load other files and merge into a single dataframe...\n    return(df)\n<\/code><\/pre>\n\n<p>Hope that helps!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-07-18 21:12:02.17 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2017-07-12 09:13:57.7 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Ho do I call a webservice deployed in Azure Machine Learning Service?",
        "Question_body":"<p>I'm trying Azure Machine Learning Service for the first time. I worked on examples given by MS. I was able to develop in Python and deploy as web services. But I'm not able to use it outside the notebook or any application. Do I need API of that web service? If yes, where can I find it?<\/p>\n\n<p>I have not got anything to try on. I googled for different methods, but couldn't find relevant link. So I didn't try much there.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-04-04 11:48:47.737 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python-3.x|azure-machine-learning-service",
        "Question_view_count":163,
        "Owner_creation_date":"2018-12-20 07:13:19.703 UTC",
        "Owner_last_access_date":"2021-02-01 05:49:25.62 UTC",
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-12-23 01:23:12.4 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Is there a way to create datasets in AuzureML Studio from a tabular model or PowerBi datasets?",
        "Question_body":"<p>My goal is to import data from a Tabular Model (via MDX or DAX) or PowerBi dataset into AzureML Studio to work with.<br \/>\nUnfortunately I can't find a way to connect to it.<\/p>\n<p>Another alternative would be to establish a connection with pyadomd (<a href=\"https:\/\/pypi.org\/project\/pyadomd\/\" rel=\"nofollow noreferrer\">https:\/\/pypi.org\/project\/pyadomd\/<\/a>). However, I am having problems installing it here as well: ERROR: Failed building wheel for pythonnet.<\/p>\n<p>Has anyone already had experience with this or is there a different approach I'm just not aware of?<\/p>\n<p>Thank you very much.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-20 08:44:42.147 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":70,
        "Owner_creation_date":"2017-06-27 13:41:14.253 UTC",
        "Owner_last_access_date":"2022-08-17 07:57:17.643 UTC",
        "Owner_location":null,
        "Owner_reputation":89,
        "Owner_up_votes":21,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-10-20 09:01:16.58 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How does Azure web service deployment work locally?",
        "Question_body":"<p>Azure ML provides client libraries (e.g. azureml for Python) for dataset management and model deploying. From what I understand, the custom algorithm would be serialized as a Pickle file, but I'm not sure what happens after that. If I have a custom model with a deep NN architecture and set up a web service for training and another for scoring, do I still need the machine that the model was developed on for the web services to run? I found this on the azureml documentation that was helpful:<\/p>\n<blockquote>\n<p>If a function has no source file associated with it (for example, you're developing inside of a REPL environment) then the functions byte code is serialized. If the function refers to any global variables those will also be serialized using Pickle. In this mode all of the state which you're referring to needs to be already defined (e.g. your published function should come after any other functions you are calling).<\/p>\n<p>If a function is saved on disk then the entire module the function is defined in will be serialized and re-executed on the server to get the function back. In this mode the entire contents of the file is serialized and the order of the function definitions don't matter.<\/p>\n<\/blockquote>\n<p>What if the function uses a library like TensorFlow or Keras? Can someone explain what happens after the Pickle model is created?<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-07-05 19:40:59.027 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python-3.x|azure|pickle|azure-machine-learning-studio",
        "Question_view_count":126,
        "Owner_creation_date":"2012-05-27 14:00:53.383 UTC",
        "Owner_last_access_date":"2020-12-22 00:05:39.673 UTC",
        "Owner_location":"Minneapolis, MN, United States",
        "Owner_reputation":115,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":"<p>You need to take the model.pkl file, zip it, and upload it into Azure Machine Learning Studio as a new dataset. Then add the python module and connect it to your newly generated zip.<\/p>\n\n<p>You can now use it inside the AML Studio experiment. To use the model add the following code in your python module:<\/p>\n\n<pre><code>import pandas as pd\nimport sys\nimport pickle\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    sys.path.insert(0,\".\\Script Bundle\")\n    model = pickle.load(open(\".\\Script Bundle\\model.pkl\", 'rb'))\n    pred = model.predict(dataframe1)\n    return pd.DataFrame([pred[0]]),\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/blogs.technet.microsoft.com\/uktechnet\/2018\/04\/25\/deploying-externally-generated-pythonr-models-as-web-services-using-azure-machine-learning-studio\/\" rel=\"nofollow noreferrer\">You may find this post useful<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2018-07-26 14:13:52.913 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Missing data in test data for Azure MachineforMachine Learning",
        "Question_body":"<p>I am new to Azure Machine Learning. I have created a training experiment where training data has some missing values. The logic for handling missing data and few other transformations is in Python code which works on this data.<\/p>\n\n<p>Now I want the same for test data. I have deployed the experiment as web service. So, the schema is produced for input and output data (all are Numeric fields).<\/p>\n\n<p>Two questions:\n1. It asks me to define the label for test data as well, otherwise it gives inconsistent number of columns error since label column is missing in the test data<br>\n2. I have some missing data in test data, which ideally Python script in the experiment should take care. But it gives me the following error because of schema.<\/p>\n\n<pre><code>The request failed with status code: 400\nContent-Length: 323\nContent-Type: application\/json; charset=utf-8\nServer: Microsoft-HTTPAPI\/2.0\nDate: Thu, 21 Jan 2016 11:44:49 GMT\nConnection: close\n\n{u'error': {u'message': u'Invalid argument provided.', u'code': 'BadArgument', u'details': [{u'message': u'Parsing of input vector failed.  Verify the input vector has the correct number of columns and data types.  Additional details: Value was either too large or too small for an Int32..', u'code': u'InputParseError', u'target': u'input1'}]}}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2016-01-21 11:57:44.1 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":796,
        "Owner_creation_date":"2013-06-26 11:14:58.297 UTC",
        "Owner_last_access_date":"2022-05-18 20:31:46.597 UTC",
        "Owner_location":"Bellevue, WA, United States",
        "Owner_reputation":757,
        "Owner_up_votes":5,
        "Owner_down_votes":7,
        "Owner_views":125,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2016-02-01 04:20:14.053 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"getting token for Azure ML",
        "Question_body":"<p>I'm quiet new to Azure. I have deployed a model using on Azure ML studio to a webservice which need token to be authenticated. I can get the token using Python SDK. but I need to get the token using postman. for this purpose I register and App in Azure Active Directory to get the access token using it but this token is not a valid token for Azure ML and when I use this token to call my web service it will give &quot;Unauthorized, invalid AAD token specified&quot;. Does anyone have any suggestion about this problem?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-09 13:26:22.37 UTC",
        "Question_favorite_count":0.0,
        "Question_score":0,
        "Question_tags":"azure-active-directory|azure-machine-learning-service",
        "Question_view_count":293,
        "Owner_creation_date":"2022-03-09 13:16:11.26 UTC",
        "Owner_last_access_date":"2022-04-19 13:22:29.093 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How can I mark an Azure Dataset as a time series dataset reading from a parquet folder with date partitions?",
        "Question_body":"<p>I would like to create a Time series dataset from a folder that contains parquet files this way:<\/p>\n<ul>\n<li>timestamp=2018-01-06<\/li>\n<li>timestamp=2018-01-07<\/li>\n<\/ul>\n<p>How can I make Azure Dataset, through the GUI, recognises the timestamp partition as a date and mark my dataset as a time series dataset?<\/p>\n<p>It is supposed to be automatic, but it doesn't work.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-09-30 14:04:18.457 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"parquet|azure-machine-learning-studio",
        "Question_view_count":109,
        "Owner_creation_date":"2015-02-11 07:34:40.283 UTC",
        "Owner_last_access_date":"2022-09-23 14:32:37.963 UTC",
        "Owner_location":"Lyon, France",
        "Owner_reputation":457,
        "Owner_up_votes":19,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Answer_body":"<p>Thanks for reaching out to us.<\/p>\n<p>In Azure Machine Learning Studio, you would need to setup partition format similar to python SDK, as follows, assuming your data path is &quot;timeseries\/timestamp=2020-01-01\/data.parquet&quot;:\n<a href=\"https:\/\/i.stack.imgur.com\/HwYfF.png\" rel=\"nofollow noreferrer\">Set up partition format when creating time series dataset<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-10-05 17:58:05.457 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":3.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Machine Learning Suggestions",
        "Question_body":"<p>I have data of a lot of students who got selected by some colleges based on their marks. Iam new to machine Learning. Can I have some suggestions how can I add Azure Machine Learning for predicting the colleges that they can get based on their marks<\/p>",
        "Question_answer_count":8,
        "Question_comment_count":0,
        "Question_creation_date":"2015-11-18 18:31:03.857 UTC",
        "Question_favorite_count":1.0,
        "Question_score":7,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":851,
        "Owner_creation_date":"2013-06-30 07:02:12.52 UTC",
        "Owner_last_access_date":"2022-01-11 18:27:32.863 UTC",
        "Owner_location":"Hyderabad",
        "Owner_reputation":562,
        "Owner_up_votes":27,
        "Owner_down_votes":2,
        "Owner_views":75,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2016-02-01 04:21:37.667 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How can I troubleshoot my Azure ML service deployment?",
        "Question_body":"<p>I am trying out <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-service\/\" rel=\"nofollow noreferrer\">Azure Machine Learning Service<\/a> to deploy a ML model as web service.<\/p>\n\n<p>I have already <a href=\"https:\/\/stackoverflow.com\/a\/55281703\/4240413\">registered a model<\/a> and now would like to deploy it as web service following the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml#deploy-in-container-instances\" rel=\"nofollow noreferrer\">guide<\/a> using Azure (Python) Notebooks.<\/p>\n\n<p>The step<\/p>\n\n<pre><code> service = Webservice.deploy_from_model(my-model-svc',\n                                   deployment_config=aciconfig,\n                                   models=[model],\n                                   image_config=image_config)\n<\/code><\/pre>\n\n<p>fails for me with<\/p>\n\n<blockquote>\n  <p>Creating image<br>\n  Image creation operation finished for image my-model-svc:5, operation \"Succeeded\" Creating service<br>\n  Running.<br>\n  FailedACI service creation operation finished, operation<br>\n  \"Failed\" Service creation polling reached terminal state, current\n  service state: Transitioning Service creation polling reached terminal\n  state, unexpected response received.<\/p>\n<\/blockquote>\n\n<p>Not sure about what could be the root cause, as (AFAIK) I have no ways to access logs of the deployment in Azure portal.<\/p>\n\n<p>Can someone shed some light on this?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-03-21 16:26:13.69 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|deployment|azureportal|azure-machine-learning-service",
        "Question_view_count":1236,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_location":"Verona, VR, Italy",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":"<p>I think that your <code>init<\/code> function is failing. I would first try to isolate the image creation from the image deployment, and just test the image first:<\/p>\n\n<ul>\n<li>Create the image first, it's very much ok if do it through the interface<\/li>\n<li>Pull the image locally with Docker (for this you'll need <a href=\"https:\/\/www.docker.com\" rel=\"nofollow noreferrer\">Docker<\/a> and the <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/install-azure-cli?view=azure-cli-latest\" rel=\"nofollow noreferrer\">Azure CLI<\/a> installed):<\/li>\n<\/ul>\n\n<pre class=\"lang-python prettyprint-override\"><code>az acr login -n &lt;container-registry&gt;\ndocker run -p 8000:5001  &lt;container-registry&gt;.azurecr.io\/&lt;image-name&gt;:&lt;image-version&gt;\n# basically, the entire image location, see pic below\n<\/code><\/pre>\n\n<ul>\n<li>test the image locally, it listens on the 8000 port:<\/li>\n<\/ul>\n\n<pre><code>POST http:\/\/localhost:8000\/score\nContent-Type: application\/json\n<\/code><\/pre>\n\n<ul>\n<li>if this works deploy it on ACI <\/li>\n<\/ul>\n\n<p><code>&lt;container-registry&gt;<\/code> is the name of the <code>Container Registry<\/code> associated with the ML Workspace, you can also extract it from the image location, taking care to remove everything after the first dot:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/W6YYj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/W6YYj.png\" alt=\"image location\"><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2019-03-21 19:44:15.297 UTC",
        "Answer_last_edit_date":"2019-04-09 16:44:35.377 UTC",
        "Answer_score":3.0,
        "Question_last_edit_date":"2019-05-30 08:26:43.203 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to save your fitted transformer into blob, so your prediction pipeline can use it in AML Service?",
        "Question_body":"<p>I am building a data transformation and training pipeline on Azure Machine Leaning Service. I'd like to save my fitted transformer (e.g. tf-idf) to the blob, so my prediction pipeline can later access it. <\/p>\n\n<pre><code>transformed_data = PipelineData(\"transformed_data\", \n                               datastore = default_datastore,\n                               output_path_on_compute=\"my_project\/tfidf\")\n\nstep_tfidf = PythonScriptStep(name = \"tfidf_step\",\n                              script_name = \"transform.py\",\n                              arguments = ['--input_data', blob_train_data, \n                                           '--output_folder', transformed_data],\n                              inputs = [blob_train_data],\n                              outputs = [transformed_data],\n                              compute_target = aml_compute,\n                              source_directory = project_folder,\n                              runconfig = run_config,\n                              allow_reuse = False)\n\n<\/code><\/pre>\n\n<p>The above code saves the transformer to a current run's folder, which is dynamically generated during each run. <\/p>\n\n<p>I want to save the transformer to a fixed location on blob, so I can access it later, when calling a prediction pipeline.<\/p>\n\n<p>I tried to use an instance of <code>DataReference<\/code> class as <code>PythonScriptStep<\/code> output, but it results in an error: \n<code>ValueError: Unexpected output type: &lt;class 'azureml.data.data_reference.DataReference'&gt;<\/code> <\/p>\n\n<p>It's because <code>PythonScriptStep<\/code> only accepts <code>PipelineData<\/code> or <code>OutputPortBinding<\/code> objects as outputs.<\/p>\n\n<p>How could I save my fitted transformer so it's later accessible by any aribitraly process (e.g. my prediction pipeline)?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-12 09:11:16.657 UTC",
        "Question_favorite_count":1.0,
        "Question_score":3,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":1056,
        "Owner_creation_date":"2017-03-23 13:26:01.927 UTC",
        "Owner_last_access_date":"2022-09-22 20:27:37.72 UTC",
        "Owner_location":"Tel Aviv",
        "Owner_reputation":83,
        "Owner_up_votes":30,
        "Owner_down_votes":0,
        "Owner_views":56,
        "Answer_body":"<p>Another solution is to pass <code>DataReference<\/code> as an input to your <code>PythonScriptStep<\/code>. <\/p>\n\n<p>Then inside <code>transform.py<\/code> you're able to read this <code>DataReference<\/code> as a command line argument. <\/p>\n\n<p>You can parse it and use it just as any regular path to save your vectorizer to.<\/p>\n\n<p>E.g. you can:<\/p>\n\n<pre><code>step_tfidf = PythonScriptStep(name = \"tfidf_step\",\n                              script_name = \"transform.py\",\n                              arguments = ['--input_data', blob_train_data, \n                                           '--output_folder', transformed_data,\n                                           '--transformer_path', trained_transformer_path],\n                              inputs = [blob_train_data, trained_transformer_path],\n                              outputs = [transformed_data],\n                              compute_target = aml_compute,\n                              source_directory = project_folder,\n                              runconfig = run_config,\n                              allow_reuse = False)\n<\/code><\/pre>\n\n<p>Then inside your script (<code>transform.py<\/code> in the example above) you can e.g.:<\/p>\n\n<pre><code>import argparse\nimport joblib as jbl\nimport os\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--transformer_path', dest=\"transformer_path\", required=True)\nargs = parser.parse_args()\n\ntfidf = ### HERE CREATE AND TRAIN YOUR VECTORIZER ###\n\nvect_filename = os.path.join(args.transformer_path, 'my_vectorizer.jbl')\n\n<\/code><\/pre>\n\n<hr>\n\n<p>EXTRA: The third way would be to just register the vectorizer as another model in your workspace. You can then use it exactly as any other registered model. (Though this option does not involve explicit writing to blob - as specified in the question above)<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-07-08 11:40:40.653 UTC",
        "Answer_last_edit_date":"2020-01-10 21:39:12.197 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML studio really slow",
        "Question_body":"<p>I had been using Azure ML studio for a while now and it was really fast but now when I try to unzip folders containing images around 3000 images using<\/p>\n<pre><code>!unzip &quot;file.zip&quot; -d &quot;to unzip directory&quot;\n<\/code><\/pre>\n<p>it took more than 30 minutes and other activities(longer concatenation methods) also seem to take a long time even using numpy arrays. Wondering if it is something with configuration or other problems. I have tried switching locations, creating new resource groups, workspaces, changing computes(Both CPU and GPU).<\/p>\n<p>Compute and other set of current configurations can be seen on the image<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/GNZao.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/GNZao.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2021-04-12 11:45:31.02 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":185,
        "Owner_creation_date":"2020-03-05 10:31:00.763 UTC",
        "Owner_last_access_date":"2022-09-23 07:09:58.617 UTC",
        "Owner_location":"Ethiopia",
        "Owner_reputation":412,
        "Owner_up_votes":127,
        "Owner_down_votes":1,
        "Owner_views":43,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to resolve \"Service status is healthy, but test call return 'BadGateway'\" error in Azure ML Studio?",
        "Question_body":"<p>I am using Designer in Azure ML studio to build a prediction model. I keep getting the following error: &quot;Deploy: Service status is healthy, but test call return 'BadGateway'&quot; when I deploy a real-time inference of the model, even after using the designer model structure from the Diabetes tutorial. The model publishes and deploys &quot;successfully&quot; (endpoint and keys are created) but it can't be consumed.<\/p>\n<p>How can I resolve this issue?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-06 07:57:46.91 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"deployment|azure-machine-learning-studio",
        "Question_view_count":70,
        "Owner_creation_date":"2021-01-06 11:29:47.417 UTC",
        "Owner_last_access_date":"2021-09-22 18:22:07.127 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How can I remove the wrapper around the input when using Inference Schema",
        "Question_body":"<p>When using Inference Schema to autogenerate the swagger doc for my AzureML endpoint (as detailed <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\" rel=\"nofollow noreferrer\">here<\/a> and <a href=\"https:\/\/github.com\/Azure\/InferenceSchema\" rel=\"nofollow noreferrer\">here<\/a>), I see that it creates a wrapper around my input_sample. Is there a way to\nnot wrap the input inside this &quot;data&quot; wrapper?<\/p>\n<p>Here is what my score.py looks like:<\/p>\n<pre><code>input_sample = {\n                &quot;id&quot;: 123,\n                &quot;language&quot;: &quot;en&quot;\n                &quot;items&quot;: [{\n                    &quot;item&quot;: 1,\n                    &quot;desc&quot;: &quot;desc&quot;\n                }]\n            }\noutput_sample = [{'prediction': 'true', 'predictionConfidence': 0.8279970776764844}]\n\n@input_schema('data', StandardPythonParameterType(input_sample))\n@output_schema(StandardPythonParameterType(output_sample))\ndef run(data):\n&quot;&quot;&quot;\n    {\n        data: { --&gt; DON'T WANT this &quot;data&quot; wrapper\n                &quot;id&quot;: 123,\n                &quot;language&quot;: &quot;en&quot;\n                &quot;items&quot;: [{\n                    &quot;item&quot;: 1,\n                    &quot;desc&quot;: &quot;desc&quot;\n                }]\n            }\n    }\n    &quot;&quot;&quot;\n    try:\n        id = data['id']\n        ...\n        \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-09-24 21:20:58.753 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|inference|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":173,
        "Owner_creation_date":"2014-07-25 14:30:39.46 UTC",
        "Owner_last_access_date":"2022-09-22 15:23:44.643 UTC",
        "Owner_location":null,
        "Owner_reputation":435,
        "Owner_up_votes":36,
        "Owner_down_votes":1,
        "Owner_views":48,
        "Answer_body":"<p>InferenceSchema used with Azure Machine Learning deployments, then the code for this package was recently published at <a href=\"https:\/\/github.com\/Azure\/InferenceSchema\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/InferenceSchema<\/a> under an MIT license. So you could possibly use that to create a version specific to your needs.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-05 07:42:35.637 UTC",
        "Answer_last_edit_date":"2020-10-05 08:09:50.513 UTC",
        "Answer_score":0.0,
        "Question_last_edit_date":"2020-09-25 13:08:05.473 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Uploading xgboost to azure machine learning: %1 is not a valid Win32 application\\r\\nProcess returned with non-zero exit code 1",
        "Question_body":"<p>I've tried to upload the xgboost python library to Azure ML, however it claim that my library is not a Win32 application.\nI've made sure to install the 32 bit version of the package and i'm running conda 32 bit as well.\nI downloaded the library from:\n<a href=\"http:\/\/www.lfd.uci.edu\/~gohlke\/pythonlibs\/#xgboost\" rel=\"nofollow noreferrer\">http:\/\/www.lfd.uci.edu\/~gohlke\/pythonlibs\/#xgboost<\/a>\nand chose the 32 bit python 3.5 version.\nPython installation as below.\n<img src=\"https:\/\/i.stack.imgur.com\/NkKRk.jpg\" alt=\"python installation\"><\/p>\n\n<p>This is the error I get returned azure ml error\n<img src=\"https:\/\/i.stack.imgur.com\/V9M1f.jpg\" alt=\"azure ml error\"><\/p>\n\n<p>Here is my installation of anaconda conda installation\n<img src=\"https:\/\/i.stack.imgur.com\/MsLyg.jpg\" alt=\"conda installation\"><\/p>\n\n<p>Can anyone see where I went wrong? <\/p>\n\n<p>Best Regards<\/p>\n\n<p>EDIT:\nYes I followed the document and uploaded a zip file containing the wheel file. When I run the following it works just fine:\n\"import pip\" and   \"pip.main(['install', '.\/Script Bundle\/xgboost-0.6-cp35-cp35m-win32.whl'])\"\nBut when I add \"import xgboost\" I get this error.<a href=\"https:\/\/i.stack.imgur.com\/coYnH.jpg\" rel=\"nofollow noreferrer\">Import error<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2017-05-31 11:57:00.517 UTC",
        "Question_favorite_count":1.0,
        "Question_score":0,
        "Question_tags":"python|azure|python-3.5|azure-machine-learning-studio",
        "Question_view_count":650,
        "Owner_creation_date":"2014-07-15 09:42:25.77 UTC",
        "Owner_last_access_date":"2018-09-24 13:29:47.797 UTC",
        "Owner_location":"Copenhagen, Denmark",
        "Owner_reputation":9,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-06-01 09:21:39.83 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML - Import Hive Query Failing - Hive over ADLS",
        "Question_body":"<p>We are working on Azure ML and ADLS combination. Since HDInsight Cluster is working over ADLS, we are trying to use Hive Query and HDFS route and running into problems. \nRequest your help in solving the problem of reading data from hive query and writing to HDFS. Below is the error URL for reference:<\/p>\n\n<p><a href=\"https:\/\/studioapi.azureml.net\/api\/sharedaccess?workspaceId=025ba20578874d7086e6c495cc49a3f2&amp;signature=ZMUCNMwRjlrksrrmsrx5SaGedSgwMmO%2FfSHvq190%2F1I%3D&amp;sharedAccessUri=https%3A%2F%2Fesprodussouth001.blob.core.windows.net%2Fexperimentoutput%2Fccf9a206-730d-4773-b44e-a2dd8c6e87b9%2Fccf9a206-730d-4773-b44e-a2dd8c6e87b9.txt%3Fsv%3D2015-02-21%26sr%3Db%26sig%3DHkuFm8B2Ba1kEWWIwanqlv%2FcQPWVz0XYveSsZnEa0Wg%3D%26st%3D2017-10-16T18%3A31%3A06Z%26se%3D2017-10-17T18%3A36%3A06Z%26sp%3Dr\" rel=\"nofollow noreferrer\">https:\/\/studioapi.azureml.net\/api\/sharedaccess?workspaceId=025ba20578874d7086e6c495cc49a3f2&amp;signature=ZMUCNMwRjlrksrrmsrx5SaGedSgwMmO%2FfSHvq190%2F1I%3D&amp;sharedAccessUri=https%3A%2F%2Fesprodussouth001.blob.core.windows.net%2Fexperimentoutput%2Fccf9a206-730d-4773-b44e-a2dd8c6e87b9%2Fccf9a206-730d-4773-b44e-a2dd8c6e87b9.txt%3Fsv%3D2015-02-21%26sr%3Db%26sig%3DHkuFm8B2Ba1kEWWIwanqlv%2FcQPWVz0XYveSsZnEa0Wg%3D%26st%3D2017-10-16T18%3A31%3A06Z%26se%3D2017-10-17T18%3A36%3A06Z%26sp%3Dr<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-10-24 00:55:05.617 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-hdinsight|azure-machine-learning-studio",
        "Question_view_count":64,
        "Owner_creation_date":"2014-12-23 06:43:26.22 UTC",
        "Owner_last_access_date":"2018-09-15 12:23:34.433 UTC",
        "Owner_location":null,
        "Owner_reputation":97,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>Azure Machine Learning supports Hive but not over ADLS. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-10-25 15:22:20.72 UTC",
        "Answer_last_edit_date":"2017-10-27 19:57:05.963 UTC",
        "Answer_score":0.0,
        "Question_last_edit_date":"2017-11-12 07:05:14.877 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML multiple models stored in dictionary",
        "Question_body":"<p><strong>Overview:<\/strong><\/p>\n\n<p>I have a unique Python model where we hold n trained random forest models in a dictionary. I tried to avoid this setup, but for the time being it's necessary. On my local, I can make predictions by passing a dataframe to a predict function and looping through the rows, calling the appropriate model for each row, like rf_models[model].predict().<\/p>\n\n<p>In AzureML I created a toy model that allows me to go:\nWeb Input -> Python Script -> Score Model -> Web output. <\/p>\n\n<p><strong>Challenge:<\/strong><\/p>\n\n<p>I need to be able to call the score_model, or specifically the predict method, from inside the \"Python Script\" function on AzureML so I can deal with the loops and n models stored in the dict. The results, either a JSON or dataframe, would be sent to AzureML's Web Output.<\/p>\n\n<p>I found a link online (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-execute-python-scripts\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-execute-python-scripts<\/a>) that got me close, but the example shows a model being trained and used to predict at the same time inside the same Python script, thus calling the predict method as a local variable and not calling a previously trained model. I found only limited documentation online to solve this problem and I could not get the rest of the way there. I'm unsure if this type of customization is not yet available or if I'm completely overlooking some key functionality.<\/p>\n\n<p>Thank you for your assistance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-08-08 18:58:06.207 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio",
        "Question_view_count":200,
        "Owner_creation_date":"2017-05-02 19:38:19.063 UTC",
        "Owner_last_access_date":"2022-06-24 15:45:00.497 UTC",
        "Owner_location":null,
        "Owner_reputation":159,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":31,
        "Answer_body":"<p>Here are two links that might help:<\/p>\n\n<ol>\n<li><a href=\"https:\/\/github.com\/Azure\/Machine-Learning-Operationalization\" rel=\"nofollow noreferrer\">AzureML Operationalization<\/a> <\/li>\n<li><a href=\"https:\/\/github.com\/Azure\/Machine-Learning-Operationalization\/blob\/master\/samples\/python\/tutorials\/realtime\/digit_classification.ipynb\" rel=\"nofollow noreferrer\">Example notebook<\/a> that shows how to publish Python model as a web service. You would do a similar thing, only you would pickle the dictionary of your models instead. <\/li>\n<\/ol>\n\n<p>Note that this functionality is currently in preview mode.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-08-27 19:08:42.243 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"'Enter Data' as list instead of list of lists in Azure ML Web Service",
        "Question_body":"<p>In Azure ML, I want to enter data to a model through a published Web Service. \nThe way to tell this to the Web Service, as far as I can tell, it to have an 'Enter Data' box coming into the same input as the Web service. <\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/m1x5x.png\" alt=\"enter image description here\"><\/p>\n\n<p>You can then set you data format in the 'Enter Data' properties:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/VQJ9V.png\" alt=\"enter image description here\"><\/p>\n\n<p>I want that list to be an arbitrary-length array of samples. This works if your input is:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"samples\"\n      ],\n      \"Values\": [\n        [\n          1\n        ],\n        [\n          2\n        ],\n        [\n          3\n        ],\n        [\n          4\n        ],\n        [\n          5\n        ]\n      ]\n    }\n  },\n  \"GlobalParameters\": {}\n}\n<\/code><\/pre>\n\n<p>This is ok, but ideally it would be easier, and (more importantly) more network-efficient, if I could send them as:<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"samples\"\n      ],\n      \"Values\": [\n        [\n          1,2,3,4,5\n        ]\n      ]\n    }\n  },\n  \"GlobalParameters\": {}\n}\n<\/code><\/pre>\n\n<p>Is there a correct syntax to implement this? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2015-07-24 11:24:06.243 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|json|azure|azure-machine-learning-studio",
        "Question_view_count":174,
        "Owner_creation_date":"2010-02-19 16:12:07.52 UTC",
        "Owner_last_access_date":"2021-10-11 05:53:43.067 UTC",
        "Owner_location":null,
        "Owner_reputation":7681,
        "Owner_up_votes":284,
        "Owner_down_votes":8,
        "Owner_views":361,
        "Answer_body":"<p>I have worked internally to request a confirmation of your concern - <\/p>\n\n<blockquote>\n  <p>'Enter Data' as list instead of list of lists in Azure ML Web Service<\/p>\n<\/blockquote>\n\n<p>but you expected feature is not available today in Azure ML Studio (The reason behind is Azure ML has to be able to read the input data as a tabular format, rows and columns). Such being the case, I would like to suggest you to submit a new feature request via below option:<\/p>\n\n<p>On Azure ML Studio -> the upper right corner, there is a smiley face, please click that and send the feedback.<\/p>\n\n<p>Should you have any further concerns, please feel free to let me know.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2015-08-06 14:28:45.837 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning pipeline: How to retry upon failure?",
        "Question_body":"<p>So I've got an Azure Machine Learning pipeline here that consists of a number of <code>PythonScriptStep<\/code> tasks - pretty basic really.<\/p>\n<p>Some of these script steps fail intermittently due to network issues or somesuch - really nothing unexpected. The solution here is always to simply trigger a rerun of the failed experiment in the browser interface of Azure Machine Learning studio.<\/p>\n<p>Despite my best efforts I haven't been able to figure out how to set a retry parameter either on the script step objects, the pipeline object, or any other AZ ML-related object.\nThis is a common pattern in pipelines of any sort: Task fails once - retry a couple of times before deciding it actually fails.<\/p>\n<p>Does anyone have pointers for me please?<\/p>\n<p>Edit: One helpful user suggested an external solution to this which requires an Azure Logic App that listens to ML pipeline events and re-triggers failed pipelines via an HTTP request. While this solution may work for some it just takes you down another rabbit hole of setting up, debugging, and maintaining another external component. I'm looking for a simple &quot;retry upon task failure&quot; option that (IMO) must be baked into the Azure ML pipeline framework and is hopefully just poorly documented.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-04 08:28:31.163 UTC",
        "Question_favorite_count":null,
        "Question_score":4,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":488,
        "Owner_creation_date":"2014-04-14 12:19:33.853 UTC",
        "Owner_last_access_date":"2022-07-29 15:38:17.45 UTC",
        "Owner_location":"Berlin, Germany",
        "Owner_reputation":73,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-08-13 09:38:24.927 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"run id from az ml cli",
        "Question_body":"<p>How to pass run id of experiment as tag information of model ?<\/p>\n\n<p>I want to run experiment and register model with tag information with run id of experiment in az ml cli in Azure DevOps Build pipeline.<\/p>\n\n<ul>\n<li><p>run experiment\naz ml run submit-script  -e test -d myenv.yml train.py<\/p><\/li>\n<li><p>model register\naz ml model register -n mymodel -p sklearn_regression_model.pkl --tag \"run id\"= ????<\/p><\/li>\n<\/ul>\n\n<p>I can't figure out how to get run id from experiment run from az ml cli and pass it to --tag argument. Any idea ?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-16 12:47:20.24 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-devops|azure-machine-learning-service",
        "Question_view_count":585,
        "Owner_creation_date":"2019-08-07 14:59:45.213 UTC",
        "Owner_last_access_date":"2021-02-14 14:41:45.463 UTC",
        "Owner_location":null,
        "Owner_reputation":71,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"ERROR:root:Line magic function `%azureml` not found?",
        "Question_body":"<p>I have created a \"Blank Jupyter Notebook\" project in Azure ML Workbench. When I try to run the Sample notebook found in the project, I get this error message:<\/p>\n\n<pre><code>ERROR:root:Line magic function `%azureml` not found.\n<\/code><\/pre>\n\n<p>What is missing?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2018-01-30 05:18:01.15 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-workbench",
        "Question_view_count":259,
        "Owner_creation_date":"2016-07-21 15:10:29.743 UTC",
        "Owner_last_access_date":"2022-09-21 20:32:07.613 UTC",
        "Owner_location":null,
        "Owner_reputation":2166,
        "Owner_up_votes":44,
        "Owner_down_votes":1,
        "Owner_views":151,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML R Model Train & Score Web Service",
        "Question_body":"<p>I created the the Azure Machine Learning sample \"<a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/R-Model-Train-Score-2\" rel=\"nofollow noreferrer\">R Model Train &amp; Score<\/a>\" from the gallery and followed the tutorial.  However, when I setup, deploy the web service ( as [New] Preview) and test, I get the error:<\/p>\n\n<blockquote>\n  <p>Score Model (RPackage) : Given path to R installation not found on machine or R executable not at this location<\/p>\n<\/blockquote>\n\n<p>The classic deployment works fine.  Any ideas on how to get the [New] Preview deployment example to run as a web service?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-01-25 06:50:01.46 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":131,
        "Owner_creation_date":"2010-06-30 04:33:09.89 UTC",
        "Owner_last_access_date":"2022-09-24 00:03:01.897 UTC",
        "Owner_location":"Phoenix, AZ",
        "Owner_reputation":11844,
        "Owner_up_votes":583,
        "Owner_down_votes":29,
        "Owner_views":656,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-01-25 06:57:28.237 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to acces output folder from a PythonScriptStep?",
        "Question_body":"<p>I'm new to <code>azure-ml<\/code>, and have been tasked to make some integration tests for a couple of pipeline steps. I have prepared some input test data and some expected output data, which I store on a <code>'test_datastore'<\/code>. The following example code is a simplified version of what I want to do:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>ws = Workspace.from_config('blabla\/config.json')\nds = Datastore.get(ws, datastore_name='test_datastore')\n\nmain_ref = DataReference(datastore=ds,\n                            data_reference_name='main_ref'\n                            )\n\ndata_ref = DataReference(datastore=ds,\n                            data_reference_name='main_ref',\n                            path_on_datastore='\/data'\n                            )\n\n\ndata_prep_step = PythonScriptStep(\n            name='data_prep',\n            script_name='pipeline_steps\/data_prep.py',\n            source_directory='\/.',\n            arguments=['--main_path', main_ref,\n                        '--data_ref_folder', data_ref\n                        ],\n            inputs=[main_ref, data_ref],\n            outputs=[data_ref],\n            runconfig=arbitrary_run_config,\n            allow_reuse=False\n            )\n<\/code><\/pre>\n<p>I would like:<\/p>\n<ul>\n<li>my <code>data_prep_step<\/code> to run,<\/li>\n<li>have it store some data on the path to my <code>data_ref<\/code>), and<\/li>\n<li>I would then like to access this stored data afterwards outside of the pipeline<\/li>\n<\/ul>\n<p>But, I can't find a useful function in the documentation. Any guidance would be much appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_creation_date":"2021-03-24 16:25:38.18 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|great-expectations",
        "Question_view_count":1327,
        "Owner_creation_date":"2016-04-01 11:46:31.443 UTC",
        "Owner_last_access_date":"2022-09-24 15:11:08.35 UTC",
        "Owner_location":null,
        "Owner_reputation":445,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":96,
        "Answer_body":"<p>two big ideas here -- let's start with the main one.<\/p>\n<h2>main ask<\/h2>\n<blockquote>\n<p>With an Azure ML Pipeline, how can I access the output data of a <code>PythonScriptStep<\/code> outside of the context of the pipeline?<\/p>\n<\/blockquote>\n<h3>short answer<\/h3>\n<p>Consider using <code>OutputFileDatasetConfig<\/code> (<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.output_dataset_config.outputdatasetconfig?view=azure-ml-py&amp;viewFallbackFrom=experimental&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">docs<\/a> <a href=\"http:\/\/%20https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-data-in-out-of-pipelines?WT.mc_id=AI-MVP-5003930#use-outputfiledatasetconfig-for-intermediate-data\" rel=\"nofollow noreferrer\">example<\/a>), instead of <code>DataReference<\/code>.<\/p>\n<p>To your example above, I would just change your last two definitions.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>data_ref = OutputFileDatasetConfig(\n    name='data_ref',\n    destination=(ds, '\/data')\n).as_upload()\n\n\ndata_prep_step = PythonScriptStep(\n    name='data_prep',\n    script_name='pipeline_steps\/data_prep.py',\n    source_directory='\/.',\n    arguments=[\n        '--main_path', main_ref,\n        '--data_ref_folder', data_ref\n                ],\n    inputs=[main_ref, data_ref],\n    outputs=[data_ref],\n    runconfig=arbitrary_run_config,\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>some notes:<\/p>\n<ul>\n<li>be sure to check out how <code>DataPath<\/code>s work. Can be tricky at first glance.<\/li>\n<li>set <code>overwrite=False<\/code> in the `.as_upload() method if you don't want future runs to overwrite the first run's data.<\/li>\n<\/ul>\n<h3>more context<\/h3>\n<p><code>PipelineData<\/code> used to be the defacto object to pass data ephemerally between pipeline steps. The idea was to make it easy to:<\/p>\n<ol>\n<li>stitch steps together<\/li>\n<li>get the data after the pipeline runs if need be (<code>datastore\/azureml\/{run_id}\/data_ref<\/code>)<\/li>\n<\/ol>\n<p>The downside was that you have no control over <em>where<\/em> the pipeline is saved. If you wanted to data for more than just as a baton that gets passed between steps, you could have a <code>DataTransferStep<\/code> to land the <code>PipelineData<\/code> wherever you please after the <code>PythonScriptStep<\/code> finishes.<\/p>\n<p>This downside is what motivated <code>OutputFileDatasetConfig<\/code><\/p>\n<h2>auxilary ask<\/h2>\n<blockquote>\n<p>how might I programmatically test the functionality of my Azure ML pipeline?<\/p>\n<\/blockquote>\n<p>there are not enough people talking about data pipeline testing, IMHO.<\/p>\n<p>There are three areas of data pipeline testing:<\/p>\n<ol>\n<li>unit testing (the code in the step works?<\/li>\n<li>integration testing (the code works when submitted to the Azure ML service)<\/li>\n<li>data expectation testing (the data coming out of the meets my expectations)<\/li>\n<\/ol>\n<p>For #1, I think it should be done outside of the pipeline perhaps as part of a package of helper functions\nFor #2, Why not just see if the whole pipeline completes, I think get more information that way. That's how we run our CI.<\/p>\n<p>#3 is the juiciest, and we do this in our pipelines with the <a href=\"https:\/\/greatexpectations.io\/\" rel=\"nofollow noreferrer\">Great Expectations (GE)<\/a> Python library. The GE community calls these &quot;expectation tests&quot;. To me you have two options for including expectation tests in your Azure ML pipeline:<\/p>\n<ol>\n<li>within the <code>PythonScriptStep<\/code> itself, i.e.\n<ol>\n<li>run whatever code you have<\/li>\n<li>test the outputs with GE before writing them out; or,<\/li>\n<\/ol>\n<\/li>\n<li>for each functional <code>PythonScriptStep<\/code>, hang a downstream <code>PythonScriptStep<\/code> off of it in which you run your expectations against the output data.<\/li>\n<\/ol>\n<p>Our team does #1, but either strategy should work. What's great about this approach is that you can run your expectation tests by just running your pipeline (which also makes integration testing easy).<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-03-24 22:47:56.987 UTC",
        "Answer_last_edit_date":"2021-03-24 22:56:02.7 UTC",
        "Answer_score":3.0,
        "Question_last_edit_date":"2021-03-28 19:58:35.96 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Issue with data lake mounting in custom RStudio application Azure ML",
        "Question_body":"<ol>\n<li>previously while creating a compute instance  we were able to see RStudio application by default and we were able to mount\/access the data lake from RStudio.<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/J17ne.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/J17ne.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/3l8Q4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3l8Q4.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"2\">\n<li>In current situation we are not able to access RStudio application by default.<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/nx5GL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/nx5GL.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"3\">\n<li>with the help of below link we are able to create custom RStudio application<\/li>\n<\/ol>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/flQyy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/flQyy.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>4.In custom RStudio we are not able to mount\/access the data lake.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/2dWL9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2dWL9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Is there way to mount\/access the data lake in custom RStudio app<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-08-19 04:30:31 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"r|azure|installation|azure-machine-learning-studio|rstudio-server",
        "Question_view_count":71,
        "Owner_creation_date":"2022-06-15 09:26:58.33 UTC",
        "Owner_last_access_date":"2022-09-22 12:13:16.827 UTC",
        "Owner_location":"Pune",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-08-23 15:38:07.767 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Truncate Table in Azure SQL Database for Azure ML Experiment",
        "Question_body":"<p>In my Azure ML experiment I am using a writer to write data into a table in Azure SQL Database. However, I would like to truncate the data in that table before each insert. Is there any way that I can achieve this through the experiment itself? Any inbuilt module through which I can achieve this?<\/p>\n\n<p>I know from sql using triggers I can achieve this. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2015-12-08 16:53:15.153 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"tsql|azure-sql-database|azure-machine-learning-studio",
        "Question_view_count":436,
        "Owner_creation_date":"2015-12-08 16:51:25.033 UTC",
        "Owner_last_access_date":"2020-10-12 14:17:25.503 UTC",
        "Owner_location":null,
        "Owner_reputation":101,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2015-12-09 18:00:18.627 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Models generate different results when moving to Azure Machine Learning Studio",
        "Question_body":"<p>We developed a Jupyter Notebook in a local machine to train models with the Python (V3) libraries <code>sklearn<\/code> and <code>gensim<\/code>.\nAs we set the <code>random_state<\/code> variable to a fixed integer, the results were always the same.<\/p>\n\n<p>After this, we tried moving the notebook to a workspace in Azure Machine Learning Studio (classic), but the results differ even if we leave the <code>random_state<\/code> the same.<\/p>\n\n<p>As suggested in the following links, we installed the same libraries versions and checked the <code>MKL<\/code> version was the same and the <code>MKL_CBWR<\/code> variable was set to <code>AUTO<\/code>.<\/p>\n\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/46766714\/t-sne-generates-different-results-on-different-machines\">t-SNE generates different results on different machines<\/a><\/p>\n\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/38228088\/same-python-code-same-data-different-results-on-different-machines\">Same Python code, same data, different results on different machines<\/a><\/p>\n\n<p>Still, we are not able to get the same results.<\/p>\n\n<p>What else should we check or why is this happening?<\/p>\n\n<p><strong>Update<\/strong><\/p>\n\n<p>If we generate a <code>pkl<\/code> file in the local machine and import it in AML, the results are the same (as the intention of the pkl file is).<\/p>\n\n<p>Still, we are looking to get the same results (if possible) without importing the pkl file.<\/p>\n\n<p><strong>Library versions<\/strong><\/p>\n\n<pre><code>gensim 3.8.3.\nsklearn 0.19.2.\nmatplotlib 2.2.3.\nnumpy 1.17.2.\nscipy 1.1.0.\n<\/code><\/pre>\n\n<p><strong>Code<\/strong><\/p>\n\n<p>Full code can be found <a href=\"https:\/\/t.ly\/YlCi\" rel=\"nofollow noreferrer\">here<\/a>, sample data link inside.<\/p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib\nfrom matplotlib import pyplot as plt\n\nfrom gensim.models import KeyedVectors\n%matplotlib inline\n\nimport time\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\n\nwordvectors_file_vec = '..\/libraries\/embeddings-new_large-general_3B_fasttext.vec'\nwordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec)\n\nmath_quests = # some transformations using wordvectors\n\ndf_subset = pd.DataFrame()\n\npca = PCA(n_components=3, random_state = 42)\npca_result = pca.fit_transform(mat_quests)\ndf_subset['pca-one'] = pca_result[:,0]\ndf_subset['pca-two'] = pca_result[:,1] \n\ntime_start = time.time()\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300, random_state = 42)\ntsne_results = tsne.fit_transform(mat_quests)\n\ndf_subset['tsne-2d-one'] = tsne_results[:,0]\ndf_subset['tsne-2d-two'] = tsne_results[:,1]\n\npca_50 = PCA(n_components=50, random_state = 42)\npca_result_50 = pca_50.fit_transform(mat_quests)\nprint('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n\ntime_start = time.time()\ntsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300, random_state = 42)\ntsne_pca_results = tsne.fit_transform(pca_result_50)\nprint('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_date":"2020-06-06 17:23:19.347 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|scikit-learn|gensim|azure-machine-learning-studio",
        "Question_view_count":201,
        "Owner_creation_date":"2020-03-30 17:44:04.877 UTC",
        "Owner_last_access_date":"2020-06-28 18:13:06.573 UTC",
        "Owner_location":null,
        "Owner_reputation":55,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":"<p>Definitely empathize with the issue you're having. Every data scientist has struggled with this at some point.<\/p>\n\n<p>The hard truth I have for you is that Azure ML Studio (classic) isn't really capable of  solving this \"works on my machine\" problem. However, the good news is that Azure ML Service is incredible at it. Studio classic doesn't let you define custom environments deterministically, only add and remove packages (and not so well even at that) <\/p>\n\n<p>Because ML Service's execution is built on top of <code>Docker<\/code> containers and <code>conda<\/code> environments, you can feel more confident in repeated results. I highly recommend you take the time to learn it (and I'm also happy to debug any issues that come up). Azure's <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\" rel=\"nofollow noreferrer\">MachineLearningNotebooks repo<\/a> has a lot of great tutorials for getting started.<\/p>\n\n<p>I spent two hours making <a href=\"https:\/\/github.com\/swanderz\/MachineLearningNotebooks\/blob\/SO_CPR\/how-to-use-azureml\/training\/train-on-amlcompute\/train-on-amlcompute.ipynb\" rel=\"nofollow noreferrer\">a proof of concept<\/a> that demonstrate how ML Service solves the problem you're having by synthesizing:<\/p>\n\n<ul>\n<li>your code sample (before you shared your notebook),<\/li>\n<li><a href=\"https:\/\/scikit-learn.org\/stable\/auto_examples\/manifold\/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py\" rel=\"nofollow noreferrer\">Jake Vanderplas's sklearn example<\/a>, and<\/li>\n<li><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-amlcompute\/train-on-amlcompute.ipynb\" rel=\"nofollow noreferrer\">this Azure ML tutorial<\/a> on remote training.<\/li>\n<\/ul>\n\n<p>I'm no T-SNE expert, but from the screenshot below, you can see that the t-sne outputs are the same when I run the script locally and remotely. This might be possible with Studio classic, but it would be hard to guarantee that it will always work.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/mhlg6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mhlg6.png\" alt=\"Azure ML Experiment Results Page\"><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-06-07 01:37:03.77 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2020-06-07 00:25:15.657 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Unable to import autoexplainer",
        "Question_body":"<p>I am getting the below error while trying to import autoexplainer in azureml:<\/p>\n\n<pre><code>from azureml.train.automl.automlexplainer import explain_model  \n<\/code><\/pre>\n\n<blockquote>\n  <p>ModuleNotFoundError                       Traceback (most recent call last)\n   in \n  ----> 1 from azureml.train.automl.automlexplainer import retrieve_model_explanation\n        2 from azureml.train.automl.automlexplainer import explain_model\n        3 \n        4 shap_values, expected_values, overall_summary, overall_imp, per_class_summary, per_class_imp = explain_model(fitted_model, x_train, x_test)\n        5 #Overall feature importance\n  ModuleNotFoundError: No module named 'azureml.train.automl.automlexplainer'<\/p>\n<\/blockquote>\n\n<p>Any suggestions?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-24 08:47:06.387 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|automl|azure-machine-learning-service",
        "Question_view_count":206,
        "Owner_creation_date":"2019-12-22 14:44:05.723 UTC",
        "Owner_last_access_date":"2020-02-27 09:00:24.303 UTC",
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure-ML-R SDK in R Studio ScriptRunConfig not recognized function error after a deprecated estimator replacement",
        "Question_body":"<p>I am trying to use Azure-ML-SDK in R Studio and used Estimator but got error stating estimator deprecated and advised to use ScriptRunConfig and when used it, it not being recognized as a function and fails to run. See the errors below. Please advise.<\/p>\n<p>Already loaded library(azuremlsdk) which should include azureml.core to recognize the ScriptRunConfig function. Is it version compatibility issue? if so, which version should i use for ScriptRunConfig and how to load specific R version in Azure ML Compute (R Studio web interface and not R Studio Desktop)<\/p>\n<p>First Error and code<\/p>\n<pre><code>est &lt;- estimator(source_directory = &quot;train-and-deploy-first-model&quot;,\n                 entry_script = &quot;accidents.R&quot;,\n                 script_params = list(&quot;--data_folder&quot; = ds$path(target_path)),\n                 compute_target = compute_target\n                 )\n<\/code><\/pre>\n<p>cran_packages, github_packages, custom_url_packages, custom_docker_image, image_registry_details, use_gpu, environment_variables, and shm_size parameters will be deprecated. Please create an environment object with them using r_environment() and pass the environment object to the estimator().'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.<\/p>\n<p>Second Code snippet trying to fix above and it's error<\/p>\n<pre><code>config &lt;- ScriptRunConfig(source_directory = &quot;.&quot;,\n                 script = &quot;accidents.R&quot;,\n                 compute_target = compute_target\n                 )\n<\/code><\/pre>\n<p>Error in ScriptRunConfig(source_directory = &quot;.&quot;, script = &quot;accidents.R&quot;,  :\ncould not find function &quot;ScriptRunConfig&quot;<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2021-04-27 16:30:27.51 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-service",
        "Question_view_count":159,
        "Owner_creation_date":"2014-04-15 12:18:57.88 UTC",
        "Owner_last_access_date":"2021-05-11 16:14:42.53 UTC",
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Scored Labels dont match Scored Probabilities",
        "Question_body":"<p>I have a predictive web service. The scored labels field don't match the highest value for the specific scored probabilities columns. Is it more reliable to search through the different columns and pick the highest?<\/p>\n\n<p>Like, I get a result that has a bunch of \n\"Scored Probabilities for Class\" \\\"\\\"\": 0.6,\n\"Scored Probabilities for Class\" \\\"\\\"\": 3.09<\/p>\n\n<p>But the scored labels show the one with 0.6, how is that possible?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2018-03-09 20:57:57.973 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":122,
        "Owner_creation_date":"2011-03-02 16:07:05.617 UTC",
        "Owner_last_access_date":"2022-09-23 21:19:38.327 UTC",
        "Owner_location":"Costa Rica",
        "Owner_reputation":1483,
        "Owner_up_votes":647,
        "Owner_down_votes":13,
        "Owner_views":219,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Custom Docker file for Azure ML Environment that contains COPY statements errors with COPY failed: \/path no such file or directory",
        "Question_body":"<p>I'm trying to submit an experiment to Azure ML using a Python script.<\/p>\n<p>The Environment being initialised uses a custom Dockerfile.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>env = Environment(name=&quot;test&quot;)\nenv.docker.base_image = None\nenv.docker.base_dockerfile = '.\/Docker\/Dockerfile'\nenv.docker.enabled = True\n<\/code><\/pre>\n<p>However the DockerFile needs a few <code>COPY<\/code> statements but those fail as follow:<\/p>\n<pre><code>Step 9\/23 : COPY requirements-azure.txt \/tmp\/requirements-azure.txt\nCOPY failed: stat \/var\/lib\/docker\/tmp\/docker-builder701026190\/requirements-azure.txt: no such file or directory\n<\/code><\/pre>\n<p>The Azure host environment responsible to build the image does not contain the files the Dockerfile requires, those exist in my local development machine from where I initiate the python script.<\/p>\n<p>I've been searching for the whole day of a way to add to the environment these files but without success.<\/p>\n<p>Below an excerpt from the Dockerfile and the python script that submits the experiment.<\/p>\n<pre><code>FROM mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04 as base\nCOPY .\/Docker\/requirements-azure.txt \/tmp\/requirements-azure.txt # &lt;- breaks here\n\n[...]\n\n<\/code><\/pre>\n<p>Here is how I'm submitting the experiment:<\/p>\n<pre><code>from azureml.core.environment import Environment\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace, Experiment\nfrom azureml.core.compute import ComputeTarget\n\nfrom azureml.core import Experiment, Workspace\nfrom azureml.train.estimator import Estimator\nimport os\n\nws = Workspace.from_config(path='\/mnt\/azure\/config\/workspace-config.json')\nenv = Environment(name=&quot;test&quot;)\nenv.docker.base_image = None\nenv.docker.base_dockerfile = '.\/Docker\/Dockerfile'\nenv.docker.enabled = True\ncompute_target = ComputeTarget(workspace=ws, name='GRComputeInstance')\nestimator = Estimator(\n    source_directory='\/workspace\/',\n    compute_target=compute_target,\n    entry_script=&quot;.\/src\/ml\/train\/main.py&quot;,\n    environment_definition=env\n)\nexperiment = Experiment(workspace=ws, name=&quot;estimator-test&quot;)\nrun = experiment.submit(estimator)\nrun.wait_for_completion(show_output=True, wait_post_processing=True)\n<\/code><\/pre>\n<p>Any idea?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-07-29 16:37:12.287 UTC",
        "Question_favorite_count":2.0,
        "Question_score":7,
        "Question_tags":"python|azure|docker|dockerfile|azure-machine-learning-service",
        "Question_view_count":927,
        "Owner_creation_date":"2009-07-24 16:26:11.43 UTC",
        "Owner_last_access_date":"2022-09-24 08:02:55.38 UTC",
        "Owner_location":"London, United Kingdom",
        "Owner_reputation":3317,
        "Owner_up_votes":466,
        "Owner_down_votes":8,
        "Owner_views":296,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-08-06 08:06:29.56 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Need help in finding classification algorithms in Azure Machine Learning Experiment",
        "Question_body":"<p>Need help in finding classification algorithms which can classify the different scored label based on the combination of multiple input parameter in Azure machine learning experiment.<\/p>\n\n<p>Ex :  In the below example we are taking the combination of input parameters Lic, Rel, type, country and flag and predicting the matching records and returning the Scored labels and its probabilities.<br>\nHere we are having multiple scored label value which will vary based on combination of all five parameter.<\/p>\n\n<p>We require classification algorithm which identifies the scored label and its probabilities based on different set of input parameters in Azure Machine learning experiments<\/p>\n\n<pre><code>Lic Rel        type country flag    Scored label    Scored Probabilities    \nC1  indi       HD   USA     Yes     1               0.477611\nC2  indi       HD   USA     Yes     2               0.477611\nC3  indi       HD   USA     Yes     3               0.477611\nC1  indi       HD   USA     Yes     1               0.477611\nC5  indi limi  HD   USA     Yes     4               0.477611    \nC6  indi limi  HD   CARIB   Yes     5               0.477611    \nC7  indi limi  HD   CARIB   Yes     6               0.477611    \nC6  indi limi  HD   CARIB   Yes     5               0.477611    \n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2017-12-22 05:43:20.763 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":100,
        "Owner_creation_date":"2017-09-08 08:51:50.663 UTC",
        "Owner_last_access_date":"2019-07-01 11:42:21.513 UTC",
        "Owner_location":null,
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-12-22 05:48:19.447 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"import custom python module in azure ml deployment environment",
        "Question_body":"<p>I have an sklearn k-means model. I am training the model and saving it in a pickle file so I can deploy it later using azure ml library. The model that I am training uses a custom Feature Encoder called <strong>MultiColumnLabelEncoder<\/strong>.\nThe pipeline model is defined as follow :<\/p>\n\n<pre><code># Pipeline\nkmeans = KMeans(n_clusters=3, random_state=0)\npipe = Pipeline([\n(\"encoder\", MultiColumnLabelEncoder()),\n('k-means', kmeans),\n])\n#Training the pipeline\nmodel = pipe.fit(visitors_df)\nprediction = model.predict(visitors_df)\n#save the model in pickle\/joblib format\nfilename = 'k_means_model.pkl'\njoblib.dump(model, filename)\n<\/code><\/pre>\n\n<p>The model saving works fine. The Deployment steps are the same as the steps in this link : <\/p>\n\n<p><a href=\"https:\/\/notebooks.azure.com\/azureml\/projects\/azureml-getting-started\/html\/how-to-use-azureml\/deploy-to-cloud\/model-register-and-deploy.ipynb\" rel=\"nofollow noreferrer\">https:\/\/notebooks.azure.com\/azureml\/projects\/azureml-getting-started\/html\/how-to-use-azureml\/deploy-to-cloud\/model-register-and-deploy.ipynb<\/a><\/p>\n\n<p>However the deployment always fails with this error :<\/p>\n\n<pre><code>  File \"\/var\/azureml-server\/create_app.py\", line 3, in &lt;module&gt;\n    from app import main\n  File \"\/var\/azureml-server\/app.py\", line 27, in &lt;module&gt;\n    import main as user_main\n  File \"\/var\/azureml-app\/main.py\", line 19, in &lt;module&gt;\n    driver_module_spec.loader.exec_module(driver_module)\n  File \"\/structure\/azureml-app\/score.py\", line 22, in &lt;module&gt;\n    importlib.import_module(\"multilabelencoder\")\n  File \"\/azureml-envs\/azureml_b707e8c15a41fd316cf6c660941cf3d5\/lib\/python3.6\/importlib\/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError: No module named 'multilabelencoder'\n<\/code><\/pre>\n\n<p>I understand that pickle\/joblib has some problems unpickling the custom function MultiLabelEncoder. That's why I defined this class in a separate python script (which I executed also). I called this custom function in the training python script, in the deployment script and in the scoring python file (score.py). The importing in the score.py file is not successful. \nSo my question is how can I import custom python module to azure ml deployment environment ?<\/p>\n\n<p>Thank you in advance.<\/p>\n\n<p>EDIT: \nThis is my .yml file<\/p>\n\n<pre><code>name: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n  - multilabelencoder==1.0.4\n  - scikit-learn\n  - azureml-defaults==1.0.74.*\n  - pandas\nchannels:\n- conda-forge\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2019-12-04 12:37:28.677 UTC",
        "Question_favorite_count":1.0,
        "Question_score":4,
        "Question_tags":"python|pickle|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":2611,
        "Owner_creation_date":"2015-07-27 08:39:50.373 UTC",
        "Owner_last_access_date":"2022-09-23 14:35:41.497 UTC",
        "Owner_location":"M\u00fcnchen, Deutschland",
        "Owner_reputation":361,
        "Owner_up_votes":61,
        "Owner_down_votes":0,
        "Owner_views":149,
        "Answer_body":"<p>In fact, the solution was to import my customized class <strong>MultiColumnLabelEncoder<\/strong> as a pip package (You can find it through pip install multilllabelencoder==1.0.5).\nThen I passed the pip package to the .yml file or in the InferenceConfig of the azure ml environment.\nIn the score.py file, I imported the class as follows :<\/p>\n\n<pre><code>from multilabelencoder import multilabelencoder\ndef init():\n    global model\n\n    # Call the custom encoder to be used dfor unpickling the model\n    encoder = multilabelencoder.MultiColumnLabelEncoder() \n    # Get the path where the deployed model can be found.\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'k_means_model_45.pkl')\n    model = joblib.load(model_path)\n<\/code><\/pre>\n\n<p>Then the deployment was successful. \nOne more important thing is I had to use the same pip package (multilabelencoder) in the training pipeline as here :<\/p>\n\n<pre><code>from multilabelencoder import multilabelencoder \npipe = Pipeline([\n    (\"encoder\", multilabelencoder.MultiColumnLabelEncoder(columns)),\n    ('k-means', kmeans),\n])\n#Training the pipeline\ntrainedModel = pipe.fit(df)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-12-06 12:24:12.34 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":4.0,
        "Question_last_edit_date":"2019-12-06 12:18:18.24 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Load .asc file into azure machine learning",
        "Question_body":"<p>For my Azure Machine Learning experiment I want to load a .asc file into an Execute R script in my experiment. It is in fact a tab delimited file with some comments on the first couple of rows. Can anyone tell me how to do this?<\/p>\n\n<p>A csv goes well, but with this file I get an error.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2016-03-09 19:38:38.89 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":69,
        "Owner_creation_date":"2013-12-19 09:29:24.537 UTC",
        "Owner_last_access_date":"2021-01-07 12:36:20.937 UTC",
        "Owner_location":"Netherlands",
        "Owner_reputation":81,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2016-03-09 22:13:45.26 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"'DecisionTreeRegressor' object has no attribute 'n_features_': 0",
        "Question_body":"<p>i had deployed my random Forest Regressor on AzureML.when i tried to request the scoring url i got the &quot;'DecisionTreeRegressor' object has no attribute 'n_features_': 0&quot;<a href=\"https:\/\/i.stack.imgur.com\/TJU5a.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/LVwEP.png\" rel=\"nofollow noreferrer\">My request code and error image<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-13 17:15:36.773 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":116,
        "Owner_creation_date":"2022-03-13 17:10:05.91 UTC",
        "Owner_last_access_date":"2022-09-18 06:30:01.36 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Embedded Azure MLmodel",
        "Question_body":"<p>Suppose I have a trained model in <a href=\"https:\/\/studio.azureml.net\" rel=\"nofollow noreferrer\">Azure ML<\/a> and I deployed it as a Web Service. Is it possible to export the model, embed it in an Android app and use it <em>locally<\/em>, without making any requests to Azure Web service?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-22 17:11:45.097 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"android|azure|sdk|azure-machine-learning-studio",
        "Question_view_count":85,
        "Owner_creation_date":"2017-01-22 11:40:40.96 UTC",
        "Owner_last_access_date":"2022-09-05 10:55:53.107 UTC",
        "Owner_location":"Ivanovo, Ivanovo Oblast, Russia",
        "Owner_reputation":490,
        "Owner_up_votes":37,
        "Owner_down_votes":0,
        "Owner_views":196,
        "Answer_body":"<p>From <a href=\"https:\/\/stackoverflow.com\/questions\/41236871\/how-to-download-the-trained-models-from-azure-machine-studio\">this answer<\/a> you won't be able to save the model locally if you do everything within Azure ML Studio.<\/p>\n\n<p>If you create the model using Python or R and execute it within Azure ML Studio, then you can save it from the library that you use.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-05-22 20:13:04.807 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Designer - Unable to connect dataset (any directory type) to clean missing data module (dataframedirectory type) in designer",
        "Question_body":"<p>Unable to connect dataset (any directory type) to clean missing data module (dataframedirectory type) in designer. Please advise. Screenshot of trying to connect is below where the clean missing module connection point is not highlighted to connect both modules, which i am assuming is because of type mismatch. Dataset output is of type \"AnyDirectory\" type where as clean missing module type is \"dataframedirectory\". How to cast in designer?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Qs3uV.png\" rel=\"nofollow noreferrer\">https:\/\/i.stack.imgur.com\/Qs3uV.png<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-28 12:41:31.757 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":241,
        "Owner_creation_date":"2014-04-15 12:18:57.88 UTC",
        "Owner_last_access_date":"2021-05-11 16:14:42.53 UTC",
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Can I use Azure interactive mode for azure-cli-ml extension?",
        "Question_body":"<p>I'm using Azure CLI interactive mode <code>az interactive<\/code> to run below command. <br \/>\n<code>az ml folder attach -w yhd-mlws -g yhd-mlws-rg<\/code><br \/><br \/>\nIt prompts me with below error message.<br \/>\n<code>az: error: unrecognized arguments: -w yhd-mlws -g yhd-mlws-rg<\/code><br \/><br \/>\nBTW, both my Machine Learning workspace <code>yhd-mlws<\/code> and resource group <code>yhd-mlws-rg<\/code> had been created in my Azure subscription. Azure CLI extension for machine learning service had also been installed via <code>az extension add -n azure-cli-ml<\/code>.<br \/><br \/>\nThen I run command <code>az ml folder attach<\/code> without any argument. I get bellow error message.<br \/><\/p>\n\n<pre><code>Message: Error, default workspace not set and workspace name parameter not provided.\nPlease set a default workspace using \"az ml folder attach -w myworkspace -g myresourcegroup\" or provide a value for the workspace name parameter.\n<\/code><\/pre>\n\n<p>The command window exit the interactive mode after above error message. Then I try the command <code>az ml folder attach -w yhd-mlws -g yhd-mlws-rg<\/code> again, bingo! It works. <br \/>\nHere comes my question, does azure-cli-ml extension support Azure CLI interactive mode? You know, Azure CLI interactive mode is amazing and I want to use it whenever possible. Thanks!<br \/><br \/>\nBTW, I'm running windows command window in Windows Server 2016 Datcenter. Azure-cli version is 2.0.79.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-25 14:47:04.3 UTC",
        "Question_favorite_count":0.0,
        "Question_score":1,
        "Question_tags":"azure|azure-cli|azure-machine-learning-service",
        "Question_view_count":408,
        "Owner_creation_date":"2020-02-22 08:47:11.693 UTC",
        "Owner_last_access_date":"2022-06-18 01:34:40.367 UTC",
        "Owner_location":"Guangzhou, China",
        "Owner_reputation":393,
        "Owner_up_votes":37,
        "Owner_down_votes":1,
        "Owner_views":58,
        "Answer_body":"<p>I can reproduce your issue, the interactive mode should support the <code>azure-cli-ml<\/code> extension, because when I run <code>az ml workspace list<\/code>, it works, once I pass the <code>-g<\/code> parameter, it gives the same error, maybe it is a bug, but I am not sure, the <code>interactive<\/code> is in preview currently.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/g4FvM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/g4FvM.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>If you want to run <code>az ml folder attach -w yhd-mlws -g yhd-mlws-rg<\/code> in the interactive mode, my workaround is to pass the <code>#<\/code>, i.e. <code># az ml folder attach -w yhd-mlws -g yhd-mlws-rg<\/code>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/pWMyH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/pWMyH.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-02-26 03:11:50.413 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2020-02-26 00:56:22.157 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AML run.log() and run.log_list() fail without error",
        "Question_body":"<p>I have a Pipeline with DatabricksSteps each containing:<\/p>\n\n<pre><code>from azureml.core.run import Run\nrun = Run.get_context()\n#do stuff\nrun.log(name, val, desc)\nrun.log_list(name, vals, desc)\nrun.log_image(title, fig, desc)\n<\/code><\/pre>\n\n<p>Only <code>log_image()<\/code> seems to work.  The image appears in the \"images\" section of the AML experiment workspace as expected, but the \"tracked metrics\" and \"charts\" areas are blank.  In an interactive job, <code>run.log()<\/code> and <code>run.log_list()<\/code> work as expected.  I tested that there is no problem with the arguments by using <code>print()<\/code> instead of <code>run.log()<\/code>.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-20 22:23:24.223 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":121,
        "Owner_creation_date":"2016-06-07 17:33:54.943 UTC",
        "Owner_last_access_date":"2021-04-01 15:14:27.47 UTC",
        "Owner_location":"Redmond, WA, USA",
        "Owner_reputation":677,
        "Owner_up_votes":13,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Answer_body":"<p>Add run.flush() at the end of the script.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-09-25 16:11:01.03 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Connect to an existing Azure Container Instance ACI from Azure ML",
        "Question_body":"<p>I have an active Azure container Instance which is running, How can I add it to my Workspace using the Azure ML SDK.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_date":"2020-07-16 13:34:41.08 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-container-instances|azure-machine-learning-service",
        "Question_view_count":169,
        "Owner_creation_date":"2018-09-18 19:45:24.587 UTC",
        "Owner_last_access_date":"2022-09-14 17:20:52.613 UTC",
        "Owner_location":"Laurel, MD, USA",
        "Owner_reputation":359,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning - CORS",
        "Question_body":"<p>I've searched for hours for this and can't find a single thing that answers the question. I've created and published a new Azure Machine Learning service, and have created an endpoint. I can call the service using the Postman REST CLient, but accessing it via a JavaScript webpage returns a console log saying that CORS is enabled for the service. Now, for the life of me, I can't figure out how to disable CORS for Azure Machine Learning services. Any help would be much appreciated, thanks!<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":4,
        "Question_creation_date":"2015-01-16 16:00:31.317 UTC",
        "Question_favorite_count":null,
        "Question_score":12,
        "Question_tags":"azure|machine-learning|cors|azure-machine-learning-studio",
        "Question_view_count":3242,
        "Owner_creation_date":"2014-06-28 09:44:15.637 UTC",
        "Owner_last_access_date":"2022-05-29 02:05:51.72 UTC",
        "Owner_location":null,
        "Owner_reputation":135,
        "Owner_up_votes":36,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":"<p>Currently, we don't support disabling CORS on API side but you can either use the above option or you can use the API management service to disable CORS. The links below should help you with this<\/p>\n\n<p>Here are the links: <a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/api-management-get-started\/\" rel=\"noreferrer\">step by step<\/a> guide, also this <a href=\"http:\/\/channel9.msdn.com\/Blogs\/AzureApiMgmt\/Last-mile-Security\" rel=\"noreferrer\">video<\/a> on setting headers, and <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn894084.aspx#JSONP\" rel=\"noreferrer\">this doc<\/a> on policies.<\/p>\n\n<p>API Management service allow CORS by enabling it in the API configuration page<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-02-02 04:31:32.627 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":4.0,
        "Question_last_edit_date":"2016-02-01 16:15:55.233 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Visual Studio project to call Azure ML Endpoint, namespace how-to",
        "Question_body":"<p>I have a Visual Studio WebForm C# project that loads in a browser. I also have a snippet of code from Azure ML to call my endpoint model. How should the *.aspx.cs file look? Thank you.\n<a href=\"https:\/\/i.stack.imgur.com\/zGogg.png\" rel=\"nofollow noreferrer\">screen shot of my visual studio *.aspx.cs file<\/a><\/p>\n<p>Here is how I plan to call it from the carprice.aspx file:<\/p>\n<pre><code>  &lt;asp:Label ID=&quot;lblResults&quot; runat=&quot;server&quot; Text=&quot;here is where results will go&quot;&gt;&lt;\/asp:Label&gt;\n<\/code><\/pre>\n<p>Here is the Namespace template from Visual Studio project, the carprice.aspx.cs file:<\/p>\n<pre><code>namespace web13\n{\npublic partial class carprice : System.Web.UI.Page\n{\n    protected void Page_Load(object sender, EventArgs e)\n    {\n\n    }\n}\n}\n<\/code><\/pre>\n<p>And here is the snippet from Azure, a different kind of namespace syntax:<\/p>\n<pre><code>namespace CallRequestResponseService\n{\nclass Program\n{\n    static void Main(string[] args)\n    {\n        InvokeRequestResponseService().Wait();\n    }\n\n    static async Task InvokeRequestResponseService()\n    {\n        var handler = new HttpClientHandler()\n        {\n            ClientCertificateOptions = ClientCertificateOption.Manual,\n            ServerCertificateCustomValidationCallback =\n                    (httpRequestMessage, cert, cetChain, policyErrors) =&gt; { return true; }\n        };\n        using (var client = new HttpClient(handler))\n        {\n            \/\/ Request data goes here\n            var scoreRequest = new\n            {\n                Inputs = new Dictionary&lt;string, List&lt;Dictionary&lt;string, string&gt;&gt;&gt;()\n                {\n                    {\n                        &quot;input1&quot;,\n                        new List&lt;Dictionary&lt;string, string&gt;&gt;()\n                        {\n                            new Dictionary&lt;string, string&gt;()\n                            {\n                                {\n                                    &quot;price&quot;, &quot;5800&quot;\n                                },\n                                {\n                                    &quot;year&quot;, &quot;2013&quot;......etc\n<\/code><\/pre>\n<p>The next day, I tried calling HTML label control from the Azure snippet of code, but I get an error, &quot;the name lblResults2 does not exist in the current context.&quot; I've also tried changing the Azure snippet to Public classes. Here is another screen shot. thank you.\n<a href=\"https:\/\/i.stack.imgur.com\/RzfSZ.png\" rel=\"nofollow noreferrer\">Visual Studio connecting Azure Results to form<\/a><\/p>\n<p>Then further along, I'm adding newer screen shots\n<a href=\"https:\/\/i.stack.imgur.com\/Eqjrd.png\" rel=\"nofollow noreferrer\">Visual Studio webform controls<\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/Th5Xw.png\" rel=\"nofollow noreferrer\">Visual Studio namespace<\/a><\/p>\n<p>further days along, this is what gets Visual Studio to compile and load in browser. screen shot is:\n<a href=\"https:\/\/i.stack.imgur.com\/NP2O3.png\" rel=\"nofollow noreferrer\">working syntax for calling endpoint<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2021-08-07 22:01:10.653 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"visual-studio-code|webforms|namespaces|azure-machine-learning-service",
        "Question_view_count":54,
        "Owner_creation_date":"2021-08-07 21:34:03.23 UTC",
        "Owner_last_access_date":"2022-04-20 01:50:41.407 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-08-23 01:26:12.373 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"\"Session has expired\" message with Machine Learning Studio",
        "Question_body":"<p>I am getting consistent error \"Your session has expired\" (screenshot below), after logging in to machine learning studio. <\/p>\n\n<p>I have tried chrome incognito and guest windows, but no difference. <\/p>\n\n<p>I am using a new account and have signed up for Free workspace. Any suggestion to get past this or delete workspace, to start again?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/fsqtw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fsqtw.png\" alt=\"Error screenshot\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-05-07 14:00:13.34 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":482,
        "Owner_creation_date":"2009-10-10 17:00:26.493 UTC",
        "Owner_last_access_date":"2021-04-06 13:17:11.493 UTC",
        "Owner_location":"Bedford, MA, USA",
        "Owner_reputation":300,
        "Owner_up_votes":31,
        "Owner_down_votes":0,
        "Owner_views":63,
        "Answer_body":"<p>I can reproduce your issue, I sign out and log in <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/<\/a> again, it solved my problem. Or you can try to clear the browsing data or change a browser. Anyway, the issue should be caused by the browser, not azure. Even if your account is not the owner of the workspace, when you click <code>Sign In<\/code> in <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/<\/a> , it will create a free workspace(with a different workspace id) for you automatically.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/MXDJC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/MXDJC.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>If you want to delete the workspace, you need to let the owner of the workspace delete it, navigate to the <code>SETTINGS<\/code> on the left of the studio -> <code>NAME<\/code> -> <code>DELETE WORKSPACE<\/code>. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/E6aUl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/E6aUl.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-05-08 07:20:39.457 UTC",
        "Answer_last_edit_date":"2019-05-08 07:27:36.467 UTC",
        "Answer_score":2.0,
        "Question_last_edit_date":"2019-05-07 14:51:50.417 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML web service input parameters",
        "Question_body":"<p>I have an experiment created in <strong>Azure ML<\/strong>, where I have a <strong>dataset<\/strong> which consists of following columns:<\/p>\n\n<pre><code>Temperature, Timestamp, Kw_system, Powerscout etc. \n<\/code><\/pre>\n\n<p>I need to input a range of timestamp say, <strong>from Oct 1st to Oct 2nd<\/strong> <strong>and all the rows between this needs to be displayed<\/strong> on which I would do anomaly detection. Please let me know how to go about it<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-20 13:09:50.653 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|parameters|azure-web-app-service|azure-machine-learning-studio|input-parameters",
        "Question_view_count":682,
        "Owner_creation_date":"2016-11-15 07:23:47.133 UTC",
        "Owner_last_access_date":"2018-07-12 09:45:50.387 UTC",
        "Owner_location":null,
        "Owner_reputation":2713,
        "Owner_up_votes":26,
        "Owner_down_votes":2,
        "Owner_views":358,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Does a call to \"Deploy web service(via API key) \" re run trained Azure ML model again",
        "Question_body":"<p>I wanted to know how exactly the following works in backend<\/p>\n\n<p><strong>Scenario :<\/strong> <\/p>\n\n<blockquote>\n  <p>-> We get data from Edgex foundry in UTC format and we it store it in Azure Document DB in (CST\/CDT timezone) format<\/p>\n  \n  <p>-> We trained ML model on data(with Date in CST\/CDT timezone) and Deploy web service.<\/p>\n<\/blockquote>\n\n<p><strong>So I have few basic doubts below<\/strong><\/p>\n\n<blockquote>\n  <ol>\n  <li><p>When web job hits our predictive webservice , will the trained ML model be run again?<\/p><\/li>\n  <li><p>Do we need to convert the UTC timezone for new incoming test data( which we want to predict) into CST\/CDT timezone, as TimeStamp does\n  matter for our prediction?<\/p><\/li>\n  <li><p>What happens in backend when predictive webservice API is called?<\/p><\/li>\n  <\/ol>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-03-06 12:33:53.757 UTC",
        "Question_favorite_count":1.0,
        "Question_score":0,
        "Question_tags":"azure|azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":92,
        "Owner_creation_date":"2017-09-08 10:46:44.87 UTC",
        "Owner_last_access_date":"2019-07-02 09:54:16.807 UTC",
        "Owner_location":"Pune, Maharashtra, India",
        "Owner_reputation":391,
        "Owner_up_votes":49,
        "Owner_down_votes":0,
        "Owner_views":125,
        "Answer_body":"<p>This is only based on my experience with Azure ML, but I think I can help with your questions.<\/p>\n\n<blockquote>\n  <p>When web job hits our predictive webservice, will the trained ML model be run again?<\/p>\n<\/blockquote>\n\n<p>Yes, in the sense that it will call the <code>predict<\/code> (or similar) method on the model on the new data. For instance, in <code>scikit-learn<\/code> you would train your model using the <code>fit<\/code> method. Once the model is in production, only the <code>predict<\/code> method would be called.<\/p>\n\n<p>It will also run the whole workflow you have set up to be deployed as the web service. As an example below is a workflow I've played around with before. Each time the web service is run with new data, this whole thing will be run. This is like creating a Pipeline in <code>scikit-learn<\/code>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YMFZb.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YMFZb.png\" alt=\"Azure ML Workflow\"><\/a><\/p>\n\n<blockquote>\n  <p>Do we need to convert the UTC timezone for new incoming test data( which we want to predict) into CST\/CDT timezone, as TimeStamp does matter for our prediction?<\/p>\n<\/blockquote>\n\n<p>I would say yes, you would need to convert to the timezone that was used when training in the model. This can be done by adding a step in your workflow then when you call the web service it will do the necessary converting for you before making a prediction.<\/p>\n\n<blockquote>\n  <p>What happens in backend when predictive webservice API is called?<\/p>\n<\/blockquote>\n\n<p>I'm not sure if anyone knows for sure other than the folks at Microsoft, but for sure it will run the workflow you have set up.<\/p>\n\n<hr>\n\n<p>I know it's not much, but I hope this helps or at least gets you on the right track for what you need.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2018-03-14 11:19:15.92 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Importing images Azure Machine Learning Studio",
        "Question_body":"<p>Is it possible to import images from your Azure storage account from within a Python script module as opposed to using the Import Images module that Azure ML Studio provides. Ideally I would like to use <code>cv2.imread()<\/code>. I only want to read in grayscale data but the Import Images module reads in RGB. \nCan I use the <code>BlockBlobService<\/code> library as if I were calling it from an external Python script?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-02-07 03:27:22.043 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-blob-storage|azure-machine-learning-studio",
        "Question_view_count":812,
        "Owner_creation_date":"2015-10-12 03:10:51.79 UTC",
        "Owner_last_access_date":"2022-09-22 00:25:05.207 UTC",
        "Owner_location":"Sydney NSW, Australia",
        "Owner_reputation":823,
        "Owner_up_votes":98,
        "Owner_down_votes":8,
        "Owner_views":48,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-02-07 06:01:13.667 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"The \"perfect error\": untraceable, unnamed, from neverland",
        "Question_body":"<p>I have an experiment running without problems when I run single modules as selected parts.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/aVsSC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/aVsSC.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The situation is pretty different when I run the entire experiment. In that case it fails, but I cannot know why.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/N2h11.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/N2h11.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The experiment returns an error and obviously it doesn't let me deploy the web service, while:<\/p>\n\n<p>1) I cannot know on <strong>which module<\/strong> my error is.<\/p>\n\n<p>2) I don't have an overall description of the error.<\/p>\n\n<p>3) It could be related to the error here but I cannot know because I don't have any feedback about that. I know that it could be a <strong>bug<\/strong> Azure is trying to solve but this is not reported anywhere.<\/p>\n\n<p>I really need to know if that's a bug and if I can do something about that.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2016-07-21 13:16:15.653 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"debugging|azure|feedback|azure-machine-learning-studio",
        "Question_view_count":75,
        "Owner_creation_date":"2015-07-09 09:05:28.61 UTC",
        "Owner_last_access_date":"2022-09-19 17:14:25.487 UTC",
        "Owner_location":"Colleferro, Italy",
        "Owner_reputation":809,
        "Owner_up_votes":109,
        "Owner_down_votes":0,
        "Owner_views":361,
        "Answer_body":"<p>This issue has been resolved. Please let me know if this happens again<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-07-28 06:57:13.83 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to time tigger a python script in the Azure ML notebooks",
        "Question_body":"<p>Hi I am currently working on a small image classification project where the model classifies whether the image contains potholes or not. For this section i have wrote the python script, and this script needs to be triggered at scheduled time. I created a scheduled compute instance but the script doesn't get implemented when the compute instance is running. So i want to know what method should i use to get this sorted.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2022-05-12 10:36:00.12 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure-functions|azure-machine-learning-studio|azure-container-instances|azure-notebooks",
        "Question_view_count":82,
        "Owner_creation_date":"2019-05-01 13:40:46.72 UTC",
        "Owner_last_access_date":"2022-09-11 08:42:22.377 UTC",
        "Owner_location":"1040\/3 Athurugiriya Road, Malabe, Sri Lanka",
        "Owner_reputation":25,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"azure custom vision model precision",
        "Question_body":"<p>Im having problems in identifying  the best way to optimize the custom vision model.<\/p>\n\n<ol>\n<li><p>In using Image classification, will labeling the same image with different label at different time effect the precision of machine learning? \n\/\/for example labeling and training image A today with the label 't-shirt', labeling and training image A tomorrow with the label 'blue'.\n\/\/We are basically trying to input one classification at a time with the same image (total of five classification, such as style and color) and wanted to know whether this way will effect the prediction precision.<\/p><\/li>\n<li><p>Will labeling larger amount of data at once when inputing the image for machine learning increase the precision of the model? (for example, will there be any difference between 50 label and 100 label for an image to learn at a time?)<\/p><\/li>\n<li><p>Is there any way to teach machine learning to identify object recognition using the result gained from the image classification, else can i teach image classification and object recognition separately with the same type of image?<\/p><\/li>\n<li><p>Will running the learning process of the machine learning longer (for example, the difference between 1hour and 10hours) always give better results?<\/p><\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2019-11-18 12:14:11.813 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|microsoft-cognitive|azure-machine-learning-service",
        "Question_view_count":73,
        "Owner_creation_date":"2018-10-09 11:30:02.26 UTC",
        "Owner_last_access_date":"2020-05-25 08:16:52.383 UTC",
        "Owner_location":null,
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-11-19 07:41:39.68 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How do you kick off an Azure ML experiment based on a scheduler?",
        "Question_body":"<p>I created an experiment within Azure ML Studio and published as a web service. I need the experiment to run nightly or possible several times a day. I currently have azure mobile services and azure web jobs as part of the application and need to create an endpoint to retrieve data from the published web service. Obviously, the whole point is to make sure I have updated data.<\/p>\n\n<p>I see answers like use azure data factory but I need specifics as in how to actually set up the scheduler.<\/p>\n\n<p>I explain my dilemma further @ <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/e7126c6e-b43e-474a-b461-191f0e27eb74\/scheduling-a-machine-learning-experiment-and-publishing-nightly?forum=AzureDataFactory\" rel=\"nofollow\">https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/e7126c6e-b43e-474a-b461-191f0e27eb74\/scheduling-a-machine-learning-experiment-and-publishing-nightly?forum=AzureDataFactory<\/a><\/p>\n\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2016-02-25 00:32:46.85 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":192,
        "Owner_creation_date":"2011-09-13 16:31:27.497 UTC",
        "Owner_last_access_date":"2019-11-12 19:36:29.83 UTC",
        "Owner_location":null,
        "Owner_reputation":923,
        "Owner_up_votes":13,
        "Owner_down_votes":5,
        "Owner_views":63,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2016-03-01 06:16:22.913 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureDevOPS ML Error: We could not find config.json in: \/home\/vsts\/work\/1\/s or in its parent directories",
        "Question_body":"<p>I am trying to create an Azure DEVOPS ML Pipeline. The following code works 100% fine on Jupyter Notebooks, but when I run it in Azure Devops I get this error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;src\/my_custom_package\/data.py&quot;, line 26, in &lt;module&gt;\n    ws = Workspace.from_config()\n  File &quot;\/opt\/hostedtoolcache\/Python\/3.8.7\/x64\/lib\/python3.8\/site-packages\/azureml\/core\/workspace.py&quot;, line 258, in from_config\n    raise UserErrorException('We could not find config.json in: {} or in its parent directories. '\nazureml.exceptions._azureml_exception.UserErrorException: UserErrorException:\n    Message: We could not find config.json in: \/home\/vsts\/work\/1\/s or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;We could not find config.json in: \/home\/vsts\/work\/1\/s or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;\n    }\n}\n<\/code><\/pre>\n<p>The code is:<\/p>\n<pre><code>#import\nfrom sklearn.model_selection import train_test_split\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.core.experiment import Experiment\nfrom datetime import date\nfrom azureml.core import Workspace, Dataset\n\n\n\nimport pandas as pd\nimport numpy as np\nimport logging\n\n#getdata\nsubscription_id = 'mysubid'\nresource_group = 'myrg'\nworkspace_name = 'mlplayground'\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\ndataset = Dataset.get_by_name(workspace, name='correctData')\n\n\n#auto ml\nws = Workspace.from_config()\n\n\nautoml_settings = {\n    &quot;iteration_timeout_minutes&quot;: 2880,\n    &quot;experiment_timeout_hours&quot;: 48,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;primary_metric&quot;: 'spearman_correlation',\n    &quot;featurization&quot;: 'auto',\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;n_cross_validations&quot;: 5,\n    &quot;max_concurrent_iterations&quot;: 4,\n    &quot;max_cores_per_iteration&quot;: -1,\n}\n\n\n\ncpu_cluster_name = &quot;computecluster&quot;\ncompute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\nprint(compute_target)\nautoml_config = AutoMLConfig(task='regression',\n                             compute_target = compute_target,\n                             debug_log='automated_ml_errors.log',\n                             training_data = dataset,\n                             label_column_name=&quot;paidInDays&quot;,\n                             **automl_settings)\n\ntoday = date.today()\nd4 = today.strftime(&quot;%b-%d-%Y&quot;)\n\nexperiment = Experiment(ws, &quot;myexperiment&quot;+d4)\nremote_run = experiment.submit(automl_config, show_output = True)\n\nfrom azureml.widgets import RunDetails\nRunDetails(remote_run).show()\n\nremote_run.wait_for_completion()\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-02-01 11:05:33.493 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":2339,
        "Owner_creation_date":"2011-04-05 19:05:03.093 UTC",
        "Owner_last_access_date":"2022-09-16 12:42:27.473 UTC",
        "Owner_location":"Brussels, B\u00e9lgica",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Answer_body":"<p>There is something weird happening on your code, you are getting the data from a first workspace (<code>workspace = Workspace(subscription_id, resource_group, workspace_name)<\/code>), then using the resources from a second one (<code>ws = Workspace.from_config()<\/code>). I would suggest avoiding having code relying on two different workspaces, especially when you know that an underlying datasource can be registered (linked) to multiple workspaces (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#create-and-register-datastores\" rel=\"nofollow noreferrer\">documentation<\/a>).<\/p>\n<p>In general using a <code>config.json<\/code> file when instantiating a <code>Workspace<\/code> object will result in an interactive authentication. When your code will be processed and you will have a log asking you to reach a specific URL and enter a code. This will use your Microsoft account to verify that you are authorized to access the Azure resource (in this case your <code>Workspace('mysubid', 'myrg', 'mlplayground')<\/code>). This has its limitations when you start deploying the code onto virtual machines or agents, you will not always manually check the logs, access the URL and authenticate yourself.<\/p>\n<p>For this matter it is strongly recommended setting up more advanced authentication methods and personally I would suggest using the service principal one since it is simple, convinient and secure if done properly.\nYou can follow Azure's official documentation <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-setup-authentication#configure-a-service-principal\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-02-09 10:17:20.13 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"azure ml & Pytorch: sample conda-dependencies.yml and docker?",
        "Question_body":"<p>Could you please point me to the documentation sample showcasing how to put together pytorch dependencies for training on AzureML?\nFew related questions to the scenario of running pytorch training workloads on AzureML: <\/p>\n\n<ul>\n<li>How can I set cuda version to 10.1? <\/li>\n<li><p>Could you please point to sample demonstrating how to use \u201cofficial\u201d pytorch docker <a href=\"https:\/\/hub.docker.com\/r\/pytorch\/pytorch\" rel=\"nofollow noreferrer\">https:\/\/hub.docker.com\/r\/pytorch\/pytorch<\/a>  (which should have all cuda stuff <a href=\"https:\/\/github.com\/pytorch\/pytorch\/blob\/master\/docker\/pytorch\/Dockerfile\" rel=\"nofollow noreferrer\">https:\/\/github.com\/pytorch\/pytorch\/blob\/master\/docker\/pytorch\/Dockerfile<\/a>)?.  <\/p><\/li>\n<li><p>I\u2019ve found <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/pytorch\/training\/distributed-pytorch-with-horovod\/distributed-pytorch-with-horovod.yml\" rel=\"nofollow noreferrer\">distributed-pytorch-with-horovod.ym<\/a>l in the docs but it does not mention any pytorch dependencies  -- am I looking in the right place?<\/p><\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-12-26 19:28:05.98 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"docker|pytorch|azure-machine-learning-service",
        "Question_view_count":490,
        "Owner_creation_date":"2017-05-14 21:57:35.123 UTC",
        "Owner_last_access_date":"2020-01-24 22:27:50.953 UTC",
        "Owner_location":"Redmond, WA, United States",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-02-03 22:21:16.267 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"ModelNotFoundError when deploying machine learning model on ACI",
        "Question_body":"<p>Please am trying to deploy a machine learning model on ACI but am having this error below at the final stage when trying to deploy the model as a  webservice on Azure. Help advise on how to fix it.<\/p>\n<pre><code>2020-08-10T11:01:28,103498848+00:00 - rsyslog\/run \n2020-08-10T11:01:28,109724839+00:00 - nginx\/run \n2020-08-10T11:01:28,111248110+00:00 - gunicorn\/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2020-08-10T11:01:28,192849628+00:00 - iot-server\/finish 1 0\n2020-08-10T11:01:28,194532107+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 19.9.0\nListening at: http:\/\/127.0.0.1:31311 (18)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 42\nSPARK_HOME not set. Skipping PySpark Initialization.\nException in worker process\nTraceback (most recent call last):\n  File &quot;\/azureml-envs\/azureml_d31cd964833447a6573171273c4f1235\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n    worker.init_process()\n  File &quot;\/azureml-envs\/azureml_d31cd964833447a6573171273c4f1235\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 129, in init_process\n    self.load_wsgi()\n  File &quot;\/azureml-envs\/azureml_d31cd964833447a6573171273c4f1235\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py&quot;, line 138, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File &quot;\/azureml-envs\/azureml_d31cd964833447a6573171273c4f1235\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n    self.callable = self.load()\n  File &quot;\/azureml-envs\/azureml_d31cd964833447a6573171273c4f1235\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 52, in load\n    return self.load_wsgiapp()\n  File &quot;\/azureml-envs\/azureml_d31cd964833447a6573171273c4f1235\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 41, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File &quot;\/azureml-envs\/azureml_d31cd964833447a6573171273c4f1235\/lib\/python3.7\/site-packages\/gunicorn\/util.py&quot;, line 350, in import_app\n    __import__(module)\n  File &quot;\/var\/azureml-server\/wsgi.py&quot;, line 1, in &lt;module&gt;\n    import create_app\n  File &quot;\/var\/azureml-server\/create_app.py&quot;, line 3, in &lt;module&gt;\n    from app import main\n  File &quot;\/var\/azureml-server\/app.py&quot;, line 31, in &lt;module&gt;\n    import main as user_main\nModuleNotFoundError: No module named 'main'\nWorker exiting (pid: 42)\nShutting down: Master\nReason: Worker failed to boot.\n2020-08-10T11:01:28,524618650+00:00 - gunicorn\/finish 3 0\n2020-08-10T11:01:28,526020716+00:00 - Exit code 3 is not normal. Killing image.\n<\/code><\/pre>\n<p>Here is the scoring script am using. Please advise if I need to import any function. Everything seems okay to me. Find it difficult to identify any issue<\/p>\n<pre><code>\nfrom azureml.contrib.services.aml_request import AMLRequest, rawhttp\nfrom azureml.contrib.services.aml_response import AMLResponse\nimport json\n\n\nfrom azureml.core.model import Model\nfrom azureml.contrib.services.aml_request import AMLRequest, rawhttp\nfrom azureml.contrib.services.aml_response import AMLResponse\n\n# Done - Faster\nfrom sentence_transformers import SentenceTransformer\nfrom sentence_transformers import models, losses\nimport scipy.spatial\nimport pickle as pkl\nimport pickle\n\nimport pandas as pd\nimport os\n\nfrom collections import OrderedDict\n  \n\nimport re\ndef clean_text(text):\n  \n  text = re.sub('\\r\\n','\\n',text)\n  text = re.sub('\\r','',text)\n  text = re.sub(r'\\s+',' ',text)\n  text = re.sub(r'\\n',' ',text)\n\n  return text\n  \n  \ndef init():\n  \n  print(&quot;This is init()&quot;)\n  \n  global model, on_path, ifc_inv, ifc_adv, wb_lend, wb_adv, smart_lesson, ifc_inv_data_map, ifc_adv_data_map, wb_lend_data_map, wb_adv_data_map, smart_lesson_data_map\n\n  on_path = Model.get_model_path(model_name='Docker_custom_KP_model', version = 2)\n  \n  \n  ## Read in Data Files Fix\n  ifc_inv =  pd.read_csv(os.path.join(on_path,'Assets\/data_file\/ifc_data\/ifc_inv.csv'),  lineterminator='\\n')\n  ifc_adv =  pd.read_csv(os.path.join(on_path,'Assets\/data_file\/ifc_data\/ifc_adv.csv'), lineterminator='\\n')\n\n  # WB data\n  wb_lend =  pd.read_csv(os.path.join(on_path,'Assets\/data_file\/wb_data\/wb_lend.csv'), lineterminator='\\n')\n  wb_adv  =  pd.read_csv(os.path.join(on_path,'Assets\/data_file\/wb_data\/wb_adv.csv') , lineterminator='\\n')\n\n  # Lesson data\n  smart_lesson = pd.read_csv(os.path.join(on_path,'Assets\/data_file\/lesson_data\/smart_lesson.csv'),  lineterminator='\\n')\n\n  \n  \n  ## Read in Data Map #Fix\n  ifc_inv_data_map = pd.read_csv(os.path.join(on_path,'Assets\/data_map\/ifc_inv_data_map.csv'))\n  ifc_adv_data_map = pd.read_csv(os.path.join(on_path,'Assets\/data_map\/ifc_adv_data_map.csv'))\n\n  wb_lend_data_map = pd.read_csv(os.path.join(on_path,'Assets\/data_map\/wb_lend_data_map.csv'))\n  wb_adv_data_map = pd.read_csv(os.path.join(on_path,'Assets\/data_map\/wb_adv_data_map.csv'))\n\n  smart_lesson_data_map = pd.read_csv(os.path.join(on_path,'Assets\/data_map\/smart_lesson_data_map.csv'))\n  \n  ## Drop irrelevant columns\n  ifc_inv.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  ifc_inv_data_map.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  \n  ifc_adv.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  ifc_adv_data_map.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  \n  wb_lend.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  wb_lend_data_map.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  \n  wb_adv.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  wb_adv_data_map.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  \n  smart_lesson.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  smart_lesson_data_map.drop(['Unnamed: 0'], axis = 1, inplace= True)\n  \n    \n    \n  ## CLean data\n  # ## TOOD - After UAT\n  ifc_inv['Project_Description'] = ifc_inv['Project_Description'].map(clean_text)\n  ifc_adv['Project_Description'] = ifc_adv['Project_Description'].map(clean_text)\n\n  wb_lend['proj_abstract'] = wb_lend['proj_abstract'].map(clean_text)\n  wb_adv['proj_abstract'] = wb_adv['proj_abstract'].map(clean_text)\n\n  smart_lesson['Abstracts'] = smart_lesson['Abstracts'].map(clean_text)\n  \n  ## end Clean data\n  \n  \n  \n  ## Read in Models\n  #word_embedding_model = models.BERT('\/dbfs\/FileStore\/tables\/dev\/models\/BERT_model_new\/') ## fix\n  word_embedding_model = models.BERT(os.path.join(on_path,'model_dir\/')) \n\n  # Applying mean pooling to get one fixed sized sentences vector\n  pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n                                 pooling_mode_mean_tokens = True,\n                                 pooling_mode_cls_token = False,\n                                 pooling_mode_max_tokens = False\n                                )\n\n  model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n\n  \ndef text_to_embedding(model, in_text):\n  \n  query_embeddings = model.encode(in_text, show_progress_bar=True)\n  return query_embeddings\n\n\n    \n@rawhttp\ndef run(request):\n  \n  print(&quot;This is run()&quot;)\n  print(&quot;Request: [{0}]&quot;.format(request))\n  if request.method == 'GET':\n    # For this example, just return the URL for GETs.\n    respBody = str.encode(request.full_path)\n    return AMLResponse(respBody, 200)\n  \n  elif request.method == 'POST':\n    \n    reqBody = request.get_data(False)\n    \n    in_text = json.loads(reqBody)['input_query']\n    in_text = [in_text]\n    \n    req_page = json.loads(reqBody)['request_page']\n    \n    n_row = json.loads(reqBody)['n_request']\n    n_row = int(n_row)\n\n    if req_page == 'IFCInvestment':\n      \n      relevant_file_dir = os.path.join(on_path,'Assets\/data_file\/ifc_data\/ifc_inv.csv')\n      data_map = os.path.join(on_path,'Assets\/data_map\/ifc_inv_data_map.csv')\n\n      #vector_dir = '.\/KPrequest\/inference_data\/' + request_page + '\/faiss_inv.index'\n\n      with open(os.path.join(on_path,'Assets\/embeddings\/embedding_ifc_inv.pkl'), 'rb') as f:\n        corpus_vecs = pickle.load(f)\n\n      vec = text_to_embedding(model, in_text)\n      #vec = [vec]\n\n      relevant_df = ifc_inv  #pd.read_csv(relevant_file_dir, lineterminator='\\n')\n      data_map_df = ifc_inv_data_map #pd.read_csv(data_map)\n\n      #relevant_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n      #data_map_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n\n\n    if req_page == 'IFCAdv':\n\n      relevant_file_dir = os.path.join(on_path,'Assets\/data_file\/ifc_data\/ifc_adv.csv')\n      data_map = os.path.join(on_path,'Assets\/data_map\/ifc_adv_data_map.csv')\n\n      #vector_dir = '.\/KPrequest\/inference_data\/' + request_page + '\/faiss_inv.index'\n\n      with open(os.path.join(on_path,'Assets\/embeddings\/embedding_ifc_adv.pkl'), 'rb') as f:\n        corpus_vecs = pickle.load(f)\n\n      vec = text_to_embedding(model, in_text)\n      #vec = [vec]\n\n      relevant_df = ifc_adv  #pd.read_csv(relevant_file_dir, lineterminator='\\n')\n      data_map_df = ifc_adv_data_map #pd.read_csv(data_map)\n\n      #relevant_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n      #data_map_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n\n\n    if req_page == 'IFCLesson':\n      \n      relevant_file_dir = os.path.join(on_path,'Assets\/data_file\/lesson_data\/smart_lesson.csv')\n      data_map = os.path.join(on_path,'Assets\/data_map\/smart_lesson_data_map.csv')\n\n      #vector_dir = '.\/KPrequest\/inference_data\/' + request_page + '\/faiss_inv.index'\n\n      with open(os.path.join(on_path,'Assets\/embeddings\/embedding_smart_lesson.pkl'), 'rb') as f:\n        corpus_vecs = pickle.load(f)\n\n      vec = text_to_embedding(model, in_text)\n      #vec = [vec]\n\n      relevant_df = smart_lesson  #pd.read_csv(relevant_file_dir, lineterminator='\\n')\n      data_map_df = smart_lesson_data_map #pd.read_csv(data_map)\n\n      #relevant_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n      #data_map_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n\n\n    if req_page == 'WBLend':\n\n      relevant_file_dir = os.path.join(on_path,'Assets\/data_file\/wb_data\/wb_lend.csv')\n      data_map = os.path.join(on_path,'Assets\/data_map\/wb_lend_data_map.csv')\n\n      #vector_dir = '.\/KPrequest\/inference_data\/' + request_page + '\/faiss_inv.index'\n\n      with open(os.path.join(on_path,'Assets\/embeddings\/embedding_wb_lend.pkl'), 'rb') as f:\n        corpus_vecs = pickle.load(f)\n\n      vec = text_to_embedding(model, in_text)\n      #vec = [vec]\n\n      relevant_df = wb_lend  #pd.read_csv(relevant_file_dir, lineterminator='\\n')\n      data_map_df = wb_lend_data_map #pd.read_csv(data_map)\n\n      #relevant_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n      #data_map_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n\n\n    if req_page == 'WBAdv':\n\n      relevant_file_dir = os.path.join(on_path,'Assets\/data_file\/wb_data\/wb_adv.csv')\n      data_map = os.path.join(on_path,'Assets\/data_map\/wb_adv_data_map.csv')\n\n      #vector_dir = '.\/KPrequest\/inference_data\/' + request_page + '\/faiss_inv.index'\n\n      with open(os.path.join(on_path,'Assets\/embeddings\/embedding_wb_adv.pkl'), 'rb') as f:\n        corpus_vecs = pickle.load(f)\n\n      vec = text_to_embedding(model, in_text)\n      #vec = [vec]\n\n      relevant_df = wb_adv #pd.read_csv(relevant_file_dir, lineterminator='\\n')\n      data_map_df = wb_adv_data_map  #pd.read_csv(data_map)\n\n      #relevant_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n      #data_map_df.drop(['Unnamed: 0'], axis = 1, inplace= True)\n\n\n    distances = scipy.spatial.distance.cdist(vec, corpus_vecs, &quot;cosine&quot;)[0]\n\n    results = zip(range(len(distances)), distances)\n    results = sorted(results, key = lambda x: x[1])\n    \n\n    result_index = list(map(lambda x: x[0],results))\n    map_index = data_map_df.iloc[result_index]\n\n    proj_index = map_index['Index'].to_list()\n    unique_proj_index = list(OrderedDict.fromkeys(proj_index))\n\n    relevant_df.fillna('', inplace=True)\n\n    kp_dataframe = relevant_df.loc[unique_proj_index[0: n_row]]\n    kp_result = kp_dataframe.to_dict(orient='records')\n\n    resp = AMLResponse(json.dumps(kp_result), 200)\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n\n    return resp\n  \n  else:\n    return AMLResponse(&quot;bad request&quot;, 500)```\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2020-08-10 11:56:49.84 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure-web-app-service|azure-machine-learning-service|azure-container-instances",
        "Question_view_count":198,
        "Owner_creation_date":"2018-09-18 19:45:24.587 UTC",
        "Owner_last_access_date":"2022-09-14 17:20:52.613 UTC",
        "Owner_location":"Laurel, MD, USA",
        "Owner_reputation":359,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-08-11 09:22:16.37 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning web service cannot read CSV from blob",
        "Question_body":"<p>I have successfully deployed a ML web service using the Reader module to take in CSV data from my blob storage. I can see the CSV data is correct by visualizing it in the experiment.<\/p>\n\n<p>However, when I try to provide the <strong>SAME<\/strong> CSV data as input to the web service using the BES example from this <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-consume-web-services\/\" rel=\"nofollow\">tutorial<\/a>, I get the following error:<\/p>\n\n<pre><code>Error 1000: AFx Library exception: table: The data set being scored must\ncontain all features used during training, missing feature(s): 'Col 2'.\n<\/code><\/pre>\n\n<p>This error makes no sense as the <strong>SAME<\/strong> data is successfully accepted by the experiment.<\/p>\n\n<p>Also note that the same problem occurs when I use TSV format.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2015-12-17 23:05:25.083 UTC",
        "Question_favorite_count":1.0,
        "Question_score":2,
        "Question_tags":"csv|azure|blob|azure-machine-learning-studio",
        "Question_view_count":777,
        "Owner_creation_date":"2014-03-06 04:32:31.107 UTC",
        "Owner_last_access_date":"2021-12-16 19:47:14.853 UTC",
        "Owner_location":"New Zealand",
        "Owner_reputation":624,
        "Owner_up_votes":39,
        "Owner_down_votes":1,
        "Owner_views":71,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2015-12-18 00:47:32.58 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to write Azure machine learning batch scoring results to data lake?",
        "Question_body":"<p>I'm trying to write the output of batch scoring into datalake:<\/p>\n<pre><code>    parallel_step_name = &quot;batchscoring-&quot; + datetime.now().strftime(&quot;%Y%m%d%H%M&quot;)\n    \n    output_dir = PipelineData(name=&quot;scores&quot;, \n                              datastore=def_ADL_store,\n                              output_mode=&quot;upload&quot;,\n                              output_path_on_compute=&quot;path in data lake&quot;)\n\nparallel_run_config = ParallelRunConfig(\n    environment=curated_environment,\n    entry_script=&quot;use_model.py&quot;,\n    source_directory=&quot;.\/&quot;,\n    output_action=&quot;append_row&quot;,\n    mini_batch_size=&quot;20&quot;,\n    error_threshold=1,\n    compute_target=compute_target,\n    process_count_per_node=2,\n    node_count=2\n)\n    \n    batch_score_step = ParallelRunStep(\n        name=parallel_step_name,\n        inputs=[test_data.as_named_input(&quot;test_data&quot;)],\n        output=output_dir,\n        parallel_run_config=parallel_run_config,\n        allow_reuse=False\n    )\n<\/code><\/pre>\n<p>However I meet the error: &quot;code&quot;: &quot;UserError&quot;,\n&quot;message&quot;: &quot;User program failed with Exception: Missing argument --output or its value is empty.&quot;<\/p>\n<p>How can I write results of batch score to data lake?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-07 06:12:30.297 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure-data-lake|azure-machine-learning-service",
        "Question_view_count":277,
        "Owner_creation_date":"2017-12-21 07:31:58.107 UTC",
        "Owner_last_access_date":"2022-09-23 09:12:49.323 UTC",
        "Owner_location":"China",
        "Owner_reputation":71,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":"<p>I don\u2019t think ADLS is supported for <code>PipelineData<\/code>. My suggestion is to use the workspace\u2019s default blob store for the <code>PipelineData<\/code>, then use a <code>DataTransferStep<\/code> for after the <code>ParallelRunStep<\/code> is completed.<\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_date":"2020-08-07 06:24:13.977 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Trouble reading Blob Storage File into Azure ML Notebook",
        "Question_body":"<p>I have an Excel file uploaded to my ML workspace.<\/p>\n<p>I can access the file as an azure FileDataset object. However, I don't know how to get it into a pandas DataFrame since 'FileDataset' object has no attribute 'to_dataframe'.<\/p>\n<p>Azure ML notebooks seem to make a point of avoiding pandas for some reason.<\/p>\n<p>Does anyone know how to get blob files into pandas dataframes from within Azure ML notebooks?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-04-08 00:07:55.963 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"pandas|azure|azure-machine-learning-service",
        "Question_view_count":363,
        "Owner_creation_date":"2018-07-23 17:19:51.747 UTC",
        "Owner_last_access_date":"2022-09-23 20:30:33.457 UTC",
        "Owner_location":"Huntington Beach, CA, USA",
        "Owner_reputation":29,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-04-08 10:53:46.02 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to create multiple endpoints through powershell for New AzureML WebServices",
        "Question_body":"<p>I have created a ML WebService on portal.azure.com. I wish to create multiple endpoints programmitically for this webservice using Powershell. \nHowever all the cmdlets available (Add-AmlWebServiceEndpoint) involve using the Old or Classic WebServices.<\/p>\n\n<p>Is there anyway to achieve this for New Azure ML WebServices<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-09-20 11:02:35.093 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"powershell|azure|machine-learning|azure-powershell|azure-machine-learning-studio",
        "Question_view_count":110,
        "Owner_creation_date":"2017-08-09 12:10:34.107 UTC",
        "Owner_last_access_date":"2018-07-24 08:17:17.513 UTC",
        "Owner_location":null,
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Is there a way to un-register an environment in Azure ML studio",
        "Question_body":"<p>I am trying to deploy a model in Azure ML and kept on getting the error 'model not found' from my score.py. So I decided to start from scratch again. I had my custom environment registered, and the Azure ML API for Environment class doesn't seem to have anything like 'delete' or 'unregister'. is there a way to work around this? Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-22 16:12:00.473 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":424,
        "Owner_creation_date":"2020-07-19 00:31:40.083 UTC",
        "Owner_last_access_date":"2021-08-19 14:16:52.393 UTC",
        "Owner_location":"Toronto, ON, Canada",
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":"<p>You can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py&amp;preserve-view=true#delete--\" rel=\"nofollow noreferrer\">delete<\/a> method in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py\" rel=\"nofollow noreferrer\">Model<\/a> class to delete a registered model.<\/p>\n<p>This can also be done via the Azure CLI as:<\/p>\n<pre><code>az ml model delete &lt;model id&gt;\n<\/code><\/pre>\n<p>Other commands can be found here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/model?view=azure-cli-latest\" rel=\"nofollow noreferrer\">az ml model<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-31 13:34:49.467 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2020-11-01 23:56:25.247 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"No ready replicas for service - azure aks",
        "Question_body":"<p>I am following the below link to deploy a model to azure Kubernetes service using SDK.\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service<\/a><\/p>\n\n<p>When I call deployed service, while it is running, either by service.run() or by request.post(). I get this message \"No ready replicas for service\". Then in a while service goes to transitioning state. Any suggestions?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-11 06:57:02.833 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|python-3.x|azure|azure-aks|azure-machine-learning-service",
        "Question_view_count":463,
        "Owner_creation_date":"2015-03-13 09:18:37.637 UTC",
        "Owner_last_access_date":"2021-01-22 14:22:32.703 UTC",
        "Owner_location":null,
        "Owner_reputation":111,
        "Owner_up_votes":42,
        "Owner_down_votes":0,
        "Owner_views":40,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-06-11 12:31:51.8 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to use Azure ML API with Ruby on Rails",
        "Question_body":"<p>I am using the code with a URL and API key but every time i will get the some error of 405 or 400. Is there any proper way to implement Azure ML API in Rails.<\/p>\n\n<p>The code as below :- <\/p>\n\n<p>data =  {<\/p>\n\n<pre><code>\"Inputs\" =&gt; {\n\n        \"input1\" =&gt;\n        {\n            \"ColumnNames\" =&gt; @a,\n            \"Values\" =&gt; [ @writer ]\n        },        },\n    \"GlobalParameters\" =&gt; {\n}\n}\n\nbody = data.to_json\nputs \"adssssssssssssssssssssssssssssss#{body}\"\nurl = \"https:\/\/ussouthcentral.services.azureml.net\/workspaces\/5aecd8f887e64999a9c854d724e5\/services\/5f350fa1b48647ce95c5279eee2170d0\/execute?api-version=2.0&amp;details=true\"\napi_key = 'wGMMQGYlo4tttV+oTjrR\/tyt6xYSmWskCezNKkbGwvAVt0wsessJUORQ==' # Replace this with the API key for the web service\nheaders = {'Content-Type' =&gt; 'application\/json', 'Authorization' =&gt; ('Bearer '+ api_key)}\n\n\n\nurl = URI.parse(url)\nreq = Net::HTTP::Get.new(url.request_uri,headers)\nhttp = Net::HTTP.new(url.host, url.port)\nres = http.request(req)\n\n{\"Inputs\":{\"input1\":{\"ColumnNames\":[\"encounter_id\",\"patient_nbr\",\"Fname\",\"Lname\",\"Email\",\"Type\",\"race\",\"gender\",\"Birth Date\",\"Birth Year\",\"age\",\"Age Min\",\"Age Max\",\"weight\",\"admission_type_id\",\"discharge_disposition_id\",\"admission_source_id\",\"time_in_hospital\",\"payer_code\",\"medical_specialty\",\"num_lab_procedures\",\"num_procedures\",\"num_medications\",\"number_outpatient\",\"number_emergency\",\"number_inpatient\",\"number_diagnoses\",\"max_glu_serum\",\"A1Cresult\",\"metformin\",\"repaglinide\",\"nateglinide\",\"chlorpropamide\",\"glimepiride\",\"acetohexamide\",\"glipizide\",\"glyburide\",\"tolbutamide\",\"pioglitazone\",\"rosiglitazone\",\"acarbose\",\"miglitol\",\"troglitazone\",\"tolazamide\",\"examide\",\"citoglipton\",\"insulin\",\"glyburide-metformin\",\"glipizide-metformin\",\"glimepiride-pioglitazone\",\"metformin-rosiglitazone\",\"metformin-pioglitazone\",\"change\",\"diabetesMed\",\"readmitted\"],\"Values\":[[[{\"$oid\":\"56b1ab886e75720ba23b5400\"},\"\",\"Rana\",\"Warhurst\",null,\"Patient\",\"Caucasian\",\"Male\",\"2012-10-23\",\"\",3,\"\",\"\",\"\",\"\",null,null,null,\"\",null,\"\",\"\",\"\",\"\",\"\",\"\",null,\"\",\"No\",\"NO\"]]]}},\"GlobalParameters\":{}}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-02-08 12:29:30.38 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"ruby-on-rails|ruby|machine-learning|azure-machine-learning-studio",
        "Question_view_count":171,
        "Owner_creation_date":"2015-10-14 13:00:07.877 UTC",
        "Owner_last_access_date":"2022-05-31 06:10:27.773 UTC",
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":66,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":29,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-03-06 05:26:47.14 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Issues accessing a FileDataset created from HTTP URIs in a PythonScriptStep",
        "Question_body":"<p>I\u2019m having some issues trying to access a FileDataset created from two http URIs in an Azure ML Pipeline PythonScriptStep.<\/p>\n<p>In the step, I\u2019m only getting a single file named <code>['https%3A\u2019]<\/code> when doing an <code>os.listdir()<\/code> on my mount point. I would have expected two files, with their actual names instead. This happens both when sending the dataset <code>as_upload<\/code> and <code>as_mount<\/code>. Even happens when I send the dataset reference to the pipeline step and mount it directly from the step.<\/p>\n<p>The dataset is registered in a notebook, the same notebook that creates and invokes the pipeline, as seen below:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>tempFileData = Dataset.File.from_files(\n        ['https:\/\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg',\n        'https:\/\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg'])\ntempFileData.register(ws, name='FileData', create_new_version=True)\n\n#...\n\nread_datasets_step = PythonScriptStep(\n    name='The Dataset Reader',\n    script_name='read-datasets.py',\n    inputs=[fileData.as_named_input('Files'), fileData.as_named_input('Files_mount').as_mount(), fileData.as_named_input('Files_download').as_download()],\n    compute_target=compute_target,\n    source_directory='.\/dataset-reader',\n    allow_reuse=False,\n)\n\n<\/code><\/pre>\n<p>The <code>FileDataset<\/code> seems to be registered properly, if I examine it within the notebook I get the following result:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;source&quot;: [\n    &quot;https:\/\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg&quot;,\n    &quot;https:\/\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg&quot;\n  ],\n  &quot;definition&quot;: [\n    &quot;GetFiles&quot;\n  ],\n  &quot;registration&quot;: {\n    &quot;id&quot;: &quot;...&quot;,\n    &quot;name&quot;: &quot;FileData&quot;,\n    &quot;version&quot;: 4,\n    &quot;workspace&quot;: &quot;Workspace.create(...)&quot;\n  }\n}\n<\/code><\/pre>\n<p>For reference, the machine running the notebook is using AML SDK v1.24, whereas the node running the pipeline steps is running v1.25.<\/p>\n<p>Has anybody encountered anything like this? Is there a way to make it work?<\/p>\n<p>Note that I'm specifically looking at file datasets created from web uris, and not necessarily interested in getting a <code>FileDataset<\/code> to work with blob storage or similar.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-19 11:38:44.14 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":91,
        "Owner_creation_date":"2009-08-13 10:15:52.417 UTC",
        "Owner_last_access_date":"2022-09-22 11:46:38.323 UTC",
        "Owner_location":"Romania",
        "Owner_reputation":7916,
        "Owner_up_votes":1735,
        "Owner_down_votes":33,
        "Owner_views":801,
        "Answer_body":"<p>The files should've been mounted at path &quot;https%3A\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg&quot; and &quot;https%3A\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg&quot;.<\/p>\n<p>We retain the directory structure following the url structure to avoid potential conflicts.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-19 17:59:29.223 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2021-04-19 16:18:14.43 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Request Response latency",
        "Question_body":"<p>I have made an Azure Machine Learning Experiment which takes a small dataset (12x3 array) and some parameters and does some calculations using a few Python modules (a linear regression calculation and some more). This all works fine.<\/p>\n\n<p>I have deployed the experiment and now want to throw data at it from the front-end of my application. The API-call goes in and comes back with correct results, but it takes up to 30 seconds to calculate a simple linear regression. Sometimes it is 20 seconds, sometimes only 1 second. I even got it down to 100 ms one time (which is what I'd like), but 90% of the time the request takes more than 20 seconds to complete, which is unacceptable.<\/p>\n\n<p>I guess it has something to do with it still being an experiment, or it is still in a development slot, but I can't find the settings to get it to run on a faster machine.<\/p>\n\n<p>Is there a way to speed up my execution?<\/p>\n\n<p>Edit: To clarify: The varying timings are obtained with the same test data, simply by sending the same request multiple times. This made me conclude it must have something to do with my request being put in a queue, there is some start-up latency or I'm throttled in some other way.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-01-25 10:40:39.993 UTC",
        "Question_favorite_count":5.0,
        "Question_score":8,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":1128,
        "Owner_creation_date":"2015-10-29 11:07:20.793 UTC",
        "Owner_last_access_date":"2020-05-19 23:12:48.357 UTC",
        "Owner_location":"Antwerp, Belgium",
        "Owner_reputation":311,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":34,
        "Answer_body":"<p>First, I am assuming you are doing your timing test on the published AML endpoint.<\/p>\n\n<p>When a call is made to the AML the first call must warm up the container. By default a web service has 20 containers. Each container is cold, and a cold container can cause a large(30 sec) delay. In the string returned by the AML endpoint, only count requests that have the <code>isWarm<\/code> flag set to true. By smashing the service with MANY requests(relative to how many containers you have running) can get all your containers warmed.<\/p>\n\n<p>If you are sending out dozens of requests a instance, the endpoint might be getting throttled. You can adjust the number of calls your endpoint can accept by going to manage.windowsazure.com\/<\/p>\n\n<ol>\n<li>manage.windowsazure.com\/<\/li>\n<li>Azure ML Section from left bar<\/li>\n<li>select your workspace<\/li>\n<li>go to web services tab<\/li>\n<li>Select your web service from list<\/li>\n<li>adjust the number of calls with slider<\/li>\n<\/ol>\n\n<p>By enabling debugging onto your endpoint you can get logs about the execution time for each of your modules to complete. You can use this to determine if a module is not running as you intended which may add to the time.<\/p>\n\n<p>Overall, there is an overhead when using the Execute python module, but I'd expect this request to complete in under 3 secs. <\/p>",
        "Answer_comment_count":11.0,
        "Answer_creation_date":"2016-01-26 18:20:06.127 UTC",
        "Answer_last_edit_date":"2016-01-27 16:10:48.927 UTC",
        "Answer_score":8.0,
        "Question_last_edit_date":"2016-01-27 16:15:36.527 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Consume Microsoft Cluster API using PowerBI",
        "Question_body":"<p>Thanks for getting back to me.<\/p>\n\n<p>Basically I subscribed to a Cluster API service (cortana analytics). This is the sample application as per Microsoft Machine Learning site<\/p>\n\n<p><a href=\"http:\/\/microsoftazuremachinelearning.azurewebsites.net\/ClusterModel.aspx\" rel=\"nofollow\">http:\/\/microsoftazuremachinelearning.azurewebsites.net\/ClusterModel.aspx<\/a><\/p>\n\n<p>As you could see there are 2 arguments to be passed on<\/p>\n\n<p>Input<\/p>\n\n<p>K<\/p>\n\n<p>Where input could be 10;5;2,18;1;6,7;5;5,22;3;4,12;2;1,10;3;4 (each row is separated by semi colon)<\/p>\n\n<p>And K is cluster number: 5 (for example)<\/p>\n\n<p>So to consume this API I use PowerBI Edit Query, <\/p>\n\n<p>So go to Get Data > More > Azure > Microsoft Data MarketPlace, I can see the list of APIs I subscribed to, one of them is the one I referred to in the link above.<\/p>\n\n<p>So I load that as Function lets called it \"Score\"<\/p>\n\n<p>Then I got energy table which I loaded in from a csv file, I want to cluster energy consumption into 5 clusters.<\/p>\n\n<p>So my data layout is<\/p>\n\n<p>Year   Energy<\/p>\n\n<p>2001   6.28213<\/p>\n\n<p>2002  14.12845<\/p>\n\n<p>2003   5.55851<\/p>\n\n<p>and so on, lets say I got 100 rows of the data.<\/p>\n\n<p>So I tried to pass \"6.28213;14.12845;5.55851\", \"5\" to Score function but I dont know how to <\/p>\n\n<ol>\n<li><p>Convert my table into records<\/p><\/li>\n<li><p>pass 2 argument records and constant value 5 as K.<\/p><\/li>\n<\/ol>\n\n<p>Hope this makes sense.<\/p>\n\n<p>Please help! :)<\/p>\n\n<p>Thank you in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-10-18 13:00:01.683 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"api|powerbi|powerquery|azure-machine-learning-studio",
        "Question_view_count":137,
        "Owner_creation_date":"2015-04-01 14:40:03.63 UTC",
        "Owner_last_access_date":"2022-03-26 09:51:33.257 UTC",
        "Owner_location":null,
        "Owner_reputation":403,
        "Owner_up_votes":21,
        "Owner_down_votes":0,
        "Owner_views":200,
        "Answer_body":"<p>To convert a column of numbers into a semicolon delimited text, do this to your table:<\/p>\n\n<ol>\n<li>Convert your Energy column is type text.<\/li>\n<li>Add <code>[Energy]<\/code> after the name of your table, which gives you a list of the numbers.<\/li>\n<li>Use <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/mt253358.aspx\" rel=\"nofollow\"><code>Text.Combine<\/code><\/a> to turn the list into a text value seperated by <code>;<\/code><\/li>\n<\/ol>\n\n<p>Here's a mashup that does that:<\/p>\n\n<pre><code>let\n    Source = Table.FromRows(Json.Document(Binary.Decompress(Binary.FromText(\"NcjBCQAgDAPAXfKWYqKR7iLdfw1F8J63N9Q70bBCKQ5Ue6VbnEHl9L9xz2GniaoD\", BinaryEncoding.Base64), Compression.Deflate)), let _t = ((type text) meta [Serialized.Text = true]) in type table [Year = _t, Energy = _t]),\n    #\"Changed Type\" = Table.TransformColumnTypes(Source,{{\"Year\", Int64.Type}, {\"Energy\", type text}}),\n    Custom1 = #\"Changed Type\"[Energy],\n    Custom2 = Text.Combine(Custom1, \";\")\nin\n    Custom2\n<\/code><\/pre>\n\n<hr>\n\n<p>Once you have a function, you'll invoke it like <code>YourFunction(Custum2, 5)<\/code><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2016-10-19 16:58:20.823 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to parallelize work on an Azure ML Service Compute cluster?",
        "Question_body":"<p>I am able to submit jobs to Azure ML services using a compute cluster. It works well, and the autoscaling combined with good flexibility for custom environments seems to be exactly what I need. However, so far all these jobs seem to only use one compute node of the cluster. Ideally I would like to use multiple nodes for a computation, but all methods that I see rely on rather deep integration with azure ML services.<\/p>\n\n<p>My modelling case is a bit atypical. From previous experiments I identified a group of architectures (pipelines of preprocessing steps + estimators in Scikit-learn) that worked well. \nHyperparameter tuning for one of these estimators can be performed reasonably fast (couple of minutes) with <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV\" rel=\"nofollow noreferrer\">RandomizedSearchCV<\/a>. So it seems less effective to parallelize this step.<\/p>\n\n<p>Now I want to tune and train this entire list of architectures.\nThis should be very easily to parallelize since all architectures can be trained independently. <\/p>\n\n<p>Ideally I would like something like (in pseudocode)<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>tuned = AzurePool.map(tune_model, [model1, model2,...])\n<\/code><\/pre>\n\n<p>However, I could not find any resources on how I could achieve this with an Azure ML Compute cluster.\nAn acceptable alternative would come in the form of a plug-and-play substitute for sklearn's CV-tuning methods, similar to the ones provided in <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV\" rel=\"nofollow noreferrer\">dask<\/a> or <a href=\"https:\/\/databricks.github.io\/spark-sklearn-docs\/#spark_sklearn.GridSearchCV\" rel=\"nofollow noreferrer\">spark<\/a>.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-16 14:48:33.733 UTC",
        "Question_favorite_count":1.0,
        "Question_score":3,
        "Question_tags":"python|azure|scikit-learn|cluster-computing|azure-machine-learning-service",
        "Question_view_count":818,
        "Owner_creation_date":"2018-05-01 15:15:47.29 UTC",
        "Owner_last_access_date":"2022-09-23 13:50:22.17 UTC",
        "Owner_location":"Belgium",
        "Owner_reputation":1466,
        "Owner_up_votes":361,
        "Owner_down_votes":11,
        "Owner_views":118,
        "Answer_body":"<p>There are a number of ways you could tackle this with AzureML. The simplest would be to just launch a number of jobs using the AzureML Python SDK (the underlying example is taken from <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/4170a394edd36413edebdbab347afb0d833c94ee\/how-to-use-azureml\/training\/train-hyperparameter-tune-deploy-with-sklearn\/train-hyperparameter-tune-deploy-with-sklearn.ipynb\" rel=\"nofollow noreferrer\">here<\/a>)<\/p>\n\n<pre><code>from azureml.train.sklearn import SKLearn\n\nruns = []\n\nfor kernel in ['linear', 'rbf', 'poly', 'sigmoid']:\n    for penalty in [0.5, 1, 1.5]:\n        print ('submitting run for kernel', kernel, 'penalty', penalty)\n        script_params = {\n            '--kernel': kernel,\n            '--penalty': penalty,\n        }\n\n        estimator = SKLearn(source_directory=project_folder, \n                            script_params=script_params,\n                            compute_target=compute_target,\n                            entry_script='train_iris.py',\n                            pip_packages=['joblib==0.13.2'])\n\n        runs.append(experiment.submit(estimator))\n<\/code><\/pre>\n\n<p>The above requires you to factor your training out into a script (or a set of scripts in a folder) along with the python packages required. The above estimator is a convenience wrapper for using Scikit Learn. There are also estimators for Tensorflow, Pytorch, Chainer and a generic one (<code>azureml.train.estimator.Estimator<\/code>) -- they all differ in the Python packages and base docker they use.<\/p>\n\n<p>A second option, if you are actually tuning parameters, is to use the HyperDrive service like so (using the same <code>SKLearn<\/code> Estimator as above):<\/p>\n\n<pre><code>from azureml.train.sklearn import SKLearn\nfrom azureml.train.hyperdrive.runconfig import HyperDriveConfig\nfrom azureml.train.hyperdrive.sampling import RandomParameterSampling\nfrom azureml.train.hyperdrive.run import PrimaryMetricGoal\nfrom azureml.train.hyperdrive.parameter_expressions import choice\n\nestimator = SKLearn(source_directory=project_folder, \n                    script_params=script_params,\n                    compute_target=compute_target,\n                    entry_script='train_iris.py',\n                    pip_packages=['joblib==0.13.2'])\n\nparam_sampling = RandomParameterSampling( {\n    \"--kernel\": choice('linear', 'rbf', 'poly', 'sigmoid'),\n    \"--penalty\": choice(0.5, 1, 1.5)\n    }\n)\n\nhyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n                                         hyperparameter_sampling=param_sampling, \n                                         primary_metric_name='Accuracy',\n                                         primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                                         max_total_runs=12,\n                                         max_concurrent_runs=4)\n\nhyperdrive_run = experiment.submit(hyperdrive_run_config)\n<\/code><\/pre>\n\n<p>Or you could use DASK to schedule the work as you were mentioning. Here is a sample of how to set up DASK on and AzureML Compute Cluster so you can do interactive work on it: <a href=\"https:\/\/github.com\/danielsc\/azureml-and-dask\" rel=\"nofollow noreferrer\">https:\/\/github.com\/danielsc\/azureml-and-dask<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-08-16 21:18:45.97 UTC",
        "Answer_last_edit_date":"2019-09-05 07:54:33.437 UTC",
        "Answer_score":2.0,
        "Question_last_edit_date":"2019-08-16 20:32:31.453 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Error converting string feature to numeric in Azure ML studio",
        "Question_body":"<p><code>QuotedPremium<\/code> column is a string feature so I need to convert it to numeric value in order to use algorithm. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/QUgm0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/QUgm0.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>So, for that I am using Edit Metadata module, where I specify data type to be converted is <code>Floating Point<\/code>. <\/p>\n\n<p>After I run it - I got an error:<\/p>\n\n<pre><code>Could not convert type System.String to type System.Double, inner exception message: Input string was not in a correct format.\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/vOEku.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vOEku.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>What am I missing here?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2018-01-04 01:26:49.813 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":2072,
        "Owner_creation_date":"2016-03-10 08:00:45.393 UTC",
        "Owner_last_access_date":"2022-09-23 23:59:58.457 UTC",
        "Owner_location":"San Diego, CA, United States",
        "Owner_reputation":4046,
        "Owner_up_votes":505,
        "Owner_down_votes":7,
        "Owner_views":825,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"When should I use Azure ML Notebooks VS Azure Databricks? Both are competitor products in my opinion",
        "Question_body":"<p>Pretty self-explanatory question. When should I use Azure ML Notebooks VS Azure Databricks? I feel there\u2019s a great overlap between the two products and one is definitely better marketed than the other.. <\/p>\n\n<p>I\u2019m mainly looking for information concerning datasets sizes and typical workflow. Why should I use Databricks over AzureML if I don\u2019t have a Spark oriented workflow ?<\/p>\n\n<p>Thanks !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-01 19:25:20.13 UTC",
        "Question_favorite_count":null,
        "Question_score":7,
        "Question_tags":"azure|machine-learning|databricks|azure-machine-learning-service",
        "Question_view_count":3755,
        "Owner_creation_date":"2015-11-12 09:22:17.14 UTC",
        "Owner_last_access_date":"2022-09-21 16:03:24.94 UTC",
        "Owner_location":null,
        "Owner_reputation":313,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":40,
        "Answer_body":"<p>@Nethim, from my pov these are the main difference:<br><\/p>\n\n<ol>\n<li><p>Data Distribution:<\/p>\n\n<ul>\n<li>Azure ML Notebooks are good when you are training with a limited data on single machine. Though Azure ML provides training clusters, the data distribution among the nodes is to be handled in the code.<\/li>\n<li>Azure Databricks with its RDDs are designed to handle data distributed on multiple nodes.This is advantageous when your data size is huge.When your data size is small and can fit in a scaled up single machine\/ you are using a pandas dataframe, then use of Azure databricks is a overkill<\/li>\n<\/ul><\/li>\n<li><p>Data Cleaning:\nDatabricks can support a lot of file formats natively and querying and cleaning huge datasets are easy where as this has to be handled custom in AzureML notebooks. This can be done with a aml notebooks but cleaning and writing to stores has to be handled.<\/p><\/li>\n<li>Training\nBoth has the capabilities if distributing the training, Databricks provides inbuilt ML algorithms that can act on chunk of data on that node and coordinate with other nodes. Though this can be done on both AzureMachineLearning and Databricks with tf,horovod etc.,<\/li>\n<\/ol>\n\n<p>In general(just my opinion), if the dataset is small, aml notebooks is good.If the data size is huge, then Azure databricks is easy for datacleanup and format conversions.Then the training can happen on AML or databricks.Though databricks has a learning curve whereas Azure ML can be easy with the python and pandas.<\/p>\n\n<p>Thanks.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-04-02 10:28:00.85 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":6.0,
        "Question_last_edit_date":"2021-07-08 02:53:28.263 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Install packages in Create R Model - AzureML",
        "Question_body":"<p>Is it currently possible to install packages in 'Create R Model'? Currently this is a huge limitation of AzureML.<\/p>\n\n<p>I know it is possible to do it in 'Execute R Script' but in 'Execute R Script' you can't save the model.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2016-11-10 09:55:03.003 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"r|azure|machine-learning|r-package|azure-machine-learning-studio",
        "Question_view_count":269,
        "Owner_creation_date":"2016-01-12 14:22:43.363 UTC",
        "Owner_last_access_date":"2019-07-02 21:45:24.25 UTC",
        "Owner_location":null,
        "Owner_reputation":105,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Add custom packages to Azure Machine Learing Studio",
        "Question_body":"<p>I need to use the function tsCV on azure machine learning studio to evaluate models of forecast, but i got the error <\/p>\n\n<pre><code>could not find function \"tsCV\n<\/code><\/pre>\n\n<p>I'm trying to update the forecast package, but no package are loaded.\nI followed this tutorial\n<a href=\"http:\/\/blog.revolutionanalytics.com\/2015\/10\/using-minicran-in-azure-ml.html\" rel=\"noreferrer\">http:\/\/blog.revolutionanalytics.com\/2015\/10\/using-minicran-in-azure-ml.html<\/a>\nand \n<a href=\"https:\/\/blog.tallan.com\/2016\/12\/27\/adding-r-packages-in-azure-ml\/\" rel=\"noreferrer\">https:\/\/blog.tallan.com\/2016\/12\/27\/adding-r-packages-in-azure-ml\/<\/a>\nbut i dont get the same result.\nNo packages are load.<\/p>\n\n<p>I need an example of a package with R code that works o Azure ML or an update of forecast package to use tsCV function.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-09-11 14:46:12.073 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":404,
        "Owner_creation_date":"2018-01-09 17:16:11.123 UTC",
        "Owner_last_access_date":"2022-07-06 14:56:48.507 UTC",
        "Owner_location":null,
        "Owner_reputation":1108,
        "Owner_up_votes":33,
        "Owner_down_votes":2,
        "Owner_views":183,
        "Answer_body":"<p>I have installed the latest version of the forecast package and here are the steps I followed during the installation. <\/p>\n\n<ol>\n<li>Download latest version of CRAN<\/li>\n<li>Be sure that tsCV is working locally<\/li>\n<li>Zip all the dependencies + forecast package<\/li>\n<li>Zip all the generated zips together and upload it to the AMLStudio<\/li>\n<li>Run the following code:<\/li>\n<\/ol>\n\n<blockquote>\n<pre><code>install.packages(\"src\/glue.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/stringi.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/assertthat.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/fansi.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/utf8.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/stringr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/labeling.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/munsell.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/R6.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/RColorBrewer.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/cli.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/crayon.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/pillar.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/xts.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/TTR.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/curl.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/digest.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/gtable.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/lazyeval.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/plyr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/reshape2.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/rlang.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/scales.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/tibble.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/viridisLite.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/withr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/quadprog.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/quantmod.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/colorspace.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/fracdiff.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggplot2.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/lmtest.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/magrittr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/Rcpp.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/timeDate.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/tseries.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/urca.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/uroot.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/zoo.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/RcppArmadillo.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/forecast.zip\", lib = \".\", repos = NULL, verbose = TRUE)\n\nlibrary(forecast, lib.loc=\".\", verbose=TRUE)\nfar2 &lt;- function(x, h){forecast(Arima(x, order=c(2,0,0)), h=h)}\ne &lt;- tsCV(lynx, far2, h=1)\n<\/code><\/pre>\n<\/blockquote>\n\n<p><a href=\"https:\/\/drive.google.com\/open?id=10Bj0RGCmRFrRECLQrVc26nbx3T-bNSL6\" rel=\"nofollow noreferrer\">Here is the zip I have generated:<\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/bbowH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bbowH.png\" alt=\"My experiment\"><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2018-09-17 13:52:18.793 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Use Azure Machine learning to detect symbol within an image",
        "Question_body":"<p>4 years ago I posted <a href=\"https:\/\/stackoverflow.com\/q\/6999920\/411094\">this question<\/a> and got a few answers that were unfortunately outside my skill level.  I just attended a build tour conference where they spoke about machine learning and this got me thinking of the possibility of using ML as a solution to my problem.  i found <a href=\"https:\/\/gallery.azureml.net\/MachineLearningAPI\/02ce55bbc0ab4fea9422fe019995c02f\" rel=\"noreferrer\">this<\/a> on the azure site but i dont think it will help me because its scope is pretty narrow.<\/p>\n\n<p>Here is what i am trying to achieve:<\/p>\n\n<p>i have a source image:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/6y76s.jpg\" alt=\"source image\"><\/p>\n\n<p>and i want to which one of the following symbols (if any) are contained in the image above:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/SuHkU.jpg\" alt=\"symbols\"><\/p>\n\n<p>the compare needs to support minor distortion, scaling, color differences, rotation, and brightness differences.<\/p>\n\n<p>the number of symbols to match will ultimately at least be greater than 100.<\/p>\n\n<p>is ML a good tool to solve this problem?  if so, any starting tips?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-06-16 05:58:53.36 UTC",
        "Question_favorite_count":3.0,
        "Question_score":14,
        "Question_tags":"opencv|azure|image-processing|machine-learning|azure-machine-learning-studio",
        "Question_view_count":6324,
        "Owner_creation_date":"2010-08-04 17:41:06.9 UTC",
        "Owner_last_access_date":"2022-09-23 19:56:34.233 UTC",
        "Owner_location":"Los Angeles, CA",
        "Owner_reputation":1141,
        "Owner_up_votes":32,
        "Owner_down_votes":0,
        "Owner_views":109,
        "Answer_body":"<p>As far as I know, Project Oxford (MS Azure CV API) wouldn't be suitable for your task. Their APIs are very focused to Face related tasks (detection, verification, etc), OCR and Image description. And apparently you can't extend their models or train new ones from the existing ones.<\/p>\n\n<p>However, even though I don't know an out of the box solution for your object detection problem; there are easy enough approaches that you could try and that would give you some start point results.<\/p>\n\n<p>For instance, here is a naive method you could use:<\/p>\n\n<p><strong>1) Create your dataset:<\/strong>\n    This is probably the more tedious step and paradoxically a crucial one. I will assume you have a good amount of images to work with. What would you need to do is to pick a fixed window size and extract positive and negative examples.\n<img src=\"https:\/\/i.stack.imgur.com\/H4uC5.png\" alt=\"enter image description here\"><\/p>\n\n<p>If some of the images in your dataset are in different sizes you would need to rescale them to a common size. You don't need to get too crazy about the size, probably 30x30 images would be more than enough. To make things easier I would turn the images to gray scale too. <\/p>\n\n<p><strong>2) Pick a classification algorithm and train it:<\/strong>\n    There is an awful amount of classification algorithms out there. But if you are new to machine learning I will pick the one I would understand the most. Keeping that in mind, I would check out logistic regression which give decent results, it's easy enough for starters and have a lot of libraries and tutorials. For instance, <a href=\"http:\/\/blog.yhathq.com\/posts\/logistic-regression-and-python.html\" rel=\"noreferrer\">this one<\/a> or <a href=\"https:\/\/msdn.microsoft.com\/en-us\/magazine\/dn948113.aspx\" rel=\"noreferrer\">this one<\/a>. At first I would say to focus in a binary classification problem (like if there is an UD logo in the picture or not) and when you master that one you can jump to the multi-class case. There are resources for that <a href=\"http:\/\/www.codeproject.com\/Articles\/821347\/MultiClass-Logistic-Classifier-in-Python\" rel=\"noreferrer\">too<\/a> or you can always have several models one per logo and run this recipe for each one separately. <\/p>\n\n<p>To train your model, you just need to read the images generated in the step 1 and turn them into a vector and label them accordingly. That would be the  dataset that will feed your model. If you are using images in gray scale, then each position in the vector would correspond to a pixel value in the range 0-255. Depending on the algorithm you might need to rescale those values to the range [0-1] (this is because some algorithms perform better with values in that range). Notice that rescaling the range in this case is fairly easy (new_value = value\/255).<\/p>\n\n<p>You also need to split your dataset, reserving some examples for training, a subset for validation and another one for testing. Again, there are different ways to do this, but I'm keeping this answer as naive as possible.<\/p>\n\n<p><strong>3) Perform the detection:<\/strong>\n    So now let's start the fun part. Given any image you want to run your model and produce coordinates in the picture where there is a logo. There are different ways to do this and I will describe one that probably <strong>is not the best nor the more efficient<\/strong>, but it's easier to develop in my opinion.<\/p>\n\n<p>You are going to scan the picture, extracting the pixels in a \"window\", rescaling those pixels to the size you selected in step 1 and then feed them to your model. <\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/VGk3f.png\" alt=\"Extracting windows to feed the model\"><\/p>\n\n<p>If the model give you a positive answer then you mark that window in the original image. Since the logo might appear in different scales you need to repeat this process with different window sizes. You also would need to tweak the amount of space between windows.<\/p>\n\n<p><strong>4) Rinse and repeat:<\/strong>\n    At the first iteration it's very likely that you will get a lot of false positives. Then you need to take those as negative examples and retrain your model. This would be an iterative process and hopefully on each iteration you will have less and less false positives and fewer false negatives.<\/p>\n\n<p>Once you are reasonable happy with your solution, you might want to improve it. You might want to try other classification algorithms like <a href=\"https:\/\/en.wikipedia.org\/wiki\/Support_vector_machine\" rel=\"noreferrer\">SVM<\/a> or <a href=\"https:\/\/en.wikipedia.org\/wiki\/Deep_learning\" rel=\"noreferrer\">Deep Learning Artificial Neural Networks<\/a>, or to try better object detection frameworks like <a href=\"https:\/\/en.wikipedia.org\/wiki\/Viola%E2%80%93Jones_object_detection_framework\" rel=\"noreferrer\">Viola-Jones<\/a>. Also, you will probably need to use <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cross-validation_%28statistics%29\" rel=\"noreferrer\">crossvalidation<\/a> to compare all your solutions (you can actually use crossvalidation from the beginning). By this moment I bet you would be confident enough that you would like to use OpenCV or another ready to use framework in which case you will have a fair understanding of what is going on under the hood. <\/p>\n\n<p>Also you could just disregard all this answer and go for an OpenCV object detection tutorial like this <a href=\"http:\/\/note.sonots.com\/SciSoftware\/haartraining.html\" rel=\"noreferrer\">one<\/a>. Or take another answer from another question like this <a href=\"https:\/\/stackoverflow.com\/questions\/10168686\/algorithm-improvement-for-coca-cola-can-shape-recognition?rq=1\">one<\/a>. Good luck!<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2015-06-16 15:38:50.29 UTC",
        "Answer_last_edit_date":"2017-05-23 12:18:30.023 UTC",
        "Answer_score":22.0,
        "Question_last_edit_date":"2017-05-23 12:10:45.11 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure AutoML download metrics",
        "Question_body":"<p>I was wondering if there is a way to download the metrics for a model after a run has completed in AutoML in Azure?  For example, I want to download the generated confusion matrix as a png file along with the other available metrics.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-24 20:12:54.613 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":376,
        "Owner_creation_date":"2020-05-20 20:35:04.49 UTC",
        "Owner_last_access_date":"2020-06-25 17:10:11.643 UTC",
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"View an rgl plot using Microsoft Azure Machine Learning",
        "Question_body":"<p>Using an \"execute R script module\" in Azure-ml studio, when I plot to an rgl device, I get a broken image icon under the graphics section of the R Device output.  <\/p>\n\n<p>Is there some way to view (and even interact with) the resulting rgl device?  If not is there some way to transfer the rgl output to a standard R graphics device?  <\/p>\n\n<p>Simple example:<\/p>\n\n<pre><code># put this code inside the execute R script module\nlibrary(rgl)\nrgl.spheres(0,0,0, radius=1, col=\"red\")\n<\/code><\/pre>\n\n<p>To be clear, I know about <code>rgl.snapshot<\/code> and <code>rgl.postscript<\/code> and how to save and \/or view an rgl device in a standard R session, but have not been able to make these standard approaches work in azure-ml.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-11-28 03:09:55.707 UTC",
        "Question_favorite_count":0.0,
        "Question_score":8,
        "Question_tags":"r|rgl|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":508,
        "Owner_creation_date":"2011-03-02 05:26:33.833 UTC",
        "Owner_last_access_date":"2020-09-10 18:33:17.113 UTC",
        "Owner_location":"United States",
        "Owner_reputation":16871,
        "Owner_up_votes":3339,
        "Owner_down_votes":315,
        "Owner_views":2183,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2016-03-01 16:32:13.913 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"unable to identify current timezone 'C'",
        "Question_body":"<p>all,<\/p>\n\n<p>I am using R on the Azure machine learning, and I have some problems.<\/p>\n\n<p>I want to use program R to calculate the difference between two date, for example, 2014\/11\/01 and 2014\/11\/03.<\/p>\n\n<p>I using the function \"strptime\" in R to do this thing, it can work on my own computer, but when I want to run the same code on Azure ml, it came out the error.<\/p>\n\n<p>The error is : <\/p>\n\n<pre><code>[ModuleOutput] 1: In strptime(x, format, tz = tz) :\n[ModuleOutput] \n[ModuleOutput]   unable to identify current timezone 'C':\n[ModuleOutput] \n[ModuleOutput] please set environment variable 'TZ'\n[ModuleOutput] \n[ModuleOutput] 2: In strptime(x, format, tz = tz) : unknown timezone 'localtime'\n<\/code><\/pre>\n\n<p>I think the problem is that it can't detect the timezone on Azure ml, but I'm not sure.<\/p>\n\n<p>Is there any way to solve this problem?<\/p>\n\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2014-11-06 08:20:44.47 UTC",
        "Question_favorite_count":1.0,
        "Question_score":4,
        "Question_tags":"r|timezone|azure-machine-learning-studio",
        "Question_view_count":1456,
        "Owner_creation_date":"2014-10-15 03:43:33.203 UTC",
        "Owner_last_access_date":"2022-09-23 15:05:13.727 UTC",
        "Owner_location":"Taipei City, Taiwan",
        "Owner_reputation":579,
        "Owner_up_votes":370,
        "Owner_down_votes":3,
        "Owner_views":73,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML operations : workspace authentication error",
        "Question_body":"<p>I need to connect with Azure ML Workspace during deployment over container instance.<\/p>\n<pre><code>ws = Workspace(subscription_id=&quot;your-sub-id&quot;,\n              resource_group=&quot;your-resource-group-id&quot;,\n              workspace_name=&quot;your-workspace-name&quot;\n              )\n<\/code><\/pre>\n<p>Interactive Authentication to the ML Workspace prompts to login and then fails with below error message.<\/p>\n<pre><code>AttributeError: 'BasicTokenAuthentication' object has no attribute 'get_token'\n<\/code><\/pre>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-setup-authentication#interactive-authentication\" rel=\"nofollow noreferrer\">i have been following this Azure Authentication document.<\/a><\/p>\n<p>Any help is much appreciated.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2020-09-22 07:59:04.463 UTC",
        "Question_favorite_count":0.0,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":706,
        "Owner_creation_date":"2018-06-29 07:41:06.24 UTC",
        "Owner_last_access_date":"2022-06-20 13:15:52.293 UTC",
        "Owner_location":null,
        "Owner_reputation":125,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":"<p>For me this was fixed by updating azureml-core from 1.13.0 to 1.14.0.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-09-22 11:48:36.867 UTC",
        "Answer_last_edit_date":"2020-09-22 13:31:18.49 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"deploy web service for registered R model in Azure ML",
        "Question_body":"<p>I have an absolute nightmare to use <a href=\"https:\/\/github.com\/Azure\/azureml-sdk-for-r\" rel=\"nofollow noreferrer\">azureml-sdk-for-r<\/a>. So I try to achieve everything via the UI (<a href=\"https:\/\/ml.azure.com\/\" rel=\"nofollow noreferrer\">https:\/\/ml.azure.com\/<\/a>). I trained a model locally like so in R 4.0.5<\/p>\n<pre><code>library(datasets)\nlibrary(caret)\n\ndata(iris)\n\nsetwd(&quot;C:\/Data&quot;)\n\nindex &lt;- createDataPartition(iris$Species, p=0.80, list=FALSE)\ntestset &lt;- iris[-index,]\ntrainset &lt;- iris[index,]\n\nmodel = train(Species ~ ., \n                  data=trainset, \n                  method=&quot;rpart&quot;, \n                  trControl = trainControl(method = &quot;cv&quot;))\n\nsaveRDS(model, &quot;model.rds&quot;)\n<\/code><\/pre>\n<p>I deployed\/registered it via the UI, no issue. The &quot;scoring script&quot; I try to use to remove the model dependency is as follows (the only dependency is really jsonlite).<\/p>\n<pre><code>library(jsonlite)\n\ninit &lt;- function()\n{\n  message(&quot;model is loaded&quot;)\n  \n  function(data)\n  {\n    prediction_data &lt;- as.data.frame(fromJSON(data))\n    return('{&quot;result&quot;: &quot;Hello world&quot;}')\n  }\n}\n<\/code><\/pre>\n<p>I use the following yml file as my conda dependency file for this screen:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ZFv3i.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZFv3i.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<pre><code>name: scoring_environment\nchannels:\n  - defaults\ndependencies:\n  - r-base=4.0.5\n  #- r-essentials=4.0.5\n  # whatever other dependencies you have\n  - jsonlite=1.7.2 \n<\/code><\/pre>\n<p>But get immediately this:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Dz7Fd.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Dz7Fd.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>How can I debug what's going on? Is the conda dependency file wrong? As it stand, Azure ML is absolutely useless for me as an R user with locally trained models )-:<\/p>\n<p>PS:<\/p>\n<p>I also try to deploy this locally like so:<\/p>\n<pre><code>library(azuremlsdk)\n\ninteractive_auth &lt;- interactive_login_authentication(tenant_id=&quot;296bf094-bdb4-488f-8ebd-92b2dd1464c2&quot;)\n\nws &lt;- get_workspace(\n        name = &quot;xxx&quot;, \n        subscription_id = &quot;xxx&quot;, \n        resource_group =&quot;xxx&quot;, \n        auth = interactive_auth\n)\n\nmodel &lt;- get_model(ws, name = &quot;iris&quot;)\n\nr_env &lt;- r_environment(name = &quot;r_env&quot;)\n\n# Create inference config\ninference_config &lt;- inference_config(\n  entry_script = &quot;score1.R&quot;,\n  source_directory = &quot;.&quot;,\n  environment = r_env)\n\nlocal_deployment_config &lt;- local_webservice_deployment_config()\n\nservice &lt;- deploy_model(ws, \n                        'rservice-local', \n                        list(model), \n                        inference_config, \n                        local_deployment_config)\n# Wait for deployment\nwait_for_deployment(service, show_output = TRUE)\n\n# Show the port of local service\nmessage(service$port)\n<\/code><\/pre>\n<p>It downloads registred model to my local machine. So this bit works but then there is this error:<\/p>\n<pre><code>\/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad\/lib\/python3.6\/site-packages\/rpy2\/rinterface\/__init__.py:146: RRuntimeWarning:  cannot open file '\/var\/azureml-app\/iris\/score1.R': No such file or directory\n<\/code><\/pre>\n<p>So I tried to deliberately created a relative folder:<\/p>\n<p>\/var\/azureml-app\/iris\/<\/p>\n<p>where the above script lives and place score1.r (see above) there. Still same error. I am lost!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-05-22 10:42:55.607 UTC",
        "Question_favorite_count":1.0,
        "Question_score":3,
        "Question_tags":"r|azure-machine-learning-studio|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":163,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-05-22 10:57:22.873 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Studio vs. Workbench",
        "Question_body":"<p>What is the difference between <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-studio\/\" rel=\"noreferrer\">Azure Machine Learning Studio<\/a> and <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-services\/\" rel=\"noreferrer\">Azure Machine Learning Workbench<\/a>?  What is the <em>intended<\/em> difference? And is it expected that Workbench is heading towards deprecation in favor of Studio?<\/p>\n\n<p>I have gathered an assorted collection of differences:<\/p>\n\n<ul>\n<li>Studio has a hard limit of 10 GB total input of training data per module, whereas Workbench has a variable limit by price.<\/li>\n<li>Studio appears to have a more fully-featured GUI and user-friendly deployment tools, whereas Workbench appears to have more powerful \/ customizable deployment tools.<\/li>\n<li>etc.<\/li>\n<\/ul>\n\n<p>However, I have also found several scattered references claiming that Studio is a renamed updated of Workbench, even though both services appear to still be offered.<\/p>\n\n<p>For a fresh Data Scientist looking to adopt the Microsoft stack (potentially on an enterprise scale within the medium-term and for the long-term), which offering should I prefer?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2018-04-02 03:01:39.293 UTC",
        "Question_favorite_count":null,
        "Question_score":8,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":3387,
        "Owner_creation_date":"2015-06-19 17:48:28.84 UTC",
        "Owner_last_access_date":"2022-09-15 11:30:21.093 UTC",
        "Owner_location":"Dallas, TX, United States",
        "Owner_reputation":2045,
        "Owner_up_votes":1074,
        "Owner_down_votes":66,
        "Owner_views":166,
        "Answer_body":"<p>Azure Machine Learning Workbench is a preview downloadable application. It provides a UI for many of the Azure Machine Learning CLI commands, particularly around experimentation submission for Python based jobs to DSVM or HDI. The Azure Machine Learning CLI is made up of many key functions, such as job submisison, and creation of real time web services. The workbench installer provided a way to install everything required to participate in the preview. <\/p>\n\n<p>Azure Machine Learning Studio is an older product, and provides a drag and drop interface for creating simply machine learning processes. It has limitations about the size of the data that can be handled (about 10gigs of processing). Learning and customer requests have based on this service have contributed to the design of the new Azure Machine Learning CLI mentioned above.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2018-04-27 05:25:01.633 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":6.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML - Model not registering, encountering WebServiceException",
        "Question_body":"<p>I've successfully registered a model with the following exact same code snippet before:<\/p>\n<pre><code>#register model\nfrom azureml.core.model import Model\n\nregister_model = Model.register(model_path = &quot;.\/models&quot;,\n                       model_name = &quot;cr_tools&quot;,\n                       description = &quot;Tools relating to the Customer Relations classifier.&quot;,\n                       workspace = ws)\n\nregister_model\n<\/code><\/pre>\n<p>But now it's not working for a different model (different <code>.\/models<\/code> directory), and I'm encountering the following error:<\/p>\n<pre><code>ServiceException: ServiceException:\n    Code: 504\n    Message: Operation returned an invalid status code 'Gateway Time-out'\n    Details:\n\n    Headers: {\n        &quot;Date&quot;: &quot;Tue, 04 Jan 2022 22:12:54 GMT&quot;,\n        &quot;Content-Type&quot;: &quot;text\/html&quot;,\n        &quot;Content-Length&quot;: &quot;160&quot;,\n        &quot;Connection&quot;: &quot;keep-alive&quot;,\n        &quot;Strict-Transport-Security&quot;: &quot;max-age=15724800; includeSubDomains; preload&quot;,\n        &quot;X-Content-Type-Options&quot;: &quot;nosniff&quot;,\n        &quot;x-request-time&quot;: &quot;60.019&quot;\n    }\n    InnerException: 504 Server Error: Gateway Time-out for url: https:\/\/eastus.experiments.azureml.net\/artifact\/v2.0\/subscriptions\/c450f3d1-583c-495f-b5d3-0b38b99e70c0\/resourceGroups\/ba-p-zeaus-group020-rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/p-group020-aml-ws-001\/artifacts\/batch\/metadata\/LocalUpload\/220104T215629-7c0d42b6\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-04 22:14:41.073 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":151,
        "Owner_creation_date":"2017-12-14 06:32:17.037 UTC",
        "Owner_last_access_date":"2022-08-09 15:59:17.103 UTC",
        "Owner_location":null,
        "Owner_reputation":399,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":47,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Experiment can't mount blob storage to compute cluster",
        "Question_body":"<p>I'm using Azure ML workspace. I'm having an issue with running ML experiment for segmentation. When I submit a run it will always end with this error:<\/p>\n<p><code>UserError: AzureMLCompute job failed. BFSMountError: Unable to mount blob fuse file system Info: Could not mount Azure Blob Container azureml-blobstore-{UID} at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid. Info: Failed to prepare an environment for the job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.<\/code><\/p>\n<p>I believe that documentation says that this blob is created automatically for storage of model files.<\/p>\n<p>Storage account in which this blob resides is integrated into VNET. Datastore has <code>Use workspace managed identity for data preview and profiling in Azure Machine Learning studio<\/code> set to yes, access key has been copied from storage account portal page, number of times. I have no idea why is this happening.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-10 13:25:51.757 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":1559,
        "Owner_creation_date":"2020-11-16 14:01:13.373 UTC",
        "Owner_last_access_date":"2021-01-09 11:50:04.08 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-12-16 06:45:02.513 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Error when creating cluster environment for azureML: \"Failed to get scoring front-end info\"",
        "Question_body":"<p>I just started with using the Azure Machine Learning Services and ran into this problem. Creating a local environment and deploying my model to localhost works perfectly fine. \nCan anyone identify what could have caused this error, because i do not know where to start..<\/p>\n\n<p>I tried to create a cluster for Location \"eastus2\" aswell, which caused the same error.\nThank you very much in advance!<\/p>\n\n<p>Btw, the ressource group and ressources are being created into my azure account.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/wYwJD.png\" rel=\"nofollow noreferrer\">Image of error<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2017-11-23 17:39:34.783 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":381,
        "Owner_creation_date":"2017-11-23 17:28:11.353 UTC",
        "Owner_last_access_date":"2018-02-22 13:38:35.653 UTC",
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":"<p>Ashvin [MSFT]<\/p>\n\n<p>Sorry to hear that you were facing issues. We checked logs on our side using the info you provided in the screenshot. The cluster setup failed because there weren't enough cores to fit AzureML and system components in the cluster. You specified agent-vm-size of D1v2 which has 1 CPU core. By default we create 2 agents so total cores were 2. To resolve, can you please try creating a new cluster without specifying agent size? Then AzureML will create 2 agents of D3v2 which is 8 cores total. This should fit the AzureML and system components and leave some room for you to deploy your services. <\/p>\n\n<p>If you wish a bigger cluster you could specify agent-count along with agent-vm-size to appropriately size your cluster but please have minimum total of 8 cores with each individual VM >= 2 cores to ensure cluster works smoothly. Hope this helps.<\/p>\n\n<p>We are working on our side to add error handling to ensure request fails with clear error message. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-11-27 19:50:51.067 UTC",
        "Answer_last_edit_date":"2017-11-27 19:56:28.163 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"why can't I see Train Model results in Azure ML Designer?",
        "Question_body":"<p>I created data from 1000 sessions of a board game simulator I ran. I'm trying to figure out what the winning strategies are and tracked several features in the data.<\/p>\n<p>I loaded the result in a Azure Machine Learning diagram and connected the data set to a model that uses linear regression.<\/p>\n<p>I click the &quot;Train Model&quot; and go to &quot;View Output&quot;. After clicking through the ensuing links, I seem to be able to locate 9 files. I don't see anything that looks like, &quot;column 9 is best predictor of column 1&quot; or something like that.<\/p>\n<p>Instead I see an iLearner file with a lot of binary I can't read. I see a schema file. There's also a lot of meta files about what version of conda ran it and data types and stuff.<\/p>\n<p>How do I see which features best indicated the label I indicated?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wO0eW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wO0eW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>EDIT:<\/strong><\/p>\n<p>As suggested, I added score model and evaluate model.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/emFsG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/emFsG.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I did see some error metrics in the evaluate results -&gt; visualize.<\/p>\n<p>Train model had a view output and a view log, but no visualize for me. When I went to &quot;view output&quot; there were a lot of files like convert_to_dataset.yaml and boosted_decision_tree_regression.yaml. Also there was a directory there called trained model which had files with names like data_type.json and score.py. It seemed like it was all meta data and nothing like, &quot;Column 1 best predicted X ...&quot;.<\/p>\n<p>I am still not seeing anything that indicates what best predicts the outcome.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/knkUR.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/knkUR.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Z8E6y.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Z8E6y.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-04-03 14:22:28.413 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|machine-learning-model",
        "Question_view_count":354,
        "Owner_creation_date":"2011-05-03 05:12:16.083 UTC",
        "Owner_last_access_date":"2022-09-23 15:17:33.027 UTC",
        "Owner_location":"Raleigh, NC",
        "Owner_reputation":2032,
        "Owner_up_votes":996,
        "Owner_down_votes":3,
        "Owner_views":515,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-04-16 14:19:14.15 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Predicting a users next action based on current day and time",
        "Question_body":"<p>I'm using Microsoft Azure Machine Learning Studio to try an experiment where I use previous analytics captured about a user (at a time, on a day) to try and predict their next action (based on day and time) so that I can adjust the UI accordingly. So if a user normally visits a certain page every Thursday at 1pm, then I would like to predict that behaviour.<\/p>\n\n<p>Warning - I am a complete novice with ML, but have watched quite a few videos and worked through tutorials like the movie recommendations example.<\/p>\n\n<p>I have a csv dataset with userid,action,datetime and would like to train a matchbox recommendation model, which, from my research appears to be the best model to use. I can't see a way to use date\/time in the training. The idea being that if I could pass in a userid and the date, then the recommendation model should be able to give me a probably result of what that user is most likely to do.<\/p>\n\n<p>I get results from the predictive endpoint, but the training endpoint gives the following error:<\/p>\n\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n<div class=\"snippet-code\">\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>{\n    \"error\": {\n        \"code\": \"ModuleExecutionError\",\n        \"message\": \"Module execution encountered an error.\",\n        \"details\": [\n            {\n                \"code\": \"18\",\n                \"target\": \"Train Matchbox Recommender\",\n                \"message\": \"Error 0018: Training dataset of user-item-rating triples contains invalid data.\"\n            }\n        ]\n    }\n}<\/code><\/pre>\n<\/div>\n<\/div>\n<\/p>\n\n<p><a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/User-analytics\" rel=\"noreferrer\">Here is a link to a public version of the experiment<\/a><\/p>\n\n<p>Any help would be appreciated.<\/p>\n\n<p>Thanks.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Z6Uhr.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Z6Uhr.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2018-03-19 13:46:14.213 UTC",
        "Question_favorite_count":1.0,
        "Question_score":11,
        "Question_tags":"azure|machine-learning|analytics|azure-machine-learning-studio",
        "Question_view_count":925,
        "Owner_creation_date":"2009-12-10 21:40:32.61 UTC",
        "Owner_last_access_date":"2022-05-10 08:54:49.827 UTC",
        "Owner_location":null,
        "Owner_reputation":659,
        "Owner_up_votes":30,
        "Owner_down_votes":5,
        "Owner_views":203,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-03-22 17:05:38.663 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"I am trying to work on R using Azure ML Studio Notebook. But while installing and importing packages i am facing some challenges",
        "Question_body":"<p>I'm trying to install the some packages in Azure ML studio R notebook.<\/p>\n<p>Upon typing <code>library(dplyr)<\/code> I get the error that<\/p>\n<blockquote>\n<p>package or namespace load failed for \u2018dbplyr\u2019 in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\nnamespace \u2018rlang\u2019 0.4.11 is already loaded, but &gt;= 1.0.0 is required<\/p>\n<\/blockquote>\n<p>Can anyone suggest on how to install and load packages here just like RStudio<br \/>\n<a href=\"https:\/\/i.stack.imgur.com\/nyIV7.png\" rel=\"nofollow noreferrer\">Screenshot of error<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_creation_date":"2022-08-04 08:25:34.797 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-service",
        "Question_view_count":54,
        "Owner_creation_date":"2017-06-02 12:27:30.497 UTC",
        "Owner_last_access_date":"2022-09-20 06:48:21.12 UTC",
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-08-04 15:26:06.307 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Provision AKS with internal load balancer from AMLS on Azure",
        "Question_body":"<p>I would like to provision an AKS cluster that is connected to a vnet and has an internal load balancer on Azure. I am using code from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet?tabs=python\" rel=\"nofollow noreferrer\">here<\/a> that looks like this:<\/p>\n<pre><code>import azureml.core\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n# Verify that cluster does not exist already\ntry:\n    aks_target = AksCompute(workspace=ws, name=aks_cluster_name)\n    print(&quot;Found existing aks cluster&quot;)\n\nexcept:\n    print(&quot;Creating new aks cluster&quot;)\n\n    # Subnet to use for AKS\n    subnet_name = &quot;default&quot;\n    # Create AKS configuration\n    prov_config=AksCompute.provisioning_configuration(load_balancer_type=&quot;InternalLoadBalancer&quot;)\n    # Set info for existing virtual network to create the cluster in\n    prov_config.vnet_resourcegroup_name = &quot;myvnetresourcegroup&quot;\n    prov_config.vnet_name = &quot;myvnetname&quot;\n    prov_config.service_cidr = &quot;10.0.0.0\/16&quot;\n    prov_config.dns_service_ip = &quot;10.0.0.10&quot;\n    prov_config.subnet_name = subnet_name\n    prov_config.docker_bridge_cidr = &quot;172.17.0.1\/16&quot;\n\n    # Create compute target\n    aks_target = ComputeTarget.create(workspace = ws, name = &quot;myaks&quot;, provisioning_configuration = prov_config)\n    # Wait for the operation to complete\n    aks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>\n<p>However, I get the following error<\/p>\n<pre><code>K8s failed to assign an IP for Load Balancer after waiting for an hour.\n<\/code><\/pre>\n<p>Is this because the AKS cluster does not yet have a 'network contributor' role for the vnet resource group? Is the only way to get this to work to first create AKS outside of AMLS, grant the network contributor role to the vnet resource group, then attach the AKS cluster to AMLS and configure the internal load balancer afterwards?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-29 18:55:35.143 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-aks|azure-machine-learning-service|vnet|internal-load-balancer",
        "Question_view_count":352,
        "Owner_creation_date":"2020-05-17 18:00:51.347 UTC",
        "Owner_last_access_date":"2022-06-27 19:36:47.687 UTC",
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":"<p>I was able to get this to work by first creating an AKS resource without an internal load balancer, then separately updating the load balancer following this code:<\/p>\n<pre><code>import azureml.core\nfrom azureml.core.compute.aks import AksUpdateConfiguration\nfrom azureml.core.compute import AksCompute\n\n# ws = workspace object. Creation not shown in this snippet\naks_target = AksCompute(ws,&quot;myaks&quot;)\n\n# Change to the name of the subnet that contains AKS\nsubnet_name = &quot;default&quot;\n# Update AKS configuration to use an internal load balancer\nupdate_config = AksUpdateConfiguration(None, &quot;InternalLoadBalancer&quot;, subnet_name)\naks_target.update(update_config)\n# Wait for the operation to complete\naks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>\n<p>No network contributor role was required.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-11-02 23:17:33.333 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2020-10-29 20:12:02.987 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning workspace's storage account permission issue",
        "Question_body":"<p>Was working on az ml cli v2 to deploy real-time endpoint with command <code>az ml online-deployment<\/code> through Azure pipeline. had double confirmed that the service connection used in this pipeline task had added the permissions below in Azure Portal but still showing the same error.<\/p>\n<pre><code>ERROR: Error with code: You don't have permission to alter this storage account. Ensure that you have been assigned both Storage Blob Data Reader and Storage Blob Data Contributor roles.\n<\/code><\/pre>\n<p>Using the same service connection, we are able to perform the creation of online endpoint with <code>az ml online-endpoint create<\/code> in the same and other workspaces.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-16 07:10:03.56 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-devops|azure-storage|azure-machine-learning-service",
        "Question_view_count":129,
        "Owner_creation_date":"2019-09-11 07:07:53.007 UTC",
        "Owner_last_access_date":"2022-09-15 16:01:06.153 UTC",
        "Owner_location":"Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia",
        "Owner_reputation":383,
        "Owner_up_votes":70,
        "Owner_down_votes":1,
        "Owner_views":35,
        "Answer_body":"<p>Issue was resolved. I did not change anything in the service principal and running it on second day using same yml got through the issue. I guess there might be some propagation issue, but longer than usual.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-17 01:37:08.623 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Is there a Java SDK for azure machine learning service?",
        "Question_body":"<p>Is there a Java SDK for Azure Machine Learning service? If not, is there a way to create Azure ML pipelines, experiments etc from Java codebase?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-19 11:44:56.657 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-java-sdk|azure-machine-learning-service",
        "Question_view_count":606,
        "Owner_creation_date":"2015-07-20 06:18:39.813 UTC",
        "Owner_last_access_date":"2021-09-22 14:43:24.71 UTC",
        "Owner_location":null,
        "Owner_reputation":132,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":29,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML Authentication for registering datasets using azureml.core.dataset",
        "Question_body":"<p>I am trying to register a data set programmatically using azurecli authentication<\/p>\n<h2>What I tried<\/h2>\n<pre><code>authentication = AzureCliAuthentication()\n\nworkspace = Workspace.from_config( &quot;config.json&quot;), auth=authentication)\nstore = Datastore.get(workspace, datastore_name)\npath = [(store, filePath)]\ndataset = Dataset.Tabular.from_delimited_files(path=path)\n\n<\/code><\/pre>\n<p>I am logged in using <code>azure-cli<\/code><\/p>\n<pre><code>az login\n<\/code><\/pre>\n<p>I am currently the owner of the datastore_name which is a gen2 datalake instance in the same subscription \/ region as the Azure ML workspace<\/p>\n<h2>Question<\/h2>\n<ul>\n<li><p><strong>I get an interactive login<\/strong>  each time I get to the <code>Dataset.Tabular.from_<\/code> line. How can make it use the azure cli creds ?<\/p>\n<\/li>\n<li><p>I plan to use the same python script as part of CI\/CD pipeline azurecli task to register the datasets across multiple workspaces<\/p>\n<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-06 14:12:46.073 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":432,
        "Owner_creation_date":"2010-04-12 17:27:26.887 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:17.55 UTC",
        "Owner_location":"United States",
        "Owner_reputation":9826,
        "Owner_up_votes":1723,
        "Owner_down_votes":15,
        "Owner_views":1238,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-07-06 14:18:15.97 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Authentication problems",
        "Question_body":"<p>I am trying to automate the process to create a model with azure machine learning services and I get some problems with the authentication. When I run my code on my remote machine everything is fine but when I run the code on remote I get this authentication sentence:<\/p>\n\n<pre><code>Make sure your code doesn't require 'az login' to have happened before using azureml-SDK, except the case when you are specifying AzureCliAuthentication in azureml-SDK.\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https:\/\/microsoft.com\/devicelogin and enter the code CZMKCYS8B to authenticate\"\n<\/code><\/pre>\n\n<p>Azure ask me for authentication and I have to make it manually.\nI would like to know if there is some way to do it automatically.<\/p>\n\n<p>I was looking for it and I was investigated how to do it using tokens but I couldn't find any solution<\/p>\n\n<p>Someone can give me an advice?<\/p>\n\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2019-02-18 12:20:51.81 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":653,
        "Owner_creation_date":"2017-08-01 17:34:44.543 UTC",
        "Owner_last_access_date":"2022-01-10 11:29:26.423 UTC",
        "Owner_location":null,
        "Owner_reputation":71,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-02-18 12:50:45.457 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Time difference reading files from Blob-Storage-Container",
        "Question_body":"<p>We are using <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/storage-how-to-mount-container-linux\" rel=\"nofollow noreferrer\">Blobfuse<\/a> for &quot;mounting&quot; our blob-storage-container to an Azure virtual machine as well as to Azure ML Studio.<br>In our blob-storage-container there are around 400 files each about 1.5MB\n<br>\n<br>\nWith the Azure VM, the algorithm needs 45 seconds to read all files.<br>\nWith Azure ML Studio, the <strong>same<\/strong> algorithm needs 5 minutes to read all files.\n<br>\n<br>\nThe Azure VM resource as well as the Azure ML Studio resource are in the same tenant.<br>\nThese resources use two different computes but have the <strong>same<\/strong> specifications.\n<br>\n<br>\nWhy does it take so much longer to read all the files when using Azure ML Studio compared to Azure VM?<br>\nIs it possible to reduce the time needed for reading all files when using Azure ML Studio without changing the storage file hierarchy in any way?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-04 10:46:04.24 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-blob-storage|azure-virtual-machine|mount|azure-machine-learning-studio",
        "Question_view_count":190,
        "Owner_creation_date":"2021-09-29 07:06:53.153 UTC",
        "Owner_last_access_date":"2022-09-23 08:06:23.973 UTC",
        "Owner_location":null,
        "Owner_reputation":139,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to dump and utilize multiple ML algorithm objects in one single pickle file in Azure ML workspace?",
        "Question_body":"<p>I am trying to create a ML model in Azure ML Workspace using Jupyter notebook. I am not using AutoML feature or Designer provided by Azure, and want to run the complete code prepared locally.<\/p>\n<p>There are 3 different algorithms used in my ML Model. I am confused how can I save all the objects in one single pickle file, which I can utilize later in &quot;Inference configuration&quot; and &quot;Score.py&quot; file? Also, once saved how can I access them in &quot;Score.py&quot; file (which is the main file that contains the driver code)?<\/p>\n<p>Currently I am using following method:<\/p>\n<pre><code>import pickle\nf= 'prediction.pkl'\nall_models=[Error_Message_countvector, ErrorMessage_tfidf_fit, model_naive]\nwith open(f, 'wb') as files:\n    pickle.dump(all_models, files)\n<\/code><\/pre>\n<p>and to access the objects:<\/p>\n<pre><code>cv_output = loaded_model[0].transform(input_series)\ntfidf_output = loaded_model[1].transform(cv_output)\nloaded_model_prediction = loaded_model[2].predict(tfidf_output)\n<\/code><\/pre>\n<p>Somehow, this method works fine when I run in the same cell as the entire code. But it throws error when I deploy the complete model.<\/p>\n<p>My &quot;Score.py&quot; file looks something like this:<\/p>\n<pre><code>import json\nfrom azureml.core.model import Model\nimport joblib\nimport pandas as pd\n\ndef init():\n    global prediction_model \n    prediction_model_path = Model.get_model_path(&quot;prediction&quot;)    \n    prediction_model = joblib.load(prediction_model_path)     \n\ndef run(data):\n    try:\n        data = json.loads(data)     \n        input_string= str(data['errorMsg']).strip()             \n        input_series=pd.Series(input_string)            \n        cv_output= prediction_model[0].transform(input_series)\n        tfidf_output = prediction_model[1].transform(cv_output) \n        result = prediction_model[2].predict(tfidf_output)           \n        return {'response' : result }\n\n    except Exception as e:\n        error = str(e)\n        return {'response' : error }\n<\/code><\/pre>\n<p>and the error received on deployment is:<\/p>\n<pre><code>Error:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Error in entry script, AttributeError: module '__main__' has no attribute 'text_cleaning', please run print(service.get_logs()) to get details.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,\n      &quot;message&quot;: &quot;Error in entry script, AttributeError: module '__main__' has no attribute 'text_cleaning', please run print(service.get_logs()) to get details.&quot;\n    }\n  ]\n}\n<\/code><\/pre>\n<p>Can anyone help me understand the issue or figure out if there is something missing\/wrong in the code?<\/p>\n<p>What is the right way of saving multiple algorithm objects in one single pickle file?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-11-10 04:14:17.44 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|machine-learning|pickle|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":182,
        "Owner_creation_date":"2021-08-05 12:26:08.503 UTC",
        "Owner_last_access_date":"2021-11-12 03:49:15.457 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-11-10 12:01:47.607 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Join 2 tables with with mutiple keys in Azure ML Studio",
        "Question_body":"<p>I have two datasets with multiple columns. I would like to join the two tables with the following keys: zip code, year, month, data, hour<\/p>\n\n<p>However whenever I use a <strong>Join Module<\/strong> on these two tables, the Join doesn't happen, and I just get a Table with Columns from Right Table with empty values.<\/p>\n\n<p>Here is the R equivalent of what I am trying to do:<\/p>\n\n<pre><code>YX &lt;- leftTableDT\nYX %&lt;&gt;% merge( rightTableDT, all.x = TRUE, by=c('zip','year','month','day','hour') )\n<\/code><\/pre>\n\n<p>Any ideas on why Join Module in Azure ML Studio doesn't work for multiple keys?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-04-23 21:25:00.45 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":582,
        "Owner_creation_date":"2010-08-14 18:36:47.747 UTC",
        "Owner_last_access_date":"2022-09-21 17:16:05.413 UTC",
        "Owner_location":"Capitola, CA",
        "Owner_reputation":3675,
        "Owner_up_votes":387,
        "Owner_down_votes":8,
        "Owner_views":638,
        "Answer_body":"<p>Double-check that you've selected \"Allow duplicates and preserve column order in selection\" in column selection options, so it matches the columns in listed order.<\/p>\n\n<p>Also, you could try Apply SQL Transformation module to join datasets.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-05-03 13:08:46.63 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Write output to Azure SQL Database",
        "Question_body":"<p>I am using Azure Machine Learning to clustering data.<\/p>\n\n<p>The input data is from an Azure SQL Database, and it works fine.\nAt the end of everything I want to write the output to a table in the same Azure SQL Database, but I get this error:<\/p>\n\n<pre><code>Error: Error 1000: AFx Library library exception: \nSql encountered an error: Login failed for user\n<\/code><\/pre>\n\n<p>Anyone any idea?\nThank you very much!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2017-11-16 13:34:00.587 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-sql-database|azure-machine-learning-studio",
        "Question_view_count":1068,
        "Owner_creation_date":"2016-03-21 11:00:39.43 UTC",
        "Owner_last_access_date":"2022-09-23 09:07:45.753 UTC",
        "Owner_location":"Trieste, Province of Trieste, Italy",
        "Owner_reputation":1657,
        "Owner_up_votes":440,
        "Owner_down_votes":4,
        "Owner_views":164,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Update private Wheel on Azure Machine Learning",
        "Question_body":"<p>I added a private wheel to my Azure environment via<\/p>\n<pre><code>    whl_url = Environment.add_private_pip_wheel(\n        workspace=ws, file_path='path_to_wheel.whl', exist_ok=True)\n    conda_dep.add_pip_package(whl_url)\n<\/code><\/pre>\n<p>When I rerun this code, it doesn't seem to update the wheel on Azure but just takes the old one. Since I'm still developing the code in the wheel, I need frequent updates, so renaming the wheel or manually increasing the version number every time is not an option.<\/p>\n<p>Is there a way to tell Azure to actually update the uploaded wheel?<\/p>\n<p>Thanks in advance.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-09 07:09:43.917 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|python-wheel|azure-machine-learning-service",
        "Question_view_count":215,
        "Owner_creation_date":"2017-12-01 09:30:50.553 UTC",
        "Owner_last_access_date":"2022-09-23 10:58:14.177 UTC",
        "Owner_location":null,
        "Owner_reputation":451,
        "Owner_up_votes":25,
        "Owner_down_votes":6,
        "Owner_views":24,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Can AZ ML workbench reference multiple data sources from Data Prep Transform Dataflow expression",
        "Question_body":"<p>Using AZ ML workbench for a class project (required tool) I coded the desired logic below in an exploration notebook but cannot find a way to include this into a Data-prep Transform Data flow.<\/p>\n\n<p><code>all_columns = df.columns\nsum_columns = [col_name for col_name in all_columns if col_name not in ['NPI', 'Gender', 'State', 'Credentials', 'Specialty']]\nsum_op_columns = list(set(sum_columns) &amp; set(df_op['Drug Name'].values))<\/code><\/p>\n\n<p>The logic is using the column names from one data source df_op (opioid drugs) to choose which subset of columns to include from another data source df (all drugs). When adding a py script\/expression Transform Data Flow I'm only seeing the ability to reference the single df. Alternatives?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-02-10 20:10:50.697 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":71,
        "Owner_creation_date":"2016-10-03 17:37:35.767 UTC",
        "Owner_last_access_date":"2019-05-28 23:53:53.907 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML data Transformation tasks",
        "Question_body":"<p>I have a machine learning task in Azure whereby I need to carry out some simplistic data transformations. Given the nature of the transformations, it is easier for me to implement them as an ML pipeline step than resort to something like DataBricks.<\/p>\n<p>My question is regarding the best way to use such transformations.<\/p>\n<p>In my case, I am chaining data transformations in a scikit-learn pipeline and registering this as an AzureML model. In deployment, I need to load two models; the data transformation and ML model and use them together.<\/p>\n<p>Is this an acceptable way to handle these situations? Is there a way whereby this can be simplified?<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-07 15:11:52.473 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":16,
        "Owner_creation_date":"2016-05-25 17:54:32.787 UTC",
        "Owner_last_access_date":"2022-08-01 18:26:20.177 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"scoring R model in Python",
        "Question_body":"<p>I am having a hard time to deploy an R model and expose it as a web service using <a href=\"https:\/\/azure.github.io\/azureml-sdk-for-r\/articles\/train-and-deploy-first-model.html\" rel=\"nofollow noreferrer\">azuremlsdk<\/a> for R. The Python side of Azure machine learning appears to be more mature as Python was deemed more important by Microsoft. Anyway, I was wondering if one score an R model, persisted as .rds file, in Python. I understand R can talk to Python via reticulate. Any input from Python experts would be very much appreciated. Thanks.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2021-05-15 05:39:30.167 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|r|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":58,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Matchbox recommender in azure machine learning workspace",
        "Question_body":"<p>The matchbox recommender available in <a href=\"http:\/\/studio.azureml.net\" rel=\"nofollow noreferrer\">http:\/\/studio.azureml.net<\/a> doesn't seem to have a counterpart in <a href=\"http:\/\/ml.azure.com\" rel=\"nofollow noreferrer\">http:\/\/ml.azure.com<\/a> (which it appears is the newer portal for azure ml). Here only the plain SVD recommender is available, which doesn't take user or item features. This is a feature takeaway from the matchbox.<\/p>\n\n<p>Is there an ETA when matchbox would be made available in the azure machine learning services? Either via SDK or designer.\nThanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-19 07:03:07.617 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":189,
        "Owner_creation_date":"2019-11-05 04:45:11.23 UTC",
        "Owner_last_access_date":"2021-11-25 09:34:42.707 UTC",
        "Owner_location":null,
        "Owner_reputation":63,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to install OpenJDK library?",
        "Question_body":"<p>I created the following <code>environment.yml<\/code> file from my local Anaconda that contains an openjdk package.<\/p>\n<pre><code>name: venv\nchannels:\n  - defaults\ndependencies:\n  - openjdk=11.0.6\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6AlVr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6AlVr.png\" alt=\"Anaconda openjdk\" \/><\/a><\/p>\n<p>However, Azure Machine Learning couldn't install the openjdk package from the <code>environment.yml<\/code> file as module is not found.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/gxuS6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gxuS6.png\" alt=\"ResolvePackageNotFound\" \/><\/a><\/p>\n<p>Backstory:<\/p>\n<p>I'm building a machine learning model using H2O.ai Python library. Unfortunately, H2O.ai is written in Java so it requires Java to run. I've installed openjdk to my local Anaconda venv for running H2O.ai locally - it runs perfectly. However, I couldn't deploy this model to Azure Machine Learning because it couldn't install openjdk from requirements.txt or environment.yml as module not found.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2021-04-27 06:07:21.653 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"java|python|anaconda|h2o|azure-machine-learning-service",
        "Question_view_count":1389,
        "Owner_creation_date":"2019-06-07 06:29:38.77 UTC",
        "Owner_last_access_date":"2022-09-22 21:28:04.37 UTC",
        "Owner_location":null,
        "Owner_reputation":569,
        "Owner_up_votes":448,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":"<p>Solution:<\/p>\n<p>Install openjdk through conda but specify conda-forge as the channel to install the package from.<\/p>\n<pre><code>name: venv\nchannels:\n  - defaults\n  - conda-forge\ndependencies:\n  - conda-forge::openjdk=11.0.9.1\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AHCye.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AHCye.png\" alt=\"Conda Forge\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-05-01 14:44:33.88 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2021-04-30 17:10:30.133 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to apply a dprep package to incoming data in score.py Azure Workbench",
        "Question_body":"<p>I had been wondering if it were possible to apply \"data preparation\" (.dprep) files to incoming data in the score.py, similar to how Pipeline objects may be applied.  This would be very useful for model deployment. To find out, I asked this question on the MSDN forums and received a <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/640e93c3-0b88-4668-9869-91da85f7f1e3\/purpose-of-dprep-files-azure-machine-learning-workbench?forum=MachineLearning\" rel=\"nofollow noreferrer\">response<\/a> confirming it were possible, but little explanation about how to actually do it.  The response was:<\/p>\n\n<blockquote>\n  <p>in your score.py file, you can invoke the dprep package from Python\n  SDK to apply the same transformation to the incoming scoring data.\n  make sure you bundle your .dprep file in the image you are building.<\/p>\n<\/blockquote>\n\n<p>So my questions are:<\/p>\n\n<ul>\n<li><p>What function do I apply to invoke this dprep package?<\/p>\n\n<ul>\n<li>Is it: <code>run_on_data(user_config, package_path, dataflow_idx=0, secrets=None, spark=None)<\/code> ?<\/li>\n<\/ul><\/li>\n<li><p>How do I bundle it into the image when creating a web-service from the CLI?<\/p>\n\n<ul>\n<li>Is there a switch to <code>-f<\/code> for score files?<\/li>\n<\/ul><\/li>\n<\/ul>\n\n<p>I have scanned through the entire <a href=\"https:\/\/opdhsblobprod01.blob.core.windows.net\/contents\/4a6d75bb3af747de838e6ccc97c5d978\/fc2d1c1c13c843cb9c6ca45d2038633b?sv=2015-04-05&amp;sr=b&amp;sig=gDlMGB31l0tV%2FBrLS6R1B0qeKhuGoKppykGocKHslSo%3D&amp;st=2018-06-22T10%3A29%3A14Z&amp;se=2018-06-23T10%3A39%3A14Z&amp;sp=r\" rel=\"nofollow noreferrer\">documentation<\/a> and <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/tree\/master\/articles\/machine-learning\/desktop-workbench\" rel=\"nofollow noreferrer\">Workbench Repo<\/a> but cannot seem to find any examples.<\/p>\n\n<p>Any suggestions would be much appreciated!<\/p>\n\n<p>Thanks!<\/p>\n\n<p>EDIT:<\/p>\n\n<p>Scenario:<\/p>\n\n<ol>\n<li><p>I import my data from a live database and let's say this data set has 10 columns.<\/p><\/li>\n<li><p>I then feature engineer this (.dsource) data set using the Workbench resulting in a .dprep file which may have 13 columns.<\/p><\/li>\n<li><p>This .dprep data set is then imported as a pandas DataFrame and used to train and test my model.<\/p><\/li>\n<li><p>Now I have a model ready for deployment.<\/p><\/li>\n<li><p>This model is deployed via Model Management to a Container Service and will be fed data from a live database which once again will be of the original format (10 columns).  <\/p><\/li>\n<li><p>Obviously this model has been trained on the transformed data (13 columns) and will not be able to make a prediction on the 10 column data set.<\/p><\/li>\n<\/ol>\n\n<p>What function may I use in the 'score.py' file to apply the same transformation I created in workbench?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2018-06-22 10:45:52.543 UTC",
        "Question_favorite_count":0.0,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":312,
        "Owner_creation_date":"2018-04-12 13:27:26.397 UTC",
        "Owner_last_access_date":"2021-05-28 21:30:52.11 UTC",
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-06-22 12:33:14.453 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Automated ML model publish in dataflow\/powerbi",
        "Question_body":"<p>when I am publishing the model with designer and referring in the data-flow or power-bi it is working fine. when I am trying to get the rest endpoint from the automated ML. it is showing this screen and I am not clear what to be input in this. I tried providing columns and values. it is not working. it is throwing following error.<\/p>\n<p>any idea what is wrong here.<\/p>\n<p>Expression.Error: We cannot convert the value &quot;[Function]&quot; to type Function.DetailsValue = [Function]<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/HHadB.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/HHadB.jpg\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-01-21 05:18:18.017 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":36,
        "Owner_creation_date":"2020-11-05 01:13:03.193 UTC",
        "Owner_last_access_date":"2022-04-26 08:48:36.923 UTC",
        "Owner_location":null,
        "Owner_reputation":37,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Mount a datalake storage in azure ML studio",
        "Question_body":"<p>I created a file dataset from a data lake folder on Azure ML Studio,  at the moment I\u00b4m able to download the data from the dataset to the compute instance with this code:<\/p>\n<pre><code>subscription_id = 'xxx'\nresource_group = 'luisdatapipelinetest'\nworkspace_name = 'ml-pipelines'\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\ndataset = Dataset.get_by_name(workspace, name='files_test')\npath = &quot;\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/demo1231\/code\/Users\/luis.rramirez\/test\/&quot;\ndataset.download(target_path=path, overwrite=True)\n<\/code><\/pre>\n<p>With that I'm able to access the files from the notebook.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/8q8y2.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8q8y2.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>But copying the data from the data lake to the compute instance is not efficient, how can I mount the data lake directory in the vm instead of copying the data each time?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-26 20:08:50.263 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-data-lake|azure-machine-learning-service|ml-studio",
        "Question_view_count":258,
        "Owner_creation_date":"2015-02-08 23:53:31.84 UTC",
        "Owner_last_access_date":"2022-09-24 00:08:32.523 UTC",
        "Owner_location":null,
        "Owner_reputation":8349,
        "Owner_up_votes":1489,
        "Owner_down_votes":6,
        "Owner_views":949,
        "Answer_body":"<p>MOUNTING ADLS2 to AML so you can save files into your mountPoint directly. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#azure-data-lake-storage-generation-2\" rel=\"nofollow noreferrer\">Here<\/a> is the example of registering the storage and <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.file_dataset.filedataset?view=azure-ml-py#mount-mount-point-none----kwargs-\" rel=\"nofollow noreferrer\">here<\/a> shows how to mount your registered datastore.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-08-30 04:49:53.133 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2021-08-27 06:10:24.417 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Web service input into SQL query into R in Azure ML",
        "Question_body":"<p>I have the following simple setup in Azure ML. <a href=\"https:\/\/i.stack.imgur.com\/kWi0S.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kWi0S.jpg\" alt=\"ML setup\"><\/a> \nBasically the Reader is a SQL query to a DB which returns a vector called Pdelta, which is then passed to the R script for further processing  and the results are then returned back to the web service. The DB query is simple (<code>SELECT Pdelta FROM ...<\/code>) and it works fine. I have set the DB query as a web service paramater as well. <\/p>\n\n<p>Everything seems to work fine, but at the end when i publish it as a web service and test it, it somehow asks for an additional input parameter. The additional parameter gets called <code>PDELTA<\/code>.\n<a href=\"https:\/\/i.stack.imgur.com\/mnzPZ.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mnzPZ.jpg\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I am wondering why is this happening, what is it that I am overlooking? I would like to make this web service ask for only one parameter - the SQL query (Delta Query) which would then deliver the Pdeltas. <\/p>\n\n<p>Any ideas or suggestions would be grealty appreciated! <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2015-10-01 09:40:39.63 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"web-services|azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":347,
        "Owner_creation_date":"2015-05-28 16:10:15.467 UTC",
        "Owner_last_access_date":"2018-11-18 20:44:24.587 UTC",
        "Owner_location":null,
        "Owner_reputation":501,
        "Owner_up_votes":184,
        "Owner_down_votes":0,
        "Owner_views":76,
        "Answer_body":"<p>You can remove the web service input block and publish the web service without it. That way the Pdelta input will be passed in only from the Reader module.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2015-10-06 16:13:01.107 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":3.0,
        "Question_last_edit_date":"2016-03-01 16:34:35.24 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Can I import data from On-Premises SQL Server Database to Azure Machine Learning virtual machine?",
        "Question_body":"<p>On the limited Azure Machine Learning Studio, one can import data from an On-Premises SQL Server Database.\nWhat about the ability to do the exact same thing on a python jupyter notebook on a virtual machine from the Azure Machine Learning Services workspace ?<\/p>\n\n<p>It does not seem possible from what I've found in the documentation.\nData sources would be limited in Azure ML Services : \"Currently, the list of supported Azure storage services that can be registered as datastores are Azure Blob Container, Azure File Share, Azure Data Lake, Azure Data Lake Gen2, Azure SQL Database, Azure PostgreSQL, and Databricks File System\"<\/p>\n\n<p>Thank you in advance for your assistance<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-21 14:26:44.447 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|sql|azure|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":1147,
        "Owner_creation_date":"2019-05-21 14:13:07.353 UTC",
        "Owner_last_access_date":"2022-04-20 09:16:53.527 UTC",
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>As of today, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-load-data#load-sql-data\" rel=\"nofollow noreferrer\">you can load SQL data, but only a MS SQL Server source (also on-premise) is supported<\/a>.<\/p>\n\n<p>Using <code>azureml.dataprep<\/code>, code would read along the lines of<\/p>\n\n<pre><code>import azureml.dataprep as dprep\n\nsecret = dprep.register_secret(value=\"[SECRET-PASSWORD]\", id=\"[SECRET-ID]\")\n\nds = dprep.MSSQLDataSource(server_name=\"[SERVER-NAME]\",\n                           database_name=\"[DATABASE-NAME]\",\n                           user_name=\"[DATABASE-USERNAME]\",\n                           password=secret)\n\ndflow = dprep.read_sql(ds, \"SELECT top 100 * FROM [YourDB].[ATable]\")\n# print first records\ndflow.head(5)\n<\/code><\/pre>\n\n<p>As far as I understand the APIs are under heavy development and <code>azureml.dataprep<\/code> may be soon superseded by functionality provided by the <a href=\"https:\/\/aka.ms\/azureml\/concepts\/datasets\" rel=\"nofollow noreferrer\">Dataset class<\/a>.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2019-05-21 22:53:14.14 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Deploying Machine Learning model to AzureML Web Service - how to deal with extreme high dimensionality?",
        "Question_body":"<p>I want to deploy a Sklearn knn model onto Azure ML Web Service according the following tutorial.<\/p>\n\n<pre><code>from azureml import services\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1, algorithm=\"auto\")\nknn_model.fit(X_train, Y_train)\n\n@services.publish(workspace_id, authorization_token)\n@services.types(input_1=int, input_2=int, input_3=int, input_4=int)\n@services.returns(int)\ndef my_knn_predictor(input_1, input_2, input_3, input_4):\n    return knn_model.predict([input_1, input_2, input_3, input_4])\n<\/code><\/pre>\n\n<p>This works indeed, but in the meantime I have to deploy a model where both the input and output dimensionality is very high (magnitude of thousands) so I do not want to type in the <code>input_1, input_2, input_3, input_4 ...<\/code> variable sequences by hand. Is there a way to extract these as a list from the <code>X_train<\/code> and <code>Y_train<\/code> and feed this list into the <code>my_knn_predictor<\/code> input\/output definition? (Simple copy of the data frame headers is not enough because I have to add <code>=int<\/code> to the column names and remove the quotation marks.)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2017-11-10 11:59:05.73 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|scikit-learn|azure-machine-learning-studio",
        "Question_view_count":133,
        "Owner_creation_date":"2016-06-24 18:19:52.047 UTC",
        "Owner_last_access_date":"2022-07-19 04:30:48.127 UTC",
        "Owner_location":null,
        "Owner_reputation":1078,
        "Owner_up_votes":12,
        "Owner_down_votes":1,
        "Owner_views":90,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"While deploying model to AKS PipelineModel.load throwing org.apache.hadoop.mapred.InvalidInputException",
        "Question_body":"<p>I am trying to deploy model to AKS. I am using AML SDK to register the model in the aml workspace. I am using PipelineModel module to save the model. And I am trying to load the model using PipelineModel.load. My entry script looks like below:<\/p>\n\n<p>` \nimport os\nimport json\nimport pandas as pd<\/p>\n\n<p>from azureml.core.model import Model\nfrom pyspark.ml import PipelineModel\nfrom mmlspark import ComputeModelStatistics<\/p>\n\n<p>def init():\n    import mmlspark  # this is needed to load mmlspark libraries\n    import logging<\/p>\n\n<pre><code># extract and load model\nglobal model, model_path\nmodel_path = Model.get_model_path(\"{model_name}\")\nprint(model_path)\nprint(os.stat(model_path))\nprint(os.path.exists(model_path))\n#model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"{model_name}\")\nlogging.basicConfig(level=logging.DEBUG)\n#print(model_path)\n#with ZipFile(model_path, 'r') as f:\n#    f.extractall('model')\nmodel = PipelineModel.load(model_path)\n#model = PipelineModel.read().load(model_path)\n<\/code><\/pre>\n\n<p>def run(input_json):\n    try:\n        output_df = model.transform(pd.read_json(input_json))\n        evaluator = ComputeModelStatistics().setScoredLabelsCol(\"prediction\").setLabelCol(\"label\").setEvaluationMetric(\"AUC\")\n        result = evaluator.transform(predictions)\n        auc = result.select(\"AUC\").collect()[0][0]\n        result = auc\n    except Exception as e:\n        result = str(e)<\/p>\n\n<pre><code>return json.dumps({{\"result\": result}})\n<\/code><\/pre>\n\n<p>`<\/p>\n\n<p>It's giving error like below:<\/p>\n\n<p>org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:\/var\/azureml-app\/azureml-models\/lightgbm.model\/2\/lightgbm.model\/metadata\\n\\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\\n\\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\\n\\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315). <\/p>\n\n<p>os.path.exists returns true the path fetched from Model.get_model_path. <\/p>\n\n<p>Am I missing something here? <\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-15 08:07:57.67 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"hadoop|pyspark|azure-aks|azure-machine-learning-service",
        "Question_view_count":32,
        "Owner_creation_date":"2012-08-23 16:58:06.593 UTC",
        "Owner_last_access_date":"2022-09-15 07:26:06.053 UTC",
        "Owner_location":null,
        "Owner_reputation":63,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Model.get_model_path(model_name=\"model\") throws an error: Model not found in cache or in root at",
        "Question_body":"<p>I have a Model that I registered it with a pipeline :<\/p>\n\n<pre><code>register_step = PythonScriptStep(name = \"Register Model\",\n                                source_directory = training_folder,\n                                script_name = \"register_model.py\",\n                                arguments = ['--model_folder', model_folder],\n                                inputs=[model_folder],\n                                compute_target = pipeline_cluster,\n                                runconfig = pipeline_run_config,\n                                allow_reuse = True)\n<\/code><\/pre>\n\n<p>And here is my register_model.py:<\/p>\n\n<pre><code>import argparse\nimport joblib\nfrom azureml.core import Workspace, Model, Run\n\n# Get parameters\nparser = argparse.ArgumentParser()\nparser.add_argument('--model_folder', type=str, dest='model_folder', default=\"model\", help='model location')\nargs = parser.parse_args()\nmodel_folder = args.model_folder\n\n# Get the experiment run context\nrun = Run.get_context()\n\n# Load the model\nprint(\"Loading model from \" + model_folder)\nmodel_file = model_folder + \"\/model.pkl\"\nmodel = joblib.load(model_file)\n\nModel.register(workspace=run.experiment.workspace,\n               model_path = model_file,\n               model_name = 'model',\n               tags={'Training context':'Pipeline'})\n\nrun.complete() \n<\/code><\/pre>\n\n<p>I can see the model is registered when i loop the existing models using the following:<\/p>\n\n<pre><code>from azureml.core import Model\n\nfor model in Model.list(ws):\n    print(model.name, 'version:', model.version)\n    for tag_name in model.tags:\n        tag = model.tags[tag_name]\n        print ('\\t',tag_name, ':', tag)\n    for prop_name in model.properties:\n        prop = model.properties[prop_name]\n        print ('\\t',prop_name, ':', prop)\n    print('\\n')\n<\/code><\/pre>\n\n<p>However when i try to load the model in my Score.py (below) to deploy the model as a servcie, I get the following error:<\/p>\n\n<p>I believe this is where the error coming from :<\/p>\n\n<pre><code>model_path = Model.get_model_path(\n        model_name=\"model\", version=1)\n<\/code><\/pre>\n\n<p>Error:<\/p>\n\n<pre><code>ModelNotFoundException                    Traceback (most recent call last)\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/model.py in get_model_path(model_name, version, _workspace)\n    751             try:\n--&gt; 752                 return Model._get_model_path_local(model_name, version)\n    753             except ModelNotFoundException as ee:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/model.py in _get_model_path_local(model_name, version)\n    783         if not os.path.exists(candidate_model_path):\n--&gt; 784             return Model._get_model_path_local_from_root(model_name)\n    785         else:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/model.py in _get_model_path_local_from_root(model_name)\n    826         raise ModelNotFoundException(\"Model not found in cache or in root at .\/{}. For more info,\"\n--&gt; 827                                      \"set logging level to DEBUG.\".format(candidate_model_path))\n    828 \n\nModelNotFoundException: ModelNotFoundException:\n    Message: Model not found in cache or in root at .\/model. For more info,set logging level to DEBUG.\n    InnerException None\n    ErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model not found in cache or in root at .\/model. For more info,set logging level to DEBUG.\"\n    }\n}\n\nDuring handling of the above exception, another exception occurred:\n\nWebserviceException                       Traceback (most recent call last)\n&lt;ipython-input-6-27e8df94d66f&gt; in &lt;module&gt;\n      1 model_path = Model.get_model_path(\n----&gt; 2         model_name=\"model\", version=1)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/model.py in get_model_path(model_name, version, _workspace)\n    756                     module_logger.debug(\"Getting model from remote\")\n    757                     return Model._get_model_path_remote(model_name, version, active_workspace)\n--&gt; 758                 raise WebserviceException(ee.message, logger=module_logger)\n    759         else:\n    760             if active_workspace is not None:\n\nWebserviceException: WebserviceException:\n    Message: Model not found in cache or in root at .\/model. For more info,set logging level to DEBUG.\n    InnerException None\n    ErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model not found in cache or in root at .\/model. For more info,set logging level to DEBUG.\"\n    }\n}\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-25 00:25:16.3 UTC",
        "Question_favorite_count":1.0,
        "Question_score":5,
        "Question_tags":"python|machine-learning|azure-machine-learning-service",
        "Question_view_count":2984,
        "Owner_creation_date":"2015-04-15 15:30:33.927 UTC",
        "Owner_last_access_date":"2021-05-19 18:39:41.463 UTC",
        "Owner_location":null,
        "Owner_reputation":261,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Recommendations API's Parameter",
        "Question_body":"<p>I would like to make a recommendation model using Recommendations API on Azure MS Cognitive Services. I can't understand three API's parameters below for \"Create\/Trigger a build.\" What do these parameters mean?<\/p>\n\n<p><a href=\"https:\/\/westus.dev.cognitive.microsoft.com\/docs\/services\/Recommendations.V4.0\/operations\/56f30d77eda5650db055a3d0\" rel=\"nofollow\">https:\/\/westus.dev.cognitive.microsoft.com\/docs\/services\/Recommendations.V4.0\/operations\/56f30d77eda5650db055a3d0<\/a><\/p>\n\n<blockquote>\n  <p>EnableModelingInsights<br> Allows you to compute metrics on the\n  recommendation model. <br> Valid Values: True\/False<\/p>\n  \n  <p>AllowColdItemPlacement<br> Indicates if the recommendation should also\n  push cold items via feature similarity. <br> Valid Values: True\/False<\/p>\n  \n  <p>ReasoningFeatureList<br> Comma-separated list of feature names to be\n  used for reasoning sentences (e.g. recommendation explanations).<br>\n  Valid Values: Feature names, up to 512 chars<\/p>\n<\/blockquote>\n\n<p>Thank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-04-06 11:41:33.017 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":279,
        "Owner_creation_date":"2016-04-06 11:19:41.603 UTC",
        "Owner_last_access_date":"2016-07-23 22:53:42.527 UTC",
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":"<p>That page is missing references to content mentioned at other locations.  See this page for a more complete guide...<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-recommendation-api-documentation\/\" rel=\"nofollow\">https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-recommendation-api-documentation\/<\/a><\/p>\n\n<p>It describes Cold Items in the Rank Build section in the document as...<\/p>\n\n<p>Features can enhance the recommendation model, but to do so requires the use of meaningful features. For this purpose a new build was introduced - a rank build. This build will rank the usefulness of features. A meaningful feature is a feature with a rank score of 2 and up. After understanding which of the features are meaningful, trigger a recommendation build with the list (or sublist) of meaningful features. It is possible to use these feature for the enhancement of both warm items and cold items. In order to use them for warm items, the UseFeatureInModel build parameter should be set up. In order to use features for cold items, the AllowColdItemPlacement build parameter should be enabled. Note: It is not possible to enable AllowColdItemPlacement without enabling UseFeatureInModel.<\/p>\n\n<p>It also describes the ReasoningFeatureList in the Recommendation Reasoning section as...<\/p>\n\n<p>Recommendation reasoning is another aspect of feature usage. Indeed, the Azure Machine Learning Recommendations engine can use features to provide recommendation explanations (a.k.a. reasoning), leading to more confidence in the recommended item from the recommendation consumer. To enable reasoning, the AllowFeatureCorrelation and ReasoningFeatureList parameters should be setup prior to requesting a recommendation build.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-04-12 21:08:01.97 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":3.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"azureml how to deploy docker image to webservice",
        "Question_body":"<p>Try to containerize models using docker and use this in a web service. Getting the following error &quot;azureml.exceptions._azureml_exception.WebserviceException: WebserviceException:Message: Models must either be of type azureml.core.Model or a str path to a file or folder&quot;.<\/p>\n<pre><code>    env = Environment.from_conda_specification(&quot;env&quot;, &quot;..\/Environments.yml&quot;)\n    inf_conf = InferenceConfig(\n    entry_script=&quot;score.py&quot;,\n    environment=env)\n\n\n    docker_image = Model.package(ws, [models_latest], inf_conf)\n    docker_image.wait_for_creation(show_output=True) \n\n\n\n    # Deploy the image\n    webservice_name = os.environ['WEB_SERVICE_NAME']\n\n    retries = 2\n    while retries &gt; 0:\n        try:\n            service = AciWebservice(workspace = ws,\n                                    name = webservice_name)\n            service.update(image = docker_image)\n            print('Webservice updated')   \n        except:\n            print('Webservice not found')\n            service = Webservice.deploy_from_image(workspace = ws,\n                                                name = webservice_name,\n                                                image = docker_image,\n                                                deployment_config = aciconfig)\n\n        # wait for deployment, get logs if failed\n        try:\n            service.wait_for_deployment(show_output = True)\n            break\n        except:\n            print(service.get_logs())\n            retries -= 1\n            if retries == 0:\n                raise\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-17 10:05:27.093 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":67,
        "Owner_creation_date":"2021-10-27 11:28:41.057 UTC",
        "Owner_last_access_date":"2022-09-22 14:14:03.98 UTC",
        "Owner_location":null,
        "Owner_reputation":128,
        "Owner_up_votes":28,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-08-17 10:11:56.87 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML studio export data Azure Storage V2",
        "Question_body":"<p>I already post my problem <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/en-US\/aff7df3f-afbc-4abc-8fb0-5597184fa6c1\/export-data-blob-storage-v2?forum=MachineLearning\" rel=\"nofollow noreferrer\">here<\/a> and they suggested me to post it here.\nI am trying to export data from Azure ML to Azure Storage but I have this error:<\/p>\n\n<p>Error writing to cloud storage: The remote server returned an error: (400) Bad Request.. Please check the url. . ( Error 0151 )<\/p>\n\n<p>My blob storage configuration is Storage v2 \/ Standard and  Require secure transfer set as enabled.<\/p>\n\n<p>If I set the Require secure transfer set as disabled, the export works fine.<\/p>\n\n<p><strong>How can I export data to my blob storage with the require secure transfer set as enabled ?<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-02-15 09:32:29.923 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-storage|azure-machine-learning-studio|azure-blob-storage",
        "Question_view_count":819,
        "Owner_creation_date":"2018-03-16 08:39:17.297 UTC",
        "Owner_last_access_date":"2022-06-16 09:15:08.42 UTC",
        "Owner_location":null,
        "Owner_reputation":160,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":27,
        "Answer_body":"<p>According to the offical tutorial <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-to-azure-blob-storage\" rel=\"nofollow noreferrer\"><code>Export to Azure Blob Storage<\/code><\/a>, there are two authentication types for exporting data to Azure Blob Storage: SAS and Account. The description for them as below.<\/p>\n\n<blockquote>\n  <ol start=\"4\">\n  <li><p>For <strong>Authentication type<\/strong>, choose <strong>Public (SAS URL)<\/strong> if you know that the storage supports access via a SAS URL.<\/p>\n  \n  <p>A SAS URL is a special type of URL that can be generated by using an Azure storage utility, and is available for only a limited time. It contains all the information that is needed for authentication and download.<\/p>\n  \n  <p>For <strong>URI<\/strong>, type or paste the full URI that defines the account and the public blob.<\/p><\/li>\n  <li><p>For private accounts, choose <strong>Account<\/strong>, and provide the account name and the account key, so that the experiment can write to the storage account.<\/p>\n  \n  <ul>\n  <li><p><strong>Account name<\/strong>: Type or paste the name of the account where you want to save the data. For example, if the full URL of the storage account is <a href=\"http:\/\/myshared.blob.core.windows.net\" rel=\"nofollow noreferrer\">http:\/\/myshared.blob.core.windows.net<\/a>, you would type myshared.<\/p><\/li>\n  <li><p><strong>Account key<\/strong>: Paste the storage access key that is associated with the account.<\/p><\/li>\n  <\/ul><\/li>\n  <\/ol>\n<\/blockquote>\n\n<p>I try to use a simple module combination as the figure and Python code below to test the issue you got.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/9XXPV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9XXPV.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<pre><code>import pandas as pd\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    dataframe1 = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n    return dataframe1,\n<\/code><\/pre>\n\n<p>When I tried to use the authentication type <code>Account<\/code> of my Blob Storage V2 account, I got the same issue as yours which the error code is <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/errors\/error-0151\" rel=\"nofollow noreferrer\">Error 0151<\/a> as below via click the <code>View error log<\/code> Button under the link of <code>View output log<\/code>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/TFQgO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TFQgO.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<blockquote>\n  <p><strong>Error 0151<\/strong><\/p>\n  \n  <p>There was an error writing to cloud storage. Please check the URL.<\/p>\n  \n  <p>This error in Azure Machine Learning occurs when the module tries to write data to cloud storage but the URL is unavailable or invalid.<\/p>\n  \n  <p><strong>Resolution<\/strong>\n  Check the URL and verify that it is writable.<\/p>\n  \n  <p><strong>Exception Messages<\/strong><\/p>\n  \n  <ul>\n  <li>Error writing to cloud storage (possibly a bad url).<\/li>\n  <li>Error writing to cloud storage: {0}. Please check the url.<\/li>\n  <\/ul>\n<\/blockquote>\n\n<p>Based on the error description above, the error should be caused by the blob url with SAS incorrectly generated by the <code>Export Data<\/code> module code with account information. May I think the code is old and not compatible with the new V2 storage API or API version information. You can report it to <code>feedback.azure.com<\/code>.<\/p>\n\n<p>However, I switched to use <code>SAS<\/code> authentication type to type a blob url with a SAS query string of my container which I generated via <a href=\"https:\/\/azure.microsoft.com\/en-us\/features\/storage-explorer\/\" rel=\"nofollow noreferrer\">Azure Storage Explorer<\/a> tool as below, it works fine.<\/p>\n\n<p>Fig 1: Right click on the container of your Blob Storage account, and click the <code>Get Shared Access Signature<\/code><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/1fyFL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/1fyFL.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 2: Enable the permission <code>Write<\/code> (recommended to use UTC timezone) and click <code>Create<\/code> button<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/IsbQQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/IsbQQ.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 3: Copy the <code>Query string<\/code> value, and build a blob url with a container SAS query string like <code>https:\/\/&lt;account name&gt;.blob.core.windows.net\/&lt;container name&gt;\/&lt;blob name&gt;&lt;query string&gt;<\/code><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/RGnxn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/RGnxn.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><strong><em>Note: The blob must be not exist in the container, otherwise an <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/errors\/error-0057\" rel=\"nofollow noreferrer\">Error 0057<\/a> will be caused.<\/em><\/strong><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-02-18 08:12:16.9 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2019-02-15 09:37:29.37 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML LibraryExecutionError",
        "Question_body":"<p>I get the following error when trying to retrieve the data from Azure Machine Learning<\/p>\n\n<pre><code>Error: LibraryExecutionError\nTarget: Score Model (AFx Library)\nMessage: table: The data set being scored must contain all features used during training, missing feature(s): 'NA'.\n<\/code><\/pre>\n\n<p>If I include NA within the values that get sent to Azure I get the following message <\/p>\n\n<pre><code>Parsing of input vector failed. Verify the input vector has the correct number of columns and data types\n<\/code><\/pre>\n\n<p>Has anyone got any idea's on how to fix this issue?<\/p>\n\n<p>James<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-12-20 14:57:21.44 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"c#|azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":187,
        "Owner_creation_date":"2012-05-15 21:40:01.493 UTC",
        "Owner_last_access_date":"2022-01-21 11:54:40.987 UTC",
        "Owner_location":"Neath, Wales",
        "Owner_reputation":97,
        "Owner_up_votes":33,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How do I indicate feature interaction in Azure Machine Learning Studio?",
        "Question_body":"<p>I am new to playing around with Azure ML, having used R a little bit for machine learning previously.<\/p>\n\n<p>In R, you can define <a href=\"https:\/\/christophm.github.io\/interpretable-ml-book\/interaction.html\" rel=\"nofollow noreferrer\">interactions<\/a> between variables using a multiplication operator, such as <\/p>\n\n<pre><code>lm(formula = target ~ var1 * var2 + var3)\n<\/code><\/pre>\n\n<p>Which would indicate that <code>var1<\/code> and <code>var2<\/code> interact while <code>var3<\/code> is independent.<\/p>\n\n<p>However, I haven\u2019t found any way to indicate this in Azure ML.  Is it possible?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-10-25 11:36:43.583 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":67,
        "Owner_creation_date":"2008-10-13 01:39:44.473 UTC",
        "Owner_last_access_date":"2022-09-08 00:53:40.017 UTC",
        "Owner_location":"Sydney, Australia",
        "Owner_reputation":5519,
        "Owner_up_votes":373,
        "Owner_down_votes":2,
        "Owner_views":672,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Future Prediction Algorithm",
        "Question_body":"<p>I support a business where customers pays for various services that they use on monthly basis.  I would like to use machine learning based on customers' historical usage of various services and predict the future usage (increase or decrease).<\/p>\n\n<p>I've used two class to create a model where it uses historical month-1 service usages and month-0 usage to predict the growth or decline. But I would like to start using all historical information not only m-1. <\/p>\n\n<p>How could I do this? Is my option to keep adding (M-2,M-3,M-4) columns? if that's the case I'm going to have hundreds of columns.<\/p>\n\n<p>I'm new to machine learning and I'm not sure which algorithm is great for the type of analysis I'm doing.<\/p>\n\n<p>Here is an example of the original table that I have:<\/p>\n\n<pre><code>Customer Name | MonthName      | Service | Usage\n------------- | ---------------|---------|------\nCustomer1     | January, 2017  |Service2 |$400\nCustomer1     | January, 2017  |Service1 |$300\nCustomer1     | January, 2017  |Service3 |$0\nCustomer1     | December, 2017 |Service2 |$600\nCustomer1     | December, 2017 |Service1 |$500\nCustomer1     | December, 2017 |Service3 |$700\nCustomer1     | November, 2016 |Service1 |$500\nCustomer1     | November, 2016 |Service2 |$50\nCustomer1     | October, 2016  |Service1 |$800\nCustomer2     | January, 2017  |Service2 |$400\nCustomer2     | January, 2017  |Service1 |$800\nCustomer2     | December, 2017 |Service2 |$600\nCustomer2     | December, 2017 |Service1 |$500\nCustomer2     | November, 2016 |Service1 |$500\nCustomer2     | November, 2016 |Service2 |$50\nCustomer2     | October, 2016  |Service1 |$800\n<\/code><\/pre>\n\n<p>Here is the table I'm using right now to come up with 2 class model:<\/p>\n\n<pre><code>+----------------+------------------+-----------------+-----------------+-----------------+-----------+-----------+-----------+-----------+-------+--------------------+\n| Customer Name  |  MonthName       | Service1  - M-1 | Service2  - M-1 | Service3  - M-1 | Usage M-1 | Service1  | Service2  | Service3  | Usage | Usage Decline Flag |\n+----------------+------------------+-----------------+-----------------+-----------------+-----------+-----------+-----------+-----------+-------+--------------------+\n| Customer1      |  October, 2016   |               0 |               0 |               0 |         0 |       800 |           |           |   800 |                  0 |\n| Customer1      |  November, 2016  |             800 |                 |                 |       800 |       500 |        50 |           |   550 |                  1 |\n| Customer1      |  December, 2017  |             500 |              50 |                 |       550 |       500 |       600 |       700 |  1800 |                  0 |\n| Customer1      |  January, 2017   |             500 |             600 |             700 |      1800 |       300 |       400 |         0 |   700 |                  1 |\n| Customer2      |  October, 2016   |               0 |               0 |               0 |         0 |      1600 |           |           |  1600 |                  0 |\n| Customer2      |  November, 2016  |            1600 |                 |                 |      1600 |       500 |       100 |           |   600 |                  1 |\n| Customer2      |  December, 2017  |             500 |             100 |                 |       600 |       500 |       600 |           |  1100 |                  0 |\n| Customer2      |  January, 2017   |             500 |             600 |                 |      1100 |       800 |       400 |           |  1200 |                  0 |\n+----------------+------------------+-----------------+-----------------+-----------------+-----------+-----------+-----------+-----------+-------+--------------------+\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2017-03-03 19:22:37.097 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|prediction|azure-machine-learning-studio",
        "Question_view_count":118,
        "Owner_creation_date":"2013-08-09 19:30:33.99 UTC",
        "Owner_last_access_date":"2019-11-26 16:16:51.63 UTC",
        "Owner_location":null,
        "Owner_reputation":97,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":29,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-03-12 08:49:15.637 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Moving Azure ML predictive experiment to another tenant",
        "Question_body":"<p>I have Azure ML predictive experiment on my tenant, I just need to move it to another azure tenant.is it possible to move or copy to another tenant ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-07-12 12:35:55.25 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":108,
        "Owner_creation_date":"2015-01-05 14:04:56.24 UTC",
        "Owner_last_access_date":"2022-09-22 12:15:52.087 UTC",
        "Owner_location":"India",
        "Owner_reputation":458,
        "Owner_up_votes":56,
        "Owner_down_votes":1,
        "Owner_views":184,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML: How to delete detached Kubernetes service clusters?",
        "Question_body":"<p>On AzureMl, I have created some Kubernetes service clusters using <code>ComputeTarget.create()<\/code>.<\/p>\n<p>Unfortunately, I have detached some of them and I can no longer see them from the AzureML page (Compute &gt; Inference Clusters). I can re-attach them on the AzureMl page but the delete bottom is not available for the re-attached clusters.<\/p>\n<p>Because those idle clusters occupy the Total Regional Cores quota I can't create new clusters, I am wondering if there is a way to delete them?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-05 03:43:18.633 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":112,
        "Owner_creation_date":"2017-04-29 23:38:18.56 UTC",
        "Owner_last_access_date":"2022-09-21 16:48:13.03 UTC",
        "Owner_location":null,
        "Owner_reputation":155,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-01-14 22:18:11.497 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AuthenticationException when creating Azure ML Dataset from Azure Data Lake Gen2 Datastore",
        "Question_body":"<p>I have an Azure Data Lake Gen2 with public endpoint and a standard Azure ML instance.\nI have created both components with my user and I am listed as Contributor.<\/p>\n<p>I want to use data from this data lake in Azure ML.<\/p>\n<p>I have added the data lake as a Datastore using Service Principal authentication.<\/p>\n<p>I then try to create a Tabular Dataset using the Azure ML GUI I get the following error:<\/p>\n<p>Access denied\nYou do not have permission to the specified path or file.<\/p>\n<pre><code>{\n  &quot;message&quot;: &quot;ScriptExecutionException was caused by StreamAccessException.\\n  StreamAccessException was caused by AuthenticationException.\\n    'AdlsGen2-ListFiles (req=1, existingItems=0)' for '[REDACTED]' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation using this permission.), client request ID '1f9e329b-2c2c-49d6-a627-91828def284e', request ID '5ad0e715-a01f-0040-24cb-b887da000000'. Error message: [REDACTED]\\n&quot;\n}\n<\/code><\/pre>\n<p>I have tried having our Azure Portal Admin, with Admin access to both Azure ML and Data Lake try the same and she gets the same error.<\/p>\n<p>I tried creating the Dataset using Python sdk and get a similar error:<\/p>\n<pre><code>ExecutionError: \nError Code: ScriptExecution.StreamAccess.Authentication\nFailed Step: 667ddfcb-c7b1-47cf-b24a-6e090dab8947\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by AuthenticationException.\n    'AdlsGen2-ListFiles (req=1, existingItems=0)' for 'https:\/\/mydatalake.dfs.core.windows.net\/mycontainer?directory=mydirectory\/csv&amp;recursive=true&amp;resource=filesystem' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation using this permission.), client request ID 'a231f3e9-b32b-4173-b631-b9ed043fdfff', request ID 'c6a6f5fe-e01f-0008-3c86-b9b547000000'. Error message: {&quot;error&quot;:{&quot;code&quot;:&quot;AuthorizationPermissionMismatch&quot;,&quot;message&quot;:&quot;This request is not authorized to perform this operation using this permission.\\nRequestId:c6a6f5fe-e01f-0008-3c86-b9b547000000\\nTime:2020-11-13T06:34:01.4743177Z&quot;}}\n| session_id=75ed3c11-36de-48bf-8f7b-a0cd7dac4d58\n<\/code><\/pre>\n<p>I have created Datastore and Datasets of both a normal blob storage and a managed sql database with no issues and I have only contributor access to those so I cannot understand why I should not be Authorized to add data lake. The fact that our admin gets the same error leads me to believe there are some other issue.<\/p>\n<p>I hope you can help me identify what it is or give me some clue of what more to test.<\/p>\n<p>Edit:\nI see I might have duplicated this post: <a href=\"https:\/\/stackoverflow.com\/questions\/63891547\/how-to-connect-amls-to-adls-gen-2\">How to connect AMLS to ADLS Gen 2?<\/a>\nI will test that solution and close this post if it works<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-13 06:49:26.337 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure|azure-active-directory|azure-data-lake|azure-data-lake-gen2|azure-machine-learning-service",
        "Question_view_count":3179,
        "Owner_creation_date":"2010-10-27 16:14:47.393 UTC",
        "Owner_last_access_date":"2022-09-23 13:31:35.43 UTC",
        "Owner_location":"Oslo, Norge",
        "Owner_reputation":1010,
        "Owner_up_votes":1344,
        "Owner_down_votes":1,
        "Owner_views":119,
        "Answer_body":"<p>This was actually a duplicate of <a href=\"https:\/\/stackoverflow.com\/questions\/63891547\/how-to-connect-amls-to-adls-gen-2\">How to connect AMLS to ADLS Gen 2?<\/a>.<\/p>\n<p>The solution is to give the service principal that Azure ML uses to access the data lake the Storage Blob Data Reader access. And note you have to wait at least some minutes for this to have effect.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-11-13 09:42:37.303 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":4.0,
        "Question_last_edit_date":"2020-11-13 07:54:31.243 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Error: TimeSeriesImputer object has no attribute '_known_df'",
        "Question_body":"<p>Running <a href=\"http:\/\/%20https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-orange-juice-sales\/auto-ml-forecasting-orange-juice-sales.ipynb\" rel=\"nofollow noreferrer\">this orange juice sales notebook<\/a> I get the below error with the <code>.forecast()<\/code> method.<\/p>\n<h3>code<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code># The featurized data, aligned to y, will also be returned.\n# This contains the assumptions that were made in the forecast\n# and helps align the forecast to the original data\ny_predictions, X_trans = fitted_model.forecast(X_test)\n<\/code><\/pre>\n<h3>Error (<a href=\"https:\/\/gist.github.com\/swanderz\/201819978b6719bbed1826a02bb2fb47\" rel=\"nofollow noreferrer\">full stacktrace<\/a>):<\/h3>\n<pre><code>**AttributeError: 'TimeSeriesImputer' object has no attribute '_known_df'**\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-28 13:28:01.953 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"time-series|azure-machine-learning-studio|forecast|azure-machine-learning-service",
        "Question_view_count":256,
        "Owner_creation_date":"2015-10-11 07:33:45.377 UTC",
        "Owner_last_access_date":"2022-01-12 11:43:12.04 UTC",
        "Owner_location":null,
        "Owner_reputation":303,
        "Owner_up_votes":105,
        "Owner_down_votes":7,
        "Owner_views":60,
        "Answer_body":"<p>This is commonly fixed by upgrading to the latest SDK. You can do this by running <code>pip install --upgrade azureml-sdk[explain,automl]<\/code>.<\/p>\n<p>Thanks,\nSabina<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-06-30 18:43:45.63 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2020-07-07 17:16:36.017 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"what is a transaction in Azure's cognitive Services text analytics API",
        "Question_body":"<p>I am looking at this:<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/en-gb\/pricing\/details\/cognitive-services\/text-analytics\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/en-gb\/pricing\/details\/cognitive-services\/text-analytics\/<\/a><\/p>\n\n<p>and would like to test drive the Free - Web\/Container to perform some sentiment analysis. It says that 5000 transactions are free. I understand that a record equals 1000 characters but what is a a transaction? Is it a text blob with potentially more than 1000 characters? Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-02-19 15:33:09.107 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-container-service|azure-cognitive-services",
        "Question_view_count":387,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Get local workspace in azureml",
        "Question_body":"<p>I am trying to run a machine learning experiment in azureml.<\/p>\n<p>I can't figure out how to get the workspace context from the control script.  Examples like <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data#control-script\" rel=\"nofollow noreferrer\">this one<\/a> in the microsoft docs use Workspace.from_config().  When I use this in the control script I get the following error:<\/p>\n<blockquote>\n<p>&quot;message&quot;: &quot;We could not find config.json in: [path] or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;<\/p>\n<\/blockquote>\n<p>I've also tried including my subscription id and the resource specs like so:<\/p>\n<pre><code>subscription_id = 'id'\nresource_group = 'name'\nworkspace_name = 'name'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n<\/code><\/pre>\n<p>In this case I have to monitor the log and authenticate on each run as I would locally.<\/p>\n<p>How do you get the local workspace from a control script for azureml?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-12 00:03:37.267 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":333,
        "Owner_creation_date":"2017-12-06 00:36:24.493 UTC",
        "Owner_last_access_date":"2022-09-22 22:49:47.607 UTC",
        "Owner_location":"Bloomington, IN, USA",
        "Owner_reputation":868,
        "Owner_up_votes":109,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Answer_body":"<p>This had no answers for 10 months, and now they are coming in :).  I figuerd this out quite a while ago but haven't gotten around to posting the answer.  Here it is.<\/p>\n<p>From the training script, you can get the workspace from the run context as follows:<\/p>\n<pre><code>from azureml.core import Run\nRun.get_context()\nws = run.experiment.workspace\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-12 03:28:12.267 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Separating a tree Regression Model based on unique values of one column",
        "Question_body":"<p>I have a data set of 20,000,000 rows. Each row has 30 columns.<\/p>\n\n<p>One of the columns contains 7000 unique Product Numbers. <\/p>\n\n<p>Each row contains a Unit Cost value that I would like to predict using all the columns other than the Unit Cost.<\/p>\n\n<p>I would like to build a unique decision tree or a unique branch of a decision tree to model the data for each Product Number.  <\/p>\n\n<p>Basically partitioning the rows for each Product Number and modelling each Product Number in isolation.<\/p>\n\n<p>I would like to train a single model in Azure to do this if possible.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-08-13 21:40:48.55 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":74,
        "Owner_creation_date":"2016-08-13 21:36:06.63 UTC",
        "Owner_last_access_date":"2016-08-13 22:39:21.39 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-07-10 14:53:10.287 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Refactor columns and features in Azure Machine Learning",
        "Question_body":"<p>Is there any way I can make my dataset features in Azure ML into something else than what it already is? <\/p>\n\n<p>I found a dataset of the Titanic ship in the sample datasets which I would like to work with but all of my columns are either a numeric feature or string feature, but I would like to categorize these. Also is there any possibility to rename the columns within my model so it\u2019s more descriptive than what I initially got? I have no clue what SibSp means for instance.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-09 14:08:01.33 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":297,
        "Owner_creation_date":"2016-06-07 19:08:35.433 UTC",
        "Owner_last_access_date":"2016-06-16 07:03:45.923 UTC",
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p>What you are doing is essentially recreating this experiment made by Raja Iqbal for the Titanic dataset. I recommend you check that out here: <a href=\"http:\/\/gallery.cortanaintelligence.com\/Experiment\/Tutorial-Building-a-classification-model-in-Azure-ML-8?share=1\" rel=\"nofollow noreferrer\">http:\/\/gallery.cortanaintelligence.com\/Experiment\/Tutorial-Building-a-classification-model-in-Azure-ML-8?share=1<\/a><\/p>\n\n<p>To answer your question, the module you can drag to your canvas in order to make the features into categories; is the Edit Metadata module where you select the columns you want and change the \u201cunchanged\u201d into \u201cMake categorical\u201d within the Categorical-properties pane like in the image below:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/2NDht.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2NDht.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>You can also use the same module to make better sense from your columns by giving them a different column name. SibSp means SiblingSpouse like I have renamed it to in the image below:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Gm9Rr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Gm9Rr.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And at last you can assign the targeted value (survived) and make the field into a label for ease of use.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LyN0j.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LyN0j.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-06-09 14:56:24.003 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2016-06-15 07:52:59.12 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to use secret keys in Azure Machine Learning Service pipelines",
        "Question_body":"<p>I am using Azure Machine Learning services and the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/concept-ml-pipelines\" rel=\"nofollow noreferrer\">pipeline functionality<\/a> for data preparation, training and testing of my Machine Learning models. However, during my data preparation step, I need to connect to a database and I want to find a way to pass my secret passwords or keys without writing them in plain text in my script files.<\/p>\n\n<p>Locally, I make use of environment variables for using secret passwords and keys, but to my best knowledge, this is impossible in the pipeline infrastructure, since Conda doesn't support passing environment variables. If anyone can confirm or deny this, it would be helpful.<\/p>\n\n<p>In the Azure Machine Learning services in the Azure Portal, I have found a 'key vault' resource, that is created automatically when I create a 'Machine Learning service workspace' resource. This seems to be exactly what I need. Is it? And if so, how do I use it?<\/p>\n\n<p>If neither of the above solves my issue, is there any other way to safely use secret passwords and keys in my scripts, without writing them in plain text in the scripts?<\/p>\n\n<p>EDIT: I realize my question have a strong focus on database connections. However, the question is really about any kinds of secrets or passwords, not just database credentials. As have been pointed out in an answer, that could be worth mentioning here, is that Azure SQL database connections can (and should) be solved using the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.data_transfer_step.datatransferstep?view=azure-ml-py\" rel=\"nofollow noreferrer\">DataTransferStep<\/a>.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2019-01-09 11:41:30.033 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service|azure-machine-learning-workbench",
        "Question_view_count":2044,
        "Owner_creation_date":"2016-05-20 15:01:49.237 UTC",
        "Owner_last_access_date":"2022-09-05 14:52:13.07 UTC",
        "Owner_location":"Uppsala, Sverige",
        "Owner_reputation":400,
        "Owner_up_votes":146,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-07-11 05:16:37.677 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Is there a way to access compute quotas with the Azure CLI or Python SDK?",
        "Question_body":"<p>I want to tabulate the compute quotas for each Azure ML workspace, in each Azure location, for my organization's Azure subscription. Although it is possible to look at the quotas manually through the Azure Portal (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#workspace-level-quota\" rel=\"nofollow noreferrer\">link<\/a>), I have not found a way to do this with the Azure CLI or Python SDK for Azure. Since there are many resource groups and AML workspaces for different teams under my Azure subscription, it would be much more efficient to do this programmatically rather than manually through the portal. Is this even possible, and if so how can it be done?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-12 16:09:02.537 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure|azure-cli|azure-machine-learning-service",
        "Question_view_count":418,
        "Owner_creation_date":"2013-05-29 21:42:57.597 UTC",
        "Owner_last_access_date":"2022-05-20 21:27:31.763 UTC",
        "Owner_location":"Cambridge, MA",
        "Owner_reputation":335,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":23,
        "Answer_body":"<p>It does look like these commands are currently in the CLI or the Python SDK. The CLI uses the Python SDK, so what's missing from one does tend to be missing from the other.<\/p>\n<p>Fortunately, you can invoke the rest endpoints directly, either in Python or by using the <code>az rest<\/code> command in the CLI.<\/p>\n<p>There are a few commands that may interest you:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/usages\/list\" rel=\"nofollow noreferrer\">Usage<\/a> and Quotas for a region:\n<code>\/subscriptions\/{subscriptionId}\/providers\/Microsoft.MachineLearningServices\/locations\/{location}\/usages?api-version=2019-05-01<\/code>\n<code>\/subscriptions\/{subscriptionId}\/providers\/Microsoft.MachineLearningServices\/locations\/{location}\/quotas?api-version=2020-04-01<\/code><\/p>\n<p>The process for updating REST specs to the offical documentation is fairly lengthy so it isn't published yet, but if you are willing to use Swagger docs to explore what is available, the 2020-06-01 version of the API is on Github, which includes endpoints for updating quotas as well as retrieving them: <a href=\"https:\/\/github.com\/Azure\/azure-rest-api-specs\/tree\/master\/specification\/machinelearningservices\/resource-manager\/Microsoft.MachineLearningServices\/stable\/2020-06-01\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/azure-rest-api-specs\/tree\/master\/specification\/machinelearningservices\/resource-manager\/Microsoft.MachineLearningServices\/stable\/2020-06-01<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2020-08-13 18:06:10.283 UTC",
        "Answer_last_edit_date":"2020-08-14 21:03:36.993 UTC",
        "Answer_score":1.0,
        "Question_last_edit_date":"2020-08-12 16:19:51.853 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Recommendations without ratings (Azure ML)",
        "Question_body":"<p>I'm trying to build an experiment to create recommendations (using the Movie Ratings sample database), but without using the ratings. I simply consider that if a user has rated certain movies, then he would be interested by other movies that have been rated by users that have also rated his movies.<\/p>\n\n<p>I can consider, for instance, that ratings are 1 (exists in the database) or 0 (does not exist), but in that case, how do I transform the initial data to reflect this?<\/p>\n\n<p>I couldn't find any kind of examples or tutorials about this kind of scenario, and I don't really know how to proceed. Should I transform the data before injecting it into an algorithm? And\/or is there any kind of specific algorithm that I should use?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2016-07-28 09:36:11.557 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":910,
        "Owner_creation_date":"2016-04-28 15:29:39.437 UTC",
        "Owner_last_access_date":"2018-11-30 14:23:33.087 UTC",
        "Owner_location":"Lille, France",
        "Owner_reputation":133,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":"<p>If you're hoping to use the Matchbox Recommender in AML, you're correct that you need to identify some user-movie pairs that <em>are<\/em> not present in the raw dataset, and add these in with a rating of zero. (I'll assume that you have already set all of the real user-movie pairs to have a rating of one, as you described above.)<\/p>\n\n<p>I would recommend generating some random candidate pairs and confirming their absence from the training data in an Execute R (or Python) Script module. I don't know the names of your dataset's features, but here is some pseudocode in R to do that:<\/p>\n\n<pre><code>library(dplyr)\ndf &lt;- maml.mapInputPort(1)  # input dataset of observed user-movie pairs\nall_movies &lt;- unique(df[['movie']])\nall_users &lt;- unique(df[['user']])\nn &lt;- 30  # number of random pairs to start with\n\nnegative_observations &lt;- data.frame(movie = sample(all_movies, n, replace=TRUE),\n                                    user = sample(all_users, n, replace=TRUE),\n                                    rating = rep(0, n))          \nacceptable_negative_observations &lt;- anti_join(unique(negative_observations), df, by=c('movie', 'user'))\ndf &lt;- rbind(df, acceptable_negative_observations)\nmaml.mapOutputPort(\"df\");\n<\/code><\/pre>\n\n<p>Alternatively, you could try a method like <a href=\"https:\/\/en.wikipedia.org\/wiki\/Association_rule_learning\" rel=\"nofollow\">association rule learning<\/a> which would not require you to add in the fake zero ratings. Martin Machac has posted a <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Frequently-bought-together-market-basket-analyses-using-ARULES-1\" rel=\"nofollow\">nice example<\/a> of how to do this in R\/AML in the Cortana Intelligence Gallery.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2016-08-16 13:34:13.81 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2016-07-28 10:18:09.49 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Mounting a FileDatasets in Azure ML Services",
        "Question_body":"<p>I am facing a problem with the Dataset module in Azure Machine Learning Services. I created a FileDataset with a bunch of images to train a model in TensorFlow. I\u2019m mounting the dataset in the target compute and then passing the mounting point to the train script as described <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets\/datasets-tutorial\/train-with-datasets.ipynb\" rel=\"nofollow noreferrer\">in the sample notebook we have on GitHub<\/a>. <\/p>\n\n<p>I tried two approaches: to pass the path as an script parameter (as suggested on GitHub) and as a named input, but none of them seem to pass the mounting point correctly.  Anyone does know which is the correct way to make it work? (I can make it work with Data Sources btw)<\/p>\n\n<p>As script parameter<\/p>\n\n<pre><code>script_params = {\n    '--data-folder': dset.as_named_input('dogscats_train').as_mount('tmp\/dataset'),\n} \n\nsrc = TensorFlow(source_directory =  r'Tensorflow',\n              framework_version = '1.13',\n              entry_script = 'train.py',\n              script_params=script_params,\n              compute_target='amlcompute', \n              vm_size='Standard_NC6', \n              use_gpu = True, \n              pip_packages = ['matplotlib', 'pillow', 'numpy', 'azureml-sdk'])\n<\/code><\/pre>\n\n<p><strong>Mounted path:<\/strong><\/p>\n\n<p>\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/aa-ml-aml-workspace\/azureml\/cats-vs-dogs-tensorflow_1570799752_014bea9f\/mounts\/workspaceblobstore\/azureml\/cats-vs-dogs-tensorflow_1570799752_014bea9f\/tmp\/dataset<\/p>\n\n<p><strong>Actual path received in the script:<\/strong><\/p>\n\n<p>\/tmp\/dataset<\/p>\n\n<p>As named input<\/p>\n\n<pre><code>src = TensorFlow(source_directory =  r'Tensorflow',\n              framework_version = '1.13',\n              entry_script = 'train.py',\n              inputs=[dset.as_named_input('dogscats_train')],\n              compute_target='amlcompute', \n              vm_size='Standard_NC6', \n              use_gpu = True, \n              pip_packages = ['matplotlib', 'pillow', 'numpy', 'azureml-sdk'])\n<\/code><\/pre>\n\n<p><strong>Mounted Path:<\/strong><\/p>\n\n<p>\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/aa-ml-aml-workspace\/azureml\/cats-vs-dogs-tensorflow_1570804147_39168dcf\/mounts\/workspaceblobstore<\/p>\n\n<p><strong>Path retrieved by run.input_datasets['dogscats_train'].mount('tmp\/dataset').mount_point:<\/strong><\/p>\n\n<p>\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/aa-ml-aml-workspace\/azureml\/cats-vs-dogs-tensorflow_1570804147_39168dcf\/mounts\/workspaceblobstore\/azureml\/cats-vs-dogs-tensorflow_1570804147_39168dcf\/tmp\/dataset<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-11 15:16:18.5 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure|tensorflow|azure-machine-learning-service",
        "Question_view_count":2898,
        "Owner_creation_date":"2019-10-11 15:06:49.227 UTC",
        "Owner_last_access_date":"2022-09-20 16:33:19.193 UTC",
        "Owner_location":"Argentina",
        "Owner_reputation":41,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-10-11 15:59:18.813 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML web service error",
        "Question_body":"<p>I try to implement random forest classifier in AzureML using Python script. It ran well in experiment but I am facing error when test the web services. <\/p>\n\n<pre><code># The script MUST contain a function named azureml_main\n# which is the entry point for this module.\n\n# imports up here can be used to \nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n# The entry point function can contain up to two input arguments:\n#   Param&lt;dataframe1&gt;: a pandas.DataFrame\n#   Param&lt;dataframe2&gt;: a pandas.DataFrame\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n\n    label_x = dataframe1[['NSP']]\n    del dataframe1['NSP']\n\n    label_y = dataframe2[['NSP']]\n    del dataframe2['NSP']\n    trained_model = random_forest_classifier(dataframe1, label_x)\n    # print (\"Trained model :: \", trained_model)\n    predictions = trained_model.predict(dataframe2)\n\n\n    # print (\"Train Accuracy :: \", accuracy_score(label_x, trained_model.predict(dataframe1)))\n    print (\"Test Accuracy  :: \", accuracy_score(label_y, predictions))\n    # print (\" Confusion matrix \", confusion_matrix(dataframe2, predictions))\n    cm = confusion_matrix(label_y, predictions)\n    TP = cm[0][0]\n    FP = cm[0][1]\n    FN = cm[1][0]\n    TN = cm[1][1]\n    print(\"True Positive: \", TP, \"False Positive: \", FP, \"True Negative: \", TN, \"False Negative: \",FN)\n    # If a zip file is connected to the third input port is connected,\n    # it is unzipped under \".\\Script Bundle\". This directory is added\n    # to sys.path. Therefore, if your zip file contains a Python file\n    # mymodule.py you can import it using:\n    # import mymodule\n\n    # Return value must be of a sequence of pandas.DataFrame\n    return pd.DataFrame(predictions)\n\ndef random_forest_classifier(features, target):\n    \"\"\"\n    To train the random forest classifier with features and target data\n    :param features:\n    :param target:\n    :return: trained random forest classifier\n    \"\"\"\n    clf = RandomForestClassifier()\n    clf.fit(features, target)\n    return clf\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/dI0Xg.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/dI0Xg.jpg\" alt=\"AzureML\"><\/a><\/p>\n\n<p>When I test the web services by entering the values, it show this error.<\/p>\n\n<blockquote>\n  <p>85: Error 0085: The following error occurred during script evaluation, please view the output log for more information: ---------- Start of error message from Python interpreter ---------- Caught exception while executing function: Traceback (most recent call last): File \"\\server\\InvokePy.py\", line 120, in executeScript outframe = mod.azureml_main(*inframes) File \"\\temp-6305281036382248739.py\", line 52, in azureml_main File \"C:\\pyhome\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 498, in predict proba = self.predict_proba(X) File \"C:\\pyhome\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 537, in predict_proba X = self._validate_X_predict(X) File \"C:\\pyhome\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 319, in _validate_X_predict return self.estimators_[0]._validate_X_predict(X, check_input=True) File \"C:\\pyhome\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 365, in _validate_X_predict X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\") File \"C:\\pyhome\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 407, in check_array context)) ValueError: Found array with 0 sample(s) (shape=(0, 21)) while a minimum of 1 is required. ---------- End of error message from Python interpreter ----------, Error code: ModuleExecutionError, Http status code: 400, Timestamp: Thu, 07 Dec 2017 15:24:18 GMT<\/p>\n<\/blockquote>\n\n<p>Can anyone tell me where is the error?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2017-12-07 15:25:45.473 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":131,
        "Owner_creation_date":"2015-06-28 00:17:57.227 UTC",
        "Owner_last_access_date":"2022-09-24 01:54:57.743 UTC",
        "Owner_location":null,
        "Owner_reputation":1232,
        "Owner_up_votes":798,
        "Owner_down_votes":2,
        "Owner_views":187,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-12-07 15:41:22.647 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Compute Instance: How can I safely upgrade the default Azure Ubuntu 16.04 LTS to the latest LTS?",
        "Question_body":"<p>I want to upgrade the default Ubuntu version that comes with the Compute Instance in Azure ML.<\/p>\n\n<p>Anyone has any guide on safely upgrading to the latest LTS?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-04 07:30:49.48 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|ubuntu|azure-machine-learning-service",
        "Question_view_count":312,
        "Owner_creation_date":"2015-12-08 02:47:47.717 UTC",
        "Owner_last_access_date":"2022-05-17 06:44:21.4 UTC",
        "Owner_location":null,
        "Owner_reputation":1302,
        "Owner_up_votes":115,
        "Owner_down_votes":1,
        "Owner_views":157,
        "Answer_body":"<p>Any specific reason you want to do this?<\/p>\n\n<p>Since there are some heavy dependencies (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#contents\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#contents<\/a>), my guess is you have to try it yourself.<\/p>\n\n<p>Create a new one and run:<\/p>\n\n<pre><code>$ sudo apt update \n$ sudo apt upgrade\n$ sudo apt dist-upgrade\n<\/code><\/pre>\n\n<p>Let us know what happened.<\/p>\n\n<p>BTW: Are Compute Instance also Docker images? If so, the upgrade might be working, if not, there might be many drivers that need to be upgraded too. The ones from the GPU would be the easiest...<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2020-06-07 12:02:00.41 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine learning python can't open file",
        "Question_body":"<p>I chose to use Python 3.8.1 Azure ML in Azure Machine learning studio, but when i run the command\n<code>!python train.py<\/code>, it uses python Anconda 3.6.9, when i downloaded python 3.8 and run the command <code>!python38 train.py<\/code> in the same dir  as before, the response was <code>python3.8: can't open file<\/code> .\nAny idea?\nAlso Python 3 in azure, is always busy, without anything running from my side.\nThank you.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2021-05-19 19:51:28.223 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":171,
        "Owner_creation_date":"2020-12-30 20:25:46.65 UTC",
        "Owner_last_access_date":"2021-06-24 19:02:37.96 UTC",
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"R error in Azure Machine Learning, not in R Studio",
        "Question_body":"<p>I'm facing a most annoying behavior where a R script works juts fine in R Studio and generates an error in Azure ML.<\/p>\n\n<p>I first I thought it was about inputs and outputs difference, but as you can see in the script below, I removed dependencies to input and outputs.<\/p>\n\n<p>The error is generated by the call to <code>chartr<\/code>: \"old\" is longer than \"new\".<\/p>\n\n<p>Any input is appreciated.<\/p>\n\n<pre><code>accented_characters &lt;- list('\u0160'='S', '\u0161'='s', '\u017d'='Z', '\u017e'='z', '\u00c0'='A', '\u00c1'='A', '\u00c2'='A', '\u00c3'='A', '\u00c4'='A', '\u00c5'='A', '\u00c6'='A', '\u00c7'='C', '\u00c8'='E', '\u00c9'='E',\n                        '\u00ca'='E', '\u00cb'='E', '\u00cc'='I', '\u00cd'='I', '\u00ce'='I', '\u00cf'='I', '\u00d1'='N', '\u00d2'='O', '\u00d3'='O', '\u00d4'='O', '\u00d5'='O', '\u00d6'='O', '\u00d8'='O', '\u00d9'='U',\n                        '\u00da'='U', '\u00db'='U', '\u00dc'='U', '\u00dd'='Y', '\u00de'='B', '\u00df'='Ss', '\u00e0'='a', '\u00e1'='a', '\u00e2'='a', '\u00e3'='a', '\u00e4'='a', '\u00e5'='a', '\u00e6'='a', '\u00e7'='c',\n                        '\u00e8'='e', '\u00e9'='e', '\u00ea'='e', '\u00eb'='e', '\u00ec'='i', '\u00ed'='i', '\u00ee'='i', '\u00ef'='i', '\u00f0'='o', '\u00f1'='n', '\u00f2'='o', '\u00f3'='o', '\u00f4'='o', '\u00f5'='o',\n                        '\u00f6'='o', '\u00f8'='o', '\u00f9'='u', '\u00fa'='u', '\u00fb'='u', '\u00fd'='y', '\u00fd'='y', '\u00fe'='b', '\u00ff'='y' )\n\ninput &lt;- data.frame(text = c(\"some piZza\u00e9 pizZa word a to : here $\",\"or there \u20ac with 28'89.5\"))\nstop_words &lt;- data.frame(international = c('pizza'))\n\nstop_words &lt;- as.character(stop_words$international)\nstop_words &lt;- gsub(\"^\\\\s+|\\\\s+$\", \"\", stop_words) # trim\nstop_words &lt;- tolower(stop_words) # lowercase\n\ninput &lt;- as.character(input$text)\ninput &lt;- gsub(\"[[:space:]]+\", ' ', input) # remove multiple spaces\ninput &lt;- gsub(\"[1-9!\\\"#$\u20ac%&amp;'()*+,.\/:;&lt;=&gt;@}~^_|`\\\\?\\\\[\\\\{]+\", '', input) # remove punctuation, numbers and some others. Note, does not remove closing bracket, can't figure out why\ninput &lt;- chartr(paste(names(accented_characters), collapse = ''),\n            paste(accented_characters, collapse = ''), input) # remove accents\ninput &lt;- tolower(input) # lowercase everything         \ninput &lt;- gsub(\"\\\\b[a-z]{1,2}\\\\b\", '', input) #remove too short words\ninput &lt;- gsub(paste(stop_words, \"|\"), '', input) # remove stop words\n\ninput &lt;- data.frame(input) # set as data.frame class\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2015-08-05 09:46:52.707 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"r|azure|azure-machine-learning-studio",
        "Question_view_count":453,
        "Owner_creation_date":"2012-07-30 15:08:34.857 UTC",
        "Owner_last_access_date":"2022-06-10 20:51:40.947 UTC",
        "Owner_location":"Paris, France",
        "Owner_reputation":2742,
        "Owner_up_votes":347,
        "Owner_down_votes":8,
        "Owner_views":291,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to get the model in scoring file from the one created in Azure AutoML pipeline (Python SDK)?",
        "Question_body":"<p>I've developed a pipeline with AutoML step and used the produced artifact to register the model. The artifact is a serialized model and is a big single file: model_data. I used pickle.load function to deserialize the model in Init function in the scoring file, but it failed during the deployment. When I unpickled the model in the main notebook it worked fine.\nThat makes me crazy. Please help, guys!<\/p>\n<p>AutoML-Pipeline.ipynb<\/p>\n<pre><code>automl_settings = {\n    &quot;experiment_timeout_minutes&quot;: 30,\n    &quot;primary_metric&quot;: 'AUC_weighted',\n    &quot;max_concurrent_iterations&quot;: 3, \n    &quot;max_cores_per_iteration&quot;: -1,\n    &quot;enable_dnn&quot;: True,\n    &quot;enable_early_stopping&quot;: True,\n    &quot;validation_size&quot;: 0.3,\n    &quot;verbosity&quot;: logging.INFO,\n    &quot;enable_voting_ensemble&quot;: False,\n    &quot;enable_stack_ensemble&quot;: False,\n}\n\nautoml_config = AutoMLConfig(task = 'classification',\n                             debug_log = 'automl_errors.log',\n                             path = &quot;.&quot;,\n                             compute_target=compute_target,\n                             training_data = train_ds,\n                             label_column_name = target_column_name,\n                             **automl_settings\n                            )\n\nmetrics_output_name = 'metrics_output'\nbest_model_output_name = 'best_model_output'\n\nmetrics_data = PipelineData(name='metrics_data',\n                           datastore=dstor,\n                           pipeline_output_name=metrics_output_name,\n                           training_output=TrainingOutput(type='Metrics'))\nmodel_data = PipelineData(name='model_data',\n                           datastore=dstor,\n                           pipeline_output_name=best_model_output_name,\n                           training_output=TrainingOutput(type='Model'))\n\nautoml_step = AutoMLStep(\n    name='automl_module',\n    automl_config=automl_config,\n    outputs=[metrics_data, model_data],\n    allow_reuse=False)\n<\/code><\/pre>\n<p>scoring_file_v_1_0_0.py<\/p>\n<pre><code>def init():\n    global model\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model_data')\n    try:\n        with open(model_path, &quot;rb&quot; ) as f:\n            model = pickle.load(f)\n    except Exception as e:\n        logging_utilities.log_traceback(e, logger)\n        raise\n<\/code><\/pre>\n<p>AutoML-Pipeline.ipynb<\/p>\n<pre><code>model = Model(ws, 'AutoML-Product')\nautoml_env = Environment.from_conda_specification(name = 'automl_env', file_path = 'conda_env_v_1_0_0.yml')\ninference_config=InferenceConfig(entry_script=&quot;scoring_file_v_1_0_0.py&quot;,environment=automl_env)\naciconfig=AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=1, \n                                               tags={'type': &quot;automl_product&quot;}, \n                                               description='Product Classification')\naci_service=Model.deploy(ws, &quot;automl-product-classification&quot;, [model], inference_config, aciconfig)\naci_service.wait_for_deployment(True)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>WebserviceException: WebserviceException: Message: Service deployment polling reached non-successful terminal state, current service state. \nError:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Your scoring file's init() function restarts frequently. You can address the error by increasing the value of memory_gb in deployment_config.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;ScoreInitRestart&quot;,\n      &quot;message&quot;: &quot;Your scoring file's init() function restarts frequently. You can address the error by increasing the value of memory_gb in deployment_config.&quot;\n    }\n  ]\n}\n<\/code><\/pre>\n<p>Successful run in notebook:\nAutoML-Pipeline.ipynb<\/p>\n<pre><code>import pickle\npath=Model.get_model_path('AutoML-Product',None,ws)\nwith open(path, &quot;rb&quot; ) as f:\n    best_model = pickle.load(f)\nbest_model\n&gt;&gt;&gt;&gt;&gt;\nPipelineWithYTransformations(Pipeline={'memory': None,\n                                       'steps': [('datatransformer',\n                                                  DataTransformer(enable_dnn=True, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=False, is_onnx_compatible=False, observer=None, task='classification', working_dir='\/mn...\n    with_std=True\n)),\n                                                 ('LogisticRegression',\n                                                  LogisticRegression(C=0.02811768697974228,\n                                                                     class_weight='balanced',\n                                                                     dual=False,\n                                                                     fit_intercept=True,\n                                                                     intercept_scaling=1,\n                                                                     l1_ratio=None,\n                                                                     max_iter=100,\n                                                                     multi_class='ovr',\n                                                                     n_jobs=-1,\n                                                                     penalty='l2',\n                                                                     random_state=None,\n                                                                     solver='saga',\n                                                                     tol=0.0001,\n                                                                     verbose=0,\n                                                                     warm_start=False))],\n                                       'verbose': False},\n                             y_transformer={},\n                             y_transformer_name='LabelEncoder')\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-13 03:42:20.233 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|scoring|automl|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":111,
        "Owner_creation_date":"2021-11-06 02:30:00.533 UTC",
        "Owner_last_access_date":"2022-08-26 03:24:42.007 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to use historical data set for training and prospective data set as input for prediction in Azure Machine Learning",
        "Question_body":"<p>Background information:\nI did an Data Mining experiment where I used historical data of customer purchases as case table for my mining structure. The second data set (prospective buyers) is used for testing.<\/p>\n\n<p>Now I want to implement the same scenario in Azure Machine Learning (Studio). However, I could not figure it out how I can use one data set to be used for training and a different data set to be used for testing. <\/p>\n\n<p>Furthermore, I'd like to ask if it is possible to use a data set for training the model but after deploying the model to a web service, to limit the input fields to certain columns?<\/p>\n\n<p>The historical data set contains 12 columns that I want to use for training the model. However, I want only 9 of those columns to be required as input when testing via the deployed model. <\/p>\n\n<p>I hope I made myself clear and that everything is understandable. If not, please ask me anything you want.<\/p>\n\n<p>Kind regards,\nlja<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-05 20:42:04.753 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":625,
        "Owner_creation_date":"2018-05-05 20:25:14.44 UTC",
        "Owner_last_access_date":"2018-05-15 19:40:16.203 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML free trial: how to submit pipeline?",
        "Question_body":"<p>I'm using a free trial account on MS Azure and I'm following this tutorial.<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score<\/a><\/p>\n\n<p>I'm stuck when I try to \"submit the pipeline\".<\/p>\n\n<p>The reason seems to be that I can't create a compute instance or a training cluster on a free plan.\nI still have 200USDs of free credits. I guess there must be a solution?<\/p>\n\n<hr>\n\n<p>Error messages:<\/p>\n\n<pre><code>Invalid graph: The pipeline compute target is invalid.\n\n400: Compute Test3 in state Failed, which is not able to use\n\nCompute instance: creation failed\nThe specified subscription has a total vCPU quota of 0 and is less than the requested compute training cluster and\/or compute instance's min nodes of 1 which maps to 4 vCPUs\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-12 08:54:46.103 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":370,
        "Owner_creation_date":"2012-07-30 21:09:03.65 UTC",
        "Owner_last_access_date":"2022-06-23 06:47:02.477 UTC",
        "Owner_location":null,
        "Owner_reputation":135,
        "Owner_up_votes":51,
        "Owner_down_votes":0,
        "Owner_views":45,
        "Answer_body":"<p>Please check the announcement from MS Team regarding this:<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/blog\/our-commitment-to-customers-and-microsoft-cloud-services-continuity\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/blog\/our-commitment-to-customers-and-microsoft-cloud-services-continuity\/<\/a><\/p>\n\n<p>All the free trials will not work as of now<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-04-12 08:55:59.587 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2020-04-12 11:18:01.397 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Influx DB as a source for MLS as a direct connection",
        "Question_body":"<p>Can we use InfluxDB as a data source for Azure ML Serv, in the form of a direct connection.  If not, what are the proposed alternatives to setup this connection?\n(Put differently, Is it possible for M LServ to connect to an InfluxDB next to some API to fetch data from. Or do we have to put all data in a SQL database?)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-24 13:43:06.13 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":105,
        "Owner_creation_date":"2020-03-24 13:41:21.607 UTC",
        "Owner_last_access_date":"2021-02-23 15:17:38.423 UTC",
        "Owner_location":null,
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Adding python modules to AzureML workspace",
        "Question_body":"<p>I've been working recently on deploying a machine learning model as a web service. I used Azure Machine Learning Studio for creating my own Workspace ID and Authorization Token. Then, I trained LogisticRegressionCV model from <strong>sklearn.linear_model<\/strong> locally on my machine (using python 2.7.13) and with the usage of below code snippet I wanted to publish my model as web service:<\/p>\n\n<pre><code>from azureml import services\n\n@services.publish('workspaceID','authorization_token')\n@services.types(var_1= float, var_2= float)\n@services.returns(int)\n\ndef predicting(var_1, var_2):\n    input = np.array([var_1, var_2].reshape(1,-1)\nreturn model.predict_proba(input)[0][1]\n<\/code><\/pre>\n\n<p>where <em>input<\/em> variable is a list with data to be scored and <em>model<\/em> variable contains trained classifier. Then after defining above function I want to make a prediction on sample input vector:<\/p>\n\n<pre><code>predicting.service(1.21, 1.34)\n<\/code><\/pre>\n\n<p>However following error occurs:<\/p>\n\n<pre><code>RuntimeError: Error 0085: The following error occurred during script \nevaluation, please view the output log for more information:\n<\/code><\/pre>\n\n<p>And the most important message in log is: <\/p>\n\n<pre><code>AttributeError: 'module' object has no attribute 'LogisticRegressionCV'\n<\/code><\/pre>\n\n<p>The error is strange to me because when I was using normal <em>sklearn.linear_model.LogisticRegression<\/em> everything was fine. I was able to make predictions sending POST requests to created endpoint, so I guess <strong>sklearn<\/strong> worked correctly. \nAfter changing to <em>LogisticRegressionCV<\/em> it does not. <\/p>\n\n<p>Therefore I wanted to update sklearn on my workspace.<\/p>\n\n<p>Do you have any ideas how to do it? Or even more general question: how to install any python module on azure machine learning studio in a way to use predict functions of any model I develpoed locally?<\/p>\n\n<p>Thanks<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2017-10-02 10:37:09.737 UTC",
        "Question_favorite_count":2.0,
        "Question_score":2,
        "Question_tags":"python|azure|scikit-learn|python-module|azure-machine-learning-studio",
        "Question_view_count":2578,
        "Owner_creation_date":"2016-03-23 16:31:44.64 UTC",
        "Owner_last_access_date":"2022-09-08 12:42:19.317 UTC",
        "Owner_location":"Warszawa, Polska",
        "Owner_reputation":186,
        "Owner_up_votes":108,
        "Owner_down_votes":1,
        "Owner_views":55,
        "Answer_body":"<p>For installing python module on Azure ML Studio, there is a section <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/cdb56f95-7f4c-404d-bde7-5bb972e6f232\/#Anchor_3\" rel=\"nofollow noreferrer\"><code>Technical Notes<\/code><\/a> of the offical document <code>Execute Python Script<\/code> which introduces it.<\/p>\n\n<p>The general steps as below.<\/p>\n\n<ol>\n<li>Create a Python project via <code>virtualenv<\/code> and active it.<\/li>\n<li>Install all packages you want via <code>pip<\/code> on the virtual Python environment, and then<\/li>\n<li>Package all files and directorys under the path <code>Lib\\site-packages<\/code> of your project as a zip file.<\/li>\n<li>Upload the zip package into your Azure ML WorkSpace as a dataSet.<\/li>\n<li>Follow the offical <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/execute-python-scripts#importing-existing-python-script-modules\" rel=\"nofollow noreferrer\">document<\/a> to import Python Module for your <code>Execute Python Script<\/code>.<\/li>\n<\/ol>\n\n<p>For more details, you can refer to the other similar SO thread <a href=\"https:\/\/stackoverflow.com\/questions\/46222606\/updating-pandas-to-version-0-19-in-azure-ml-studio\/46232963#46232963\">Updating pandas to version 0.19 in Azure ML Studio<\/a>, it even introduced how to update the version of Python packages installed by Azure.<\/p>\n\n<p>Hope it helps.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2017-10-03 07:03:59.333 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML Web Service for R models shows unpredictable",
        "Question_body":"<p>When publishing an Azure ML Web Service and preloading data in our R model we see inconsistent performance. First calls are slow but following calls are fast, waiting a bit (couple of minutes) for the next call ends up showing longer response times.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-06-21 11:47:43.807 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":69,
        "Owner_creation_date":"2016-06-21 10:08:08.92 UTC",
        "Owner_last_access_date":"2016-06-30 13:22:38.78 UTC",
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":64,
        "Answer_body":"<p>The way Azure ML Web Services work in the background means that instances hosting the models are provisioned and moved in a very dynamic multi-tenant environment. Caching data (warming up) can be helpful but this doesn't mean all subsequent calls will land on the same instance with the same data available in the cache. <\/p>\n\n<p>For models that need a lot of in-memory data there is a limit to what the Azure ML Web Services hosting layer can offer at this point. Microsoft R server could be an alternative to host these big ML workloads and looking at Service Fabric to scale <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-06-22 12:52:42.023 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2016-06-22 15:41:56.06 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to use an existing machine learning model with Azure Machine Learning?",
        "Question_body":"<p>I have a Keras ML model .h5 file that I would like to publish as a web-service. This model was created in databricks. I want to use Azure ML for this purpose.\nI am following the steps given in this Azure documentation -\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model<\/a><\/p>\n\n<p>One of the prerequisites is to have \"Azure Machine Learning SDK\".<\/p>\n\n<p>My question is how to install \"Azure Machine Learning SDK\" in my Azure ml workspace? Do I need to type the commands in the Cloud Shell? <\/p>\n\n<p>Any pointer would be helpful. Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-01 00:02:21.26 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-service",
        "Question_view_count":273,
        "Owner_creation_date":"2016-01-21 02:29:13.593 UTC",
        "Owner_last_access_date":"2022-09-14 19:49:37.23 UTC",
        "Owner_location":"Phoenix, AZ, USA",
        "Owner_reputation":445,
        "Owner_up_votes":44,
        "Owner_down_votes":1,
        "Owner_views":66,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How do we do Batch Inferencing on Azure ML Service with Parameterized Dataset\/DataPath input?",
        "Question_body":"<p>The ParallelRunStep Documentation suggests the following:<\/p>\n<p>A named input Dataset (<code>DatasetConsumptionConfig<\/code> class)<\/p>\n<pre><code>path_on_datastore = iris_data.path('iris\/')\ninput_iris_ds = Dataset.Tabular.from_delimited_files(path=path_on_datastore, validate=False)\nnamed_iris_ds = input_iris_ds.as_named_input(iris_ds_name)\n<\/code><\/pre>\n<p>Which is just passed as an Input:<\/p>\n<pre><code>distributed_csv_iris_step = ParallelRunStep(\n    name='example-iris',\n    inputs=[named_iris_ds],\n    output=output_folder,\n    parallel_run_config=parallel_run_config,\n    arguments=['--model_name', 'iris-prs'],\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>The Documentation to submit Dataset Inputs as Parameters suggests the following:\nThe Input is a <code>DatasetConsumptionConfig<\/code> class element<\/p>\n<pre><code>tabular_dataset = Dataset.Tabular.from_delimited_files('https:\/\/dprepdata.blob.core.windows.net\/demo\/Titanic.csv')\ntabular_pipeline_param = PipelineParameter(name=&quot;tabular_ds_param&quot;, default_value=tabular_dataset)\ntabular_ds_consumption = DatasetConsumptionConfig(&quot;tabular_dataset&quot;, tabular_pipeline_param)\n<\/code><\/pre>\n<p>Which is passed in <code>arguments<\/code> as well in <code>inputs<\/code><\/p>\n<pre><code>train_step = PythonScriptStep(\n    name=&quot;train_step&quot;,\n    script_name=&quot;train_with_dataset.py&quot;,\n    arguments=[&quot;--param2&quot;, tabular_ds_consumption],\n    inputs=[tabular_ds_consumption],\n    compute_target=compute_target,\n    source_directory=source_directory)\n<\/code><\/pre>\n<p>While submitting with new parameter we create a new <code>Dataset<\/code> class:<\/p>\n<pre><code>iris_tabular_ds = Dataset.Tabular.from_delimited_files('some_link')\n<\/code><\/pre>\n<p>And submit it like this:<\/p>\n<pre><code>pipeline_run_with_params = experiment.submit(pipeline, pipeline_parameters={'tabular_ds_param': iris_tabular_ds})\n<\/code><\/pre>\n<p>However, how do we combine this: How do we pass a Dataset Input as a Parameter to the ParallelRunStep?<\/p>\n<p>If we create a <code>DatasetConsumptionConfig<\/code> class element like so:<\/p>\n<pre><code>tabular_dataset = Dataset.Tabular.from_delimited_files('https:\/\/dprepdata.blob.core.windows.net\/demo\/Titanic.csv')\ntabular_pipeline_param = PipelineParameter(name=&quot;tabular_ds_param&quot;, default_value=tabular_dataset)\ntabular_ds_consumption = DatasetConsumptionConfig(&quot;tabular_dataset&quot;, tabular_pipeline_param)\n<\/code><\/pre>\n<p>And pass it as an argument in the ParallelRunStep, it will throw an error.<\/p>\n<p>References:<\/p>\n<ol>\n<li><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-showcasing-dataset-and-pipelineparameter.ipynb\" rel=\"nofollow noreferrer\">Notebook with Dataset Input Parameter<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/tabular-dataset-inference-iris.ipynb\" rel=\"nofollow noreferrer\">ParallelRunStep Notebook<\/a><\/li>\n<\/ol>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-19 15:51:52.093 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":664,
        "Owner_creation_date":"2020-10-03 12:46:02.437 UTC",
        "Owner_last_access_date":"2022-09-21 15:27:45.773 UTC",
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Answer_body":"<p>For the inputs we create Dataset class instances:<\/p>\n<pre><code>tabular_ds1 = Dataset.Tabular.from_delimited_files('some_link')\ntabular_ds2 = Dataset.Tabular.from_delimited_files('some_link')\n<\/code><\/pre>\n<p>ParallelRunStep produces an output file, we use the PipelineData class to create a folder which will store this output:<\/p>\n<pre><code>from azureml.pipeline.core import Pipeline, PipelineData\n\noutput_dir = PipelineData(name=&quot;inferences&quot;, datastore=def_data_store)\n<\/code><\/pre>\n<p>The ParallelRunStep depends on ParallelRunConfig Class to include details about the environment, entry script, output file name and other necessary definitions:<\/p>\n<pre><code>from azureml.pipeline.core import PipelineParameter\nfrom azureml.pipeline.steps import ParallelRunStep, ParallelRunConfig\n\nparallel_run_config = ParallelRunConfig(\n    source_directory=scripts_folder,\n    entry_script=script_file,\n    mini_batch_size=PipelineParameter(name=&quot;batch_size_param&quot;, default_value=&quot;5&quot;),\n    error_threshold=10,\n    output_action=&quot;append_row&quot;,\n    append_row_file_name=&quot;mnist_outputs.txt&quot;,\n    environment=batch_env,\n    compute_target=compute_target,\n    process_count_per_node=PipelineParameter(name=&quot;process_count_param&quot;, default_value=2),\n    node_count=2\n)\n<\/code><\/pre>\n<p>The input to ParallelRunStep is created using the following code<\/p>\n<pre><code>tabular_pipeline_param = PipelineParameter(name=&quot;tabular_ds_param&quot;, default_value=tabular_ds1)\ntabular_ds_consumption = DatasetConsumptionConfig(&quot;tabular_dataset&quot;, tabular_pipeline_param)\n<\/code><\/pre>\n<p>The PipelineParameter helps us run the pipeline for different datasets.\nParallelRunStep consumes this as an input:<\/p>\n<pre><code>parallelrun_step = ParallelRunStep(\n    name=&quot;some-name&quot;,\n    parallel_run_config=parallel_run_config,\n    inputs=[ tabular_ds_consumption ],\n    output=output_dir,\n    allow_reuse=False\n)\n<\/code><\/pre>\n<p>To consume with another dataset:<\/p>\n<pre><code>pipeline_run_2 = experiment.submit(pipeline, \n                                   pipeline_parameters={&quot;tabular_ds_param&quot;: tabular_ds2}\n)\n<\/code><\/pre>\n<p>There is an error currently: <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1312\" rel=\"nofollow noreferrer\">DatasetConsumptionConfig and PipelineParameter cannot be reused<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-02 06:41:28.81 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML Hyperdrive. Pass data between trials",
        "Question_body":"<p>Is it possible to pass data between individual trials in HyperDrive experiment?<\/p>\n<p>The <a href=\"https:\/\/github.com\/Azure\/azureml-examples\/blob\/sdk-preview\/sdk\/jobs\/single-step\/lightgbm\/iris\/src\/main.py\" rel=\"nofollow noreferrer\">example notebook from AzureML<\/a> reads training data inside training script, which will be executed in every separate trial of the HyperDrive experiment. However, it would be much more efficient if we could read data only once and pass it between all trials.<\/p>\n<p>Is it possible to configure it?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-12 16:55:10.647 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|hyperdrive",
        "Question_view_count":20,
        "Owner_creation_date":"2018-07-19 09:41:42.317 UTC",
        "Owner_last_access_date":"2022-09-23 16:55:26.937 UTC",
        "Owner_location":null,
        "Owner_reputation":367,
        "Owner_up_votes":52,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Import ONNX model to tensorflow-ValidationError: BatchNormalization.scale in initializer but not in graph input",
        "Question_body":"<p>I have downloaded ONNX model form CustomVision.ai and now I want to import into tensorflow and I am follwing \"<a href=\"https:\/\/github.com\/onnx\/tutorials\/blob\/master\/tutorials\/OnnxTensorflowImport.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/onnx\/tutorials\/blob\/master\/tutorials\/OnnxTensorflowImport.ipynb<\/a>\" for guidance.<\/p>\n\n<p>I have installed all the prerequisites as discussed in the above link. I am facing an error while executing \"tf_rep = prepare(model)\"---ValidationError: BatchNormalization.scale in initializer but not in graph input<\/p>\n\n<pre><code>import onnx\nfrom onnx_tf.backend import prepare\nmodel = onnx.load('C:\\\\Pankaj\\\\XYZ\\\\abc.onnx')\ntf_rep = prepare(model)\n<\/code><\/pre>\n\n<p>Thank you for your help and time.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2018-05-23 06:49:56.637 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python-3.x|image-processing|tensorflow|artificial-intelligence|azure-machine-learning-studio",
        "Question_view_count":434,
        "Owner_creation_date":"2012-05-09 16:13:36.97 UTC",
        "Owner_last_access_date":"2022-04-09 20:22:01.52 UTC",
        "Owner_location":"Hyderabad, India",
        "Owner_reputation":209,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2018-05-23 07:02:51.817 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML Model.profile() timeout without ever running the model",
        "Question_body":"<p>When trying to profile our AzureML model we run into a timeout. According to the log statements, <strong>the model is initialized<\/strong> but the <strong>run function is never called<\/strong>.<\/p>\n<p>The dataset provided contains one column (&quot;profile_requests&quot;) and 100 samples of serialized json that the model usually consumes. Both model and score.py work fine when deploying via Model.deploy (see below).<\/p>\n<p>Why is the run function never called?<\/p>\n<pre><code>profile = Model.profile(ws, \n    profile_name='my-profile-name',\n    models=[latest_model], \n    inference_config=InferenceConfig(\n                                    entry_script='score.py', \n                                    source_directory=&quot;deployment&quot;,\n                                    environment=Environment.get(ws, &quot;my_environment&quot;)), \n    input_dataset=processed_dataset,\n    cpu=2,\n    memory_in_gb=3)\n<\/code><\/pre>\n<pre><code>{...,\n 'error': {'code': 'ModelTestTimeOut',\n  'statusCode': 500,\n  'message': 'The model did not finish the test within the allowed time: 30 min. Error logs URL: https:\/\/link-to-logfile',\n  'details': []},\n 'errorLogsUri': 'https:\/\/link-to-logfile'}\n<\/code><\/pre>\n<p>Profiling log file:<\/p>\n<pre><code>==========Logs from model deployed to container with 2 cpu and 3 GB memory==========\n[...]\nInvoking user's init function\nModel loaded.\nUsers's init has completed successfully\nScoring timeout setting is not found. Use default timeout: 3600000 ms\n<\/code><\/pre>\n<p>One sample from the DataFrame (<code>sample_event=processed_dataset.to_pandas_dataframe().loc[0,&quot;profile_requests&quot;]<\/code>)<\/p>\n<pre><code>'{&quot;allevents&quot;: [{&quot;temperature&quot;: 103.76252626686478, &quot;ambienttemperature&quot;: 20.763083531178108, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:02&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 104.00700291712167, &quot;ambienttemperature&quot;: 20.77088671236806, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:07&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.73538818128196, &quot;ambienttemperature&quot;: 20.927115571418366, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:12&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.26993925975171, &quot;ambienttemperature&quot;: 20.977784248757075, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:17&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.47584351197627, &quot;ambienttemperature&quot;: 20.528207412934027, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:22&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.53497833736942, &quot;ambienttemperature&quot;: 21.176729435416277, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:27&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.33621482217512, &quot;ambienttemperature&quot;: 21.083552645791112, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:32&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.13542993745558, &quot;ambienttemperature&quot;: 20.80351544511668, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:37&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.45331951321728, &quot;ambienttemperature&quot;: 21.404335822865523, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:42&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.52506972734126, &quot;ambienttemperature&quot;: 20.51882900857312, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:47&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.61395300883524, &quot;ambienttemperature&quot;: 21.110307039511532, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:52&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}, {&quot;temperature&quot;: 103.49871551548077, &quot;ambienttemperature&quot;: 21.133206947070178, &quot;timeCreated&quot;: &quot;2020-04-02T12:07:57&quot;, &quot;ConnectionDeviceId&quot;: &quot;milkbottleEdge&quot;, &quot;ConnectionDeviceGenerationId&quot;: &quot;637211838651873534&quot;}]}'\n<\/code><\/pre>\n<p>Running the sample against the deployed webservice that uses the same environment and score.py <code>service.run(sample_event)<\/code> works as expected.<\/p>\n<pre><code>{'result': False,\n 'ConnectionDeviceId': 'milkbottleEdge',\n 'timeCreatedStart': '2020-04-02T12:07:02',\n 'timeCreatedEnd': '2020-04-02T12:07:57',\n 'hasError': False,\n 'errorMessage': None}\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-25 09:03:04.063 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":176,
        "Owner_creation_date":"2020-03-20 14:42:07.427 UTC",
        "Owner_last_access_date":"2021-08-19 12:58:38.267 UTC",
        "Owner_location":"Hamburg, Germany",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Is there a way to identify Azure ML vs Local PC environment using Python VS Code or JupyterLab?",
        "Question_body":"<p>I am new to Azure ML and VS Code. I'm running some projects in Azure ML, but at times I have to test it on my local PC. I was wondering if there's a way to distinguish between the two automatically so that I can load the data from the appropriate location depending on the environment. I couldn't find anything on the web search, or I couldn't understand some that I found.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2022-05-26 19:04:47.643 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|visual-studio-code|azure-machine-learning-service",
        "Question_view_count":42,
        "Owner_creation_date":"2016-10-20 15:12:05.47 UTC",
        "Owner_last_access_date":"2022-06-22 00:17:46.243 UTC",
        "Owner_location":null,
        "Owner_reputation":801,
        "Owner_up_votes":79,
        "Owner_down_votes":4,
        "Owner_views":106,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"\"Failure Exception: OSError: [Errno 30] Read-only file system\" when using AzureML in Python Azure Function",
        "Question_body":"<h2>Issue<\/h2>\n<p>I am trying prepare and then submit a new experiment to Azure Machine Learning from an Azure Function in Python. I therefore register a new dataset for my Azure ML workspace, which contains the training data for my ML model using <code>dataset.register(...<\/code>. However, when I try to create this dataset with the following line of code<\/p>\n<pre><code>dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)\n<\/code><\/pre>\n<p>then I get a <code>Failure Exception: OSError: [Errno 30] Read-only file system ...<\/code>.<\/p>\n<h2>Ideas<\/h2>\n<ol>\n<li>I know that I shouldn't write to the file system from within an Azure function if possible. But I actually don't want to write anything to the local file system. I only want to create the dataset as a reference to my blob storage under <code>datastore_path<\/code> and then register this to my Azure Machine Learning workspace. But it seems that the method <code>from_delimited_files<\/code> is trying to write to the file system anyway (maybe some caching?).<\/li>\n<li>I also know that there is a temp folder in which writing temporary files is permitted. However, I belive I cannot really control where this method is writing data. I already tried changing the current working directory to this temp folder just before the function call using <code>os.chdir(tempfile.gettempdir())<\/code>, but that didn't help.<\/li>\n<\/ol>\n<p>Any other ideas? I don't think I am doing something particularly unusually...<\/p>\n<h2>Details<\/h2>\n<p>I am using python 3.7 and azureml-sdk 1.9.0 and I can run the python script locally without problems. I currently deploy from VSCode using the Azure Functions extension version 0.23.0 (and an Azure DevOps pipeline for CI\/CD).<\/p>\n<p>Here is my full stack trace:<\/p>\n<pre><code>Microsoft.Azure.WebJobs.Host.FunctionInvocationException: Exception while executing function: Functions.HttpTrigger_Train\n ---&gt; Microsoft.Azure.WebJobs.Script.Workers.Rpc.RpcException: Result: Failure\nException: OSError: [Errno 30] Read-only file system: '\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/bin\/deps.lock'\nStack:   File &quot;\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py&quot;, line 345, in _handle__invocation_request\n    self.__run_sync_func, invocation_id, fi.func, args)\n  File &quot;\/usr\/local\/lib\/python3.7\/concurrent\/futures\/thread.py&quot;, line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File &quot;\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py&quot;, line 480, in __run_sync_func\n    return func(**params)\n  File &quot;\/home\/site\/wwwroot\/HttpTrigger_Train\/__init__.py&quot;, line 11, in main\n    train()\n  File &quot;\/home\/site\/wwwroot\/shared_code\/train.py&quot;, line 70, in train\n    dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/_loggerfactory.py&quot;, line 126, in wrapper\n    return func(*args, **kwargs)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/dataset_factory.py&quot;, line 308, in from_delimited_files\n    quoting=support_multi_line)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/readers.py&quot;, line 100, in read_csv\n    df = Dataflow._path_to_get_files_block(path, archive_options)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/dataflow.py&quot;, line 2387, in _path_to_get_files_block\n    return datastore_to_dataflow(path)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 41, in datastore_to_dataflow\n    datastore, datastore_value = get_datastore_value(source)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 83, in get_datastore_value\n    _set_auth_type(workspace)\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py&quot;, line 134, in _set_auth_type\n    get_engine_api().set_aml_auth(SetAmlAuthMessageArgument(AuthType.SERVICEPRINCIPAL, json.dumps(auth)))\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 18, in get_engine_api\n    _engine_api = EngineAPI()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py&quot;, line 55, in __init__\n    self._message_channel = launch_engine()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py&quot;, line 300, in launch_engine\n    dependencies_path = runtime.ensure_dependencies()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 141, in ensure_dependencies\n    with _FileLock(deps_lock_path, raise_on_timeout=timeout_exception):\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 113, in __enter__\n    self.acquire()\n  File &quot;\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py&quot;, line 72, in acquire\n    self.lockfile = os.open(self.lockfile_path, os.O_CREAT | os.O_EXCL | os.O_RDWR)\n\n   at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker.InvokeCore(Object[] parameters, FunctionInvocationContext context) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/Workers\/WorkerFunctionInvoker.cs:line 85\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionInvokerBase.Invoke(Object[] parameters) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/FunctionInvokerBase.cs:line 85\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionGenerator.Coerce[T](Task`1 src) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/FunctionGenerator.cs:line 225\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2.InvokeAsync(Object instance, Object[] arguments) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.cs:line 52\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.InvokeAsync(IFunctionInvoker invoker, ParameterHelper parameterHelper, CancellationTokenSource timeoutTokenSource, CancellationTokenSource functionCancellationTokenSource, Boolean throwOnTimeout, TimeSpan timerInterval, IFunctionInstance instance) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 587\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithWatchersAsync(IFunctionInstanceEx instance, ParameterHelper parameterHelper, ILogger logger, CancellationTokenSource functionCancellationTokenSource) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 532\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, ParameterHelper parameterHelper, IFunctionOutputDefinition outputDefinition, ILogger logger, CancellationTokenSource functionCancellationTokenSource) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 470\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, FunctionStartedMessage message, FunctionInstanceLogEntry instanceLogEntry, ParameterHelper parameterHelper, ILogger logger, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 278\n   --- End of inner exception stack trace ---\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, FunctionStartedMessage message, FunctionInstanceLogEntry instanceLogEntry, ParameterHelper parameterHelper, ILogger logger, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 325\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.TryExecuteAsyncCore(IFunctionInstanceEx functionInstance, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 117\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-13 22:20:36.433 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|azure-functions|readonly|azure-machine-learning-service|oserror",
        "Question_view_count":1092,
        "Owner_creation_date":"2020-08-13 19:15:32.177 UTC",
        "Owner_last_access_date":"2022-06-30 19:57:08.65 UTC",
        "Owner_location":null,
        "Owner_reputation":61,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":"<p>The issue was an incompatible OS version in my virtual environment.<\/p>\n<p>A huge thanks goes to <a href=\"https:\/\/docs.microsoft.com\/answers\/users\/111253\/pramodvalavala-msft.html\" rel=\"nofollow noreferrer\">PramodValavala-MSFT<\/a> for his idea to create a docker container! Following his suggestion, I suddenly got the following error message for the  <code>dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)<\/code> command:<\/p>\n<blockquote>\n<p>Exception: NotImplementedError: Unsupported Linux distribution debian 10.<\/p>\n<\/blockquote>\n<p>which reminded me of the following warning in the azure machine learning documentation:<\/p>\n<blockquote>\n<p>Some dataset classes have dependencies on the azureml-dataprep\npackage, which is only compatible with 64-bit Python. For Linux users,\nthese classes are supported only on the following distributions: Red\nHat Enterprise Linux (7, 8), Ubuntu (14.04, 16.04, 18.04), Fedora (27,\n28), Debian (8, 9), and CentOS (7).<\/p>\n<\/blockquote>\n<p>Choosing the predefined docker image <code>2.0-python3.7<\/code> (running Debian 9) instead of  <code>3.0-python3.7<\/code> (running Debian 10) solved the issue (see <a href=\"https:\/\/hub.docker.com\/_\/microsoft-azure-functions-python\" rel=\"nofollow noreferrer\">https:\/\/hub.docker.com\/_\/microsoft-azure-functions-python<\/a>).<\/p>\n<p>I suspect that the default virtual environment, which I was using originally, also ran on an incompatible OS.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-08-16 22:27:27.4 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":3.0,
        "Question_last_edit_date":"2021-02-15 16:41:46.92 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Test multiple algorithms in one experiment",
        "Question_body":"<p>Is there any way to test multiple algorithms rather than doing it once for each and every algorithm; then checking the result? There are a lot of times where I don\u2019t really know which one to use, so I would like to test multiple and get the result (error rate) fairly quick in Azure Machine Learning Studio.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_date":"2016-05-31 08:33:50.827 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":425,
        "Owner_creation_date":"2016-02-24 10:28:58.853 UTC",
        "Owner_last_access_date":"2016-08-22 12:20:52.243 UTC",
        "Owner_location":null,
        "Owner_reputation":39,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>The module you are looking for, is the one called \u201c<strong>Cross-Validate Model<\/strong>\u201d. It basically splits whatever comes in from the input-port (dataset) into 10 pieces, then reserves the last piece as the \u201canswer\u201d; and trains the nine other subset models and returns a set of accuracy statistics measured towards the last subset. What you would look at is the column called \u201cMean absolute error\u201d which is the average error for the trained models. You can connect whatever algorithm you want to one of the ports, and subsequently you will receive the result for that algorithm in particular after you \u201cright-click\u201d the port which gives the score.<\/p>\n\n<p>After that you can assess which algorithm did the best. And as a pro-tip; you could use the <strong>Filter-based-feature selection<\/strong> to actually see which column had a significant impact on the result.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-05-31 08:58:13.653 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2016-06-15 08:05:20.52 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML with python - (SSLError(SSLError('The write operation timed out',),),) when doing a table storage entity query",
        "Question_body":"<p>Hi I am trying to begin an Azure ML algorithm by executing a python script that queries data from a table storage account. I do it using this:<\/p>\n<pre><code>entities_Azure=table_session.query_entities(table_name=table_name, \n                                                filter=&quot;PartitionKey eq '&quot; + partitionKey + &quot;'&quot;,\n                                                select='PartitionKey,RowKey,Timestamp,value',\n                                                next_partition_key = next_pk,\n                                                next_row_key = next_rk, top=1000)  \n<\/code><\/pre>\n<p>I pass in the variables needed when calling the function that this bit of code sits in, and I include the function by including a zip file in Azure ML.<\/p>\n<p>I assume the error is due to the query taking too long, or something like that, but it has to take a long time because I might have to query loads of data.... I looked at this SO post <a href=\"https:\/\/stackoverflow.com\/questions\/18825567\/windows-azure-storage-table-connection-timed-out\">Windows Azure Storage Table connection timed out<\/a> which is a similar issue I think with regard to hitting specified thresholds for these queries, but I don't know how I'd be able to avoid it. The run time of the program is only about 1.5 mins before timing out..<\/p>\n<p>Any ideas as to why this is happening and how I might be able to solve it?<\/p>\n<h3>Edit:<\/h3>\n<p>As per <a href=\"https:\/\/stackoverflow.com\/users\/4989676\/peter-pan-msft\">Peter Pan - MSFT<\/a>'s advice I ran a query that was more specific:<\/p>\n<pre><code>entities_Azure=table_service.query_entities(table_name='#######',select='PartitionKey,RowKey,Timestamp,value', next_partition_key = None, next_row_key = None, top=2)\n<\/code><\/pre>\n<p>This returned the following error log:<\/p>\n<pre><code>Error 0085: The following error occurred during script evaluation, please view the output log for more information:  \n---------- Start of error message from Python interpreter ----------  \ndata:text\/plain,Caught exception while executing function: Traceback (most recent call last):    \n\nFile &quot;C:\\server\\invokepy.py&quot;, line 169, in \nbatch odfs = mod.azureml_main(*idfs)    \n\nFile &quot;C:\\temp\\azuremod.py&quot;, line 61, in \nazureml_main entities_Azure=table_service.query_entities(table_name='######',select='PartitionKey,RowKey,Timestamp,value', next_partition_key = None, next_row_key = None, top=2)    \n\nFile &quot;.\/Script Bundle\\azure\\storage\\table\\tableservice.py&quot;, line 421, in query_entities\n response = self._perform_request(request)    \n\nFile &quot;.\/Script Bundle\\azure\\storage\\storageclient.py&quot;, line 171, in _perform_request\n resp = self._filter(request)    \n\nFile &quot;.\/Script Bundle\\azure\\storage\\table\\tableservice.py&quot;, line 664, in _perform_request_worker\n return self._httpclient.perform_request(request)    \n\nFile &quot;.\/Script Bundle\\azure\\storage\\_http\\httpclient.py&quot;, line 181, in perform_request\n self.send_request_body(connection, request.body)    \n\nFile &quot;.\/Script Bundle\\azure\\storage\\_http\\httpclient.py&quot;, line 145, in send_request_body\n connection.send(None)    \n\nFile &quot;.\/Script Bundle\\azure\\storage\\_http\\requestsclient.py&quot;, line 81, in send\n self.response = self.session.request(self.method, self.uri, data=request_body, headers=self.headers, timeout=self.timeout)    \n\nFile &quot;C:\\pyhome\\lib\\site-packages\\requests\\sessions.py&quot;, line 456, in request\n resp = self.send(prep, **send_kwargs)    \n\nFile &quot;C:\\pyhome\\lib\\site-packages\\requests\\sessions.py&quot;, line 559, in send\n r = adapter.send(request, **kwargs)    \n\nFile &quot;C:\\pyhome\\lib\\site-packages\\requests\\adapters.py&quot;, line 382, in send\n raise SSLError(e, request=request) \n\nSSLError: The write operation timed out    \n---------- End of error message from Python  interpreter \n---------- Start time: UTC 11\/18\/2015 11:39:32 End time: UTC 11\/18\/2015 11:40:53\n<\/code><\/pre>\n<p>Hopefully this brings more insight to the situation!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2015-11-17 14:03:00.763 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"python|machine-learning|azure-storage|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":782,
        "Owner_creation_date":"2014-10-28 20:39:56.207 UTC",
        "Owner_last_access_date":"2018-08-05 14:18:56.57 UTC",
        "Owner_location":null,
        "Owner_reputation":135,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":66,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How connect Azure Function with my own model? It is possible to use Azure Storage?",
        "Question_body":"<h3>Intro<\/h3>\n<p>I created my own model locally and then register it and deploy it to azure and it works.<\/p>\n<h3>deployed model output:<\/h3>\n<p><a href=\"https:\/\/i.stack.imgur.com\/gaLCH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/gaLCH.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<h3>my approach<\/h3>\n<p>I used <a href=\"https:\/\/medium.com\/microsoftazure\/deploying-azure-machine-learning-containers-41bcb02a4e1b\" rel=\"nofollow noreferrer\">this tutorial<\/a>, and I want use my model in Azure Function and I can do it:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def main(req: func.HttpRequest, msg: func.Out[func.QueueMessage]) -&gt; str:\n    name = req.params.get('name')\n    scoring_uri = 'http:\/\/1f72b1bf-5ca9-42d9-bedd-f41773591a4f.francecentral.azurecontainer.io\/score'\n    headers = {'Content-Type':'application\/json'}\n    test_data = json.dumps({'text': 'Today is a great day!'})\n    response = requests.post(scoring_uri, data=test_data, headers=headers)\n\nif not name:\n    try:\n        req_body = req.get_json()\n    except ValueError:\n        pass\n    else:\n        name = req_body.get('name')\n\nif name:\n    msg.set(name)\n    return func.HttpResponse(f&quot;Hello {name}! Najlepszy wynik: {response.json()}&quot;)\nelse:\n    return func.HttpResponse(\n        &quot;Please pass a name on the query string or in the request body&quot;,\n        status_code=400\n    )\n<\/code><\/pre>\n<h3>questions<\/h3>\n<ol>\n<li>Is my usage correct?<\/li>\n<li>Is it possible to use azure storage for model storage and how to do it?<\/li>\n<li>Is there any other way to use the model in Azure Function?<\/li>\n<\/ol>\n<p>I am wondering because I had specified in the requirements that I should use azure functions and azure storage. I don't understand why.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-05 21:22:46.29 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-functions|azure-storage|azure-machine-learning-service",
        "Question_view_count":210,
        "Owner_creation_date":"2020-11-20 01:00:01.337 UTC",
        "Owner_last_access_date":"2021-04-10 20:06:50.227 UTC",
        "Owner_location":null,
        "Owner_reputation":73,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-01-06 15:01:34.497 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How do I improve Azure ML learning performance?",
        "Question_body":"<p>Training a simple convolutional network to recognize MNIST digits on Microsoft Azure (in Machine Learning Studio) takes many many times longer than it does for (already very slow) learning of exactly the same model locally, on a CPU (MacBook Pro, with limited memory) with TensorFlow.<\/p>\n\n<p>Is there a way \u2014 perhaps purchasing resources or connecting virtual GPUs \u2014 to improve performance of Azure Machine Learning?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2016-05-12 19:59:41.15 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"performance|machine-learning|cloud|azure-machine-learning-studio",
        "Question_view_count":1048,
        "Owner_creation_date":"2011-03-12 19:54:30.313 UTC",
        "Owner_last_access_date":"2022-09-21 19:06:38.42 UTC",
        "Owner_location":"United States",
        "Owner_reputation":41475,
        "Owner_up_votes":1198,
        "Owner_down_votes":107,
        "Owner_views":1912,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Using the MsticPY library in Azure ML to Open A Data Provider to Log Analytics",
        "Question_body":"<p>I am using the msticpy Library in Azure ML to open a connection to a Log Analytics workspace.\nI keep unable to get connected. I get &quot;Could not connect to kql query provider for loganalytics...&quot;\nI have tired using both the CLI login passing cli=locals() as well as msi=locals().<\/p>\n<p>I have made sure the System Managed Identity ML is setup in Identity, and assigned it the Log reader role for the resource group.<\/p>\n<p>has anyone been able to successfully make a connection to a Log Analytics workspace from Azure ML using the msticpy Library?<\/p>\n<p>thank you<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-12-03 15:53:26.737 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|python-3.x|azure|azure-machine-learning-service",
        "Question_view_count":64,
        "Owner_creation_date":"2017-11-23 16:24:01.753 UTC",
        "Owner_last_access_date":"2022-09-22 14:52:56.36 UTC",
        "Owner_location":null,
        "Owner_reputation":2221,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-12-14 19:12:09.887 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Deployemnt Time out error in AKS and Endpoint stuck in \"Transitioning\" state",
        "Question_body":"<p>We are working on the deployment of 170 ML models using ML studio and azure Kubernetes service which is referred on the below doc link &quot;https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-deploy-azure-kubernetes-service.md&quot;.<\/p>\n<p>We are training the model using python script with the custom environment and we are registering the ml model on the Azure ML services. Once we register the mode we are deploying it on the AKS by using the container images.<\/p>\n<p>While deploying the ML model we are able to deploy up to 10 to 11 models per pod for each Node in AKS. When we try to deploy the model on the same node we are getting deployment timeout error and we are getting the below error message.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/KFa6l.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KFa6l.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>For deploying the model in Azure Kubernetes Service using python language with below sample code.<\/p>\n<pre><code>#  Create an environment and add conda dependencies to it and for this creating our environment and building the custom container image.\n     myenv = Environment(name = Deployment_name)\n     myenv.python.conda_dependencies = CondaDependencies.create(pip_packages)\n    \n        \n #  Inference_Conifiguration\n     inf_config = InferenceConfig(environment= myenv, entry_script='.\/Script_file.py')\n    \n    \n # Deployment_Conifiguration\n     deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, cpu_cores_limit = 2, memory_gb_limit = 2, traffic_percentile = 10)\n    \n #  AKS cluster compute target \n     aks_target = ComputeTarget(ws, 'pipeline')\n       \n    \n#  Deploying the model in AKS server\n       service = Model.deploy(ws, Deployment_name, model_1, inf_config,\n                   deployment_config, aks_target, overwrite=True)\n    \n        service.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>We also checked on the azure documentation and we could able to find any configuration or deployment setup for aks nodes.<\/p>\n<p>Can you please provide us more clarification regarding &quot;The number of models to be deployed is limited to 1,000 models per deployment (per container)&quot; and Can you please give insight\/feedback on how to increase the number of ml models that can be deployed in each node in Azure Kubernetes Service? Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2021-09-06 07:41:13.2 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-aks|azure-machine-learning-studio|azure-container-registry|azure-machine-learning-service",
        "Question_view_count":313,
        "Owner_creation_date":"2020-09-22 12:59:55.247 UTC",
        "Owner_last_access_date":"2022-04-04 16:25:23.413 UTC",
        "Owner_location":null,
        "Owner_reputation":7,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"running OpenGL on AML gpu clusters",
        "Question_body":"<p>I am trying to run rendering code based on OpenGL (<a href=\"https:\/\/glumpy.readthedocs.io\/en\/latest\/api\/app-backends.html\" rel=\"nofollow noreferrer\">https:\/\/glumpy.readthedocs.io\/en\/latest\/api\/app-backends.html<\/a>) on NC machines as part of an AML experiment.\nNo matter the back-end I try to use, I get errors when rendering.<\/p>\n\n<p>Is OpenGL usage supported in AML?\nDid anyone had similar experiences? Where you able to solve it?<\/p>\n\n<p>thanks,\nEmanuel<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2020-02-27 19:00:21.823 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":57,
        "Owner_creation_date":"2018-03-01 09:03:25.313 UTC",
        "Owner_last_access_date":"2022-03-13 07:26:26.35 UTC",
        "Owner_location":null,
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Run script locally with remote dataset on AzureML",
        "Question_body":"<p>I have a script that for development purposes I would like to run and debug locally. However, I do not want to store the data needed for my experiment on my local machine.<\/p>\n<p>I am using the <code>azureml<\/code> library with the Azure Machine Learning Studio. See my code below<\/p>\n<pre><code># General\nimport os\nimport argparse\n\n# Data analysis and wrangling\nimport pandas as pd\n\n# Machine learning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom azureml.core import Run\n\n# Get the environment of this run\nrun = Run.get_context()\n\nif __name__ == &quot;__main__&quot;:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--data_path',\n        type=str,\n        help='Path to the training data',\n        # The default path is on my local machine, however I would like to reference a remote datastore on Azure as a parameter to this script\n        default=os.path.join(os.getcwd(), 'data')\n    )\n    args = parser.parse_args()\n\n    # Obtain the data from the datastore\n    train_df = pd.read_csv(os.path.join(args.data_path, os.listdir(args.data_path)[0]))\n\n    # Drop unnecessary columns\n    train_df = train_df.drop(['Name', 'PassengerId', 'Ticket', 'Cabin'], axis=1)\n\n    # Encode non-numeric features as dummies\n    train_df = pd.get_dummies(train_df)\n\n    # Drop NA's\n    train_df.dropna(inplace=True)\n\n    # Use gridsearch CV to find the best parameters for the model\n    parameters = {'kernel': ('linear', 'rbf'),\n                  'C': [1, 10]}\n\n    # Initialize the grid search\n    search = GridSearchCV(SVC(), param_grid=parameters, cv=8)\n\n    # Train the model\n    search.fit(train_df.drop(&quot;Survived&quot;, axis=1), train_df[&quot;Survived&quot;])\n\n<\/code><\/pre>\n<p>Now, the script uses a local folder 'data'. However, I would like to give an argument to this script that indicates I would like to use a remote datastore in the Azure Machine Learning Studio. How could I achieve that?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-07-01 10:39:02.17 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":245,
        "Owner_creation_date":"2020-04-06 10:20:27.24 UTC",
        "Owner_last_access_date":"2022-09-23 14:24:39.773 UTC",
        "Owner_location":null,
        "Owner_reputation":299,
        "Owner_up_votes":44,
        "Owner_down_votes":2,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML model on ACI - multiple request handling?",
        "Question_body":"<p>I want to understand if the ML model deployed to an Azure Container Instance (ACI) will handle multiple simultaneous incoming requests. At the moment we have a need to host 2 ML models for an application that might have a peak of 20 requests per hour. What I am unsure about is whether the deployed container from the ML Workspace can handle multiple requests simultaneously? So for example, if it receives 5-10 requests simultaneously is the container deployed in ACI capable of multithreading and handling the incoming requests. OR does it queue these up to handle one at a time? Reason I ask is because a single call takes 10-15 seconds and so was wondering if subsequent requests arriving within a close duration while the first request is still being processed, get queued in FIFO order OR if it can internally spawn more threads to address the multiple requests like a web server would?<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-17 23:05:42.937 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service|azure-container-instances",
        "Question_view_count":151,
        "Owner_creation_date":"2013-08-15 14:39:30.773 UTC",
        "Owner_last_access_date":"2022-09-23 17:28:32.673 UTC",
        "Owner_location":null,
        "Owner_reputation":301,
        "Owner_up_votes":27,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"OpenSSL critical Vulnerability in AzureML Model Deployment to Kubernetes",
        "Question_body":"<p>I have an issue with OpenSSL, I am using the following command to install the latest version of OpenSSL in my Base Docker Image of Azure ML Deployment as the older version has some critical security vulnerability. However, the final image still has the older versions of OPENSSL, it could either be that or AzureML is installing the packages by itself, can anyone tell me how to get past this issue? or delete older versions of OpenSSL?<\/p>\n<pre><code>FROM ubuntu:18.04\n\n# Install dependencies:\nRUN apt-get update  &amp;&amp; apt-get -y install openssl\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/jDAXW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/jDAXW.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-22 15:13:45.127 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"docker|kubernetes|openssl|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":46,
        "Owner_creation_date":"2016-01-26 08:54:35.09 UTC",
        "Owner_last_access_date":"2022-09-21 20:10:11.297 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2022-08-24 07:32:54.98 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Comparing brier score for Azure ML classifier",
        "Question_body":"<p>I'm trying to compare the brier score for two classifiers in Azure ML studio:<\/p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import brier_score_loss\n\ndef azureml_main(dataframe1, dataframe2):\n    colnames_1 = dataframe1.columns\n    y_true_1 = np.array(dataframe1[colnames_1[1]])\n    y_prob_1 = np.array(dataframe1[colnames_1[-1]])\n    brier_score_1 = brier_score_loss(y_true_1, y_prob_1)\n\n    colnames_2 = dataframe2.columns\n    y_true_2 = np.array(dataframe2[colnames_2[1]])\n    y_prob_2 = np.array(dataframe2[colnames_2[-1]])\n    brier_score_2 = brier_score_loss(y_true_2, y_prob_2)\n\n    data = {'brier_score': [brier_score_1, brier_score_2]}\n    result = pd.DataFrame(data, columns=['brier_score'])\n\n    return result\n<\/code><\/pre>\n\n<p>My problem is that the script only outputs a value in the first row with the brier score of the first dataset. The second row is empty. This is how I have connected the script: \n<img src=\"https:\/\/anonimag.es\/i\/azure0f4ae.png\" alt=\"azure\"><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2017-03-16 20:55:07.193 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|python-3.x|azure|azure-machine-learning-studio",
        "Question_view_count":97,
        "Owner_creation_date":"2015-02-22 16:00:48.827 UTC",
        "Owner_last_access_date":"2022-09-23 13:13:21.623 UTC",
        "Owner_location":null,
        "Owner_reputation":2026,
        "Owner_up_votes":599,
        "Owner_down_votes":15,
        "Owner_views":130,
        "Answer_body":"<p>I turned out that the problem was caused by a few NaN values in the second dataframe.\nAdding <code>dataframe2 = dataframe2.dropna()<\/code> to the top of the script solved the problem.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2017-03-30 18:58:43.347 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2017-03-17 02:01:37.823 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Write to a mounted filesystem in azureml with azureml-sdk",
        "Question_body":"<p>I am trying to use and AMLCompute instance to preprocess my data.  To do so I need to be able to write the processed data back to the datastore.  I am taking this approach because the cluster will automatically shutdown when it is complete so I can let it run until it is done without worrying about paying for more time than is needed.<\/p>\n<p>The problem is when I try to write back to the datastore (which is mounted as a dataset) I get the following error:<\/p>\n<pre><code>OSError: [Errno 30] Read-only file system: '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/[...]\/wav_test'\n<\/code><\/pre>\n<p>I have set the access policy for my datastore to allow read, add, create, write, delete, and list, but I don't think that is the issue because I can already write to the datastore from the Microsoft Azure File Explorer.<\/p>\n<p>Is there a way to mount a datastore directly or through a dataset <strong>with write privileges<\/strong> from the azureml python sdk?<\/p>\n<p>Alternatively, is there a better way to preprocess this (audio) data on azure for machine learning?<\/p>\n<p>Thanks!<\/p>\n<p>EDIT:\nI'm adding an example that illustrates the problem.<\/p>\n<pre><code>from azureml.core import Workspace, Dataset, Datastore\nimport os\n\nws = Workspace.from_config()\nds = Dataset.get_by_name(ws, name='birdsongs_alldata')\n\nmount_context = ds.mount()\nmount_context.start()\n\nos.listdir(mount_context.mount_point)\n<\/code><\/pre>\n<p>output:<\/p>\n<blockquote>\n<p>['audio_10sec', 'mp3', 'npy', 'resources', 'wav']<\/p>\n<\/blockquote>\n<p>So the file system is mounted and visible.<\/p>\n<pre><code># try to write to the mounted file system\noutfile = os.path.join(mount_context.mount_point, 'test.txt')\n\nwith open(outfile, 'w') as f:\n    f.write('test')\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>--------------------------------------------------------------------------- OSError                                   Traceback (most recent call last) &lt;ipython-input-9-1b15714faded&gt; in &lt;module&gt;\n      1 outfile = os.path.join(mount_context.mount_point, 'test.txt')\n      2 \n----&gt; 3 with open(outfile, 'w') as f:\n      4     f.write('test')\n\nOSError: [Errno 30] Read-only file system: '\/tmp\/tmp8ltgsx6x\/test.txt'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-13 19:30:11.127 UTC",
        "Question_favorite_count":0.0,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":961,
        "Owner_creation_date":"2017-12-06 00:36:24.493 UTC",
        "Owner_last_access_date":"2022-09-22 22:49:47.607 UTC",
        "Owner_location":"Bloomington, IN, USA",
        "Owner_reputation":868,
        "Owner_up_votes":109,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2021-04-14 23:11:10.743 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to combine two algorithms for predictive analysis in MS Azure",
        "Question_body":"<p>I am developing a combined-algorithm model in MS Azure Machine Learning Studio that should be able to predict whether a Telco-customer churn or not. Given that I have 19 variable features, e.g. monthly fee, usage length etc., how do I combine two useful algorithms? And how do I know these provide the highest Accuracy (Highest possible Accuracy needed), ie. which elements do I yet need to add and how should I use for predicting churn behaviour onto another dataset of a \"fresh\" set of customers? <\/p>\n\n<p>I have:\n1) Edit Metadata\nHaving excluded the User_ID variable I have used the Edit Metadata element to label the Attrition variable (Attrition is whether a customer has churned, i.e. Yes or No). Simultaneously I have transformed Attrition into a categorical variable, specifying that the selected values should be treated in two categories, i.e. Yes or No. <\/p>\n\n<p>Normalize data\nSince the three identified numerical variables (Usage_Length, Monthly_Fee and Total_Fee) a quite different in scale, e.g. Max(Monthly_Fee) is at 78,80 while Max(Total_Fee) is at 5.789,87, I have normalized Monthly_Fee and Total_Fee using the LogNormal Transformation method. <\/p>\n\n<p>Edit Metadata (2nd use)\nHaving normalized two of the numerical values, I have made all non-numerical features, e.g. User_Gender, Is_Senior etc., into categorical values to make them useful for the coming analysis. <\/p>\n\n<p>Split data\nOnce the above steps have been carried out, I have made a testing\/training split of 0.2 and 0.8, respectively on which I run the models.<\/p>\n\n<p>Choice of algorithm\nI have selected Two-class Boosed Decision Tree and Two-Class Decision Forest as they provide the highest possible individual Accuracy; 0.963 and 0.967, respectively. <\/p>\n\n<p>No coding used - only elements added. <\/p>\n\n<p>I expect the highest possible Accuracy, currently at 0.967 when combining the models into an Evaluation element<a href=\"https:\/\/i.stack.imgur.com\/HGPuI.png\" rel=\"nofollow noreferrer\">Current Model Screenshot<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":10,
        "Question_creation_date":"2019-07-22 10:22:56.267 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":39,
        "Owner_creation_date":"2019-07-22 10:08:48.347 UTC",
        "Owner_last_access_date":"2019-08-14 09:16:46.103 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2019-07-22 10:49:04.86 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Getting error Missing required package \"azureml-dataset-runtime\" in VSCode",
        "Question_body":"<p>I am trying to setup my virtual environment for Azure in VS Code. I have installed the required packages, e.g., <code>azureml-core<\/code> and <code>azureml-widgets<\/code> and <code>azureml-dataset-runtime<\/code>. Both <code>azureml-core<\/code> and <code>azureml-widget<\/code> work fine, however, I keep getting an error missing required package for <code>azureml-dataset-runtime<\/code> although I installed it.<\/p>\n<p>I have Python 3.7 and Python 3.8 installed, both 64 bit and I tried both of them in my virtual environment, still no luck.<\/p>\n<p>Any suggestions?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-05-07 15:53:49.14 UTC",
        "Question_favorite_count":null,
        "Question_score":7,
        "Question_tags":"azure|visual-studio-code|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":433,
        "Owner_creation_date":"2020-09-12 17:36:28.727 UTC",
        "Owner_last_access_date":"2022-09-22 00:17:59.883 UTC",
        "Owner_location":null,
        "Owner_reputation":105,
        "Owner_up_votes":52,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"VS code cannot connect to computer instances in Azure Machine Learning",
        "Question_body":"<p>The original question can be found <a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/469700\/terminal-of-computer-instance-keeps-loading-and-at.html\" rel=\"nofollow noreferrer\">here<\/a>. I am posting the question here again, because it seems to be an issue of VS code instead of Azure Machine Learning according to the AML team.<\/p>\n<p>I haven't experienced this issue indeed, if I only use Azure Machine Learning in the browser without trying to connect to VS code. If I try to connect with VS code, the same issue happens.<\/p>\n<p>Could someone help me to solve this issue? Thanks!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2021-07-22 13:26:08.803 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure|visual-studio-code|azure-machine-learning-studio",
        "Question_view_count":452,
        "Owner_creation_date":"2019-01-17 12:03:12.98 UTC",
        "Owner_last_access_date":"2022-02-16 16:52:04.867 UTC",
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Best way to handle missing file in azureml Dataset from_delimited_files call",
        "Question_body":"<p>I have the following code statement in Python with the AzureML SDK, that works great, unless if there are no files matching the partition name wildcard filter.<\/p>\n\n<p>In that case, an exception is thrown.  (see error below the code).  I can obviously catch the Error and check for the description, but I would prefer to have a way to check if there's a file matching the given file name.  What would be the best way (without impacting performance too much) here?<\/p>\n\n<p><strong>The code<\/strong>:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>partition_name = 'BE*'\ndatastore_name = 'ml'\n\nfrom azureml.core import Workspace, Dataset, Datastore\nfrom azureml.data.datapath import DataPath\n\nws = Workspace.from_config()\ndatastore = Datastore(ws, name=datastore_name)\ndataset = Dataset.Tabular.from_delimited_files(header=False,\n                    path=DataPath(datastore, '\/' + partition_name + '.csv')) \ndf = aml_dataset.to_pandas_dataframe()\n<\/code><\/pre>\n\n<p><strong>The exception:<\/strong><\/p>\n\n<pre><code>ExecutionError: The provided path is not valid or the files could not be accessed.\n(No files were found using path provided. Please make sure the path you've specified is correct, \nfiles exist and can be accessed.)|session_id=xxx \nDuring handling of the above exception, another exception occurred:\n\nDatasetValidationError                    Traceback (most recent call last)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_creation_date":"2020-05-08 07:55:55.06 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":272,
        "Owner_creation_date":"2013-02-12 07:50:30.743 UTC",
        "Owner_last_access_date":"2022-09-21 18:28:12.907 UTC",
        "Owner_location":"Belgium",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-05-08 08:05:39.69 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Problem with init() function for model deployment in Azure",
        "Question_body":"<p>I want to deploy model in Azure but I'm struggling with the following problem.<\/p>\n<p>I have my model registered in Azure. The file with extension .sav is located locally. The registration looks the following:<\/p>\n<pre><code>import urllib.request\nfrom azureml.core.model import Model\n\n# Register model\nmodel = Model.register(ws, model_name=&quot;my_model_name.sav&quot;, model_path=&quot;model\/&quot;) \n<\/code><\/pre>\n<p>I have my <code>score.py<\/code> file. The <code>init()<\/code> function in the file looks like this:<\/p>\n<pre><code>import json\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nfrom azureml.core.model import Model\n\n def init():\n    \n    global model\n    model_path = Model.get_model_path(model_name = 'my_model_name.sav', _workspace='workspace_name')\n    model = pickle(open(model_path, 'rb'))\n<\/code><\/pre>\n<p>But when I try to deploy I se the following error:<\/p>\n<pre><code>&quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n    1. Please check the logs for your container instance: leak-tester-pm. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n<\/code><\/pre>\n<p>And when I run <code>print(service.logs())<\/code> I have the following output (I have only one model registered in Azure):<\/p>\n<pre><code>None\n<\/code><\/pre>\n<p>Am I doing something wrong with loading  model in score.py file?<\/p>\n<p>P.S. The .yml file for the deployment:<\/p>\n<pre><code>name: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n  - scikit-learn==0.24.2\n  - azureml-defaults\n  - numpy\n  - pickle-mixin\n  - pandas\n  - xgboost\n  - azure-ml-api-sdk\nchannels:\n- anaconda\n- conda-forge\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-15 09:04:33.623 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":271,
        "Owner_creation_date":"2019-07-30 13:42:54.517 UTC",
        "Owner_last_access_date":"2022-09-21 08:53:39.343 UTC",
        "Owner_location":"Wroc\u0142aw, \u041f\u043e\u043b\u044c\u0448\u0430",
        "Owner_reputation":73,
        "Owner_up_votes":22,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML: Include additional files during model deployment",
        "Question_body":"<p>In my AML pipeline, I've got a model built and deployed to the AciWebservice. I now have a need to include some additional data that would be used by score.py. This data is in json format (~1mb) and is specific to the model that's built. To accomplish this, I was thinking of sticking this file in blob store and updating some \"placholder\" vars in the score.py during deployment, but it seems hacky. <\/p>\n\n<p>Here are some options I was contemplating but wasn't sure on the practicality<\/p>\n\n<p><strong>Option 1:<\/strong>\nIs it possible to include this file, during the model deployment itself so that it's part of the docker image? <\/p>\n\n<p><strong>Option 2:<\/strong>\nAnother possibility I was contemplating, would it be possible to include this json data part of the Model artifacts?<\/p>\n\n<p><strong>Option 3:<\/strong>\nHow about registering it as a dataset and pull that in the score file?<\/p>\n\n<p>What is the recommended way to deploy dependent files in a model deployment scenario?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-14 16:56:48.817 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":866,
        "Owner_creation_date":"2012-02-23 16:54:25.41 UTC",
        "Owner_last_access_date":"2022-09-02 23:23:03.83 UTC",
        "Owner_location":null,
        "Owner_reputation":1704,
        "Owner_up_votes":61,
        "Owner_down_votes":7,
        "Owner_views":232,
        "Answer_body":"<p>There are few ways to accomplish this:<\/p>\n\n<ol>\n<li><p>Put the additional file in the same folder as your model file, and <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none--sample-input-dataset-none--sample-output-dataset-none--resource-configuration-none-\" rel=\"nofollow noreferrer\">register<\/a> the whole folder as the model. In this approach the file is stored alongside the model.<\/p><\/li>\n<li><p>Put the file in a local folder, and specify that folder as source_directory in <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.inferenceconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\">InferenceConfig<\/a>. In this approach the file is re-uploaded every time you deploy a new endpoint.<\/p><\/li>\n<li><p>Use custom base image in InferenceConfig to bake the file into Docker image itself.<\/p><\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-05-14 19:28:31.663 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":"2020-05-14 18:07:01.85 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"forecast package versions different result",
        "Question_body":"<p>I am using R forecast package auto.arima() function, testing it against a predictable sine wave time series. When I run the R code on local machine in R studio, I get a significantly different output to running exactly the same code with the same source data as in azure ML. The only difference I can see is that azure has an older version of forecast package 5.4 whereas i have downloaded the latest version on local machine 5.9. (Interestingly the older version in azure ML correctly forecasts future values, the newer version predicts an attenuating amplitude, which is incorrect). <\/p>\n\n<p>My question then is for anyone who may know why a function's behaviour would change so significantly between package versions, which strikes me as very strange. Or am I missing something here? I am new to both R and azure ML.. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2015-04-27 22:04:46.407 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"r|azure-virtual-machine|azure-machine-learning-studio",
        "Question_view_count":212,
        "Owner_creation_date":"2015-04-27 21:54:34.327 UTC",
        "Owner_last_access_date":"2016-09-26 18:31:41.38 UTC",
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-01-04 09:51:11.853 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Use Azure ML methods like an API",
        "Question_body":"<p>Is that possible to use machine learning methods from Microsoft Azure Machine Learning  as an API from my own code (without ML Studio) with possibility to calculate everything on their side?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2015-12-16 19:26:56.51 UTC",
        "Question_favorite_count":1.0,
        "Question_score":1,
        "Question_tags":"frameworks|rapidminer|azure-machine-learning-studio",
        "Question_view_count":180,
        "Owner_creation_date":"2012-05-05 14:23:44.22 UTC",
        "Owner_last_access_date":"2022-09-22 08:49:42.56 UTC",
        "Owner_location":null,
        "Owner_reputation":834,
        "Owner_up_votes":159,
        "Owner_down_votes":2,
        "Owner_views":122,
        "Answer_body":"<p>You can <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-publish-a-machine-learning-web-service\/\" rel=\"nofollow\">publish<\/a> an experiment (machine learning functions you hooked together in Azure ML Studio) as an API. When you call that API in your custom code you give it your data and all the computation runs in the cloud in Azure ML. <\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_date":"2015-12-17 02:00:13.533 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Unable to access python packages installed in Azure ML",
        "Question_body":"<p>I am trying to deploy a pre-trained ML model (saved as .h5 file) to Azure ML. I have created an AKS cluster and trying to deploy the model as shown below:<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.model import Model\n\nfrom azureml.core.environment import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.model import InferenceConfig\n\nfrom azureml.core.webservice import AksWebservice, LocalWebservice\nfrom azureml.core.compute import ComputeTarget\n\nworkspace = Workspace.from_config(path=&quot;config.json&quot;)\n\nenv = Environment.get(workspace, name='AzureML-TensorFlow-1.13-GPU')\n\n# Installing packages present in my requirements file\nwith open('requirements.txt') as f:\n    dependencies = f.readlines()\ndependencies = [x.strip() for x in dependencies if '# ' not in x]\ndependencies.append(&quot;azureml-defaults&gt;=1.0.45&quot;)\n\nenv.python.conda_dependencies = CondaDependencies.create(conda_packages=dependencies)\n\n# Including the source folder so that all helper scripts are included in my deployment\ninference_config = InferenceConfig(entry_script='app.py', environment=env, source_directory='.\/ProcessImage')\n\naks_target = ComputeTarget(workspace=workspace, name='sketch-ppt-vm')\n\n# Deployment with suitable config\ndeployment_config = AksWebservice.deploy_configuration(cpu_cores=4, memory_gb=32)\nmodel = Model(workspace, 'sketch-inference')\nservice = Model.deploy(workspace, &quot;process-sketch-dev&quot;, [model], inference_config, deployment_config, deployment_target=aks_target, overwrite=True)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n<p>My main entry script requires some additional helper scripts, which I include by mentioning the source folder in my inference config.<\/p>\n<p>I was expecting that the helper scripts I add should be able to access the packages installed while setting up the environment during deployment, but I get ModuleNotFoundError.<\/p>\n<p>Here is the error output, along with the a couple of environment variables I printed while executing entry script:<\/p>\n<pre><code>    AZUREML_MODEL_DIR ----  azureml-models\/sketch-inference\/1\n    PYTHONPATH ----  \/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages:\/var\/azureml-server:\n    PATH ----  \/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/bin:\/opt\/miniconda\/bin:\/usr\/local\/nvidia\/bin:\/usr\/local\/cuda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin:\/opt\/intel\/compilers_and_libraries\/linux\/mpi\/bin64\n    Exception in worker process\n    Traceback (most recent call last):\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n        worker.init_process()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 129, in init_process\n        self.load_wsgi()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 138, in load_wsgi\n        self.wsgi = self.app.wsgi()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n        self.callable = self.load()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 52, in load\n        return self.load_wsgiapp()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 41, in load_wsgiapp\n        return util.import_app(self.app_uri)\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/util.py&quot;, line 350, in import_app\n        __import__(module)\n    File &quot;\/var\/azureml-server\/wsgi.py&quot;, line 1, in &lt;module&gt;\n        import create_app\n    File &quot;\/var\/azureml-server\/create_app.py&quot;, line 3, in &lt;module&gt;\n        from app import main\n    File &quot;\/var\/azureml-server\/app.py&quot;, line 32, in &lt;module&gt;\n        from aml_blueprint import AMLBlueprint\n    File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 25, in &lt;module&gt;\n        import main\n    File &quot;\/var\/azureml-app\/main.py&quot;, line 12, in &lt;module&gt;\n        driver_module_spec.loader.exec_module(driver_module)\n    File &quot;\/structure\/azureml-app\/ProcessImage\/app.py&quot;, line 16, in &lt;module&gt;\n        from ProcessImage.samples.coco.inference import run as infer\n    File &quot;\/var\/azureml-app\/ProcessImage\/samples\/coco\/inference.py&quot;, line 1, in &lt;module&gt;\n        import skimage.io\n    ModuleNotFoundError: No module named 'skimage'\n<\/code><\/pre>\n<p>The existing answers related to this aren't of much help. I believe there must be a simpler way to fix this, since AzureML specifically provides the feature to setup environment with pip\/conda packages installed either by supplying requirements.txt file or individually.<\/p>\n<p>What am I missing here? Kindly help.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-11-24 03:16:03.027 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1381,
        "Owner_creation_date":"2015-04-23 17:51:38.813 UTC",
        "Owner_last_access_date":"2022-09-23 21:23:01.117 UTC",
        "Owner_location":"Boston, MA, USA",
        "Owner_reputation":1910,
        "Owner_up_votes":85,
        "Owner_down_votes":6,
        "Owner_views":316,
        "Answer_body":"<p>So, after some trial and error, creating a fresh environment and then adding the packages solved the problem for me. I am still not clear on why this didn't work when I tried to use <a href=\"http:\/\/from%20azureml.core%20import%20Workspace%20from%20azureml.core.model%20import%20Model%20from%20azureml.core.environment%20import%20Environment,%20DEFAULT_GPU_IMAGE%20from%20azureml.core.conda_dependencies%20import%20CondaDependencies%20from%20azureml.core.model%20import%20InferenceConfig%20from%20azureml.core.webservice%20import%20AksWebservice,%20LocalWebservice%20from%20azureml.core.compute%20import%20ComputeTarget%20%20%20#%201.%20Instantiate%20the%20workspace%20workspace%20=%20Workspace.from_config(path=%22config.json%22)%20%20#%202.%20Setup%20the%20environment%20env%20=%20Environment(%27sketchenv%27)%20with%20open(%27requirements.txt%27)%20as%20f:%20#%20Fetch%20all%20dependencies%20as%20a%20list%20%20%20%20%20dependencies%20=%20f.readlines()%20dependencies%20=%20%5Bx.strip()%20for%20x%20in%20dependencies%20if%20%27#%20%27%20not%20in%20x%5D%20env.docker.base_image%20=%20DEFAULT_GPU_IMAGE%20env.python.conda_dependencies%20=%20CondaDependencies.create(conda_packages=%5B%27numpy==1.17.4%27,%20%27Cython%27%5D,%20pip_packages=dependencies)%20%20#%203.%20Inference%20Config%20inference_config%20=%20InferenceConfig(entry_script=%27app.py%27,%20environment=env,%20source_directory=%27.\/ProcessImage%27)%20%20#%204.%20Compute%20target%20(using%20existing%20cluster%20from%20the%20workspacke)%20aks_target%20=%20ComputeTarget(workspace=workspace,%20name=%27sketch-ppt-vm%27)%20%20#%205.%20Deployment%20config%20deployment_config%20=%20AksWebservice.deploy_configuration(cpu_cores=6,%20memory_gb=100)%20%20#%206.%20Model%20deployment%20model%20=%20Model(workspace,%20%27sketch-inference%27)%20#%20Registered%20model%20(which%20contains%20model%20files\/folders)%20service%20=%20Model.deploy(workspace,%20%22process-sketch-dev%22,%20%5Bmodel%5D,%20inference_config,%20deployment_config,%20deployment_target=aks_target,%20overwrite=True)%20service.wait_for_deployment(show_output%20=%20True)%20print(service.state)\" rel=\"nofollow noreferrer\">Environment.from_pip_requirements()<\/a>. A detailed answer in this regard would be interesting to read.<\/p>\n<p>My primary task was inference - object detection given an image, and we have our own model developed by our team. There are two types of imports I wanted to have:<\/p>\n<p><strong>1. Standard python packages (installed through pip)<\/strong><br \/>\nThis was solved by creating conda dependencies and add it to env object (Step 2)<\/p>\n<p><strong>2. Methods\/vars from helper scripts<\/strong> (if you have pre\/post processing to be done during model inference):<br \/>\nThis was done by mentioning <code>source_directory<\/code> in InferenceConfig (step 3)<\/p>\n<p>Here is my updated script which combines Environment creation, Inference and Deployment configs and using existing compute in the workspace (created through portal).<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.environment import Environment, DEFAULT_GPU_IMAGE\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.webservice import AksWebservice, LocalWebservice\nfrom azureml.core.compute import ComputeTarget\n\n\n# 1. Instantiate the workspace\nworkspace = Workspace.from_config(path=&quot;config.json&quot;)\n\n# 2. Setup the environment\nenv = Environment('sketchenv')\nwith open('requirements.txt') as f: # Fetch all dependencies as a list\n    dependencies = f.readlines()\ndependencies = [x.strip() for x in dependencies if '# ' not in x]\nenv.docker.base_image = DEFAULT_GPU_IMAGE\nenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['numpy==1.17.4', 'Cython'], pip_packages=dependencies)\n\n# 3. Inference Config\ninference_config = InferenceConfig(entry_script='app.py', environment=env, source_directory='.\/ProcessImage')\n\n# 4. Compute target (using existing cluster from the workspacke)\naks_target = ComputeTarget(workspace=workspace, name='sketch-ppt-vm')\n\n# 5. Deployment config\ndeployment_config = AksWebservice.deploy_configuration(cpu_cores=6, memory_gb=100)\n\n# 6. Model deployment\nmodel = Model(workspace, 'sketch-inference') # Registered model (which contains model files\/folders)\nservice = Model.deploy(workspace, &quot;process-sketch-dev&quot;, [model], inference_config, deployment_config, deployment_target=aks_target, overwrite=True)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n<hr \/>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-11-24 20:27:00.653 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"deploy model and expose model as web service via azure machine learning + azuremlsdk in R",
        "Question_body":"<p>I am trying to follow <a href=\"https:\/\/azure.github.io\/azureml-sdk-for-r\/articles\/train-and-deploy-first-model.html\" rel=\"nofollow noreferrer\">this post<\/a> to deploy a &quot;model&quot; in Azure.<\/p>\n<p>A code snipet is as follows and the model, which is simply a function adding 2 numbers, seems to register fine. I don't even use the model to isolate the problem after 1000s of attempts as this scoring code shows:<\/p>\n<pre><code>library(jsonlite)\n\ninit &lt;- function()\n{\n  message(&quot;hello world&quot;)\n  \n  function(data)\n  {\n    vars &lt;- as.data.frame(fromJSON(data))\n    prediction &lt;- 2\n    toJSON(prediction)\n  }\n}\n<\/code><\/pre>\n<p>Should be fine shouldn't it? Any way I run this code snippet:<\/p>\n<pre><code>r_env &lt;- r_environment(name = &quot;basic_env&quot;)\ninference_config &lt;- inference_config(\n  entry_script = &quot;score.R&quot;,\n  source_directory = &quot;.&quot;,\n  environment = r_env)\n\naci_config &lt;- aci_webservice_deployment_config(cpu_cores = 1, memory_gb = 0.5)\n\naci_service &lt;- deploy_model(ws, \n                            'xxxxx', \n                            list(model), \n                            inference_config, \n                            aci_config)\n\nwait_for_deployment(aci_service, show_output = TRUE)\n<\/code><\/pre>\n<p>Which produces this (after a looooong time):<\/p>\n<pre><code>Running.....................................................................\nFailed\nService deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 14c35064-7ff4-46aa-9bfa-ab8a63218a2c\nMore information can be found using '.get_logs()'\nError:\n{\n  &quot;code&quot;: &quot;AciDeploymentFailed&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;Aci Deployment failed with exception: Error in entry script, RuntimeError: Error in file(filename, \\&quot;r\\&quot;, encoding = encoding) : , please run print(service.get_logs()) to get details.&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;CrashLoopBackOff&quot;,\n      &quot;message&quot;: &quot;Error in entry script, RuntimeError: Error in file(filename, \\&quot;r\\&quot;, encoding = encoding) : , please run print(service.get_logs()) to get details.&quot;\n    }\n  ]\n}\n<\/code><\/pre>\n<p>It does not tell me much. Not sure how to debug this further? How can I run this:<\/p>\n<pre><code>print(service.get_logs())\n<\/code><\/pre>\n<p>and where please? Guess this is a Python artifact? Any other input very much welcome.<\/p>\n<p>PS:<\/p>\n<p>At this point in time, I have my suspicion that the above R entry file definition is not what is expected these days. Looking at the Python equivalent taken from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli\" rel=\"nofollow noreferrer\">here<\/a>:<\/p>\n<pre><code>import json\n\ndef init():\n    print(&quot;This is init&quot;)\n\ndef run(data):\n    test = json.loads(data)\n    print(f&quot;received data {test}&quot;)\n    return f&quot;test is {test}&quot;\n<\/code><\/pre>\n<p>Would something like this not be more suitable (tried it without success).<\/p>\n<pre><code>library(jsonlite)\n\ninit &lt;- function()\n{\n    message(&quot;hello world&quot;)\n}\n\ninit &lt;- function()\n{\n    return(42)\n}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-14 13:17:56.233 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"r|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":282,
        "Owner_creation_date":"2010-03-01 10:53:04.443 UTC",
        "Owner_last_access_date":"2022-09-24 18:56:19.313 UTC",
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Answer_body":"<p>Great to see people putting the R SDK through it's paces!<\/p>\n<p>The vignette you're using is obviously a great way to get started. It seems you're almost all the way through without a hitch.<\/p>\n<p>Deployment is always tricky, and I'm not expert myself. I'd point you to this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment-local?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">guide on troubleshooting deployment locally<\/a>. Similar functionality exists for the R SDK, namely: <a href=\"https:\/\/azure.github.io\/azureml-sdk-for-r\/reference\/local_webservice_deployment_config.html\" rel=\"nofollow noreferrer\"><code>local_webservice_deployment_config()<\/code><\/a>.<\/p>\n<p>So I think you change your example to this:<\/p>\n<pre class=\"lang-r prettyprint-override\"><code>deployment_config &lt;- local_webservice_deployment_config(port = 8890)\n<\/code><\/pre>\n<p>Once you know the service is working locally, the issue you're having with the ACI webservice becomes a lot easier to narrow down.<\/p>",
        "Answer_comment_count":8.0,
        "Answer_creation_date":"2021-05-14 15:53:45.123 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2021-05-14 16:02:03.54 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Studio: cannot deploy model with rpy2 as a dependency",
        "Question_body":"<p>I am trying to deploy a custom model on Azure Machine Learning Studio that needs rpy2 (Python wrapper for R) to run.  So, I created the following yml file (myenv.yml), specifying the required dependency (besides other stuff),<\/p>\n<pre><code># Conda environment specification. The dependencies defined in this file will\n# be automatically provisioned for runs with userManagedDependencies=False.\n\n# Details about the Conda environment file format:\n# https:\/\/conda.io\/docs\/user-guide\/tasks\/manage-environments.html#create-env-file-manually\n\nname: project_environment\n\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2    \n- pip:\n  - azureml-train-automl-runtime==1.8.0.post1\n  - inference-schema\n  - azureml-explain-model==1.8.0\n  - azureml-defaults==1.8.0\n  - rpy2==3.3.5\n- dill==0.3.2\n- numpy&gt;=1.16.0,&lt;=1.16.2\n- pandas&gt;=0.21.0,&lt;=0.23.4\n- scikit-learn&gt;=0.19.0,&lt;=0.20.3\n- py-xgboost&lt;=0.90\n- fbprophet==0.5\n- psutil&gt;=5.2.2,&lt;6.0.0\n\nchannels:\n- anaconda\n- conda-forge\n<\/code><\/pre>\n<p>and then ran the following script (based on <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment<\/a>):<\/p>\n<pre><code>from azureml.core.environment import Environment\nfrom azureml.core.model import Model, InferenceConfig\nfrom azureml.core import Workspace\nfrom azureml.core.webservice import AciWebservice\n\nws = Workspace.from_config()\nmodel = Model(workspace = ws, name = 'test-rpy2') # this is my (registered) model that needs rpy2 to run\n\n# create inference configuration based on the requirements defined in the YAML\nmyenv = Environment.from_conda_specification(name = &quot;myenv&quot;, file_path = &quot;myenv.yml&quot;)\n\ninference_config = InferenceConfig(entry_script = &quot;score.py&quot;, environment = myenv) # score.py: my custom scoring file where rpy2 is imported\n\n# deploy the model\naci_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n\nservice = Model.deploy(workspace         = ws,\n                       name              = 'test-rpy2',\n                       models            = [model],\n                       inference_config  = inference_config,\n                       deployment_config = aci_config)\n\nservice.wait_for_deployment(show_output=True)\n<\/code><\/pre>\n<p>However, I get the following error:<\/p>\n<pre><code>    Error: rpy2 in API mode cannot be built without R in the PATH or R_HOME defined. Correct this or force ABI mode-only by defining the environment variable RPY2_CFFI_MODE=ABI\n<\/code><\/pre>\n<p>I expected that the issue would be fixed by adding the line<\/p>\n<pre><code>myenv.environment_variables['RPY2_CFFI_MODE'] = 'ABI'\n<\/code><\/pre>\n<p>right after the definition of myenv, but the exact same error shows up again.<\/p>\n<p>Does anyone have any idea on how to make it work?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-30 08:58:32.337 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"python|anaconda|rpy2|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1275,
        "Owner_creation_date":"2017-08-11 12:35:17.96 UTC",
        "Owner_last_access_date":"2021-01-27 09:52:25.2 UTC",
        "Owner_location":"Milano, MI, Italia",
        "Owner_reputation":132,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2020-07-30 23:22:43.577 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"R code on Azure Machine Learning is slow compared to local execution time",
        "Question_body":"<p>Getting straight to it:\nWhy is my R code doing fine on my local CPU (under one minute), but tens of times slower on Azure Machine Learning, using one R script block (over 18 minutes)?<\/p>\n\n<p>I assume that it has to do with the resources allocated to the experiment, but how can I be sure? Can I obtain details about the resource allocated to the R script block from somwehere hidden in the Azure-ML Studio machinery?<\/p>\n\n<p>Thank you, Flo<\/p>\n\n<p>Later Edit:\nAs it often happens, I did finally find some information, which still doesn't solve my issue. According to <a href=\"https:\/\/msdn.microsoft.com\/library\/en-us\/Dn905952.aspx#Technical%20Notes\" rel=\"nofollow noreferrer\">https:\/\/msdn.microsoft.com\/library\/en-us\/Dn905952.aspx#Technical%20Notes<\/a> \"User-specified R code is run by a 64-bit R interpreter that runs in Azure using an A8 virtual machine with 56 GB of RAM.\"<\/p>\n\n<p>This is more than my local machine has, the R code is still much slower on the Azure-ML studio.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_date":"2016-11-28 12:27:39.453 UTC",
        "Question_favorite_count":1.0,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":733,
        "Owner_creation_date":"2016-04-01 09:30:32.96 UTC",
        "Owner_last_access_date":"2017-12-05 09:55:37.783 UTC",
        "Owner_location":"Vienna, Austria",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":"<p>Consider using rbenchmark or other benchmarking tools to get an idea of the runtime and complexity of your code. In general for loops tend to be slow.<\/p>\n\n<p>It's very possible that the server has less resources available (ram, cpu) or that you have to wait in a que before you get served. Without any more code it's hard to comment further on this issue.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2016-11-28 13:27:37.187 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":"2016-11-28 13:03:14.65 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"The amlignore file doesn't reduce the size of snapshot",
        "Question_body":"<p>To overcome <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-save-write-experiment-files#storage-limits-of-experiment-snapshots\" rel=\"nofollow noreferrer\">300MB snapshot size limit<\/a> I created an .amlignore file in the root of my repository:<\/p>\n\n<pre><code>\/*\n!\/root\n<\/code><\/pre>\n\n<p>The intention is to exclude everything except <code>\/root<\/code> directory where all python code is. The size of the <code>root<\/code> directory is less than 1MB, still I get an error of exceeding snapshot limit size of 300MB. What am I doing wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-11 17:23:39.87 UTC",
        "Question_favorite_count":null,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":522,
        "Owner_creation_date":"2018-02-15 14:47:43.68 UTC",
        "Owner_last_access_date":"2022-08-24 16:53:36.967 UTC",
        "Owner_location":null,
        "Owner_reputation":95,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Answer_body":"<p>This is fixed in version <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/azure-machine-learning-release-notes#azure-machine-learning-sdk-for-python-v1074\" rel=\"nofollow noreferrer\">1.0.74 of azureml-sdk<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-11-16 19:31:39.567 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"AzureML: Dataset Profile fails when parquet file is empty",
        "Question_body":"<p>I have created a Tabular Dataset using Azure ML python API. Data under question is a bunch of parquet files (~10K parquet files each of size of 330 KB) residing in Azure Data Lake Gen 2 spread across multiple partitions. When I trigger &quot;Generate Profile&quot; operation for the dataset, it throws following error while handling empty parquet file and then the profile generation stops.<\/p>\n<pre><code>User program failed with ExecutionError: \nError Code: ScriptExecution.StreamAccess.Validation\nValidation Error Code: NotSupported\nValidation Target: ParquetFile\nFailed Step: 77866d0a-8243-4d3d-8bc6-599d466488dd\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  Failed to read Parquet file at: &lt;my_blob_path&gt;\/20211217.parquet\n    Current parquet file is not supported.\n      Exception of type 'Thrift.Protocol.TProtocolException' was thrown.\n| session_id=6be4db0b-bdc1-4dd6-b8a6-6e9466f7bc54\n\n<\/code><\/pre>\n<p>By empty parquet file, I mean that the if I read the individual parquet file using pandas (<code>pd.read_parquet<\/code>), it results in an empty DF (df.empty == True).<\/p>\n<p>Any suggestion to avoid this error will be appreciated.<\/p>\n<p><strong>Update<\/strong>\nThe issue has been fixed in the following version:<\/p>\n<ul>\n<li>azureml-dataprep : 3.0.1<\/li>\n<li>azureml-core :  1.40.0<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-10 10:53:07.177 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":255,
        "Owner_creation_date":"2010-07-30 15:52:19.753 UTC",
        "Owner_last_access_date":"2022-09-23 12:22:17.867 UTC",
        "Owner_location":"Bangalore, India",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Answer_body":"<p>Thanks for reporting it.\nThis is a bug in handling of the parquet files with columns but empty row set. This has been fixed already and will be included in next release.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-03-04 22:22:14.34 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":1.0,
        "Question_last_edit_date":"2022-03-30 12:31:36.673 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Executing R script from Azure function",
        "Question_body":"<p>I want to execute a R script every time an azure function is triggered. The R script executes perfectly on Azure machine learning Studio. But I am failing to execute through azure function.\nIs there any way to execute it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-02-05 10:58:02.103 UTC",
        "Question_favorite_count":null,
        "Question_score":3,
        "Question_tags":"r|azure-functions|azure-machine-learning-studio",
        "Question_view_count":640,
        "Owner_creation_date":"2016-09-29 12:55:05.707 UTC",
        "Owner_last_access_date":"2022-09-15 16:11:00.29 UTC",
        "Owner_location":null,
        "Owner_reputation":79,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":"<p>AFAIK you'll have to create your own Runtime as <code>R<\/code> isn't supported natively.<\/p>\n<p>Have you already tried <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/azure-functions\/functions-create-function-linux-custom-image?tabs=bash%2Cportal&amp;pivots=programming-language-other\" rel=\"nofollow noreferrer\">&quot;Create a function on Linux using a custom container&quot;<\/a>? Interestingly they have given <code>R<\/code> as the example of custom runtime, so hopefully that answers your question.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-02-05 22:37:51.217 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":2.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to import a library \u201crmarkdown\u201d using the AzureML package?",
        "Question_body":"<p>I'm trying to import <code>rmarkdown<\/code> into <code>AzureML<\/code> for one of my projects.<\/p>\n\n<p>This is the function I'm trying to upload into <code>AzureML<\/code>. <\/p>\n\n<p>The <code>R.version<\/code> check is because the function is evaluated in the local environment before uploaded to <code>AzureML<\/code>. <\/p>\n\n<pre><code>fun &lt;- function (b5) {\n    if (R.version[[\"os\"]]==\"mingw32\" &amp;&amp; ! require(talection)) {\n        install.packages(\n            \"src\/rmarkdown_0.9.6.zip\",\n            lib=\".\",\n            type=\"win.binary\",\n            repos=NULL,\n            verbose=TRUE)\n    }\n    ans &lt;- as.data.frame(c(\"Finished\"))\n}\n<\/code><\/pre>\n\n<p><code>rmarkdown_0.9.6.zip<\/code> is in a <code>miniCRAN<\/code> library. <\/p>\n\n<p>The following code, is the code that uploads <code>rmarkwodn<\/code> to <code>Azure ML<\/code>. Please note the line <code>packages<\/code>, which tells R to upload <code>rmarkdown<\/code> to <code>Azure ML<\/code>. <\/p>\n\n<pre><code>test &lt;- as.data.frame(\n    cbind(\n        c(0.0,  0.3,  0.0,  0.0,  0.0),\n        c(0.0,  0.0,  0.0, -0.4,  0.0),\n        c(0,      0,    0,    0,    0))\n)\n\nep &lt;- publishWebService (\n  ws,\n  fun = fun,\n  name = \"Talection-fun\",\n  inputSchema = test,\n  outputSchema = list(\n    ans = \"character\"\n  ),\n  packages = c(\"rmarkdown\")\n)\n\nprint(consume(ep,test))\n<\/code><\/pre>\n\n<p>The code returns <\/p>\n\n<blockquote>\n  <p>Request failed with status 400. Waiting 12.7 seconds before retry<br>\n  Request failed with status 400. Waiting 33.6 seconds before retry<br>\n  Request failed with status 400. Waiting 76.7 seconds before retry<br>\n  Request failed with status 400. Waiting 234.3 seconds before retry<br>\n  Request failed with status 400. Waiting 123.1 seconds before retry<br>\n  Error: AzureML returns error code:<br>\n  HTTP status code : 400<br>\n  AzureML error code  : LibraryExecutionError  <\/p>\n<\/blockquote>\n\n<p>Any and all relevant suggestions welcome. Thank you.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2016-05-31 15:17:27.62 UTC",
        "Question_favorite_count":1.0,
        "Question_score":3,
        "Question_tags":"r|r-markdown|azure-machine-learning-studio",
        "Question_view_count":147,
        "Owner_creation_date":"2012-11-11 09:14:39.067 UTC",
        "Owner_last_access_date":"2022-06-13 17:53:53.847 UTC",
        "Owner_location":"Levanger, Norway",
        "Owner_reputation":445,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":63,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2016-11-03 12:19:31.603 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning compute instance : Static IP address?",
        "Question_body":"<p>I have a SQL Server database which is accessible only by whitelisting IP addresses. I would like to use an Azure Machine Learning compute instance to run some python code to query the database using the <code>pyodbc<\/code> library.<\/p>\n<p>Does a compute instance in Azure Machine Learning have a static IP address ?\nIf yes, can I safely provide this address to be whitelisted or is there a risk that it might change through time ?<\/p>\n<p>Thank you very much.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-24 09:10:26.183 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"python|azure|machine-learning|static-ip-address|azure-machine-learning-service",
        "Question_view_count":139,
        "Owner_creation_date":"2020-04-10 11:23:52.39 UTC",
        "Owner_last_access_date":"2022-08-12 18:19:53.33 UTC",
        "Owner_location":null,
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure ML web service times out",
        "Question_body":"<p>I have created a simple experiment in Azure ML and trigger it with an http client. In Azure ML workspace, everything works ok when executed. However, the experiment times out and fails when I trigger the experiment using an http client. Setting a timeout value for the http client does not seem to work.<\/p>\n\n<p>Is there any way we can set this timeout value so that the experiment does not fail?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_date":"2015-06-30 05:57:37.76 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"c#|azure|azure-machine-learning-studio",
        "Question_view_count":1681,
        "Owner_creation_date":"2011-08-16 10:01:08.533 UTC",
        "Owner_last_access_date":"2022-09-14 10:48:09.797 UTC",
        "Owner_location":null,
        "Owner_reputation":209,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":42,
        "Answer_body":"<p>Looks like it isn't possible to set this timeout based on <a href=\"https:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/6472562-configurable-timeout-for-experiments-and-web-servi\" rel=\"nofollow noreferrer\">a feature request that is still marked as \"planned\" as of 4\/1\/2018<\/a>.<\/p>\n\n<p>The recommendation from <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/sqlserver\/en-US\/cb4ee96d-c2ca-4c65-b02f-0ccb26181f7f\/timeout-in-web-service?forum=MachineLearning\" rel=\"nofollow noreferrer\">MSDN forums from 2017<\/a> is to use the Batch Execution Service, which starts the machine learning experiment and then asynchronously asks whether it's done.<\/p>\n\n<p>Here's a code snippet from the Azure ML Web Services Management Sample Code (all comments are from their sample code):<\/p>\n\n<pre><code>        using (HttpClient client = new HttpClient())\n        {\n            var request = new BatchExecutionRequest()\n            {\n\n                Outputs = new Dictionary&lt;string, AzureBlobDataReference&gt; () {\n                    {\n                        \"output\",\n                        new AzureBlobDataReference()\n                        {\n                            ConnectionString = storageConnectionString,\n                            RelativeLocation = string.Format(\"{0}\/outputresults.file_extension\", StorageContainerName) \/*Replace this with the location you would like to use for your output file, and valid file extension (usually .csv for scoring results, or .ilearner for trained models)*\/\n                        }\n                    },\n                },    \n\n                GlobalParameters = new Dictionary&lt;string, string&gt;() {\n                }\n            };\n\n            client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", apiKey);\n\n            \/\/ WARNING: The 'await' statement below can result in a deadlock\n            \/\/ if you are calling this code from the UI thread of an ASP.Net application.\n            \/\/ One way to address this would be to call ConfigureAwait(false)\n            \/\/ so that the execution does not attempt to resume on the original context.\n            \/\/ For instance, replace code such as:\n            \/\/      result = await DoSomeTask()\n            \/\/ with the following:\n            \/\/      result = await DoSomeTask().ConfigureAwait(false)\n\n            Console.WriteLine(\"Submitting the job...\");\n\n            \/\/ submit the job\n            var response = await client.PostAsJsonAsync(BaseUrl + \"?api-version=2.0\", request);\n\n            if (!response.IsSuccessStatusCode)\n            {\n                await WriteFailedResponse(response);\n                return;\n            }\n\n            string jobId = await response.Content.ReadAsAsync&lt;string&gt;();\n            Console.WriteLine(string.Format(\"Job ID: {0}\", jobId));\n\n            \/\/ start the job\n            Console.WriteLine(\"Starting the job...\");\n            response = await client.PostAsync(BaseUrl + \"\/\" + jobId + \"\/start?api-version=2.0\", null);\n            if (!response.IsSuccessStatusCode)\n            {\n                await WriteFailedResponse(response);\n                return;\n            }\n\n            string jobLocation = BaseUrl + \"\/\" + jobId + \"?api-version=2.0\";\n            Stopwatch watch = Stopwatch.StartNew();\n            bool done = false;\n            while (!done)\n            {\n                Console.WriteLine(\"Checking the job status...\");\n                response = await client.GetAsync(jobLocation);\n                if (!response.IsSuccessStatusCode)\n                {\n                    await WriteFailedResponse(response);\n                    return;\n                }\n\n                BatchScoreStatus status = await response.Content.ReadAsAsync&lt;BatchScoreStatus&gt;();\n                if (watch.ElapsedMilliseconds &gt; TimeOutInMilliseconds)\n                {\n                    done = true;\n                    Console.WriteLine(string.Format(\"Timed out. Deleting job {0} ...\", jobId));\n                    await client.DeleteAsync(jobLocation);\n                }\n                switch (status.StatusCode) {\n                    case BatchScoreStatusCode.NotStarted:\n                        Console.WriteLine(string.Format(\"Job {0} not yet started...\", jobId));\n                        break;\n                    case BatchScoreStatusCode.Running:\n                        Console.WriteLine(string.Format(\"Job {0} running...\", jobId));\n                        break;\n                    case BatchScoreStatusCode.Failed:\n                        Console.WriteLine(string.Format(\"Job {0} failed!\", jobId));\n                        Console.WriteLine(string.Format(\"Error details: {0}\", status.Details));\n                        done = true;\n                        break;\n                    case BatchScoreStatusCode.Cancelled:\n                        Console.WriteLine(string.Format(\"Job {0} cancelled!\", jobId));\n                        done = true;\n                        break;\n                    case BatchScoreStatusCode.Finished:\n                        done = true;\n                        Console.WriteLine(string.Format(\"Job {0} finished!\", jobId));\n                        ProcessResults(status);\n                        break;\n                }\n\n                if (!done) {\n                    Thread.Sleep(1000); \/\/ Wait one second\n                }\n            }\n        }\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2018-04-01 17:33:08.173 UTC",
        "Answer_last_edit_date":null,
        "Answer_score":0.0,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"create and run notebooks in azure ML studio by terraform or powershell",
        "Question_body":"<p>I am trying to automate the process of creation of ML Studio along with compute instance and notebook and to run the notebook. I have a code that creates ML studio workspace but not finding any leads on creating the notebook in it to run.<\/p>\n<pre><code># retrive current connection data\ndata &quot;azurerm_client_config&quot; &quot;current&quot; {}\n\n    # Create App Insight\n    resource &quot;azurerm_application_insights&quot; &quot;AML&quot; {\n      name                = &quot;${var.prefix}iotMLInsights&quot;\n      location            = var.resource_group_location\n      resource_group_name = var.resource_group_name\n      application_type    = &quot;web&quot;\n    }\n    \n    # Create Azure Key Vault\n    resource &quot;azurerm_key_vault&quot; &quot;AML&quot; {\n      name                = &quot;${var.prefix}iotKeyVault&quot;\n      location            = var.resource_group_location\n      resource_group_name = var.resource_group_name\n      tenant_id           = data.azurerm_client_config.current.tenant_id\n      sku_name            = &quot;premium&quot;\n    }\n    \n    # Create Azure ML Service\n    resource &quot;azurerm_machine_learning_workspace&quot; &quot;AML&quot; {\n      name                    = &quot;${var.prefix}iotMLStudio&quot;\n      location                = var.resource_group_location\n      resource_group_name     = var.resource_group_name\n      application_insights_id = azurerm_application_insights.AML.id\n      key_vault_id            = azurerm_key_vault.AML.id\n      storage_account_id      = var.storage_account_id\n    \n      identity {\n        type = &quot;SystemAssigned&quot;\n      }\n    }\n<\/code><\/pre>\n<p>need some suggestions to take this forward, either in terraform or powershell.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-20 17:16:01.113 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"powershell|terraform|azure-machine-learning-service|rnotebook",
        "Question_view_count":50,
        "Owner_creation_date":"2022-07-20 10:15:16.01 UTC",
        "Owner_last_access_date":"2022-09-13 11:42:26.987 UTC",
        "Owner_location":null,
        "Owner_reputation":17,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":28,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"Azure Machine Learning Endpoint SQL Access fails, works in experiement",
        "Question_body":"<p>I've created a classification endpoint using Azure ML, the input for which is a database query to retrieve the database row to classify.<\/p>\n\n<p>When I run my experiment in the Machine Learning Studio, it works and connects properly to my database. When I submit the same query as a web service parameter on the import data module, I get the following error: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Dkf3H.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Dkf3H.jpg\" alt=\"enter image description here\"><\/a>\nIgnoring the dangers of an SQL query as input, why am I getting this? Shouldn't it work the same?<\/p>\n\n<p>Sidenote: I've used an SQL query on my training endpoint in the exact same way on the same database, and this didn't cause any problems.<\/p>\n\n<p>UPDATE: It seems as if this is only a problem when I create a new endpoint for a service. If I use the default endpoint it does indeed work, but any new endpoints do not.<\/p>\n\n<p>UPDATE 2: It also works when I submit my request as a batch run. If I use Request-Response, it fails.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2017-01-11 15:41:57.233 UTC",
        "Question_favorite_count":null,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":113,
        "Owner_creation_date":"2012-05-10 11:17:41.41 UTC",
        "Owner_last_access_date":"2022-03-14 11:39:15.463 UTC",
        "Owner_location":null,
        "Owner_reputation":627,
        "Owner_up_votes":40,
        "Owner_down_votes":4,
        "Owner_views":61,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":"2017-01-12 09:59:43.627 UTC",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"How to select a subset of Avro files from Azure Data Lake Gen2 by data content",
        "Question_body":"<p>I have lots of Avro files in an Azure Data Lake Gen2 storage sent by an Event Hub service with capture enabled. These Avro files contain data from different sensors and engines. The structure of the directory is organized in folders with the following path format (typical of Azure Blobs): <\/p>\n\n<p><code>namespace\/eventhub\/partition\/year\/month\/day\/hour\/minute\/file.avro<\/code><\/p>\n\n<p>I need to access to some of these files, in order to get data to 1) pre-process and 2) train or re-train a machine learning model. I'd like to know what procedure could I follow to download or mount just the files containing data of a particular engine and\/or sensor, given that not data from all of them are present in all Avro files. Let's assume I'm interested just in files containing data from:<\/p>\n\n<pre><code>Engine = engine_ID_4012\nSensor = sensor_engine_4012_ID_0114\n<\/code><\/pre>\n\n<p>I'm aware that Spark offers some advantages working with Avro files, so I could consider to carry out this task using Databricks. Otherwise the option is Azure Machine Learning service, but maybe there are other possiblities, for instance a combination. The goal is to speed up the data ingestion process, avoiding to read files with no needed data.<\/p>\n\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-10 16:45:07.233 UTC",
        "Question_favorite_count":1.0,
        "Question_score":0,
        "Question_tags":"avro|azure-data-lake|azure-eventhub|azure-databricks|azure-machine-learning-service",
        "Question_view_count":248,
        "Owner_creation_date":"2018-09-07 11:08:23.563 UTC",
        "Owner_last_access_date":"2022-09-20 13:21:15.58 UTC",
        "Owner_location":null,
        "Owner_reputation":150,
        "Owner_up_votes":64,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_title":"No `read_json_lines_files()` function for `OutputFileDatasetConfig`",
        "Question_body":"<p>I have a pipeline step which produces image labels like the one exported from a <code>Data Labeling<\/code> project which is a <code>jsonl<\/code> file.<\/p>\n<p>This step produces the <code>jsonl<\/code> label file in a <code>OutputFileDatasetConfig<\/code> and then I think I would do<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>output_file_dataset_config.read_json_lines_files().register_on_complete(&quot;foo&quot;)\n<\/code><\/pre>\n<p>but this magical <code>read_json_lines_files()<\/code> function does not exists.<\/p>\n<p>How can I achieve the same behavior with then currently available API?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-09-15 15:25:52.63 UTC",
        "Question_favorite_count":null,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":83,
        "Owner_creation_date":"2012-01-26 14:27:40.553 UTC",
        "Owner_last_access_date":"2022-09-24 16:26:41.58 UTC",
        "Owner_location":null,
        "Owner_reputation":802,
        "Owner_up_votes":288,
        "Owner_down_votes":0,
        "Owner_views":91,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_last_edit_date":null,
        "Answer_score":null,
        "Question_last_edit_date":null,
        "Question_exclusive_tag":"Azure Machine Learning"
    }
]