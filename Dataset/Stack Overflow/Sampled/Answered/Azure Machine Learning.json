[
    {
        "Question_id":52278613,
        "Question_title":"Add custom packages to Azure Machine Learing Studio",
        "Question_body":"<p>I need to use the function tsCV on azure machine learning studio to evaluate models of forecast, but i got the error <\/p>\n\n<pre><code>could not find function \"tsCV\n<\/code><\/pre>\n\n<p>I'm trying to update the forecast package, but no package are loaded.\nI followed this tutorial\n<a href=\"http:\/\/blog.revolutionanalytics.com\/2015\/10\/using-minicran-in-azure-ml.html\" rel=\"noreferrer\">http:\/\/blog.revolutionanalytics.com\/2015\/10\/using-minicran-in-azure-ml.html<\/a>\nand \n<a href=\"https:\/\/blog.tallan.com\/2016\/12\/27\/adding-r-packages-in-azure-ml\/\" rel=\"noreferrer\">https:\/\/blog.tallan.com\/2016\/12\/27\/adding-r-packages-in-azure-ml\/<\/a>\nbut i dont get the same result.\nNo packages are load.<\/p>\n\n<p>I need an example of a package with R code that works o Azure ML or an update of forecast package to use tsCV function.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1536677172073,
        "Question_score":3,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":404,
        "Owner_creation_time":1515518171123,
        "Owner_last_access_time":1657119408507,
        "Owner_location":null,
        "Owner_reputation":1108,
        "Owner_up_votes":33,
        "Owner_down_votes":2,
        "Owner_views":183,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I have installed the latest version of the forecast package and here are the steps I followed during the installation. <\/p>\n\n<ol>\n<li>Download latest version of CRAN<\/li>\n<li>Be sure that tsCV is working locally<\/li>\n<li>Zip all the dependencies + forecast package<\/li>\n<li>Zip all the generated zips together and upload it to the AMLStudio<\/li>\n<li>Run the following code:<\/li>\n<\/ol>\n\n<blockquote>\n<pre><code>install.packages(\"src\/glue.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/stringi.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/assertthat.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/fansi.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/utf8.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/stringr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/labeling.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/munsell.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/R6.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/RColorBrewer.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/cli.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/crayon.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/pillar.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/xts.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/TTR.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/curl.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/digest.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/gtable.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/lazyeval.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/plyr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/reshape2.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/rlang.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/scales.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/tibble.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/viridisLite.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/withr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/quadprog.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/quantmod.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/colorspace.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/fracdiff.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/ggplot2.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/lmtest.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/magrittr.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/Rcpp.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/timeDate.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/tseries.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/urca.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/uroot.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/zoo.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/RcppArmadillo.zip\", lib = \".\", repos = NULL, verbose = TRUE)\ninstall.packages(\"src\/forecast.zip\", lib = \".\", repos = NULL, verbose = TRUE)\n\nlibrary(forecast, lib.loc=\".\", verbose=TRUE)\nfar2 &lt;- function(x, h){forecast(Arima(x, order=c(2,0,0)), h=h)}\ne &lt;- tsCV(lynx, far2, h=1)\n<\/code><\/pre>\n<\/blockquote>\n\n<p><a href=\"https:\/\/drive.google.com\/open?id=10Bj0RGCmRFrRECLQrVc26nbx3T-bNSL6\" rel=\"nofollow noreferrer\">Here is the zip I have generated:<\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/bbowH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bbowH.png\" alt=\"My experiment\"><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1537192338793,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52278613",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62457880,
        "Question_title":"AML - Web service TimeoutError",
        "Question_body":"<p>We created a webservice endpoint and tested it with the following code, and also with POSTMAN.<\/p>\n\n<p>We deployed the service to an AKS in the same resource group and subscription as the AML resource.<\/p>\n\n<p><strong>UPDATE: the attached AKS had a custom networking configuration and rejected external connections.<\/strong><\/p>\n\n<pre><code>import numpy\nimport os, json, datetime, sys\nfrom operator import attrgetter\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.image import Image\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.authentication import AzureCliAuthentication\n\ncli_auth = AzureCliAuthentication()\n# Get workspace\nws = Workspace.from_config(auth=cli_auth)\n\n# Get the AKS Details\ntry:\n    with open(\"..\/aml_config\/aks_webservice.json\") as f:\n        config = json.load(f)\nexcept:\n    print(\"No new model, thus no deployment on AKS\")\n    # raise Exception('No new model to register as production model perform better')\n    sys.exit(0)\n\nservice_name = config[\"aks_service_name\"]\n# Get the hosted web service\nservice = Webservice(workspace=ws, name=service_name)\n\n# Input for Model with all features\ninput_j = [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]]\nprint(input_j)\ntest_sample = json.dumps({\"data\": input_j})\ntest_sample = bytes(test_sample, encoding=\"utf8\")\ntry:\n    prediction = service.run(input_data=test_sample)\n    print(prediction)\nexcept Exception as e:\n    result = str(e)\n    print(result)\n    raise Exception(\"AKS service is not working as expected\")\n<\/code><\/pre>\n\n<p>In AML Studio, the deployment state is \"Healthy\".<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/RTB10.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/RTB10.png\" alt=\"Endpoint attributes\"><\/a><\/p>\n\n<p>We get the following error when testing:<\/p>\n\n<pre><code>Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'\n<\/code><\/pre>\n\n<p><strong>Log just after deploying the AKS Webservice <a href=\"http:\/\/t.ly\/t79b\" rel=\"nofollow noreferrer\">here<\/a>.<\/strong><\/p>\n\n<p><strong>Log after running the test script <a href=\"http:\/\/t.ly\/79k5\" rel=\"nofollow noreferrer\">here<\/a>.<\/strong><\/p>\n\n<p>How can we know what is causing this problem and fix it?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1592508291480,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio|azure-aks|azure-machine-learning-service",
        "Question_view_count":332,
        "Owner_creation_time":1585590244877,
        "Owner_last_access_time":1593367986573,
        "Owner_location":null,
        "Owner_reputation":55,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":1592590061567,
        "Answer_body":"<p>We checked the AKS networking configuration and realized it has an Azure CNI profile.<\/p>\n\n<p>In order to test the webservice we need to do it from inside the created virtual network.\nIt worked well!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1592590202853,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62457880",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32451243,
        "Question_title":"How to load images faster from Azure Blob?",
        "Question_body":"<p>I've been trying to upload some images to azure blob and then using <strong>ImageReader<\/strong> in <strong>Azure ML studio<\/strong> to read them from the blob. The problem is that ImageReader takes a lot of time to load images and I need it in real time. <br>\nI also tried making a <strong>csv<\/strong> of <strong>4 images (four rows)<\/strong> containing 800x600 pixels as columns <strong>(500,000 cols. approx)<\/strong> and tried simple <strong>Reader<\/strong>. Reader took <strong>31 mins<\/strong> to read the file from the blob.<br>\nI want to know the alternate methods of loading and reading images in Azure ML studio. If anyone know any other method or can share a helpful and relevant link.<br>\nPlease share if i can speed up ImageReader by any means.\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1441695780200,
        "Question_score":1,
        "Question_tags":"opencv|azure|azure-machine-learning-studio",
        "Question_view_count":803,
        "Owner_creation_time":1387426285030,
        "Owner_last_access_time":1659463166403,
        "Owner_location":"Lahore, Pakistan",
        "Owner_reputation":2128,
        "Owner_up_votes":128,
        "Owner_down_votes":8,
        "Owner_views":211,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Look at the Azure CDN <a href=\"http:\/\/azure.microsoft.com\/en-us\/services\/cdn\/\" rel=\"nofollow\">http:\/\/azure.microsoft.com\/en-us\/services\/cdn\/<\/a> , after which the blobs will get an alternative url. My blob downloads became about 4 times faster after switching.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1441739836497,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32451243",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67015185,
        "Question_title":"How can I match my local azure automl python sdk version to the remote version?",
        "Question_body":"<p>I'm using the azure automl python sdk to download and save a model then reload it. I get the following error:<\/p>\n<pre><code>anaconda3\\envs\\automl_21\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n<\/code><\/pre>\n<p>How can I ensure that the versions match?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1617943623520,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":62,
        "Owner_creation_time":1324351066393,
        "Owner_last_access_time":1663204677817,
        "Owner_location":"Christchurch, New Zealand",
        "Owner_reputation":1306,
        "Owner_up_votes":49,
        "Owner_down_votes":5,
        "Owner_views":81,
        "Question_last_edit_time":null,
        "Answer_body":"<p>My Microsoft contact says -<\/p>\n<p>&quot;For this, their best  bet is probably to see what the training env was pinned to and install those same pins. They can get that env by running child_run.get_environment() and then pip install all the pkgs listed in there with the pins listed there.&quot;<\/p>\n<p>A useful code snippet.<\/p>\n<pre><code>for run in experiment.get_runs():\n    tags_dictionary = run.get_tags()\n    best_run = AutoMLRun(experiment, tags_dictionary['automl_best_child_run_id'])\n    env = best_run.get_environment()\n    print(env.python.conda_dependencies.serialize_to_string())\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1618176409273,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1618178182617,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67015185",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71649163,
        "Question_title":"Can azureml pass variables from one step to another?",
        "Question_body":"<p>I have a requirement to use azure machine learning to develop a pipeline. In this pipeline we don't pass data as inputs\/outputs but variables (for example a list or an int). I have looked on the Microsoft documentation but could not seem to find something fitting my case. Also tried to use the PipelineData class but could not retrieve my variables.<\/p>\n<ol>\n<li>Is this possible?<\/li>\n<li>Is this a good approach?<\/li>\n<\/ol>\n<p>Thanks for your help.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1648478111533,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":399,
        "Owner_creation_time":1648477773363,
        "Owner_last_access_time":1663242033903,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I know I'm a bit late to the party but here we go:<\/p>\n<p><strong>Passing variables between AzureML Pipeline Steps<\/strong><\/p>\n<p>To directly answer your question, to my knowledge it is not possible to pass variables directly between PythonScriptSteps in an AzureML Pipeline.<\/p>\n<p>The reason for that is that the steps are executed in isolation, i.e. the code is run in different processes or even computes. The only interface a PythonScriptStep has is (a) command line arguments that need to be set prior to submission of the pipeline and (b) data.<\/p>\n<p><strong>Using datasets to pass information between PythonScriptSteps<\/strong><\/p>\n<p>As a workaround you can use PipelineData to pass data between steps.\nThe previously posted blog post may help: <a href=\"https:\/\/vladiliescu.net\/3-ways-to-pass-data-between-azure-ml-pipeline-steps\/\" rel=\"nofollow noreferrer\">https:\/\/vladiliescu.net\/3-ways-to-pass-data-between-azure-ml-pipeline-steps\/<\/a><\/p>\n<p>As for your concrete problem:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># pipeline.py\n\n# This will make Azure create a unique directory on the datastore everytime the pipeline is run.\nvariables_data = PipelineData(&quot;variables_data&quot;, datastore=datastore)\n\n# `variables_data` will be mounted on the target compute and a path is given as a command line argument\nwrite_variable = PythonScriptStep(\n    script_name=&quot;write_variable.py&quot;,\n    arguments=[\n        &quot;--data_path&quot;,\n        variables_data\n    ],\n    outputs=[variables_data],\n)\n\nread_variable = PythonScriptStep(\n    script_name=&quot;read_variable.py&quot;,\n    arguments=[\n        &quot;--data_path&quot;,\n        variables_data\n    ],\n    inputs=[variables_data],\n)\n\n<\/code><\/pre>\n<p>In your script you'll want to serialize the variable \/ object that you're trying to pass between steps:<\/p>\n<p>(You could of course use JSON or any other serialization method)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># write_variable.py\n\nimport argparse\nimport pickle\nfrom pathlib import Path\n\nparser = argparse.ArgumentParser()\nparser.add_argument(&quot;--data_path&quot;)\nargs = parser.parse_args()\n\nobj = [1, 2, 3, 4]\n\nPath(args.data_path).mkdir(parents=True, exist_ok=True)\nwith open(args.data_path + &quot;\/obj.pkl&quot;, &quot;wb&quot;) as f:\n    pickle.dump(obj, f)\n<\/code><\/pre>\n<p>Finally, you can read the variable in the next step:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># read_variable.py\n\nimport argparse\nimport pickle\n\nparser = argparse.ArgumentParser()\nparser.add_argument(&quot;--data_path&quot;)\nargs = parser.parse_args()\n\n\nwith open(args.data_path + &quot;\/obj.pkl&quot;, &quot;rb&quot;) as f:\n    obj = pickle.load(f)\n\nprint(obj)\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1658826630380,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1658826747247,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71649163",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68172002,
        "Question_title":"How to trigger Azure ML Pipeline from Power Automate",
        "Question_body":"<p>I have a published Azure ML Pipeline that I am trying to trigger from an Automate Flow I have that triggers when users edit a document. Since I have the REST Endpoint for the Published Pipeline, I figured I should be able to make a POST request using the HTTP module available in Power Automate to trigger the pipeline.<\/p>\n<p>However, when I actually try this, I get an authentication error. I assume this is because I need to include some access token with the REST Endpoint, but I can't find any documentation that will tell me where to get that token from. Please note that I do not need to pass any data to the Pipeline, it handles its own data collection, I literally just need a way to trigger it.<\/p>\n<p>Does anybody know how to trigger a Published Azure ML Pipeline using the REST Endpoint? Does it make sense to use the HTTP module, or is there a better way to achieve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1624934847563,
        "Question_score":1,
        "Question_tags":"azure|rest|power-automate|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":305,
        "Owner_creation_time":1611181716003,
        "Owner_last_access_time":1639435799460,
        "Owner_location":null,
        "Owner_reputation":119,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":1624937966803,
        "Answer_body":"<p>So I figured out how to do it by following the directions contained within this piece of Microsoft Documentation:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest<\/a><\/p>\n<p>Specifically, it required performing two of the calls in the documentation;<\/p>\n<ul>\n<li>The first to get an AAD token using an Azure Service Principle that is authorised to access the Machine Learning Instance.<\/li>\n<\/ul>\n<blockquote>\n<p>curl -X POST <a href=\"https:\/\/login.microsoftonline.com\/\" rel=\"nofollow noreferrer\">https:\/\/login.microsoftonline.com\/<\/a>\/oauth2\/token -d &quot;grant_type=client_credentials&amp;resource=https%3A%2F%2Fmanagement.azure.com%2F&amp;client_id=&amp;client_secret=&quot;<\/p>\n<\/blockquote>\n<ul>\n<li>The second to use this token to trigger your pipeline from its rest endpoint. This one I had to figure out myself a little, but below is the basic structure I used.<\/li>\n<\/ul>\n<blockquote>\n<p>curl -X POST {PIPELINE_REST_ENDPOINT} -H &quot;Authorisation:Bearer {AAD_TOKEN}&quot; -H &quot;Content-Type: application\/json&quot; -d &quot;{&quot;ExperimentName&quot;: &quot;{EXPERIMENT_NAME}&quot;,&quot;ParameterAssignments&quot;: {}}&quot;<\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1630892629443,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68172002",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59829017,
        "Question_title":"Azure Machine Learning - Memory Error while creating dataframe",
        "Question_body":"<p>I am getting memory error while creating simple dataframe read from CSV file on Azure Machine Learning using notebook VM as compute instance. The VM has config of DS 13 56gb RAM, 8vcpu, 112gb storage on Ubuntu (Linux (ubuntu 16.04). CSV file is 5gb file. <\/p>\n\n<pre><code>blob_service = BlockBlobService(account_name,account_key)\nblobstring = blob_service.get_blob_to_text(container,filepath).content\ndffinaldata = pd.read_csv(StringIO(blobstring), sep=',')\n<\/code><\/pre>\n\n<p>What I am doing wrong here ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1579544749467,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":507,
        "Owner_creation_time":1500744375327,
        "Owner_last_access_time":1660004233300,
        "Owner_location":null,
        "Owner_reputation":255,
        "Owner_up_votes":20,
        "Owner_down_votes":0,
        "Owner_views":130,
        "Question_last_edit_time":1579556126093,
        "Answer_body":"<p>you need to provide the right encoding when calling get_blob_to_text, please refer to the <a href=\"https:\/\/github.com\/Azure\/azure-storage-python\/blob\/master\/samples\/blob\/block_blob_usage.py#L390\" rel=\"nofollow noreferrer\">sample<\/a>.<\/p>\n\n<p>The code below is what  normally use for reading data file in blob storages. Basically, you can use blob\u2019s url along with sas token and use a request method. However, You might want to edit the \u2018for loop\u2019 depending what types of data you have (e.g. csv, jpg, and etc).<\/p>\n\n<p>-- Python code below --<\/p>\n\n<pre><code>import requests\nfrom azure.storage.blob import BlockBlobService, BlobPermissions\nfrom azure.storage.blob.baseblobservice import BaseBlobService\nfrom datetime import datetime, timedelta\n\naccount_name = '&lt;account_name&gt;'\naccount_key = '&lt;account_key&gt;'\ncontainer_name = '&lt;container_name&gt;'\n\nblob_service=BlockBlobService(account_name,account_key)\ngenerator = blob_service.list_blobs(container_name)\n\nfor blob in generator:\n    url = f\"https:\/\/{account_name}.blob.core.windows.net\/{container_name}\"\n    service = BaseBlobService(account_name=account_name, account_key=account_key)\n    token = service.generate_blob_shared_access_signature(container_name, img_name, permission=BlobPermissions.READ, expiry=datetime.utcnow() + timedelta(hours=1),)\n    url_with_sas = f\"{url}?{token}\"\n    response = requests.get(url_with_sas)\n<\/code><\/pre>\n\n<p>Please follow the below link to read data on Azure Blob Storage.\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1579583849897,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1579586200473,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59829017",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57923187,
        "Question_title":"How to modify the input\/output schema for an Azure deployment service?",
        "Question_body":"<p>I started to develop machine learning models on The Microsoft Azure Machine Learning Studio service. The tutorials and information related to this service are rather clear but I am looking for some information that I did not find concerning the deployment of the service.<\/p>\n\n<p>I would like to understand why the input schema requires the definition of the variable to predict and why the output returns all variable fields given in entry. In this response\/request exchange a part of information transmitted is useless. I wondering if it is possible to modify manually this schema.<\/p>\n\n<p>I searched in the configuration tab of the web service panel but I did not find any information to modify the schema passed to the model.<\/p>\n\n<p>The code below is the input schema that the model requires and the value to predict is <code>WallArea<\/code>. It is not really useful to pass this variable because it is the one we try to predict. (except if we want to compare the actual value and the predicted one for test purpose).<\/p>\n\n<pre><code>{\n  \"Inputs\": {\n    \"input1\": {\n      \"ColumnNames\": [\n        \"WallArea\",\n        \"RoofArea\",\n        \"OverallHeight\",\n        \"GlazingArea\",\n        \"HeatingLoad\"\n      ],\n      \"Values\": [\n        [\n          \"0\",\n          \"0\",\n          \"0\",\n          \"0\",\n          \"0\"\n        ]\n      ]\n    }\n  },\n  \"GlobalParameters\": {}\n}\n<\/code><\/pre>\n\n<p>The json returned by the model with the predicted value sent all data. It is much more info to what we really need (\"Scored Label Mean\" and \"Scored Label Standard Deviation\")<\/p>\n\n<pre><code>{\n  \"Results\": {\n    \"output1\": {\n      \"type\": \"DataTable\",\n      \"value\": {\n        \"ColumnNames\": [\n          \"WallArea\",\n          \"RoofArea\",\n          \"OverallHeight\",\n          \"GlazingArea\",\n          \"HeatingLoad\",\n          \"Scored Label Mean\",\n          \"Scored Label Standard Deviation\"\n        ],\n        \"ColumnTypes\": [\n          \"Numeric\",\n          \"Numeric\",\n          \"Numeric\",\n          \"Numeric\",\n          \"Numeric\",\n          \"Numeric\",\n          \"Numeric\"\n        ],\n        \"Values\": [\n          [\n            \"0\",\n            \"0\",\n            \"0\",\n            \"0\",\n            \"0\",\n            \"0\",\n            \"0\"\n          ]\n        ]\n      }\n    }\n  }\n}\n<\/code><\/pre>\n\n<p>My question is how to reduce\/synthesize the input\/output schema if it is possible and why the variable to predict must be sent with the input schema?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1568375681780,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":471,
        "Owner_creation_time":1492331396980,
        "Owner_last_access_time":1651244309180,
        "Owner_location":null,
        "Owner_reputation":197,
        "Owner_up_votes":35,
        "Owner_down_votes":1,
        "Owner_views":40,
        "Question_last_edit_time":1568376011443,
        "Answer_body":"<p>I found the solution.<\/p>\n\n<p>For those who have the same problem, it is pretty simple in fact. You need to add two <strong>Select Columns in Dataset<\/strong> box in your <strong>Predictive experiment<\/strong> schema.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/JA3q2.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/JA3q2.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><strong>Update 2020:<\/strong> Following some updates done on the service, the solution proposed is partially broken. Indeed, if you decide to not include the outcome in the first Select columns box, you well not be able to retrieve it in the second <strong><em>Select Column box<\/em><\/strong> leading to an error. To solve that, you have to remove the first Select Column box and take all features. For the second <strong><em>Select Column box<\/em><\/strong> nothing change, you select the features you want for your predictive response.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1568622249777,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1583405648423,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57923187",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38500359,
        "Question_title":"Azure: importing not already existing packages in 'src'",
        "Question_body":"<p>I have an experiment in which a module R script uses functions defined in a zip source (Data Exploration). <a href=\"https:\/\/blogs.msdn.microsoft.com\/benjguin\/2014\/09\/24\/how-to-upload-an-r-package-to-azure-machine-learning\/\" rel=\"nofollow noreferrer\">Here<\/a> it's described how to do about the packages not already existing in the Azure environment.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/jKLlP.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/jKLlP.png\" alt=\"enter image description here\"><\/a> <\/p>\n\n<p>The DataExploration module has been imported from a file Azure.zip containing all the packages and functions I need (as shown in the next picture).<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WlrVE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/WlrVE.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When I run the experiment nothing goes wrong. At the contrary, watching the log it seems clear that Azure is able to manage the source.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/AuJLD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AuJLD.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The problem is that, when I deploy the web service (classic), if I run the experiment I get the following error:<\/p>\n\n<blockquote>\n  <p>FailedToEvaluateRScript: The following error occurred during\n  evaluation of R script: R_tryEval: return error: Error in\n  .zip.unpack(pkg, tmpDir) : zip file 'src\/scales_0.4.0.zip' not found ,\n  Error code: LibraryExecutionError, Http status code: 400, Timestamp:\n  Thu, 21 Jul 2016 09:05:25 GMT<\/p>\n<\/blockquote>\n\n<p>It's like he cannot see the scales_0.4.0.zip into the 'src' folder.<\/p>\n\n<p>The strange fact is that all used to work until some days ago. Then I have copied the experiment on a second workspace and it gives me the above error. <\/p>\n\n<p>I have also tried to upload again the DataExploration module on the new workspace, but it's the same.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1469093505773,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio|azure-web-app-service",
        "Question_view_count":144,
        "Owner_creation_time":1436432728610,
        "Owner_last_access_time":1663607665487,
        "Owner_location":"Colleferro, Italy",
        "Owner_reputation":809,
        "Owner_up_votes":109,
        "Owner_down_votes":0,
        "Owner_views":361,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I have \"solved\" thanks to the help of the AzureML support: it is a bug they are trying to solve right now.<\/p>\n\n<p>The bug shows up when you have <strong>more R script modules<\/strong>, and the <strong>first has no a zip<\/strong> input module while the following have. <\/p>\n\n<p><em>Workaround<\/em>: connect the zip input module to the first R script module too.\n<a href=\"https:\/\/i.stack.imgur.com\/C4fV9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/C4fV9.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1469606718630,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38500359",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58278844,
        "Question_title":"Does the Azure CLI ML \"service run\" command work?",
        "Question_body":"<p>I have deployed a Model to an ACI container and have an endpoint that I can hit in Postman or using python SDK. I use Python to hit the endpoint as well as Postman and I get a response and the Container Instance logging records the event. I now what to use the AZ ML CLI to run the service and pass in some hardcoded JSON:<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/service?view=azure-cli-latest#ext-azure-cli-ml-az-ml-service-run\" rel=\"nofollow noreferrer\">From the Azure ML CLI docs<\/a>:  <\/p>\n\n<pre><code>az ml service run --name (-n) --input-data (-d)\n<\/code><\/pre>\n\n<p>I run this <\/p>\n\n<pre><code>az ml service run -n \"rj-aci-5\" -d {\\\"input_df\\\": [{\\\"width\\\": 50, \\\"shoe_size\\\": 28}]}\n<\/code><\/pre>\n\n<p>There is no output or error. The logs do not record any invocation. Has anyone used the Azure CLI ML extensions to run a service in the manner above?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1570495889007,
        "Question_score":0,
        "Question_tags":"azure|azure-cli|azure-machine-learning-service",
        "Question_view_count":63,
        "Owner_creation_time":1256089885500,
        "Owner_last_access_time":1663046676847,
        "Owner_location":"Sydney, Australia",
        "Owner_reputation":4947,
        "Owner_up_votes":277,
        "Owner_down_votes":8,
        "Owner_views":531,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The az cli is likely failing to parse the provided data input. If I attempt to run the same command I see the following error:<\/p>\n\n<p><code>az: error: unrecognized arguments: [{\"width\": 50, \"shoe_size\": 28}]}<\/code><\/p>\n\n<p>You need to wrap the input in quotes for it to appropriately be taken as a single input parameter:<\/p>\n\n<p><code>az ml service run -n \"rj-aci-5\" -d \"{\\\"input_df\\\": [{\\\"width\\\": 50, \\\"shoe_size\\\": 28}]}\"<\/code><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1570637042413,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58278844",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37462268,
        "Question_title":"Python in AzureML fail to pass dataframe without changes",
        "Question_body":"<p>when trying to pass data without doing anything in python, getting this error:<\/p>\n\n<pre><code>Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nCaught exception while executing function: Traceback (most recent call last):\n  File \"C:\\server\\invokepy.py\", line 175, in batch\n    rutils.RUtils.DataFrameToRFile(outlist[i], outfiles[i])\n  File \"C:\\server\\RReader\\rutils.py\", line 28, in DataFrameToRFile\n    rwriter.write_attribute_list(attributes)\n  File \"C:\\server\\RReader\\rwriter.py\", line 59, in write_attribute_list\n    self.write_object(value);\n  File \"C:\\server\\RReader\\rwriter.py\", line 121, in write_object\n    write_function(flags, value.values())\n  File \"C:\\server\\RReader\\rwriter.py\", line 104, in write_objects\n    self.write_object(value)\n  File \"C:\\server\\RReader\\rwriter.py\", line 121, in write_object\n    write_function(flags, value.values())\n  File \"C:\\server\\RReader\\rwriter.py\", line 71, in write_integers\n    self.write_integer(value)\n  File \"C:\\server\\RReader\\rwriter.py\", line 147, in write_integer\n    self.writer.WriteInt32(value)\n  File \"C:\\server\\RReader\\BinaryIO\\binarywriter.py\", line 26, in WriteInt32\n    self.WriteData(self.Int32Format, data)\n  File \"C:\\server\\RReader\\BinaryIO\\binarywriter.py\", line 14, in WriteData\n    self.stream.write(pack(format, data))\nerror: cannot convert argument to integer\n\n---------- End of error message from Python  interpreter  ----------\nStart time: UTC 05\/26\/2016 13:16:01\nEnd time: UTC 05\/26\/2016 13:16:13\n<\/code><\/pre>\n\n<p>here is the data i'm trying to pass:\n<a href=\"https:\/\/i.stack.imgur.com\/ysG36.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ysG36.png\" alt=\"the data\"><\/a><\/p>\n\n<p>here is the experiment:\n<a href=\"https:\/\/i.stack.imgur.com\/vgdSn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vgdSn.png\" alt=\"the experiment\"><\/a><\/p>\n\n<p>and the python code:\n<a href=\"https:\/\/i.stack.imgur.com\/LRSAE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LRSAE.png\" alt=\"python code\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1464269301867,
        "Question_score":3,
        "Question_tags":"python|python-2.7|pandas|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":739,
        "Owner_creation_time":1320061998253,
        "Owner_last_access_time":1656424560827,
        "Owner_location":null,
        "Owner_reputation":778,
        "Owner_up_votes":176,
        "Owner_down_votes":6,
        "Owner_views":89,
        "Question_last_edit_time":null,
        "Answer_body":"<p>after talking to Microsoft support, the problem was that the \"Execute Python Script\" module cannot return empty values.\nthis can be solved by adding a \"Clean Missing Data\" module before reading it from python:\n<a href=\"https:\/\/i.stack.imgur.com\/BzCUZ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BzCUZ.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1468139774183,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37462268",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59328925,
        "Question_title":"Is it possible to speed up local AzureML model deployment?",
        "Question_body":"<p>We want to be able to quickly test changes to <code>entry_script.py<\/code>. We can test minor changes with unit tests but we want to run a model in the context of our other backend pieces, locally. <\/p>\n\n<p>So we run <code>az ml model deploy<\/code> with a deployment config with a <code>computeType<\/code> of <code>LOCAL<\/code>. Non-local deployment is slow, but we were hoping that local deployment would be faster. Unfortunately it isn't. In some cases it can take up to 20 minutes to deploy a model to a local endpoint.<\/p>\n\n<p>Is there a way to speed this up for faster edit-debug loops or a better way of handling this scenario?<\/p>\n\n<p>Few things I was thinking of:<\/p>\n\n<ul>\n<li>I was thinking <code>az ml service update<\/code> could be an option but even that takes a long time.<\/li>\n<li>Editing the file directly in the container is an option, but this is still annoying to manually synchronize with changes in your local filesystem.<\/li>\n<li>I was thinking of a folder mount in the container, but it seems there is some magic AzureML does, for example copying the <code>entry_script.py<\/code> to <code>\/var\/azureml-app\/main.py<\/code>. We could maybe emulate this by creating a <code>dist<\/code> folder locally that matches the layout and mounting that to the container, but I'm not sure if this folder layout would change or there's other things that AzureML does.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1576266473653,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":339,
        "Owner_creation_time":1254279877887,
        "Owner_last_access_time":1663949658720,
        "Owner_location":"Seattle, WA",
        "Owner_reputation":153,
        "Owner_up_votes":101,
        "Owner_down_votes":1,
        "Owner_views":111,
        "Question_last_edit_time":1576476751263,
        "Answer_body":"<p>Please follow the below notebook, If you want to test deploying a model rapidly you should check out \n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/deployment\/deploy-to-local\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/deployment\/deploy-to-local<\/a><\/p>\n\n<p>the SDK enables building and running the docker locally and updating in place as you iterate on your script to save time.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1576497182733,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59328925",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36763479,
        "Question_title":"How to tell the learner type of machine learning models",
        "Question_body":"<p>It is my first time to use Azure Machine Learning...<\/p>\n\n<p>When I have trained 2 models using the same training data and testing data, when it comes to evaluate model, it shows error<\/p>\n\n<blockquote>\n  <p>All models must have the same learner type<\/p>\n<\/blockquote>\n\n<p>Do you know what is \"learner type\" of machine learning models and how to tell the learner type of a model?<\/p>\n\n<p>Below is the screenshot of my basic practice on Azure Machine Learning:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/plx4V.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/plx4V.png\" alt=\"Azure Machine Learning practice\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1461225939707,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":516,
        "Owner_creation_time":1361240380857,
        "Owner_last_access_time":1663870148467,
        "Owner_location":null,
        "Owner_reputation":3349,
        "Owner_up_votes":865,
        "Owner_down_votes":1,
        "Owner_views":465,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The models you compare should be of the same type - binary classification, regression, multi-class classification etc. For example, you can't compare effectiveness of linear regression to the effectiveness of logistics regression. They solve absolutely different tasks.<\/p>\n\n<p>This is the case for you - you try to compare linear regression (which outputs real value) with the multiclass decision forest, which tries to classify input to some class.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1461249085857,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36763479",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50334563,
        "Question_title":"Deployment of an Azure ML Experiment as a Web Service through Azure Machine Learning Studio",
        "Question_body":"<p>I used Machine learning tutorial: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/create-experiment\" rel=\"nofollow noreferrer\">Create your first data science experiment in Azure Machine Learning Studio<\/a> to create an <code>Experiment<\/code> and then converted it to a <code>predictive experiment<\/code>. Now I'm trying to deploy it as a Web Service by following this article that was referenced in the above article: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/publish-a-machine-learning-web-service#deploy-it-as-a-web-service\" rel=\"nofollow noreferrer\">Deploy it as a web service<\/a>. But when I click on <code>Run<\/code> and then on <code>Deploy Web Service<\/code>, I don't see the <code>Price Plan<\/code> dropdown and <code>Plan Name<\/code> input box etc as mentioned in the section <code>Machine Learning Web Service portal Deploy Experiment Page<\/code> of the second article above. After I clicked on Deploy Web Service link in ML studio, I got the page shown below.<strong>Question<\/strong>: What I may be doing wrong?<\/p>\n\n<p>Note: You can click on the picture to get a larger view.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/G3TKo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/G3TKo.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1526313605237,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":330,
        "Owner_creation_time":1330144099340,
        "Owner_last_access_time":1664039192277,
        "Owner_location":null,
        "Owner_reputation":19815,
        "Owner_up_votes":2703,
        "Owner_down_votes":22,
        "Owner_views":2272,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I think it depends on what workspace you're in. If you're in the free one then you get the screen that you already get, but if you create a workspace in the Azure portal and use that one, then you will get a screen like below.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/drRpa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/drRpa.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>To create a new workspace, in the Azure Portal, create a new \"Machine Learning Studio Workspace\" and when you go to Azure ML Studio select the new workspace from the top right.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1526322971967,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50334563",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42324035,
        "Question_title":"How to select Scored Probabilities from azure prediction model",
        "Question_body":"<p>I have a model in AzureML that scores incoming values from a csv.<\/p>\n\n<p>The flow is ...->(Score Model using one-class SVM)->(Normalize Data)->(Convert to CSV)->(Convert to Dataset)->(Web Service Output)<\/p>\n\n<p>When the experiment is run I can download the csv from the (Convert to CSV) module output and it will contain Scored Probabilities column.<\/p>\n\n<p>But when I'm using a streaming job I don't know how to access the Scored Probabilities column using Query SQL. How do I do it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1487482693377,
        "Question_score":1,
        "Question_tags":"azure|azure-stream-analytics|azure-machine-learning-studio",
        "Question_view_count":576,
        "Owner_creation_time":1300047702250,
        "Owner_last_access_time":1563817416587,
        "Owner_location":null,
        "Owner_reputation":586,
        "Owner_up_votes":33,
        "Owner_down_votes":3,
        "Owner_views":108,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can access the response using the amlresult.[Scored Probabilities] notation, where amlresult is an alias for the return value from your AzureML call.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1488576068267,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42324035",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69355385,
        "Question_title":"Size of the input \/ output parameters in the pipeline step in Azure",
        "Question_body":"<p>while running pipeline creation python script facing the following error.\n&quot;AzureMLCompute job failed. JobConfigurationMaxSizeExceeded: The specified job configuration exceeds the max allowed size of 32768 characters. Please reduce the size of the job's command line arguments and environment settings&quot;<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1632798980813,
        "Question_score":4,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":208,
        "Owner_creation_time":1632461310820,
        "Owner_last_access_time":1650860148037,
        "Owner_location":null,
        "Owner_reputation":107,
        "Owner_up_votes":49,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>When we tried to pass a quite lengthy content as argument value to a Pipeline. You can try to upload file to blob, optionally create a dataset, then pass on dataset name or file path to AML pipeline as parameter. The pipeline step will read content of the file from the blob.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1632803094283,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69355385",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67161293,
        "Question_title":"Issues accessing a FileDataset created from HTTP URIs in a PythonScriptStep",
        "Question_body":"<p>I\u2019m having some issues trying to access a FileDataset created from two http URIs in an Azure ML Pipeline PythonScriptStep.<\/p>\n<p>In the step, I\u2019m only getting a single file named <code>['https%3A\u2019]<\/code> when doing an <code>os.listdir()<\/code> on my mount point. I would have expected two files, with their actual names instead. This happens both when sending the dataset <code>as_upload<\/code> and <code>as_mount<\/code>. Even happens when I send the dataset reference to the pipeline step and mount it directly from the step.<\/p>\n<p>The dataset is registered in a notebook, the same notebook that creates and invokes the pipeline, as seen below:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>tempFileData = Dataset.File.from_files(\n        ['https:\/\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg',\n        'https:\/\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg'])\ntempFileData.register(ws, name='FileData', create_new_version=True)\n\n#...\n\nread_datasets_step = PythonScriptStep(\n    name='The Dataset Reader',\n    script_name='read-datasets.py',\n    inputs=[fileData.as_named_input('Files'), fileData.as_named_input('Files_mount').as_mount(), fileData.as_named_input('Files_download').as_download()],\n    compute_target=compute_target,\n    source_directory='.\/dataset-reader',\n    allow_reuse=False,\n)\n\n<\/code><\/pre>\n<p>The <code>FileDataset<\/code> seems to be registered properly, if I examine it within the notebook I get the following result:<\/p>\n<pre class=\"lang-json prettyprint-override\"><code>{\n  &quot;source&quot;: [\n    &quot;https:\/\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg&quot;,\n    &quot;https:\/\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg&quot;\n  ],\n  &quot;definition&quot;: [\n    &quot;GetFiles&quot;\n  ],\n  &quot;registration&quot;: {\n    &quot;id&quot;: &quot;...&quot;,\n    &quot;name&quot;: &quot;FileData&quot;,\n    &quot;version&quot;: 4,\n    &quot;workspace&quot;: &quot;Workspace.create(...)&quot;\n  }\n}\n<\/code><\/pre>\n<p>For reference, the machine running the notebook is using AML SDK v1.24, whereas the node running the pipeline steps is running v1.25.<\/p>\n<p>Has anybody encountered anything like this? Is there a way to make it work?<\/p>\n<p>Note that I'm specifically looking at file datasets created from web uris, and not necessarily interested in getting a <code>FileDataset<\/code> to work with blob storage or similar.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1618832324140,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":91,
        "Owner_creation_time":1250158552417,
        "Owner_last_access_time":1663847198323,
        "Owner_location":"Romania",
        "Owner_reputation":7916,
        "Owner_up_votes":1735,
        "Owner_down_votes":33,
        "Owner_views":801,
        "Question_last_edit_time":1618849094430,
        "Answer_body":"<p>The files should've been mounted at path &quot;https%3A\/vladiliescu.net\/images\/deploying-models-with-azure-ml-pipelines.jpg&quot; and &quot;https%3A\/vladiliescu.net\/images\/reverse-engineering-automated-ml.jpg&quot;.<\/p>\n<p>We retain the directory structure following the url structure to avoid potential conflicts.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1618855169223,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67161293",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61546680,
        "Question_title":"ModuleNotFoundError: No module named 'pyspark.dbutils'",
        "Question_body":"<p>I am running pyspark from an Azure Machine Learning notebook. I am trying to move a file using the dbutil module.<\/p>\n\n<pre><code>from pyspark.sql import SparkSession\n    spark = SparkSession.builder.getOrCreate()\n    def get_dbutils(spark):\n        try:\n            from pyspark.dbutils import DBUtils\n            dbutils = DBUtils(spark)\n        except ImportError:\n            import IPython\n            dbutils = IPython.get_ipython().user_ns[\"dbutils\"]\n        return dbutils\n\n    dbutils = get_dbutils(spark)\n    dbutils.fs.cp(\"file:source\", \"dbfs:destination\")\n<\/code><\/pre>\n\n<p>I got this error: \nModuleNotFoundError: No module named 'pyspark.dbutils'\nIs there a workaround for this? <\/p>\n\n<p>Here is the error in another Azure Machine Learning notebook:<\/p>\n\n<pre><code>---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-1-183f003402ff&gt; in get_dbutils(spark)\n      4         try:\n----&gt; 5             from pyspark.dbutils import DBUtils\n      6             dbutils = DBUtils(spark)\n\nModuleNotFoundError: No module named 'pyspark.dbutils'\n\nDuring handling of the above exception, another exception occurred:\n\nKeyError                                  Traceback (most recent call last)\n&lt;ipython-input-1-183f003402ff&gt; in &lt;module&gt;\n     10         return dbutils\n     11 \n---&gt; 12 dbutils = get_dbutils(spark)\n\n&lt;ipython-input-1-183f003402ff&gt; in get_dbutils(spark)\n      7         except ImportError:\n      8             import IPython\n----&gt; 9             dbutils = IPython.get_ipython().user_ns[\"dbutils\"]\n     10         return dbutils\n     11 \n\nKeyError: 'dbutils'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_time":1588351032100,
        "Question_score":2,
        "Question_tags":"pyspark|databricks|azure-databricks|azure-machine-learning-service|dbutils",
        "Question_view_count":7629,
        "Owner_creation_time":1330373362200,
        "Owner_last_access_time":1663907622027,
        "Owner_location":"Kennett Square, PA",
        "Owner_reputation":445,
        "Owner_up_votes":377,
        "Owner_down_votes":0,
        "Owner_views":104,
        "Question_last_edit_time":1591892764407,
        "Answer_body":"<p>This is a known issue with Databricks Utilities - DButils.<\/p>\n\n<p>Most of DButils aren't supported for Databricks Connect. The only parts that do work are <strong>fs<\/strong> and <strong>secrets<\/strong>. <\/p>\n\n<p><strong>Reference:<\/strong> <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/dev-tools\/databricks-connect#limitations\" rel=\"nofollow noreferrer\">Databricks Connect - Limitations<\/a> and <a href=\"https:\/\/datathirst.net\/blog\/2019\/3\/7\/databricks-connect-limitations\" rel=\"nofollow noreferrer\">Known issues<\/a>.<\/p>\n\n<p><strong>Note:<\/strong> Currently fs and secrets work (locally). Widgets (!!!), libraries etc do not work. This shouldn\u2019t be a major issue. If you execute on Databricks using the Python Task dbutils will fail with the error:<\/p>\n\n<pre><code>ImportError: No module named 'pyspark.dbutils'\n<\/code><\/pre>\n\n<p>I'm able to execute the query successfully by running as a notebook.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/RFVm8.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/RFVm8.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1588593659053,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61546680",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":43249220,
        "Question_title":"Need more than 2 datasets for \u201cExecute R Script\u201d module in \u201cAzure Machine Learning Studio\u201d",
        "Question_body":"<p>Since connecting to Azure SQL database from \u201cExecute R Script\u201d module in \u201cAzure Machine Learning Studio\u201d is not possible, and using Import Data modules (a.k.a Readers) is the only recommended approach, my question is that what can I do when I need more than 2 datasets as input for \"Execute R Script module\"?<\/p>\n\n<pre><code>\/\/ I'm already doing the following to get first 2 datasets,\ndataset1 &lt;- maml.mapInputPort(1)\ndataset2 &lt;- maml.mapInputPort(2)\n<\/code><\/pre>\n\n<p>How can I \"import\" a dataset3?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1491465771163,
        "Question_score":0,
        "Question_tags":"r|azure|azure-sql-database|azure-machine-learning-studio",
        "Question_view_count":337,
        "Owner_creation_time":1487901477287,
        "Owner_last_access_time":1664081754313,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>One thing you can do is combining two data-sets together and selecting the appropriate fields using the R script. That would be an easy workaround.   <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1491492855983,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/43249220",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36132719,
        "Question_title":"Select columns dynamically in Azure ML model",
        "Question_body":"<p>I have deployed a model as a Webservice in Azure ML.Its a simple one and all it does is do a linear Regression .The underlying code is python . Now i need to pass which all columns have to selected as independent variables, dynamically, from the client side . How may i do this in Azure ML studio?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1458567955050,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":238,
        "Owner_creation_time":1422821109973,
        "Owner_last_access_time":1664007162760,
        "Owner_location":"India",
        "Owner_reputation":1238,
        "Owner_up_votes":45,
        "Owner_down_votes":5,
        "Owner_views":172,
        "Question_last_edit_time":1458612577147,
        "Answer_body":"<p>Based on my understanding, I think you want to dynamically get the selected columns data via request the Azure ML webservice with some parameters on the client.<\/p>\n\n<p>You can refer to the offical document <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-web-service-parameters\/\" rel=\"nofollow\">Use Azure Machine Learning Web Service Parameters<\/a> and the blog <a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2014\/11\/25\/azureml-web-service-parameters\/\" rel=\"nofollow\">AzureML Web Service Parameters<\/a> to know how to set and use the web service parameters to implement your needs via add the selected column names as array into the json parameter <code>GlobalParameters<\/code>.<\/p>\n\n<p>Meanwhile, there is a client sample on GitHub <a href=\"https:\/\/github.com\/nk773\/AzureML_RRSApp\" rel=\"nofollow\">https:\/\/github.com\/nk773\/AzureML_RRSApp<\/a>. Althought it was writen in Java, I think it is easy to understand, then you can rewrite in Python with <code>requests<\/code> package.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1458632118243,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1458699277763,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36132719",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72775967,
        "Question_title":"R, pins and AzureStor: unused argument (azure_storage_progress_bar = progress)",
        "Question_body":"<pre><code>pins 1.0.1\nAzureStor 3.7.0\n<\/code><\/pre>\n<p>I'm getting this error<\/p>\n<pre><code>Error in withr::local_options(azure_storage_progress_bar = progress, .local_envir = env) : \n  unused argument (azure_storage_progress_bar = progress)\nCalls: %&gt;% ... pin_meta.pins_board_azure -&gt; azure_download -&gt; local_azure_progress\nExecution halted\n<\/code><\/pre>\n<p>when running <code>pin_read()<\/code> in the following code (<code>pin_list()<\/code> works fine)<\/p>\n<pre><code>bl_endp_key &lt;- storage_endpoint(endpoint = &lt;endpoint URL&gt;, key =&lt;endpoint key&gt;&quot;)\ncontainer &lt;- storage_container(endpoint = bl_endp_key, name = &lt;blob name&gt;)\nboard &lt;- board_azure(container = container, path = &quot;accidentsdata&quot;)\ncat(&quot;Testing pins:\\n&quot;)\nprint(board %&gt;% pin_list())\naccidents2 &lt;- board %&gt;% pins::pin_read('accidents') %&gt;% as_tibble()\n<\/code><\/pre>\n<p>My goal is to &quot;pin_read&quot; a dataset located on a Azure Blob Storage from an R script being run from <strong>pipelineJoB (YAML)<\/strong> including a <code>command: Rscript script.R ...<\/code> and an <code>environment:<\/code> based on a dockerfile installing <strong>R version 4.0.0<\/strong> (2020-04-24) -- &quot;Arbor Day&quot;<\/p>\n<p>The pipelineJob is being called from an Azure DevOps Pipeline task with <code>az ml job create &lt;pipelineJob YAML&gt; &lt;resource grp&gt; &lt;aml workspace name&gt;<\/code>.<\/p>\n<p>Note: the R script runs fine on my Windows RStudio desktop, with R version 4.1.3 (2022-03-10) -- &quot;One Push-Up&quot;.<\/p>\n<p>I've already tried with<\/p>\n<p><code>options(azure_storage_progress_bar=FALSE)<\/code> or<\/p>\n<p><code>withr::local_options(azure_storage_progress_bar=FALSE)<\/code><\/p>\n<p>but I'm getting the same <code>unused argument (azure_storage_progress_bar ...<\/code> error.<\/p>\n<p>FYI: <code>local_azure_progress<\/code> is defined here <a href=\"https:\/\/rdrr.io\/github\/rstudio\/pins\/src\/R\/board_azure.R#sym-local_azure_progress\" rel=\"nofollow noreferrer\">here<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1656349974407,
        "Question_score":0,
        "Question_tags":"r|azure-devops|azure-pipelines|azure-machine-learning-service|pins",
        "Question_view_count":80,
        "Owner_creation_time":1384730587840,
        "Owner_last_access_time":1657810539597,
        "Owner_location":"France",
        "Owner_reputation":717,
        "Owner_up_votes":143,
        "Owner_down_votes":0,
        "Owner_views":112,
        "Question_last_edit_time":1656680662490,
        "Answer_body":"<p>Issue has been filed in <a href=\"https:\/\/github.com\/rstudio\/pins\/issues\/624\" rel=\"nofollow noreferrer\">pins<\/a>, it seems that is not an AzureStor issue.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1656936659777,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72775967",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34047782,
        "Question_title":"Jupyter notebook kernel dies when creating dummy variables with pandas",
        "Question_body":"<p>I am working on the Walmart Kaggle competition and I'm trying to create a dummy column of of the \"FinelineNumber\" column. For context, <code>df.shape<\/code> returns <code>(647054, 7)<\/code>. I am trying to make a dummy column for <code>df['FinelineNumber']<\/code>, which has 5,196 unique values. The results should be a dataframe of shape <code>(647054, 5196)<\/code>, which I then plan to <code>concat<\/code> to the original dataframe. <\/p>\n\n<p>Nearly every time I run <code>fineline_dummies = pd.get_dummies(df['FinelineNumber'], prefix='fl')<\/code>, I get the following error message <code>The kernel appears to have died. It will restart automatically.<\/code> I am running python 2.7 in jupyter notebook on a MacBookPro with 16GB RAM.<\/p>\n\n<p>Can someone explain why this is happening (and why it happens most of the time but not every time)? Is it a jupyter notebook or pandas bug? Also, I thought it might have to do with not enough RAM but I get the same error on a Microsoft Azure Machine Learning notebook with >100 GB of RAM. On Azure ML, the kernel dies every time - almost immediately.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1449073471520,
        "Question_score":5,
        "Question_tags":"python|pandas|ipython-notebook|azure-machine-learning-studio",
        "Question_view_count":5063,
        "Owner_creation_time":1373475615300,
        "Owner_last_access_time":1663780318293,
        "Owner_location":"New York, United States",
        "Owner_reputation":2037,
        "Owner_up_votes":61,
        "Owner_down_votes":1,
        "Owner_views":193,
        "Question_last_edit_time":1454300528203,
        "Answer_body":"<p>It very much could be memory usage - a 647054, 5196 data frame has 3,362,092,584 elements, which would be 24GB just for the pointers to the objects on a 64-bit system.  On AzureML while the VM has a large amount of memory you're actually limited in how much memory you have available (currently 2GB, soon to be 4GB) - and when you hit the limit the kernel typically dies.  So it seems very likely it is a memory usage issue.<\/p>\n\n<p>You might try doing <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/sparse.html\" rel=\"noreferrer\">.to_sparse()<\/a> on the data frame first before doing any additional manipulations.  That should allow Pandas to keep most of the data frame out of memory.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1449768300887,
        "Answer_score":8.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34047782",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60638587,
        "Question_title":"How to get insights in exceptions and logging of AzureML endpoint deployment",
        "Question_body":"<p>Because of a faulty score.py file in my InferenceConfig, a Model.Deploy failed to Azure Machine Learning, using ACI.  I wanted to create the endpoint in the cloud, but the only state I can see in the portal is Unhealthy.  My local script to deploy the model (using ) keeps running, until it times out. (using the <code>service.wait_for_deployment(show_output=True)<\/code>statement).<\/p>\n\n<p>Is there an option to get more insights in the actual reason\/error message of the deployment turning \"Unhealthy\"?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1583937572180,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":364,
        "Owner_creation_time":1360655430743,
        "Owner_last_access_time":1663784892907,
        "Owner_location":"Belgium",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Question_last_edit_time":1584215688010,
        "Answer_body":"<p>Usually the timeout is caused by an error in init() function in scoring script. You can get the detailed logs using <code>print(service.get_logs())<\/code> to find the Python error.<\/p>\n\n<p>For more comprehensive troubleshooting guide, see:<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1584133364177,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60638587",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57436140,
        "Question_title":"How to reuse successfully built docker images in Azure ML?",
        "Question_body":"<p>In our company I use Azure ML and I have the following issue. I specify a <em>conda_requirements.yaml<\/em> file with the PyTorch estimator class, like so (... are placeholders so that I do not have to type everything out):<\/p>\n\n<pre><code>from azureml.train.dnn import PyTorch\nest = PyTorch(source_directory=\u2019.\u2019, script_params=..., compute_target=..., entry_script=..., conda_dependencies_file_path=\u2019conda_requirements.yaml\u2019, environment_variables=..., framework_version=\u20191.1\u2019)\n<\/code><\/pre>\n\n<p>The <em>conda_requirements.yaml<\/em> (shortened version of the pip part) looks like this:<\/p>\n\n<pre><code>dependencies:\n  -  conda=4.5.11\n  -  conda-package-handling=1.3.10\n  -  python=3.6.2\n  -  cython=0.29.10\n  -  scikit-learn==0.21.2\n  -  anaconda::cloudpickle==1.2.1\n  -  anaconda::cffi==1.12.3\n  -  anaconda::mxnet=1.1.0\n  -  anaconda::psutil==5.6.3\n  -  anaconda::pip=19.1.1\n  -  anaconda::six==1.12.0\n  -  anaconda::mkl==2019.4\n  -  conda-forge::openmpi=3.1.2\n  -  conda-forge::pycparser==2.19\n  -  tensorboard==1.13.1\n  -  tensorflow==1.13.1\n  -  pip:\n        - torch==1.1.0\n        - torchvision==0.2.1\n<\/code><\/pre>\n\n<p>This successfully builds on Azure. Now in order to reuse the resulting docker image in that case, I use the <code>custom_docker_image<\/code> parameter to pass to the <\/p>\n\n<pre><code>from azureml.train.estimator import Estimator\nest = Estimator(source_directory=\u2019.\u2019, script_params=..., compute_target=..., entry_script=..., custom_docker_image=\u2019&lt;container registry name&gt;.azurecr.io\/azureml\/azureml_c3a4f...\u2019, environment_variables=...)\n<\/code><\/pre>\n\n<p>But now Azure somehow seems to rebuild the image again and when I run the experiment it cannot install torch. So it seems to only install the conda dependencies and not the pip dependencies, but actually I do not want Azure to rebuild the image. Can I solve this somehow?<\/p>\n\n<p>I attempted to somehow build a docker image from my Docker file and then add to the registry. I can do az login and according to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/container-registry\/container-registry-authentication\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/container-registry\/container-registry-authentication<\/a> I then should also be able to do an acr login and push. This does not work. \nEven using the credentials from<\/p>\n\n<pre><code>az acr credential show \u2013name &lt;container registry name&gt;\n<\/code><\/pre>\n\n<p>and then doing a <\/p>\n\n<pre><code>docker login &lt;container registry name&gt;.azurecr.io \u2013u &lt;username from credentials above&gt; -p &lt;password from credentials above&gt;\n<\/code><\/pre>\n\n<p>does not work.\nThe error message is <em>authentication required<\/em> even though I used <\/p>\n\n<pre><code>az login\n<\/code><\/pre>\n\n<p>successfully. Would also be happy if someone could explain that to me in addition to how to reuse docker images when using Azure ML.\nThank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1565379277197,
        "Question_score":1,
        "Question_tags":"azure|docker|pip|conda|azure-machine-learning-service",
        "Question_view_count":604,
        "Owner_creation_time":1524670343370,
        "Owner_last_access_time":1663769326433,
        "Owner_location":"Z\u00fcrich, Schweiz",
        "Owner_reputation":460,
        "Owner_up_votes":668,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Question_last_edit_time":null,
        "Answer_body":"<p>AzureML should actually cache your docker image once it was created. The service will hash the base docker info and the contents of the conda.yaml file and will use that as the hash key -- unless you change any of that information, the docker should come from the ACR. <\/p>\n\n<p>As for the custom docker usage, did you set the parameter <code>user_managed=True<\/code>? Otherwise, AzureML will consider your docker to be a base image on top of which it will create the conda environment per your yaml file.<br>\nThere is an example of how to use a custom docker image in this notebook:\n<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/4170a394edd36413edebdbab347afb0d833c94ee\/how-to-use-azureml\/training-with-deep-learning\/how-to-use-estimator\/how-to-use-estimator.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/4170a394edd36413edebdbab347afb0d833c94ee\/how-to-use-azureml\/training-with-deep-learning\/how-to-use-estimator\/how-to-use-estimator.ipynb<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1565501907287,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57436140",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51088145,
        "Question_title":"Azure Python SDK & Machine Learning Studio Web Service Batch Execution Snippet: TypeError",
        "Question_body":"<p><strong>First Issue resolved, please read scroll down to EDIT2<\/strong><\/p>\n\n<p>I'm trying to access a Web Service deployed via Azure Machine Learning Studio, using the Batch Execution-Sample Code for Python on the bottom of below page:<\/p>\n\n<p><a href=\"https:\/\/studio.azureml.net\/apihelp\/workspaces\/306bc1f050ba4cdba0dbc6cc561c6ab0\/webservices\/e4e3d2d32ec347ae9a829b200f7d31cd\/endpoints\/61670382104542bc9533a920830b263c\/jobs\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/apihelp\/workspaces\/306bc1f050ba4cdba0dbc6cc561c6ab0\/webservices\/e4e3d2d32ec347ae9a829b200f7d31cd\/endpoints\/61670382104542bc9533a920830b263c\/jobs<\/a><\/p>\n\n<p>I have already fixed an Issue according to this question (replaced BlobService by BlobBlockService and so on):<\/p>\n\n<p><a href=\"https:\/\/studio.azureml.net\/apihelp\/workspaces\/306bc1f050ba4cdba0dbc6cc561c6ab0\/webservices\/e4e3d2d32ec347ae9a829b200f7d31cd\/endpoints\/61670382104542bc9533a920830b263c\/jobs\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/apihelp\/workspaces\/306bc1f050ba4cdba0dbc6cc561c6ab0\/webservices\/e4e3d2d32ec347ae9a829b200f7d31cd\/endpoints\/61670382104542bc9533a920830b263c\/jobs<\/a><\/p>\n\n<p>And I also have entered the API-Key, Container-Name, URL, account_key and account_name according to the instructions.<\/p>\n\n<p>However it seems that today the Code Snippet is even more outdated than it was back then because I receive a different error now:<\/p>\n\n<pre><code>File \"C:\/Users\/Alex\/Desktop\/scripts\/BatchExecution.py\", line 80, in uploadFileToBlob\n    blob_service = asb.BlockBlobService(account_name=storage_account_name, account_key=storage_account_key)\n\n  File \"C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\azure\\storage\\blob\\blockblobservice.py\", line 145, in __init__\n\n  File \"C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\azure\\storage\\blob\\baseblobservice.py\", line 205, in __init__\n\nTypeError: get_service_parameters() got an unexpected keyword argument 'token_credential'\n<\/code><\/pre>\n\n<p>I also noticed, that when installing the Azure SDK for Python via pip, I get the following warnings in the end of the process (installation is successful however):<\/p>\n\n<pre><code>azure-storage-queue 1.3.0 has requirement azure-storage-common&lt;1.4.0,&gt;=1.3.0, but you'll have azure-storage-common 1.1.0 which is incompatible.\n\nazure-storage-file 1.3.0 has requirement azure-storage-common&lt;1.4.0,&gt;=1.3.0, but you'll have azure-storage-common 1.1.0 which is incompatible.\n\nazure-storage-blob 1.3.0 has requirement azure-storage-common&lt;1.4.0,&gt;=1.3.0, but you'll have azure-storage-common 1.1.0 which is incompatible.\n<\/code><\/pre>\n\n<p>I can't find anything about all this in the latest documentation for the Python SDK (the word 'token_credential' is not even contained):<\/p>\n\n<p><a href=\"https:\/\/media.readthedocs.org\/pdf\/azure-storage\/latest\/azure-storage.pdf\" rel=\"nofollow noreferrer\">https:\/\/media.readthedocs.org\/pdf\/azure-storage\/latest\/azure-storage.pdf<\/a><\/p>\n\n<p>Does anyone have a clue what's going wrong during the installation or why the type-error with the 'token_credential' pops up during execution?<\/p>\n\n<p>Or does anyone know how I can install the necessary version of azure-storage-common or azure-storage-blob?<\/p>\n\n<p>EDIT: Here's a my code (however not-reproducible because I changed the keys before posting)<\/p>\n\n<pre><code># How this works:\n#\n# 1. Assume the input is present in a local file (if the web service accepts input)\n# 2. Upload the file to an Azure blob - you\"d need an Azure storage account\n# 3. Call BES to process the data in the blob. \n# 4. The results get written to another Azure blob.\n\n# 5. Download the output blob to a local file\n#\n# Note: You may need to download\/install the Azure SDK for Python.\n# See: http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/python-how-to-install\/\n\nimport urllib\n# If you are using Python 3+, import urllib instead of urllib2\n\nimport json\nimport time\nimport azure.storage.blob as asb          # replaces BlobService by BlobBlockService\n\n\ndef printHttpError(httpError):\n    print(\"The request failed with status code: \" + str(httpError.code))\n\n    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n    print(httpError.info())\n\n    print(json.loads(httpError.read()))\n    return\n\n\ndef saveBlobToFile(blobUrl, resultsLabel):\n    output_file = \"myresults.csv\" # Replace this with the location you would like to use for your output file\n    print(\"Reading the result from \" + blobUrl)\n    try:\n        # If you are using Python 3+, replace urllib2 with urllib.request in the following code\n        response = urllib.request.urlopen(blobUrl)\n    except urllib.request.HTTPError:\n        printHttpError(urllib.HTTPError)\n        return\n\n    with open(output_file, \"w+\") as f:\n        f.write(response.read())\n    print(resultsLabel + \" have been written to the file \" + output_file)\n    return\n\n\ndef processResults(result):\n\n\n    first = True\n    results = result[\"Results\"]\n    for outputName in results:\n        result_blob_location = results[outputName]\n        sas_token = result_blob_location[\"SasBlobToken\"]\n        base_url = result_blob_location[\"BaseLocation\"]\n        relative_url = result_blob_location[\"RelativeLocation\"]\n\n        print(\"The results for \" + outputName + \" are available at the following Azure Storage location:\")\n        print(\"BaseLocation: \" + base_url)\n        print(\"RelativeLocation: \" + relative_url)\n        print(\"SasBlobToken: \" + sas_token)\n\n\n        if (first):\n            first = False\n            url3 = base_url + relative_url + sas_token\n            saveBlobToFile(url3, \"The results for \" + outputName)\n    return\n\n\n\ndef uploadFileToBlob(input_file, input_blob_name, storage_container_name, storage_account_name, storage_account_key):\n    blob_service = asb.BlockBlobService(account_name=storage_account_name, account_key=storage_account_key)\n\n    print(\"Uploading the input to blob storage...\")\n    data_to_upload = open(input_file, \"r\").read()\n    blob_service.put_blob(storage_container_name, input_blob_name, data_to_upload, x_ms_blob_type=\"BlockBlob\")\n\ndef invokeBatchExecutionService():\n    storage_account_name = \"storage1\" # Replace this with your Azure Storage Account name\n    storage_account_key = \"kOveEtQMoP5zbUGfFR47\" # Replace this with your Azure Storage Key\n    storage_container_name = \"input\" # Replace this with your Azure Storage Container name\n    connection_string = \"DefaultEndpointsProtocol=https;AccountName=\" + storage_account_name + \";AccountKey=\" + storage_account_key #\"DefaultEndpointsProtocol=https;AccountName=mayatostorage1;AccountKey=aOYA2P5VQPR3ZQCl+aWhcGhDRJhsR225teGGBKtfXWwb2fNEo0CrhlwGWdfbYiBTTXPHYoKZyMaKuEAU8A\/Fzw==;EndpointSuffix=core.windows.net\"\n    api_key = \"5wUaln7n99rt9k+enRLG2OrhSsr9VLeoCfh0q3mfYo27hfTCh32f10PsRjJtuA==\" # Replace this with the API key for the web service\n    url = \"https:\/\/ussouthcentral.services.azureml.net\/workspaces\/306bc1f050\/services\/61670382104542bc9533a920830b263c\/jobs\" #\"https:\/\/ussouthcentral.services.azureml.net\/workspaces\/306bc1f050ba4cdba0dbc6cc561c6ab0\/services\/61670382104542bc9533a920830b263c\/jobs\/job_id\/start?api-version=2.0\"\n\n\n\n    uploadFileToBlob(r\"C:\\Users\\Alex\\Desktop\\16_da.csv\", # Replace this with the location of your input file\n                     \"input1datablob.csv\", # Replace this with the name you would like to use for your Azure blob; this needs to have the same extension as the input file \n                     storage_container_name, storage_account_name, storage_account_key)\n\n    payload =  {\n\n        \"Inputs\": {\n\n            \"input1\": { \"ConnectionString\": connection_string, \"RelativeLocation\": \"\/\" + storage_container_name + \"\/input1datablob.csv\" },\n        },     \n\n        \"Outputs\": {\n\n            \"output1\": { \"ConnectionString\": connection_string, \"RelativeLocation\": \"\/\" + storage_container_name + \"\/output1results.csv\" },\n        },\n        \"GlobalParameters\": {\n}\n    }\n\n    body = str.encode(json.dumps(payload))\n    headers = { \"Content-Type\":\"application\/json\", \"Authorization\":(\"Bearer \" + api_key)}\n    print(\"Submitting the job...\")\n\n    # If you are using Python 3+, replace urllib2 with urllib.request in the following code\n\n    # submit the job\n    req = urllib.request.Request(url + \"?api-version=2.0\", body, headers)\n    try:\n        response = urllib.request.urlopen(req)\n    except urllib.request.HTTPError:\n        printHttpError(urllib.HTTPError)\n        return\n\n    result = response.read()\n    job_id = result[1:-1] # remove the enclosing double-quotes\n    print(\"Job ID: \" + job_id)\n\n\n    # If you are using Python 3+, replace urllib2 with urllib.request in the following code\n    # start the job\n    print(\"Starting the job...\")\n    req = urllib.request.Request(url + \"\/\" + job_id + \"\/start?api-version=2.0\", \"\", headers)\n    try:\n        response = urllib.request.urlopen(req)\n    except urllib.request.HTTPError:\n        printHttpError(urllib.HTTPError)\n        return\n\n    url2 = url + \"\/\" + job_id + \"?api-version=2.0\"\n\n    while True:\n        print(\"Checking the job status...\")\n        # If you are using Python 3+, replace urllib2 with urllib.request in the follwing code\n        req = urllib.request.Request(url2, headers = { \"Authorization\":(\"Bearer \" + api_key) })\n\n        try:\n            response = urllib.request.urlopen(req)\n        except urllib.request.HTTPError:\n            printHttpError(urllib.HTTPError)\n            return    \n\n        result = json.loads(response.read())\n        status = result[\"StatusCode\"]\n        if (status == 0 or status == \"NotStarted\"):\n            print(\"Job \" + job_id + \" not yet started...\")\n        elif (status == 1 or status == \"Running\"):\n            print(\"Job \" + job_id + \" running...\")\n        elif (status == 2 or status == \"Failed\"):\n            print(\"Job \" + job_id + \" failed!\")\n            print(\"Error details: \" + result[\"Details\"])\n            break\n        elif (status == 3 or status == \"Cancelled\"):\n            print(\"Job \" + job_id + \" cancelled!\")\n            break\n        elif (status == 4 or status == \"Finished\"):\n            print(\"Job \" + job_id + \" finished!\")\n\n            processResults(result)\n            break\n        time.sleep(1) # wait one second\n    return\n\ninvokeBatchExecutionService()\n<\/code><\/pre>\n\n<p>EDIT 2: The above issue has been resolved thanks to jon and the csv gets uploaded in blob storage.<\/p>\n\n<p>However now there is an HTTPError, when the job gets submitted in Line 130:<\/p>\n\n<pre><code>   raise HTTPError(req.full_url, code, msg, hdrs, fp)  HTTPError: Bad Request\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1530205297260,
        "Question_score":0,
        "Question_tags":"python|rest|azure|azure-blob-storage|azure-machine-learning-studio",
        "Question_view_count":499,
        "Owner_creation_time":1513445313103,
        "Owner_last_access_time":1646340377377,
        "Owner_location":"NE",
        "Owner_reputation":29,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Question_last_edit_time":1530279219953,
        "Answer_body":"<p>I think the code they give may be pretty old at this point.<\/p>\n\n<p>The <a href=\"https:\/\/pypi.org\/project\/azure-storage-blob\/#history\" rel=\"nofollow noreferrer\">latest version<\/a> of <code>azure.storage.blob<\/code> is 1.3. So perhaps a <code>pip install azure.storage.blob --update<\/code> or simply uninstalling and reinstalling would help.<\/p>\n\n<p>Once you got the latest version, try using the <code>create_blob_from_text<\/code> method to load the file to your storage container.<\/p>\n\n<pre><code>from azure.storage.blob import BlockBlobService\n\nblobService = BlockBlobService(account_name=\"accountName\", account_key=\"accountKey)\n\nblobService.create_blob_from_text(\"containerName\", \"fileName\", csv_file)\n<\/code><\/pre>\n\n<p>Hope that works to help lead you down the right path, but if not we can work through it. :)<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1530266278530,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51088145",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37520849,
        "Question_title":"Can't approximate simple multiplication function in neural network with 1 hidden layer",
        "Question_body":"<p>I just wanted to test how good can neural network approximate multiplication function (regression task). \nI am using Azure Machine Learning Studio. I have 6500 samples, 1 hidden layer\n(I have tested 5 \/30 \/100 neurons per hidden layer), no normalization. And default parameters \n<a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn906030.aspx\" rel=\"nofollow\">Learning rate - 0.005, Number of learning iterations - 200, The initial learning weigh - 0.1,\n The momentum - 0 [description]<\/a>. I got extremely bad accuracy, close to 0.\n<em>At the same time boosted Decision forest regression shows very good approximation.<\/em><\/p>\n\n<p>What am I doing wrong? This task should be very easy for NN.<\/p>",
        "Question_answer_count":6,
        "Question_comment_count":0,
        "Question_creation_time":1464596393980,
        "Question_score":3,
        "Question_tags":"neural-network|deep-learning|azure-machine-learning-studio",
        "Question_view_count":4342,
        "Owner_creation_time":1354644345813,
        "Owner_last_access_time":1624458498500,
        "Owner_location":null,
        "Owner_reputation":3969,
        "Owner_up_votes":674,
        "Owner_down_votes":17,
        "Owner_views":356,
        "Question_last_edit_time":1491916922983,
        "Answer_body":"<p>Big multiplication function gradient forces the net probably almost immediately into some horrifying state where all its hidden nodes have zero gradient.\nWe can use two approaches:<\/p>\n\n<p>1) Devide by constant. We are just deviding everything before the learning and multiply after.<\/p>\n\n<p>2) Make log-normalization. It makes multiplication into addition:<\/p>\n\n<pre><code>m = x*y =&gt; ln(m) = ln(x) + ln(y).\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1465277784230,
        "Answer_score":5.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":1465820459197,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37520849",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66923216,
        "Question_title":"Change Disk Type Azure ML",
        "Question_body":"<p>I have azure ml , I created compute for learning.\nCost for instance is 2-5usd with my use. But cost for p10(premium SSD) Disk 17usd.<\/p>\n<p>I don't know how change it because its not appear in azure Disk and in ML studio i cant find option for manage storage type for compute.<\/p>\n<p>Some one know how change it ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1617385541497,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":150,
        "Owner_creation_time":1561015783553,
        "Owner_last_access_time":1664083277457,
        "Owner_location":null,
        "Owner_reputation":97,
        "Owner_up_votes":167,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Question_last_edit_time":null,
        "Answer_body":"<p>There is no possible way to change the compute disk type if you use the Azure ML compute cluster and compute instance. Only when you use the extra computer, you can manage the separate resources such as the disk, network, and so on. For example, you attach a VM as the target computer to the Azure ML. Then when you create the VM you can set the disk type with HDD.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1617778657403,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66923216",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68422680,
        "Question_title":"how to write to Azure PipelineData properly?",
        "Question_body":"<p>Im trying to learn Azure, with little luck (yet). All the tutorials show using PipelineData just as a file, when configured in &quot;upload&quot; mode. However, im getting &quot;FileNotFoundError: [Errno 2] No such file or directory: ''&quot; error. I would love to ask a more specific question, but i just can't see what im doing wrong.<\/p>\n<pre><code>from azureml.core import Workspace, Datastore,Dataset,Environment\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.pipeline.steps import PythonScriptStep\nfrom azureml.pipeline.core import Pipeline, PipelineData\nimport os\n\nws = Workspace.from_config()\ndatastore = ws.get_default_datastore()\n\ncompute_name = &quot;cpucluster&quot;\ncompute_target = ComputeTarget(workspace=ws, name=compute_name)\naml_run_config = RunConfiguration()\naml_run_config.target = compute_target\naml_run_config.environment.python.user_managed_dependencies = False\naml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n    conda_packages=['pandas','scikit-learn'], \n    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n    pin_sdk_version=False)\n\noutput1 = PipelineData(&quot;processed_data1&quot;,datastore=datastore, output_mode=&quot;upload&quot;)\nprep_step = PythonScriptStep(\n    name=&quot;dataprep&quot;,\n    script_name=&quot;dataprep.py&quot;,\n    source_directory=os.path.join(os.getcwd(),'dataprep'),\n    arguments=[&quot;--output&quot;, output1],\n    outputs = [output1],\n    compute_target=compute_target,\n    runconfig=aml_run_config,\n    allow_reuse=True\n)\n<\/code><\/pre>\n<p>In the dataprep.py i hve the following:<\/p>\n<pre><code>import numpy, argparse, pandas\nfrom azureml.core import Run\nrun = Run.get_context()\nparser = argparse.ArgumentParser()\nparser.add_argument('--output', dest='output', required=True)\nargs = parser.parse_args()\ndf = pandas.DataFrame(numpy.random.rand(100,3))\ndf.iloc[:, 2] = df.iloc[:,0] + df.iloc[:,1]\nprint(df.iloc[:5,:])\ndf.to_csv(args.output)\n\n<\/code><\/pre>\n<p>So, yeah. pd is supposed to write to the output, but my compute cluster says the following:<\/p>\n<pre><code>&quot;User program failed with FileNotFoundError: [Errno 2] No such file or directory: ''\\&quot;.\n<\/code><\/pre>\n<p>When i dont include the to_csv() function, the cluster does not complain<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1626541888290,
        "Question_score":4,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":404,
        "Owner_creation_time":1588424911653,
        "Owner_last_access_time":1664069253107,
        "Owner_location":null,
        "Owner_reputation":59,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":1626559748577,
        "Answer_body":"<p>Here is an <a href=\"https:\/\/github.com\/james-tn\/highperformance_python_in_azure\/blob\/master\/parallel_python_processing\/pipeline_definition.ipynb\" rel=\"nofollow noreferrer\">example<\/a> for PRS.\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipelinedata?view=azure-ml-py\" rel=\"nofollow noreferrer\">PipelineData<\/a> was intended to represent &quot;transient&quot; data from one step to the next one, while OutputDatasetConfig was intended for capturing the final state of a dataset (and hence why you see features like lineage, ADLS support, etc). PipelineData always outputs data in a folder structure like {run_id}{output_name}. OutputDatasetConfig allows to decouple the data from the run and hence it allows you to control where to land the data (although by default it will produce similar folder structure). The OutputDatasetConfig allows even to register the output as a Dataset, where getting rid of such folder structure makes sense. From the docs itself: &quot;Represent how to copy the output of a run and be promoted as a FileDataset. The OutputFileDatasetConfig allows you to specify how you want a particular local path on the compute target to be uploaded to the specified destination&quot;.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-batch-scoring-classification#create-dataset-objects\" rel=\"nofollow noreferrer\">OutFileDatasetConfig<\/a> is a control plane concept to pass data between pipeline steps.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1626667519373,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1626668067887,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68422680",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58040933,
        "Question_title":"Error in connecting Azure SQL database from Azure Machine Learning Service using python",
        "Question_body":"<p>I am trying to connect <strong>Azure SQL Database<\/strong> from <strong>Azure Machine Learning service<\/strong>, but I got the below error.<\/p>\n\n<p><strong>Please check Error: -<\/strong><\/p>\n\n<pre><code>**('IM002', '[IM002] [unixODBC][Driver Manager]Data source name not found and no default driver specified (0) (SQLDriverConnect)')**\n<\/code><\/pre>\n\n<p>Please Check the below code that I have used for database connection: -<\/p>\n\n<pre><code>import pyodbc\n\nclass DbConnect:\n    # This class is used for azure database connection using pyodbc\n    def __init__(self):\n        try:\n            self.sql_db = pyodbc.connect(SERVER=&lt;servername&gt;;PORT=1433;DATABASE=&lt;databasename&gt;;UID=&lt;username&gt;;PWD=&lt;password&gt;')\n\n            get_name_query = \"select name from contacts\"\n            names = self.sql_db.execute(get_name_query)\n            for name in names:\n                print(name)\n\n        except Exception as e:\n            print(\"Error in azure sql server database connection : \", e)\n            sys.exit()\n\nif __name__ == \"__main__\":\n    class_obj = DbConnect()\n<\/code><\/pre>\n\n<p>Is there any way to solve the above error? Please let me know if there is any way.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1569073789150,
        "Question_score":1,
        "Question_tags":"python|sql|azure|azure-sql-database|azure-machine-learning-service",
        "Question_view_count":1013,
        "Owner_creation_time":1554466050937,
        "Owner_last_access_time":1578409023530,
        "Owner_location":null,
        "Owner_reputation":219,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I'd consider using <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-dataprep\/azureml.dataprep?view=azure-dataprep-py\" rel=\"nofollow noreferrer\"><code>azureml.dataprep<\/code><\/a> over pyodbc for this task (the API may change, but this worked last time I tried):<\/p>\n\n<pre><code>import azureml.dataprep as dprep\n\nds = dprep.MSSQLDataSource(server_name=&lt;server-name,port&gt;,\n                           database_name=&lt;database-name&gt;,\n                           user_name=&lt;username&gt;,\n                           password=&lt;password&gt;)\n<\/code><\/pre>\n\n<p>You should then be able to collect the result of an SQL query in pandas e.g. via<\/p>\n\n<pre><code>dataflow = dprep.read_sql(ds, \"SELECT top 100 * FROM [dbo].[MYTABLE]\")\ndataflow.to_pandas_dataframe()\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1569108921710,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1569146709727,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58040933",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58500807,
        "Question_title":"Run failed: User program failed with ModuleNotFoundError: No module named 'amlrun' in Azure ML Experiment",
        "Question_body":"<p>I'm using VS Code to submit a Machine Learning experiment in Azure Portal. When running the experiment I'm obtaining the following error:<\/p>\n\n<p>Run failed: User program failed with ModuleNotFoundError: No module named 'amlrun'<\/p>\n\n<p>This is the code structure:<\/p>\n\n<p>.vscode (json configuration file)<\/p>\n\n<p>aml_config<\/p>\n\n<p>scripts<\/p>\n\n<p>----- amlrun.py (a script with some functions)<\/p>\n\n<p>----- model_training.py (a script creating and saving the model)<\/p>\n\n<p>This is the configuration file:<\/p>\n\n<pre><code>{\n    \"script\": \"model_training.py\",\n    \"framework\": \"Python\",\n    \"communicator\": \"None\",\n    \"target\": \"testazure\",\n    \"environment\": {\n        \"python\": {\n            \"userManagedDependencies\": false,\n            \"condaDependencies\": {\n                \"dependencies\": [\n                    \"python=3.6.2\",\n                    \"scikit-learn\",\n                    \"numpy\",\n                    \"pandas\",\n                    {\n                        \"pip\": [\n                            \"azureml-defaults\"\n                        ]\n                    }\n                ]\n            }\n        },\n        \"docker\": {\n            \"baseImage\": \"mcr.microsoft.com\/azureml\/base:0.2.4\",\n            \"enabled\": true,\n            \"baseImageRegistry\": {\n                \"address\": null,\n                \"username\": null,\n                \"password\": null\n            }\n        }\n    },\n    \"history\": {\n        \"outputCollection\": true,\n        \"snapshotProject\": false,\n        \"directoriesToWatch\": [\n            \"logs\"\n        ]\n    }\n}\n<\/code><\/pre>\n\n<p>Am I missing something?\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1571735433200,
        "Question_score":2,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":901,
        "Owner_creation_time":1547138031703,
        "Owner_last_access_time":1607969329513,
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Question_last_edit_time":null,
        "Answer_body":"<p>When your training script is running in azure, it's not able to find all your local imports i.e. <code>amlrun.py<\/code> script. <\/p>\n\n<p>The submitted training job to azure builds a docker image with your files first and runs the experiment; but in this case the extension hasn't included <code>amlrun.py<\/code>. <\/p>\n\n<p>This is probably because when you have submit the training job with the extension, the visual studio code window opened is not pointing to be in <code>scripts<\/code> folder.<\/p>\n\n<p>Taken from one of the replies to a <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/24032\" rel=\"nofollow noreferrer\">previously raised github issue<\/a>:<\/p>\n\n<blockquote>\n  <p>The extension currently requires the script you are working on to be\n  in the folder that is open in VS Code and not in a sub-directory.<\/p>\n<\/blockquote>\n\n<hr>\n\n<p>To fix this you can do <strong>either<\/strong> of the following:<\/p>\n\n<ol>\n<li><p>You would need to re-open Visual Studio Code in <code>scripts<\/code> folder instead of parent directory.<\/p><\/li>\n<li><p>Move all files in <code>script<\/code> directory to be in it's parent directory.<\/p><\/li>\n<\/ol>\n\n<hr>\n\n<p>If you're looking for more flexible way to submit training jobs and managing aml - you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/intro?view=azure-ml-py\" rel=\"nofollow noreferrer\">azure machine learning sdk<\/a> for python.<\/p>\n\n<p>Some examples of using the SDK to manage expirements can be found in the links below:<\/p>\n\n<ol>\n<li><p><a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/service\/tutorial-train-models-with-aml.md\" rel=\"nofollow noreferrer\">Scikit Learn Model Training Docs<\/a> <\/p><\/li>\n<li><p><a href=\"https:\/\/github.com\/rithinch\/heartfulness-similar-content-service\" rel=\"nofollow noreferrer\">Basic Pytorch Model Training and Deployment Example Repo<\/a><\/p><\/li>\n<\/ol>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1571837118727,
        "Answer_score":1.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":1571838372440,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58500807",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60523435,
        "Question_title":"How do I version control Azure ML workspaces with custom environments and pipelines?",
        "Question_body":"<p>I'm trying to figure out how viable Azure ML in production; I would like to accomplish the following:<\/p>\n\n<ol>\n<li>Specify <em>custom environments<\/em> for my pipelines using a <em>pip file<\/em> and use them in a pipeline<\/li>\n<li><em>Declaratively<\/em> specify my workspace, environments and pipelines in an <em>Azure DevOps repo<\/em><\/li>\n<li><em>Reproducibly<\/em> deploy my Azure ML workspace to my subscription using an <em>Azure DevOps pipeline<\/em><\/li>\n<\/ol>\n\n<p>I found an <a href=\"https:\/\/stackoverflow.com\/questions\/60506398\/how-do-i-use-an-environment-in-an-ml-azure-pipeline\">explanation of how to specify environments using notebooks<\/a> but this seems ill-suited for the second and third requirements I have.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1583316022363,
        "Question_score":1,
        "Question_tags":"azure|azure-devops|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":659,
        "Owner_creation_time":1317398821727,
        "Owner_last_access_time":1660507764847,
        "Owner_location":null,
        "Owner_reputation":1263,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":44,
        "Question_last_edit_time":1583348292107,
        "Answer_body":"<p>Currently, we have a python script, <code>pipeline.py<\/code> that uses the <code>azureml-sdk<\/code>to create, register and run all of our ML artifacts (envs, pipelines, models). We call this script in our Azure DevOps CI pipeline with a Python Script task after building the right pip env from the requirements file in our repo.<\/p>\n\n<p>However, it is worth noting there is YAML support for ML artifact definition. Though I don't know if the existing support will cover all of your bases (though that is the plan).<\/p>\n\n<p>Here's some great docs from MSFT to get you started:<\/p>\n\n<ul>\n<li><a href=\"https:\/\/github.com\/microsoft\/MLOpsPython\" rel=\"nofollow noreferrer\">GitHub Template repo of an end-to-end example of ML pipeline + deployment<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments\" rel=\"nofollow noreferrer\">How to define\/create an environment (using Pip or Conda) and use it in a remote compute context<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/devops\/pipelines\/targets\/azure-machine-learning?context=azure%2Fmachine-learning%2Fservice%2Fcontext%2Fml-context&amp;view=azure-devops&amp;tabs=yaml\" rel=\"nofollow noreferrer\">Azure Pipelines guidance on CI\/CD for ML Service<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-pipeline-yaml\" rel=\"nofollow noreferrer\">Defining ML pipelines in YAML<\/a><\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1583340584893,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1583340824233,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60523435",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58323029,
        "Question_title":"Azure ML deploy locally: tarfile.ReadError: file could not be opened successfully",
        "Question_body":"<p>I am trying to deploy(local) using this line:<\/p>\n\n<pre><code>local_service = Model.deploy(ws, \"test\", [model], inference_config, deployment_config)\n<\/code><\/pre>\n\n<p>Then I get this output in the terminal:<\/p>\n\n<pre><code>tarfile.ReadError: file could not be opened successfully\n<\/code><\/pre>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WXbPe.png\" rel=\"nofollow noreferrer\">Screenshot of the output<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1570710941163,
        "Question_score":1,
        "Question_tags":"python|deployment|azure-machine-learning-service",
        "Question_view_count":77,
        "Owner_creation_time":1570704481987,
        "Owner_last_access_time":1594546331983,
        "Owner_location":null,
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>There was a bug with the retry logic when files were being uploaded. That bug has since been fixed, so updating your SDK should fix the issue.<\/p>\n\n<p>Similar post: <a href=\"https:\/\/stackoverflow.com\/questions\/57854136\/registering-and-downloading-a-fasttext-bin-model-fails-with-azure-machine-learn\">Registering and downloading a fastText .bin model fails with Azure Machine Learning Service<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1570725963837,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58323029",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69036277,
        "Question_title":"Run independent `PythonScriptStep` steps in parallel",
        "Question_body":"<p>In my pipeline multiple steps are independent and so I would like them to run in parallel based on input dependencies.<\/p>\n<p>As the compute I use has multiple nodes I would have expected this to be the default.<\/p>\n<p>For example:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Iye85.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Iye85.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>All 3 upper steps should run in parallel, then both <code>finetune<\/code> steps in parallel as soon as their inputs are satisfied and the same for <code>rgb_test<\/code>.<\/p>\n<p>Currently only 1 step runs at a time, the other are <code>Queued<\/code>.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1630612166280,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":156,
        "Owner_creation_time":1327588060553,
        "Owner_last_access_time":1664036801580,
        "Owner_location":null,
        "Owner_reputation":802,
        "Owner_up_votes":288,
        "Owner_down_votes":0,
        "Owner_views":91,
        "Question_last_edit_time":null,
        "Answer_body":"<p>It ended up being because of vCPU quota.<\/p>\n<p>After increasing the quota, parallel tasks can run at the same time as expected.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1632769372630,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69036277",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":33229576,
        "Question_title":"Arduino Uno - WebService (AzureML)",
        "Question_body":"<p>I'd like to connect to an AzureML Web Service. I have looked into the POST Method on the Arduino Homepage and also here <a href=\"https:\/\/iotguys.wordpress.com\/2014\/12\/25\/communicating-with-microsoft-azure-eventhub-using-arduino\/\" rel=\"nofollow\">https:\/\/iotguys.wordpress.com\/2014\/12\/25\/communicating-with-microsoft-azure-eventhub-using-arduino\/<\/a><\/p>\n\n<p>Here is my Setup method:<\/p>\n\n<pre><code>    void setup()\n    {\n      Serial.begin(9600);\n      while (!Serial) {\n      ; \/\/ wait for serial port to connect.\n      }\n\n     Serial.println(\"ethernet\");\n\n     if (Ethernet.begin(mac) == 0) {\n       Serial.println(\"ethernet failed\");\n       for (;;) ;\n     }\n    \/\/ give the Ethernet shield a second to initialize:\n    delay(1000);\n }\n<\/code><\/pre>\n\n<p>The Post Method is based on this: <a href=\"http:\/\/playground.arduino.cc\/Code\/WebClient\" rel=\"nofollow\">http:\/\/playground.arduino.cc\/Code\/WebClient<\/a><\/p>\n\n<p>I just added <code>sprintf(outBuf, \"Authorization: Bearer %s\\r\\n\", api_key);<\/code> to the header, with <code>char* api_key = \"the ML Web Service API KEY\"<\/code><\/p>\n\n<p>Also, unlike specified in the WebClient I use the whole WebService URI as url and do not specify a page name.<\/p>\n\n<p>This doesn't work.<\/p>\n\n<p>The Network to which I am connecting has Internet Access.<\/p>\n\n<p>What am I doing wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1445322870153,
        "Question_score":0,
        "Question_tags":"web-services|azure|arduino-uno|azure-machine-learning-studio",
        "Question_view_count":154,
        "Owner_creation_time":1369151239453,
        "Owner_last_access_time":1653069662220,
        "Owner_location":"Germany",
        "Owner_reputation":516,
        "Owner_up_votes":5,
        "Owner_down_votes":1,
        "Owner_views":57,
        "Question_last_edit_time":1459290344957,
        "Answer_body":"<p>Machine Learning Studio services that you create needs to receive requests from a device that has SSL capabilities to perform HTTPS requests. AFAIK, Arduino doesn't support SSL capabilities.<\/p>\n\n<p>One usual scenario is to attach the Arduino to a third device like Raspberry Pi 2 etc to use it as a gateway and do the call from the Pi itself.<\/p>\n\n<p>Here's a sample <a href=\"https:\/\/github.com\/Azure\/connectthedots\/blob\/master\/GettingStarted.md\" rel=\"nofollow\">project<\/a> from Microsoft Open Technologies team that utilizes Arduino Uno, Raspberry pi and Azure stuff.<\/p>\n\n<p>Hope this helps!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1450337261483,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1450346645647,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/33229576",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72518344,
        "Question_title":"Logging and Fetching Run Parameters in AzureML",
        "Question_body":"<p>I am able to log and fetch metrics to AzureML using Run.log, however, I need a way to also log run parameters, like Learning Rate, or Momentum. I can't seem to find anything in the AzureML Python SDK documentation to achieve this. However, if I use MLflow's mlflow.log_param, I am able to log parameters, and they even nicely show up on the AzureML Studio Dashboard (bottom right of the image):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/q9b7Q.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/q9b7Q.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Again, I am able to fetch this using MLflow's get_params() function, but I can't find a way to do this using just AzureML's Python SDK. Is there a way to do this directly using <code>azureml<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1654521747343,
        "Question_score":0,
        "Question_tags":"azure|mlflow|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":73,
        "Owner_creation_time":1554497484963,
        "Owner_last_access_time":1664005308093,
        "Owner_location":"Hyderabad, Telangana, India",
        "Owner_reputation":438,
        "Owner_up_votes":15,
        "Owner_down_votes":2,
        "Owner_views":120,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The retrieving of log run parameters like <strong>Learning Rate, or Momentum<\/strong> is not possible with <strong>AzureML<\/strong> alone. Because it was tied with <strong>MLFlow<\/strong> and <strong>azureml-core<\/strong>. without those two involvements, we cannot retrieve the log run parameters.<\/p>\n<pre><code>pip install azureml-core mlflow azureml-mlflow\n<\/code><\/pre>\n<p>Need to install these three for getting run parameters. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Link<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1656998954310,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72518344",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58060865,
        "Question_title":"Deploy Azure Machine Learning models using Custom Docker Image on Azure Container Regisrty",
        "Question_body":"<p>I want to train <strong>Azure Machine Learning model<\/strong> on azure using <strong>Azure Machine Learning Service.<\/strong> But I want to use the <strong>custom Docker image<\/strong> for deploying the model on azure. I am not able to understand how to deploy Machine Learning models using Custom Docker Image.<\/p>\n\n<p>Please share me if there is any tutorial or blog about the deploy ml models using a custom image.<\/p>\n\n<p>Please check the below Docker file commands:-<\/p>\n\n<pre><code># Set locale\nRUN apt-get update\nRUN apt-get install locales\nRUN locale-gen en_US.UTF-8\nRUN update-locale LANG=en_US.UTF-8\n\n# Install MS SQL v13 driver for PyOdbc\nRUN apt-get install -y curl\nRUN apt-get install apt-transport-https\nRUN curl https:\/\/packages.microsoft.com\/keys\/microsoft.asc | apt-key add - \nRUN curl https:\/\/packages.microsoft.com\/config\/ubuntu\/16.04\/prod.list &gt; \/etc\/apt\/sources.list.d\/mssql-release.list\nRUN exit\nRUN apt-get update\n\nRUN ACCEPT_EULA=Y apt-get install -y msodbcsql\nRUN apt-get install -y unixodbc-dev\n<\/code><\/pre>\n\n<p>I want to use the <strong>Azure Container Registry<\/strong> for push the docker image and use the <strong>Custom Docker Image.<\/strong> Please let me know if there is any way.<\/p>\n\n<p><strong>Is there any way to Deploy Azure ML Models using Custom docker images?<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1569236101160,
        "Question_score":0,
        "Question_tags":"python|python-3.x|azure|docker|azure-machine-learning-service",
        "Question_view_count":864,
        "Owner_creation_time":1554466050937,
        "Owner_last_access_time":1578409023530,
        "Owner_location":null,
        "Owner_reputation":219,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":35,
        "Question_last_edit_time":1569244969490,
        "Answer_body":"<p>You can do following:<\/p>\n\n<ol>\n<li>Create an [Environment][1] with the coordinates of your custom Docker image specified in Docker section.<\/li>\n<li>Create [InferenceConfig][2] with that Environment as argument, and use it when deploying the model.<\/li>\n<\/ol>\n\n<p>For example, assuming you have a model already and eliding other arguments:<\/p>\n\n<pre><code>from azureml.core.environment import Environment\nfrom azureml.core.model import InferenceConfig\n\nenv = Environment(name=\"myenv\")\nenv.docker.base_image = \"mybaseimage\"\nenv.docker.base_image_registry.address = \"ip-address\"\nenv.docker.base_image_registry.username = \"my-username\"\nenv.docker.base_image_registry.password = \"my-password\"\n\nic = InferenceConfig(\u2026,environment = env)\nmodel.deploy(\u2026,inference_config = ic)\n<\/code><\/pre>\n\n<pre><code>\n  [1]: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.environment.environment?view=azure-ml-py\n  [2]: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.inferenceconfig?view=azure-ml-py\n<\/code><\/pre>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1569245799797,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1569412440893,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58060865",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56240481,
        "Question_title":"Can I import data from On-Premises SQL Server Database to Azure Machine Learning virtual machine?",
        "Question_body":"<p>On the limited Azure Machine Learning Studio, one can import data from an On-Premises SQL Server Database.\nWhat about the ability to do the exact same thing on a python jupyter notebook on a virtual machine from the Azure Machine Learning Services workspace ?<\/p>\n\n<p>It does not seem possible from what I've found in the documentation.\nData sources would be limited in Azure ML Services : \"Currently, the list of supported Azure storage services that can be registered as datastores are Azure Blob Container, Azure File Share, Azure Data Lake, Azure Data Lake Gen2, Azure SQL Database, Azure PostgreSQL, and Databricks File System\"<\/p>\n\n<p>Thank you in advance for your assistance<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1558448804447,
        "Question_score":0,
        "Question_tags":"python|sql|azure|jupyter-notebook|azure-machine-learning-service",
        "Question_view_count":1147,
        "Owner_creation_time":1558447987353,
        "Owner_last_access_time":1650446213527,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":null,
        "Answer_body":"<p>As of today, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-load-data#load-sql-data\" rel=\"nofollow noreferrer\">you can load SQL data, but only a MS SQL Server source (also on-premise) is supported<\/a>.<\/p>\n\n<p>Using <code>azureml.dataprep<\/code>, code would read along the lines of<\/p>\n\n<pre><code>import azureml.dataprep as dprep\n\nsecret = dprep.register_secret(value=\"[SECRET-PASSWORD]\", id=\"[SECRET-ID]\")\n\nds = dprep.MSSQLDataSource(server_name=\"[SERVER-NAME]\",\n                           database_name=\"[DATABASE-NAME]\",\n                           user_name=\"[DATABASE-USERNAME]\",\n                           password=secret)\n\ndflow = dprep.read_sql(ds, \"SELECT top 100 * FROM [YourDB].[ATable]\")\n# print first records\ndflow.head(5)\n<\/code><\/pre>\n\n<p>As far as I understand the APIs are under heavy development and <code>azureml.dataprep<\/code> may be soon superseded by functionality provided by the <a href=\"https:\/\/aka.ms\/azureml\/concepts\/datasets\" rel=\"nofollow noreferrer\">Dataset class<\/a>.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1558479194140,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56240481",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66348756,
        "Question_title":"Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core",
        "Question_body":"<p>According to this documentation:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py<\/a><\/p>\n<p>training_data can be either a dataframe or a dataset.<\/p>\n<p>However when I use a dataframe I get this error:<\/p>\n<pre><code>\nConfigException: ConfigException:\n    Message: Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset]\n    InnerException: None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset]&quot;,\n        &quot;details_uri&quot;: &quot;https:\/\/aka.ms\/AutoMLConfig&quot;,\n        &quot;target&quot;: &quot;training_data&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;BadArgument&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;ArgumentInvalid&quot;,\n                &quot;inner_error&quot;: {\n                    &quot;code&quot;: &quot;InvalidInputDatatype&quot;\n                }\n            }\n        }\n    }\n}\n<\/code><\/pre>\n<p>My code is really simple:<\/p>\n<pre><code>\nclient = CosmosClient(HOST, MASTER_KEY)\ndatabase = client.get_database_client(database=DATABASE_ID)\ncontainer = database.get_container_client(CONTAINER_ID)\n\nitem_list = list(container.read_all_items(max_item_count=10))\ndf = pd.DataFrame(item_list)\n\nfrom azureml.core.workspace import Workspace\nws = Workspace.from_config()\n\nfrom azureml.automl.core.forecasting_parameters import ForecastingParameters\n\nforecasting_parameters = ForecastingParameters(time_column_name='EventEnqueuedUtcTime', \n                                               forecast_horizon=50,\n                                               time_series_id_column_names=[&quot;eui&quot;],\n                                               freq='H',\n                                               target_lags='auto',\n                                               target_rolling_window_size=10)\n\nfrom azureml.core.workspace import Workspace\nfrom azureml.core.experiment import Experiment\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nimport logging\n\namlcompute_cluster_name = &quot;computecluster&quot;\ncompute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\nexperiment_name = 'iot-forecast'\n\nexperiment = Experiment(ws, experiment_name)\n\nautoml_config = AutoMLConfig(task='forecasting',\n                             primary_metric='normalized_root_mean_squared_error',\n                             experiment_timeout_minutes=100,\n                             enable_early_stopping=True,\n                             training_data=df,\n                             compute_target = compute_target,\n                             label_column_name='TempC_DS',\n                             n_cross_validations=5,\n                             enable_ensembling=False,\n                             verbosity=logging.INFO,\n                             forecasting_parameters=forecasting_parameters)\n\nremote_run = experiment.submit(automl_config, show_output=True)\n<\/code><\/pre>\n<p>what am I missing here?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1614161544217,
        "Question_score":1,
        "Question_tags":"python|python-3.x|pandas|machine-learning|azure-machine-learning-studio",
        "Question_view_count":315,
        "Owner_creation_time":1302030303093,
        "Owner_last_access_time":1663332147473,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Looks like you are trying to run the experiment remotely, AFAIK and as per the doc <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#data-source-and-format?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">here<\/a> :<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/CXYyE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/CXYyE.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>You could refer this article to understand creating <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">Azure ML TabularDataset<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1614750517020,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66348756",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63811726,
        "Question_title":"How to execute python commands from a conda .yaml specification file?",
        "Question_body":"<p>I am trying to list conda dependencies using a .yaml file for an AzureML <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#define-an-inference-configuration\" rel=\"nofollow noreferrer\">environment<\/a>. I do not want to use a custom docker image just for a few variations. I wonder if there is a way to instruct the build to run python commands using the .yaml file. Here are excerpts of what I have tried as of now:<\/p>\n<pre><code>name: classifer_environment\ndependencies:\n- python=3.6.2\n\n- pip:\n  - azureml-defaults&gt;=1.0.45\n  - nltk==3.4.5\n  - spacy\n\n- command: \n  - bash -c &quot;python -m nltk.downloader stopwords&quot;\n  - bash -c &quot;python -m spacy download en_core_web_sm&quot;\n<\/code><\/pre>\n<p>I also tried this:<\/p>\n<pre><code>name: classifer_environment\ndependencies:\n- python=3.6.2\n\n- pip:\n  - azureml-defaults&gt;=1.0.45\n  - nltk==3.4.5\n  - spacy\n\n- python: \n  - nltk.downloader stopwords\n  - spacy download en_core_web_sm\n<\/code><\/pre>\n<p>I do not have much clarity about yaml specifications. Both the specifications fail with the following messages respectively in the build logs: <br>\n&quot;Unable to install package for command.&quot; <br>\n&quot;Unable to install package for python.&quot;<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1599654539997,
        "Question_score":0,
        "Question_tags":"python-3.x|yaml|conda|azure-machine-learning-service",
        "Question_view_count":408,
        "Owner_creation_time":1555424023330,
        "Owner_last_access_time":1663862330683,
        "Owner_location":"Bhubaneswar, Odisha, India",
        "Owner_reputation":328,
        "Owner_up_votes":31,
        "Owner_down_votes":4,
        "Owner_views":53,
        "Question_last_edit_time":null,
        "Answer_body":"<p>This might be a neat feature to have, but for now it's not a thing - at least not directly in the YAML like this.<\/p>\n<p>Instead, the unit of computation in Conda is the <em>package<\/em>. That is, if you need to run additional scripts or commands at environment creation, it can be achieved by building a custom package and including this package in the YAML as a dependency. The package itself could be pretty much empty, but whatever code one needs to run would be included via <a href=\"https:\/\/docs.conda.io\/projects\/conda-build\/en\/latest\/resources\/link-scripts.html\" rel=\"nofollow noreferrer\">some installation scripts<\/a>.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1599673418303,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63811726",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52003180,
        "Question_title":"How to understand output from a Multiclass Neural Network",
        "Question_body":"<p>Built a flow in Azure ML using a Neural network Multiclass module (for settings see picture). \n <a href=\"https:\/\/i.stack.imgur.com\/6xTYY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6xTYY.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Some more info about the Multiclass:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/lLUVC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/lLUVC.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The data flow is simple, split of 80\/20. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/k72ZX.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/k72ZX.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Preparation of the data is made before it goes into Azure. Data looks like this: <a href=\"https:\/\/i.stack.imgur.com\/SoSUa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/SoSUa.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>My problem comes when I want to make sense of the output and if possible transform\/calculate the output to probabilities. Output looks like this: <a href=\"https:\/\/i.stack.imgur.com\/kBZOM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kBZOM.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>My question: If scored probabilities output for my model is 0.6 and scored labels = 1, how sure is the model of the scored labels 1? And how sure can I be that actual outcome will be a 1?<\/p>\n\n<p>Can I safely assume that a scored probabilities of 0.80 = 80% chance of outcome? Or what type of outcomes should I watch out for?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_time":1535108970810,
        "Question_score":0,
        "Question_tags":"machine-learning|neural-network|azure-machine-learning-studio|multiclass-classification",
        "Question_view_count":263,
        "Owner_creation_time":1466013021617,
        "Owner_last_access_time":1550758296713,
        "Owner_location":"Malm\u00f6, Sverige",
        "Owner_reputation":103,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":54,
        "Question_last_edit_time":1535126329423,
        "Answer_body":"<p>To start with, your are in a <em>binary<\/em> classification setting, not in a multi-class one (we normally use this term when number of classes > 2).<\/p>\n\n<blockquote>\n  <p>If scored probabilities output for my model is 0.6 and scored labels = 1, how sure is the model of the scored labels 1? <\/p>\n<\/blockquote>\n\n<p>In <em>practice<\/em>, the scored probabilities are routinely interpreted as the <em>confidence<\/em> of the model; so, in this example, we would say that your model has 60% confidence that the particular sample belongs to class 1 (and, complementary, 40% confidence that it belongs to class 0).<\/p>\n\n<blockquote>\n  <p>And how sure can I be that actual outcome will be a 1?<\/p>\n<\/blockquote>\n\n<p>If you don't have any alternate means of computing such outcomes yourself (e.g. a different model), I cannot see how this question is different from your previous one.<\/p>\n\n<blockquote>\n  <p>Can I safely assume that a scored probabilities of 0.80 = 80% chance of outcome? <\/p>\n<\/blockquote>\n\n<p>This is the kind of statement that would drive a professional statistician mad; nevertheless, the clarifications above regarding the confidence should be enough for your purposes (they are enough indeed for ML practitioners).<\/p>\n\n<p>My answer in <a href=\"https:\/\/stackoverflow.com\/questions\/51367755\/predict-classes-or-class-probabilities\/51423325#51423325\">Predict classes or class probabilities?<\/a> should also be helpful.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1535111519160,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1535111877860,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52003180",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36450108,
        "Question_title":"Azure Recommendations API's Parameter",
        "Question_body":"<p>I would like to make a recommendation model using Recommendations API on Azure MS Cognitive Services. I can't understand three API's parameters below for \"Create\/Trigger a build.\" What do these parameters mean?<\/p>\n\n<p><a href=\"https:\/\/westus.dev.cognitive.microsoft.com\/docs\/services\/Recommendations.V4.0\/operations\/56f30d77eda5650db055a3d0\" rel=\"nofollow\">https:\/\/westus.dev.cognitive.microsoft.com\/docs\/services\/Recommendations.V4.0\/operations\/56f30d77eda5650db055a3d0<\/a><\/p>\n\n<blockquote>\n  <p>EnableModelingInsights<br> Allows you to compute metrics on the\n  recommendation model. <br> Valid Values: True\/False<\/p>\n  \n  <p>AllowColdItemPlacement<br> Indicates if the recommendation should also\n  push cold items via feature similarity. <br> Valid Values: True\/False<\/p>\n  \n  <p>ReasoningFeatureList<br> Comma-separated list of feature names to be\n  used for reasoning sentences (e.g. recommendation explanations).<br>\n  Valid Values: Feature names, up to 512 chars<\/p>\n<\/blockquote>\n\n<p>Thank you!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1459942893017,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":279,
        "Owner_creation_time":1459941581603,
        "Owner_last_access_time":1469314422527,
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Question_last_edit_time":null,
        "Answer_body":"<p>That page is missing references to content mentioned at other locations.  See this page for a more complete guide...<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-recommendation-api-documentation\/\" rel=\"nofollow\">https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-recommendation-api-documentation\/<\/a><\/p>\n\n<p>It describes Cold Items in the Rank Build section in the document as...<\/p>\n\n<p>Features can enhance the recommendation model, but to do so requires the use of meaningful features. For this purpose a new build was introduced - a rank build. This build will rank the usefulness of features. A meaningful feature is a feature with a rank score of 2 and up. After understanding which of the features are meaningful, trigger a recommendation build with the list (or sublist) of meaningful features. It is possible to use these feature for the enhancement of both warm items and cold items. In order to use them for warm items, the UseFeatureInModel build parameter should be set up. In order to use features for cold items, the AllowColdItemPlacement build parameter should be enabled. Note: It is not possible to enable AllowColdItemPlacement without enabling UseFeatureInModel.<\/p>\n\n<p>It also describes the ReasoningFeatureList in the Recommendation Reasoning section as...<\/p>\n\n<p>Recommendation reasoning is another aspect of feature usage. Indeed, the Azure Machine Learning Recommendations engine can use features to provide recommendation explanations (a.k.a. reasoning), leading to more confidence in the recommended item from the recommendation consumer. To enable reasoning, the AllowFeatureCorrelation and ReasoningFeatureList parameters should be setup prior to requesting a recommendation build.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1460495281970,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36450108",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37418265,
        "Question_title":"Azure Machine Learning using Javascript Ajax call",
        "Question_body":"<p>I wanted to know if there is a way to call the Azure Machine Learning webservice using JavaScript Ajax.<\/p>\n\n<p>The Azure ML gives sample code for C#, Python and R.<\/p>\n\n<p>I did try out to call the webservice using JQuery Ajax but it returns a failure.<\/p>\n\n<p>I am able to call the same service using a python script.<\/p>\n\n<p>Here is my Ajax code : <\/p>\n\n<pre><code>  $.ajax({\n        url: webserviceurl,\n        type: \"POST\",           \n        data: sampleData,            \n        dataType:'jsonp',                        \n        headers: {\n        \"Content-Type\":\"application\/json\",            \n        \"Authorization\":\"Bearer \" + apiKey                       \n        },\n        success: function (data) {\n          console.log('Success');\n        },\n        error: function (data) {\n           console.log('Failure ' +  data.statusText + \" \" + data.status);\n        },\n  });\n<\/code><\/pre>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_time":1464104729493,
        "Question_score":2,
        "Question_tags":"javascript|ajax|azure|azure-machine-learning-studio",
        "Question_view_count":1607,
        "Owner_creation_time":1460664823627,
        "Owner_last_access_time":1504814384707,
        "Owner_location":null,
        "Owner_reputation":81,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1526047792277,
        "Answer_body":"<p>Well after a lot of RnD, I was able to finally call Azure ML using some workarounds.<\/p>\n\n<p>Wrapping Azure ML webservice on Azure API is one option.<\/p>\n\n<p>But, what I did was that I created a python webservice which calls the Azure webservice.<\/p>\n\n<p>So now my HTML App calls the python webservice which calls Azure ML and returns data to the HTML App.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1464718210400,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37418265",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":31130629,
        "Question_title":"Azure ML web service times out",
        "Question_body":"<p>I have created a simple experiment in Azure ML and trigger it with an http client. In Azure ML workspace, everything works ok when executed. However, the experiment times out and fails when I trigger the experiment using an http client. Setting a timeout value for the http client does not seem to work.<\/p>\n\n<p>Is there any way we can set this timeout value so that the experiment does not fail?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1435643857760,
        "Question_score":2,
        "Question_tags":"c#|azure|azure-machine-learning-studio",
        "Question_view_count":1681,
        "Owner_creation_time":1313488868533,
        "Owner_last_access_time":1663152489797,
        "Owner_location":null,
        "Owner_reputation":209,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":42,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Looks like it isn't possible to set this timeout based on <a href=\"https:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/6472562-configurable-timeout-for-experiments-and-web-servi\" rel=\"nofollow noreferrer\">a feature request that is still marked as \"planned\" as of 4\/1\/2018<\/a>.<\/p>\n\n<p>The recommendation from <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/sqlserver\/en-US\/cb4ee96d-c2ca-4c65-b02f-0ccb26181f7f\/timeout-in-web-service?forum=MachineLearning\" rel=\"nofollow noreferrer\">MSDN forums from 2017<\/a> is to use the Batch Execution Service, which starts the machine learning experiment and then asynchronously asks whether it's done.<\/p>\n\n<p>Here's a code snippet from the Azure ML Web Services Management Sample Code (all comments are from their sample code):<\/p>\n\n<pre><code>        using (HttpClient client = new HttpClient())\n        {\n            var request = new BatchExecutionRequest()\n            {\n\n                Outputs = new Dictionary&lt;string, AzureBlobDataReference&gt; () {\n                    {\n                        \"output\",\n                        new AzureBlobDataReference()\n                        {\n                            ConnectionString = storageConnectionString,\n                            RelativeLocation = string.Format(\"{0}\/outputresults.file_extension\", StorageContainerName) \/*Replace this with the location you would like to use for your output file, and valid file extension (usually .csv for scoring results, or .ilearner for trained models)*\/\n                        }\n                    },\n                },    \n\n                GlobalParameters = new Dictionary&lt;string, string&gt;() {\n                }\n            };\n\n            client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", apiKey);\n\n            \/\/ WARNING: The 'await' statement below can result in a deadlock\n            \/\/ if you are calling this code from the UI thread of an ASP.Net application.\n            \/\/ One way to address this would be to call ConfigureAwait(false)\n            \/\/ so that the execution does not attempt to resume on the original context.\n            \/\/ For instance, replace code such as:\n            \/\/      result = await DoSomeTask()\n            \/\/ with the following:\n            \/\/      result = await DoSomeTask().ConfigureAwait(false)\n\n            Console.WriteLine(\"Submitting the job...\");\n\n            \/\/ submit the job\n            var response = await client.PostAsJsonAsync(BaseUrl + \"?api-version=2.0\", request);\n\n            if (!response.IsSuccessStatusCode)\n            {\n                await WriteFailedResponse(response);\n                return;\n            }\n\n            string jobId = await response.Content.ReadAsAsync&lt;string&gt;();\n            Console.WriteLine(string.Format(\"Job ID: {0}\", jobId));\n\n            \/\/ start the job\n            Console.WriteLine(\"Starting the job...\");\n            response = await client.PostAsync(BaseUrl + \"\/\" + jobId + \"\/start?api-version=2.0\", null);\n            if (!response.IsSuccessStatusCode)\n            {\n                await WriteFailedResponse(response);\n                return;\n            }\n\n            string jobLocation = BaseUrl + \"\/\" + jobId + \"?api-version=2.0\";\n            Stopwatch watch = Stopwatch.StartNew();\n            bool done = false;\n            while (!done)\n            {\n                Console.WriteLine(\"Checking the job status...\");\n                response = await client.GetAsync(jobLocation);\n                if (!response.IsSuccessStatusCode)\n                {\n                    await WriteFailedResponse(response);\n                    return;\n                }\n\n                BatchScoreStatus status = await response.Content.ReadAsAsync&lt;BatchScoreStatus&gt;();\n                if (watch.ElapsedMilliseconds &gt; TimeOutInMilliseconds)\n                {\n                    done = true;\n                    Console.WriteLine(string.Format(\"Timed out. Deleting job {0} ...\", jobId));\n                    await client.DeleteAsync(jobLocation);\n                }\n                switch (status.StatusCode) {\n                    case BatchScoreStatusCode.NotStarted:\n                        Console.WriteLine(string.Format(\"Job {0} not yet started...\", jobId));\n                        break;\n                    case BatchScoreStatusCode.Running:\n                        Console.WriteLine(string.Format(\"Job {0} running...\", jobId));\n                        break;\n                    case BatchScoreStatusCode.Failed:\n                        Console.WriteLine(string.Format(\"Job {0} failed!\", jobId));\n                        Console.WriteLine(string.Format(\"Error details: {0}\", status.Details));\n                        done = true;\n                        break;\n                    case BatchScoreStatusCode.Cancelled:\n                        Console.WriteLine(string.Format(\"Job {0} cancelled!\", jobId));\n                        done = true;\n                        break;\n                    case BatchScoreStatusCode.Finished:\n                        done = true;\n                        Console.WriteLine(string.Format(\"Job {0} finished!\", jobId));\n                        ProcessResults(status);\n                        break;\n                }\n\n                if (!done) {\n                    Thread.Sleep(1000); \/\/ Wait one second\n                }\n            }\n        }\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1522603988173,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/31130629",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65795579,
        "Question_title":"Debugging AML Model Deployment",
        "Question_body":"<p>I have an ML model (trained locally) in python. Previously the model has been deployed to a Windows IIS server and it's working fine.<\/p>\n<p>Now, I am trying to deploy it as a service on Azure container instance (ACI) with 1 core, and 1 GB of memory. I took references from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\" rel=\"nofollow noreferrer\">one<\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model\" rel=\"nofollow noreferrer\">two<\/a> Microsoft docs. The docs use SDK for all the steps, but <strong>I am using the GUI feature from the Azure portal<\/strong>.<\/p>\n<p>After registering the model, I created an entry script and a conda environment YAML file (see below), and uploaded both to &quot;Custom deployment asset&quot; (at Deploy model area).<\/p>\n<p>Unfortunately, after hitting deploy, the Deployment state is stuck at Transitioning state. Even after 4 hours, the state remains the same and there were no Deployment logs too, so I am unable to find what I am doing wrong here.<\/p>\n<blockquote>\n<p>NOTE: below is just an excerpt of the entry script<\/p>\n<\/blockquote>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nimport pickle\nimport re, json\nimport numpy as np\nimport sklearn\n\ndef init():\n    global model \n    global classes\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'randomForest50.pkl')\n    model = pickle.load(open(model_path, &quot;rb&quot;))\n\n    classes = lambda x : [&quot;F&quot;, &quot;M&quot;][x]\n\ndef run(data):\n    try:\n        namesList = json.loads(data)[&quot;data&quot;][&quot;names&quot;]\n        pred = list(map(classes, model.predict(preprocessing(namesList))))\n        return str(pred[0])\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<pre class=\"lang-yaml prettyprint-override\"><code>name: gender_prediction\ndependencies:\n- python\n- numpy\n- scikit-learn\n- pip:\n    - pandas\n    - pickle\n    - re\n    - json\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1611073723990,
        "Question_score":1,
        "Question_tags":"machine-learning|yaml|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":106,
        "Owner_creation_time":1582182357613,
        "Owner_last_access_time":1664032157167,
        "Owner_location":null,
        "Owner_reputation":155,
        "Owner_up_votes":112,
        "Owner_down_votes":0,
        "Owner_views":27,
        "Question_last_edit_time":1611079944120,
        "Answer_body":"<p>The issue was in the YAML file. <strong>The dependencies\/libraries in the YAML should be according to conda environment<\/strong>. So, I changed everything accordingly, and it worked.<\/p>\n<p>Modified YAML file:<\/p>\n<pre><code>name: gender_prediction\ndependencies:\n- python=3.7\n- numpy\n- scikit-learn\n- pip:\n    - azureml-defaults\n    - pandas\n    - pickle4\n    - regex\n    - inference-schema[numpy-support]   \n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1612491964670,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65795579",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53588040,
        "Question_title":"No module named 'automl' when unpickle auto-trained model",
        "Question_body":"<p>I'm trying to reproduce 2 tutorials below using my own dataset instead of MNIST dataset.\n<a href=\"https:\/\/docs.microsoft.com\/ja-jp\/azure\/machine-learning\/service\/tutorial-auto-train-models\" rel=\"noreferrer\">https:\/\/docs.microsoft.com\/ja-jp\/azure\/machine-learning\/service\/tutorial-auto-train-models<\/a>\n<a href=\"https:\/\/docs.microsoft.com\/ja-jp\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml\" rel=\"noreferrer\">https:\/\/docs.microsoft.com\/ja-jp\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml<\/a><\/p>\n\n<p>About\n'\/notebooks\/tutorials\/03.auto-train-models.ipynb'\nthere's no problem. I've got 'model.pkl'.<\/p>\n\n<p>However, \n'\/notebooks\/tutorials\/02.deploy-models.ipynb'\nhas an error below in 'Predict test data' cell.\nI guess it's a matter of 'pickle' and 'import'.<\/p>\n\n<p>Tell me solutions, please.<\/p>\n\n<pre><code>ModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-6-11cf888b622f&gt; in &lt;module&gt;\n      2 from sklearn.externals import joblib\n      3 \n----&gt; 4 clf = joblib.load('.\/model.pkl')\n      5 # clf = joblib.load('.\/sklearn_mnist_model.pkl')\n      6 y_hat = clf.predict(X_test)\n\n~\/anaconda3_501\/lib\/python3.6\/site-packages\/sklearn\/externals\/joblib\/numpy_pickle.py in load(filename, mmap_mode)\n    576                     return load_compatibility(fobj)\n    577 \n--&gt; 578                 obj = _unpickle(fobj, filename, mmap_mode)\n    579 \n    580     return obj\n\n~\/anaconda3_501\/lib\/python3.6\/site-packages\/sklearn\/externals\/joblib\/numpy_pickle.py in _unpickle(fobj, filename, mmap_mode)\n    506     obj = None\n    507     try:\n--&gt; 508         obj = unpickler.load()\n    509         if unpickler.compat_mode:\n    510             warnings.warn(\"The file '%s' has been generated with a \"\n\n~\/anaconda3_501\/lib\/python3.6\/pickle.py in load(self)\n   1048                     raise EOFError\n   1049                 assert isinstance(key, bytes_types)\n-&gt; 1050                 dispatch[key[0]](self)\n   1051         except _Stop as stopinst:\n   1052             return stopinst.value\n\n~\/anaconda3_501\/lib\/python3.6\/pickle.py in load_global(self)\n   1336         module = self.readline()[:-1].decode(\"utf-8\")\n   1337         name = self.readline()[:-1].decode(\"utf-8\")\n-&gt; 1338         klass = self.find_class(module, name)\n   1339         self.append(klass)\n   1340     dispatch[GLOBAL[0]] = load_global\n\n~\/anaconda3_501\/lib\/python3.6\/pickle.py in find_class(self, module, name)\n   1386             elif module in _compat_pickle.IMPORT_MAPPING:\n   1387                 module = _compat_pickle.IMPORT_MAPPING[module]\n-&gt; 1388         __import__(module, level=0)\n   1389         if self.proto &gt;= 4:\n   1390             return _getattribute(sys.modules[module], name)[0]\n\nModuleNotFoundError: No module named 'automl'\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1543815453630,
        "Question_score":5,
        "Question_tags":"python|pickle|azure-machine-learning-studio|automl",
        "Question_view_count":4788,
        "Owner_creation_time":1543814686770,
        "Owner_last_access_time":1544423620710,
        "Owner_location":null,
        "Owner_reputation":53,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Question_last_edit_time":null,
        "Answer_body":"<p>you have to include azureml-train-automl package. and you have to do this:<\/p>\n\n<p>import azureml.train.automl<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1543816325650,
        "Answer_score":5.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53588040",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52603929,
        "Question_title":"AML Studio: Register mutliple gateways on the same server",
        "Question_body":"<p>I am struggling to find a way to register multiple gateways. I have a local instance of my SQL server and have created a gateway to access to it from the AML Studio workspace. It works fine but now I would like to access to the same SQL server instance from another workspace. So the question is: how to register a new gateway without removing the previous one?\nI followed this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\" rel=\"nofollow noreferrer\">documentation<\/a>.\nDoes the following explanation mean that there is no way to do that?<\/p>\n\n<blockquote>\n  <p>You can create and set up multiple gateways in Studio for each workspace. For example, you may have a gateway that you want to connect to your test data sources during development, and a different gateway for your production data sources. Azure Machine Learning gives you the flexibility to set up multiple gateways depending upon your corporate environment. Currently you can\u2019t share a gateway between workspaces and only one gateway can be installed on a single computer.<\/p>\n<\/blockquote>\n\n<p>It is quite limiting as connecting to the same server from multiple workspaces may be sometimes crucial.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1538466090420,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":40,
        "Owner_creation_time":1528790837107,
        "Owner_last_access_time":1660146049397,
        "Owner_location":"Paris, France",
        "Owner_reputation":610,
        "Owner_up_votes":143,
        "Owner_down_votes":0,
        "Owner_views":203,
        "Question_last_edit_time":1538485474347,
        "Answer_body":"<p>Well, finally I have found a way to bypass this limitation. From this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\" rel=\"nofollow noreferrer\">documentation<\/a> I have found that: <\/p>\n\n<blockquote>\n  <p>The IR does not need to be on the same machine as the data source. But staying closer to the data source reduces the time for the gateway to connect to the data source. We recommend that you install the IR on a machine that's different from the one that hosts the on-premises data source so that the gateway and data source don't compete for resources.<\/p>\n<\/blockquote>\n\n<p>So the  logic is pretty simple. You provide access to your local server to another machine on vpn and install your gateway there. Important: I have set up the firewall rules on the server before, to be able to establish the connection remotely.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1538648158570,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52603929",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40018320,
        "Question_title":"Is it secure to pass the DB query to AzureML as a global parameter?",
        "Question_body":"<p>When using AzureMLBatchExecution activity in Azure Data Factory, is it secure to pass the DB query as a global parameter to the AzureML web service? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1476354083450,
        "Question_score":2,
        "Question_tags":"azure|azure-data-factory|azure-machine-learning-studio",
        "Question_view_count":68,
        "Owner_creation_time":1452608563363,
        "Owner_last_access_time":1562103924250,
        "Owner_location":null,
        "Owner_reputation":105,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":null,
        "Answer_body":"<p>When you talk about \"secure\", are you worried about secure transmission between AML and ADF, or secure storage of your DB query information? For the former, all communication between these two services will be done with HTTPS. For the latter, our production storage has its strict access control. Besides, we only log the count of the global parameters and never the values. I believe it's secure to pass your DB query as a global parameter to the AzureML web service.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1476431199480,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40018320",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64137409,
        "Question_title":"How can I create an Azure dataset in Azure ML studio (through the GUI) from a parquet file created with Azure Spark",
        "Question_body":"<p>I'm trying to load files as a dataset in the GUI of Azure ML Studio. These parquet files have been created through Spark.<\/p>\n<p>In my folder, Spark creates files such as &quot;_SUCCESS&quot; or &quot;_committed_8998000&quot;.<\/p>\n<p>Azure ML Studio is not able to read them or ignore them and tells me:<\/p>\n<pre><code>The provided file(s) have invalid byte(s) for the specified file encoding.\n{\n  &quot;message&quot;: &quot; &quot;\n}\n<\/code><\/pre>\n<p>I selected &quot;Ignore unmatched files path&quot; and yet, it still does not work.<\/p>\n<p>If I remove the &quot;_SUCCESS&quot; and other Spark files, it works.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1601468292143,
        "Question_score":2,
        "Question_tags":"azure|apache-spark|parquet|azure-machine-learning-studio",
        "Question_view_count":178,
        "Owner_creation_time":1423640080283,
        "Owner_last_access_time":1663943557963,
        "Owner_location":"Lyon, France",
        "Owner_reputation":457,
        "Owner_up_votes":19,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Thanks for the feedback. You can use globing in path. e.g. path = '**\/*.parquet' to select only the parquet files<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1601483944070,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64137409",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62780977,
        "Question_title":"Threshold for allowed amount of failed Hyperdrive runs",
        "Question_body":"<p>Because &quot;reasons&quot;, we know that when we use <code>azureml-sdk<\/code>'s <code>HyperDriveStep<\/code> we expect a number of <code>HyperDrive<\/code> runs to fail -- normally around 20%. How can we handle this without failing the entire <code>HyperDriveStep<\/code> (and then all downstream steps)? Below is an example of the pipeline.<\/p>\n<p>I thought there would be an <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.hyperdrive.hyperdriverunconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\"><code>HyperDriveRunConfig<\/code><\/a> param to allow for this, but it doesn't seem to exist. Perhaps this is controlled on the Pipeline itself with the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipeline(class)?view=azure-ml-py#remarks\" rel=\"nofollow noreferrer\"><code>continue_on_step_failure<\/code><\/a> param?<\/p>\n<p>The workaround we're considering is to catch the failed run within our <code>train.py<\/code> script and manually log the primary_metric as zero.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/U8iNL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/U8iNL.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1594143669730,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":185,
        "Owner_creation_time":1405457120427,
        "Owner_last_access_time":1663947733100,
        "Owner_location":"Seattle, WA, USA",
        "Owner_reputation":3359,
        "Owner_up_votes":1187,
        "Owner_down_votes":14,
        "Owner_views":555,
        "Question_last_edit_time":1594159181910,
        "Answer_body":"<p>thanks for your question.<\/p>\n<p>I'm assuming that HyperDriveStep is one of the steps in your Pipeline and that you want the remaining Pipeline steps to continue, when HyperDriveStep fails, is that correct?\nEnabling continue_on_step_failure, should allow the rest of the pipeline steps to continue, when any single steps fails.<\/p>\n<p>Additionally, the HyperDrive run consists of multiple child runs, controlled by the HyperDriveConfig. If the first 3 child runs explored by HyperDrive fail (e.g. with user script errors), the system automatically cancels the entire HyperDrive run, in order to avoid further wasting resources.<\/p>\n<p>Are you looking to continue other Pipeline steps when the HyperDriveStep fails? or are you looking to continue other child runs within the HyperDrive run, when the first 3 child runs fail?<\/p>\n<p>Thanks!<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1594154863553,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62780977",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49016896,
        "Question_title":"How to bypass ID column without being used in the training model but have it as output - Azure ML",
        "Question_body":"<p>The input data in the model includes column ControlNo.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/eqULH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/eqULH.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>But I don't want this column being part of learning process so I'm using <code>Select Columns in Dataset<\/code> to exclude <code>ControlNo<\/code> column.<\/p>\n<p>But as a output I want those columns:<\/p>\n<pre><code>ControlNo, Score Label, Score Probability\n<\/code><\/pre>\n<p>So basically I need NOT to include column <code>ControlNo<\/code> into learning process,\nbut have it as output along with <code>Score Label<\/code> column.<\/p>\n<p>How can I do that?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/iPlpa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/iPlpa.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1519761299607,
        "Question_score":2,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|ml-studio",
        "Question_view_count":582,
        "Owner_creation_time":1457596845393,
        "Owner_last_access_time":1663977598457,
        "Owner_location":"San Diego, CA, United States",
        "Owner_reputation":4046,
        "Owner_up_votes":505,
        "Owner_down_votes":7,
        "Owner_views":825,
        "Question_last_edit_time":1592644375060,
        "Answer_body":"<p>Instead of removing the ControlNo column from the dataset, you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/edit-metadata\" rel=\"nofollow noreferrer\">Edit Metadata<\/a> module to clear its \"Feature\" flag - just select the column and set <strong>Fields<\/strong> to <strong>Clear feature<\/strong>. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/EUy9A.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EUy9A.png\" alt=\"Edit Metadata settings\"><\/a><\/p>\n\n<p>This will cause the Azure ML Studio algorithms to ignore it during training, and you'll be able to return it as part of your output. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1533111465720,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49016896",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62407943,
        "Question_title":"Restrict the number of nodes used by an Azure Machine Learning pipeine",
        "Question_body":"<p>I have written a pipeline that I want to run on a remote compute cluster within Azure Machine Learning. My aim is to process a large amount of historical data, and to do this I will need to run the pipeline on a large number of input parameter combinations.<\/p>\n\n<p>Is there a way to restrict the number of nodes that the pipeline uses on the cluster? By default it will use all the nodes available to the cluster, and I would like to restrict it so that it only uses a pre-defined maximum. This allows me to leave the rest of the cluster free for other users.<\/p>\n\n<p>My current code to start the pipeline looks like this:<\/p>\n\n<pre><code># Setup the pipeline\nsteps = [data_import_step] # Contains PythonScriptStep\npipeline = Pipeline(workspace=ws, steps=steps)\npipeline.validate()\n\n# Big long list of historical dates that I want to process data for\ndts = pd.date_range('2019-01-01', '2020-01-01', freq='6H', closed='left')\n# Submit the pipeline job\nfor dt in dts:\n    pipeline_run = Experiment(ws, 'my-pipeline-run').submit(\n        pipeline,\n        pipeline_parameters={\n            'import_datetime': dt.strftime('%Y-%m-%dT%H:00'),\n        }\n    )\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1592308824897,
        "Question_score":3,
        "Question_tags":"python|azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":274,
        "Owner_creation_time":1403698315160,
        "Owner_last_access_time":1664014370483,
        "Owner_location":"London, UK",
        "Owner_reputation":1534,
        "Owner_up_votes":171,
        "Owner_down_votes":3,
        "Owner_views":56,
        "Question_last_edit_time":null,
        "Answer_body":"<p>For me, the killer feature of Azure ML is not having to worry about load balancing like this. Our team has a compute target with <code>max_nodes=100<\/code> for every feature branch and we have <code>Hyperdrive<\/code> pipelines that result in 130 runs for each pipeline.<\/p>\n<p>We can submit multiple <code>PipelineRun<\/code>s back-to-back and the orchestrator does the heavy lifting of queuing, submitting, all the runs so that the <code>PipelineRun<\/code>s execute in the serial order I submitted them, and that the cluster is never overloaded. This works without issue for us 99% of the time.<\/p>\n<p>If what you're looking for is that you'd like the <code>PipelineRun<\/code>s to be executed in parallel, then you should check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-parallel-run-step#build-and-run-the-pipeline-containing-parallelrunstep\" rel=\"nofollow noreferrer\"><code>ParallelRunStep<\/code><\/a>.<\/p>\n<p>Another option is to isolate your computes. You can have up to 200 <code>ComputeTarget<\/code>s per workspace. Two 50-node <code>ComputeTarget<\/code>s cost the same as one 100-node <code>ComputeTarget<\/code>.<\/p>\n<p>On our team, we use <a href=\"https:\/\/www.pygit2.org\/\" rel=\"nofollow noreferrer\"><code>pygit2<\/code><\/a> to have a <code>ComputeTarget<\/code> created for each feature branch, so that, as data scientists, we can be confident that we're not stepping on our coworkers' toes.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1592597207007,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1592842949400,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62407943",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52537861,
        "Question_title":"What is the role of feature type in AzureML?",
        "Question_body":"<p>I want to know what is the difference between <code>feature numeric<\/code> and <code>numeric<\/code> columns in Azure Machine Learning Studio.<\/p>\n\n<p>The <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/edit-metadata\" rel=\"nofollow noreferrer\">documentation site<\/a> states: <\/p>\n\n<blockquote>\n  <p>Because all columns are initially treated as features, for modules\n  that perform mathematical operations, you might need to use this\n  option to prevent numeric columns from being treated as variables.<\/p>\n<\/blockquote>\n\n<p>But nothing more. Not what a feature is, in which modules you need features. Nothing. <\/p>\n\n<p>I specifically would like to understand if the <code>clear feature<\/code> dropdown option in the <code>fields<\/code> in the <code>edit metadata<\/code>-module has any effect. Can somebody give me a szenario where this <code>clear feature<\/code>-operation changes the ML outcome? Thank you<\/p>\n\n<p>According to the documentation in ought to have an effect:<\/p>\n\n<blockquote>\n  <p>Use the Fields option if you want to change the way that Azure Machine\n  Learning uses the data in a model.<\/p>\n<\/blockquote>\n\n<p>But what can this effect be? Any example might help<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1538054010173,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|code-documentation",
        "Question_view_count":70,
        "Owner_creation_time":1368739128833,
        "Owner_last_access_time":1653605354277,
        "Owner_location":"Riga, Latvia",
        "Owner_reputation":1763,
        "Owner_up_votes":527,
        "Owner_down_votes":52,
        "Owner_views":380,
        "Question_last_edit_time":1538054394440,
        "Answer_body":"<p>As you suspect, setting a column as <code>feature<\/code> does have an effect, and it's actually quite important - when training a model, the algorithms will only take into account columns with the <code>feature<\/code> flag, effectively ignoring the others. <\/p>\n\n<p>For example, if you have a dataset with columns <code>Feature1<\/code>, <code>Feature2<\/code>, and <code>Label<\/code> and you want to try out just <code>Feature1<\/code>, you would apply <code>clear feature<\/code> to the <code>Feature2<\/code> column (while making sure that <code>Feature1<\/code> has the <code>feature<\/code> label set, of course).<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1538116098500,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52537861",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55353889,
        "Question_title":"Azure container instances deployment failed",
        "Question_body":"<p>I am deploying a machine learning image to Azure Container Instances from Azure Machine Learning services according to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-deploy-models-with-aml\" rel=\"nofollow noreferrer\">this article<\/a>, but am always stuck with the error message:<\/p>\n\n<blockquote>\n  <p>Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.<br>\n  Please check the logs for your container instance xxxxxxx'.<\/p>\n<\/blockquote>\n\n<p>I tried:<\/p>\n\n<ol>\n<li>increasing memory_gb=4 in aci_config.<\/li>\n<li>I did\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-troubleshoot-deployment#debug-the-docker-image-locally\" rel=\"nofollow noreferrer\">troubleshooting<\/a> locally, but I could not have found any.<\/li>\n<\/ol>\n\n<p>Below is my score.py<\/p>\n\n<pre><code>def init():\n    global model\n    model_path = Model.get_model_path('pofc_fc_model')\n    model = joblib.load(model_path)\n\ndef run(raw_data):\n    data = np.array(json.loads(raw_data)['data'])\n    y_hat = model.predict(data)\n    return y_hat.tolist()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1553593173310,
        "Question_score":2,
        "Question_tags":"python|containers|azure-container-instances|azure-machine-learning-service",
        "Question_view_count":3020,
        "Owner_creation_time":1510960409297,
        "Owner_last_access_time":1640215803973,
        "Owner_location":"Bangkok Thailand",
        "Owner_reputation":306,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Question_last_edit_time":1562618473093,
        "Answer_body":"<p>Have you registered the model <code>'pofc_fc_model'<\/code> in your workspace using the <code>register()<\/code> function on the model object? If not, there will be no model path and that can cause failure.<\/p>\n\n<p>See this section on model registration: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#registermodel\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#registermodel<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1553715289510,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55353889",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65556574,
        "Question_title":"How to make prediction after model registration in azure?",
        "Question_body":"<p>I created a simply model and then registered in azure. How can I make a prediction?<\/p>\n<pre><code>from sklearn import svm\nimport joblib\nimport numpy as np\n\n# customer ages\nX_train = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\nX_train = X_train.reshape(-1, 1)\n# churn y\/n\ny_train = [&quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;]\n\nclf = svm.SVC(gamma=0.001, C=100.)\nclf.fit(X_train, y_train)\n\njoblib.dump(value=clf, filename=&quot;churn-model.pkl&quot;)\n<\/code><\/pre>\n<p>Registration:<\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.get(name=&quot;myworkspace&quot;, subscription_id='My_subscription_id', resource_group='ML_Lingaro')\n\nfrom azureml.core.model import Model\nmodel = Model.register(workspace=ws, model_path=&quot;churn-model.pkl&quot;, model_name=&quot;churn-model-test&quot;)\n<\/code><\/pre>\n<p>Prediction:<\/p>\n<pre><code>from azureml.core.model import Model\nimport os\n\nmodel = Model(workspace=ws, name=&quot;churn-model-test&quot;)\nX_test = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\nmodel.predict(X_test) ???? \n<\/code><\/pre>\n<p>Error: <code>AttributeError: 'Model' object has no attribute 'predict'<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1609722575690,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":540,
        "Owner_creation_time":1605834001337,
        "Owner_last_access_time":1618085210227,
        "Owner_location":null,
        "Owner_reputation":73,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Question_last_edit_time":1609723457017,
        "Answer_body":"<p>great question -- I also had the same misconception starting out. The missing piece is that there's a difference between model 'registration' and model 'deployment'. Registration is simply for tracking and for easy downloading at a later place and time. Deployment is what you're after, making a model available to be scored against.<\/p>\n<p>There's a <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python&amp;WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">whole section in the docs about deployment<\/a>. My suggestion would be to deploy it locally first for testing.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1609737626627,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65556574",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69764100,
        "Question_title":"Endpoints cost on Azure Machine Learning",
        "Question_body":"<p>I have been following the learning path for <a href=\"https:\/\/docs.microsoft.com\/en-us\/learn\/certifications\/exams\/ai-900\" rel=\"nofollow noreferrer\">Microsoft Azure AI 900<\/a>. In the second module, I have deployed my model as an endpoint. It says Container instances for compute type. How much will this cost me. Azure doesn't seem to show any pricing for this. Is this endpoint always active? If yes how much does it cost?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1635485800157,
        "Question_score":3,
        "Question_tags":"azure|azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":633,
        "Owner_creation_time":1566078293737,
        "Owner_last_access_time":1663949466117,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":449,
        "Owner_up_votes":370,
        "Owner_down_votes":2,
        "Owner_views":77,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The price depends on the number of <strong>vCPU<\/strong> and <strong>GBs<\/strong> of memory requested for the container group. You are charged based on the <strong>vCPU request<\/strong> for your container group rounded up to the nearest whole number for the duration (measured in seconds) <strong>your instance is running<\/strong>. You are also charged for the <strong>GB request<\/strong> for your container group rounded up to the nearest tenths place for the duration (measured in seconds) your <strong>container group is running<\/strong>. There is an additional charge of $0.000012 per vCPU second for Windows software duration on Windows container groups. Check here <a href=\"https:\/\/azure.microsoft.com\/en-us\/pricing\/details\/container-instances\/\" rel=\"nofollow noreferrer\">Pricing - Container Instances | Microsoft Azure<\/a> for details<\/p>\n<ul>\n<li>After Deployed the Azure Machine Learning managed online endpoint (preview).<\/li>\n<li>Have at least <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/role-based-access-control\/role-assignments-portal.md\" rel=\"nofollow noreferrer\">Billing Reader<\/a> access on the subscription where the endpoint is deployed<\/li>\n<\/ul>\n<p>To know the costs estimation<\/p>\n<ol>\n<li><p>In the <a href=\"https:\/\/portal.azure.com\/\" rel=\"nofollow noreferrer\">Azure portal<\/a>, Go to your subscription<\/p>\n<\/li>\n<li><p>Select <strong>Cost Analysis<\/strong> for your subscription.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/W2eaRIO.png\" alt=\"enter image description here\" \/><\/p>\n<p>Create a filter to scope data to your Azure Machine learning workspace resource:<\/p>\n<ol>\n<li><p>At the top navigation bar, select <strong>Add filter<\/strong>.<\/p>\n<\/li>\n<li><p>In the first filter dropdown, select <strong>Resource<\/strong> for the filter type.<\/p>\n<\/li>\n<li><p>In the second filter dropdown, select your Azure Machine Learning workspace.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/HEvprph.png\" alt=\"enter image description here\" \/><\/p>\n<p>Create a tag filter to show your managed online endpoint and\/or managed online deployment:<\/p>\n<ol>\n<li><p>Select <strong>Add filter<\/strong> &gt; <strong>Tag<\/strong> &gt; <strong>azuremlendpoint<\/strong>: &quot;&lt; your endpoint name&gt;&quot;<\/p>\n<\/li>\n<li><p>Select <strong>Add filter<\/strong> &gt; <strong>Tag<\/strong> &gt; <strong>azuremldeployment<\/strong>: &quot;&lt; your deployment name&gt;&quot;.<\/p>\n<\/li>\n<\/ol>\n<p><img src=\"https:\/\/i.imgur.com\/1aapYGB.png\" alt=\"enter image description here\" \/><\/p>\n<p>Refer  <a href=\"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-view-online-endpoints-costs.md\" rel=\"nofollow noreferrer\">here <\/a> for more detailed steps<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1635505501917,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69764100",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71321757,
        "Question_title":"What are valid Azure ML Workspace connection argument options?",
        "Question_body":"<p>I want to build an Azure ML environment with two python packages that I have in Azure Devops.\nFor this I need a workspace connection to Azure Devops. One package is published to an artifact feed and I can access it using the python SDK using a personal access token:<\/p>\n<pre><code>ws.set_connection(name=&quot;ConnectionName&quot;, \n                  category= &quot;PythonFeed&quot;, \n                  target = &quot;https:\/\/pkgs.dev.azure.com\/&quot;, \n                  authType = &quot;PAT&quot;, \n                  value = PAT_TOKEN)\n<\/code><\/pre>\n<p>However, for the other I need to get the package from the git repository in Azure Devops. The documentation of the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.workspace.workspace?view=azure-ml-py#azureml-core-workspace-workspace-set-connection\" rel=\"nofollow noreferrer\">Python SDK<\/a> and the underlying <a href=\"https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspace-connections\/create\" rel=\"nofollow noreferrer\">REST API<\/a> don't give the options for the arguments, only that they need to be strings (see links).<\/p>\n<p>My question: what are the options for the following arguments:<\/p>\n<ul>\n<li>authType<\/li>\n<li>category<\/li>\n<li>valueFormat<\/li>\n<\/ul>\n<p>And what do I need to set for target argument, so that I can connect to the Azure DevOps repository with potentially different authentication?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1646219844250,
        "Question_score":0,
        "Question_tags":"python|azure-devops|azure-machine-learning-studio|azureml-python-sdk|azure-python-sdk",
        "Question_view_count":93,
        "Owner_creation_time":1646219230530,
        "Owner_last_access_time":1663852436163,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":"<p>To get the package from a Azure DevOps git repository you can change the target to the repository URL:<\/p>\n<pre><code>ws.set_connection(\n    name=&quot;ConnectionName&quot;, \n    category = &quot;PythonFeed&quot;,\n    target = &quot;https:\/\/dev.azure.com\/&lt;MY-ORG&gt;\/&lt;MY-PROJECT&gt;\/_git\/&lt;MY-REPO&gt;&quot;, \n    authType = &quot;PAT&quot;, \n    value = &lt;PAT-TOKEN&gt;)\n<\/code><\/pre>\n<p>Note here that there is no user specified in the URL (the standard &quot;clone&quot; URL in Azure DevOps also contains &quot;DevOps-Vx@&quot;).<\/p>\n<p>As for any other options for &quot;authType&quot;, &quot;category&quot; and &quot;valueFormat&quot;, I don't know.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1659435013617,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71321757",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63691515,
        "Question_title":"Azure Machine Learning Studio: cannot create Datastore from Azure SQL Database",
        "Question_body":"<p>I am trying to connect to an Azure SQL Database from inside Azure Machine Learning Studio. Based on <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py<\/a>, it seems that the recommended pattern is to create a Datastore using the Datastore.register_azure_sql_database method as follows:<\/p>\n<pre><code>import os\nfrom azureml.core import Workspace, Datastore\n\nws = Workspace.from_config() # asks for interactive authentication the first time\n\nsql_datastore_name  = &quot;datastore_test_01&quot; # any name should be fine\nserver_name         = os.getenv(&quot;SQL_SERVERNAME&quot;    , &quot;{SQL_SERVERNAME}&quot;) # Name of the Azure SQL server\ndatabase_name       = os.getenv(&quot;SQL_DATABASENAME&quot;  , &quot;{SQL_DATABASENAME}&quot;) # Name of the Azure SQL database\nusername            = os.getenv(&quot;SQL_USER_NAME&quot;     , &quot;{SQL_USER_NAME}&quot;) # The username of the database user.\npassword            = os.getenv(&quot;SQL_USER_PASSWORD&quot; , &quot;{SQL_USER_PASSWORD}&quot;) # The password of the database user.\n\nsql_datastore = Datastore.register_azure_sql_database(workspace      = ws,\n                                                      datastore_name = sql_datastore_name,\n                                                      server_name    = server_name,\n                                                      database_name  = database_name,\n                                                      username       = username,\n                                                      password       = password)\n<\/code><\/pre>\n<p>I am pretty sure I have set all parameters right, having copied them from the ADO.NET connection string at my SQL Database resource --&gt; Settings --&gt; Connection strings:<\/p>\n<pre><code>Server=tcp:{SQL_SERVERNAME}.database.windows.net,1433;Initial Catalog={SQL_DATABASENAME};Persist Security Info=False;User ID={SQL_USER_NAME};Password={SQL_USER_PASSWORD};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;\n<\/code><\/pre>\n<p>However, I get the following error:<\/p>\n<pre><code>Registering datastore failed with a 400 error code and error message 'Azure SQL Database Error -2146232060: Please check the correctness of the datastore information.'\n<\/code><\/pre>\n<p>Am I missing something? E.g., a firewall rule? I have also tried adding the Azure ML compute resource's public IP address to the list of allowed IP addresses in my SQL Database resource, but still no success.<\/p>\n<hr \/>\n<p><strong>UPDATE<\/strong>: adding <code>skip_validation = True<\/code> to <code>Datastore.register_azure_sql_database<\/code> solves the issue. I can then query the data with<\/p>\n<pre><code>from azureml.core import Dataset\nfrom azureml.data.datapath import DataPath\n\nquery   = DataPath(sql_datastore, 'SELECT * FROM my_table')\ntabular = Dataset.Tabular.from_sql_query(query, query_timeout = 10)\ndf = tabular.to_pandas_dataframe()\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1598976793243,
        "Question_score":1,
        "Question_tags":"azure|azure-sql-database|azure-machine-learning-studio|azure-machine-learning-service|azure-sdk-python",
        "Question_view_count":793,
        "Owner_creation_time":1502454917960,
        "Owner_last_access_time":1611741145200,
        "Owner_location":"Milano, MI, Italia",
        "Owner_reputation":132,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Question_last_edit_time":1599032818923,
        "Answer_body":"<p>is the datastore behind vnet? where are you running the registration code above? On a compute instance behind the same vnet?\nhere is the doc that describe what you need to do to connect to data behind vnet:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#use-datastores-and-datasets\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#use-datastores-and-datasets<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1598979186260,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63691515",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60490195,
        "Question_title":"Unable to build local AMLS environment with private wheel",
        "Question_body":"<p>I am trying to write a small program using the AzureML Python SDK (v1.0.85) to register an Environment in AMLS and use that definition to construct a local Conda environment when experiments are being run (for a pre-trained model). The code works fine for simple scenarios where all dependencies are loaded from Conda\/ public PyPI, but when I introduce a private dependency (e.g. a utils library) I am getting a InternalServerError with the message \"Error getting recipe specifications\".<\/p>\n\n<p>The code I am using to register the environment is (after having authenticated to Azure and connected to our workspace):<\/p>\n\n<pre><code>environment_name = config['environment']['name']\npy_version = \"3.7\"\nconda_packages = [\"pip\"]\npip_packages = [\"azureml-defaults\"]\nprivate_packages = [\".\/env-wheels\/utils-0.0.3-py3-none-any.whl\"]\n\nprint(f\"Creating environment with name {environment_name}\")\nenvironment = Environment(name=environment_name)\nconda_deps = CondaDependencies()\n\nprint(f\"Adding Python version: {py_version}\")\nconda_deps.set_python_version(py_version)\n\nfor conda_pkg in conda_packages:\n    print(f\"Adding Conda denpendency: {conda_pkg}\")\n    conda_deps.add_conda_package(conda_pkg)\n\nfor pip_pkg in pip_packages:\n    print(f\"Adding Pip dependency: {pip_pkg}\")\n    conda_deps.add_pip_package(pip_pkg)\n\nfor private_pkg in private_packages:\n    print(f\"Uploading private wheel from {private_pkg}\")\n    private_pkg_url = Environment.add_private_pip_wheel(workspace=ws, file_path=Path(private_pkg).absolute(), exist_ok=True)\n    print(f\"Adding private Pip dependency: {private_pkg_url}\")\n    conda_deps.add_pip_package(private_pkg_url)\n\nenvironment.python.conda_dependencies = conda_deps\nenvironment.register(workspace=ws)\n<\/code><\/pre>\n\n<p>And the code I am using to create the local Conda environment is:<\/p>\n\n<pre><code>amls_environment = Environment.get(ws, name=environment_name, version=environment_version)\n\nprint(f\"Building environment...\")\namls_environment.build_local(workspace=ws)\n<\/code><\/pre>\n\n<p>The exact error message being returned when <code>build_local(...)<\/code> is called is:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"C:\\Anaconda\\envs\\AMLSExperiment\\lib\\site-packages\\azureml\\core\\environment.py\", line 814, in build_local\n    raise error\n  File \"C:\\Anaconda\\envs\\AMLSExperiment\\lib\\site-packages\\azureml\\core\\environment.py\", line 807, in build_local\n    recipe = environment_client._get_recipe_for_build(name=self.name, version=self.version, **payload)\n  File \"C:\\Anaconda\\envs\\AMLSExperiment\\lib\\site-packages\\azureml\\_restclient\\environment_client.py\", line 171, in _get_recipe_for_build\n    raise Exception(message)\nException: Error getting recipe specifications. Code: 500\n: {\n  \"error\": {\n    \"code\": \"ServiceError\",\n    \"message\": \"InternalServerError\",\n    \"detailsUri\": null,\n    \"target\": null,\n    \"details\": [],\n    \"innerError\": null,\n    \"debugInfo\": null\n  },\n  \"correlation\": {\n    \"operation\": \"15043e1469e85a4c96a3c18c45a2af67\",\n    \"request\": \"19231be75a2b8192\"\n  },\n  \"environment\": \"westeurope\",\n  \"location\": \"westeurope\",\n  \"time\": \"2020-02-28T09:38:47.8900715+00:00\"\n}\n\nProcess finished with exit code 1\n<\/code><\/pre>\n\n<p>Has anyone seen this error before or able to provide some guidance around what the issue may be?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1583156836040,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":239,
        "Owner_creation_time":1526889513900,
        "Owner_last_access_time":1621512507353,
        "Owner_location":null,
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The issue was with out firewall blocking the required requests between AMLS and the storage container (I presume to get the environment definitions\/ private wheels).<\/p>\n\n<p>We resolved this by updating the firewall with appropriate ALLOW rules for the AMLS service to contact and read from the attached storage container.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1583243758050,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60490195",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30859824,
        "Question_title":"Use Azure Machine learning to detect symbol within an image",
        "Question_body":"<p>4 years ago I posted <a href=\"https:\/\/stackoverflow.com\/q\/6999920\/411094\">this question<\/a> and got a few answers that were unfortunately outside my skill level.  I just attended a build tour conference where they spoke about machine learning and this got me thinking of the possibility of using ML as a solution to my problem.  i found <a href=\"https:\/\/gallery.azureml.net\/MachineLearningAPI\/02ce55bbc0ab4fea9422fe019995c02f\" rel=\"noreferrer\">this<\/a> on the azure site but i dont think it will help me because its scope is pretty narrow.<\/p>\n\n<p>Here is what i am trying to achieve:<\/p>\n\n<p>i have a source image:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/6y76s.jpg\" alt=\"source image\"><\/p>\n\n<p>and i want to which one of the following symbols (if any) are contained in the image above:<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/SuHkU.jpg\" alt=\"symbols\"><\/p>\n\n<p>the compare needs to support minor distortion, scaling, color differences, rotation, and brightness differences.<\/p>\n\n<p>the number of symbols to match will ultimately at least be greater than 100.<\/p>\n\n<p>is ML a good tool to solve this problem?  if so, any starting tips?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1434434333360,
        "Question_score":14,
        "Question_tags":"opencv|azure|image-processing|machine-learning|azure-machine-learning-studio",
        "Question_view_count":6324,
        "Owner_creation_time":1280943666900,
        "Owner_last_access_time":1663962994233,
        "Owner_location":"Los Angeles, CA",
        "Owner_reputation":1141,
        "Owner_up_votes":32,
        "Owner_down_votes":0,
        "Owner_views":109,
        "Question_last_edit_time":1495541445110,
        "Answer_body":"<p>As far as I know, Project Oxford (MS Azure CV API) wouldn't be suitable for your task. Their APIs are very focused to Face related tasks (detection, verification, etc), OCR and Image description. And apparently you can't extend their models or train new ones from the existing ones.<\/p>\n\n<p>However, even though I don't know an out of the box solution for your object detection problem; there are easy enough approaches that you could try and that would give you some start point results.<\/p>\n\n<p>For instance, here is a naive method you could use:<\/p>\n\n<p><strong>1) Create your dataset:<\/strong>\n    This is probably the more tedious step and paradoxically a crucial one. I will assume you have a good amount of images to work with. What would you need to do is to pick a fixed window size and extract positive and negative examples.\n<img src=\"https:\/\/i.stack.imgur.com\/H4uC5.png\" alt=\"enter image description here\"><\/p>\n\n<p>If some of the images in your dataset are in different sizes you would need to rescale them to a common size. You don't need to get too crazy about the size, probably 30x30 images would be more than enough. To make things easier I would turn the images to gray scale too. <\/p>\n\n<p><strong>2) Pick a classification algorithm and train it:<\/strong>\n    There is an awful amount of classification algorithms out there. But if you are new to machine learning I will pick the one I would understand the most. Keeping that in mind, I would check out logistic regression which give decent results, it's easy enough for starters and have a lot of libraries and tutorials. For instance, <a href=\"http:\/\/blog.yhathq.com\/posts\/logistic-regression-and-python.html\" rel=\"noreferrer\">this one<\/a> or <a href=\"https:\/\/msdn.microsoft.com\/en-us\/magazine\/dn948113.aspx\" rel=\"noreferrer\">this one<\/a>. At first I would say to focus in a binary classification problem (like if there is an UD logo in the picture or not) and when you master that one you can jump to the multi-class case. There are resources for that <a href=\"http:\/\/www.codeproject.com\/Articles\/821347\/MultiClass-Logistic-Classifier-in-Python\" rel=\"noreferrer\">too<\/a> or you can always have several models one per logo and run this recipe for each one separately. <\/p>\n\n<p>To train your model, you just need to read the images generated in the step 1 and turn them into a vector and label them accordingly. That would be the  dataset that will feed your model. If you are using images in gray scale, then each position in the vector would correspond to a pixel value in the range 0-255. Depending on the algorithm you might need to rescale those values to the range [0-1] (this is because some algorithms perform better with values in that range). Notice that rescaling the range in this case is fairly easy (new_value = value\/255).<\/p>\n\n<p>You also need to split your dataset, reserving some examples for training, a subset for validation and another one for testing. Again, there are different ways to do this, but I'm keeping this answer as naive as possible.<\/p>\n\n<p><strong>3) Perform the detection:<\/strong>\n    So now let's start the fun part. Given any image you want to run your model and produce coordinates in the picture where there is a logo. There are different ways to do this and I will describe one that probably <strong>is not the best nor the more efficient<\/strong>, but it's easier to develop in my opinion.<\/p>\n\n<p>You are going to scan the picture, extracting the pixels in a \"window\", rescaling those pixels to the size you selected in step 1 and then feed them to your model. <\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/VGk3f.png\" alt=\"Extracting windows to feed the model\"><\/p>\n\n<p>If the model give you a positive answer then you mark that window in the original image. Since the logo might appear in different scales you need to repeat this process with different window sizes. You also would need to tweak the amount of space between windows.<\/p>\n\n<p><strong>4) Rinse and repeat:<\/strong>\n    At the first iteration it's very likely that you will get a lot of false positives. Then you need to take those as negative examples and retrain your model. This would be an iterative process and hopefully on each iteration you will have less and less false positives and fewer false negatives.<\/p>\n\n<p>Once you are reasonable happy with your solution, you might want to improve it. You might want to try other classification algorithms like <a href=\"https:\/\/en.wikipedia.org\/wiki\/Support_vector_machine\" rel=\"noreferrer\">SVM<\/a> or <a href=\"https:\/\/en.wikipedia.org\/wiki\/Deep_learning\" rel=\"noreferrer\">Deep Learning Artificial Neural Networks<\/a>, or to try better object detection frameworks like <a href=\"https:\/\/en.wikipedia.org\/wiki\/Viola%E2%80%93Jones_object_detection_framework\" rel=\"noreferrer\">Viola-Jones<\/a>. Also, you will probably need to use <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cross-validation_%28statistics%29\" rel=\"noreferrer\">crossvalidation<\/a> to compare all your solutions (you can actually use crossvalidation from the beginning). By this moment I bet you would be confident enough that you would like to use OpenCV or another ready to use framework in which case you will have a fair understanding of what is going on under the hood. <\/p>\n\n<p>Also you could just disregard all this answer and go for an OpenCV object detection tutorial like this <a href=\"http:\/\/note.sonots.com\/SciSoftware\/haartraining.html\" rel=\"noreferrer\">one<\/a>. Or take another answer from another question like this <a href=\"https:\/\/stackoverflow.com\/questions\/10168686\/algorithm-improvement-for-coca-cola-can-shape-recognition?rq=1\">one<\/a>. Good luck!<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1434469130290,
        "Answer_score":22.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":1495541910023,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30859824",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51238413,
        "Question_title":"Azure Machine Learning Workbench hangs while creating new project",
        "Question_body":"<p>I was trying Azure Machine Learning Services following this tutorial (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/quickstart-installation\" rel=\"nofollow noreferrer\">Link<\/a>). After successfully creating the Azure Machine Learning services accounts, I successfully installed the Workbench on my Windows 10 Laptop (Behind Proxy; Proxy has been configured at the WorkBench). Next, I was trying to create project following this section (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/quickstart-installation#create-a-project-in-workbench\" rel=\"nofollow noreferrer\">Link<\/a>). Once I click on the Create button, it goes to \"Creating\" state and stays there for ever. The errors displayed at Errors.log is the following. Any suggestion will be appreciated. <\/p>\n\n<pre><code>[2018-07-09 09:47:08.437] [ERROR] HttpService - {\"event\":\"HttpService\",\"task\":\"Failed\",\"data\":{\"url\":\"http:\/\/localhost:54240\/projects\/v1.0\/create\/template\",\"status\":500,\"statusText\":\"INKApi Error\",\"jsonError\":null,\"requestId\":null,\"sessionType\":\"Workbench\"},\"sid\":\"365395c0-832b-11e8-b4ce-e5d7046c6143\"}\n\n[2018-07-09 09:47:08.960] [ERROR] CreateProjectForm - {\"event\":\"CreateProject\",\"task\":\"Error\",\"data\":{\"_body\":null,\"status\":500,\"ok\":false,\"statusText\":\"INKApi Error\",\"headers\":{\"Date\":[\"Mon\",\" 09 Jul 2018 04:17:06 GMT\"],\"Via\":[\"1.1 localhost.localdomain\"],\"Proxy-Connection\":[\"close\"],\"Content-Length\":[\"0\"],\"Content-Type\":[\"text\/html\"]},\"type\":2,\"url\":\"http:\/\/localhost:54240\/projects\/v1.0\/create\/template\"},\"sid\":\"365395c0-832b-11e8-b4ce-e5d7046c6143\"}\n\n[2018-07-09 09:47:08.963] [FATAL] ExceptionLogger - {\"event\":\"exception\",\"task\":\"\",\"data\":{\"message\":\"Cannot read property 'error' of null\",\"name\":\"TypeError\",\"stack\":\"TypeError: Cannot read property 'error' of null\\n    at SafeSubscriber._error (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:61476:58)\\n    at SafeSubscriber.__tryOrUnsub (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:212279:20)\\n    at SafeSubscriber.error (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:212241:30)\\n    at Subscriber._error (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:212172:30)\\n    at Subscriber.error (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:212146:22)\\n    at MergeMapSubscriber.OuterSubscriber.notifyError (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:210968:30)\\n    at InnerSubscriber._error (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:211072:25)\\n    at InnerSubscriber.Subscriber.error (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:212146:22)\\n    at DeferSubscriber.OuterSubscriber.notifyError (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:210968:30)\\n    at InnerSubscriber._error (file:\/\/\/C:\/Users\/MyUser\/AppData\/Local\/AmlWorkbench\/resources\/app.asar\/src\/App\/main.bundle.js:211072:25)\"},\"sid\":\"365395c0-832b-11e8-b4ce-e5d7046c6143\"}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1531112127690,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":67,
        "Owner_creation_time":1280505139753,
        "Owner_last_access_time":1663935737867,
        "Owner_location":"Bangalore, India",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Question_last_edit_time":null,
        "Answer_body":"<p>It was happening because of the Proxy (although I have configured the Proxy on the Workbench). When I am connected to internet directly, everything works fine (Able to create project, train, compare models etc). However the Workbench should return meaningful error instead of hanging or simply waiting while creating the project.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1531201276973,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51238413",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73760033,
        "Question_title":"How to transfer a csv file from notebook folder to a datastore",
        "Question_body":"<p>I want to transfer a generated csv file <code>test_df.csv<\/code> from my Azure ML notebook folder which has a path <code>\/Users\/Ankit19.Gupta\/test_df.csv<\/code> to a datastore which has a web path <code>https:\/\/abc.blob.core.windows.net\/azureml\/LocalUpload\/f3db18b6<\/code>. I have written the python code as<\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.from_config()\ndatastore = ws.get_default_datastore()\n    \ndatastore.upload_files('\/Users\/Ankit19.Gupta\/test_df.csv',\n                  target_path='https:\/\/abc.blob.core.windows.net\/azureml\/LocalUpload\/f3db18b6',\n                  overwrite=True)\n<\/code><\/pre>\n<p>But it is showing the following error message:<\/p>\n<pre><code>UserErrorException: UserErrorException:\n    Message: '\/' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\n    InnerException None\n    ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;'\/' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.&quot;\n    }\n}\n<\/code><\/pre>\n<p>I have tried <a href=\"https:\/\/stackoverflow.com\/questions\/67897947\/how-to-transfer-data-from-azure-ml-notebooks-to-a-storage-container\">this<\/a> but it is not working for me. Can anyone please help me to resolve this issue. Any help would be appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1663473633117,
        "Question_score":0,
        "Question_tags":"python|azure|file-upload|azure-machine-learning-service|movefile",
        "Question_view_count":43,
        "Owner_creation_time":1540154634483,
        "Owner_last_access_time":1664030893903,
        "Owner_location":null,
        "Owner_reputation":237,
        "Owner_up_votes":60,
        "Owner_down_votes":0,
        "Owner_views":173,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The way the path was mentioned is not accurate. The datastore path will be different manner.\nReplace the below code for the small change in the calling path.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4o1WU.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4o1WU.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<pre><code>from azureml.core import Workspace\nws = Workspace.from_config()\ndatastore = ws.get_default_datastore()\n    \ndatastore.upload_files('.\/Users\/foldername\/filename.csv',\n                  target_path=\u2019your targetfolder',\n                  overwrite=True)\n<\/code><\/pre>\n<p>We need to call all the parent folders before the folder.  <strong><code>\u201c.\/\u201d<\/code><\/strong> is the way we can call the dataset from datastore.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1663658453173,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73760033",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70929123,
        "Question_title":"AzureMLCompute job failed with `FailedLoginToImageRegistry`",
        "Question_body":"<p>I've been trying to send a train job through azure ml python sdk with:<\/p>\n<pre><code>from azureml.core import Workspace, Experiment, ScriptRunConfig \n\nif __name__ == &quot;__main__&quot;:\n    ws = Workspace.from_config()\n    experiment = Experiment(workspace=ws, name='ConstructionTopicsModel')\n\n    config = ScriptRunConfig(source_directory='.\/',\n                         script='src\/azureml\/train.py',\n                         arguments=None,\n                         compute_target='ComputeTargetName',\n                         )\n\n    env = ws.environments['test-env']\n    config.run_config.environment = env\n    run = experiment.submit(config)\n    \n    run.wait_for_completion(show_output=True)\n\n    aml_url = run.get_portal_url()\n    print(aml_url)\n<\/code><\/pre>\n<p>But I was getting the <code>ServiceError<\/code> message:<\/p>\n<pre><code>AzureMLCompute job failed. FailedLoginToImageRegistry: Unable to login to docker image repo\nReason: Failed to login to the docker registry\nerror: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nserviceURL: 7ac86b04d6564d36aa80ae2ad090582c.azurecr.io\nReason: WARNING! Using --password via the CLI is insecure. Use --password-stdin. Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`\n\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n<\/code><\/pre>\n<p>I also tried using the azure cli without success, same error message<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1643645330913,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":202,
        "Owner_creation_time":1589293508567,
        "Owner_last_access_time":1663681781073,
        "Owner_location":null,
        "Owner_reputation":833,
        "Owner_up_votes":9,
        "Owner_down_votes":9,
        "Owner_views":55,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The only way I've found so far to make this work, was to run it on a terminal of the compute-target itself. That's how the docker error goes away. Trying to run the experiment from a terminal of a different compute instance raises the exception.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1643645330913,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70929123",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49130977,
        "Question_title":"Does a call to \"Deploy web service(via API key) \" re run trained Azure ML model again",
        "Question_body":"<p>I wanted to know how exactly the following works in backend<\/p>\n\n<p><strong>Scenario :<\/strong> <\/p>\n\n<blockquote>\n  <p>-> We get data from Edgex foundry in UTC format and we it store it in Azure Document DB in (CST\/CDT timezone) format<\/p>\n  \n  <p>-> We trained ML model on data(with Date in CST\/CDT timezone) and Deploy web service.<\/p>\n<\/blockquote>\n\n<p><strong>So I have few basic doubts below<\/strong><\/p>\n\n<blockquote>\n  <ol>\n  <li><p>When web job hits our predictive webservice , will the trained ML model be run again?<\/p><\/li>\n  <li><p>Do we need to convert the UTC timezone for new incoming test data( which we want to predict) into CST\/CDT timezone, as TimeStamp does\n  matter for our prediction?<\/p><\/li>\n  <li><p>What happens in backend when predictive webservice API is called?<\/p><\/li>\n  <\/ol>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1520339633757,
        "Question_score":0,
        "Question_tags":"azure|azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":92,
        "Owner_creation_time":1504867604870,
        "Owner_last_access_time":1562061256807,
        "Owner_location":"Pune, Maharashtra, India",
        "Owner_reputation":391,
        "Owner_up_votes":49,
        "Owner_down_votes":0,
        "Owner_views":125,
        "Question_last_edit_time":null,
        "Answer_body":"<p>This is only based on my experience with Azure ML, but I think I can help with your questions.<\/p>\n\n<blockquote>\n  <p>When web job hits our predictive webservice, will the trained ML model be run again?<\/p>\n<\/blockquote>\n\n<p>Yes, in the sense that it will call the <code>predict<\/code> (or similar) method on the model on the new data. For instance, in <code>scikit-learn<\/code> you would train your model using the <code>fit<\/code> method. Once the model is in production, only the <code>predict<\/code> method would be called.<\/p>\n\n<p>It will also run the whole workflow you have set up to be deployed as the web service. As an example below is a workflow I've played around with before. Each time the web service is run with new data, this whole thing will be run. This is like creating a Pipeline in <code>scikit-learn<\/code>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YMFZb.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YMFZb.png\" alt=\"Azure ML Workflow\"><\/a><\/p>\n\n<blockquote>\n  <p>Do we need to convert the UTC timezone for new incoming test data( which we want to predict) into CST\/CDT timezone, as TimeStamp does matter for our prediction?<\/p>\n<\/blockquote>\n\n<p>I would say yes, you would need to convert to the timezone that was used when training in the model. This can be done by adding a step in your workflow then when you call the web service it will do the necessary converting for you before making a prediction.<\/p>\n\n<blockquote>\n  <p>What happens in backend when predictive webservice API is called?<\/p>\n<\/blockquote>\n\n<p>I'm not sure if anyone knows for sure other than the folks at Microsoft, but for sure it will run the workflow you have set up.<\/p>\n\n<hr>\n\n<p>I know it's not much, but I hope this helps or at least gets you on the right track for what you need.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1521026355920,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49130977",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60539094,
        "Question_title":"Is it possible to share compute instance with other user?",
        "Question_body":"<p>I create one compute instance 'yhd-notebook' in Azure Machine Learning compute with user1. When I login with user2, and try to open the JupyterLab of this compute instance, it shows an error message like below.<\/p>\n\n<blockquote>\n  <p>User user2 does not have access to compute instance yhd-notebook.<\/p>\n  \n  <p>Only the creator can access a compute instance.<\/p>\n  \n  <p>Click here to sign out and sign in again with a different account.<\/p>\n<\/blockquote>\n\n<p>Is it possible to share compute instance with another user? BTW, both user1 and user2 have Owner role with the Azure subscription.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1583388412943,
        "Question_score":8,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":3705,
        "Owner_creation_time":1582361231693,
        "Owner_last_access_time":1655516080367,
        "Owner_location":"Guangzhou, China",
        "Owner_reputation":393,
        "Owner_up_votes":37,
        "Owner_down_votes":1,
        "Owner_views":58,
        "Question_last_edit_time":null,
        "Answer_body":"<p>According to MS, all users in the workspace contributor and owner role can create, delete, start, stop, and restart compute instances across the workspace. However, only the creator of a specific compute instance is allowed to access Jupyter, JupyterLab, and RStudio on that compute instance. The creator of the compute instance has the compute instance dedicated to them, have root access, and can terminal in through Jupyter. Compute instance will have single-user login of creator user and all actions will use that user\u2019s identity for RBAC and attribution of experiment runs. SSH access is controlled through public\/private key mechanism.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1583393458820,
        "Answer_score":7.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60539094",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64486262,
        "Question_title":"Is there a way to un-register an environment in Azure ML studio",
        "Question_body":"<p>I am trying to deploy a model in Azure ML and kept on getting the error 'model not found' from my score.py. So I decided to start from scratch again. I had my custom environment registered, and the Azure ML API for Environment class doesn't seem to have anything like 'delete' or 'unregister'. is there a way to work around this? Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1603383120473,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":424,
        "Owner_creation_time":1595118700083,
        "Owner_last_access_time":1629382612393,
        "Owner_location":"Toronto, ON, Canada",
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1604274985247,
        "Answer_body":"<p>You can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py&amp;preserve-view=true#delete--\" rel=\"nofollow noreferrer\">delete<\/a> method in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py\" rel=\"nofollow noreferrer\">Model<\/a> class to delete a registered model.<\/p>\n<p>This can also be done via the Azure CLI as:<\/p>\n<pre><code>az ml model delete &lt;model id&gt;\n<\/code><\/pre>\n<p>Other commands can be found here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/model?view=azure-cli-latest\" rel=\"nofollow noreferrer\">az ml model<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1604151289467,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64486262",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68303285,
        "Question_title":"'MSIAuthentication' object has no attribute 'get_token'",
        "Question_body":"<p>On Azure ML Workspace Notebook, I'm trying to get my workspace instance, as seen at<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-models#configure-workspace.<\/a><\/p>\n<p>I have a config file and I am running the notebook in an Azure compute instance.<\/p>\n<p>I tried to execute Workspace.from_config().<\/p>\n<p>As a result, I'm getting the 'MSIAuthentication' object has no attribute 'get_token' error.<\/p>\n<p>I tried to submit both <code>MsiAuthentication<\/code> and <code>InteractiveLoginAuthentication<\/code>, as suggested in<\/p>\n<p><a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb.<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1625753450150,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":1670,
        "Owner_creation_time":1589293508567,
        "Owner_last_access_time":1663681781073,
        "Owner_location":null,
        "Owner_reputation":833,
        "Owner_up_votes":9,
        "Owner_down_votes":9,
        "Owner_views":55,
        "Question_last_edit_time":null,
        "Answer_body":"<p><strong>There are 2 solutions I've found:<\/strong><\/p>\n<p>1.- Use the kernel &quot;Python 3.6 - AzureML&quot;<\/p>\n<p>2.- <code>pip install azureml-core --upgrade<\/code><\/p>\n<p>This will <strong>upgrade<\/strong><\/p>\n<blockquote>\n<p>azureml-core to 1.32.0<\/p>\n<\/blockquote>\n<p>But will <strong>downgrade<\/strong>:<\/p>\n<blockquote>\n<p>azure-mgmt-resource to 13.0.0 (was 18.0.0)<\/p>\n<\/blockquote>\n<blockquote>\n<p>azure-mgmt-storage down to 11.2.0 (was 18.0.0)<\/p>\n<\/blockquote>\n<blockquote>\n<p>urllib3 to 1.26.5 (was 1.26.6)<\/p>\n<\/blockquote>\n<p>This upgrade \/ downgrade allows the same package versions as in the python 3.6 anaconda install<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1625753450150,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68303285",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67713876,
        "Question_title":"Is there a way to stop Azure ML throwing an error when exporting zero lines of data?",
        "Question_body":"<p>I am currently developing an Azure ML pipeline that as one of its outputs is maintaining a SQL table holding all of the unique items that are fed into it. There is no way to know in advance if the data fed into the pipeline is new unique items or repeats of previous items, so before updating the table that it maintains it pulls the data already in that table and drops any of the new items that already appear.<\/p>\n<p>However, due to this there are cases where this self-reference results in zero new items being found, and as such there is nothing to export to the SQL table. When this happens Azure ML throws an error, as it is considered an error for there to be zero lines of data to export. In my case, however, this is expected behaviour, and as such absolutely fine.<\/p>\n<p>Is there any way for me to suppress this error, so that when it has zero lines of data to export it just skips the export module and moves on?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1622071490553,
        "Question_score":1,
        "Question_tags":"azure|azure-sql-database|azure-machine-learning-studio",
        "Question_view_count":94,
        "Owner_creation_time":1611181716003,
        "Owner_last_access_time":1639435799460,
        "Owner_location":null,
        "Owner_reputation":119,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Question_last_edit_time":null,
        "Answer_body":"<p>This issue has been resolved by an update to Azure Machine Learning; You can now run pipelines with a flag set to &quot;Continue on Failure Step&quot;, which means that steps following the failed data export will continue to run.<\/p>\n<p>This does mean you will need to design your pipeline to be able to handles upstream failures in its downstream modules; this must be done very carefully.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1630895031177,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67713876",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35870839,
        "Question_title":"Is it possible to import python scripts in Azure?",
        "Question_body":"<p>I have a python script that is written in different files (one for importing, one for calculations, et cetera). These are all in the same folder, and when I need a function from another function I do something like<\/p>\n\n<pre><code>import file_import\nfile_import.do_something_usefull()\n<\/code><\/pre>\n\n<p>where, of course, in the <code>file_import<\/code> there is a function <code>do_something_usefull()<\/code> that, uhm, does something usefull. How can I accomplish the same in Azure?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_time":1457449397920,
        "Question_score":1,
        "Question_tags":"python|azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":1473,
        "Owner_creation_time":1379265931347,
        "Owner_last_access_time":1663852656720,
        "Owner_location":"Rotterdam, Netherlands",
        "Owner_reputation":6502,
        "Owner_up_votes":1650,
        "Owner_down_votes":188,
        "Owner_views":561,
        "Question_last_edit_time":1457540530820,
        "Answer_body":"<p>I found it out myself. It is documenten on Microsoft's site <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-execute-python-scripts\/\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<p>The steps, very short, are:<\/p>\n\n<ol>\n<li>Include all the python you want in a .zip<\/li>\n<li>Upload that zip as a dataset<\/li>\n<li>Drag the dataset as the third option parameter in the 'execute python'-block (example below)<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/9FuMr.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9FuMr.png\" alt=\"Example dragging zip to Python script\"><\/a><\/p>\n\n<ol start=\"4\">\n<li>execute said function by importing <code>import Hello<\/code> (the name of the file, not the zip) and running <code>Hello.do_something_usefull()<\/code><\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1457451133737,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1457451850803,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35870839",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":31507547,
        "Question_title":"Azure Machine Learning - batch execution partially working",
        "Question_body":"<p>I have been following this <a href=\"https:\/\/gallery.azureml.net\/Experiment\/370c80490e774a6cb26edba69c583c9b\" rel=\"nofollow\">gallery sample<\/a> but I just can't seem to get batch execution to return multiple scores in one job.<\/p>\n\n<p>Everything works fine i.e. can deploy the prediction web API and request a single scoring. But whenever I send a batch execution job (using the <a href=\"https:\/\/studio.azureml.net\/apihelp\/workspaces\/9dbdce0846e64a5f9c925116e0cb6388\/webservices\/7df2a06ad50348d78f0e1cb81f3742ab\/endpoints\/87bfd4ea0615412bac19c34422ced730\/jobs\" rel=\"nofollow\">sample C# codes<\/a>) with more than one request e.g.:<\/p>\n\n<pre><code>ID1,ID2\n1,2\n3,1\n5,1\n<\/code><\/pre>\n\n<p>Azure ML will only return the prediction scores for the first request <code>1,2<\/code> but not for the other rows.<\/p>\n\n<p>I'm not sure where I'm doing wrong but I should be expecting results for all three requests. Any help would be appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1437353901330,
        "Question_score":1,
        "Question_tags":"c#|azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":269,
        "Owner_creation_time":1316278453427,
        "Owner_last_access_time":1663640052820,
        "Owner_location":"Singapore",
        "Owner_reputation":1365,
        "Owner_up_votes":544,
        "Owner_down_votes":512,
        "Owner_views":310,
        "Question_last_edit_time":1437413945293,
        "Answer_body":"<p>It looks like you've chosen an unfortunate example: the custom scripts in the Retail Forecasting web service explicitly drop all but the first ID pair. To see this, try loading the \"Retail Forecasting: Step 6A of 6\" experiment and check out the code in the \"Create a complete time series. Add future time stamps\" module. You will find the following:<\/p>\n\n<pre><code>all.time &lt;- data.frame(ID1 = data$ID1[1], ID2 = data$ID2[1], time = all.time)\ndata &lt;- join(all.time, data, by = c(\"ID1\", \"ID2\", \"time\"), type = \"left\")\nmaml.mapOutputPort(\"data\");\n<\/code><\/pre>\n\n<p>The left join statement will ignore any rows where data$ID1 != data$ID1[1]  and data$ID2 != data$ID2[1]. That is why you are losing everything but the first ID pair.<\/p>\n\n<p>It appears batch prediction for multiple ID pairs in a single job was not a use case that the custom script authors envisioned for their web service. If you are proficient in R and particularly interested in this use case, you could modify the scripts in this experiment to support processing multiple time series concurrently. Otherwise, you might want to simply try another example experiment.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1472479254437,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/31507547",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52705769,
        "Question_title":"Azure ML Tune Model Hyper Parameters",
        "Question_body":"<p>Here's question proposed at the end of the chapter in 70-774 exam reference book. <\/p>\n\n<blockquote>\n  <p>If you connect a neural network with a Tune Model Hyperparameters module configured\n  with Random Sweep and Maximum number of runs on random sweep = 1, how\n  many neural networks are trained during the execution of the experiment? Why? If you\n  connect a validation dataset to the third input of the Tune Model Hyperparameters\n  module, how many neural networks are trained now?<\/p>\n<\/blockquote>\n\n<p>And the answer is :<\/p>\n\n<blockquote>\n  <p>Without validation dataset 11 (10 of k-fold cross validation + 1 trained with all the data\n  with the best combination of hyperparameters). With the validation set only 1 neural\n  network is trained, so the best model is not trained using the validation set if you provide\n  it.<\/p>\n<\/blockquote>\n\n<p>Where does 10 come from? As far as I understand the number should be 2 and 1 respectively. Shouldn't it create n-folds where n is equal to the number of runs?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1539013176610,
        "Question_score":0,
        "Question_tags":"machine-learning|neural-network|azure-machine-learning-studio",
        "Question_view_count":329,
        "Owner_creation_time":1528790837107,
        "Owner_last_access_time":1660146049397,
        "Owner_location":"Paris, France",
        "Owner_reputation":610,
        "Owner_up_votes":143,
        "Owner_down_votes":0,
        "Owner_views":203,
        "Question_last_edit_time":null,
        "Answer_body":"<p>When you use the Tune Model Hyperparameters module without a validation dataset, this means, when you use only the 2nd input data port, the module works in cross-validation mode. So the best-parameters model is found by doing cross-validation over the provided dataset, and to do this, the dataset is splitted in k-folds. By default, the module splits the data in 10 folds. In case you want to split the data in a different number of folds, you can connect a Partition and Sample module at the 2nd input, selecting Assign to Folds and indicating the number of folds desired. In many cases k=5 is a reasonable option.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1539202336323,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52705769",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45328657,
        "Question_title":"Scheduling Azure Machine Learning Experimnets",
        "Question_body":"<p>How do i schedule Azure ML Experiments which is not deployed as web service?<\/p>\n\n<p>I have developed a Azure Experiment which imports data from on-premise database and exports data to SQL db. How can i schedule that to run weekly?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1501076325577,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":520,
        "Owner_creation_time":1359784845430,
        "Owner_last_access_time":1654012514917,
        "Owner_location":"India",
        "Owner_reputation":400,
        "Owner_up_votes":40,
        "Owner_down_votes":2,
        "Owner_views":147,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can use <strong>Azure PowerShell<\/strong> for automating this task, and use <strong>Windows Task Scheduler<\/strong> to schedule this script to run automatically.<\/p>\n\n<p>For Azure PowerShell,<\/p>\n\n<p>You may visit <a href=\"https:\/\/github.com\/hning86\/azuremlps\" rel=\"nofollow noreferrer\"><strong>this page<\/strong><\/a> to setup an Azure PowerShell script. It's a long journey, but it's worth it. Make sure to <strong><em>follow the prerequisites to be installed on your local PC (Azure-PowerShell v4.0.1)<\/em><\/strong>.<\/p>\n\n<p>For Windows Task Scheduler,<\/p>\n\n<p>Visit <a href=\"https:\/\/www.metalogix.com\/help\/Content%20Matrix%20Console\/SharePoint%20Edition\/002_HowTo\/004_SharePointActions\/012_SchedulingPowerShell.htm\" rel=\"nofollow noreferrer\"><strong>this link<\/strong><\/a> to schedule your created Azure PowerShell script to run at a scheduled\/repeated time.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1502973065180,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45328657",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35631267,
        "Question_title":"Azure ML in \"Execute Python Script\" module :Common table expressions is not supported in sqlite3",
        "Question_body":"<p>I ran into this issue yesterday, while trying to use the same sqlite script I used in \"Apply SQL Transformation\" module in Azure ML, in Sqlite over Python module in Azure ML:<\/p>\n\n<pre><code>with tbl as (select * from t1)\nselect * from tbl\n<\/code><\/pre>\n\n<p>Here is the error I got:<\/p>\n\n<pre><code>[Critical]     Error: Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\n  File \"C:\\server\\invokepy.py\", line 169, in batch\ndata:text\/plain,Caught exception while executing function: Traceback (most recent call last):\n    odfs = mod.azureml_main(*idfs)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\io\\sql.py\", line 388, in read_sql\n  File \"C:\\temp\\azuremod.py\", line 193, in azureml_main\n    results = pd.read_sql(query,con)\n    coerce_float=coerce_float, parse_dates=parse_dates)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\io\\sql.py\", line 1017, in execute\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\io\\sql.py\", line 1022, in read_sql\n    cursor = self.execute(*args)\n    raise_with_traceback(ex)\n  File \"C:\\pyhome\\lib\\site-packages\\pandas\\io\\sql.py\", line 1006, in execute\n---------- End of error message from Python  interpreter  ----------\n    cur.execute(*args)\nDatabaseError: Execution failed on sql:  with tbl as (select * from t1)\n                    select * from tbl\n<\/code><\/pre>\n\n<p>and the Python code:<\/p>\n\n<pre><code>def azureml_main(dataframe1 = None, dataframe2 = None):\n    import pandas as pd\n    import sqlite3 as lite\n    import sys\n    con = lite.connect('data1.db')\n    con.text_factory = str\n    with con:\n        cur = con.cursor()\n\n        if (dataframe1 is not None):\n            cur.execute(\"DROP TABLE IF EXISTS t1\")\n            dataframe1.to_sql('t1',con)\n        query = '''with tbl as (select * from t1)\n                    select * from tbl'''                      \n        results = pd.read_sql(query,con)    \n\n    return results,\n<\/code><\/pre>\n\n<p>when replacing the query with:<\/p>\n\n<pre><code>select * from t1\n<\/code><\/pre>\n\n<p>It worked as expected.\nAs you probably know, Common table expressions is a key feature in Sqlite, the ability to run recursive code is a \"must have\" in any functional language such as Sqlite.<\/p>\n\n<p>I also tried to run my Python script in Jupyter Notebook in Azure, that also worked as expected.<\/p>\n\n<p>Is it possible we have a different configuration for Sqlite in the Python module than in Jupyter Notebook and in \"Apply SQL Transformation\" module?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1456413421317,
        "Question_score":2,
        "Question_tags":"python|sqlite|common-table-expression|azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":280,
        "Owner_creation_time":1320061998253,
        "Owner_last_access_time":1656424560827,
        "Owner_location":null,
        "Owner_reputation":778,
        "Owner_up_votes":176,
        "Owner_down_votes":6,
        "Owner_views":89,
        "Question_last_edit_time":1456812883803,
        "Answer_body":"<p>I reproduced your issue and reviewed the <code>SQL Queries<\/code> doc of <code>pandas.io.sql<\/code> at <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/io.html#sql-queries\" rel=\"nofollow\">http:\/\/pandas.pydata.org\/pandas-docs\/stable\/io.html#sql-queries<\/a>. I tried to use <code>read_sql_query<\/code> to solve it, but failed.<\/p>\n\n<p>According to the <code>pandas<\/code> doc, tt seems that <code>Pandas<\/code> not support the usage for this SQL syntax.<\/p>\n\n<p>Base on my experience and according to your SQL, I tried to do the SQL <code>select * from (select * from t1) as tbl<\/code> instead of your SQL that work for <code>Pandas<\/code>.<\/p>\n\n<p>Hope it helps. Best Regards. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1456485065183,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35631267",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46500756,
        "Question_title":"Azure ML Studio workspace from 3rd party does not show up in workspace list on https:\/\/studio.azureml.net\/",
        "Question_body":"<p>I have had a few azure ml workspaces though my own Azure account for a while. Recently I was added as \"Contributor\" to a new Azure workspace as Contributor. In Azure Portal I can see it clearly and have access to it. When going to <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/<\/a> It does not show up in the list of workspaces of the correct region, nor in any other region. <\/p>\n\n<p>In Azure Portal I have to change \"Directory\" (top right account menu) to the 3rd party directory to see it.<\/p>\n\n<p>Is there a way to do that in azureml.net ? Or is there something else that might be wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1506758082960,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":56,
        "Owner_creation_time":1403185510317,
        "Owner_last_access_time":1598430888713,
        "Owner_location":null,
        "Owner_reputation":383,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":36,
        "Question_last_edit_time":null,
        "Answer_body":"<p>access to the workspace is controlled by the workspace owner from the settings page inside of the Azure ML workspace. the owners\/contributors etc. listed in Azure portal does NOT grant you access to the workspace. <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1506907193290,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46500756",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56021977,
        "Question_title":"Replace values in a column based on a condition in Azure ML Studio",
        "Question_body":"<p>How do I replace the values in a specific column with a particular value based on a condition in Azure ML Studio. I can do this using pandas in python as foolows:<\/p>\n\n<pre><code>df.loc[df['col_name'] &gt; 1990, 'col_name'] = 1\n<\/code><\/pre>\n\n<p>I'm trying to find a Module in Azure Machine Learning Studio that does the equivalent of this. <\/p>\n\n<p>I understand there is a replace option under the ConverToDataset module and a Replace Discrete Values module. But neither of these seems to do what I want. Is there an option to replace the values in just one column to a specific value based on a condition?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1557229871357,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":564,
        "Owner_creation_time":1450260166773,
        "Owner_last_access_time":1663955203357,
        "Owner_location":null,
        "Owner_reputation":1587,
        "Owner_up_votes":123,
        "Owner_down_votes":8,
        "Owner_views":540,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can use either the more general <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/apply-sql-transformation\" rel=\"nofollow noreferrer\">Apply SQL Transformation<\/a>, or the dedicated <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/clip-values\" rel=\"nofollow noreferrer\">Clip Values<\/a> module. If all else fails, there's also <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/execute-python-script\" rel=\"nofollow noreferrer\">Execute Python Script<\/a>.<\/p>\n\n<p>Personally, for your example I'd use <code>Clip Values<\/code> with <code>Clip Peaks<\/code> and <code>Upper Threshold<\/code> set. For more complex rules I'd use either <code>Apply SQL Transformation<\/code> or <code>Execute Python Script<\/code>, depending on the rules but favouring SQL :).<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1557391929597,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56021977",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61392212,
        "Question_title":"Authentication Error: Compute instance for Azure Machine Learning",
        "Question_body":"<p>I created Compute instance in Azure Machine Learning in the Edge browser right after logging in. When it was started, I clicked on the Jupyter link. <\/p>\n\n<p>I got the following authentication error: \"User live.com#myname@outlook.com does not have access to compute instance vm-aml-lab4.\nOnly the creator can access a compute instance.\"<\/p>\n\n<p>Is there a way to avoid this error?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1587659313437,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":953,
        "Owner_creation_time":1330373362200,
        "Owner_last_access_time":1663907622027,
        "Owner_location":"Kennett Square, PA",
        "Owner_reputation":445,
        "Owner_up_votes":377,
        "Owner_down_votes":0,
        "Owner_views":104,
        "Question_last_edit_time":1591885030160,
        "Answer_body":"<p>Currently the AML compute instance only allows the creator to access the CI.It's known bug, once it's fixed we will update you. We think it is related to MSA accounts.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1587713029463,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1598335141843,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61392212",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70571948,
        "Question_title":"Why is env different in an Azure ML notbook and an Azure ML terminal?",
        "Question_body":"<p>I'm using MS Azure ML and have found that when I start a Notebook (from the Azure ML Studio) it is executing in a a different environment than if I create a Python script and run it from the studio. I want to be able to create a specific environment and have the Notebook use that. The environment that the Notebook seems to run does not contain the packages I need and I want to preserve different environments.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1641247442447,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":225,
        "Owner_creation_time":1639768329610,
        "Owner_last_access_time":1644962247200,
        "Owner_location":"Eden Prarie, MN",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":"<p>First open a terminal, using the same compute target as you want to use with your Notebook afterwards, and to use and <strong>existing environment<\/strong> you can do:<\/p>\n<pre><code>conda activate existing_env\nconda install ipykernel\npython -m ipykernel install --user --name existing_env --display-name &quot;Python 3.8 - Existing Environment&quot;   \n<\/code><\/pre>\n<p>However, to create a <strong>new environment<\/strong> and use it in you AzureML Notebook, you have to do the following commands:<\/p>\n<pre><code>conda create --name new_env python=3.8\nconda activate new_env\nconda install pip\nconda install ipykernel\npython -m ipykernel install --user --name new_env --display-name &quot;Python 3.8 - New Environment&quot;\n<\/code><\/pre>\n<p>And then last, but not least, you have to edit the Jupyter Kernel display names:<\/p>\n<p><strong>IMPORTANT<\/strong> Please ensure you are comfortable running all these steps:<\/p>\n<pre><code>jupyter kernelspec list\ncd &lt;folder-that-matches-the-kernel-of-your-environment&gt;\nsudo nano kernel.json\n<\/code><\/pre>\n<p>Then edit the name to match what you want and save the file.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1641553768433,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1641841183277,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70571948",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34990561,
        "Question_title":"Azure Machine Learning Request Response latency",
        "Question_body":"<p>I have made an Azure Machine Learning Experiment which takes a small dataset (12x3 array) and some parameters and does some calculations using a few Python modules (a linear regression calculation and some more). This all works fine.<\/p>\n\n<p>I have deployed the experiment and now want to throw data at it from the front-end of my application. The API-call goes in and comes back with correct results, but it takes up to 30 seconds to calculate a simple linear regression. Sometimes it is 20 seconds, sometimes only 1 second. I even got it down to 100 ms one time (which is what I'd like), but 90% of the time the request takes more than 20 seconds to complete, which is unacceptable.<\/p>\n\n<p>I guess it has something to do with it still being an experiment, or it is still in a development slot, but I can't find the settings to get it to run on a faster machine.<\/p>\n\n<p>Is there a way to speed up my execution?<\/p>\n\n<p>Edit: To clarify: The varying timings are obtained with the same test data, simply by sending the same request multiple times. This made me conclude it must have something to do with my request being put in a queue, there is some start-up latency or I'm throttled in some other way.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1453718439993,
        "Question_score":8,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":1128,
        "Owner_creation_time":1446116840793,
        "Owner_last_access_time":1589929968357,
        "Owner_location":"Antwerp, Belgium",
        "Owner_reputation":311,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":34,
        "Question_last_edit_time":1453911336527,
        "Answer_body":"<p>First, I am assuming you are doing your timing test on the published AML endpoint.<\/p>\n\n<p>When a call is made to the AML the first call must warm up the container. By default a web service has 20 containers. Each container is cold, and a cold container can cause a large(30 sec) delay. In the string returned by the AML endpoint, only count requests that have the <code>isWarm<\/code> flag set to true. By smashing the service with MANY requests(relative to how many containers you have running) can get all your containers warmed.<\/p>\n\n<p>If you are sending out dozens of requests a instance, the endpoint might be getting throttled. You can adjust the number of calls your endpoint can accept by going to manage.windowsazure.com\/<\/p>\n\n<ol>\n<li>manage.windowsazure.com\/<\/li>\n<li>Azure ML Section from left bar<\/li>\n<li>select your workspace<\/li>\n<li>go to web services tab<\/li>\n<li>Select your web service from list<\/li>\n<li>adjust the number of calls with slider<\/li>\n<\/ol>\n\n<p>By enabling debugging onto your endpoint you can get logs about the execution time for each of your modules to complete. You can use this to determine if a module is not running as you intended which may add to the time.<\/p>\n\n<p>Overall, there is an overhead when using the Execute python module, but I'd expect this request to complete in under 3 secs. <\/p>",
        "Answer_comment_count":11.0,
        "Answer_creation_time":1453832406127,
        "Answer_score":8.0,
        "Question_favorite_count":5.0,
        "Answer_last_edit_time":1453911048927,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34990561",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59637596,
        "Question_title":"Where does Python modules installed on Azure Machine Learning Studio",
        "Question_body":"<p>I understand the azure machine learning studio (classic) version using Anaconda distribution but my question is where would the python modules like pandas\/tensorflow are installed when using <strong>IPython interface of Azure ML<\/strong>. Is this on AML studio itself or in azure blob (AML studio uses blob as backend store)? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1578440246977,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":136,
        "Owner_creation_time":1500744375327,
        "Owner_last_access_time":1660004233300,
        "Owner_location":null,
        "Owner_reputation":255,
        "Owner_up_votes":20,
        "Owner_down_votes":0,
        "Owner_views":130,
        "Question_last_edit_time":1578440835317,
        "Answer_body":"<p>Here is my screenshots for tabs <code>EXPERIMENTS<\/code> and <code>NOTEBOOKS<\/code> in Azure Machine Learning Studio (classic), as the figures below.<\/p>\n\n<p>Fig 1. I created a <code>Excute Python Script<\/code> module with the code to print the <code>sys.path<\/code> and the real path of <code>pandas<\/code> installed.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/KdkJa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KdkJa.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 2. The <code>View output log<\/code> page of the code in Fig 1 shows <code>EXPERIMENTS<\/code> is a runtime of Anaconda on Windows. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/zo9te.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/zo9te.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 3. I created a notebook named <code>demo<\/code> and run the same code as Fig 1, the result shows <code>NOTEBOOKS<\/code> is a runtime of Anaconda on Linux, even the notenooks url is started with <code>notebooks.azure.com<\/code>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/uAGRk.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/uAGRk.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Fig 4. I used different commands like <code>lsb_release -a<\/code>, <code>fdisk -l<\/code>, <code>lsdev<\/code>, <code>ls \/dev<\/code>, <code>df -a<\/code> to try to see the Linux version and its disk or partition information, the result shows it's a Ubuntu Linux container.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/R4wC6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/R4wC6.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Other infomation what you want to know, you can try to check by yourself.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1578465543193,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59637596",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37519858,
        "Question_title":"What type should the returned scores from an R scoring script?",
        "Question_body":"<p>I am attempting to develop an Azure ML experiment that uses R to perform predictions of a continuous response variable. The initial experiment is relatively simple, incorporating only a few experiment items, including \"Create R Model\", \"Train Model\" and \"Score Model\", along with some data input.<\/p>\n\n<p>I have written a training script and a scoring script, both of which appear to execute without errors when I run the experiment within ML Studio. However, when I examine the scored dataset, the score values are all missing values. So I am concerned that my scoring script could be returning scores incorrectly. Can anyone advise what type I should be returning? Is it meant to be a single column data.frame, or something else?<\/p>\n\n<p>It is also possible that my scores are not being properly calculated within the scoring script, although I have run the training and scoring scripts within R Studio, which shows the expected results. It would also be helpful if someone could suggest how to perform debugging of my scoring script in some way, so that I could determine whereabouts the code is failing to behave as expected.<\/p>\n\n<p>Thanks, Paul<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1464593030317,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":238,
        "Owner_creation_time":1464571689107,
        "Owner_last_access_time":1470182061490,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Try using this sample and compare with yours - <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Compare-Sample-5-in-R-vs-Azure-ML-1\" rel=\"nofollow\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/Compare-Sample-5-in-R-vs-Azure-ML-1<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1464675335140,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37519858",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73702976,
        "Question_title":"How to split Azure ML pipeline steps to debug",
        "Question_body":"<p>I have created an Azure ML pipeline with different steps (data preprocess, train, validation ...). And for pass data from one step to the next I have used the PipelineData object.<\/p>\n<p><em>Example passing the model from train step to validate one:<\/em><\/p>\n<pre><code>    # Create a PipelineData to pass model from train to register\n    model_path = PipelineData('model')\n\n    # Step 2\n    train_step = PythonScriptStep(\n        name = 'Train the Model',\n        script_name = 'TrainStepScript.py',\n        source_directory = source_folder,\n        arguments = ['--training_data', prepped_data,\n                     '--model_name', model_name,\n                     '--model_path', model_path],\n        outputs = [model_path],\n        compute_target = compute_target,\n        runconfig = aml_run_config,\n        allow_reuse = True\n    )\n\n    # Step 3\n    third_step = PythonScriptStep(\n        name = 'Evaluate &amp; register the Model',\n        script_name = 'ValidateStepScript.py',\n        source_directory = source_folder,\n        arguments = ['--model_name', model_name,\n                     '--model_path', model_path],\n        inputs = [model_path],\n        compute_target = compute_target,\n        runconfig = aml_run_config,\n        allow_reuse = True\n    )\n<\/code><\/pre>\n<p>Now for debugging and development purposes I want to create a script to run separately the different steps using a ScriptRunConfig (with the same environment and arguments of the StepScript in the pipeline). But the problem is I don't know how to simulate the data input\/output of each step, because the DataPipeline object is not working for this purpose.<\/p>\n<p>Just for clarification, my goal is to NOT modify the original pipeline StepScripts, so I can use them after debugging in the final pipeline. To sum up, my question is: how can I emulate the DataPipeline object (if possible) in this case?<\/p>\n<p><em>Example of what I'm trying to build:<\/em><\/p>\n<pre><code># Passing in some way the model path (from local)\nmodel_path = PipelineData('model')\n\n# Create a script config for validate step\nvalidate_script_config = ScriptRunConfig(\n    source_directory = source_folder,\n    script = 'ValidateStepScript.py',\n    arguments = ['--model_name', model_name,\n                 '--model_path', model_path],\n    environment = experiment_env,\n    docker_runtime_config = DockerConfiguration(use_docker=True)\n)\n\nexperiment = Experiment(workspace=ws, name=experiment_name)\ndata_run = experiment.submit(config=data_script_config)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1663071829967,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":41,
        "Owner_creation_time":1661942018833,
        "Owner_last_access_time":1663930344050,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Question_last_edit_time":null,
        "Answer_body":"<p>We can download the output of the model in a repository and make them as the source file for the later steps as required. The below code block can be incorporated in the same pipeline which is being used now.<\/p>\n<p>To download the model output:<\/p>\n<pre><code>train_step = pipeline_run1.find_step_run('train.py')\n\nif train_step:\n    train_step_obj = train_step[0] \n    train_step_obj.get_output_data('processed_data1').download(&quot;.\/outputs&quot;) # download the output to current directory\n<\/code><\/pre>\n<p>after downloading the model, then use that as the parent source directory in source_directory<\/p>\n<pre><code>from azureml.core import ScriptRunConfig, Experiment\n   # create or load an experiment\n   experiment = Experiment(workspace, 'MyExperiment')\n   # create or retrieve a compute target\n   cluster = workspace.compute_targets['MyCluster']\n   # create or retrieve an environment\n   env = Environment.get(ws, name='MyEnvironment')\n   # configure and submit your training run\n   config = ScriptRunConfig(source_directory='.',\n                            command=['python', 'train.py'],\n                            compute_target=cluster,\n                            environment=env)\n   script_run = experiment.submit(config)\n<\/code><\/pre>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1663156202290,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73702976",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42844593,
        "Question_title":"Comparing brier score for Azure ML classifier",
        "Question_body":"<p>I'm trying to compare the brier score for two classifiers in Azure ML studio:<\/p>\n\n<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import brier_score_loss\n\ndef azureml_main(dataframe1, dataframe2):\n    colnames_1 = dataframe1.columns\n    y_true_1 = np.array(dataframe1[colnames_1[1]])\n    y_prob_1 = np.array(dataframe1[colnames_1[-1]])\n    brier_score_1 = brier_score_loss(y_true_1, y_prob_1)\n\n    colnames_2 = dataframe2.columns\n    y_true_2 = np.array(dataframe2[colnames_2[1]])\n    y_prob_2 = np.array(dataframe2[colnames_2[-1]])\n    brier_score_2 = brier_score_loss(y_true_2, y_prob_2)\n\n    data = {'brier_score': [brier_score_1, brier_score_2]}\n    result = pd.DataFrame(data, columns=['brier_score'])\n\n    return result\n<\/code><\/pre>\n\n<p>My problem is that the script only outputs a value in the first row with the brier score of the first dataset. The second row is empty. This is how I have connected the script: \n<img src=\"https:\/\/anonimag.es\/i\/azure0f4ae.png\" alt=\"azure\"><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1489697707193,
        "Question_score":0,
        "Question_tags":"python|python-3.x|azure|azure-machine-learning-studio",
        "Question_view_count":97,
        "Owner_creation_time":1424620848827,
        "Owner_last_access_time":1663938801623,
        "Owner_location":null,
        "Owner_reputation":2026,
        "Owner_up_votes":599,
        "Owner_down_votes":15,
        "Owner_views":130,
        "Question_last_edit_time":1489716097823,
        "Answer_body":"<p>I turned out that the problem was caused by a few NaN values in the second dataframe.\nAdding <code>dataframe2 = dataframe2.dropna()<\/code> to the top of the script solved the problem.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1490900323347,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42844593",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38927230,
        "Question_title":"Panda AssertionError columns passed, passed data had 2 columns",
        "Question_body":"<p>I am working on Azure ML implementation on text analytics with NLTK, the following execution is throwing <\/p>\n\n<pre><code>AssertionError: 1 columns passed, passed data had 2 columns\\r\\nProcess returned with non-zero exit code 1\n<\/code><\/pre>\n\n<p>Below is the code <\/p>\n\n<pre><code># The script MUST include the following function,\n# which is the entry point for this module:\n# Param&lt;dataframe1&gt;: a pandas.DataFrame\n# Param&lt;dataframe2&gt;: a pandas.DataFrame\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    # import required packages\n    import pandas as pd\n    import nltk\n    import numpy as np\n    # tokenize the review text and store the word corpus\n    word_dict = {}\n    token_list = []\n    nltk.download(info_or_id='punkt', download_dir='C:\/users\/client\/nltk_data')\n    nltk.download(info_or_id='maxent_treebank_pos_tagger', download_dir='C:\/users\/client\/nltk_data')\n    for text in dataframe1[\"tweet_text\"]:\n        tokens = nltk.word_tokenize(text.decode('utf8'))\n        tagged = nltk.pos_tag(tokens)\n\n\n      # convert feature vector to dataframe object\n    dataframe_output = pd.DataFrame(tagged, columns=['Output'])\n    return [dataframe_output]\n<\/code><\/pre>\n\n<p>Error is throwing here <\/p>\n\n<pre><code> dataframe_output = pd.DataFrame(tagged, columns=['Output'])\n<\/code><\/pre>\n\n<p>I suspect this to be the tagged data type passed to dataframe, can some one let me know the right approach to add this to dataframe.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1471040597197,
        "Question_score":7,
        "Question_tags":"python|pandas|dataframe|nltk|azure-machine-learning-studio",
        "Question_view_count":48200,
        "Owner_creation_time":1370924418390,
        "Owner_last_access_time":1663478900357,
        "Owner_location":"Toronto, ON, Canada",
        "Owner_reputation":1748,
        "Owner_up_votes":136,
        "Owner_down_votes":55,
        "Owner_views":339,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Try this:<\/p>\n\n<pre><code>dataframe_output = pd.DataFrame(tagged, columns=['Output', 'temp'])\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1471040769603,
        "Answer_score":13.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38927230",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58035744,
        "Question_title":"AML run.log() and run.log_list() fail without error",
        "Question_body":"<p>I have a Pipeline with DatabricksSteps each containing:<\/p>\n\n<pre><code>from azureml.core.run import Run\nrun = Run.get_context()\n#do stuff\nrun.log(name, val, desc)\nrun.log_list(name, vals, desc)\nrun.log_image(title, fig, desc)\n<\/code><\/pre>\n\n<p>Only <code>log_image()<\/code> seems to work.  The image appears in the \"images\" section of the AML experiment workspace as expected, but the \"tracked metrics\" and \"charts\" areas are blank.  In an interactive job, <code>run.log()<\/code> and <code>run.log_list()<\/code> work as expected.  I tested that there is no problem with the arguments by using <code>print()<\/code> instead of <code>run.log()<\/code>.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1569018204223,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":121,
        "Owner_creation_time":1465320834943,
        "Owner_last_access_time":1617290067470,
        "Owner_location":"Redmond, WA, USA",
        "Owner_reputation":677,
        "Owner_up_votes":13,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Add run.flush() at the end of the script.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1569427861030,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58035744",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56024354,
        "Question_title":"\"Session has expired\" message with Machine Learning Studio",
        "Question_body":"<p>I am getting consistent error \"Your session has expired\" (screenshot below), after logging in to machine learning studio. <\/p>\n\n<p>I have tried chrome incognito and guest windows, but no difference. <\/p>\n\n<p>I am using a new account and have signed up for Free workspace. Any suggestion to get past this or delete workspace, to start again?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/fsqtw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fsqtw.png\" alt=\"Error screenshot\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1557237613340,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":482,
        "Owner_creation_time":1255194026493,
        "Owner_last_access_time":1617715031493,
        "Owner_location":"Bedford, MA, USA",
        "Owner_reputation":300,
        "Owner_up_votes":31,
        "Owner_down_votes":0,
        "Owner_views":63,
        "Question_last_edit_time":1557240710417,
        "Answer_body":"<p>I can reproduce your issue, I sign out and log in <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/<\/a> again, it solved my problem. Or you can try to clear the browsing data or change a browser. Anyway, the issue should be caused by the browser, not azure. Even if your account is not the owner of the workspace, when you click <code>Sign In<\/code> in <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow noreferrer\">https:\/\/studio.azureml.net\/<\/a> , it will create a free workspace(with a different workspace id) for you automatically.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/MXDJC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/MXDJC.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>If you want to delete the workspace, you need to let the owner of the workspace delete it, navigate to the <code>SETTINGS<\/code> on the left of the studio -> <code>NAME<\/code> -> <code>DELETE WORKSPACE<\/code>. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/E6aUl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/E6aUl.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1557300039457,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1557300456467,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56024354",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38119062,
        "Question_title":"Pulling data from Stream Analytics to Azure Machine Learning",
        "Question_body":"<p>Working on a IoT telemetry project that receives humidity and weather pollution data from different sites on the field. I will then apply Machine Learning on the collected data. I'm using Event Hubs and Stream Analytics. Is there a way of pulling the data to Azure Machine Learning without the hassle of writing an application to get it from Stream Analytics and push to AML web service?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1467278958850,
        "Question_score":0,
        "Question_tags":"azure|iot|azure-stream-analytics|azure-machine-learning-studio",
        "Question_view_count":627,
        "Owner_creation_time":1311017514580,
        "Owner_last_access_time":1664027428383,
        "Owner_location":"Beirut, Lebanon",
        "Owner_reputation":408,
        "Owner_up_votes":88,
        "Owner_down_votes":6,
        "Owner_views":32,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Stream Analytics has a functionality called the \u201c<a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/\" rel=\"nofollow\">Functions<\/a>\u201d. You can call any web service you\u2019ve published using AML from within Stream Analytics and apply it within your Stream Analytics query. Check this <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/stream-analytics-machine-learning-integration-tutorial\/\" rel=\"nofollow\">link for a tutorial<\/a>.\nExample workflow in your case would be like the following;<\/p>\n\n<ul>\n<li>Telemetry arrives and reaches Stream Analytics<\/li>\n<li>Streaming Analytics (SA) calls the Machine Learning function to apply it on the data<\/li>\n<li>SA redirects it to the output accordingly, here you can use the PowerBI to create a predictions dashboards.<\/li>\n<\/ul>\n\n<p>Another way would be using R, and here\u2019s a good tutorial showing that <a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/\" rel=\"nofollow\">https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/12\/10\/azure-ml-now-available-as-a-function-in-azure-stream-analytics\/<\/a> . \nIt is more work of course but can give you more control as you control the code.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1467284456457,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38119062",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64597526,
        "Question_title":"Provision AKS with internal load balancer from AMLS on Azure",
        "Question_body":"<p>I would like to provision an AKS cluster that is connected to a vnet and has an internal load balancer on Azure. I am using code from <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet?tabs=python\" rel=\"nofollow noreferrer\">here<\/a> that looks like this:<\/p>\n<pre><code>import azureml.core\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n# Verify that cluster does not exist already\ntry:\n    aks_target = AksCompute(workspace=ws, name=aks_cluster_name)\n    print(&quot;Found existing aks cluster&quot;)\n\nexcept:\n    print(&quot;Creating new aks cluster&quot;)\n\n    # Subnet to use for AKS\n    subnet_name = &quot;default&quot;\n    # Create AKS configuration\n    prov_config=AksCompute.provisioning_configuration(load_balancer_type=&quot;InternalLoadBalancer&quot;)\n    # Set info for existing virtual network to create the cluster in\n    prov_config.vnet_resourcegroup_name = &quot;myvnetresourcegroup&quot;\n    prov_config.vnet_name = &quot;myvnetname&quot;\n    prov_config.service_cidr = &quot;10.0.0.0\/16&quot;\n    prov_config.dns_service_ip = &quot;10.0.0.10&quot;\n    prov_config.subnet_name = subnet_name\n    prov_config.docker_bridge_cidr = &quot;172.17.0.1\/16&quot;\n\n    # Create compute target\n    aks_target = ComputeTarget.create(workspace = ws, name = &quot;myaks&quot;, provisioning_configuration = prov_config)\n    # Wait for the operation to complete\n    aks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>\n<p>However, I get the following error<\/p>\n<pre><code>K8s failed to assign an IP for Load Balancer after waiting for an hour.\n<\/code><\/pre>\n<p>Is this because the AKS cluster does not yet have a 'network contributor' role for the vnet resource group? Is the only way to get this to work to first create AKS outside of AMLS, grant the network contributor role to the vnet resource group, then attach the AKS cluster to AMLS and configure the internal load balancer afterwards?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1603997735143,
        "Question_score":1,
        "Question_tags":"azure-aks|azure-machine-learning-service|vnet|internal-load-balancer",
        "Question_view_count":352,
        "Owner_creation_time":1589738451347,
        "Owner_last_access_time":1656358607687,
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":1604002322987,
        "Answer_body":"<p>I was able to get this to work by first creating an AKS resource without an internal load balancer, then separately updating the load balancer following this code:<\/p>\n<pre><code>import azureml.core\nfrom azureml.core.compute.aks import AksUpdateConfiguration\nfrom azureml.core.compute import AksCompute\n\n# ws = workspace object. Creation not shown in this snippet\naks_target = AksCompute(ws,&quot;myaks&quot;)\n\n# Change to the name of the subnet that contains AKS\nsubnet_name = &quot;default&quot;\n# Update AKS configuration to use an internal load balancer\nupdate_config = AksUpdateConfiguration(None, &quot;InternalLoadBalancer&quot;, subnet_name)\naks_target.update(update_config)\n# Wait for the operation to complete\naks_target.wait_for_completion(show_output = True)\n<\/code><\/pre>\n<p>No network contributor role was required.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1604359053333,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64597526",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70268372,
        "Question_title":"How to adjust feature importance in Azure AutoML",
        "Question_body":"<p>I am hoping to have some <strong>low code model<\/strong> using Azure AutoML, which is really just going to the AutoML tab, running a classification experiment with my dataset, after it's done, I deploy the best selected model.<\/p>\n<p>The model kinda works (meaning, I publish the endpoint and then I do some manual validation, seems accurate), however, I am not confident enough, because when I am looking at the explanation, I can see something like this:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qM51x.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qM51x.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>4 top features are not really closely important. The most &quot;important&quot; one is really not the one I prefer it to use. I am hoping it will use the <code>Title<\/code> feature more.<\/p>\n<p>Is there such a thing I can adjust the importance of individual features, like ranking all features before it starts the experiment?<\/p>\n<p>I would love to do more reading, but I only found this:<\/p>\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/52484233\/increase-feature-importance\">Increase feature importance<\/a><\/p>\n<p>The only answer seems to be about how to measure if a feature is important.<\/p>\n<p>Hence, does it mean, if I want to customize the experiment, such as selecting which features to &quot;focus&quot;, I should learn how to use the &quot;designer&quot; part in Azure ML? Or is it something I can't do, even with the designer. I guess my confusion is, with ML being such a big topic, I am looking for a direction of learning, in this case of what I am having, so I can improve my current model.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1638921326880,
        "Question_score":2,
        "Question_tags":"machine-learning|azure-machine-learning-studio|azure-machine-learning-service|azure-auto-ml",
        "Question_view_count":119,
        "Owner_creation_time":1296571549840,
        "Owner_last_access_time":1663809103810,
        "Owner_location":"Seattle, WA",
        "Owner_reputation":1021,
        "Owner_up_votes":79,
        "Owner_down_votes":7,
        "Owner_views":138,
        "Question_last_edit_time":1638925038330,
        "Answer_body":"<p>Here is <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-automated-ml#customize-featurization\" rel=\"nofollow noreferrer\">link<\/a> to the document for feature customization.<\/p>\n<p>Using the SDK you can specify &quot;feauturization&quot;: 'auto' \/ 'off' \/ 'FeaturizationConfig' in your <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py\" rel=\"nofollow noreferrer\">AutoMLConfig<\/a> object. Learn more about <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-features\" rel=\"nofollow noreferrer\">enabling featurization<\/a>.<\/p>\n<p>Automated ML tries out different ML models that have different settings which control for overfitting.  Automated ML will pick which overfitting parameter configuration is best based on the best score (e.g. accuracy) it gets from hold-out data.  The kind of overfitting settings these models has includes:<\/p>\n<ul>\n<li>Explicitly penalizing overly-complex models in the loss function that the ML model is optimizing<\/li>\n<li>Limiting model complexity before training, for example by limiting the size of trees in an ensemble tree learning model (e.g. gradient boosting trees or random forest)<\/li>\n<\/ul>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1641210936730,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70268372",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68505595,
        "Question_title":"failing to create image in azure ml workspace",
        "Question_body":"<p>I am able to create image and run azure ml service in one env but when I am moving to another env its not able to create image and failing with this error -<\/p>\n<p>Message: Received bad response from Model Management Service:\nResponse Code: 500\n{&quot;code&quot;:&quot;InternalServerError&quot;,&quot;statusCode&quot;:500,&quot;message&quot;:&quot;An internal server error occurred. Please try again. If the problem persists, contact support.&quot;,&quot;correlation&quot;:{&quot;RequestId&quot;:&quot;8667981d-ef71-4e7c-a735-c43ef07b51b8&quot;}}'<\/p>\n<p>these logs are not helpful to find issue<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1627079442010,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":110,
        "Owner_creation_time":1567209656790,
        "Owner_last_access_time":1663349187993,
        "Owner_location":null,
        "Owner_reputation":417,
        "Owner_up_votes":53,
        "Owner_down_votes":0,
        "Owner_views":233,
        "Question_last_edit_time":null,
        "Answer_body":"<p>As the error message said, this issue is an internal issue, please raise a support ticket to assign a support engineer to investigate it.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1628037949483,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1629745090063,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68505595",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64816630,
        "Question_title":"AuthenticationException when creating Azure ML Dataset from Azure Data Lake Gen2 Datastore",
        "Question_body":"<p>I have an Azure Data Lake Gen2 with public endpoint and a standard Azure ML instance.\nI have created both components with my user and I am listed as Contributor.<\/p>\n<p>I want to use data from this data lake in Azure ML.<\/p>\n<p>I have added the data lake as a Datastore using Service Principal authentication.<\/p>\n<p>I then try to create a Tabular Dataset using the Azure ML GUI I get the following error:<\/p>\n<p>Access denied\nYou do not have permission to the specified path or file.<\/p>\n<pre><code>{\n  &quot;message&quot;: &quot;ScriptExecutionException was caused by StreamAccessException.\\n  StreamAccessException was caused by AuthenticationException.\\n    'AdlsGen2-ListFiles (req=1, existingItems=0)' for '[REDACTED]' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation using this permission.), client request ID '1f9e329b-2c2c-49d6-a627-91828def284e', request ID '5ad0e715-a01f-0040-24cb-b887da000000'. Error message: [REDACTED]\\n&quot;\n}\n<\/code><\/pre>\n<p>I have tried having our Azure Portal Admin, with Admin access to both Azure ML and Data Lake try the same and she gets the same error.<\/p>\n<p>I tried creating the Dataset using Python sdk and get a similar error:<\/p>\n<pre><code>ExecutionError: \nError Code: ScriptExecution.StreamAccess.Authentication\nFailed Step: 667ddfcb-c7b1-47cf-b24a-6e090dab8947\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by AuthenticationException.\n    'AdlsGen2-ListFiles (req=1, existingItems=0)' for 'https:\/\/mydatalake.dfs.core.windows.net\/mycontainer?directory=mydirectory\/csv&amp;recursive=true&amp;resource=filesystem' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation using this permission.), client request ID 'a231f3e9-b32b-4173-b631-b9ed043fdfff', request ID 'c6a6f5fe-e01f-0008-3c86-b9b547000000'. Error message: {&quot;error&quot;:{&quot;code&quot;:&quot;AuthorizationPermissionMismatch&quot;,&quot;message&quot;:&quot;This request is not authorized to perform this operation using this permission.\\nRequestId:c6a6f5fe-e01f-0008-3c86-b9b547000000\\nTime:2020-11-13T06:34:01.4743177Z&quot;}}\n| session_id=75ed3c11-36de-48bf-8f7b-a0cd7dac4d58\n<\/code><\/pre>\n<p>I have created Datastore and Datasets of both a normal blob storage and a managed sql database with no issues and I have only contributor access to those so I cannot understand why I should not be Authorized to add data lake. The fact that our admin gets the same error leads me to believe there are some other issue.<\/p>\n<p>I hope you can help me identify what it is or give me some clue of what more to test.<\/p>\n<p>Edit:\nI see I might have duplicated this post: <a href=\"https:\/\/stackoverflow.com\/questions\/63891547\/how-to-connect-amls-to-adls-gen-2\">How to connect AMLS to ADLS Gen 2?<\/a>\nI will test that solution and close this post if it works<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1605250166337,
        "Question_score":2,
        "Question_tags":"azure|azure-active-directory|azure-data-lake|azure-data-lake-gen2|azure-machine-learning-service",
        "Question_view_count":3179,
        "Owner_creation_time":1288196087393,
        "Owner_last_access_time":1663939895430,
        "Owner_location":"Oslo, Norge",
        "Owner_reputation":1010,
        "Owner_up_votes":1344,
        "Owner_down_votes":1,
        "Owner_views":119,
        "Question_last_edit_time":1605254071243,
        "Answer_body":"<p>This was actually a duplicate of <a href=\"https:\/\/stackoverflow.com\/questions\/63891547\/how-to-connect-amls-to-adls-gen-2\">How to connect AMLS to ADLS Gen 2?<\/a>.<\/p>\n<p>The solution is to give the service principal that Azure ML uses to access the data lake the Storage Blob Data Reader access. And note you have to wait at least some minutes for this to have effect.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1605260557303,
        "Answer_score":4.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64816630",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57596224,
        "Question_title":"How to expose port from locally-deployed AzureML container?",
        "Question_body":"<p>I want to be able to debug a running <code>entry_script.py<\/code> script in VSCode. This code runs in the container created through <code>az ml deploy<\/code> with its own docker run command. This is a local deployment so I'm using a deployment config that looks like this:<\/p>\n\n<pre><code>{\n    \"computeType\": \"LOCAL\",\n    \"port\": 32267\n}\n<\/code><\/pre>\n\n<p>I was thinking about using <code>ptvsd<\/code> to set up a VSCode server but I need to also expose\/map the 5678 port in addition to that 32267 port for the endpoint itself. So it's not clear to me how to map an additional exposed port (typically using the <code>-p<\/code> or <code>-P<\/code> flags in the <code>docker run<\/code> command). <\/p>\n\n<p>Sure, I can <code>EXPOSE<\/code> it in the <code>extra_dockerfile_steps<\/code> configuration but that won't actually map it to a host port that I can connect to\/attach to in VSCode.<\/p>\n\n<p>I tried to determine the run command and maybe modify it but I couldn't find out what that run command is. If I knew how to run the image that's created through AzureML local deployment then I could modify these flags. <\/p>\n\n<p>Ultimately it felt too hacky - if there was a more supported way through <code>az ml deploy<\/code> or through the deployment configuration that would be preferred.<\/p>\n\n<p>This is the code I'm using at the start of the entry_script to enable attachment via <code>ptvsd<\/code>: <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code># 5678 is the default attach port in the VS Code debug configurations\nprint(\"Waiting for debugger attach\")\nptvsd.enable_attach(address=('localhost', 5678), redirect_output=True)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1566406835043,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":206,
        "Owner_creation_time":1254279877887,
        "Owner_last_access_time":1663949658720,
        "Owner_location":"Seattle, WA",
        "Owner_reputation":153,
        "Owner_up_votes":101,
        "Owner_down_votes":1,
        "Owner_views":111,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Unfortunately az ml deploy local doesn't support binding any ports other then the port hosting the scoring server. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1566419274223,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57596224",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40007515,
        "Question_title":"Azure Machine Learning Studio: how to add a dataset from a local Excel file?",
        "Question_body":"<p>Despite prominent how-to posts on how to add datasets to Azure Machine Learning that say Excel is supported, when I actually go to add a dataset and select a local Excel file, there's no option for \"Excel\" in the required datatype property dropdown. I'm surprised that Azure wouldn't support Excel (right?) - am I missing something?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1476303145067,
        "Question_score":2,
        "Question_tags":"excel|azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":1250,
        "Owner_creation_time":1357592818807,
        "Owner_last_access_time":1621964227647,
        "Owner_location":"Ann Arbor, MI",
        "Owner_reputation":99,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The dropdown list indicates the \"Destination\" datatype for the new DATASET file you are creating, not the source type.<\/p>\n\n<p>I just uploaded a <code>.xlsx<\/code> file successfully into a <code>.CSV<\/code> file in AML.<\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_time":1476307260447,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1476377527560,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40007515",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62140446,
        "Question_title":"Dependency missing when running AzureML Estimator in docker environment",
        "Question_body":"<h3>Scenario description<\/h3>\n\n<p>I'm trying to submit a training script to AzureML (want to use AmlCompute, but I'm starting\/testing locally first, for debugging purposes).<\/p>\n\n<p>The <code>train.py<\/code> script I have uses a custom package (<code>arcus.ml<\/code>) and I believe I have specified the right settings and dependencies, but still I get the error: <\/p>\n\n<p><code>User program failed with ModuleNotFoundError: No module named 'arcus.ml'<\/code><\/p>\n\n<h3>Code and reproduction<\/h3>\n\n<p>This the python code I have:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>name='test'\nscript_params = {\n    '--test-par': 0.2\n}\n\nest = Estimator(source_directory='.\/' + name,\n                   script_params=script_params,\n                   compute_target='local',\n                   entry_script='train.py',\n                   pip_requirements_file='requirements.txt',\n                   conda_packages=['scikit-learn','tensorflow', 'keras'])\n\nrun = exp.submit(est)\nprint(run.get_portal_url())\n<\/code><\/pre>\n\n<p>This is the (fully simplified) train.py script in the <code>test<\/code>directory:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from arcus.ml import dataframes as adf\nfrom azureml.core import Workspace, Dataset, Datastore, Experiment, Run\n\n# get hold of the current run\nrun = Run.get_context()\nws = run.get_environment()\n\nprint('training finished')\n<\/code><\/pre>\n\n<p>And this is my requirements.txt file<\/p>\n\n<pre><code>arcus-azureml\narcus-ml\nnumpy\npandas\nazureml-core\ntqdm\njoblib\nscikit-learn\nmatplotlib\ntensorflow\nkeras\n<\/code><\/pre>\n\n<h3>Logs<\/h3>\n\n<p>In the logs file of the run, I can see this section, sot it seems the external module is being installed anyhow.<\/p>\n\n<pre><code>Collecting arcus-azureml\n  Downloading arcus_azureml-1.0.3-py3-none-any.whl (3.1 kB)\nCollecting arcus-ml\n  Downloading arcus_ml-1.0.6-py3-none-any.whl (2.1 kB)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1591043054577,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":208,
        "Owner_creation_time":1360655430743,
        "Owner_last_access_time":1663784892907,
        "Owner_location":"Belgium",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I think this error isn't necessarily about Azure ML. I think the error has to do w\/ the difference b\/w using a hyphen and a period in your package name. But I'm a python packaging newb. \nIn a new conda environment on my laptop, I ran the following<\/p>\n\n<pre><code>&gt; conda create -n arcus python=3.6 -y\n&gt; conda activate arcus\n&gt; pip install arcus-ml\n&gt; python\n&gt;&gt;&gt; from arcus.ml import dataframes as adf\nModuleNotFoundError: No module named 'arcus'\n<\/code><\/pre>\n\n<p>When I look in the env's site packages folder, I didn't see the <code>arcus\/ml<\/code> folder structure I was expecting. There's no arcus code there at all, only the <code>.dist-info<\/code> file<\/p>\n\n<h3><code>~\/opt\/anaconda3\/envs\/arcus\/lib\/python3.6\/site-packages<\/code><\/h3>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/caExn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/caExn.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1591043858447,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1591044471110,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62140446",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57600154,
        "Question_title":"How to correctly specify a private ACR Docker image in an Azure ML Pipeline?",
        "Question_body":"<p>I created a private Azure Container Registry, and pushed a docker image to that registry. I was trying to understand the correct way to access that registry in my pipeline, and my understanding was that I needed to set the following info in the run configuration:<\/p>\n\n<pre><code>        run_config.environment.docker.base_image = \"myprivateacr.azurecr.io\/mydockerimage:0.0.1\"\n        run_config.environment.docker.base_image_registry.username = \"MyPrivateACR\"\n        run_config.environment.docker.base_image_registry.password = \"&lt;the password for the registry&gt;\"\n<\/code><\/pre>\n\n<p>Let's assume that I correctly provided the username and password. Any idea why this didn't work? Or: is there an example of a pipeline notebook that uses a docker image that's in a private docker registry, and thus deals with this type of authentication issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1566428573660,
        "Question_score":0,
        "Question_tags":"docker|azure-machine-learning-service",
        "Question_view_count":278,
        "Owner_creation_time":1491928725063,
        "Owner_last_access_time":1583476614733,
        "Owner_location":"Redmond, WA, United States",
        "Owner_reputation":45,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>There's a separate address property for a custom image registry. Try specifying it this way:<\/p>\n\n<pre><code>run_config.environment.docker.base_image = \"mydockerimage:0.0.1\"\nrun_config.environment.docker.base_image_registry.address = \"myprivateacr.azurecr.io\"\nrun_config.environment.docker.base_image_registry.username = \"MyPrivateACR\"\nrun_config.environment.docker.base_image_registry.password = \"&lt;the password for the registry&gt;\"\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1566481255417,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57600154",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":55837639,
        "Question_title":"How to enable authentication for an ACI webservice in Azure Machine Learning service?",
        "Question_body":"<p>I am able to deploy a Azure Machine learning prediction service in my workspace <code>ws<\/code> using the syntax<\/p>\n\n<pre><code>aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                               memory_gb=8, \n                                               tags={\"method\" : \"some method\"}, \n                                               description='Predict something')\n<\/code><\/pre>\n\n<p>and then<\/p>\n\n<pre><code>service = Webservice.deploy_from_image(deployment_config = aciconfig,\n                                       image = image,\n                                       name = service_name,\n                                       workspace = ws)\n<\/code><\/pre>\n\n<p>as described in the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-deploy-and-where#aci\" rel=\"nofollow noreferrer\">documentation<\/a>.<br>\nHowever, this exposes a service publicly and this is not really optimal.<\/p>\n\n<p>What's the easiest way to shield the ACI service? I understand that passing an <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.webservice.aciwebservice?view=azure-ml-py#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none-\" rel=\"nofollow noreferrer\"><code>auth_enabled=True<\/code><\/a> parameter may do the job, but then how can I instruct a client (say, using <code>curl<\/code> or Postman) to use the service afterwards? <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1556135731340,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azure-container-instances",
        "Question_view_count":676,
        "Owner_creation_time":1415722650717,
        "Owner_last_access_time":1664051478173,
        "Owner_location":"Verona, VR, Italy",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Question_last_edit_time":1556186547293,
        "Answer_body":"<p>See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service#call-the-service-c\" rel=\"nofollow noreferrer\">here<\/a> for an example (in C#). When you enable auth, you will need to send the API key in the \"Authorization\" header in the HTTP request:<\/p>\n\n<pre><code>client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", authKey);\n<\/code><\/pre>\n\n<p>See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service#authentication-key\" rel=\"nofollow noreferrer\">here<\/a> how to retrieve the key.<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1556182170523,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1556183204093,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55837639",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72083832,
        "Question_title":"Send alert if Azure ML pipeline fails",
        "Question_body":"<p>I am trying to add an alert if Azure ML pipeline fails. It looks that one of the ways is to create a monitor in the Azure Portal. The problem is that I cannot find a correct signal name (required when setting up condition), which would identify pipeline fail. What signal name should I use? Or is there another way to send an email if Azure pipeline fails?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1651478303433,
        "Question_score":1,
        "Question_tags":"azure|azureportal|azure-machine-learning-service",
        "Question_view_count":158,
        "Owner_creation_time":1313536247313,
        "Owner_last_access_time":1662987058983,
        "Owner_location":"Vilnius, Lithuania",
        "Owner_reputation":563,
        "Owner_up_votes":76,
        "Owner_down_votes":4,
        "Owner_views":108,
        "Question_last_edit_time":1651956277630,
        "Answer_body":"<blockquote>\n<p>What signal name should I use?<\/p>\n<\/blockquote>\n<p>You can use <code>PipelineChangeEvent<\/code> category of <code>AmlPipelineEvent<\/code> table to view events when ML pipeline draft or endpoint or module are accessed (read, created, or deleted).<\/p>\n<p>For example, according to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/monitor-azure-machine-learning#analyzing-logs\" rel=\"nofollow noreferrer\">documentation<\/a>, use <code>AmlComputeJobEvent<\/code> to get failed jobs in the last five days:<\/p>\n<pre><code>AmlComputeJobEvent\n| where TimeGenerated &gt; ago(5d) and EventType == &quot;JobFailed&quot;\n| project  TimeGenerated , ClusterId , EventType , ExecutionState , ToolType\n<\/code><\/pre>\n<p><strong>Updated answer:<\/strong><\/p>\n<p>According to <a href=\"https:\/\/stackoverflow.com\/users\/897665\/laurynas-g\">Laurynas G<\/a>:<\/p>\n<pre><code>AmlRunStatusChangedEvent \n| where Status == &quot;Failed&quot; or Status == &quot;Canceled&quot;\n<\/code><\/pre>\n<p>You can refer to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/monitor-azure-machine-learning#analyzing-logs\" rel=\"nofollow noreferrer\">Monitor Azure Machine Learning<\/a>, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Log &amp; view metrics and log files<\/a> and <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-pipelines\" rel=\"nofollow noreferrer\">Troubleshooting machine learning pipelines<\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1651723432757,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1658464027763,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72083832",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37807158,
        "Question_title":"Train multiple models with various measures and accumulate predictions",
        "Question_body":"<p>So I have been playing around with Azure ML lately, and I got one dataset where I have multiple values I want to predict. All of them uses different algorithms and when I try to train multiple models within one experiment; it says the \u201ctrain model can only predict one value\u201d, and there are not enough input ports on the train-model to take in multiple values even if I was to use the same algorithm for each measure. I tried launching the column selector and making rules, but I get the same error as mentioned. How do I predict multiple values and later put the predicted columns together for the web service output so I don\u2019t have to have multiple API\u2019s?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1465894075710,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":1763,
        "Owner_creation_time":1463041289043,
        "Owner_last_access_time":1465915063043,
        "Owner_location":null,
        "Owner_reputation":25,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>What you would want to do is to train each model and save them as already trained models.\nSo create a new experiment, train your models and save them by right clicking on each model and they will show up in the left nav bar in the Studio. Now you are able to drag your models into the canvas and have them score predictions where you eventually make them end up in the same output as I have done in my example through the \u201cAdd columns\u201d module. I made this example for Ronaldo (Real Madrid CF player) on how he will perform in match after training day. You can see my demo on <a href=\"http:\/\/ronaldoinform.azurewebsites.net\" rel=\"nofollow noreferrer\">http:\/\/ronaldoinform.azurewebsites.net<\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ZwzUy.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZwzUy.png\" alt=\"Ronaldo InForm\"><\/a><\/p>\n\n<p>For more detailed explanation on how to save the models and train multiple values; you can check out Raymond Langaeian (MSFT) answer in the comment section on this link:\n<a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-convert-training-experiment-to-scoring-experiment\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-convert-training-experiment-to-scoring-experiment\/<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1465904564903,
        "Answer_score":2.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37807158",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34320449,
        "Question_title":"Use Azure ML methods like an API",
        "Question_body":"<p>Is that possible to use machine learning methods from Microsoft Azure Machine Learning  as an API from my own code (without ML Studio) with possibility to calculate everything on their side?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1450294016510,
        "Question_score":1,
        "Question_tags":"frameworks|rapidminer|azure-machine-learning-studio",
        "Question_view_count":180,
        "Owner_creation_time":1336227824220,
        "Owner_last_access_time":1663836582560,
        "Owner_location":null,
        "Owner_reputation":834,
        "Owner_up_votes":159,
        "Owner_down_votes":2,
        "Owner_views":122,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-publish-a-machine-learning-web-service\/\" rel=\"nofollow\">publish<\/a> an experiment (machine learning functions you hooked together in Azure ML Studio) as an API. When you call that API in your custom code you give it your data and all the computation runs in the cloud in Azure ML. <\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1450317613533,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34320449",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64097278,
        "Question_title":"Why is the field \"compute target\" for data drift monitoring in Azure ML studio still blank whereas I have a compute instance?",
        "Question_body":"<p>I have created a compute instance:<\/p>\n<p>Virtual machine size\nSTANDARD_DS3_V2 (4 Cores, 14 GB RAM, 28 GB Disk)<\/p>\n<p>Processing Unit\nCPU - General purpose<\/p>\n<p>But, I'm not able to access it when trying to set it for data drift monitoring.\nThe dropdown list is empty. I can't understand why. Can you help me please?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Pf10h.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Pf10h.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1601276103867,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":88,
        "Owner_creation_time":1423640080283,
        "Owner_last_access_time":1663943557963,
        "Owner_location":"Lyon, France",
        "Owner_reputation":457,
        "Owner_up_votes":19,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I found the answer. You must give a <strong>cluster<\/strong> compute instance to do data drift in Azure Machine Learning Studio. As it is not clear, I'm planning to add something in the documentation of Azure.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1601278985530,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64097278",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67818831,
        "Question_title":"Azure Batch API rising 'AttributeError' in ML notebook",
        "Question_body":"<p>I am trying to interact with Azure Batch with python API, in the following way:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azure.batch import BatchServiceClient\nbatch = BatchServiceClient('&lt;mycredential&gt;','https:\/\/&lt;mybatchaccount&gt;.&lt;region&gt;.batch.azure.com')\nnext(batch.job.list())\n<\/code><\/pre>\n<p>This is run in a ML Studio notebook.<\/p>\n<p>However the following error appears: <code>AttributeError: 'str' object has no attribute 'signed_session'<\/code>.<br \/>\nI am taking the url and credentials from my batch console UI:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/lc9n4m.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/lc9n4m.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>As a credential I tried both Primary and Secondary access keys amd &quot;URL&quot; as batch url.<br \/>\nAm I doing anything wrong?<br \/>\nThanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1622712274873,
        "Question_score":0,
        "Question_tags":"python|azure|azure-batch|azure-machine-learning-service",
        "Question_view_count":52,
        "Owner_creation_time":1436006890427,
        "Owner_last_access_time":1663945829127,
        "Owner_location":"Amsterdam, Paesi Bassi",
        "Owner_reputation":959,
        "Owner_up_votes":136,
        "Owner_down_votes":31,
        "Owner_views":204,
        "Question_last_edit_time":1622714028187,
        "Answer_body":"<p><code>&lt;mycredential&gt;<\/code> should not be your bare auth key string. You need to create a shared auth key object.<\/p>\n<pre><code>credentials = batchauth.SharedKeyCredentials(BATCH_ACCOUNT_NAME, BATCH_ACCOUNT_KEY)\nbatch_client = batch.BatchServiceClient(credentials, base_url=BATCH_ACCOUNT_URL)\n<\/code><\/pre>\n<p>Please see the <a href=\"https:\/\/docs.microsoft.com\/azure\/batch\/tutorial-parallel-python\" rel=\"nofollow noreferrer\">Azure Batch Python tutorial<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1622734661130,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67818831",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68959934,
        "Question_title":"Contextual version conflict error, Microsoft Azure Machine Learning Studio",
        "Question_body":"<p>I'm trying to run this 10 line .ipynb file from Google Colab in Microsoft Azure Machine Learning Studio<\/p>\n<p><a href=\"https:\/\/colab.research.google.com\/drive\/1o_-QIR8yVphfnbNZGYemyEr111CHHxSv?usp=sharing\" rel=\"nofollow noreferrer\">https:\/\/colab.research.google.com\/drive\/1o_-QIR8yVphfnbNZGYemyEr111CHHxSv?usp=sharing<\/a><\/p>\n<p>When I get to this step:<\/p>\n<pre><code>import gradio as gr\nimport tensorflow as tf\nfrom transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n<\/code><\/pre>\n<p>I get this error:<\/p>\n<pre><code>ContextualVersionConflict: (Flask 1.0.3 (\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages), Requirement.parse('Flask&gt;=1.1.1'), {'gradio'})\n<\/code><\/pre>\n<p>I tried to install the Flask 1.1.1 version but I get more errors. Any idea what I should do to get past this step in Azure ML Studio?<\/p>\n<pre><code>!pip install \u2013force-reinstall Flask==1.1.1\n\/\/ More errors\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1630103458310,
        "Question_score":2,
        "Question_tags":"python|jupyter-notebook|google-colaboratory|azure-machine-learning-studio",
        "Question_view_count":237,
        "Owner_creation_time":1630103231523,
        "Owner_last_access_time":1664075236640,
        "Owner_location":null,
        "Owner_reputation":17,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1630103807137,
        "Answer_body":"<p>The issue is because <code>gradio<\/code> package using existing Flask package (version 1.0.3). But as your application required Flask&gt;=1.1.1, therefore it is showing error. You need to uninstall the existing Flask package and then install the latest required version.<\/p>\n<p>To uninstall the existing package:\n<code>!pip uninstall Flask -y<\/code><\/p>\n<p>To install latest package:\n<code>!pip install Flask&gt;=1.1.1<\/code><\/p>\n<p><strong>Then, make sure to restart your runtime to pick up the new Flask using the Runtime -&gt; Restart runtime menu.<\/strong><\/p>\n<p>Finally, import gradio.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1630303052770,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68959934",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69356567,
        "Question_title":"How to access local files from AzureML File Share?",
        "Question_body":"<p>Earlier when using AzureML from the Notebooks blade of Azure ML UI, we could access the local files in AzureML using simple relative paths:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/bKZ0W.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bKZ0W.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>For example, in the above image to access the CSV from the <code>test.ipynb<\/code> we could just mention the relative path:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>df = pandas.read_csv('WHO-COVID-19-global-data.csv')\n<\/code><\/pre>\n<p>However, we are not able to do that anymore.<\/p>\n<p>Also when we run<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nos.getcwd()\n<\/code><\/pre>\n<p>We see the output as\n<code>'\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/&lt;cluster-name&gt;'<\/code>.<\/p>\n<p>Hence, we are unable to access the files in the FileStore which was not the case earlier.<\/p>\n<p>When we run the same from the JuyterLab environment of the compute environment we get:<\/p>\n<p><code>'\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/&lt;cluster-name&gt;\/code\/Users\/&lt;current-user-name&gt;\/temp'<\/code>.<\/p>\n<p>We can easily solve it by adding the path <code>'\/code\/Users\/&lt;current-user-name&gt;\/temp'<\/code> at the base and use that instead. But this is not recommended as with a change in the environment we are using the code needs to change every time. How do we resolve this issue without going through this path appending method.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1632809238003,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":375,
        "Owner_creation_time":1601729162437,
        "Owner_last_access_time":1663774065773,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I work on the Notebooks team in AzureML, I just tried this. Did this just start happening today?<\/p>\n<p>It seems like things are working as expected: <a href=\"https:\/\/i.stack.imgur.com\/xeDIT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/xeDIT.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1632845944177,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69356567",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41743792,
        "Question_title":"Is there an Azure Machine Learning Studio module that works like the Pandas 'mask' method?",
        "Question_body":"<p>I'm trying to perform the following Python Pandas operation in Azure Machine Learning Studio, but cannot find a module that handles it:<\/p>\n\n<pre><code>df.credit_score = df.credit_score.mask(df.credit_score &gt; 800, df.credit_score \/ 10)\n<\/code><\/pre>\n\n<p>So I'm effectively just trying to find all values in my 'credit_score' column that are greater than 800 and divide them by 10.  I have been unable so far to find a module in AML Studio that does that.<\/p>\n\n<p>Also, I should add that I'm having issues with my Python script in AML Studio, which is why I'm attempting to replicate all of my code using AML built-in modules.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1484834877413,
        "Question_score":1,
        "Question_tags":"pandas|azure-machine-learning-studio",
        "Question_view_count":57,
        "Owner_creation_time":1483888458947,
        "Owner_last_access_time":1556908168660,
        "Owner_location":null,
        "Owner_reputation":107,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Question_last_edit_time":1484835455797,
        "Answer_body":"<p>To my knowledge, there's no built-in module to do this succinctly (to my knowledge). If you prefer to use built-ins, you could:<\/p>\n\n<ol>\n<li>Use a Split Dataset module to split the entries based on credit\nscore<\/li>\n<li>Divide the credit score in large-credit-score rows by 10 using\nApply Math Operation<\/li>\n<li>Concatenate the two datasets row-wise with an Add Rows module<\/li>\n<\/ol>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1485350815923,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41743792",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45582412,
        "Question_title":"How to build a Convolution Neural Net in Azure Machine Learning?",
        "Question_body":"<p>Someone should add \"net#\" as a tag. I'm trying to improve my neural network in Azure Machine Learning Studio by turning it into a convolution neural net using this tutorial:<\/p>\n\n<p><a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Neural-Network-Convolution-and-pooling-deep-net-2\" rel=\"noreferrer\">https:\/\/gallery.cortanaintelligence.com\/Experiment\/Neural-Network-Convolution-and-pooling-deep-net-2<\/a><\/p>\n\n<p>The differences between mine and the tutorial is I'm doing regression with 35 features and 1 label and they're doing classification with 28x28 features and 10 labels. <\/p>\n\n<p>I start with the basic and 2nd example and get them working with:<\/p>\n\n<pre><code>input Data [35];\n\nhidden H1 [100]\n    from Data all;\n\nhidden H2 [100]\n    from H1 all;\n\noutput Result [1] linear\n    from H2 all;\n<\/code><\/pre>\n\n<p>Now the transformation to convolution I misunderstand. In the tutorial and documentation here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-azure-ml-netsharp-reference-guide\" rel=\"noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-azure-ml-netsharp-reference-guide<\/a> it doesn't mention how the node tuple values are calculated for the hidden layers. The tutorial says:<\/p>\n\n<pre><code>hidden C1 [5, 12, 12]\n  from Picture convolve {\n    InputShape  = [28, 28];\n    KernelShape = [ 5,  5];\n    Stride      = [ 2,  2];\n    MapCount = 5;\n  }\n\nhidden C2 [50, 4, 4]\n   from C1 convolve {\n     InputShape  = [ 5, 12, 12];\n     KernelShape = [ 1,  5,  5];\n     Stride      = [ 1,  2,  2];\n     Sharing     = [ F,  T,  T];\n     MapCount = 10;\n  }\n<\/code><\/pre>\n\n<p>Seems like the [5, 12, 12] and [50,4,4] pop out of no where along with the KernalShape, Stride, and MapCount. How do I know what values are valid for my example? I tried using the same values, but it didn't work and I have a feeling since he has a [28,28] input and I have a [35], I need tuples with 2 integers not 3. <\/p>\n\n<p>I just tried with random values that seem to correlate with the tutorial:<\/p>\n\n<pre><code>const { T = true; F = false; }\n\ninput Data [35];\n\nhidden C1 [7, 23]\n  from Data convolve {\n    InputShape  = [35];\n    KernelShape = [7];\n    Stride      = [2];\n    MapCount = 7;\n  }\n\nhidden C2 [200, 6]\n   from C1 convolve {\n     InputShape  = [ 7, 23];\n     KernelShape = [ 1,  7];\n     Stride      = [ 1,  2];\n     Sharing     = [ F,  T];\n     MapCount = 14;\n  }\n\nhidden H3 [100]\n  from C2 all;\n\noutput Result [1] linear\n  from H3 all;\n<\/code><\/pre>\n\n<p>Right now it seems impossible to debug because the only error code Azure Machine Learning Studio ever gives is:<\/p>\n\n<pre><code>Exception\":{\"ErrorId\":\"LibraryException\",\"ErrorCode\":\"1000\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 1000: TLC library exception: Exception of type 'Microsoft.Numerics.AFxLibraryException' was thrown.\",\"Exception\":{\"Library\":\"TLC\",\"ExceptionType\":\"LibraryException\",\"Message\":\"Exception of type 'Microsoft.Numerics.AFxLibraryException' was thrown.\"}}}Error: Error 1000: TLC library exception: Exception of type 'Microsoft.Numerics.AFxLibraryException' was thrown. Process exited with error code -2\n<\/code><\/pre>\n\n<p>Lastly my setup is <a href=\"https:\/\/i.stack.imgur.com\/PBN9L.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PBN9L.png\" alt=\"Azure Machine Learning Setup\"><\/a> <\/p>\n\n<p>Thanks for the help!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1502257048253,
        "Question_score":9,
        "Question_tags":"machine-learning|convolution|azure-machine-learning-studio|net#",
        "Question_view_count":1268,
        "Owner_creation_time":1418505926277,
        "Owner_last_access_time":1664040770893,
        "Owner_location":"Missouri",
        "Owner_reputation":1454,
        "Owner_up_votes":117,
        "Owner_down_votes":15,
        "Owner_views":328,
        "Question_last_edit_time":1502686418057,
        "Answer_body":"<p>The correct network definition for 35-column length input with given kernels and strides would be following:<\/p>\n\n<pre><code>const { T = true; F = false; }\n\ninput Data [35];\n\nhidden C1 [7, 15]\n  from Data convolve {\n    InputShape  = [35];\n    KernelShape = [7];\n    Stride      = [2];\n    MapCount = 7;\n  }\n\nhidden C2 [14, 7, 5]\n   from C1 convolve {\n     InputShape  = [ 7, 15];\n     KernelShape = [ 1,  7];\n     Stride      = [ 1,  2];\n     Sharing     = [ F,  T];\n     MapCount = 14;\n  }\n\nhidden H3 [100]\n  from C2 all;\n\noutput Result [1] linear\n  from H3 all;\n<\/code><\/pre>\n\n<p>First, the C1 = [7,15]. The first dimension is simply the MapCount. For the second dimension, the kernel shape defines the length of the \"window\" that's used to scan the input columns, and the stride defines how much it moves at each step. So the kernel windows would cover columns 1-7, 3-9, 5-11,...,29-35, yielding the second dimension of 15 when you tally the windows.<\/p>\n\n<p>Next, the C2 = [14,7,5]. The first dimension is again the MapCount. For the second and third dimension, the 1-by-7 kernel \"window\" has to cover the input size of 7-by-15, using steps of 1 and 2 along corresponding dimensions. <\/p>\n\n<p>Note that you could specify C2 hidden layer shape of [98,5] or even [490], if you wanted to flatten the outputs. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1503342256370,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45582412",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73192053,
        "Question_title":"azure cli not recognizing the following command az ml data create -f <file-name>.yml",
        "Question_body":"<p>got a folder called data-asset which contains a yaml file with the following<\/p>\n<pre><code>type: uri_folder\nname: &lt;name_of_data&gt;\ndescription: &lt;description goes here&gt;\npath: &lt;path&gt;\n<\/code><\/pre>\n<p>In a pipeline am referencing this using azure cli inline script using the following command az ml data create -f .yml but getting error<\/p>\n<p>full error-D:\\a\\1\\s\\ETL\\data-asset&gt;az ml data create -f data-asset.yml\nERROR: 'ml' is misspelled or not recognized by the system.<\/p>\n<p>Examples from AI knowledge base:\naz extension add --name anextension\nAdd extension by name<\/p>\n<p>trying to implement this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-data-assets?tabs=CLI\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-data-assets?tabs=CLI<\/a><\/p>\n<p>how can a resolve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1659348144177,
        "Question_score":0,
        "Question_tags":"azure|yaml|azure-cli|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":112,
        "Owner_creation_time":1606756004663,
        "Owner_last_access_time":1661935729383,
        "Owner_location":null,
        "Owner_reputation":49,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Question_last_edit_time":null,
        "Answer_body":"<p>One of the workaround you can follow to resolve the above issue;<\/p>\n<p>Based on this <a href=\"https:\/\/github.com\/Azure\/azure-cli\/issues\/21390#issuecomment-1161782243\" rel=\"nofollow noreferrer\"><em><strong>GitHub issue<\/strong><\/em><\/a> as suggested by @<em>adba-msft<\/em> .<\/p>\n<blockquote>\n<p><strong>Please make sure that you have upgraded your azure cli to latest and<\/strong>\n<strong>Azure CLI ML extension v2 is being used.<\/strong><\/p>\n<\/blockquote>\n<p>To check and upgrade the cli we can use the below <code>cmdlts<\/code>:<\/p>\n<pre><code>az version\n\naz upgrade\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Uopde.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Uopde.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>For more information please refer this similar <a href=\"https:\/\/stackoverflow.com\/questions\/73110661\/create-is-misspelled-or-not-recognized-by-the-system-on-az-ml-dataset-create\"><em><strong>SO THREAD|'create' is misspelled or not recognized by the system on az ml dataset create<\/strong><\/em><\/a> .<\/p>\n<p>I did observe the same issue after trying the aforementioned suggestion by @<em>Dor Lugasi-Gal<\/em> it works for me with (in my case <code>az ml -h<\/code>) after installed the extension with  <code>az extension add -n ml -y<\/code> can able to get the result of <code>az ml -h<\/code> without any error.<\/p>\n<p><em><strong>SCREENSHOT FOR REFERENCE:-<\/strong><\/em><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/39LHa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/39LHa.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1659361184080,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1659362947923,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73192053",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65997961,
        "Question_title":"How to trigger an AzureML Pipeline from Azure DevOps?",
        "Question_body":"<p>If we have an AzureML Pipeline published, how can we trigger it from Azure DevOps <strong>without using Python Script Step or Azure CLI Step<\/strong>?<\/p>\n<p>The AzureML Steps supported natively in Azure DevOps include Model_Deployment and Model_Profiling.<\/p>\n<p>Is there any step in Azure DevOps which can be used to directly trigger a published Azure Machine Learning Pipeline while maintaining capabilities like using Service Connections and passing environmental variables, Gated Release (Deployment)?<\/p>\n<p>Edit:\nThis process can then be used to run as an agentless job.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1612203126923,
        "Question_score":2,
        "Question_tags":"azure|azure-devops|azure-machine-learning-service",
        "Question_view_count":1923,
        "Owner_creation_time":1601729162437,
        "Owner_last_access_time":1663774065773,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Question_last_edit_time":1612249107730,
        "Answer_body":"<p>Assumptions:<\/p>\n<ol>\n<li>An AzureML Pipeline is published and the REST endpoint is ready- To be referred to in this answer as &lt;AML_PIPELINE_REST_URI&gt;. And Published Pipeline ID is also ready- To be referred to in this answer as &lt;AML_PIPELINE_ID&gt;<\/li>\n<li>You have the Azure Machine Learning Extension installed: <a href=\"https:\/\/marketplace.visualstudio.com\/items?itemName=ms-air-aiagility.vss-services-azureml&amp;ssr=false#review-details\" rel=\"nofollow noreferrer\">Azure Machine Learning Extension<\/a><\/li>\n<\/ol>\n<p>To Invoke the Azure Machine Learning Pipeline we use the <code>Invoke ML Pipeline<\/code> step available in Azure DevOps. It is available when running an Agentless Job.<\/p>\n<p>To trigger it the workflow is as follows:<\/p>\n<ol>\n<li>Create a New Pipeline. Using the Classic Editor, delete the default Agent Job 1 stage.\n<a href=\"https:\/\/i.stack.imgur.com\/phzL3.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/phzL3.png\" alt=\"enter image description here\" \/><\/a><\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/QkiPY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/QkiPY.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ol start=\"2\">\n<li><p>Add an agentless job:\n<a href=\"https:\/\/i.stack.imgur.com\/0PXwg.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/0PXwg.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Add a task to this Agentless Job:\n<a href=\"https:\/\/i.stack.imgur.com\/trW7j.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/trW7j.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Use AzureML Published Pipeline Task:\n<a href=\"https:\/\/i.stack.imgur.com\/3rl4z.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/3rl4z.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Use the Service Connection Mapped to the AML Workspace. You can find more on this at the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/devops\/pipelines\/library\/service-endpoints?view=azure-devops&amp;tabs=yaml\" rel=\"nofollow noreferrer\">official documentation<\/a>\n<a href=\"https:\/\/i.stack.imgur.com\/mnV36.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mnV36.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Choose the Pipeline to trigger using the &lt;AML_PIPELINE_ID&gt;:\n<a href=\"https:\/\/i.stack.imgur.com\/fbpQW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fbpQW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Give The experiment name and Pipeline Parameters if any:\n<a href=\"https:\/\/i.stack.imgur.com\/og1kx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/og1kx.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>That's it, you can Save and Queue:\n<a href=\"https:\/\/i.stack.imgur.com\/iCwdl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/iCwdl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<\/ol>\n<p>Alternatively, you can simply use the following jobs:<\/p>\n<pre><code>- job: Job_2\n  displayName: Agentless job\n  pool: server\n  steps:\n  - task: MLPublishedPipelineRestAPITask@0\n    displayName: Invoke ML pipeline\n    inputs:\n      connectedServiceName: &lt;REDACTED-AML-WS-Level-Service_Connection-ID&gt;\n      PipelineId: &lt;AML_PIPELINE_ID&gt;\n      ExperimentName: experimentname\n      PipelineParameters: ''\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1612256282837,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1612281801243,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65997961",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50576929,
        "Question_title":"Replacing values in dataset within Azure Machine Learning Studio",
        "Question_body":"<p>In Azure Machine Learning studio I need to convert a column of data that has three categorical values 'yes', 'no' and 'maybe', and wish to combine the 'no' and 'maybe' values as just 'no'. <\/p>\n\n<p>I can do this easily using SQL, R, or Python but for these purposes I need to show if it is possible to do this without using these languages. I can't seem to find a way to do this. <\/p>\n\n<p>Does anyone have any ideas? I'm fine if the answer is no but I don't want to say it's not possible if it is. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1527572052450,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":484,
        "Owner_creation_time":1367782461047,
        "Owner_last_access_time":1574911198153,
        "Owner_location":null,
        "Owner_reputation":1647,
        "Owner_up_votes":365,
        "Owner_down_votes":8,
        "Owner_views":321,
        "Question_last_edit_time":null,
        "Answer_body":"<p>It can be done! :)<\/p>\n\n<p>You would just use the \"Group Categorical Values\" module. Choose the column that has the data you want to group, and you can set the values like the following:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/UGhrR.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/UGhrR.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>What's going on here is that the default, which will get used if the other levels aren't caught, is set to \"yes\". Then when any values are \"no\", or \"maybe\", it gets grouped into a category of \"no\".<\/p>\n\n<p>However, this will error unless you make that column a categorical type, so you would need to use the \"Edit Metadata\" module to do that.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/45s2Q.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/45s2Q.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>The example I used is <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/Replace-Values-in-Dataset\" rel=\"nofollow noreferrer\">published to the gallery<\/a>, if you need to reference it.<\/p>\n\n<p>If you need more info, just let me know.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1527597469393,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50576929",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45009184,
        "Question_title":"Powershell AzureML Get-AmlWorkspace",
        "Question_body":"<pre><code>Get-AmlWorkspace : One or more errors occurred.\nAt line:1 char:1\n+ Get-AmlWorkspace\n+ ~~~~~~~~~~~~~~~~\n+ CategoryInfo          : NotSpecified: (:) [Get-AmlWorkspace], \nAggregateException\n+ FullyQualifiedErrorId : \nSystem.AggregateException,AzureML.PowerShell.GetWorkspace\n<\/code><\/pre>\n\n<p>I am trying to use Powershell to connect to Azure ML studio as it looks like an easier way to manage a workspace. I've downloaded the dll file from <a href=\"https:\/\/github.com\/hning86\/azuremlps\" rel=\"nofollow noreferrer\">https:\/\/github.com\/hning86\/azuremlps<\/a> and changed my config.json file, but get the error above if I try to run any AzureML commands. I've unblocked the DLL file and imported the AzureMLPS module, and I can see the module and commands I am trying to use have been imported by doing <code>Get-Module<\/code> and <code>Get-Command<\/code><\/p>\n\n<p>For info I've not used Powershell before.<\/p>\n\n<p>Any suggestions much appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1499681034153,
        "Question_score":1,
        "Question_tags":"powershell|azure-machine-learning-studio",
        "Question_view_count":428,
        "Owner_creation_time":1397507727100,
        "Owner_last_access_time":1663075667463,
        "Owner_location":null,
        "Owner_reputation":340,
        "Owner_up_votes":60,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Have you installed Azure PowerShell Installer on your local machine?\n<strong><a href=\"https:\/\/github.com\/Azure\/azure-powershell\/releases\" rel=\"nofollow noreferrer\">Click here<\/a><\/strong> for more info.<\/p>\n\n<p>Download the latest <strong>Azure PowerShell Installer (4.3.1)<\/strong>, then install on your local machine. Then retry using Azure PowerShell module and commands.<\/p>\n\n<p>I installed mine last May, using Azure PowerShell 4.0.1, and the command Get-AmlWorkspace is working.<\/p>\n\n<pre><code># Set local folder location\nSet-Location -Path \"C:\\Insert here the location of AzureMLPS.dll\"\n\n# Unblock and import Azure Powershell Module (leverages config.json file)\nUnblock-File .\\AzureMLPS.dll\nImport-Module .\\AzureMLPS.dll\n\n# Get Azure ML Workspace info\nGet-AmlWorkspace\n<\/code><\/pre>\n\n<p>The output on my side looks like this:\n<a href=\"https:\/\/i.stack.imgur.com\/mEGeT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mEGeT.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1503389654690,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45009184",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50954802,
        "Question_title":"Recommender Split Returning Empty Dataset",
        "Question_body":"<p>I'm using a \"Split Data\" module set to recommender split to split data for training and testing a matchbox recommender. The input data is a valid user-item-rating tuple (for example, 575978 - 157381 - 3) and I've left the parameters for the recommender split as default (0s for everything), besides changing it to a .75 and .25 split. However, when this module finishes, it returns the complete, unsplit dataset for dataset1 and a completely empty (but labelled) dataset for dataset2. This also happens when doing a stratified split using the \"Split Rows\" mode. Any idea what's going on?<\/p>\n\n<p>Thanks.<\/p>\n\n<p>Edit: Including a sample of my data.<\/p>\n\n<pre><code>UserID  ItemID  Rating\n835793  165937  3\n154738  11214   3\n938459  748288  3\n819375  789768  6\n738571  98987   3\n847509  153777  3\n991757  124458  3\n968685  288070  2\n236349  8337    3\n127299  545885  3\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1529519087767,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":88,
        "Owner_creation_time":1436818579270,
        "Owner_last_access_time":1656621730207,
        "Owner_location":"Eugene, OR, USA",
        "Owner_reputation":474,
        "Owner_up_votes":322,
        "Owner_down_votes":12,
        "Owner_views":28,
        "Question_last_edit_time":1529527790943,
        "Answer_body":"<p>Figured it out. In my \"Remove Duplicate Rows\" module up the chain a bit I was only removing duplicates by UserID instead of UserID <em>and<\/em> ItemID. This still left quite a bit of rows but I'm assuming it messed with the stratification. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1529598877083,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50954802",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65112585,
        "Question_title":"Pip installation stuck in infinite loop if unresolvable conflicts in dependencies",
        "Question_body":"<p>Pip installation is stuck in an infinite loop if there are unresolvable conflicts in dependencies. To reproduce, <code>pip==20.3.0<\/code> and:<\/p>\n<pre><code>pip install pyarrow==2.0.0 azureml-defaults==1.18.0\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_time":1606928045387,
        "Question_score":13,
        "Question_tags":"python|pip|azure-machine-learning-service",
        "Question_view_count":2146,
        "Owner_creation_time":1568658032913,
        "Owner_last_access_time":1625529665640,
        "Owner_location":"Redmond, WA, USA",
        "Owner_reputation":133,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1608739608113,
        "Answer_body":"<p>Workarounds:<\/p>\n<p>Local environment:\nDowngrade pip to &lt; 20.3<\/p>\n<p>Conda environment created from yaml:\nThis will be seen only if conda-forge is highest priority channel, anaconda channel doesn't have pip 20.3 (as of now). To mitigate the issue please explicitly specify pip&lt;20.3 (!=20.3 or =20.2.4 pin to other version) as a conda dependency in the conda specification file<\/p>\n<p>AzureML experimentation:\nFollow the case above to make sure pinned pip resulted as a conda dependency in the environment object, either from yml file or programmatically<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1606928528563,
        "Answer_score":12.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65112585",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30068341,
        "Question_title":"How to write the results of Azure ML web service to the azure sql database (The output of Azure ML web service is in Json structure)",
        "Question_body":"<p>The results can be written to SQL Azure using the writer module in the experiment but after publishing the web service the output comes in the Json Structure and it doesn't go to the writer module <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1430890566837,
        "Question_score":0,
        "Question_tags":"azure-sql-database|azure-scheduler|azure-machine-learning-studio",
        "Question_view_count":990,
        "Owner_creation_time":1403541426413,
        "Owner_last_access_time":1592469887883,
        "Owner_location":"Bengaluru, India",
        "Owner_reputation":191,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Question_last_edit_time":1431065815883,
        "Answer_body":"<p>Don't set output port and use Batch execution service - details are provided here - <a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-publish-a-machine-learning-web-service\/\" rel=\"nofollow\">Publish web service<\/a> and <a href=\"http:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-consume-web-services\/\" rel=\"nofollow\">consume web service<\/a><\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1430897690130,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30068341",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":65099376,
        "Question_title":"Segmentation fault error in importing sentence_transformers in Azure Machine Learning Service Nvidia Compute",
        "Question_body":"<p>I would like to use sentence_transformers in AML to run XLM-Roberta model for sentence embedding. I have a script in which I import sentence_transformers:<\/p>\n<pre><code>from sentence_transformers import SentenceTransformer\n<\/code><\/pre>\n<p>Once I run my AML pipeline, the run fails on this script with the following error:<\/p>\n<pre><code>AzureMLCompute job failed.\nUserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault.\n    Cause: segmentation fault\n    TaskIndex: \n    NodeIp: #####\n    NodeId: #####\n<\/code><\/pre>\n<p>I'm pretty sure that this import is causing this error, because if I comment out this import, the rest of the script will run.\nThis is weird because the installation of the sentence_transformers succeed.<\/p>\n<p>This is the details of my compute:<\/p>\n<pre><code>Virtual machine size\nSTANDARD_NV24 (24 Cores, 224 GB RAM, 1440 GB Disk)\nProcessing Unit\nGPU - 4 x NVIDIA Tesla M60\n<\/code><\/pre>\n<p>Agent Pool:<\/p>\n<pre><code>Azure Pipelines\n<\/code><\/pre>\n<p>Agent Specification:<\/p>\n<pre><code>ubuntu-16.04\n<\/code><\/pre>\n<p>requirements.txt file:<\/p>\n<pre><code>torch==1.4.0\nsentence-transformers\n<\/code><\/pre>\n<p>Does anyone have a solution for this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1606861020137,
        "Question_score":1,
        "Question_tags":"azure|nvidia|azure-machine-learning-service|roberta-language-model|sentence-transformers",
        "Question_view_count":530,
        "Owner_creation_time":1450889293150,
        "Owner_last_access_time":1663403554823,
        "Owner_location":"Finland",
        "Owner_reputation":398,
        "Owner_up_votes":21,
        "Owner_down_votes":1,
        "Owner_views":28,
        "Question_last_edit_time":1606866767497,
        "Answer_body":"<p>I fixed the issue by changing the pytorch version from 1.4.0 to 1.6.0.\nSo the requirements.txt looks like this:<\/p>\n<pre><code>torch==1.6.0\nsentence-transformers\n<\/code><\/pre>\n<p>At first I tried one of the older versions of sentence-transformers which was compatible with pytorch 1.4.0. But the older version doesn't support &quot;xml-roberta-base&quot; model, so I tried to upgrade the pytorch version.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1606866538210,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1606867069223,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65099376",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40844351,
        "Question_title":"R code on Azure Machine Learning is slow compared to local execution time",
        "Question_body":"<p>Getting straight to it:\nWhy is my R code doing fine on my local CPU (under one minute), but tens of times slower on Azure Machine Learning, using one R script block (over 18 minutes)?<\/p>\n\n<p>I assume that it has to do with the resources allocated to the experiment, but how can I be sure? Can I obtain details about the resource allocated to the R script block from somwehere hidden in the Azure-ML Studio machinery?<\/p>\n\n<p>Thank you, Flo<\/p>\n\n<p>Later Edit:\nAs it often happens, I did finally find some information, which still doesn't solve my issue. According to <a href=\"https:\/\/msdn.microsoft.com\/library\/en-us\/Dn905952.aspx#Technical%20Notes\" rel=\"nofollow noreferrer\">https:\/\/msdn.microsoft.com\/library\/en-us\/Dn905952.aspx#Technical%20Notes<\/a> \"User-specified R code is run by a 64-bit R interpreter that runs in Azure using an A8 virtual machine with 56 GB of RAM.\"<\/p>\n\n<p>This is more than my local machine has, the R code is still much slower on the Azure-ML studio.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_time":1480336059453,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":733,
        "Owner_creation_time":1459503032960,
        "Owner_last_access_time":1512467737783,
        "Owner_location":"Vienna, Austria",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":1480338194650,
        "Answer_body":"<p>Consider using rbenchmark or other benchmarking tools to get an idea of the runtime and complexity of your code. In general for loops tend to be slow.<\/p>\n\n<p>It's very possible that the server has less resources available (ram, cpu) or that you have to wait in a que before you get served. Without any more code it's hard to comment further on this issue.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1480339657187,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40844351",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36285329,
        "Question_title":"How to import a third party library \"causalImpact\" using R script in AzureML studio?",
        "Question_body":"<p>I tried to import causalImpact library from github using \"devtools\" in AzureML studio for one of my projects.\ncode used was:<\/p>\n\n<pre><code>library(devtools)\ndevtools::install_github(\"google\/CausalImpact\")\n<\/code><\/pre>\n\n<p>Unfortunately, Azure doesn't support this.So tried importing it following the procedure in this <a href=\"https:\/\/blogs.msdn.microsoft.com\/benjguin\/2014\/09\/24\/how-to-upload-an-r-package-to-azure-machine-learning\/\" rel=\"nofollow\">blog<\/a>.It is giving multiple errors on the name of dependent packages of casualImpact(i.e. BOOM, BH etc.). Can anyone help me out in importing this package on Azure?<\/p>\n\n<p>This is the R-script I used following the link given above:<\/p>\n\n<pre><code>library(assertthat)\nlibrary(dplyr)\nlibrary(hflights)\nlibrary(Lahman)\nlibrary(magrittr)\nlibrary(LGPL)\ninstall.packages(\"src\/BH_1.55.0-3.zip\", lib = \".\", repos = NULL, verbose = TRUE)\nsuccess &lt;- library(\"BH \", lib.loc=\".\", logical.return = TRUE, verbose=TRUE)\n\nlibrary(BH)\ninstall.packages(\"src\/Boom_0.1.zip\", lib = \".\", repos = NULL, verbose = TRUE)\nsuccess &lt;- library(\"Boom \", lib.loc=\".\", logical.return = TRUE, verbose=TRUE)\n\ninstall.packages(\"src\/BoomSpikeSlab.zip\", lib = \".\", repos = NULL, verbose = TRUE)\nsuccess &lt;- library(\"BoomSpikeSlab\", lib.loc=\".\", logical.return = TRUE, verbose=TRUE)\n\ninstall.packages(\"src\/bsts_0.5.1.zip\", lib = \".\", repos = NULL, verbose = TRUE)\nsuccess &lt;- library(\"bsts\", lib.loc=\".\", logical.return = TRUE, verbose=TRUE)\nlibrary(zoo)\nlibrary(xts)\ninstall.packages(\"src\/CausalImpact.zip\", lib = \".\", repos = NULL, verbose = TRUE)\nsuccess &lt;- library(\"CausalImpact\", lib.loc=\".\", logical.return = TRUE, verbose=TRUE)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1459257130213,
        "Question_score":2,
        "Question_tags":"r|github|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":326,
        "Owner_creation_time":1423214734843,
        "Owner_last_access_time":1470891961370,
        "Owner_location":"Bangalore",
        "Owner_reputation":55,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":34,
        "Question_last_edit_time":1459402444997,
        "Answer_body":"<p>You will have to upload all dependent packages of casualImpact as a zip file - see sample <a href=\"http:\/\/gallery.azureml.net\/Details\/7507f907deb845d9b9b193b455a8615d\" rel=\"nofollow\">here<\/a> which shows uploading two packages required for xgboost<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1459314427723,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36285329",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68658385,
        "Question_title":"Azure Machine Learning Studio designer - \"create new version\" unexpected when registering a data set",
        "Question_body":"<p>I am trying to register a data set as a Python step with the Azure Machine Learning Studio designer. Here is my code:<\/p>\n<pre><code>import pandas as pd\nfrom azureml.core import Workspace, Run, Dataset\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    run = Run.get_context()\n    ws = run. experiment.workspace\n    ds = Dataset.from_pandas_dataframe(dataframe1)\n    ds.register(workspace = ws,\n                name = &quot;data set name&quot;,\n                description = &quot;example description&quot;,\n                create_new_version = True)\n    return dataframe1, \n<\/code><\/pre>\n<p>I get an error saying that &quot;create_new_version&quot; in the ds.register line was an unexpected keyword argument. However, this keyword appears in the documentation and I need it to keep track of new versions of the file.<\/p>\n<p>If I remove the argument, I get a different error: &quot;Local data source path not supported for this operation&quot;, so it still does not work. Any help is appreciated. Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1628113771587,
        "Question_score":2,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":565,
        "Owner_creation_time":1371499229817,
        "Owner_last_access_time":1664024865427,
        "Owner_location":null,
        "Owner_reputation":1111,
        "Owner_up_votes":124,
        "Owner_down_votes":2,
        "Owner_views":191,
        "Question_last_edit_time":null,
        "Answer_body":"<h2>update<\/h2>\n<p>sharing OP's solution here for easier discovery<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import pandas as pd\nfrom azureml.core import Workspace, Run, Dataset\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    run = Run.get_context()\n    ws = run. experiment.workspace\n    datastore = ws.get_default_datastore()\n    ds = Dataset.Tabular.register_pandas_dataframe(\n        dataframe1, datastore, 'data_set_name',\n        description = 'data set description.')\n    return dataframe1,\n<\/code><\/pre>\n<h2>original answer<\/h2>\n<p>Sorry you're struggling. You're very close!<\/p>\n<p>A few things may be the culprit here.<\/p>\n<ol>\n<li>It looks like you're using the <code>Dataset<\/code> class, which has been deprecated. I recommend trying <code>Dataset.Tabular.register_pandas_dataframe()<\/code> (<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.dataset_factory.tabulardatasetfactory?view=azure-ml-py#register-pandas-dataframe-dataframe--target--name--description-none--tags-none--show-progress-true-\" rel=\"nofollow noreferrer\">docs link<\/a>) instead of <code>Dataset.from_pandas_dataframe()<\/code>. (<a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/dataset-api-change-notice.md\" rel=\"nofollow noreferrer\">more about the Dataset API deprecation<\/a>)<\/li>\n<li>More conjectire here, but another thing is there might be some limitations to using dataset registration within an &quot;Execute Python Script&quot; (EPS) module due to:\n<ol>\n<li>the workspace object might not have the right permissions<\/li>\n<li>you might not be able to use the <code>register_pandas_dataframe<\/code> method inside the EPS module, but might have better luck with save the dataframe first to parquet, then calling <code>Dataset.Tabular.from_parquet_files<\/code><\/li>\n<\/ol>\n<\/li>\n<\/ol>\n<p>Hopefully something works here!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1628119362627,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1628180472980,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68658385",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58031370,
        "Question_title":"How to cancel a running job from the UI?",
        "Question_body":"<p>Am I missing something but how can I cancel a run in my workspace from <a href=\"https:\/\/ms.portal.azure.com\/\" rel=\"nofollow noreferrer\">https:\/\/ms.portal.azure.com\/<\/a> ? The cancel button is always greyed out.<\/p>\n\n<p>I know I can use use the sdk to cancel a run using:<\/p>\n\n<pre><code>run = [ r for r in Experiment(ws, 'myExp').get_runs() if r.id == '899b8314-26b6-458f-9f5c-539ffbf01b91'].pop()\nrun.cancel()\n<\/code><\/pre>\n\n<p>But it would be more convenient to be able to do it from the UI<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1568993659347,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":204,
        "Owner_creation_time":1565794118450,
        "Owner_last_access_time":1664072200673,
        "Owner_location":null,
        "Owner_reputation":113,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":"<p>What kind of run is this? Canceling is not currently enabled for pipeline runs in the UI, but is supported for other run types.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1569333175230,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1569508172863,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58031370",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":41903982,
        "Question_title":"Web service output - Azure ML Studio",
        "Question_body":"<p>I am new to Azure ML Studio. I tried creating an experiment that takes a numeric value as input and a gives a data table type output. I works fine when I run it in the portal , but not when I run it as a web service. It shows a single value numeric output , when it has to be a data table type.<\/p>\n\n<p>Is there a way to change the output type of web service output? <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/oq5Xb.png\" rel=\"nofollow noreferrer\">Visualizing output in portal<\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/wUmN7.png\" rel=\"nofollow noreferrer\">Test RRS output(web service)<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_time":1485555724117,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":587,
        "Owner_creation_time":1449123268407,
        "Owner_last_access_time":1660064690440,
        "Owner_location":"East Newark, NJ, United States",
        "Owner_reputation":33,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Question_last_edit_time":1485558200660,
        "Answer_body":"<p>Make is a classic web service and see the JSON output getting from it. If it's providing all data you need.. go for it.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1486009486973,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/41903982",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64338898,
        "Question_title":"How to load an experiment in azureml?",
        "Question_body":"<p>I have many experiment, like:<\/p>\n<p><img src=\"https:\/\/user-images.githubusercontent.com\/40580910\/95883598-82a07d00-0d51-11eb-847d-872452f6caa4.png\" alt=\"image\" \/><\/p>\n<p>and now, i want load an experiment<\/p>\n<pre><code>#%% sumonando os pacotes e verificando azureml.core\nimport azureml.core\nimport pandas as pd\nimport numpy as np\nimport logging\n\nprint(&quot;AzureML SDK Version: &quot;, azureml.core.VERSION)\n\n#%% Conectando ao azure e crinado o exparimento\n\nfrom azureml.core import Workspace, Experiment\n\nws = Workspace.from_config() \nprint(Experiment.list(ws))\n#%%\nExperiment = Experiment.from_directory('teste2-Monitor-Runs') `\n<\/code><\/pre>\n<p>but<\/p>\n<pre><code>&quot;error&quot;: {\n    &quot;message&quot;: &quot;No cache found for current project, try providing resource group and workspace \narguments&quot;\n}`\n<\/code><\/pre>\n<hr \/>\n<p>Content: <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.experiment(class)?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.core.Experiment class - Azure Machine Learning Python<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1602604847240,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":254,
        "Owner_creation_time":1522634496793,
        "Owner_last_access_time":1663943775803,
        "Owner_location":"Rio de Janeiro, RJ, Brasil",
        "Owner_reputation":264,
        "Owner_up_votes":276,
        "Owner_down_votes":2,
        "Owner_views":23,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I believe it is that way.<\/p>\n<pre><code>from azureml.core import Experiment, Workspace\nExperiment = ws.experiments[&quot;teste2-Monitor-Runs&quot;]\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1602700300720,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64338898",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36563769,
        "Question_title":"How to download the entire scored dataset from Azure machine studio?",
        "Question_body":"<p>I have an experiment in azure machine learning studio, and I would like to the see entire scored dataset.<\/p>\n\n<p>Naturally I used the 'visualise' option on the scored dataset but these yields only 100 rows (the test dataset is around 500 rows)<\/p>\n\n<p>I also tired the 'save as dataset' option, but then file does not open well with excel or text editor (special character encoding)<\/p>\n\n<p>Basically, I want to see the entire test data with scored labels as table or download as .csv maybe<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1460436159040,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":5296,
        "Owner_creation_time":1406266059940,
        "Owner_last_access_time":1663232189147,
        "Owner_location":"Link\u00f6ping, Sweden",
        "Owner_reputation":1677,
        "Owner_up_votes":82,
        "Owner_down_votes":2,
        "Owner_views":221,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Please try the Convert to CSV module: <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/faa6ba63-383c-4086-ba58-7abf26b85814\" rel=\"noreferrer\">https:\/\/msdn.microsoft.com\/library\/azure\/faa6ba63-383c-4086-ba58-7abf26b85814<\/a><\/p>\n\n<p>After you run the experiment, right click on the output of the module to download the CSV file.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1460437058280,
        "Answer_score":14.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36563769",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46523924,
        "Question_title":"Adding python modules to AzureML workspace",
        "Question_body":"<p>I've been working recently on deploying a machine learning model as a web service. I used Azure Machine Learning Studio for creating my own Workspace ID and Authorization Token. Then, I trained LogisticRegressionCV model from <strong>sklearn.linear_model<\/strong> locally on my machine (using python 2.7.13) and with the usage of below code snippet I wanted to publish my model as web service:<\/p>\n\n<pre><code>from azureml import services\n\n@services.publish('workspaceID','authorization_token')\n@services.types(var_1= float, var_2= float)\n@services.returns(int)\n\ndef predicting(var_1, var_2):\n    input = np.array([var_1, var_2].reshape(1,-1)\nreturn model.predict_proba(input)[0][1]\n<\/code><\/pre>\n\n<p>where <em>input<\/em> variable is a list with data to be scored and <em>model<\/em> variable contains trained classifier. Then after defining above function I want to make a prediction on sample input vector:<\/p>\n\n<pre><code>predicting.service(1.21, 1.34)\n<\/code><\/pre>\n\n<p>However following error occurs:<\/p>\n\n<pre><code>RuntimeError: Error 0085: The following error occurred during script \nevaluation, please view the output log for more information:\n<\/code><\/pre>\n\n<p>And the most important message in log is: <\/p>\n\n<pre><code>AttributeError: 'module' object has no attribute 'LogisticRegressionCV'\n<\/code><\/pre>\n\n<p>The error is strange to me because when I was using normal <em>sklearn.linear_model.LogisticRegression<\/em> everything was fine. I was able to make predictions sending POST requests to created endpoint, so I guess <strong>sklearn<\/strong> worked correctly. \nAfter changing to <em>LogisticRegressionCV<\/em> it does not. <\/p>\n\n<p>Therefore I wanted to update sklearn on my workspace.<\/p>\n\n<p>Do you have any ideas how to do it? Or even more general question: how to install any python module on azure machine learning studio in a way to use predict functions of any model I develpoed locally?<\/p>\n\n<p>Thanks<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1506940629737,
        "Question_score":2,
        "Question_tags":"python|azure|scikit-learn|python-module|azure-machine-learning-studio",
        "Question_view_count":2578,
        "Owner_creation_time":1458750704640,
        "Owner_last_access_time":1662640939317,
        "Owner_location":"Warszawa, Polska",
        "Owner_reputation":186,
        "Owner_up_votes":108,
        "Owner_down_votes":1,
        "Owner_views":55,
        "Question_last_edit_time":null,
        "Answer_body":"<p>For installing python module on Azure ML Studio, there is a section <a href=\"https:\/\/msdn.microsoft.com\/library\/azure\/cdb56f95-7f4c-404d-bde7-5bb972e6f232\/#Anchor_3\" rel=\"nofollow noreferrer\"><code>Technical Notes<\/code><\/a> of the offical document <code>Execute Python Script<\/code> which introduces it.<\/p>\n\n<p>The general steps as below.<\/p>\n\n<ol>\n<li>Create a Python project via <code>virtualenv<\/code> and active it.<\/li>\n<li>Install all packages you want via <code>pip<\/code> on the virtual Python environment, and then<\/li>\n<li>Package all files and directorys under the path <code>Lib\\site-packages<\/code> of your project as a zip file.<\/li>\n<li>Upload the zip package into your Azure ML WorkSpace as a dataSet.<\/li>\n<li>Follow the offical <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/execute-python-scripts#importing-existing-python-script-modules\" rel=\"nofollow noreferrer\">document<\/a> to import Python Module for your <code>Execute Python Script<\/code>.<\/li>\n<\/ol>\n\n<p>For more details, you can refer to the other similar SO thread <a href=\"https:\/\/stackoverflow.com\/questions\/46222606\/updating-pandas-to-version-0-19-in-azure-ml-studio\/46232963#46232963\">Updating pandas to version 0.19 in Azure ML Studio<\/a>, it even introduced how to update the version of Python packages installed by Azure.<\/p>\n\n<p>Hope it helps.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1507014239333,
        "Answer_score":2.0,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46523924",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46963846,
        "Question_title":"Azure ML Workbench Kubernetes Deployment Failed",
        "Question_body":"<p>I am trying to deploy a prediction web service to Azure using ML Workbench process using cluster mode in this tutorial (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/preview\/tutorial-classifying-iris-part-3#prepare-to-operationalize-locally\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/preview\/tutorial-classifying-iris-part-3#prepare-to-operationalize-locally<\/a>)<\/p>\n\n<p>The model gets sent to the manifest, the scoring script and schema <\/p>\n\n<blockquote>\n  <p>Creating\n  service..........................................................Error\n  occurred: {'Error': {'Code': 'KubernetesDeploymentFailed', 'Details':\n  [{'Message': 'Back-off 40s restarting failed container=...pod=...',\n  'Code': 'CrashLoopBackOff'}], 'StatusCode': 400, 'Message':\n  'Kubernetes Deployment failed'}, 'OperationType': 'Service',\n  'State':'Failed', 'Id': '...', 'ResourceLocation':\n  '\/api\/subscriptions\/...', 'CreatedTime':\n  '2017-10-26T20:30:49.77362Z','EndTime': '2017-10-26T20:36:40.186369Z'}<\/p>\n<\/blockquote>\n\n<p>Here is the result of checking the ml service realtime logs <\/p>\n\n<pre><code>C:\\Users\\userguy\\Documents\\azure_ml_workbench\\projecto&gt;az ml service logs realtime -i projecto\n2017-10-26 20:47:16,118 CRIT Supervisor running as root (no user in config file)\n2017-10-26 20:47:16,120 INFO supervisord started with pid 1\n2017-10-26 20:47:17,123 INFO spawned: 'rsyslog' with pid 9\n2017-10-26 20:47:17,124 INFO spawned: 'program_exit' with pid 10\n2017-10-26 20:47:17,124 INFO spawned: 'nginx' with pid 11\n2017-10-26 20:47:17,125 INFO spawned: 'gunicorn' with pid 12\n2017-10-26 20:47:18,160 INFO success: rsyslog entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\n2017-10-26 20:47:18,160 INFO success: program_exit entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\n2017-10-26 20:47:22,164 INFO success: nginx entered RUNNING state, process has stayed up for &gt; than 5 seconds (startsecs)\n2017-10-26T20:47:22.519159Z, INFO, 00000000-0000-0000-0000-000000000000, , Starting gunicorn 19.6.0\n2017-10-26T20:47:22.520097Z, INFO, 00000000-0000-0000-0000-000000000000, , Listening at: http:\/\/127.0.0.1:9090 (12)\n2017-10-26T20:47:22.520375Z, INFO, 00000000-0000-0000-0000-000000000000, , Using worker: sync\n2017-10-26T20:47:22.521757Z, INFO, 00000000-0000-0000-0000-000000000000, , worker timeout is set to 300\n2017-10-26T20:47:22.522646Z, INFO, 00000000-0000-0000-0000-000000000000, , Booting worker with pid: 22\n2017-10-26 20:47:27,669 WARN received SIGTERM indicating exit request\n2017-10-26 20:47:27,669 INFO waiting for nginx, gunicorn, rsyslog, program_exit to die\n2017-10-26T20:47:27.669556Z, INFO, 00000000-0000-0000-0000-000000000000, , Handling signal: term\n2017-10-26 20:47:30,673 INFO waiting for nginx, gunicorn, rsyslog, program_exit to die\n2017-10-26 20:47:33,675 INFO waiting for nginx, gunicorn, rsyslog, program_exit to die\nInitializing logger\n2017-10-26T20:47:36.564469Z, INFO, 00000000-0000-0000-0000-000000000000, , Starting up app insights client\n2017-10-26T20:47:36.564991Z, INFO, 00000000-0000-0000-0000-000000000000, , Starting up request id generator\n2017-10-26T20:47:36.565316Z, INFO, 00000000-0000-0000-0000-000000000000, , Starting up app insight hooks\n2017-10-26T20:47:36.565642Z, INFO, 00000000-0000-0000-0000-000000000000, , Invoking user's init function\n2017-10-26 20:47:36.715933: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instruc\ntions, but these are available on your machine and could speed up CPU computations.\n2017-10-26 20:47:36,716 INFO waiting for nginx, gunicorn, rsyslog, program_exit to die\n2017-10-26 20:47:36.716376: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instruc\ntions, but these are available on your machine and could speed up CPU computations.\n2017-10-26 20:47:36.716542: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructio\nns, but these are available on your machine and could speed up CPU computations.\n2017-10-26 20:47:36.716703: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructi\nons, but these are available on your machine and could speed up CPU computations.\n2017-10-26 20:47:36.716860: W tensorflow\/core\/platform\/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructio\nns, but these are available on your machine and could speed up CPU computations.\nthis is the init\n2017-10-26T20:47:37.551940Z, INFO, 00000000-0000-0000-0000-000000000000, , Users's init has completed successfully\nUsing TensorFlow backend.\n2017-10-26T20:47:37.553751Z, INFO, 00000000-0000-0000-0000-000000000000, , Worker exiting (pid: 22)\n2017-10-26T20:47:37.885303Z, INFO, 00000000-0000-0000-0000-000000000000, , Shutting down: Master\n2017-10-26 20:47:37,885 WARN killing 'gunicorn' (12) with SIGKILL\n2017-10-26 20:47:37,886 INFO stopped: gunicorn (terminated by SIGKILL)\n2017-10-26 20:47:37,889 INFO stopped: nginx (exit status 0)\n2017-10-26 20:47:37,890 INFO stopped: program_exit (terminated by SIGTERM)\n2017-10-26 20:47:37,891 INFO stopped: rsyslog (exit status 0)\n\nReceived 41 lines of log\n<\/code><\/pre>\n\n<p>My best guess is theres something silent happening to cause \"WARN received SIGTERM indicating exit request\". The rest of the scoring.py script seems to kick off - see tensorflow get initiated and the \"this is the init\" print statement.<\/p>\n\n<p><a href=\"http:\/\/127.0.0.1:63437\" rel=\"nofollow noreferrer\">http:\/\/127.0.0.1:63437<\/a> is accessible from my local machine, but the ui endpoint is blank.<\/p>\n\n<p>Any ideas on how to get this up and running in an Azure cluster? I'm not very familiar with how Kubernetes works, so any basic debugging guidance would be appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1509052128353,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":447,
        "Owner_creation_time":1421081882987,
        "Owner_last_access_time":1663964806323,
        "Owner_location":null,
        "Owner_reputation":588,
        "Owner_up_votes":47,
        "Owner_down_votes":3,
        "Owner_views":64,
        "Question_last_edit_time":1511310430993,
        "Answer_body":"<p>We discovered a bug in our system that could have caused this. The fix was deployed last night. Can you please try again and let us know if you still encounter this issue?<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1509114740967,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46963846",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66592313,
        "Question_title":"Get local workspace in azureml",
        "Question_body":"<p>I am trying to run a machine learning experiment in azureml.<\/p>\n<p>I can't figure out how to get the workspace context from the control script.  Examples like <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data#control-script\" rel=\"nofollow noreferrer\">this one<\/a> in the microsoft docs use Workspace.from_config().  When I use this in the control script I get the following error:<\/p>\n<blockquote>\n<p>&quot;message&quot;: &quot;We could not find config.json in: [path] or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.&quot;<\/p>\n<\/blockquote>\n<p>I've also tried including my subscription id and the resource specs like so:<\/p>\n<pre><code>subscription_id = 'id'\nresource_group = 'name'\nworkspace_name = 'name'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n<\/code><\/pre>\n<p>In this case I have to monitor the log and authenticate on each run as I would locally.<\/p>\n<p>How do you get the local workspace from a control script for azureml?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1615507417267,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":333,
        "Owner_creation_time":1512520584493,
        "Owner_last_access_time":1663886987607,
        "Owner_location":"Bloomington, IN, USA",
        "Owner_reputation":868,
        "Owner_up_votes":109,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Question_last_edit_time":null,
        "Answer_body":"<p>This had no answers for 10 months, and now they are coming in :).  I figuerd this out quite a while ago but haven't gotten around to posting the answer.  Here it is.<\/p>\n<p>From the training script, you can get the workspace from the run context as follows:<\/p>\n<pre><code>from azureml.core import Run\nRun.get_context()\nws = run.experiment.workspace\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1641958092267,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66592313",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68349739,
        "Question_title":"Packaging multiple models from Azure ML experiment",
        "Question_body":"<p>So I have started to create a MLOps pipeline that is training multiple models within multiple pipeline steps.<\/p>\n<p>The picture below is the graphical representation of the coded pipeline steps within the Azure ML Studio.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/QvZxX.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/QvZxX.png\" alt=\"pipeline steps\" \/><\/a><\/p>\n<p>These steps run fine and both the end steps produce the models I want (Train Data - Non EOW TFIDF and Train Data - EOW TFIDF)...<\/p>\n<p>However this is where I get stuck with registering and packaging the model parts for deployment. These models get produced and stored within the individual pipeline step (see below for the model output of Train Data - Non EOW TFIDF)<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/MoE5W.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/MoE5W.png\" alt=\"non eow step output\" \/><\/a><\/p>\n<p>but I don't know how I would register the model outputs from both pipeline steps together as the docs I have read for registering a model seem to only reference the ability to register one model from one path.\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none--sample-input-dataset-none--sample-output-dataset-none--resource-configuration-none-\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none--sample-input-dataset-none--sample-output-dataset-none--resource-configuration-none-<\/a><\/p>\n<p>Basically, is it possible to produce multiple model outputs from multiple pipeline steps and register them together as one??<\/p>\n<p>Thanks in advance for the help!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1626102561633,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":578,
        "Owner_creation_time":1567669433587,
        "Owner_last_access_time":1663943001867,
        "Owner_location":null,
        "Owner_reputation":130,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":1626351577673,
        "Answer_body":"<p>Here is sample for Multi-model Register and deploy. <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb<\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1627574880243,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68349739",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":29485562,
        "Question_title":"Machine Learning-Classifying web page as address and no-address by content",
        "Question_body":"<p>Currently I am using azure machine learning .I train my ML with sets of data of two types they are nothing but web page content with address and without address<\/p>\n\n<p><strong><em>TRAINING INPUT:<\/em><\/strong><\/p>\n\n<pre><code>i.e)\nthis is a address no 24\/5    address\nthis is no address    no-address \n<\/code><\/pre>\n\n<p>I am using two-class bayesian classification to classify them should i use any other method <\/p>\n\n<p><strong><em>GIVEN INPUT:<\/em><\/strong><\/p>\n\n<pre><code>i.e)\nThis a address 12\/4 \n<\/code><\/pre>\n\n<p><strong><em>OBTAINED OUTPUT:<\/em><\/strong><\/p>\n\n<pre><code>i.e)\ncontent    score    probability\nThis a address 12\/4    no-address    0.54\n<\/code><\/pre>\n\n<p><strong><em>EXPECTED OUTPUT:<\/em><\/strong><\/p>\n\n<pre><code>i.e)\ncontent    score    probability\nThis a address 12\/4    address    with higher probability \n<\/code><\/pre>\n\n<p>My experiment looks like :<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/exzqV.png\" alt=\"enter image description here\"><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1428389541860,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio",
        "Question_view_count":195,
        "Owner_creation_time":1415957539617,
        "Owner_last_access_time":1664070583007,
        "Owner_location":"Chennai, India",
        "Owner_reputation":7743,
        "Owner_up_votes":2734,
        "Owner_down_votes":4,
        "Owner_views":1464,
        "Question_last_edit_time":1428389971683,
        "Answer_body":"<p>You need to use the Feature Hashing module to convert the text into word features. This, however, might not be enough as words are not good features for your problem. You may want to do some processing of the text and create more useful features (perhaps detecting the presence of zip codes, positions of numbers, etc...)<\/p>\n\n<p>Edit: Using the raw text column as one feature will not get you anywhere. You don\u2019t want your model to learn the addresses the way they are written. Instead, you need to learn patterns in the text that provide evidence for address vs. non-address instances.\nWhen you use feature hashing, the text column will be transformed to multiple word (or n-gram) columns, where the values represent counts of those words in each text input. The problem here is overfitting. For example, these two addresses have no words in common:\n\u201c100 broadway st, GA\u201d and \u201c200 main rd, NY\u201d but it\u2019s clear they have similar structure. One way to create \u2018useful features\u2019 is to replace the words with tags: \u201c#NUM #TXT, #STATE\u201d and use feature hashing (bi-grams) to create features such as \u201c#NUM #TXT\u201d and \u201c, #STATE\u201d. As you can see, these bi-grams count as evidence in both addresses and suggest some kind of similarity between them (compared to other non-address instances). Of course this is an oversimplification of the problem but I hope you see why you can\u2019t use the raw text or plain feature hashing.<br>\nYou can still use the Azure ML modules for feature hashing, training, and scoring in addition to an \u2018Execute R\u2019 module to do the text processing before training.<\/p>\n\n<p>Edit: Example of feature hashing usage: <a href=\"http:\/\/gallery.azureml.net\/Details\/cf65bf129fee4190b6f48a53e599a755\" rel=\"nofollow\">http:\/\/gallery.azureml.net\/Details\/cf65bf129fee4190b6f48a53e599a755<\/a> <\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1428422166660,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1428492704453,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/29485562",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51780562,
        "Question_title":"How to prevent Azure ML Studio from converting a feature column to DateTime while importing a dataset",
        "Question_body":"<p>I\u2019m having some issues trying to load a dataset in Azure ML Studio, a dataset containing a column that looks like a DateTime, but is in fact a string. Azure ML Studio converts the values to DateTimes internally, and no amount of wrangling seems to convince it of the that they\u2019re in fact strings.<\/p>\n\n<p>This is an issue, because during conversion the values lose precision and start appearing as duplicates whereas in fact they are unique. Does anybody know if ML Studio can be configured not to infer data types for columns while importing a dataset?<\/p>\n\n<p>Now, for the long(er) story :)<\/p>\n\n<p>I\u2019m working here with a public dataset - specifically <a href=\"https:\/\/www.kaggle.com\/c\/new-york-city-taxi-fare-prediction\" rel=\"noreferrer\">Kaggle\u2019s New York City Fare Prediction<\/a> competition. I wanted to see if I could do a quick-and-dirty solution using Azure ML Studio, however the dataset\u2019s unique key values are of the form\n<code>\n    2015-01-27 13:08:24.0000003\n    2015-01-27 13:08:24.0000002\n    2011-10-06 12:10:20.0000001\n<\/code>\nand so on. <\/p>\n\n<p>When importing them in my experiment the key values get converted to DateTime, making them no longer unique, even though they\u2019re unique in the csv. Needless to say, this prevents me from submitting any solution to Kaggle, since I can\u2019t identify the rows uniquely :).<\/p>\n\n<p>I\u2019ve tried the following:<\/p>\n\n<ul>\n<li>edit the metadata of the dataset after it has been loaded and setting the data type of the column to string, but this doesn\u2019t do much as the precision has already been lost<\/li>\n<li>import the dataset from an Azure blob, convert it to csv and then loading it in Jupyter\/Python - this brings me the same (duplicated) keys. <\/li>\n<li>loading the dataset locally with pandas works, as expected.<\/li>\n<\/ul>\n\n<p>I\u2019ve reproduced this behavior with both the big, 5.5GB <code>train<\/code> dataset, but also with the more manageable <code>sample_submission<\/code> dataset. <\/p>\n\n<p>Curious to know if there is some sort of workaround to tell ML Studio not to try converting this column while loading the dataset. I'm looking here specifically for Azure ML Studio-only solutions, as I don't want to do any preprocessing on the dataset.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1533883639527,
        "Question_score":5,
        "Question_tags":"azure|azure-machine-learning-studio|kaggle|ml-studio",
        "Question_view_count":401,
        "Owner_creation_time":1250158552417,
        "Owner_last_access_time":1663847198323,
        "Owner_location":"Romania",
        "Owner_reputation":7916,
        "Owner_up_votes":1735,
        "Owner_down_votes":33,
        "Owner_views":801,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I have tried with you sample data and here is my quick and dirty solution:\n1) Add any symbol (I've added the '#') in front of each date\n2) Load it to AML Studio (it is now considered as a string feature)\n3) Add a Python\/R component to remove the '#' symbol and explicitly convert the column to string (as.string(columnname) or str(columnname))<\/p>\n\n<p>Hope this helps<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1534433513133,
        "Answer_score":4.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51780562",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67639665,
        "Question_title":"Azure ML not able to create conda environment (exit code: -15)",
        "Question_body":"<p>When I try to run the experiment defined in <a href=\"https:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/06%20-%20Work%20with%20Data.ipynb\" rel=\"nofollow noreferrer\">this notebook<\/a> in  notebook, I encountered an error when it is creating the conda env. The error occurs when the below cell is executed:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Experiment, ScriptRunConfig, Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.widgets import RunDetails\n\n\n# Create a Python environment for the experiment\nsklearn_env = Environment(&quot;sklearn-env&quot;)\n\n# Ensure the required packages are installed (we need scikit-learn, Azure ML defaults, and Azure ML dataprep)\npackages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n                                    pip_packages=['azureml-defaults','azureml-dataprep[pandas]'])\nsklearn_env.python.conda_dependencies = packages\n\n# Get the training dataset\ndiabetes_ds = ws.datasets.get(&quot;diabetes dataset&quot;)\n\n# Create a script config\nscript_config = ScriptRunConfig(source_directory=experiment_folder,\n                              script='diabetes_training.py',\n                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n                                           '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n                              environment=sklearn_env)\n\n# submit the experiment\nexperiment_name = 'mslearn-train-diabetes'\nexperiment = Experiment(workspace=ws, name=experiment_name)\nrun = experiment.submit(config=script_config)\nRunDetails(run).show()\nrun.wait_for_completion() \n<\/code><\/pre>\n<p>Everytime I run this, I always faced the issue of creating the conda env as below:<\/p>\n<pre><code>Creating conda environment...\nRunning: ['conda', 'env', 'create', '-p', '\/home\/azureuser\/.azureml\/envs\/azureml_000000000000', '-f', 'azureml-environment-setup\/mutated_conda_dependencies.yml']\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n\nInstalling pip dependencies: ...working... \n\nAttempting to clean up partially built conda environment: \/home\/azureuser\/.azureml\/envs\/azureml_000000000000\nRemove all packages in environment \/home\/azureuser\/.azureml\/envs\/azureml_000000000000:\nCreating conda environment failed with exit code: -15\n<\/code><\/pre>\n<p>I could not find anything useful on the internet and this is not the only script where it fail. When I am try to run other experiments I have sometimes faced this issue. One solution which worked in the above case is I moved the pandas from pip to conda and it was able to create the coonda env. Example below:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code># Ensure the required packages are installed (we need scikit-learn, Azure ML defaults, and Azure ML dataprep)\npackages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n                                    pip_packages=['azureml-defaults','azureml-dataprep[pandas]'])\n\n<\/code><\/pre>\n<pre class=\"lang-py prettyprint-override\"><code># Ensure the required packages are installed (we need scikit-learn, Azure ML defaults, and Azure ML dataprep)\npackages = CondaDependencies.create(conda_packages=['scikit-learn','pip','pandas'],\n                                    pip_packages=['azureml-defaults','azureml-dataprep'])\n\n<\/code><\/pre>\n\n<p>The error message (or the logs from Azure) is also not much help. Would apprecite if a proper solution is available.<\/p>\n<p>Edit: I have recently started learning to use Azure for Machine learning and so if I am not sure if I am missing something? I assume the example notebooks should work as is hence raised this question.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1621610368967,
        "Question_score":4,
        "Question_tags":"anaconda|azure-machine-learning-service",
        "Question_view_count":2373,
        "Owner_creation_time":1488207114693,
        "Owner_last_access_time":1655016627737,
        "Owner_location":"India",
        "Owner_reputation":493,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Question_last_edit_time":1621615281777,
        "Answer_body":"<h2>short answer<\/h2>\n<p>Totally been in your shoes before. This code sample seems a smidge out of date. Using <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/train-with-datasets\/train-with-datasets.ipynb\" rel=\"nofollow noreferrer\">this notebook<\/a> as a reference, can you try the following?<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>packages = CondaDependencies.create(\n    pip_packages=['azureml-defaults','scikit-learn']\n)\n<\/code><\/pre>\n<h2>longer  answer<\/h2>\n<p><a href=\"https:\/\/www.anaconda.com\/blog\/using-pip-in-a-conda-environment\" rel=\"nofollow noreferrer\">Using pip with Conda<\/a> is not always smooth sailing. In this instance, conda isn't reporting up the issue that pip is having. The solution is to create and test this environment locally where we can get more information, which will at least will give you a more informative error message.<\/p>\n<ol>\n<li>Install anaconda  or miniconda (or use an Azure ML Compute Instance which has conda pre-installed)<\/li>\n<li>Make a  file called environment.yml that looks like this<\/li>\n<\/ol>\n<pre class=\"lang-yaml prettyprint-override\"><code>name: aml_env\ndependencies:\n - python=3.8\n - pip=21.0.1\n - pip:\n    - azureml-defaults\n    - azureml-dataprep[pandas]\n    - scikit-learn==0.24.1\n<\/code><\/pre>\n<ol start=\"3\">\n<li>Create this environment with the command <code>conda env create -f environment.yml<\/code>.<\/li>\n<li>respond to any discovered error message<\/li>\n<li>If there' no error, use this new <code>environment.yml<\/code> with Azure ML like so<\/li>\n<\/ol>\n<pre class=\"lang-py prettyprint-override\"><code>sklearn_env = Environment.from_conda_specification(name = 'sklearn-env', file_path = '.\/environment.yml')\n<\/code><\/pre>\n<h2>more context<\/h2>\n<p>the error I'm guessing that's happening is when you reference a pip requirements file from a conda environment file. In this scenario, conda calls <code>pip install -r  requirements.txt<\/code> and if that command errors out, conda can't report the error.<\/p>\n<h3><code>requirements.txt<\/code><\/h3>\n<pre><code>scikit-learn==0.24.1\nazureml-dataprep[pandas]\n<\/code><\/pre>\n<h3><code>environment.yml<\/code><\/h3>\n<pre><code>name: aml_env\ndependencies:\n - python=3.8\n - pip=21.0.1\n - pip:\n    - -rrequirements.txt\n<\/code><\/pre>",
        "Answer_comment_count":6.0,
        "Answer_creation_time":1621615054950,
        "Answer_score":3.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1621619024733,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67639665",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39150834,
        "Question_title":"probability on azure recommendations api",
        "Question_body":"<p>I am using the azure recommendation api on <a href=\"http:\/\/recommendations.azurewebsites.net\/\" rel=\"nofollow noreferrer\">http:\/\/recommendations.azurewebsites.net\/<\/a>.\nI prepared the catalog to be like <code>&lt;Item Id&gt;<\/code>, <code>&lt;Item Name&gt;<\/code>, <code>&lt;Item Category&gt;<\/code>, <code>&lt;Features list&gt;<\/code> and the usage file : <code>&lt;userId&gt;<\/code>, <code>&lt;ItemId&gt;<\/code>.\nNow when I test the recommender, I always get a probability of 0.5 for all items, so I had to presume something is not right.\nIn order to know what's the problem I added two items to the catalog \none with same features as an other item but with different name and id,\nand an other item with different id and one different feature.\nI still get the 0.5 probability and now i'm sure something is not right but I still can figure out what the problem.<\/p>\n\n<p>here is a screenshot of what I get when I add the item to the cart<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/zhwiq.png\" alt=\"\"><\/p>\n\n<p>Is there any possibility to use the azure ml matchbox recommender with features and without ratings? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1472144085380,
        "Question_score":0,
        "Question_tags":"recommendation-engine|azure-machine-learning-studio",
        "Question_view_count":98,
        "Owner_creation_time":1447254948300,
        "Owner_last_access_time":1663768823953,
        "Owner_location":"Tunis, Gouvernorat de Tunis, Tunisie",
        "Owner_reputation":31,
        "Owner_up_votes":61,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Question_last_edit_time":1491136060303,
        "Answer_body":"<p>Tayehi, <\/p>\n\n<p>Nice to meet you. I am the program manager in charge of the recommendations API.\n2 things:<\/p>\n\n<ol>\n<li><p>If you get a 0.5 probability you are most likely getting \"default recommendations\". This usually means that you do not have enough training data or that there are not enough co-occurrences for the item you are testing in the data. To describe the extreme case, imagine an item A that only gets purchased with an item B only one or two times -- it would be hard to say with confidence (statistical significance) that someone that likes item A is also likely to like item B.<\/p><\/li>\n<li><p>It looks like you are still using the old recommendations API. I would like to encourage you to use our newer version (the Recommendations API cognitive service). Please take a look at <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/cognitive-services-migration-from-dm\/to\" rel=\"nofollow\">https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/cognitive-services-migration-from-dm\/to<\/a> help you in this process.<\/p><\/li>\n<\/ol>\n\n<p>Thanks!\nLuis Cabrera\nCortana Intelligence Applications.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1476373208683,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1476476017407,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39150834",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62623166,
        "Question_title":"Azure ML Error: TimeSeriesImputer object has no attribute '_known_df'",
        "Question_body":"<p>Running <a href=\"http:\/\/%20https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/forecasting-orange-juice-sales\/auto-ml-forecasting-orange-juice-sales.ipynb\" rel=\"nofollow noreferrer\">this orange juice sales notebook<\/a> I get the below error with the <code>.forecast()<\/code> method.<\/p>\n<h3>code<\/h3>\n<pre class=\"lang-py prettyprint-override\"><code># The featurized data, aligned to y, will also be returned.\n# This contains the assumptions that were made in the forecast\n# and helps align the forecast to the original data\ny_predictions, X_trans = fitted_model.forecast(X_test)\n<\/code><\/pre>\n<h3>Error (<a href=\"https:\/\/gist.github.com\/swanderz\/201819978b6719bbed1826a02bb2fb47\" rel=\"nofollow noreferrer\">full stacktrace<\/a>):<\/h3>\n<pre><code>**AttributeError: 'TimeSeriesImputer' object has no attribute '_known_df'**\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1593350881953,
        "Question_score":1,
        "Question_tags":"time-series|azure-machine-learning-studio|forecast|azure-machine-learning-service",
        "Question_view_count":256,
        "Owner_creation_time":1444548825377,
        "Owner_last_access_time":1641987792040,
        "Owner_location":null,
        "Owner_reputation":303,
        "Owner_up_votes":105,
        "Owner_down_votes":7,
        "Owner_views":60,
        "Question_last_edit_time":1594142196017,
        "Answer_body":"<p>This is commonly fixed by upgrading to the latest SDK. You can do this by running <code>pip install --upgrade azureml-sdk[explain,automl]<\/code>.<\/p>\n<p>Thanks,\nSabina<\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1593542625630,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62623166",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":69768602,
        "Question_title":"How to output data to Azure ML Batch Endpoint correctly using python?",
        "Question_body":"<p>When invoking Azure ML Batch Endpoints (creating jobs for inferencing), the run() method should return a pandas DataFrame or an array as explained <a href=\"https:\/\/i.stack.imgur.com\/azJDX.png\" rel=\"nofollow noreferrer\">here<\/a><\/p>\n<p>However this example shown, doesn't represent an output with headers for a csv, as it is often needed.<\/p>\n<p>The first thing I've tried was to return the data as a <em>pandas DataFrame<\/em> and the result is just a simple csv with a single column and without the headers.<\/p>\n<p>When trying to pass the values with several columns and it's corresponding headers, to be later saved as csv, as a result, I'm getting awkward square brackets (representing the lists in python) and the apostrophes (representing strings)<\/p>\n<p>I haven't been able to find documentation elsewhere, to fix this:\n<a href=\"https:\/\/i.stack.imgur.com\/azJDX.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/azJDX.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1635509192960,
        "Question_score":2,
        "Question_tags":"azure|batch-processing|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":295,
        "Owner_creation_time":1589293508567,
        "Owner_last_access_time":1663681781073,
        "Owner_location":null,
        "Owner_reputation":833,
        "Owner_up_votes":9,
        "Owner_down_votes":9,
        "Owner_views":55,
        "Question_last_edit_time":null,
        "Answer_body":"<p>This is the way I found to create a clean output in csv format using python, from a batch endpoint invoke in AzureML:<\/p>\n<pre><code>def run(mini_batch):\n    batch = []\n    for file_path in mini_batch:\n        df = pd.read_csv(file_path)\n        \n        # Do any data quality verification here:\n        if 'id' not in df.columns:\n            logger.error(&quot;ERROR: CSV file uploaded without id column&quot;)\n            return None\n        else:\n            df['id'] = df['id'].astype(str)\n\n        # Now we need to create the predictions, with previously loaded model in init():\n        df['prediction'] = model.predict(df)\n        # or alternative, df[MULTILABEL_LIST] = model.predict(df)\n\n        batch.append(df)\n\n    batch_df = pd.concat(batch)\n\n    # After joining all data, we create the columns headers as a string,\n    # here we remove the square brackets and apostrophes:\n    azureml_columns = str(batch_df.columns.tolist())[1:-1].replace('\\'','')\n    result = []\n    result.append(azureml_columns)\n\n    # Now we have to parse all values as strings, row by row, \n    # adding a comma between each value\n    for row in batch_df.iterrows():\n        azureml_row = str(row[1].values).replace(' ', ',')[1:-1].replace('\\'','').replace('\\n','')\n        result.append(azureml_row)\n\n    logger.info(&quot;Finished Run&quot;)\n    return result\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1635509192960,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1638266985653,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69768602",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50035628,
        "Question_title":"Include additional scripts when deploying a Azure ML experimentation service",
        "Question_body":"<p>When training my model the data I start with consist of rows of json data and the expected values I would like to predict from that json data. The json data follows the schema I my deployed service will receive the input as. Before training I run a number of python functions to transform the data and extract features calculated from the raw json data. It is that transformed data which my model is trained on.<\/p>\n\n<p>I have extracted the code to transform the json data into the input my model expects into a separate python file. Now I would like to have my scoring script use that python script to prepare the input sent to the service before feeding it into my trained model.<\/p>\n\n<p>Is there a way to include the data transformation script with the scoring script when deploying my service using the cli command:<\/p>\n\n<pre><code>az ml service create realtime \n    -f &lt;scoring-script&gt;.py \n    --model-file model.pkl \n    -s service_schema.json \n    -n &lt;some-name&gt; \n    -r python \n    --collect-model-data true \n    -c aml_config\\conda_dependencies.yml\n<\/code><\/pre>\n\n<p><em>(the new lines in the above command added for clarity)<\/em><\/p>\n\n<p>The two ways I've come up with is to either:<\/p>\n\n<ul>\n<li>Create my own base docker image that contains the transformation script and use that image as the base for my service. Seems a bit cumbersome to do if I need similar (but different) data transformations for later models.<\/li>\n<li>Concatenate the transformation script with my scoring script into a single file. Seems a bit hacky.<\/li>\n<\/ul>\n\n<p><strong>Is there another way to achive my goal of having a separate data transformation script used both in training and in scoring?<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1524721574190,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":252,
        "Owner_creation_time":1275401694660,
        "Owner_last_access_time":1664029322520,
        "Owner_location":"Gothenburg, Sweden",
        "Owner_reputation":18969,
        "Owner_up_votes":699,
        "Owner_down_votes":20,
        "Owner_views":517,
        "Question_last_edit_time":1524806425600,
        "Answer_body":"<p>So running <code>az ml service create realtime -h<\/code> provides information about the <code>-d<\/code> flag.<\/p>\n\n<p><code>-d : Files and directories required by the service. Multiple dependencies can be specified with additional -d arguments.<\/code><\/p>\n\n<p>Please try using this flag and provide the additional python file that you would like to call too from your <code>score.py<\/code><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1524806224530,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50035628",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37540703,
        "Question_title":"Test multiple algorithms in one experiment",
        "Question_body":"<p>Is there any way to test multiple algorithms rather than doing it once for each and every algorithm; then checking the result? There are a lot of times where I don\u2019t really know which one to use, so I would like to test multiple and get the result (error rate) fairly quick in Azure Machine Learning Studio.<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_time":1464683630827,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":425,
        "Owner_creation_time":1456309738853,
        "Owner_last_access_time":1471868452243,
        "Owner_location":null,
        "Owner_reputation":39,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1465977920520,
        "Answer_body":"<p>The module you are looking for, is the one called \u201c<strong>Cross-Validate Model<\/strong>\u201d. It basically splits whatever comes in from the input-port (dataset) into 10 pieces, then reserves the last piece as the \u201canswer\u201d; and trains the nine other subset models and returns a set of accuracy statistics measured towards the last subset. What you would look at is the column called \u201cMean absolute error\u201d which is the average error for the trained models. You can connect whatever algorithm you want to one of the ports, and subsequently you will receive the result for that algorithm in particular after you \u201cright-click\u201d the port which gives the score.<\/p>\n\n<p>After that you can assess which algorithm did the best. And as a pro-tip; you could use the <strong>Filter-based-feature selection<\/strong> to actually see which column had a significant impact on the result.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1464685093653,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37540703",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45051055,
        "Question_title":"Read multiple CSV files in Azure ML Python Script",
        "Question_body":"<p>I have 4 csv files that are inputs to the python script in azure ML, but the widget has only 2 inputs for dataframes and the third for a zip file. I tried to put the csv files in a zipped folder and connect it to the third input for the script but that also did not work :\n<a href=\"https:\/\/i.stack.imgur.com\/FkxRE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FkxRE.png\" alt=\"Image of workspace\"><\/a><\/p>\n\n<p>I would like to know how to read multiple csv files in the python script.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1499844354733,
        "Question_score":1,
        "Question_tags":"python|csv|azure|azure-machine-learning-studio",
        "Question_view_count":944,
        "Owner_creation_time":1470376815797,
        "Owner_last_access_time":1660941481503,
        "Owner_location":null,
        "Owner_reputation":596,
        "Owner_up_votes":72,
        "Owner_down_votes":3,
        "Owner_views":57,
        "Question_last_edit_time":1499850837700,
        "Answer_body":"<p>Here's some more detail on the approach others have outlined above. Try replacing the code currently in the \"Execute Python Script\" module with the following:<\/p>\n\n<pre><code>import pandas as pd\nimport os\ndef azureml_main(dataframe1=None, dataframe2=None):\n    print(os.listdir('.'))\n    return(pd.DataFrame([]))\n<\/code><\/pre>\n\n<p>After running the experiment, click on the module. There should be a \"View output log\" link now in the right-hand bar. I get something like the following:<\/p>\n\n<pre><code>[Information]         Started in [C:\\temp]\n[Information]         Running in [C:\\temp]\n[Information]         Executing 4af67c05ba02417a980f6a16e84e61dc with inputs [] and generating outputs ['.maml.oport1']\n[Information]         Extracting Script Bundle.zip to .\\Script Bundle\n[Information]         File Name                                             Modified             Size\n[Information]         temp.csv                                       2016-05-06 13:16:56           52\n[Information]         [ READING ] 0:00:00\n[Information]         ['4af67c05ba02417a980f6a16e84e61dc.py', 'Script Bundle', 'Script Bundle.zip']\n<\/code><\/pre>\n\n<p>This tells me that the contents of my zip file have been extracted to the <code>C:\\temp\\Script Bundle<\/code> folder. In my case the zip file contained just one CSV file, <code>temp.csv<\/code>: your output would probably have four files. You may also have zipped a folder containing your four files, in which case the filepath would be one layer deeper. You can use the <code>os.listdir()<\/code> to explore your directory structure further if necessary.<\/p>\n\n<p>Once you think you know the full filepaths for your CSV files, edit your Execute Python Script module's code to load them, e.g.:<\/p>\n\n<pre><code>import pandas as pd\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    df = pd.read_csv('C:\/temp\/Script Bundle\/temp.csv')\n    # ...load other files and merge into a single dataframe...\n    return(df)\n<\/code><\/pre>\n\n<p>Hope that helps!<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1500412322170,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45051055",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72637756,
        "Question_title":"Azure Machine Learning Model deployment as AKS web service from multiple workspaces",
        "Question_body":"<p>I am trying to determine how the Az ML model deployment works with AKS. If you have a single AKS cluster but attach from two separate workspaces, will models from both workspaces get deployed into different azureml-fe's with different IP addresses OR a single azureml-fe with a single IP address? Reason I ask is because I want to purchase a certificate but am unsure if all the models (regardless of workspace) will get exposed under the same IP Address OR multiple IP Addresses? If its the former, I can do it with one certificate...otherwise I have to do it with multiple certificates or SAN based certificates. So if anyone has experience with this, please let me know!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1655326759547,
        "Question_score":0,
        "Question_tags":"azure-aks|azure-machine-learning-service",
        "Question_view_count":127,
        "Owner_creation_time":1376577570773,
        "Owner_last_access_time":1663954112673,
        "Owner_location":null,
        "Owner_reputation":301,
        "Owner_up_votes":27,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Question_last_edit_time":null,
        "Answer_body":"<p>By checking AKS webservice class, we can do the multiple services links to single AKS cluster. The endpoint management was described in <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.webservice.aks.akswebservice?view=azure-ml-py\" rel=\"nofollow noreferrer\">document<\/a>, but this is representing one-to-one cluster and service. For multiple workspaces refer <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.webservice.aksendpoint?view=azure-ml-py#azureml-core-webservice-aksendpoint-create-version\" rel=\"nofollow noreferrer\">document<\/a>.<\/p>\n<p>Regarding <strong><code>azureml-fe<\/code><\/strong>. There will be one <strong>azureml-fe<\/strong> for one cluster. That means, when we are using different workspaces for deployment into one AKS, then only <strong>one<\/strong> <strong>azureml-fe<\/strong> and can be considered to take <strong>one certificate.<\/strong><\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-deploy-azure-kubernetes-service?tabs=python#azure-ml-router\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-deploy-azure-kubernetes-service?tabs=python#azure-ml-router<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1655345708050,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72637756",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48879595,
        "Question_title":"ImportError: No module named cassandra in Azure Machine Learning Studio",
        "Question_body":"<p>I am trying to install python package cassandra driver in Azure Machine Learning studio. I am following this answer from <a href=\"https:\/\/stackoverflow.com\/questions\/44371692\/install-python-packages-in-azure-ml\">here<\/a>. Unfortunately i don't see any wheel file for cassandra-driver <a href=\"https:\/\/pypi.python.org\/pypi\/cassandra-driver\/\" rel=\"nofollow noreferrer\">https:\/\/pypi.python.org\/pypi\/cassandra-driver\/<\/a> so i downloaded the .tar file and converted to zip.<\/p>\n<p>I included this .zip file as dataset and connected to python script<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/omsO9.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/omsO9.jpg\" alt=\"jpg1\" \/><\/a><\/p>\n<p>But when i run it, it says No module named cassandra\n<a href=\"https:\/\/i.stack.imgur.com\/4DKTB.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4DKTB.jpg\" alt=\"jpg2\" \/><\/a><\/p>\n<p>Does this work only with wheel file? Any solution is much appreciated.<\/p>\n<p>I am using Python Version :  Anoconda 4.0\/Python 3.5<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1519110374087,
        "Question_score":1,
        "Question_tags":"python|python-3.x|azure|cassandra|azure-machine-learning-studio",
        "Question_view_count":500,
        "Owner_creation_time":1489644560420,
        "Owner_last_access_time":1646025882010,
        "Owner_location":"Planet Earth",
        "Owner_reputation":791,
        "Owner_up_votes":55,
        "Owner_down_votes":4,
        "Owner_views":253,
        "Question_last_edit_time":1592644375060,
        "Answer_body":"<p>I got it working. Changed the folder inside .zip file to <code>\"cassandra\"<\/code> (just like cassandra package). <\/p>\n\n<p>And in the Python script, i added <\/p>\n\n<pre><code>from cassandra import *\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1519124227917,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48879595",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73187536,
        "Question_title":"Error while detaching AKS cluster through Azure ML SDK extension",
        "Question_body":"<p>I created an AKS cluster using Azure Machine Learning SDK extension and I attached to the workspace created. When the cluster is created and attached, I doesn't show any error. When I am trying to detach it from workspace, it is not accepting the operations.<\/p>\n<p>I would like to detach the existing AKS cluster from workspace either by program manner, using CLI or even using Azure portal.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1659308799773,
        "Question_score":0,
        "Question_tags":"azure|azure-aks|azure-machine-learning-studio",
        "Question_view_count":47,
        "Owner_creation_time":1651093614703,
        "Owner_last_access_time":1659335138797,
        "Owner_location":"Netherland",
        "Owner_reputation":19,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":null,
        "Answer_body":"<p>If we are using any <strong>extensions of SDK or Azure CLI<\/strong> for machine learning to detach AKS cluster, it <strong>will not work<\/strong> and it will not get deleted or detached. Instead, we need to use <strong>Azure CLI with AKS<\/strong>. There are two types of implementations we can perform.<\/p>\n<p><strong>Python:<\/strong><\/p>\n<pre><code>Aks_target.detach()\n<\/code><\/pre>\n<p><strong>Azure CLI:<\/strong><\/p>\n<p>Before performing this step, we need to get the details of the working AKS cluster name attached to our workspace. Resource Group details and workspace name<\/p>\n<pre><code>az ml computertarget detach -n youraksname -g yourresourcegroup -w yourworkspacename\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1659333006090,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73187536",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71499094,
        "Question_title":"Python AzureML Hello world - Can't find module azureml",
        "Question_body":"<p>Python 3.10, Pip install azureml-sdk 1.39.0.<br \/>\nEnvironments: Win10 PS, VS2022, and a docker image- all same results . Pip show shows the azureml-core package.<\/p>\n<p>Simple (I thought) script, but it can't find &quot;azureml.core&quot;   No module named azureml is the error.\nHow do I make it &quot;find&quot; it? I'm new at python so it could be syntax.<\/p>\n<pre><code>import os\nfrom azureml.core import Workspace, Experiment, Environment, Model,Dataset,Datastore,ScriptRunConfig\n     \n    # check core SDK version number\n    print(&quot;Azure ML SDK Version: &quot;, azureml.core.VERSION)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1647441787870,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":310,
        "Owner_creation_time":1263312456837,
        "Owner_last_access_time":1662141819340,
        "Owner_location":null,
        "Owner_reputation":49,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":15,
        "Question_last_edit_time":null,
        "Answer_body":"<p>azureml python sdk does not support py3.10 yet, AutoML sdk supports py&lt;=3.8.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1648177993987,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71499094",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71747545,
        "Question_title":"Commands in the Azure ML yml files",
        "Question_body":"<p>When reading the examples from Microsoft on azure ML CLI v2, they use the symbols:\n&quot;|&quot;, &quot;&gt;&quot;, etc., in their yml files.<\/p>\n<p>What do they mean, and where can I find explanations of possible syntax for the Azure CLI v2 engine?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1649142429250,
        "Question_score":0,
        "Question_tags":"yaml|command-line-interface|azure-machine-learning-studio",
        "Question_view_count":100,
        "Owner_creation_time":1620049475610,
        "Owner_last_access_time":1663926087860,
        "Owner_location":"Denmark",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":null,
        "Answer_body":"<p>| - This pipe symbol in YAML document is used for <em><strong>&quot;Multiple line statements&quot;<\/strong><\/em><\/p>\n<pre><code>description: |\n  # Azure Machine Learning &quot;hello world&quot; job\n\n  This is a &quot;hello world&quot; job running in the cloud via Azure Machine Learning!\n\n  ## Description\n\n  Markdown is supported in the studio for job descriptions! You can edit the description there or via CLI.\n<\/code><\/pre>\n<p>in the above example, we need to write some multiple line description. So, we need to use &quot;|&quot; symbol<\/p>\n<p>&quot;&gt;&quot; - This symbol is used to save some content directly to a specific location document.<\/p>\n<pre><code>command: echo &quot;hello world&quot; &gt; .\/outputs\/helloworld.txt\n<\/code><\/pre>\n<p>In this above command, we need to post <strong>&quot;hello world&quot;<\/strong> to <em><strong>&quot;helloworld.txt&quot;<\/strong><\/em><\/p>\n<p>Check the below link for complete documentation regarding YAML files.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-job-command\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-yaml-job-command<\/a><\/p>\n<p>All these symbols are the YAML job commands which are used to accomplish a specific task through CLI.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1649231701843,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71747545",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63766714,
        "Question_title":"Run.get_context() gives the same run id",
        "Question_body":"<p>I am submitting the training through a script file. Following is the content of the <code>train.py<\/code> script. Azure ML is treating all these as one run (instead of run per alpha value as coded below) as <code>Run.get_context()<\/code> is returning the same Run id.<\/p>\n<p><strong>train.py<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.opendatasets import Diabetes\nfrom azureml.core import Run\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.externals import joblib\n\nimport math\nimport os\nimport logging\n\n# Load dataset\ndataset = Diabetes.get_tabular_dataset()\nprint(dataset.take(1))\n\ndf = dataset.to_pandas_dataframe()\ndf.describe()\n\n# Split X (independent variables) &amp; Y (target variable)\nx_df = df.dropna()      # Remove rows that have missing values\ny_df = x_df.pop(&quot;Y&quot;)    # Y is the label\/target variable\n\nx_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=66)\nprint('Original dataset size:', df.size)\nprint(&quot;Size after dropping 'na':&quot;, x_df.size)\nprint(&quot;Training split size: &quot;, x_train.size)\nprint(&quot;Test split size: &quot;, x_test.size)\n\n# Training\nalphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # Define hyperparameters\n\n# Create and log interactive runs\n\noutput_dir = os.path.join(os.getcwd(), 'outputs')\n\nfor hyperparam_alpha in alphas:\n    # Get the experiment run context\n    run = Run.get_context()\n    print(&quot;Started run: &quot;, run.id)\n    run.log(&quot;train_split_size&quot;, x_train.size)\n    run.log(&quot;test_split_size&quot;, x_train.size)\n    run.log(&quot;alpha_value&quot;, hyperparam_alpha)\n\n    # Train\n    print(&quot;Train ...&quot;)\n    model = Ridge(hyperparam_alpha)\n    model.fit(X = x_train, y = y_train)\n    \n    # Predict\n    print(&quot;Predict ...&quot;)\n    y_pred = model.predict(X = x_test)\n\n    # Calculate &amp; log error\n    rmse = math.sqrt(mean_squared_error(y_true = y_test, y_pred = y_pred))\n    run.log(&quot;rmse&quot;, rmse)\n    print(&quot;rmse&quot;, rmse)\n\n    # Serialize the model to local directory\n    if not os.path.isdir(output_dir):\n        os.makedirs(output_dir, exist_ok=True) \n\n    print(&quot;Save model ...&quot;)\n    model_name = &quot;model_alpha_&quot; + str(hyperparam_alpha) + &quot;.pkl&quot; # Pickle file\n    file_path = os.path.join(output_dir, model_name)\n    joblib.dump(value = model, filename = file_path)\n\n    # Upload the model\n    run.upload_file(name = model_name, path_or_stream = file_path)\n\n    # Complete the run\n    run.complete()\n<\/code><\/pre>\n<p><strong>Experiments view<\/strong>\n<a href=\"https:\/\/i.stack.imgur.com\/E6xAG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/E6xAG.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>Authoring code (i.e. control plane)<\/strong><\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nfrom azureml.core import Workspace, Experiment, RunConfiguration, ScriptRunConfig, VERSION, Run\n\nws = Workspace.from_config()\nexp = Experiment(workspace = ws, name = &quot;diabetes-local-script-file&quot;)\n\n# Create new run config obj\nrun_local_config = RunConfiguration()\n\n# This means that when we run locally, all dependencies are already provided.\nrun_local_config.environment.python.user_managed_dependencies = True\n\n# Create new script config\nscript_run_cfg = ScriptRunConfig(\n    source_directory =  os.path.join(os.getcwd(), 'code'),\n    script = 'train.py',\n    run_config = run_local_config) \n\nrun = exp.submit(script_run_cfg)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1599411710610,
        "Question_score":3,
        "Question_tags":"azure|hyperparameters|azure-machine-learning-service",
        "Question_view_count":2523,
        "Owner_creation_time":1245726715290,
        "Owner_last_access_time":1664077528337,
        "Owner_location":"Cumming, GA",
        "Owner_reputation":77230,
        "Owner_up_votes":2724,
        "Owner_down_votes":43,
        "Owner_views":6359,
        "Question_last_edit_time":1599438192360,
        "Answer_body":"<h2>Short Answer<\/h2>\n<h3>Option 1: create child runs within run<\/h3>\n<p><code>run = Run.get_context()<\/code> assigns the run object of the run that you're currently in to <code>run<\/code>. So in every iteration of the hyperparameter search, you're logging to the same run. To solve this, you need to create child (or sub-) runs for each hyperparameter value. You can do this with <code>run.child_run()<\/code>. Below is the template for making this happen.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>run = Run.get_context()\n\nfor hyperparam_alpha in alphas:\n    # Get the experiment run context\n    run_child = run.child_run()\n    print(&quot;Started run: &quot;, run_child.id)\n    run_child.log(&quot;train_split_size&quot;, x_train.size)\n<\/code><\/pre>\n<p>On the <code>diabetes-local-script-file<\/code> Experiment page, you can see that Run <code>9<\/code> was the parent run and Runs <code>10-19<\/code> were the child runs if you click &quot;Include child runs&quot; page. There is also a &quot;Child runs&quot; tab on Run 9 details page.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/5IMcz.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/5IMcz.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<h2>Long answer<\/h2>\n<p>I highly recommend abstracting the hyperparameter search away from the data plane (i.e. <code>train.py<\/code>) and into the control plane (i.e. &quot;authoring code&quot;). This becomes especially valuable as training time increases and you can arbitrarily parallelize and also choose Hyperparameters more intelligently by using Azure ML's <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters\" rel=\"noreferrer\"><code>Hyperdrive<\/code><\/a>.<\/p>\n<h3>Option 2 Create runs from control plane<\/h3>\n<p>Remove the loop from your code, add the code like below (<a href=\"https:\/\/gist.github.com\/swanderz\/f5c0dc1aefc796d37f6bc3600f2ae3cd\" rel=\"noreferrer\">full data and control here<\/a>)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import argparse\nfrom pprint import pprint\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--alpha', type=float, default=0.5)\nargs = parser.parse_args()\nprint(&quot;all args:&quot;)\npprint(vars(args))\n\n# use the variable like this\nmodel = Ridge(args.alpha)\n<\/code><\/pre>\n<p>below is how to submit a single run using a script argument. To submit multiple runs, just use a loop in the control plane.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # Define hyperparameters\n\nlist_rcs = [ScriptRunConfig(\n    source_directory =  os.path.join(os.getcwd(), 'code'),\n    script = 'train.py',\n    arguments=['--alpha',a],\n    run_config = run_local_config) for a in alphas]\n\nlist_runs = [exp.submit(rc) for rc in list_rcs]\n\n<\/code><\/pre>\n<h3>Option 3 Hyperdrive (IMHO the recommended approach)<\/h3>\n<p>In this way you outsource the hyperparameter source to <code>Hyperdrive<\/code>. The UI will also report results exactly how you want them, and via the API you can easily download the best model.  Note you can't use this locally anymore and must use <code>AMLCompute<\/code>, but to me it is a worthwhile trade-off.<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters#configure-experiment\" rel=\"noreferrer\">This is a great overview<\/a>. Excerpt below (<a href=\"https:\/\/gist.github.com\/swanderz\/f5c0dc1aefc796d37f6bc3600f2ae3cd#file-hyperdrive-ipynb\" rel=\"noreferrer\">full code here<\/a>)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>param_sampling = GridParameterSampling( {\n        &quot;alpha&quot;: choice(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)\n    }\n)\n\nestimator = Estimator(\n    source_directory =  os.path.join(os.getcwd(), 'code'),\n    entry_script = 'train.py',\n    compute_target=cpu_cluster,\n    environment_definition=Environment.get(workspace=ws, name=&quot;AzureML-Tutorial&quot;)\n)\n\nhyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n                          hyperparameter_sampling=param_sampling, \n                          policy=None,\n                          primary_metric_name=&quot;rmse&quot;, \n                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                          max_total_runs=10,\n                          max_concurrent_runs=4)\n\nrun = exp.submit(hyperdrive_run_config)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/q1AhJ.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/q1AhJ.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1599436122230,
        "Answer_score":7.0,
        "Question_favorite_count":3.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63766714",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63458904,
        "Question_title":"Azure-ML Deployment does NOT see AzureML Environment (wrong version number)",
        "Question_body":"<p>I've followed the documentation pretty well as outlined <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-custom-docker-image\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<p>I've setup my azure machine learning environment the following way:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Workspace\n\n# Connect to the workspace\nws = Workspace.from_config()\n\nfrom azureml.core import Environment\nfrom azureml.core import ContainerRegistry\n\nmyenv = Environment(name = &quot;myenv&quot;)\n\nmyenv.inferencing_stack_version = &quot;latest&quot;  # This will install the inference specific apt packages.\n\n# Docker\nmyenv.docker.enabled = True\nmyenv.docker.base_image_registry.address = &quot;myazureregistry.azurecr.io&quot;\nmyenv.docker.base_image_registry.username = &quot;myusername&quot;\nmyenv.docker.base_image_registry.password = &quot;mypassword&quot;\nmyenv.docker.base_image = &quot;4fb3...&quot; \nmyenv.docker.arguments = None\n\n# Environment variable (I need python to look at folders \nmyenv.environment_variables = {&quot;PYTHONPATH&quot;:&quot;\/root&quot;}\n\n# python\nmyenv.python.user_managed_dependencies = True\nmyenv.python.interpreter_path = &quot;\/opt\/miniconda\/envs\/myenv\/bin\/python&quot; \n\nfrom azureml.core.conda_dependencies import CondaDependencies\nconda_dep = CondaDependencies()\nconda_dep.add_pip_package(&quot;azureml-defaults&quot;)\nmyenv.python.conda_dependencies=conda_dep\n\nmyenv.register(workspace=ws) # works!\n<\/code><\/pre>\n<p>I have a score.py file configured for inference (not relevant to the problem I'm having)...<\/p>\n<p>I then setup inference configuration<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.model import InferenceConfig\ninference_config = InferenceConfig(entry_script=&quot;score.py&quot;, environment=myenv)\n<\/code><\/pre>\n<p>I setup my compute cluster:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.compute import ComputeTarget, AksCompute\nfrom azureml.exceptions import ComputeTargetException\n\n# Choose a name for your cluster\naks_name = &quot;theclustername&quot; \n\n# Check to see if the cluster already exists\ntry:\n    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n    print('Found existing compute target')\nexcept ComputeTargetException:\n    print('Creating a new compute target...')\n    prov_config = AksCompute.provisioning_configuration(vm_size=&quot;Standard_NC6_Promo&quot;)\n\n    aks_target = ComputeTarget.create(workspace=ws, name=aks_name, provisioning_configuration=prov_config)\n\n    aks_target.wait_for_completion(show_output=True)\n\nfrom azureml.core.webservice import AksWebservice\n\n# Example\ngpu_aks_config = AksWebservice.deploy_configuration(autoscale_enabled=False,\n                                                    num_replicas=3,\n                                                    cpu_cores=4,\n                                                    memory_gb=10)\n<\/code><\/pre>\n<p>Everything succeeds; then I try and deploy the model for inference:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.model import Model\n\nmodel = Model(ws, name=&quot;thenameofmymodel&quot;)\n\n# Name of the web service that is deployed\naks_service_name = 'tryingtodeply'\n\n# Deploy the model\naks_service = Model.deploy(ws,\n                           aks_service_name,\n                           models=[model],\n                           inference_config=inference_config,\n                           deployment_config=gpu_aks_config,\n                           deployment_target=aks_target,\n                           overwrite=True)\n\naks_service.wait_for_deployment(show_output=True)\nprint(aks_service.state)\n<\/code><\/pre>\n<p>And it fails saying that it can't find the environment. More specifically, my environment version is <strong>version 11<\/strong>, but it keeps trying to find an environment with a version number that is 1 higher (i.e., <strong>version 12<\/strong>) than the current environment:<\/p>\n<pre><code>FailedERROR - Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 0f03a025-3407-4dc1-9922-a53cc27267d4\nMore information can be found here: \nError:\n{\n  &quot;code&quot;: &quot;BadRequest&quot;,\n  &quot;statusCode&quot;: 400,\n  &quot;message&quot;: &quot;The request is invalid&quot;,\n  &quot;details&quot;: [\n    {\n      &quot;code&quot;: &quot;EnvironmentDetailsFetchFailedUserError&quot;,\n      &quot;message&quot;: &quot;Failed to fetch details for Environment with Name: myenv Version: 12.&quot;\n    }\n  ]\n}\n\n<\/code><\/pre>\n<p>I have tried to manually edit the environment JSON to match the version that azureml is trying to fetch, but nothing works. Can anyone see anything wrong with this code?<\/p>\n<h1>Update<\/h1>\n<p>Changing the name of the environment (e.g., <code>my_inference_env<\/code>) and passing it to <code>InferenceConfig<\/code> seems to be on the right track. However, the error now changes to the following<\/p>\n<pre><code>Running..........\nFailed\nERROR - Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: f0dfc13b-6fb6-494b-91a7-de42b9384692\nMore information can be found here: https:\/\/some_long_http_address_that_leads_to_nothing\nError:\n{\n  &quot;code&quot;: &quot;DeploymentFailed&quot;,\n  &quot;statusCode&quot;: 404,\n  &quot;message&quot;: &quot;Deployment not found&quot;\n}\n<\/code><\/pre>\n<h1>Solution<\/h1>\n<p>The answer from Anders below is <strong>indeed correct<\/strong> regarding the use of azure ML environments. However, the last error I was getting was because I was setting the <em>container image<\/em> using the digest value (a sha) and NOT the image name and tag (e.g., <code>imagename:tag<\/code>). Note the line of code in the first block:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>myenv.docker.base_image = &quot;4fb3...&quot; \n<\/code><\/pre>\n<p>I reference the digest value, but it should be changed to<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>myenv.docker.base_image = &quot;imagename:tag&quot;\n<\/code><\/pre>\n<p>Once I made that change, the deployment succeeded! :)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_time":1597699827673,
        "Question_score":3,
        "Question_tags":"azure|azure-aks|azure-sdk-python|azure-machine-learning-service",
        "Question_view_count":1768,
        "Owner_creation_time":1432406490590,
        "Owner_last_access_time":1663530034717,
        "Owner_location":"Milwaukee, WI",
        "Owner_reputation":381,
        "Owner_up_votes":48,
        "Owner_down_votes":4,
        "Owner_views":62,
        "Question_last_edit_time":1599771558393,
        "Answer_body":"<p>One concept that took me a while to get was the bifurcation of registering and using an Azure ML <code>Environment<\/code>. If you have already registered your env, <code>myenv<\/code>, and none of the details of the your environment have changed, there is no need re-register it with <code>myenv.register()<\/code>. You can simply get the already register env using <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.environment.environment?view=azure-ml-py#get-workspace--name--version-none-\" rel=\"nofollow noreferrer\"><code>Environment.get()<\/code><\/a> like so:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>myenv = Environment.get(ws, name='myenv', version=11)\n<\/code><\/pre>\n<p>My recommendation would be to name your environment something new: like <code>&quot;model_scoring_env&quot;<\/code>. Register it once, then pass it to the <code>InferenceConfig<\/code>.<\/p>",
        "Answer_comment_count":9.0,
        "Answer_creation_time":1597702121697,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63458904",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58906453,
        "Question_title":"H2O Download CSV in Azure Machine Learning",
        "Question_body":"<p>I am trying to build a ML model in Azure Machine Learning using H2o AutoML and could successfully create the model and do prediction.\nWhat I am struggling with is to download the result as csv (ideally to my local PC).<\/p>\n\n<p>The code I used is :<\/p>\n\n<pre><code>#Predict on the whole dataset\npred = best_model.predict(data)\ndata_pred = data.cbind(pred)\n\n# Download as csv\nh2o.download_csv(data_pred,'data_pred .csv')\n<\/code><\/pre>\n\n<p>The above code runs without any error &amp; shows <strong><em>'\/mnt\/azmnt\/code\/Users\/SA\/data_pred.csv'<\/em><\/strong> as the result message. I assume the csv has been created succesfully.<\/p>\n\n<p>But I don't know where to locate it.\nI searched in AzureML datasets but there is none. Appreciate if someone can help me with this. Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1574035772023,
        "Question_score":0,
        "Question_tags":"python|download|h2o|automl|azure-machine-learning-service",
        "Question_view_count":60,
        "Owner_creation_time":1444403737137,
        "Owner_last_access_time":1663734909200,
        "Owner_location":null,
        "Owner_reputation":167,
        "Owner_up_votes":264,
        "Owner_down_votes":0,
        "Owner_views":69,
        "Question_last_edit_time":null,
        "Answer_body":"<p>H2O Documentation says that:<\/p>\n\n<p><code>h2o.h2o.download_csv(data, filename)<\/code><\/p>\n\n<p><code>data : H2OFrame<\/code> An H2OFrame object to be downloaded.<\/p>\n\n<p><code>filename : str<\/code> A string indicating the name that the CSV file should be should be saved to.<\/p>\n\n<p>Additionally, as you have written in your question <code>\/mnt\/azmnt\/code\/Users\/SA\/data_pred.csv'<\/code> should be the path.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1574036423173,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58906453",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42766263,
        "Question_title":"How to Find Azure ML Experiment based on Deployed Web Service",
        "Question_body":"<p>I have a list of ML experiments which I have created in Azure Machine Learning Studio.  I have deployed them as web services (the new version, not classic).  <\/p>\n\n<p>How can I go into Azure Machine Learning Web Services, click on a web service (which was deployed from an experiment), then navigate back to the experiment \/ predictive model which feeds it?<\/p>\n\n<p>The only link I can find between the two is by updating the web service from the predictive experiment, which then confirms what the web service is. I can see that the \"ExperimentId\" is a GUID in the URL when in the experiment and the web service, so hopefully this is possible.<\/p>\n\n<p>My reasoning is that relying on matching naming conventions, etc., to select the appropriate model to update is subject to human error.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1489415750577,
        "Question_score":7,
        "Question_tags":"web-services|azure|azure-machine-learning-studio",
        "Question_view_count":224,
        "Owner_creation_time":1377703476330,
        "Owner_last_access_time":1626302147190,
        "Owner_location":"Bristol, United Kingdom",
        "Owner_reputation":592,
        "Owner_up_votes":18,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The <em>new<\/em> web service does not store any information about the experiment or workspace that was deployed (not all <em>new<\/em> web services are deployed from an experiment).<\/p>\n\n<p>Here are the options available to track the relationship between the experiment and a <em>new<\/em> web service.<\/p>\n\n<h2>last deployment<\/h2>\n\n<p>However, the experiment keeps track of the <strong>last<\/strong> <em>new<\/em> web service that was deployed from the experiment. each deployment to a <em>new<\/em> web service overwrites this value.<\/p>\n\n<p>The value is stored in the experiment graph. One way to get the graph is to use the powershell module <a href=\"http:\/\/aka.ms\/amlps\" rel=\"nofollow noreferrer\">amlps<\/a><\/p>\n\n<p><code>Export-AmlExperimentGraph -ExperimentId &lt;Experiment Id&gt; -OutputFile e.json<\/code><\/p>\n\n<p><strong>e.json<\/strong><\/p>\n\n<pre><code>{\n\"ExperimentId\":\"&lt;Experiment Id&gt;\",\n\/\/ . . .\n\"WebService\":{\n\/\/ . . .\n\"ArmWebServiceId\":\"&lt;Arm Id&gt;\"\n},\n\/\/ . . . \n}\n<\/code><\/pre>\n\n<h2>azure resource tags<\/h2>\n\n<p>The tags feature for Azure resources is supported by the <em>new<\/em> web services. Setting a <code>tag<\/code> on the web service programmatically, with powershell or via the azure portal UX can be used to store a reference to the experiment on the <em>new<\/em> web service.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1490283526690,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42766263",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":42010405,
        "Question_title":"The way to pass input for azure machine experiment from app ( for example console app )",
        "Question_body":"<p>I'm trying to do some kind of web job application that can run for period time and make prediction on azure machine learning studio. After that i want get the result of this experiment and do something with that in my console application. What is the best way to do this in azure with machine learning or maybe some similiar stuff to prediction data from data series ? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1486062508683,
        "Question_score":0,
        "Question_tags":"azure|prediction|azure-machine-learning-studio",
        "Question_view_count":62,
        "Owner_creation_time":1432141466930,
        "Owner_last_access_time":1591285402750,
        "Owner_location":null,
        "Owner_reputation":327,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":78,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You can try using Azure Data Factory to create a Machine Learning pipeline or use Azure ML Studio's Predictive Web Services.<\/p>\n\n<ol>\n<li><p>With Azure Data Factory\nFollow <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/data-factory\/data-factory-azure-ml-batch-execution-activity\" rel=\"nofollow noreferrer\">this link<\/a> for details. Azure Data Factory implementations would seem difficult at first but they do work great with Azure ML experiments. <\/p>\n\n<p>Azure Data Factory can run your ML Experiment on a schedule or one-off at a specified time (I guess you can set only for UTC Timezone right now) and monitor it through a dashboard (which is pretty cool).<\/p>\n\n<p>As an example you can look @ <a href=\"https:\/\/github.com\/Microsoft\/azure-docs\/blob\/master\/articles\/data-factory\/data-factory-azure-ml-batch-execution-activity.md\" rel=\"nofollow noreferrer\">ML Batch Execution<\/a>. I used this in one of our implementations (we do have latency issues, but trying to solve that).<\/p><\/li>\n<li><p>If you directly want to use the experiment in your console (assuming it is a web application), use create a Predictive Web service out of your ML Experiment, details <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-walkthrough-5-publish-web-service\" rel=\"nofollow noreferrer\">here<\/a><\/p><\/li>\n<\/ol>\n\n<p>I couldn't exactly understand your use case so I posted two alternatives that should help you. Hope this might lead you to a better solution\/approach.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1486537080117,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1486537417793,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/42010405",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57660058,
        "Question_title":"Azure ML SDK DataReference - File Pattern - MANY files",
        "Question_body":"<p>I\u2019m building out a pipeline that should execute and train fairly frequently.  I\u2019m following this: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-your-first-pipeline\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-your-first-pipeline<\/a> <\/p>\n\n<p>Anyways, I\u2019ve got a stream analytics job dumping telemetry into .json files on blob storage (soon to be adls gen2).  Anyways, I want to find all .json files and use all of those files to train with.  I could possibly use just new .json files as well (interesting option honestly).<\/p>\n\n<p>Currently I just have the store mounted to a data lake and available; and it just iterates the mount for the data files and loads them up.<\/p>\n\n<ol>\n<li>How can I use data references for this instead?<\/li>\n<li>What does data references do for me that mounting time stamped data does not?\na.  From an audit perspective, I have version control, execution time and time stamped read only data.  Albeit, doing a replay on this would require additional coding, but is do-able.<\/li>\n<\/ol>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1566830274697,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":296,
        "Owner_creation_time":1384802035143,
        "Owner_last_access_time":1663094482000,
        "Owner_location":"Miami Beach, FL",
        "Owner_reputation":2682,
        "Owner_up_votes":75,
        "Owner_down_votes":4,
        "Owner_views":1006,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You could pass pointer to folder as an input parameter for the pipeline, and then your step can mount the folder to iterate over the json files.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1566854588780,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57660058",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67533091,
        "Question_title":"where are registered models in azure machine learning",
        "Question_body":"<p>I try to use azuremlsdk to deploy a locally trained model (a perfectly valid use case AFIK). I follow <a href=\"https:\/\/cran.r-project.org\/web\/packages\/azuremlsdk\/vignettes\/train-and-deploy-first-model.html\" rel=\"nofollow noreferrer\">this<\/a> and managed to create a ML workspace and register a &quot;model&quot; like so:<\/p>\n<pre><code>library(azuremlsdk)\n\ninteractive_auth &lt;- interactive_login_authentication(tenant_id=&quot;xxx&quot;)\nws &lt;- get_workspace(\n        name = &quot;xxx&quot;, \n        subscription_id = &quot;xxx&quot;, \n        resource_group =&quot;xxx&quot;, \n        auth = interactive_auth\n)\n\nadd &lt;- function(a, b) {\n    return(a + b)\n}\n\nadd(1,2)\n\nsaveRDS(add, file = &quot;D:\/add.rds&quot;)\n\nmodel &lt;- register_model(\n    ws, \n    model_path = &quot;D:\/add.rds&quot;, \n    model_name = &quot;add_model&quot;,\n    description = &quot;An amazing model&quot;\n)\n<\/code><\/pre>\n<p>This seemed to work fine, as I get some nice log messages telling me that the model was registered. For my sanity, I wonder where can I find this registered (&quot;materialised&quot;) model\/object\/function in the Azure UI please?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1620989367110,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-service|azuremlsdk",
        "Question_view_count":41,
        "Owner_creation_time":1267440784443,
        "Owner_last_access_time":1664045779313,
        "Owner_location":"Somewhere",
        "Owner_reputation":15705,
        "Owner_up_votes":2171,
        "Owner_down_votes":91,
        "Owner_views":2150,
        "Question_last_edit_time":null,
        "Answer_body":"<p>On ml.azure.com, there is a &quot;Models&quot; option on the left-hand blade.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Y7cZe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Y7cZe.png\" alt=\"UI Sidebar\" \/><\/a><\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1621001633740,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67533091",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71169178,
        "Question_title":"azureml.contrib.dataset vs azureml.data",
        "Question_body":"<p>Looks like AzureML Python SDK has two Dataset packages exposed over API:<\/p>\n<ol>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.contrib.dataset<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-contrib-dataset\/azureml.contrib.dataset.tabulardataset?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.data<\/a><\/li>\n<\/ol>\n<p>The documentation doesn't clearly mention the difference or when should we use which one? But, it creates confusion for sure. For example, There are two Tabular Dataset classes exposed over API. And they have different APIs for different functions:<\/p>\n<ol>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.data.TabularDataset<\/a><\/li>\n<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-contrib-dataset\/azureml.contrib.dataset.tabulardataset?view=azure-ml-py\" rel=\"nofollow noreferrer\">azureml.contrib.dataset.TabularDataset<\/a><\/li>\n<\/ol>\n<p>Any suggestion about when should I use which package will be helpful.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1645165311677,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":24,
        "Owner_creation_time":1280505139753,
        "Owner_last_access_time":1663935737867,
        "Owner_location":"Bangalore, India",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Question_last_edit_time":1645167982083,
        "Answer_body":"<p>As per the <a href=\"https:\/\/pypi.org\/project\/azureml-contrib-dataset\/\" rel=\"nofollow noreferrer\">PyPi<\/a>, <code>azureml.contrib.dataset<\/code> has been deprecated and <code>azureml.data<\/code> should be used instead:<\/p>\n<blockquote>\n<p>The azureml-contrib-dataset package has been deprecated and might not\nreceive future updates and removed from the distribution altogether.\nPlease use azureml-core instead.<\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1645168074897,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71169178",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59653641,
        "Question_title":"Missing module tensorflow on iPython azure machine learning (Classic)",
        "Question_body":"<p>Yesterday I have install tensorflow module from iPython notebook from Azure machine learning studio (classic) version. The import worked well after installing the module using (!pip install tensorflow). But today when tried to import this module got this \"missing module\" error and when I tried reinstalling the module it works well. Am I missing anything here? \nDo I need to install the module each and everyday, before using it? Can someone please explain?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/rI7hE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rI7hE.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1578516766930,
        "Question_score":0,
        "Question_tags":"python|python-3.x|azure|tensorflow|azure-machine-learning-studio",
        "Question_view_count":140,
        "Owner_creation_time":1500744375327,
        "Owner_last_access_time":1660004233300,
        "Owner_location":null,
        "Owner_reputation":255,
        "Owner_up_votes":20,
        "Owner_down_votes":0,
        "Owner_views":130,
        "Question_last_edit_time":1578577931443,
        "Answer_body":"<p>For Azure Machine Learning (Classic) Studio notebooks, you need to install Tensorflow. Furthermore, the notebook server session times out after a period of inactivity, hence, you need to re-install Tensorflow once the server shuts down or after starting a new session. Thanks.<\/p>\n\n<p>Here are some references:<\/p>\n\n<p><a href=\"https:\/\/notebooks.azure.com\/help\/jupyter-notebooks\/timeouts\" rel=\"nofollow noreferrer\">https:\/\/notebooks.azure.com\/help\/jupyter-notebooks\/timeouts<\/a><\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/notebooks\/install-packages-jupyter-notebook\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/notebooks\/install-packages-jupyter-notebook<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1578608056697,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59653641",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":62815426,
        "Question_title":"Azure ML: How to train a model on multiple instances",
        "Question_body":"<p>I have a AML compute cluster with the min &amp; max nodes set to 2. When I execute a pipeline, I expect the cluster to run the training on both instances in parallel. But the cluster status reports that only one node is busy and the other is idle.<\/p>\n<p>Here's my code to submit the pipeline, as you can see, I'm resolving the cluster name and passing that to my Step1, thats training a model on Keras.<\/p>\n<pre><code>aml_compute = AmlCompute(ws, &quot;cluster-name&quot;)\nstep1 = PythonScriptStep(name=&quot;train_step&quot;,\n                         script_name=&quot;Train.py&quot;, \n                         arguments=[&quot;--sourceDir&quot;, os.path.realpath(source_directory) ],\n                         compute_target=aml_compute, \n                         source_directory=source_directory,\n                         runconfig=run_config,\n                         allow_reuse=False)\npipeline_run = Experiment(ws, 'MyExperiment').submit(pipeline1, regenerate_outputs=False)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_time":1594299602573,
        "Question_score":1,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":623,
        "Owner_creation_time":1330016065410,
        "Owner_last_access_time":1662160983830,
        "Owner_location":null,
        "Owner_reputation":1704,
        "Owner_up_votes":61,
        "Owner_down_votes":7,
        "Owner_views":232,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Each python script step runs on a single node even if you allocate multiple nodes in your cluster. I'm not sure whether training on different instances is possible off-the-shelf in AML, but there's definitely the possibility to use that single node more effectively (looking into using all your cores, etc.)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1594303708130,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62815426",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30133814,
        "Question_title":"How to build an image classification dataset in Azure?",
        "Question_body":"<p>I've a set of images that have a single classification of OPEN (they show something that is open).  I couldn't find a way to directly add a status of open to the image reader dataset so I have FULL OUTER JOIN-ed a single ENTER DATA to an IMAGE READER as per the following.  This seems like a hack, does anyone know the \"right\" way to do this?\n<img src=\"https:\/\/i.stack.imgur.com\/Kt1Rv.png\" alt=\"enter image description here\"><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1431124435077,
        "Question_score":16,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":1403,
        "Owner_creation_time":1322863592970,
        "Owner_last_access_time":1664017479013,
        "Owner_location":null,
        "Owner_reputation":373,
        "Owner_up_votes":119,
        "Owner_down_votes":4,
        "Owner_views":34,
        "Question_last_edit_time":1446192398650,
        "Answer_body":"<p>Another way is to have R or python code that replicates the status for each image and then use add-columns. I think R\/Python code to just replicate the status for each image may be easier and faster than outer join.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1431886381620,
        "Answer_score":5.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30133814",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":44881303,
        "Question_title":"Best way to import MongoDB data in Azure Machine Learning",
        "Question_body":"<p>I have a MongoDB database (the Bitnami one) hosted on Azure. I want to import the data there to use it in my Azure Machine Learning experiment.<\/p>\n\n<p>Currently, I am exporting the data to <strong>.csv<\/strong> using <strong>mongoexport<\/strong> and then copy\/pasting it to the <strong>\"Enter Manually Data\"<\/strong> module. This is fine for small amounts of data but I would prefer to have a more robust technique for larger databases.<\/p>\n\n<p>I also thought about using the <strong>\"Import Data\"<\/strong> module from http url along with the <strong>http port (28017) of my mongodb<\/strong> instance but read this was not the recommended use of the http mongodb feature.<\/p>\n\n<p>Finally, I have installed <strong>cosmosDB<\/strong> instead of my bitnami MongoDB and it worked fine but this thing <strong>costs an arm<\/strong> when used with sitecore (it reaches around 100\u20ac per day) and we can't afford it so I switched back to by Mongo.<\/p>\n\n<p>So is there a better way to export data from Mongo to Azure ML ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1499071780183,
        "Question_score":1,
        "Question_tags":"mongodb|azure|azure-machine-learning-studio",
        "Question_view_count":724,
        "Owner_creation_time":1441267698017,
        "Owner_last_access_time":1663761804133,
        "Owner_location":null,
        "Owner_reputation":781,
        "Owner_up_votes":516,
        "Owner_down_votes":0,
        "Owner_views":97,
        "Question_last_edit_time":null,
        "Answer_body":"<p>one way is to use a Python code block in AzureML, something like this:<\/p>\n\n<pre><code>import pandas as p\nimport pymongo as m\n\ndef azureml_main():\n    c = m.MongoClient(host='host_IP')\n    a = p.DataFrame(c.database_names())\n    return a\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1504686538047,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/44881303",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63891547,
        "Question_title":"How to connect AMLS to ADLS Gen 2?",
        "Question_body":"<p>I would like to register a dataset from ADLS Gen2 in my Azure Machine Learning workspace (<code>azureml-core==1.12.0<\/code>). Given that service principal information is not required in the Python SDK <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore.datastore?view=azure-ml-py#register-azure-data-lake-gen2-workspace--datastore-name--filesystem--account-name--tenant-id-none--client-id-none--client-secret-none--resource-url-none--authority-url-none--protocol-none--endpoint-none--overwrite-false-\" rel=\"noreferrer\">documentation<\/a> for <code>.register_azure_data_lake_gen2()<\/code>, I successfully used the following code to register ADLS gen2 as a datastore:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Datastore\n\nadlsgen2_datastore_name = os.environ['adlsgen2_datastore_name']\naccount_name=os.environ['account_name'] # ADLS Gen2 account name\nfile_system=os.environ['filesystem']\n\nadlsgen2_datastore = Datastore.register_azure_data_lake_gen2(\n    workspace=ws,\n    datastore_name=adlsgen2_datastore_name,\n    account_name=account_name, \n    filesystem=file_system\n)\n<\/code><\/pre>\n<p>However, when I try to register a dataset, using<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Dataset\nadls_ds = Datastore.get(ws, datastore_name=adlsgen2_datastore_name)\ndata = Dataset.Tabular.from_delimited_files((adls_ds, 'folder\/data.csv'))\n<\/code><\/pre>\n<p>I get an error<\/p>\n<blockquote>\n<p>Cannot load any data from the specified path. Make sure the path is accessible and contains data.\n<code>ScriptExecutionException<\/code> was caused by <code>StreamAccessException<\/code>.\nStreamAccessException was caused by AuthenticationException.\n<code>'AdlsGen2-ReadHeaders'<\/code> for '[REDACTED]' on storage failed with status code 'Forbidden' (This request is not authorized to perform this operation using this permission.), client request ID &lt;CLIENT_REQUEST_ID&gt;, request ID &lt;REQUEST_ID&gt;. Error message: [REDACTED]\n| session_id=&lt;SESSION_ID&gt;<\/p>\n<\/blockquote>\n<p>Do I need the to enable the service principal to get this to work? Using the ML Studio UI, it appears that the service principal is required even to register the datastore.<\/p>\n<p>Another issue I noticed is that AMLS is trying to access the dataset here:\n<code>https:\/\/adls_gen2_account_name.**dfs**.core.windows.net\/container\/folder\/data.csv<\/code> whereas the actual URI in ADLS Gen2 is: <code>https:\/\/adls_gen2_account_name.**blob**.core.windows.net\/container\/folder\/data.csv<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1600115991930,
        "Question_score":7,
        "Question_tags":"python|azure-machine-learning-service|azure-data-lake-gen2",
        "Question_view_count":3331,
        "Owner_creation_time":1589738451347,
        "Owner_last_access_time":1656358607687,
        "Owner_location":null,
        "Owner_reputation":179,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Question_last_edit_time":1600160631357,
        "Answer_body":"<p>According to this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#azure-data-lake-storage-generation-2\" rel=\"noreferrer\">documentation<\/a>,you need to enable the service principal.<\/p>\n<p>1.you need to register your application and grant the service principal with <strong>Storage Blob Data Reader access<\/strong>.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/FZl8O.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FZl8O.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>2.try this code:<\/p>\n<pre><code>adlsgen2_datastore = Datastore.register_azure_data_lake_gen2(workspace=ws,\n                                                             datastore_name=adlsgen2_datastore_name,\n                                                             account_name=account_name,\n                                                             filesystem=file_system,\n                                                             tenant_id=tenant_id,\n                                                             client_id=client_id,\n                                                             client_secret=client_secret\n                                                             )\n\nadls_ds = Datastore.get(ws, datastore_name=adlsgen2_datastore_name)\ndataset = Dataset.Tabular.from_delimited_files((adls_ds,'sample.csv'))\nprint(dataset.to_pandas_dataframe())\n<\/code><\/pre>\n<p><strong>Result:<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/50mit.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/50mit.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1600155716360,
        "Answer_score":9.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1600166834147,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63891547",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":52294404,
        "Question_title":"R Server on Azure",
        "Question_body":"<p>I need to execute R code as webservice, so i tried MLS and it works ok. \nThe problem is that the packages are too old, and i need functions that are not implemented on old packages. \nI asked microsoft support about it, and they have no data up upgrade it, and the new packages require a upgrade of it.<\/p>\n\n<p>How can i do that using other resources, like webapi instead of MLS?\nAll solutions i found requires R installed on machine, wich is a problem for create an azure webapp, function, or api.\nI need an endpoint for forecast on-demand.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1536752847560,
        "Question_score":2,
        "Question_tags":"r|azure-web-app-service|azure-functions|azure-machine-learning-studio",
        "Question_view_count":327,
        "Owner_creation_time":1515518171123,
        "Owner_last_access_time":1657119408507,
        "Owner_location":null,
        "Owner_reputation":1108,
        "Owner_up_votes":33,
        "Owner_down_votes":2,
        "Owner_views":183,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I found one way to execute R on Azure functions.\nthe solutions is copy R-Portable in\n<a href=\"https:\/\/sourceforge.net\/projects\/rportable\/\" rel=\"nofollow noreferrer\">https:\/\/sourceforge.net\/projects\/rportable\/<\/a>\nunzip it using powershell and create a process on function code. In my case i used the code:<\/p>\n\n<pre><code>System.Diagnostics.Process process = new System.Diagnostics.Process();\n            process.StartInfo.WorkingDirectory = @\"D:\\home\\site\\tools\\R-Portable\\App\\R-Portable\\bin\\\";\n            process.StartInfo.FileName = @\"D:\\home\\site\\tools\\R-Portable\\App\\R-Portable\\bin\\Rscript.exe\";\n            process.StartInfo.Arguments = \"-e \\\"print('Hello world')\\\"\";\n            process.StartInfo.UseShellExecute = false;\n            process.StartInfo.RedirectStandardOutput = true;\n            process.StartInfo.RedirectStandardError = true;\n            process.Start();\n            string outputt = process.StandardOutput.ReadToEnd();\n            string err = process.StandardError.ReadToEnd();\n            process.WaitForExit();\n<\/code><\/pre>\n\n<p>On your script you can access csv files or write, and after on function read and return that file.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1537264424307,
        "Answer_score":0.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/52294404",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72210450,
        "Question_title":"Is there any way to create or delete workspaces in AML studio using powershell?",
        "Question_body":"<p>I am working on a prediction model and am about to use the azure machine learning studio resources. The main operation is to create a workspace on azure ML studio through Powershell. I would like to operate my workspace through the command line. Is there any way to develop and operate the ML Studio workspace through Powershell?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1652332894457,
        "Question_score":0,
        "Question_tags":"azure|powershell|azure-machine-learning-studio",
        "Question_view_count":104,
        "Owner_creation_time":1652331444420,
        "Owner_last_access_time":1652336195337,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":null,
        "Answer_body":"<p>According to the requirements, there is no procedure developed to create\/delete workspaces through PowerShell in machine learning studio. For reference of creation of workspaces, you can check the below link and the point to be noted is we can create\/delete workspaces using <em><strong>Az<\/strong><\/em><\/p>\n<p>Here is the table link to check PowerShell support table<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/previous-versions\/azure\/machine-learning\/classic\/powershell-module\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/previous-versions\/azure\/machine-learning\/classic\/powershell-module<\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/PGfhb.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PGfhb.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1652333522490,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72210450",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37943572,
        "Question_title":"Azure ML Web Service for R models shows unpredictable",
        "Question_body":"<p>When publishing an Azure ML Web Service and preloading data in our R model we see inconsistent performance. First calls are slow but following calls are fast, waiting a bit (couple of minutes) for the next call ends up showing longer response times.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1466509663807,
        "Question_score":0,
        "Question_tags":"azure-web-app-service|azure-machine-learning-studio",
        "Question_view_count":69,
        "Owner_creation_time":1466503688920,
        "Owner_last_access_time":1467292958780,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":64,
        "Question_last_edit_time":1466610116060,
        "Answer_body":"<p>The way Azure ML Web Services work in the background means that instances hosting the models are provisioned and moved in a very dynamic multi-tenant environment. Caching data (warming up) can be helpful but this doesn't mean all subsequent calls will land on the same instance with the same data available in the cache. <\/p>\n\n<p>For models that need a lot of in-memory data there is a limit to what the Azure ML Web Services hosting layer can offer at this point. Microsoft R server could be an alternative to host these big ML workloads and looking at Service Fabric to scale <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1466599962023,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37943572",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61279914,
        "Question_title":"AzureML: ResolvePackageNotFound azureml-dataprep",
        "Question_body":"<p>I've got a basic ScriptStep in my AML Pipeline and it's just trying to read an attached dataset. When i execute this simple example, the pipeline fails with the following in the driver log:<\/p>\n\n<blockquote>\n  <p>ImportError: azureml-dataprep is not installed. Dataset cannot be used\n  without azureml-dataprep. Please make sure\n  azureml-dataprep[fuse,pandas] is installed by specifying it in the\n  conda dependencies. pandas is optional and should be only installed if\n  you intend to create a pandas DataFrame from the dataset.<\/p>\n<\/blockquote>\n\n<p>I then modified my step to include the conda package but then the driver fails with \"ResolvePackageNotFound: azureml-dataprep\". The entire log file can be accessed <a href=\"https:\/\/www.dropbox.com\/s\/372ht6jkvzu9loo\/conda.err.txt?dl=0\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n\n<pre><code># create a new runconfig object\nrun_config = RunConfiguration()\nrun_config.environment.docker.enabled = True\nrun_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\nrun_config.environment.python.user_managed_dependencies = False\nrun_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['azureml-dataprep[pandas,fuse]'])\n\nsource_directory = '.\/read-step'\nprint('Source directory for the step is {}.'.format(os.path.realpath(source_directory)))\nstep2 = PythonScriptStep(name=\"read_step\",\n                         script_name=\"Read.py\", \n                         arguments=[\"--dataFilePath\", dataset.as_named_input('local_ds').as_mount() ],\n                         compute_target=aml_compute, \n                         source_directory=source_directory,\n                         runconfig=run_config,\n                         allow_reuse=False)\n<\/code><\/pre>\n\n<p>I'm out of ideas, would deeply appreciate any help here!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1587154334353,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":1244,
        "Owner_creation_time":1330016065410,
        "Owner_last_access_time":1662160983830,
        "Owner_location":null,
        "Owner_reputation":1704,
        "Owner_up_votes":61,
        "Owner_down_votes":7,
        "Owner_views":232,
        "Question_last_edit_time":1591825691630,
        "Answer_body":"<p>The <code>azureml-sdk<\/code> isn't available on conda, you need to install it with <code>pip<\/code>.<\/p>\n\n<pre><code>myenv = Environment(name=\"myenv\")\nconda_dep = CondaDependencies().add_pip_package(\"azureml-dataprep[pandas,fuse]\")\nmyenv.python.conda_dependencies=conda_dep\nrun_config.environment = myenv\n<\/code><\/pre>\n\n<p>For more information, about this error, the logs tab has a log named <code>20_image_build_log.txt<\/code> which Docker build logs. It contains the error where <code>conda<\/code> failed to failed to find <code>azureml-dataprep<\/code><\/p>\n\n<p>EDIT:<\/p>\n\n<p>Soon, you won't have to specify this dependency anymore. the Azure Data4ML team says <code>azureml-dataprep[pandas,fuse]<\/code> is getting added as a dependency for <code>azureml-defaults<\/code> which is automatically installed on all images. <\/p>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1587162956780,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1587416360077,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61279914",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73318372,
        "Question_title":"several dependency errors causing in Azure AutoML while running model",
        "Question_body":"<p>I am trying to work on different models on a small piece of ML project which needs to work on azure platform and get the score.py with all the values. It is getting not a single library issue, but getting multiple <strong>Module errors<\/strong> and <strong>Attribute errors<\/strong>. I am using latest SDK version only, but I am not sure, where I am going side path.<\/p>\n<p>Any previous observations on this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1660210046063,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":29,
        "Owner_creation_time":1651094469217,
        "Owner_last_access_time":1660762207473,
        "Owner_location":null,
        "Owner_reputation":41,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The compatibility break is there for the newer version of the packages based on the current version of <strong>SDK<\/strong>. If the current SDK version is <strong>1.13.0<\/strong> and above, previous versions of packages are not in working stage. The compatibility issue is raising because of support of packages from SDK for different versions. It differs from version-to-version package support from <strong>SDK<\/strong>.<\/p>\n<p>Because of this we are getting Module not found,  <code>ImportError and AttributeError<\/code>.<\/p>\n<p>This solution depends on the AutoML SDK training version.<\/p>\n<ul>\n<li>If you are using 1.13.0 above version of SDK, update the versions of pandas to 0.25.1 and scikit-learn to 0.22.1<\/li>\n<\/ul>\n<p>Using the following command in  <code>BASH<\/code>  to upgrade the versions.<\/p>\n<pre><code>pip install \u2013upgrade pandas==0.25.1\n\npip install \u2013upgrade sickit-learn==0.22.1\n\n<\/code><\/pre>\n<p>The generic syntax for upgrading is:<\/p>\n<pre><code>pip install \u2013upgrade package_name==version\n\n<\/code><\/pre>\n<ul>\n<li>If the error occurs in AutoML Configuration file, then need to upgrade that also.<\/li>\n<li>But it is suggestable to uninstall and reinstall  <code>AutoMLConfig<\/code>.<\/li>\n<\/ul>\n<pre><code>pip uninstall azureml-train automl\n\n<\/code><\/pre>\n<p>Then reinstall using the below code,<\/p>\n<pre><code>pip install azureml-train automl\n\n<\/code><\/pre>\n<p>If you are using windows operating system, then install  <a href=\"https:\/\/docs.conda.io\/en\/latest\/miniconda.html\" rel=\"nofollow noreferrer\">Miniconda<\/a>.<\/p>\n<p>If you are a linux user, then using sudo or conda syntaxes for the same operation.<\/p>\n<p>Some of the advanced libraries of computer vision supportive like TensorFlow will be installed by default. Then we need to install them from dependencies.<\/p>\n<blockquote>\n<pre><code>azureml.core.runconfig import RunConfiguration from\nazureml.core.conda_dependencies import CondaDependencies run_config =\nRunConfiguration() run_config.environment.python.conda_dependencies =\nCondaDependencies.create(conda_packages=['tensorflow==1.12.0']) \n\n<\/code><\/pre>\n<\/blockquote>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-auto-ml#tensorflow\" rel=\"nofollow noreferrer\">Documentation<\/a>  credit to @Larry Franks.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1660213117330,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73318372",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":57500954,
        "Question_title":"Automatically delete files in storage",
        "Question_body":"<p>So I've noticed that whenever I do a machine learning train\/retrain (<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/retrain-machine-learning-model\" rel=\"nofollow noreferrer\">from here<\/a>), it generates a lot of files in my Azure blob storage as shown here<\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/QN08i.png\" alt=\"Screenshot\"><\/p>\n\n<p>I wanted to ask if it was possible to automatically delete all these files or prevent them from ever being generated?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1565811221207,
        "Question_score":1,
        "Question_tags":"azure|azure-storage|azure-machine-learning-studio",
        "Question_view_count":2077,
        "Owner_creation_time":1526863814910,
        "Owner_last_access_time":1599796576180,
        "Owner_location":null,
        "Owner_reputation":45,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Question_last_edit_time":1565832393773,
        "Answer_body":"<p>For automatically delete all these files in blob storage, you can use the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/storage-lifecycle-management-concepts#azure-portal-list-view\" rel=\"nofollow noreferrer\">Lifecycle Management<\/a> of blob storage.<\/p>\n<p>It's easy to set up a rule and filter, after the rule is set up, all the files will be deleted as per the rule you defined.<\/p>\n<p>Simple steps:<\/p>\n<p>1.Nav to azure portal -&gt; your storage account -&gt; Blob services -&gt; Lifecycle Management, then click &quot;Add rule&quot;.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/n2Wne.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/n2Wne.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>2.In the &quot;Action set&quot; tab, select Delete blob and fill in the textbox; Then in &quot;Filter set&quot; tab, select a path.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/a2cdQ.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/a2cdQ.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>For more details\/instructions, please follow this <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/storage-lifecycle-management-concepts#azure-portal-list-view\" rel=\"nofollow noreferrer\">article<\/a>.<\/p>\n<p>Also note that the rule runs once per day, and for the first time, it may take 24 hours to take effect.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1565832229083,
        "Answer_score":4.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1592644375060,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57500954",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":53908529,
        "Question_title":"How to fix ModuleNotFoundError in azureml-sdk when installed inside conda environment",
        "Question_body":"<p>I'm setting up a conda environment on Windows 10 Pro x64 using Miniconda 4.5.12 and have done a pip install of azureml-sdk inside the environment but get a ModuleNotFoundError when attempting to execute the following code:<\/p>\n\n<pre><code>import azureml.core\nazureml.core.VERSION\n<\/code><\/pre>\n\n<p>This is the output:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"azureml.py\", line 1, in &lt;module&gt;\n    import azureml.core\n  File \"D:\\Projects\\style-transfer\\azureml.py\", line 1, in &lt;module&gt;\n    import azureml.core\nModuleNotFoundError: No module named 'azureml.core'; 'azureml' is not a package\n<\/code><\/pre>\n\n<p>The code above has been run from the conda prompt, with the test environment active as well as in vscode with the same environment selected.<\/p>\n\n<p>I setup the conda environment as per the following:<\/p>\n\n<ol>\n<li>Created the conda environment <code>conda create -n test<\/code>.<\/li>\n<li>Activated the environment <code>activate test<\/code>.<\/li>\n<li>Installed pip <code>conda install pip<\/code>.<\/li>\n<li>Installed azureml-sdk <code>pip install azureml-sdk<\/code>.<\/li>\n<\/ol>\n\n<p>This results in the following packages being installed in the environment as per <code>conda list<\/code>:<\/p>\n\n<pre><code>adal                      1.2.0                     &lt;pip&gt;\nantlr4-python3-runtime    4.7.2                     &lt;pip&gt;\napplicationinsights       0.11.7                    &lt;pip&gt;\nargcomplete               1.9.4                     &lt;pip&gt;\nasn1crypto                0.24.0                    &lt;pip&gt;\nazure-cli-command-modules-nspkg 2.0.2                     &lt;pip&gt;\nazure-cli-core            2.0.54                    &lt;pip&gt;\nazure-cli-nspkg           3.0.3                     &lt;pip&gt;\nazure-cli-profile         2.1.2                     &lt;pip&gt;\nazure-cli-telemetry       1.0.0                     &lt;pip&gt;\nazure-common              1.1.16                    &lt;pip&gt;\nazure-graphrbac           0.53.0                    &lt;pip&gt;\nazure-mgmt-authorization  0.51.1                    &lt;pip&gt;\nazure-mgmt-containerregistry 2.5.0                     &lt;pip&gt;\nazure-mgmt-keyvault       1.1.0                     &lt;pip&gt;\nazure-mgmt-nspkg          3.0.2                     &lt;pip&gt;\nazure-mgmt-resource       2.0.0                     &lt;pip&gt;\nazure-mgmt-storage        3.1.0                     &lt;pip&gt;\nazure-nspkg               3.0.2                     &lt;pip&gt;\nazure-storage-blob        1.4.0                     &lt;pip&gt;\nazure-storage-common      1.4.0                     &lt;pip&gt;\nazure-storage-nspkg       3.1.0                     &lt;pip&gt;\nazureml-core              1.0.6                     &lt;pip&gt;\nazureml-pipeline          1.0.6                     &lt;pip&gt;\nazureml-pipeline-core     1.0.6                     &lt;pip&gt;\nazureml-pipeline-steps    1.0.6                     &lt;pip&gt;\nazureml-sdk               1.0.6                     &lt;pip&gt;\nazureml-telemetry         1.0.6                     &lt;pip&gt;\nazureml-train             1.0.6                     &lt;pip&gt;\nazureml-train-core        1.0.6                     &lt;pip&gt;\nazureml-train-restclients-hyperdrive 1.0.6                     &lt;pip&gt;\nbackports.tempfile        1.0                       &lt;pip&gt;\nbackports.weakref         1.0.post1                 &lt;pip&gt;\nbcrypt                    3.1.5                     &lt;pip&gt;\nca-certificates           2018.03.07                    0\ncertifi                   2018.11.29               py37_0\ncffi                      1.11.5                    &lt;pip&gt;\nchardet                   3.0.4                     &lt;pip&gt;\ncolorama                  0.4.1                     &lt;pip&gt;\ncontextlib2               0.5.5                     &lt;pip&gt;\ncryptography              2.4.2                     &lt;pip&gt;\ndocker                    3.6.0                     &lt;pip&gt;\ndocker-pycreds            0.4.0                     &lt;pip&gt;\nfutures                   3.1.1                     &lt;pip&gt;\nhumanfriendly             4.17                      &lt;pip&gt;\nidna                      2.8                       &lt;pip&gt;\nisodate                   0.6.0                     &lt;pip&gt;\njmespath                  0.9.3                     &lt;pip&gt;\njsonpickle                1.0                       &lt;pip&gt;\nknack                     0.5.1                     &lt;pip&gt;\nmsrest                    0.6.2                     &lt;pip&gt;\nmsrestazure               0.6.0                     &lt;pip&gt;\nndg-httpsclient           0.5.1                     &lt;pip&gt;\noauthlib                  2.1.0                     &lt;pip&gt;\nopenssl                   1.1.1a               he774522_0\nparamiko                  2.4.2                     &lt;pip&gt;\npathspec                  0.5.9                     &lt;pip&gt;\npip                       18.1                     py37_0\nportalocker               1.2.1                     &lt;pip&gt;\npyasn1                    0.4.4                     &lt;pip&gt;\npycparser                 2.19                      &lt;pip&gt;\nPygments                  2.3.1                     &lt;pip&gt;\nPyJWT                     1.7.1                     &lt;pip&gt;\nPyNaCl                    1.3.0                     &lt;pip&gt;\npyOpenSSL                 18.0.0                    &lt;pip&gt;\npypiwin32                 223                       &lt;pip&gt;\npyreadline                2.1                       &lt;pip&gt;\npython                    3.7.1                h8c8aaf0_6\npython-dateutil           2.7.5                     &lt;pip&gt;\npytz                      2018.7                    &lt;pip&gt;\npywin32                   224                       &lt;pip&gt;\nPyYAML                    3.13                      &lt;pip&gt;\nrequests                  2.21.0                    &lt;pip&gt;\nrequests-oauthlib         1.0.0                     &lt;pip&gt;\nruamel.yaml               0.15.51                   &lt;pip&gt;\nSecretStorage             2.3.1                     &lt;pip&gt;\nsetuptools                40.6.3                   py37_0\nsix                       1.12.0                    &lt;pip&gt;\nsqlite                    3.26.0               he774522_0\ntabulate                  0.8.2                     &lt;pip&gt;\nurllib3                   1.23                      &lt;pip&gt;\nvc                        14.1                 h0510ff6_4\nvs2015_runtime            14.15.26706          h3a45250_0\nwebsocket-client          0.54.0                    &lt;pip&gt;\nwheel                     0.32.3                   py37_0\nwheel                     0.30.0                    &lt;pip&gt;\nwincertstore              0.2                      py37_0\n<\/code><\/pre>\n\n<p>If I run <code>which pip<\/code>, I get the following output, which confirms that I used the pip inside the environment to install azureml-sdk, I think:<\/p>\n\n<pre><code>\/c\/Users\/allan\/Miniconda3\/envs\/test\/Scripts\/pip\n<\/code><\/pre>\n\n<p>I can also see that the azureml packages do in fact exist within the environment folder structure.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1545617082117,
        "Question_score":0,
        "Question_tags":"python|conda|azure-machine-learning-studio",
        "Question_view_count":6343,
        "Owner_creation_time":1460456204197,
        "Owner_last_access_time":1610092459520,
        "Owner_location":"Australia",
        "Owner_reputation":140,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Question_last_edit_time":null,
        "Answer_body":"<p>It's probably because the name if your python file is the same as a module name you are trying import. In this case, rename the file to something other than <code>azureml.py<\/code>.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1545633498167,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/53908529",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36249716,
        "Question_title":"Automating Azure Machine Learning",
        "Question_body":"<p>Is there a way of automating the calls to the Azure Machine Learning Service (AML)? <\/p>\n\n<p>I\u2019ve created the web service from AML. Now I have to do the calls the automated way. I\u2019m trying to build a system, that connects to a Raspberry Pi for sensor data and gets a prediction from the ML service to be saved with the data itself. <\/p>\n\n<p>Is there something in Azure to automate this or should I do it within the application?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1459095760807,
        "Question_score":0,
        "Question_tags":"azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":341,
        "Owner_creation_time":1459065054367,
        "Owner_last_access_time":1459181119923,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1459199614030,
        "Answer_body":"<p>I'm assuming you've created the webservice from the experiment and asking about the consumption of the webservice. You can consume the webservice from anything that can do an API call to the endpoint. I don't know the exact architecture of your solution but take a look at this as it might suit your scenario. <\/p>\n\n<p>Stream analytics on Azure has a new feature called Functions(just a heads-up, its still in preview) that can automate the usage of deployed ML services from your account.Since you are trying to gather info from IoT devices, you might use <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/event-hubs-csharp-ephcs-getstarted\/\" rel=\"nofollow\">Event Hubs<\/a> or <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/iot-hub-csharp-csharp-getstarted\/\" rel=\"nofollow\">IoT Hubs<\/a> to get the data and process it using Stream Analytics and during the process you can use the Webservice as Function in SA to achieve on-the-go ML results.<\/p>\n\n<p>Usage is relatively simple if you are familiar with Stream Analytics or SQL queries in general.This <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/stream-analytics-machine-learning-integration-tutorial\/\" rel=\"nofollow\">link<\/a> shows the step by step implementation and the usage is below;<\/p>\n\n<pre><code>    WITH subquery AS (  \n    SELECT text, \"webservicealias\"(text) as result from input  \n    )  \n\n    Select text, result.[Score]  \n    Into output  \n    From subquery  \n<\/code><\/pre>\n\n<p>Hope this helps!<\/p>\n\n<p>Mert<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1459099456053,
        "Answer_score":4.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36249716",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50078161,
        "Question_title":"Azure ML Prediction Is Constant",
        "Question_body":"<p>I am using the Azure ML model available at <a href=\"https:\/\/gallery.azure.ai\/Experiment\/Weather-prediction-model-1\" rel=\"nofollow noreferrer\">https:\/\/gallery.azure.ai\/Experiment\/Weather-prediction-model-1<\/a> to design a prediction mechanism based on temperature and humidity. I haven't done any changes to the existing model and feeding in data from a simulator. The prediction output is stuck at 0.489944100379944. I have taken over 17k samples and still, the prediction is constant at this value. <\/p>\n\n<p>Any help will be highly appreciated.<\/p>\n\n<p><em>N.B. - This is my first stint with ML<\/em><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":10,
        "Question_creation_time":1524929526273,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|data-science|azure-machine-learning-studio|machine-learning-model",
        "Question_view_count":163,
        "Owner_creation_time":1338385871600,
        "Owner_last_access_time":1664032112660,
        "Owner_location":null,
        "Owner_reputation":118,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":52,
        "Question_last_edit_time":null,
        "Answer_body":"<p>This was caused by the training dataset. The dataset had characters in the humidity and temperature columns. This led to the model expecting characters but operating on floating point numbers. I cleaned the dataset and ensured that there are only floats in the temperature and humidity columns. Then I used this training data for the model and phew!!!! Everything's working now. <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1525107860377,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50078161",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60525454,
        "Question_title":"Intel optimized Python on Machine Learning Service Compute",
        "Question_body":"<p>Is it possible to run a Python script or Estimator step on the Azure Machine Learning Service in a container with the intel optimized Python distribution?\nI understand this is available on the <a href=\"https:\/\/azure.microsoft.com\/en-in\/blog\/intel-and-microsoft-bring-optimizations-to-deep-learning-on-azure\/\" rel=\"nofollow noreferrer\">Azure Data Science VMs<\/a> (<a href=\"https:\/\/www.intel.ai\/intel-optimized-data-science-virtual-machine-azure\/#gs.yuntlp\" rel=\"nofollow noreferrer\">or described here<\/a>), but I could not find out how to use this as an Azure Machine Learning Service Compute target.<\/p>\n\n<p>For my current use case I am specifically interested in using an mkl linked numpy package in the aml service container.<\/p>\n\n<p>Note: Running numpy.show_config() inside the container suggests numpy is linked against openblas and not mkl<\/p>\n\n<pre><code>blas_mkl_info:\n  NOT AVAILABLE\nblis_info:\n  NOT AVAILABLE\nopenblas_info:\n    libraries = ['openblas', 'openblas']\n    library_dirs = ['\/usr\/local\/lib']\n    language = c\n    define_macros = [('HAVE_CBLAS', None)]\nblas_opt_info:\n    libraries = ['openblas', 'openblas']\n    library_dirs = ['\/usr\/local\/lib']\n    language = c\n    define_macros = [('HAVE_CBLAS', None)]\nlapack_mkl_info:\n  NOT AVAILABLE\nopenblas_lapack_info:\n    libraries = ['openblas', 'openblas']\n    library_dirs = ['\/usr\/local\/lib']\n    language = c\n    define_macros = [('HAVE_CBLAS', None)]\nlapack_opt_info:\n    libraries = ['openblas', 'openblas']\n    library_dirs = ['\/usr\/local\/lib']\n    language = c\n    define_macros = [('HAVE_CBLAS', None)]\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1583322849310,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":81,
        "Owner_creation_time":1582187824717,
        "Owner_last_access_time":1618135237967,
        "Owner_location":null,
        "Owner_reputation":23,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1583354777670,
        "Answer_body":"<p>The Azure ML base images use <a href=\"https:\/\/docs.conda.io\/en\/latest\/miniconda.html\" rel=\"nofollow noreferrer\">Miniconda<\/a> Python distribution, which uses MKL.<\/p>\n\n<p>You can find the details of the base images here:<a href=\"https:\/\/github.com\/Azure\/AzureML-Containers\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/AzureML-Containers<\/a><\/p>\n\n<p>Also, if you install using Anaconda numpy in following way<\/p>\n\n<pre><code>conda_dep.add_conda_package(\"numpy\")\nrunconfig.run_config.environment.python.conda_dependencies = conda_dep\n<\/code><\/pre>\n\n<p>you should see this kind of output from <code>numpy.show_config()<\/code>. <\/p>\n\n<blockquote>\n  <p>blas_mkl_info:<\/p>\n  \n  <p>libraries = ['blas', 'cblas', 'lapack', 'pthread', 'blas', 'cblas',\n  'lapack']<\/p>\n  \n  <p>library_dirs =\n  ['\/azureml-envs\/azureml_a8ad8e485613e21e6e8adc1bfda86b40\/lib']<\/p>\n  \n  <p>define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]<\/p>\n  \n  <p>include_dirs =\n  ['\/azureml-envs\/azureml_a8ad8e485613e21e6e8adc1bfda86b40\/include']<\/p>\n<\/blockquote>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1583345664733,
        "Answer_score":-1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1583437574647,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60525454",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63296185,
        "Question_title":"How to write Azure machine learning batch scoring results to data lake?",
        "Question_body":"<p>I'm trying to write the output of batch scoring into datalake:<\/p>\n<pre><code>    parallel_step_name = &quot;batchscoring-&quot; + datetime.now().strftime(&quot;%Y%m%d%H%M&quot;)\n    \n    output_dir = PipelineData(name=&quot;scores&quot;, \n                              datastore=def_ADL_store,\n                              output_mode=&quot;upload&quot;,\n                              output_path_on_compute=&quot;path in data lake&quot;)\n\nparallel_run_config = ParallelRunConfig(\n    environment=curated_environment,\n    entry_script=&quot;use_model.py&quot;,\n    source_directory=&quot;.\/&quot;,\n    output_action=&quot;append_row&quot;,\n    mini_batch_size=&quot;20&quot;,\n    error_threshold=1,\n    compute_target=compute_target,\n    process_count_per_node=2,\n    node_count=2\n)\n    \n    batch_score_step = ParallelRunStep(\n        name=parallel_step_name,\n        inputs=[test_data.as_named_input(&quot;test_data&quot;)],\n        output=output_dir,\n        parallel_run_config=parallel_run_config,\n        allow_reuse=False\n    )\n<\/code><\/pre>\n<p>However I meet the error: &quot;code&quot;: &quot;UserError&quot;,\n&quot;message&quot;: &quot;User program failed with Exception: Missing argument --output or its value is empty.&quot;<\/p>\n<p>How can I write results of batch score to data lake?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1596780750297,
        "Question_score":2,
        "Question_tags":"azure-data-lake|azure-machine-learning-service",
        "Question_view_count":277,
        "Owner_creation_time":1513841518107,
        "Owner_last_access_time":1663924369323,
        "Owner_location":"China",
        "Owner_reputation":71,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I don\u2019t think ADLS is supported for <code>PipelineData<\/code>. My suggestion is to use the workspace\u2019s default blob store for the <code>PipelineData<\/code>, then use a <code>DataTransferStep<\/code> for after the <code>ParallelRunStep<\/code> is completed.<\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_time":1596781453977,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63296185",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72798225,
        "Question_title":"Remote Connection fails in setup of Python data-science client for SQL Server Machine Learning Services",
        "Question_body":"<p>I am trying to test the remote connection of a Python data-science client with SQL Server Machine Learning Services following this guide: <a href=\"https:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/python\/setup-python-client-tools-sql\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/python\/setup-python-client-tools-sql<\/a> (section 6).\nRunning the following script<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def send_this_func_to_sql():\n    from revoscalepy import RxSqlServerData, rx_import\n    from pandas.tools.plotting import scatter_matrix\n    import matplotlib.pyplot as plt\n    import io\n    \n    # remember the scope of the variables in this func are within our SQL Server Python Runtime\n    connection_string = &quot;Driver=SQL Server;Server=localhost\\instance02;Database=testmlsiris;Trusted_Connection=Yes;&quot;\n    \n    # specify a query and load into pandas dataframe df\n    sql_query = RxSqlServerData(connection_string=connection_string, sql_query = &quot;select * from iris_data&quot;)\n    df = rx_import(sql_query)\n    \n    scatter_matrix(df)\n    \n    # return bytestream of image created by scatter_matrix\n    buf = io.BytesIO()\n    plt.savefig(buf, format=&quot;png&quot;)\n    buf.seek(0)\n    \n    return buf.getvalue()\n\nnew_db_name = &quot;testmlsiris&quot;\nconnection_string = &quot;driver={sql server};server=sqlrzs\\instance02;database=%s;trusted_connection=yes;&quot; \n\nfrom revoscalepy import RxInSqlServer, rx_exec\n\n# create a remote compute context with connection to SQL Server\nsql_compute_context = RxInSqlServer(connection_string=connection_string%new_db_name)\n\n# use rx_exec to send the function execution to SQL Server\nimage = rx_exec(send_this_func_to_sql, compute_context=sql_compute_context)[0]\n<\/code><\/pre>\n<p>yields the following error message returned by rx_exec (stored in the <em>image<\/em> variable)<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>connection_string: &quot;driver={sql server};server=sqlrzs\\instance02;database=testmlsiris;trusted_connection=yes;&quot;\nnum_tasks: 1\nexecution_timeout_seconds: 0\nwait: True\nconsole_output: False\nauto_cleanup: True\npackages_to_load: []\ndescription: &quot;sqlserver&quot;\nversion: &quot;1.0&quot;\nXXX lineno: 2, opcode: 0\nTraceback (most recent call last):\n  File &quot;&lt;string&gt;&quot;, line 3, in &lt;module&gt;\n  File &quot;E:\\SQL\\MSSQL15.INSTANCE02\\PYTHON_SERVICES\\lib\\site-packages\\revoscalepy\\computecontext\\RxInSqlServer.py&quot;, line 664, in rx_sql_satellite_pool_call\n    exec(inputfile.read())\n  File &quot;&lt;string&gt;&quot;, line 34, in &lt;module&gt;\n  File &quot;E:\\SQL\\MSSQL15.INSTANCE02\\PYTHON_SERVICES\\lib\\site-packages\\revoscalepy\\computecontext\\RxInSqlServer.py&quot;, line 886, in rx_remote_call\n    results = rx_resumeexecution(state_file = inputfile, patched_server_name=args[&quot;hostname&quot;])\n  File &quot;E:\\SQL\\MSSQL15.INSTANCE02\\PYTHON_SERVICES\\lib\\site-packages\\revoscalepy\\computecontext\\RxInSqlServer.py&quot;, line 135, in rx_resumeexecution\n    return _state[&quot;function&quot;](**_state[&quot;args&quot;])\n  File &quot;C:\\Users\\username\\sendtosql.py&quot;, line 2, in send_this_func_to_sql\nSystemError: unknown opcode\n====== sqlrzs ( process 0 ) has started run at 2022-06-29 13:47:04 W. Europe Daylight Time ======\n{'local_state': {}, 'args': {}, 'function': &lt;function send_this_func_to_sql at 0x0000020F5810F1E0&gt;}\n<\/code><\/pre>\n<p>What is going wrong here? Line 2 in the script is just an import (which works when testing Python scripts on SQL Server directly). Any help is appreciated - thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1656491540923,
        "Question_score":0,
        "Question_tags":"python|sql-server|azure-machine-learning-studio|microsoft-machine-learning-server",
        "Question_view_count":54,
        "Owner_creation_time":1656427742040,
        "Owner_last_access_time":1664010979637,
        "Owner_location":null,
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1656503806377,
        "Answer_body":"<p>I just figured out the reason. As of today, the Python versions for the data clients in <a href=\"https:\/\/docs.microsoft.com\/de-de\/sql\/machine-learning\/python\/setup-python-client-tools-sql?view=sql-server-ver15\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/de-de\/sql\/machine-learning\/python\/setup-python-client-tools-sql?view=sql-server-ver15<\/a> are not the newest (revoscalepy Version 9.3), while the version of Machine Learning Services that we have running in our SQL Server is already 9.4.7.\nHowever, the revoscalepy libraries for the client and server must be the same, otherwise the deserialization fails server-sided.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1656513437860,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72798225",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72399408,
        "Question_title":"How to get list of compute instance size under Azure Machine Learning and Azure Databricks?",
        "Question_body":"<p>Goal here is to query a list of frequently used compute instance size under Azure Machine Learning and Azure Databricks using Azure Resource Graph Explorer from Azure Portal using Kusto query. From the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/governance\/resource-graph\/reference\/supported-tables-resources#resources\" rel=\"nofollow noreferrer\">documentation<\/a> here, there is a list of resources can be queried but there isn't any compute under <code>microsoft.machinelearningservices\/<\/code>(not classic studio) and <code>Microsoft.Databricks\/workspaces<\/code>.<\/p>\n<p>Below is what was tried, to get VM instance size but not showing what we have under Azure Machine Learning\/Azure Databricks.<\/p>\n<pre><code>Resources\n| project name, location, type, vmSize=tostring(properties.hardwareProfile.vmSize)\n| where type =~ 'Microsoft.Compute\/virtualMachines'\n| order by name desc\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1653612949060,
        "Question_score":0,
        "Question_tags":"azure|size|azure-databricks|azure-machine-learning-service|azure-resource-graph",
        "Question_view_count":153,
        "Owner_creation_time":1568185673007,
        "Owner_last_access_time":1663257666153,
        "Owner_location":"Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia",
        "Owner_reputation":383,
        "Owner_up_votes":70,
        "Owner_down_votes":1,
        "Owner_views":35,
        "Question_last_edit_time":null,
        "Answer_body":"<blockquote>\n<p>Unfortunately, Azure Resource Graph Explorer doesn't provide any query\nto get any compute related information from both, Azure Machine\nLearning and Databricks.<\/p>\n<\/blockquote>\n<p>Though Azure Resource Graph Explorer supports join functionality, allowing for more advanced exploration of your Azure environment by enabling you to correlate between resources and their properties. But these services only applicable on few Azure resources like VM, storage account, Cosmos DB, SQL databases, Network Security Groups, public IP addresses, etc.<\/p>\n<p><strong>Hence, there is no such Kusto query available in Azure Resource Graph Explorer which can list compute instance size of Machine Learning service and Databricks.<\/strong><\/p>\n<p><strong>Workarounds<\/strong><\/p>\n<p>Machine Learning Service<\/p>\n<p>For machine learning service you can manage the compute instance directly from ML service by using Python SDK. Refer <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=python#manage\" rel=\"nofollow noreferrer\">Python SDK azureml v1<\/a> to know more.<\/p>\n<p>Azure Databricks<\/p>\n<p>Cluster is the computational resource in Databricks. You can <strong>filter the cluster list<\/strong> from Databricks UI and manage the same. Features like cluster configuration, cluster cloning, access control, etc. are available which you can used based on your requirement. For more details, please check <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/clusters\/clusters-manage#filter-cluster-list\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1653626541543,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72399408",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48267427,
        "Question_title":"Trouble in creating graphics with matplotlib in a Jupyter notebook",
        "Question_body":"<p>Following the pandas documentation for visualization (<a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/visualization.html#visualization-hist\" rel=\"nofollow noreferrer\">https:\/\/pandas.pydata.org\/pandas-docs\/stable\/visualization.html#visualization-hist<\/a>) I am trying to create the following graphics:<\/p>\n\n<pre><code>import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n## A data set in my AzureML workplace experiment \ndf = ds.to_dataframe()\nplt.figure(); \ndf.plot.hist(stacked=True, bins=20) \nplt.figure();df.boxplot()\n<\/code><\/pre>\n\n<p>However, the output is limited to <code>\"&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd12e15dc18&gt;\"<\/code> (for the histogram(=) and <code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd12e0ce828&gt;\"<\/code> (to the box plot), but no image appearing. Can anyone help me to identify what I'm missing out? Thanks!<\/p>\n\n<p>I'm using Python 3 in Jupyter Notebook in AzureML. <\/p>\n\n<p>The <code>df.describe()<\/code> method works properly (there is a dataFrame)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1516035090403,
        "Question_score":0,
        "Question_tags":"python|pandas|matplotlib|azure-machine-learning-studio",
        "Question_view_count":378,
        "Owner_creation_time":1316565559337,
        "Owner_last_access_time":1655585549090,
        "Owner_location":"Brazil",
        "Owner_reputation":2563,
        "Owner_up_votes":368,
        "Owner_down_votes":2,
        "Owner_views":503,
        "Question_last_edit_time":1516035342393,
        "Answer_body":"<p>Have you set the backend?<\/p>\n\n<pre><code>%matplotlib inline\n<\/code><\/pre>\n\n<p>Worth reading about what this does for a notebook here too\n<a href=\"https:\/\/stackoverflow.com\/questions\/43027980\/purpose-of-matplotlib-inline\/43028034\">Purpose of &quot;%matplotlib inline&quot;<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1516035353070,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48267427",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46340959,
        "Question_title":"Multiple Inputs\/Outputs from Execute R Script",
        "Question_body":"<p>Assume I have an Execute R Script that calculates multiple variables, say X and Y.\nIs it possible to save X as a dataset ds_X and Y as a dataset ds_Y?<\/p>\n\n<p>The problem is that there is only 1 output port available that needs to be mapped to a data.frame. Am I missing an option to add more output ports?\nSame problem for input ports. I may connect 2 of the \"Enter Data Manually\" modules to it, but what if I need 3? The current workaround is to put CSV files in a ZIP file and connect that. Are there easier solution?<\/p>\n\n<p><strong>Example of what i tried:<\/strong><\/p>\n\n<p>I tried adding ds_X and ds_Y to a list. The idea is to pass this list to multiple \"Execute R Script\" modules and use the required list elements there.\nMapping a list to an output port does not seem to work though:<\/p>\n\n<pre><code># Calculate lots of stuff - results are ds_X and ds_Y\nds_X &lt;- mtcars\nds_Y &lt;- cars\nout &lt;- list(ds_X, ds_Y)\n\nmaml.mapOutputPort(\"out\")\n<\/code><\/pre>\n\n<p>results in an error:<\/p>\n\n<pre><code>Error: Mapped variable must be of class type data.frame at this time.\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_time":1505987948480,
        "Question_score":0,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":754,
        "Owner_creation_time":1389795136837,
        "Owner_last_access_time":1663761689240,
        "Owner_location":null,
        "Owner_reputation":625,
        "Owner_up_votes":88,
        "Owner_down_votes":3,
        "Owner_views":36,
        "Question_last_edit_time":1505991363610,
        "Answer_body":"<p>You can author custom R Modules. <\/p>\n\n<p>Here is some documentation: \n<a href=\"https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/04\/23\/build-your-own-r-modules-in-azure-ml\/\" rel=\"nofollow noreferrer\">https:\/\/blogs.technet.microsoft.com\/machinelearning\/2015\/04\/23\/build-your-own-r-modules-in-azure-ml\/<\/a>\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-custom-r-modules\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/machine-learning-custom-r-modules<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1506004266757,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46340959",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56418684,
        "Question_title":"Possible to access the internal representation of a neural network trained in Azure Machine Learning Service or Azure Machine Learning Studio?",
        "Question_body":"<p>I'm working with data scientists who would like to gain insight and understanding of the neural network models that they train using the visual interfaces in Azure Machine Learning Studio\/Service. Is it possible to dump out and inspect the internal representation of a neural network model? Is there a way that I could write code that accesses the nodes and weights of a trained neural network in order to visualize the network as a graph structure? Or if Azure Machine Learning Studio\/Service doesn't support this I'd appreciate advice on a different machine learning framework that might be more appropriate for this kind of analysis.<\/p>\n\n<p>Things I have tried:<\/p>\n\n<ul>\n<li>Train Model outputs an ILearnerDotNet (AML Studio) or Model (AML Service). I looked for items to drag into the workspace where I could write custom code such as Execute Python Script. They seem to accept datasets, but not ILearnerDotNet\/Model as input.<\/li>\n<li>I wasn't able to locate documentation about the ILearnerDotNet\/Model interfaces.<\/li>\n<li>Selecting the Train Model output offers the option to Save as Trained Model. This creates a trained model object and that would help me reference the trained model in other places, but I didn't find a way to use this to get at its internals.<\/li>\n<\/ul>\n\n<p>I'm new to the Azure Machine Learning landscape, and could use some help with how to get started on how to access this data.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1559506858340,
        "Question_score":2,
        "Question_tags":"neural-network|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":167,
        "Owner_creation_time":1427643193810,
        "Owner_last_access_time":1663710082517,
        "Owner_location":null,
        "Owner_reputation":45,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Quote from Azure ML Exam reference:<\/p>\n\n<blockquote>\n  <p>By default, the architecture of neural networks is limited to a single\n  hidden layer with sigmoid as the activation function and softmax in\n  the last layer. You can change this in the properties of the model,\n  opening the Hidden layer specification dropdown list, and selecting a\n  Custom definition script. A text box will appear in which you will be\n  able to insert a Net# script. This script language allows you to\n  define neural networks architectures.<\/p>\n<\/blockquote>\n\n<p>For instance, if you want to create a two layer network, you may put the following code.<\/p>\n\n<pre><code>input Picture [28, 28];\nhidden H1 [200] from Picture all;\nhidden H2 [200] from H1 all;\noutput Result [10] softmax from H2 all;\n<\/code><\/pre>\n\n<p>Nevertheless, with Net# you will face certain limitations as, it does not accept regularization (neither L2 nor dropout). Also, there is no ReLU activation that are\ncommonly used in deep learning due to their benefits in backpropagation. You cannot modify the batch size of the Stochastic Gradient Descent (SGD). Besides that, you cannot use other optimization algorithms. You can use SGD with momentum, but not others like Adam, or RMSprop. You cannot define recurrent or recursive neural networks.<\/p>\n\n<p>Another great tool is CNTK (Cognitive Toolkit) that allows you defining your computational graph and create a fully customizable model.\nQuote from documentation<\/p>\n\n<blockquote>\n  <p>It is a Microsoft open source deep learning toolkit. Like other deep\n  learning tools, CNTK is based on the construction of computational\n  graphs and their optimization using automatic differentiation. The\n  toolkit is highly optimized and scales efficiently (from CPU, to GPU,\n  to multiple machines). CNTK is also very portable and flexible; you\n  can use it with programming languages like Python, C#, or C++, but you\n  can also use a model description language called BrainScript.<\/p>\n<\/blockquote>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1559896269913,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56418684",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32422626,
        "Question_title":"Part of speech tagging and entity recognition - python",
        "Question_body":"<p>I want to perform part of speech tagging and entity recognition in python similar to Maxent_POS_Tag_Annotator and Maxent_Entity_Annotator functions of openNLP in R.  I would prefer a code in python which takes input as textual sentence and gives output as different features- like number of \"CC\", number of \"CD\", number of \"DT\" etc.. CC, CD, DT are POS tags as used in Penn Treebank. So there should be 36 columns\/features for POS tagging corresponding to 36 POS tags as in <a href=\"http:\/\/www.ling.upenn.edu\/courses\/Fall_2003\/ling001\/penn_treebank_pos.html\" rel=\"nofollow\">Penn Treebank POS<\/a>. I want to implement this on Azure ML \"Execute Python Script\" module and Azure ML supports python 2.7.7. I heard nltk in python may does the job, but I am a beginner on python. Any help would be appreciated. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1441535794287,
        "Question_score":0,
        "Question_tags":"python|azure|named-entity-recognition|part-of-speech|azure-machine-learning-studio",
        "Question_view_count":1014,
        "Owner_creation_time":1431324152360,
        "Owner_last_access_time":1444093237570,
        "Owner_location":null,
        "Owner_reputation":19,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Question_last_edit_time":1441776651843,
        "Answer_body":"<p>Take a look at <a href=\"http:\/\/www.nltk.org\/book\/ch05.html\" rel=\"nofollow\">NTLK book<\/a>, Categorizing and Tagging Words section.<\/p>\n\n<p>Simple example, it uses the Penn Treebank tagset:<\/p>\n\n<pre><code>from nltk.tag import pos_tag\nfrom nltk.tokenize import word_tokenize\npos_tag(word_tokenize(\"John's big idea isn't all that bad.\")) \n\n[('John', 'NNP'),\n(\"'s\", 'POS'),\n ('big', 'JJ'),\n ('idea', 'NN'),\n ('is', 'VBZ'),\n (\"n't\", 'RB'),\n ('all', 'DT'),\n ('that', 'DT'),\n ('bad', 'JJ'),\n ('.', '.')]\n<\/code><\/pre>\n\n<p>Then you can use<\/p>\n\n<pre><code>from collections import defaultdict\ncounts = defaultdict(int)\nfor (word, tag) in pos_tag(word_tokenize(\"John's big idea isn't all that bad.\")):\n    counts[tag] += 1\n<\/code><\/pre>\n\n<p>to get frequencies:<\/p>\n\n<pre><code>defaultdict(&lt;type 'int'&gt;, {'JJ': 2, 'NN': 1, 'POS': 1, '.': 1, 'RB': 1, 'VBZ': 1, 'DT': 2, 'NNP': 1})\n<\/code><\/pre>",
        "Answer_comment_count":7.0,
        "Answer_creation_time":1441539548050,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32422626",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58377444,
        "Question_title":"swagger.json example json for forecast model doesn't seem to return predictions",
        "Question_body":"<p>When trying to make predictions for forecasting models using Azure ML Service, the swagger.json includes the following schema for input:<\/p>\n\n<pre><code>\"example\": {\"data\": [{\"date\": \"2019-08-30T00:00:00.000Z\", \"y_query\": 1.0}]}\n<\/code><\/pre>\n\n<p>However, when I feed this as an input to generate predictions, I receive the following error:<\/p>\n\n<pre><code>data= {\"data\": [{\"date\": \"2019-08-30T00:00:00.000Z\", \"y_query\": 1 }]}\n# Convert to JSON string\ninput_data = json.dumps(data)\n\n# Set the content type\nheaders = {'Content-Type': 'application\/json'}\n# If authentication is enabled, set the authorization header\n#headers['Authorization'] = f'Bearer {key}'\n\n# Make the request and display the response\nresp = requests.post(scoring_uri, input_data, headers=headers)\nprint(resp.text)\n\n<\/code><\/pre>\n\n<pre><code>\"{\\\"error\\\": \\\"DataException:\\\\n\\\\tMessage: y values are present for each date. Nothing to forecast.\\\\n\\\\tInnerException None\\\\n\\\\tErrorResponse \\\\n{\\\\n    \\\\\\\"error\\\\\\\": {\\\\n        \\\\\\\"code\\\\\\\": \\\\\\\"UserError\\\\\\\",\\\\n        \\\\\\\"inner_error\\\\\\\": {\\\\n            \\\\\\\"code\\\\\\\": \\\\\\\"InvalidData\\\\\\\"\\\\n        },\\\\n        \\\\\\\"message\\\\\\\": \\\\\\\"y values are present for each date. Nothing to forecast.\\\\\\\"\\\\n    }\\\\n}\\\"}\"\n<\/code><\/pre>\n\n<p>I have tried not passing a y value, which causes an 'expected two axis got one' and passing 0 as the y_query. Any guidance on how to make predictions using this approach would be greatly appreciated. <\/p>\n\n<p>The documentation for web services is here: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-consume-web-service<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":6,
        "Question_creation_time":1571058071523,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":530,
        "Owner_creation_time":1464949169833,
        "Owner_last_access_time":1657738559383,
        "Owner_location":null,
        "Owner_reputation":25,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Try using nan as the value for y_query. and make sure the date is the next time unit after the one that was used in the training set.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1571417536483,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58377444",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":61168984,
        "Question_title":"Azure ML free trial: how to submit pipeline?",
        "Question_body":"<p>I'm using a free trial account on MS Azure and I'm following this tutorial.<\/p>\n\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score<\/a><\/p>\n\n<p>I'm stuck when I try to \"submit the pipeline\".<\/p>\n\n<p>The reason seems to be that I can't create a compute instance or a training cluster on a free plan.\nI still have 200USDs of free credits. I guess there must be a solution?<\/p>\n\n<hr>\n\n<p>Error messages:<\/p>\n\n<pre><code>Invalid graph: The pipeline compute target is invalid.\n\n400: Compute Test3 in state Failed, which is not able to use\n\nCompute instance: creation failed\nThe specified subscription has a total vCPU quota of 0 and is less than the requested compute training cluster and\/or compute instance's min nodes of 1 which maps to 4 vCPUs\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1586681686103,
        "Question_score":2,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":370,
        "Owner_creation_time":1343682543650,
        "Owner_last_access_time":1655966822477,
        "Owner_location":null,
        "Owner_reputation":135,
        "Owner_up_votes":51,
        "Owner_down_votes":0,
        "Owner_views":45,
        "Question_last_edit_time":1586690281397,
        "Answer_body":"<p>Please check the announcement from MS Team regarding this:<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/blog\/our-commitment-to-customers-and-microsoft-cloud-services-continuity\/\" rel=\"nofollow noreferrer\">https:\/\/azure.microsoft.com\/blog\/our-commitment-to-customers-and-microsoft-cloud-services-continuity\/<\/a><\/p>\n\n<p>All the free trials will not work as of now<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1586681759587,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61168984",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37375506,
        "Question_title":"AzureML: \"Train Matchbox Recommender\" is not working and does not descibe the error",
        "Question_body":"<p>I tried to create my own experiment using the module, but failed to make it work.\nhere is the exception i got:  <\/p>\n\n<blockquote>\n  <p>Error 0018: Training dataset of user-item-rating triples contains invalid data.\n  [Critical]     {\"InputParameters\":{\"DataTable\":[{\"Rows\":14,\"Columns\":3,\"estimatedSize\":12668928,\"ColumnTypes\":{\"System.String\":1,\"System.Int32\":1,\"System.Double\":1},\"IsComplete\":true,\"Statistics\":{\"0\":[10,0],\"1\":[5422.0,5999.0,873.0,6616.0,1758.0582820478173,7.0,0.0],\"2\":[1.0,1.0,1.0,1.0,0.0,1.0,0.0]}},{\"Rows\":2338,\"Columns\":3,\"estimatedSize\":1404928,\"ColumnTypes\":{\"System.String\":1,\"System.Int32\":1,\"System.Double\":1},\"IsComplete\":true,\"Statistics\":{\"0\":[2338,0],\"1\":[7.5367835757057318,3.0,0.0,704.0,17.738259318519511,64.0,0.0],\"2\":[3.3737234816082085,1.5,0.0,352.0,8.3956874404883841,122.0,0.0]}},{\"Rows\":2532,\"Columns\":22,\"estimatedSize\":4648960,\"ColumnTypes\":{\"System.Int32\":10,\"System.String\":5,\"System.Double\":6,\"System.Boolean\":1},\"IsComplete\":true,\"Statistics\":{\"0\":[4575.7263033175359,5326.5,539.0,6871.0,1987.9561375024909,2532.0,0.0],\"1\":[4575.7263033175359,5326.5,539.0,6871.0,1987.9561375024909,2532.0,0.0],\"2\":[613.0,613.0,613.0,613.0,0.0,1.0,0.0],\"3\":[0,2532],\"4\":[0,2532],\"5\":[4575.7263033175359,5326.5,539.0,6871.0,1987.9561375024909,2532.0,0.0],\"6\":[23.647231437598673,19.99,1.99,149.99,17.237723488320938,90.0,0.0],\"7\":[0.043827014218009476,0.0,0.0,45.99,1.3460680431173562,3.0,0.0],\"8\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"9\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"10\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"11\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"12\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"13\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"14\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"15\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"16\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"17\":[0.0,0.0,0.0,0.0,0.0,1.0,0.0],\"18\":[2524,0],\"19\":[242,18],\"20\":[1,0],\"21\":[2524,0]}}],\"Generic\":{\"traitCount\":10,\"iterationCount\":5,\"batchCount\":4}},\"OutputParameters\":[],\"ModuleType\":\"Microsoft.Analytics.Modules.MatchboxRecommender.Dll\",\"ModuleVersion\":\" Version=6.0.0.0\",\"AdditionalModuleInfo\":\"Microsoft.Analytics.Modules.MatchboxRecommender.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.Analytics.Modules.MatchboxRecommender.Dll.MatchboxRecommender;Train\",\"Errors\":\"Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0018: Training dataset of user-item-rating triples contains invalid data.\\r\\n   at Microsoft.Analytics.Modules.MatchboxRecommender.Dll.Utilities.UpdateRatingMetadata(DataTable dataset, String datasetName) in d:\\_Bld\\8833\\7669\\Sources\\Product\\Source\\Modules\\MatchboxRecommender.Dll\\Utilities.cs:line 179\\r\\n   at Microsoft.Analytics.Modules.MatchboxRecommender.Dll.MatchboxRecommender.TrainImpl(DataTable userItemRatingTriples, DataTable userFeatures, DataTable itemFeatures, Int32 traitCount, Int32 iterationCount, Int32 batchCount) in d:\\_Bld\\8833\\7669\\Sources\\Product\\Source\\Modules\\MatchboxRecommender.Dll\\MatchboxRecommender.cs:line 62\",\"Warnings\":[],\"Duration\":\"00:00:00.6722068\"}\n  Module finished after a runtime of 00:00:01.1250071 with exit code -2\n  Module failed due to negative exit code of -2<\/p>\n<\/blockquote>\n\n<p>i've check the input data i'm setting as input user-place-rating table, record by record (no worries it's only 14 records) here it is: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LjyD6.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LjyD6.png\" alt=\"the input data\"><\/a><\/p>\n\n<p>Here is a screenshot of the experiment:\n<a href=\"https:\/\/i.stack.imgur.com\/I43tG.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/I43tG.png\" alt=\"the experiment\"><\/a><\/p>\n\n<p>since the error message is not very informative, I don't know where to start, so, if anybody has an idea, I would be happy to hear about it.<\/p>\n\n<p>Update:\nA friend of mine suggested to add \"Edit Metadata\" module to change the \"rating\" feature into \"int\" or \"float\" types, and the two other(placeID and userID) into string features. that didn't help as well.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1463926726100,
        "Question_score":3,
        "Question_tags":"azure|machine-learning|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":1187,
        "Owner_creation_time":1320061998253,
        "Owner_last_access_time":1656424560827,
        "Owner_location":null,
        "Owner_reputation":778,
        "Owner_up_votes":176,
        "Owner_down_votes":6,
        "Owner_views":89,
        "Question_last_edit_time":1463935698457,
        "Answer_body":"<p>The matchbox recommender requires that ratings be numerical or categorical. Also when training, your ratings cannot all be the same.<\/p>\n\n<p>You need to use a metadata editor <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn905986.aspx\" rel=\"nofollow\">https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn905986.aspx<\/a> to convert the ratings into numerical features and you need to make sure you are using a range of ratings.<\/p>\n\n<p>Then this should work!<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1464083199417,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37375506",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64054587,
        "Question_title":"How can I remove the wrapper around the input when using Inference Schema",
        "Question_body":"<p>When using Inference Schema to autogenerate the swagger doc for my AzureML endpoint (as detailed <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\" rel=\"nofollow noreferrer\">here<\/a> and <a href=\"https:\/\/github.com\/Azure\/InferenceSchema\" rel=\"nofollow noreferrer\">here<\/a>), I see that it creates a wrapper around my input_sample. Is there a way to\nnot wrap the input inside this &quot;data&quot; wrapper?<\/p>\n<p>Here is what my score.py looks like:<\/p>\n<pre><code>input_sample = {\n                &quot;id&quot;: 123,\n                &quot;language&quot;: &quot;en&quot;\n                &quot;items&quot;: [{\n                    &quot;item&quot;: 1,\n                    &quot;desc&quot;: &quot;desc&quot;\n                }]\n            }\noutput_sample = [{'prediction': 'true', 'predictionConfidence': 0.8279970776764844}]\n\n@input_schema('data', StandardPythonParameterType(input_sample))\n@output_schema(StandardPythonParameterType(output_sample))\ndef run(data):\n&quot;&quot;&quot;\n    {\n        data: { --&gt; DON'T WANT this &quot;data&quot; wrapper\n                &quot;id&quot;: 123,\n                &quot;language&quot;: &quot;en&quot;\n                &quot;items&quot;: [{\n                    &quot;item&quot;: 1,\n                    &quot;desc&quot;: &quot;desc&quot;\n                }]\n            }\n    }\n    &quot;&quot;&quot;\n    try:\n        id = data['id']\n        ...\n        \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1600982458753,
        "Question_score":2,
        "Question_tags":"python|inference|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":173,
        "Owner_creation_time":1406298639460,
        "Owner_last_access_time":1663860224643,
        "Owner_location":null,
        "Owner_reputation":435,
        "Owner_up_votes":36,
        "Owner_down_votes":1,
        "Owner_views":48,
        "Question_last_edit_time":1601039285473,
        "Answer_body":"<p>InferenceSchema used with Azure Machine Learning deployments, then the code for this package was recently published at <a href=\"https:\/\/github.com\/Azure\/InferenceSchema\" rel=\"nofollow noreferrer\">https:\/\/github.com\/Azure\/InferenceSchema<\/a> under an MIT license. So you could possibly use that to create a version specific to your needs.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1601883755637,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1601885390513,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64054587",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39251701,
        "Question_title":"AzureML: experiment working for a subset and not for the whole dataset",
        "Question_body":"<p>some times ago I had written a code in AzureML meeting \"out of memory\" issues. So I tried to split the code in three different codes and that partially worked. It remains a part that (I think) is affected by memory issues too.<\/p>\n\n<p>I have created an experiment that I have published in this <a href=\"http:\/\/gallery.cortanaintelligence.com\/Experiment\/TextMining-sample-NA-v1-1\" rel=\"nofollow noreferrer\">link<\/a>.<\/p>\n\n<p>There is a module that considers only a sample of my dataset, and it does work. This means that the code is supposed to work correctly. If you remove the sampling code (the second module starting from the top) <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Cbzhj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Cbzhj.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>and you connect directly the original dataset you have the following situation<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/XOo8e.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/XOo8e.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>producing the following error:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/mRSSQ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/mRSSQ.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Does someone have some way to understand where Azure crashes?<\/p>\n\n<p>Thanks you,<\/p>\n\n<p>Andrea<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1472651915230,
        "Question_score":1,
        "Question_tags":"r|azure-machine-learning-studio",
        "Question_view_count":102,
        "Owner_creation_time":1436432728610,
        "Owner_last_access_time":1663607665487,
        "Owner_location":"Colleferro, Italy",
        "Owner_reputation":809,
        "Owner_up_votes":109,
        "Owner_down_votes":0,
        "Owner_views":361,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Thanks so much for publishing the example -- this really helped to understand the issue. I suspect that you want to modify the <code>gsub()<\/code> calls in your script by adding the argument \"<code>fixed=TRUE<\/code>\" to each. (The documentation for this function is <a href=\"https:\/\/stat.ethz.ch\/R-manual\/R-devel\/library\/base\/html\/grep.html\" rel=\"nofollow\">here<\/a>.)<\/p>\n\n<p>What appears to have happened is that somewhere in your full dataset -- but not in the subsampled dataset -- there is some text that winds up being included in <code>df[i, \"names\"]<\/code> as \"<code>(art.<\/code>\".  Your script pads this into \"<code>\\\\b(art.\\\\b<\/code>\". The <code>gsub()<\/code> function tries to interpret this as a regular expression instead of a simple string, then throws an error because it is not a valid regular expression: it contains an opening parenthesis but no closing parenthesis. I believe that you actually did not want <code>gsub()<\/code> to interpret the input as a regular expression in the first place, and specifying <code>gsub(..., fixed=TRUE)<\/code> will correct that.<\/p>\n\n<p>I believe the reason why this error disappears when you add the sample\/partition module is because, by chance, the problematic input value was dropped on subsampling. I do not think it is an issue of available resources on Azure ML. (Caveat: I cannot confirm the fix works yet; I made the suggested update and started running the experiment, but it has not yet completed successfully.)<\/p>",
        "Answer_comment_count":6.0,
        "Answer_creation_time":1472676812497,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39251701",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":30092360,
        "Question_title":"How do i schedule Azure Machine learning web service in Azure Scheduler?",
        "Question_body":"<p>I have published the web service from Azure Machine Learning experiment and now i want this web service to be scheduled using Azure Scheduler<\/p>\n\n<p>Can somebody please state the procedure?<\/p>\n\n<p>I got the API KEY, REQUEST\/RESPONSE and Batch Execution URI from the web service homepage.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1430975121057,
        "Question_score":2,
        "Question_tags":"azure|machine-learning|azure-scheduler|azure-machine-learning-studio",
        "Question_view_count":1301,
        "Owner_creation_time":1403541426413,
        "Owner_last_access_time":1592469887883,
        "Owner_location":"Bengaluru, India",
        "Owner_reputation":191,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Question_last_edit_time":1431617131740,
        "Answer_body":"<p>You will need to first create a new job in the Azure management portal (<a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn495651.aspx\" rel=\"nofollow\">https:\/\/msdn.microsoft.com\/en-us\/library\/azure\/dn495651.aspx<\/a>), where you can configure the URL and the HTTP method to POST, and specify the body. However, the initial configuration screens don't let you add any headers, so once you have created the job, go in and edit it to add the following headers:<\/p>\n\n<p>Content-Type: application\/json<br>\nAccept: application\/json<br>\nAuthorization: Bearer <\/p>\n\n<p>This will work, but am wondering if this actually serves your purpose. If you're calling the synchronous (request response) endpoint of the AzureML service, you need to specify the inputs in the request payload, which is statically configured with the Azure Scheduler job. So you will effectively be repeating the same call over and over again. You may also want to explore <a href=\"http:\/\/azure.microsoft.com\/en-us\/services\/data-factory\/\" rel=\"nofollow\">Azure Data Factory<\/a> if your needs are served by calling the asynchronous (batch) endpoint of the AzureML service.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1431016140103,
        "Answer_score":2.0,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/30092360",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35970126,
        "Question_title":"Increase the size of \/dev\/shm in Azure ML Studio",
        "Question_body":"<p>I'm trying to execute the following code in Azure ML Studio notebook:<\/p>\n\n<pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.cross_validation import KFold, cross_val_score\n\nfor C in np.linspace(0.01, 0.2, 30):\n    cv = KFold(n=X_train.shape[0], n_folds=7, shuffle=True, random_state=12345)\n    clf = LogisticRegression(C=C, random_state=12345)\n    print C, sum(cross_val_score(clf, X_train_scaled, y_train, scoring='roc_auc', cv=cv, n_jobs=2)) \/ 7.0\n<\/code><\/pre>\n\n<p>and I'm getting this error:<\/p>\n\n<pre><code>Failed to save &lt;type 'numpy.ndarray'&gt; to .npy file:\nTraceback (most recent call last):\n  File \"\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/externals\/joblib\/numpy_pickle.py\", line 271, in save\n    obj, filename = self._write_array(obj, filename)\n  File \"\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/externals\/joblib\/numpy_pickle.py\", line 231, in _write_array\n    self.np.save(filename, array)\n  File \"\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/numpy\/lib\/npyio.py\", line 491, in save\n    pickle_kwargs=pickle_kwargs)\n  File \"\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/numpy\/lib\/format.py\", line 585, in write_array\n    array.tofile(fp)\nIOError: 19834920 requested and 8384502 written\n\n---------------------------------------------------------------------------\nIOError                                   Traceback (most recent call last)\n&lt;ipython-input-29-9740e9942629&gt; in &lt;module&gt;()\n      6     cv = KFold(n=X_train.shape[0], n_folds=7, shuffle=True, random_state=12345)\n      7     clf = LogisticRegression(C=C, random_state=12345)\n----&gt; 8     print C, sum(cross_val_score(clf, X_train_scaled, y_train, scoring='roc_auc', cv=cv, n_jobs=2)) \/ 7.0\n\n\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/cross_validation.pyc in cross_val_score(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\n   1431                                               train, test, verbose, None,\n   1432                                               fit_params)\n-&gt; 1433                       for train, test in cv)\n   1434     return np.array(scores)[:, 0]\n   1435 \n\n\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/externals\/joblib\/parallel.pyc in __call__(self, iterable)\n    808                 # consumption.\n    809                 self._iterating = False\n--&gt; 810             self.retrieve()\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n\n\/home\/nbcommon\/env\/lib\/python2.7\/site-packages\/sklearn\/externals\/joblib\/parallel.pyc in retrieve(self)\n    725                 job = self._jobs.pop(0)\n    726             try:\n--&gt; 727                 self._output.extend(job.get())\n    728             except tuple(self.exceptions) as exception:\n    729                 # Stop dispatching any new job in the async callback thread\n\n\/home\/nbcommon\/env\/lib\/python2.7\/multiprocessing\/pool.pyc in get(self, timeout)\n    565             return self._value\n    566         else:\n--&gt; 567             raise self._value\n    568 \n    569     def _set(self, i, obj):\n\nIOError: [Errno 28] No space left on device\n<\/code><\/pre>\n\n<p>With <code>n_jobs=1<\/code> it works fine.<\/p>\n\n<p>I think this is because <code>joblib<\/code> library tries to save my data to <code>\/dev\/shm<\/code>. The problem is that it has only 64M capacity:<\/p>\n\n<pre><code>Filesystem         Size  Used Avail Use% Mounted on\nnone               786G  111G  636G  15% \/\ntmpfs               56G     0   56G   0% \/dev\nshm                 64M     0   64M   0% \/dev\/shm\ntmpfs               56G     0   56G   0% \/sys\/fs\/cgroup\n\/dev\/mapper\/crypt  786G  111G  636G  15% \/etc\/hosts\n<\/code><\/pre>\n\n<p>I can't change this folder by setting <code>JOBLIB_TEMP_FOLDER<\/code> environment variable (<code>export<\/code> doesn't work).<\/p>\n\n<pre><code>In [35]: X_train_scaled.nbytes\n\nOut[35]: 158679360\n<\/code><\/pre>\n\n<p>Thanks for any advice!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1457871506333,
        "Question_score":2,
        "Question_tags":"python|azure|scikit-learn|joblib|azure-machine-learning-studio",
        "Question_view_count":630,
        "Owner_creation_time":1452022246890,
        "Owner_last_access_time":1657271456120,
        "Owner_location":"Moscow, Russia",
        "Owner_reputation":708,
        "Owner_up_votes":34,
        "Owner_down_votes":69,
        "Owner_views":167,
        "Question_last_edit_time":1457939841650,
        "Answer_body":"<p>The <code>\/dev\/shm<\/code> is a virtual filesystem for passing data between programs that implementation of traditional shared memory on Linux.<\/p>\n\n<p>So you could not increase it via set up some options on Application Layout.<\/p>\n\n<p>But for example, you can remount <code>\/dev\/shm<\/code> with 8G size in Linux Shell with administrator permission like <code>root<\/code> as follows.<\/p>\n\n<p><code>mount -o remount,size=8G \/dev\/shm<\/code><\/p>\n\n<p>However, it seems that Azure ML studio not support remote access via SSH protocol, so the feasible plan is upgrade the standard tier if using free tier at present.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1457947589353,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35970126",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71014584,
        "Question_title":"Azure ML Tabular Dataset : missing 1 required positional argument: 'stream_column'",
        "Question_body":"<p>For the Python API for tabular dataset of AzureML (<code>azureml.data.TabularDataset<\/code>), there are two experimental methods which have been introduced:<\/p>\n<ol>\n<li><code>download(stream_column, target_path=None, overwrite=False, ignore_not_found=True)<\/code><\/li>\n<li><code>mount(stream_column, mount_point=None)<\/code><\/li>\n<\/ol>\n<p>Parameter <code>stream_column<\/code> has been defined as The stream column to mount or download.<\/p>\n<p>What is the actual meaning of <code>stream_column<\/code>? I don't see any example any where?<\/p>\n<p>Any pointer will be helpful.<\/p>\n<p>The stack trace:<\/p>\n<pre><code>Method download: This is an experimental method, and may change at any time. Please see https:\/\/aka.ms\/azuremlexperimental for more information.\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n\/tmp\/ipykernel_11561\/3904436543.py in &lt;module&gt;\n----&gt; 1 tab_dataset.download(target_path=&quot;..\/data\/tabular&quot;)\n\n\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/_base_sdk_common\/_docstring_wrapper.py in wrapped(*args, **kwargs)\n     50     def wrapped(*args, **kwargs):\n     51         module_logger.warning(&quot;Method {0}: {1} {2}&quot;.format(func.__name__, _method_msg, _experimental_link_msg))\n---&gt; 52         return func(*args, **kwargs)\n     53     return wrapped\n     54 \n\n\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/data\/_loggerfactory.py in wrapper(*args, **kwargs)\n    130             with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n    131                 try:\n--&gt; 132                     return func(*args, **kwargs)\n    133                 except Exception as e:\n    134                     if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\nTypeError: download() missing 1 required positional argument: 'stream_column'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1644217302490,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azureml-python-sdk|azuremlsdk",
        "Question_view_count":356,
        "Owner_creation_time":1280505139753,
        "Owner_last_access_time":1663935737867,
        "Owner_location":"Bangalore, India",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Question_last_edit_time":1645197572643,
        "Answer_body":"<p><strong>Update on 5th March, 2022<\/strong><\/p>\n<p>I posted this as a support ticket with Azure. Following is the answer I have received:<\/p>\n<blockquote>\n<p>As you can see from our documentation of <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py\" rel=\"nofollow noreferrer\">TabularDataset Class<\/a>,\nthe \u201cstream_column\u201d parameter is required. So, that error is occurring\nbecause you are not passing any parameters when you are calling the\ndownload method.    The \u201cstream_column\u201d parameter should have the\nstream column to download\/mount. So, you need to pass the column name\nthat contains the paths from which the data will be streamed.<br \/>\nPlease find an example <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-labeled-dataset#explore-labeled-datasets-via-pandas-dataframe\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1646484376340,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1648643627873,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71014584",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58301879,
        "Question_title":"Unable to upload statsmodels 0.9rc1 python package in Azure ML studio",
        "Question_body":"<p>I'm not able to upload statsmodels 0.9rc1 python package in Azure ML studio for Time series analysis.<\/p>\n\n<p>I have downloaded <a href=\"https:\/\/files.pythonhosted.org\/packages\/df\/6f\/df6cf5faecd8082ee23916ff45d396dfee5a1f17aa275da7bab4f5c8926a\/statsmodels-0.9.0rc1-cp36-cp36m-win_amd64.whl\" rel=\"nofollow noreferrer\">statsmodels 0.9rc1<\/a>, unzipped contents and added statsmodels folder and model.pkl file to zip folder.<\/p>\n\n<p>But, while uploading to Microsoft Azure ML studio it says <strong>failed to build schema and visualization<\/strong><\/p>\n\n<p>I'm using this external package in <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/execute-python-scripts\" rel=\"nofollow noreferrer\">Execute Python script<\/a><\/p>\n\n<p>PS: I have succesfully uploaded packages like Adal, dateutils etc.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1570616046857,
        "Question_score":2,
        "Question_tags":"python|azure|machine-learning|statsmodels|azure-machine-learning-studio",
        "Question_view_count":141,
        "Owner_creation_time":1548341556520,
        "Owner_last_access_time":1663921446773,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Owner_reputation":2907,
        "Owner_up_votes":354,
        "Owner_down_votes":2,
        "Owner_views":238,
        "Question_last_edit_time":1570619708227,
        "Answer_body":"<p>I have switched to Azure Jupyter Notebook where I installed package using pip<\/p>\n\n<pre><code>!pip install statsmodels==0.9.0rc1\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1573144655863,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58301879",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49818134,
        "Question_title":"how connect to Azure Machine Learning Web service using PowerShell?",
        "Question_body":"<p>To use Azure Machine Learning Web service <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/consume-web-services\" rel=\"nofollow noreferrer\">here<\/a> you can find some sample code in C#, R, Python and JavaScript. I want to use it in PowerShell.\nI found <a href=\"https:\/\/www.sepago.com\/blog\/2015\/11\/30\/zugriff-mit-powershell-auf-azure-machine-learning-api-azureml\" rel=\"nofollow noreferrer\">this<\/a> tutorial, but when I am running bellow line of code, it will return error that it is not recognized:<\/p>\n\n<pre><code>Set-AzureMLWebServiceConnection -URI $Url -APIKey $API_key\n\nOutput:\nSet-AzureMLWebServiceConnection : The term 'Set-AzureMLWebServiceConnection' is not recognized as the name of a cmdlet, function, script file, or operable \nprogram. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.\nAt C:\\Users\\Reza\\Desktop\\ndbench\\Azure\\Automation\\01_get_metrics\\add_target_to_tables - runbook_01.ps1:33 char:1\n+ Set-AzureMLWebServiceConnection -URI $Url -APIKey $API_key\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : ObjectNotFound: (Set-AzureMLWebServiceConnection:String) [], CommandNotFoundException\n    + FullyQualifiedErrorId : CommandNotFoundException\n<\/code><\/pre>\n\n<p>I can't found <code>Set-AzureMLWebServiceConnection<\/code> in my PowerShell command-list and I don't know how I can enable\/install it.\n<a href=\"https:\/\/i.stack.imgur.com\/YMso7.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YMso7.jpg\" alt=\"enter image description here\"><\/a>\nCan you please guide me, how I can connect to Azure Machine Learning Web service using PowerShell?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1523625908693,
        "Question_score":0,
        "Question_tags":"powershell|azure|azure-powershell|azure-machine-learning-studio",
        "Question_view_count":303,
        "Owner_creation_time":1433870950220,
        "Owner_last_access_time":1663930681917,
        "Owner_location":"Tehran, Iran",
        "Owner_reputation":1316,
        "Owner_up_votes":180,
        "Owner_down_votes":11,
        "Owner_views":201,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The comment @gvee mentioned may be the best to use going forward though it is in beta.<\/p>\n\n<p>However, to answer your question, use the <code>Install-Module -Name AzureML<\/code> <a href=\"https:\/\/www.powershellgallery.com\/packages\/AzureML\/1.0.1\" rel=\"nofollow noreferrer\">command<\/a> to get access to the Azure ML commands.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ZerMp.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZerMp.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1523724686213,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49818134",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71783228,
        "Question_title":"How do I specify nodeSelector while deploying an Azure ML model to an AKS Cluster?",
        "Question_body":"<p>I am currently deploying a model trained using AzureML to an AKS cluster as follows:<\/p>\n<pre><code>deployment_config_aks = AksWebservice.deploy_configuration(\n    cpu_cores = 1, \n    memory_gb = 1)\n\nservice = Model.deploy(ws, &quot;test&quot;, [model], inference_config, deployment_config_aks, aks_target)\n\n<\/code><\/pre>\n<p>I would like this service to be scheduled on a specific nodepool. With normal Kubernetes deployment, I can specify a <code>nodeSelector<\/code> like:<\/p>\n<pre><code>spec:\n  nodeSelector:\n    myNodeName: alpha\n<\/code><\/pre>\n<p>How do I specify a <code>nodeSelector<\/code> while deploying an Azure ML model to an AKS Cluster? Or in general, is there a way to merge my custom pod spec with the one generated by Azure ML library?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1649338837060,
        "Question_score":0,
        "Question_tags":"azure|azure-aks|azure-machine-learning-service",
        "Question_view_count":289,
        "Owner_creation_time":1338974093053,
        "Owner_last_access_time":1663927880003,
        "Owner_location":"Beijing, China",
        "Owner_reputation":1830,
        "Owner_up_votes":413,
        "Owner_down_votes":3,
        "Owner_views":155,
        "Question_last_edit_time":null,
        "Answer_body":"<blockquote>\n<p>How do I specify a nodeSelector while deploying an Azure ML model to an AKS Cluster? Or in general, is there a way to merge my custom pod spec with the one generated by Azure ML library?<\/p>\n<\/blockquote>\n<p>As per <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-attach-arc-kubernetes?tabs=studio\" rel=\"nofollow noreferrer\">Configure Kubernetes clusters for machine learning<\/a>:<\/p>\n<p><code>nodeSelector<\/code> : Set the node selector so the extension components and the training\/inference workloads will only be deployed to the nodes with all specified selectors.<\/p>\n<p>For example:<\/p>\n<p><code>nodeSelector.key=value<\/code> , <code>nodeSelector.node-purpose=worker<\/code> and <code>nodeSelector.node-region=eastus<\/code><\/p>\n<p>You can refer to <a href=\"https:\/\/kubernetes.io\/docs\/concepts\/scheduling-eviction\/assign-pod-node\/#built-in-node-labels\" rel=\"nofollow noreferrer\">Assigning Pods to Nodes<\/a> and <a href=\"https:\/\/github.com\/Azure\/AKS\/issues\/2866\" rel=\"nofollow noreferrer\">Cannot create nodepool with node-restriction.kubernetes.io\/ prefix label<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1650522075520,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71783228",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39941622,
        "Question_title":"Parallel *apply in Azure Machine Learning Studio",
        "Question_body":"<p>I have just started to get myself acquainted with parallelism in R. <\/p>\n\n<p>As I am planning to use <a href=\"https:\/\/studio.azureml.net\/\" rel=\"nofollow\">Microsoft Azure Machine Learning Studio<\/a> for my project, I have started investigating what <a href=\"https:\/\/mran.revolutionanalytics.com\/documents\/rro\/multithread\/\" rel=\"nofollow\">Microsoft R Open<\/a> offers for parallelism, and thus, I found <a href=\"https:\/\/mran.revolutionanalytics.com\/documents\/rro\/multithread\/\" rel=\"nofollow\">this<\/a>, in which it says that parallelism is done under the hood that leverages the benefit of all available cores, without changing the R code. The article also shows some performance benchmarks, however, most of them demonstrate the performance benefit in doing mathematical operations.<\/p>\n\n<p>This was good so far. In addition, I am also interested to know whether it also parallelize the <code>*apply<\/code> functions under the hood or not. I also found these 2 articles that describes how to parallelize <code>*apply<\/code> functions in general:<\/p>\n\n<ol>\n<li><a href=\"https:\/\/www.r-bloggers.com\/quick-guide-to-parallel-r-with-snow\/\" rel=\"nofollow\">Quick guide to parallel R with snow<\/a>: describes facilitating parallelism using <a href=\"https:\/\/cran.r-project.org\/web\/packages\/snow\/snow.pdf\" rel=\"nofollow\"><code>snow<\/code><\/a> package, <code>par*apply<\/code> function family, and <code>clusterExport<\/code>.<\/li>\n<li><a href=\"http:\/\/www.win-vector.com\/blog\/2016\/01\/parallel-computing-in-r\/\" rel=\"nofollow\">A gentle introduction to parallel computing in R<\/a>: using <code>parallel<\/code> package, <code>par*apply<\/code> function family, and binding values to environment.<\/li>\n<\/ol>\n\n<p>So my question is when I will be using <code>*apply<\/code> functions in Microsoft Azure Machine Learning Studio, will that be parallelized under the hood by default, or I need to make use of packages like <code>parallel<\/code>, <code>snow<\/code> etc.?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1476002256777,
        "Question_score":1,
        "Question_tags":"r|parallel-processing|azure-machine-learning-studio|microsoft-r",
        "Question_view_count":501,
        "Owner_creation_time":1365684640140,
        "Owner_last_access_time":1664014410763,
        "Owner_location":"Paderborn, Germany",
        "Owner_reputation":4588,
        "Owner_up_votes":1194,
        "Owner_down_votes":3,
        "Owner_views":453,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Personally, I think we could have marketed MRO a bit differently, without making such a big deal about parallelism\/multithreading. Ah well.<\/p>\n\n<p>R comes with an Rblas.dll\/.so which implements the routines used for linear algebra computations. These routines are used in various places, but one common use case is for fitting regression models. With MRO, we replace the standard Rblas with one that uses the <a href=\"https:\/\/software.intel.com\/en-us\/intel-mkl\" rel=\"noreferrer\">Intel Math Kernel Library<\/a>. When you call a function like <code>lm<\/code> or <code>glm<\/code>, MRO will use multiple threads and optimized CPU instructions to fit the model, which can get you dramatic speedups over the standard implementation.<\/p>\n\n<p>MRO isn't the only way you can get this sort of speedup; you can also compile\/download other BLAS implementations that are similarly optimized. We just make it an easy one-step download.<\/p>\n\n<p>Note that the MKL only affects code that involves linear algebra. It isn't a general-purpose speedup tool; any R code that doesn't do matrix computations won't see a performance improvement. In particular, it won't speed up any code that involves <em>explicit<\/em> parallelism, such as code using the parallel package, SNOW, or other cluster computing tools.<\/p>\n\n<p>On the other hand, it won't <em>degrade<\/em> them either. You can still use packages like parallel, SNOW, etc to create compute clusters and distribute your code across multiple processes. MRO works just like regular CRAN R in this respect. (One thing you might want to do, though, if you're creating a cluster of nodes on the one machine, is reduce the number of MKL threads. Otherwise you risk contention between the nodes for CPU cores, which will degrade performance.)<\/p>\n\n<p>Disclosure: I work for Microsoft.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1476024698777,
        "Answer_score":5.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39941622",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34545078,
        "Question_title":"Azure ML vs Cortana Analytics Suite",
        "Question_body":"<p>I am wondering what is the difference between Cortana Analytics and Azure ML ?<\/p>\n\n<ul>\n<li>those are 2 distincts solutions ? <\/li>\n<li>one is part of the other ?<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1451558192573,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-studio|cortana-intelligence",
        "Question_view_count":1150,
        "Owner_creation_time":1425637780190,
        "Owner_last_access_time":1605735689050,
        "Owner_location":null,
        "Owner_reputation":559,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":18,
        "Question_last_edit_time":1543674264230,
        "Answer_body":"<p>Azure Machine Learning is part of the Cortana analytics suite<\/p>\n\n<p>You will find more info with the link below<\/p>\n\n<p><a href=\"http:\/\/www.sqlchick.com\/entries\/2015\/8\/22\/what-is-the-cortana-analytics-suite\" rel=\"nofollow\">All the details on the Cortana link here<\/a><\/p>\n\n<p>All the best<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1451558834643,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1457447097077,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34545078",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":35304901,
        "Question_title":"Azure Machine Learning Reader + Table Storage",
        "Question_body":"<p>Duplicating: <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/6560c2d6-9836-41a1-8076-caf0d514222a\/azure-machine-learning-reader-table-storage?forum=MachineLearning\" rel=\"nofollow\">https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/6560c2d6-9836-41a1-8076-caf0d514222a\/azure-machine-learning-reader-table-storage?forum=MachineLearning<\/a><\/p>\n\n<p>I currently have a table storage setup which is constantly performing insertions. There is approximately 260 million rows in the table storage. <\/p>\n\n<p>I have set up two machine learning experiments to use a 'Reader' to read the data from the 'Azure Table'. <\/p>\n\n<p>Experiment 1 is set to read all the rows to train the model.<\/p>\n\n<p>Experiment 2 is set to read only the top 1,000 rows to train the model.<\/p>\n\n<p>Experiment 1 has been running for over 5 hours with no results.<\/p>\n\n<p>Experiment 2 has been running for over 1 hour with no results.<\/p>\n\n<p>It is stuck on the 'Reader' process.<\/p>\n\n<p>I do not understand why experiment 2 is taking so long. I know I have set this up right as I tested the 'Reader's with another table storage. Thanks in advance for any help\/suggestions.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1455064585877,
        "Question_score":0,
        "Question_tags":"azure|azure-table-storage|azure-machine-learning-studio",
        "Question_view_count":104,
        "Owner_creation_time":1373050450247,
        "Owner_last_access_time":1663971630963,
        "Owner_location":null,
        "Owner_reputation":498,
        "Owner_up_votes":24,
        "Owner_down_votes":0,
        "Owner_views":47,
        "Question_last_edit_time":null,
        "Answer_body":"<p>A lot of this will probably depend on the design of your tables. Table Storage is a key \/ value store (think of it as a dictionary). It has some capabilities for scanning within a partition and across partitions - but the latencies will differ greatly. Ideally if you want to query 1000 rows they should be localized within a partition. See <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/storage-table-design-guide\/\" rel=\"nofollow\">Table Design Guide<\/a> and <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/storage-performance-checklist\/\" rel=\"nofollow\">Perf and Scalability Checklist<\/a> for full details.  <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1455137464833,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/35304901",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":59881727,
        "Question_title":"Debugging R Scripts in azure-ml: Where can stdout and stderr logs be found? (or why are they empty?)",
        "Question_body":"<p>I'm using \"studio (preview)\" from Microsoft Azure Machine Learning to create a pipeline that applies machine learning to a dataset in a blob storage that is connected to our data warehouse.<\/p>\n\n<p>In the \"Designer\", an \"Exectue R Script\" action can be added to the pipeline. I'm using this functionality to execute some of my own machine learning algorithms.<\/p>\n\n<p>I've got a 'hello world' version of this script working (including using the \"script bundle\" to load the functions in my own R files). It applies a very simple manipulation (compute the days difference with the date in the date column and 'today'), and stores the output as a new file. Given that the exported file has the correct information, I know that the R script works well.<\/p>\n\n<p>The script looks like this:<\/p>\n\n<pre><code># R version: 3.5.1\n# The script MUST contain a function named azureml_main\n# which is the entry point for this module.\n\n# The entry point function can contain up to two input arguments:\n#   Param&lt;medals&gt;: a R DataFrame\n#   Param&lt;matches&gt;: a R DataFrame\n\nazureml_main &lt;- function(dataframe1, dataframe2){\n\n  message(\"STARTING R script run.\")\n\n  # If a zip file is connected to the third input port, it is\n  # unzipped under \".\/Script Bundle\". This directory is added\n  # to sys.path.\n\n  message('Adding functions as source...')\n\n  if (FALSE) {\n    # This works...\n      source(\".\/Script Bundle\/first_function_for_script_bundle.R\")\n  } else {\n    # And this works as well!\n    message('Sourcing all available functions...')\n    functions_folder = '.\/Script Bundle'\n\n    list.files(path = functions_folder)\n    list_of_R_functions &lt;- list.files(path = functions_folder, pattern = \"^.*[Rr]$\", include.dirs = FALSE, full.names = TRUE)\n    for (fun in list_of_R_functions) {\n\n      message(sprintf('Sourcing &lt;%s&gt;...', fun))\n\n      source(fun)\n\n    }\n  }\n\n  message('Executing R pipeline...')\n  dataframe1 = calculate_days_difference(dataframe = dataframe1)\n\n  # Return datasets as a Named List\n  return(list(dataset1=dataframe1, dataset2=dataframe2))\n}\n<\/code><\/pre>\n\n<p>And although I do print some messages in the R Script, I haven't been able to find the \"stdoutlogs\" nor the \"stderrlogs\" that should contain these printed messages.<\/p>\n\n<p>I need the printed messages for 1) information on how the analysis went and -most importantly- 2) debugging in case the code failed.<\/p>\n\n<p>Now, I have found (on multiple locations) the files \"stdoutlogs.txt\" and \"stderrlogs.txt\". These can be found under \"Logs\" when I click on \"Exectue R Script\" in the \"Designer\".\nI can also find \"stdoutlogs.txt\" and \"stderrlogs.txt\" files under \"Experiments\" when I click on a finished \"Run\" and then both under the tab \"Outputs\" and under the tab \"Logs\".\nHowever... all of these files are empty.<\/p>\n\n<p>Can anyone tell me how I can print messages from my R Script and help me locate where I can find the printed information?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1579792546180,
        "Question_score":1,
        "Question_tags":"r|azure|machine-learning|rstudio|azure-machine-learning-service",
        "Question_view_count":287,
        "Owner_creation_time":1534511592567,
        "Owner_last_access_time":1663852418420,
        "Owner_location":"Netherlands",
        "Owner_reputation":423,
        "Owner_up_votes":15,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Can you please click on the \"Execute R module\" and download the 70_driver.log? I tried message(\"STARTING R script run.\") in an R sample and can found the output there.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Z7s7h.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Z7s7h.png\" alt=\"view logs for a execute R script module\"><\/a><\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_time":1579829908723,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1579846977960,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59881727",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58885873,
        "Question_title":"Is it possible to use DistributedDataParallel with PyTorch Estimator",
        "Question_body":"<p>We know that Horovod is suppported. Is there an example script which uses DistributedDataParallel and Pytorch estimator?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1573859552880,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":98,
        "Owner_creation_time":1488866265607,
        "Owner_last_access_time":1638567942300,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You should be able to specify nccl or gloo as distributed data parallel backend, in addition to MPI with Horovod. See the <em>distributed_training<\/em> parameter of <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.dnn.pytorch?view=azure-ml-py\" rel=\"nofollow noreferrer\">PyTorch Estimator<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1574100412503,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58885873",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":32252282,
        "Question_title":"Where does AzureML run its analytics?",
        "Question_body":"<p>If I have data in a Hadoop Cluster or SQL Elastic DB, is ML bringing that data onto ML servers, or leaving it on Hadoop\/sql and running its analysis there?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1440686059093,
        "Question_score":0,
        "Question_tags":"azure|bigdata|azure-machine-learning-studio",
        "Question_view_count":82,
        "Owner_creation_time":1384802035143,
        "Owner_last_access_time":1663094482000,
        "Owner_location":"Miami Beach, FL",
        "Owner_reputation":2682,
        "Owner_up_votes":75,
        "Owner_down_votes":4,
        "Owner_views":1006,
        "Question_last_edit_time":1440686537417,
        "Answer_body":"<p>Currently, Azure Machine Learning will bring that data onto ML servers.  <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1440686498027,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/32252282",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58691120,
        "Question_title":"Metric Document is too large in Azure ML Service",
        "Question_body":"<p>I am trying to save metrics : loss, validation loss and mAP at every epoch during 100 and 50 epochs but at the end of the experiment I have this error: \nRun failed: RunHistory finalization failed: ServiceException: Code: 400 Message: (ValidationError) Metric Document is too large<\/p>\n\n<p>I am using this code to save the metrics<\/p>\n\n<pre><code>run.log_list(\"loss\", history.history[\"loss\"])\nrun.log_list(\"val_loss\", history.history[\"val_loss\"])\nrun.log_list(\"val_mean_average_precision\", history.history[\"val_mean_average_precision\"])\n<\/code><\/pre>\n\n<p>I don't understand why trying to save only 3 metrics exceeds the limits of Azure ML Service.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_time":1572862036240,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-service",
        "Question_view_count":368,
        "Owner_creation_time":1488384135020,
        "Owner_last_access_time":1663838517883,
        "Owner_location":"Paris, France",
        "Owner_reputation":620,
        "Owner_up_votes":589,
        "Owner_down_votes":5,
        "Owner_views":54,
        "Question_last_edit_time":1572863952217,
        "Answer_body":"<p>You could break the run history list writes into smaller blocks like this:<\/p>\n\n<pre><code>run.log_list(\"loss\", history.history[\"loss\"][:N])\nrun.log_list(\"loss\", history.history[\"loss\"][N:])\n<\/code><\/pre>\n\n<p>Internally, the run history service concatenates the blocks with same metric name into a contiguous list.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1572880035733,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58691120",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72641789,
        "Question_title":"Azure Machine Learning workspace's storage account permission issue",
        "Question_body":"<p>Was working on az ml cli v2 to deploy real-time endpoint with command <code>az ml online-deployment<\/code> through Azure pipeline. had double confirmed that the service connection used in this pipeline task had added the permissions below in Azure Portal but still showing the same error.<\/p>\n<pre><code>ERROR: Error with code: You don't have permission to alter this storage account. Ensure that you have been assigned both Storage Blob Data Reader and Storage Blob Data Contributor roles.\n<\/code><\/pre>\n<p>Using the same service connection, we are able to perform the creation of online endpoint with <code>az ml online-endpoint create<\/code> in the same and other workspaces.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1655363403560,
        "Question_score":0,
        "Question_tags":"azure-devops|azure-storage|azure-machine-learning-service",
        "Question_view_count":129,
        "Owner_creation_time":1568185673007,
        "Owner_last_access_time":1663257666153,
        "Owner_location":"Kuala Lumpur, Federal Territory of Kuala Lumpur, Malaysia",
        "Owner_reputation":383,
        "Owner_up_votes":70,
        "Owner_down_votes":1,
        "Owner_views":35,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Issue was resolved. I did not change anything in the service principal and running it on second day using same yml got through the issue. I guess there might be some propagation issue, but longer than usual.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1655429828623,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72641789",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50219664,
        "Question_title":"Azure ML Experiment Batch Webservice Call Fails with Invalid Output Extension",
        "Question_body":"<p>I have an Azure webjob that is calling a ML training experiment via HttpRequests, leveraging the code generated in the ML webportal:<\/p>\n\n<pre><code>var request = new BatchExecutionRequest()\n            {\n                Inputs = new Dictionary&lt;string, AzureBlobDataReference&gt;() {\n                    {\n                        \"input1\",\n                        new AzureBlobDataReference()\n                        {\n                            ConnectionString = _connectionString,\n                            RelativeLocation = $\"{_containerName}\/{experimentId}\/{tenantId}\/{trainingDataFileName}\"\n                        }\n                    },\n                },\n\n                Outputs = new Dictionary&lt;string, AzureBlobDataReference&gt;() {\n                    {\n                        \"output1\",\n                        new AzureBlobDataReference()\n                        {\n                            ConnectionString = \"azureStorageConnectionString\",\n                            RelativeLocation = $\"{_containerName}\/{experimentId}\/{tenantId}\/Model_2018421.ilearner\"\n                        }\n                    },\n                },\n\n                GlobalParameters = new Dictionary&lt;string, string&gt;()\n                {\n                }\n            };\n<\/code><\/pre>\n\n<p>However, the request fails with the following message:<\/p>\n\n<blockquote>\n  <p>The blob reference:\n  experiments\/experimentId\/TenantId\/Model_2018421.ilearner\n  has an invalid or missing file extension. Supported file extensions\n  for this output type are: \\\\\".csv, .tsv, .arff\\\\\"<\/p>\n<\/blockquote>\n\n<p>I'm pretty confused about this, since it's written right the documentation all over the place that if I'm expecting a trained model to use \".ilearner\" as the file extension for the model.<\/p>\n\n<p>I've seen <a href=\"https:\/\/stackoverflow.com\/questions\/47920098\/use-azure-data-factory-updating-azure-machine-learning-models\">this question<\/a> asking about the same error leveraging the DataFactory, and also <a href=\"https:\/\/datascience.stackexchange.com\/questions\/27397\/azure-machine-learning-model-retraining-problem\">this question on datascience.stackexchange<\/a>. Neither one had any clues, answers, or other follow up.<\/p>\n\n<p>Any insight on what I'm missing would be greatly appreciated!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1525714637430,
        "Question_score":0,
        "Question_tags":"c#|rest|azure|azure-machine-learning-studio",
        "Question_view_count":83,
        "Owner_creation_time":1477057589223,
        "Owner_last_access_time":1663770639160,
        "Owner_location":"Columbus, OH, United States",
        "Owner_reputation":547,
        "Owner_up_votes":1387,
        "Owner_down_votes":1,
        "Owner_views":45,
        "Question_last_edit_time":null,
        "Answer_body":"<p>For anyone looking for your \"Don't Overthink It\" moment of the day:<\/p>\n\n<p>I needed to provide TWO output blob file references:<\/p>\n\n<pre><code>var request = new BatchExecutionRequest()\n            {\n                Inputs = new Dictionary&lt;string, AzureBlobDataReference&gt;() {\n                    {\n                        \"input1\",\n                        new AzureBlobDataReference()\n                        {\n                            ConnectionString = _connectionString,\n                            RelativeLocation = $\"{_containerName}\/{experimentId}\/{tenantId}\/{trainingDataFileName}.csv\"\n                        }\n                    },\n                },\n\n                Outputs = new Dictionary&lt;string, AzureBlobDataReference&gt;() {\n                    {\n                        \"output1\",\n                        new AzureBlobDataReference()\n                        {\n                            ConnectionString = _connectionString,\n                            RelativeLocation = $\"{_containerName}\/{experimentId}\/{tenantId}\/{outputFileNameCsv}.csv\"\n                        }\n                    },\n                    {\n                        \"output2\",\n                        new AzureBlobDataReference()\n                        {\n                            ConnectionString = _connectionString,\n                            RelativeLocation = $\"{_containerName}\/{experimentId}\/{tenantId}\/{outputFileNameIlearner}.ilearner\"\n                        }\n                    },\n                },\n\n                GlobalParameters = new Dictionary&lt;string, string&gt;()\n                {\n                }\n            };\n<\/code><\/pre>\n\n<p>There's an old saying in American English about not making assumptions, and I assumed the second output was an optional parameter used in batch operations. Since I'm not actually looking for more than one result from each call, I thought I was safe to remove the second output parameter.<\/p>\n\n<p>TL\/DR: Keep all the parameters the webservice portal's \"Consume\" tab generates, and make sure the first one is a .csv file reference.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1525787996893,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50219664",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":26193051,
        "Question_title":"Replacing specific values in dataset with Azure ML",
        "Question_body":"<p>Lately i've been testing Azure Machine Learning, and i like it. However, when i try to transform my dataset, there's a step that i can't perform easily : replacing a specific value in a column by another one.<\/p>\n\n<p>The <code>Missing Values Scrubber<\/code> module allows me to deal with undefined values, but in my case i need to change a specific value, or remove rows where that value appears. I don't see which module meets my requirement.<\/p>\n\n<p>Do you have any suggestion about this issue ? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1412427424453,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":3772,
        "Owner_creation_time":1345114008840,
        "Owner_last_access_time":1495626547660,
        "Owner_location":"Lyon, France",
        "Owner_reputation":4233,
        "Owner_up_votes":67,
        "Owner_down_votes":1,
        "Owner_views":151,
        "Question_last_edit_time":1446191259743,
        "Answer_body":"<p>I found a solution <a href=\"http:\/\/social.msdn.microsoft.com\/Forums\/en-US\/bf8f76c7-f976-4552-8553-8e54133ff2c6\/replacing-specific-values-in-dataset-with-azure-ml?forum=MachineLearning\" rel=\"nofollow\">there<\/a>, by using a <code>Convert to Dataset<\/code> module.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1412637208267,
        "Answer_score":4.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/26193051",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64315239,
        "Question_title":"Azure ML Inference Schema - \"List index out of range\" error",
        "Question_body":"<p>I have an ML model deployed on Azure ML Studio and I was updating it with an inference schema to allow compatibility with Power BI as described <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<p>When sending data up to the model via REST api (before adding this inference schema), everything works fine and I get results returned. However, once adding the schema as described in the instructions linked above and personalising to my data, the same data sent via REST api only returns the error &quot;list index out of range&quot;. The deployment goes ahead fine and is designated as &quot;healthy&quot; with no error messages.<\/p>\n<p>Any help would be greatly appreciated. Thanks.<\/p>\n<p>EDIT:<\/p>\n<p>Entry script:<\/p>\n<pre><code> import numpy as np\n import pandas as pd\n import joblib\n from azureml.core.model import Model\n    \n from inference_schema.schema_decorators import input_schema, output_schema\n from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n    \n def init():\n     global model\n     #Model name is the name of the model registered under the workspace\n     model_path = Model.get_model_path(model_name = 'databricksmodelpowerbi2')\n     model = joblib.load(model_path)\n    \n #Provide 3 sample inputs for schema generation for 2 rows of data\n numpy_sample_input = NumpyParameterType(np.array([[2400.0, 78.26086956521739, 11100.0, 3.612565445026178, 3.0, 0.0], [368.55, 96.88311688311687, 709681.1600000012, 73.88059701492537, 44.0, 0.0]], dtype = 'float64'))\n pandas_sample_input = PandasParameterType(pd.DataFrame({'1': [2400.0, 368.55], '2': [78.26086956521739, 96.88311688311687], '3': [11100.0, 709681.1600000012], '4': [3.612565445026178, 73.88059701492537], '5': [3.0, 44.0], '6': [0.0, 0.0]}))\n standard_sample_input = StandardPythonParameterType(0.0)\n    \n # This is a nested input sample, any item wrapped by `ParameterType` will be described by schema\n sample_input = StandardPythonParameterType({'input1': numpy_sample_input, \n                                             'input2': pandas_sample_input, \n                                             'input3': standard_sample_input})\n    \n sample_global_parameters = StandardPythonParameterType(1.0) #this is optional\n sample_output = StandardPythonParameterType([1.0, 1.0])\n    \n @input_schema('inputs', sample_input)\n @input_schema('global_parameters', sample_global_parameters) #this is optional\n @output_schema(sample_output)\n    \n def run(inputs, global_parameters):\n     try:\n         data = inputs['input1']\n         # data will be convert to target format\n         assert isinstance(data, np.ndarray)\n         result = model.predict(data)\n         return result.tolist()\n     except Exception as e:\n         error = str(e)\n         return error\n<\/code><\/pre>\n<p>Prediction script:<\/p>\n<pre><code> import requests\n import json\n from ast import literal_eval\n    \n # URL for the web service\n scoring_uri = ''\n ## If the service is authenticated, set the key or token\n #key = '&lt;your key or token&gt;'\n    \n # Two sets of data to score, so we get two results back\n data = {&quot;data&quot;: [[2400.0, 78.26086956521739, 11100.0, 3.612565445026178, 3.0, 0.0], [368.55, 96.88311688311687, 709681.1600000012, 73.88059701492537, 44.0, 0.0]]}\n # Convert to JSON string\n input_data = json.dumps(data)\n    \n # Set the content type\n headers = {'Content-Type': 'application\/json'}\n ## If authentication is enabled, set the authorization header\n #headers['Authorization'] = f'Bearer {key}'\n    \n # Make the request and display the response\n resp = requests.post(scoring_uri, input_data, headers=headers)\n print(resp.text)\n    \n result = literal_eval(resp.text)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1602495267847,
        "Question_score":1,
        "Question_tags":"azure|powerbi|schema|endpoint|azure-machine-learning-studio",
        "Question_view_count":785,
        "Owner_creation_time":1600260166047,
        "Owner_last_access_time":1615561616230,
        "Owner_location":null,
        "Owner_reputation":15,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":1615561798207,
        "Answer_body":"<p>The Microsoft <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#power-bi-compatible-endpoint\" rel=\"nofollow noreferrer\">documentation<\/a> say's: &quot;In order to generate conforming swagger for automated web service consumption, scoring script run() function must have API shape of:<\/p>\n<blockquote>\n<p>A first parameter of type &quot;StandardPythonParameterType&quot;, named\n<strong>Inputs<\/strong> and nested.<\/p>\n<p>An optional second parameter of type &quot;StandardPythonParameterType&quot;,\nnamed GlobalParameters.<\/p>\n<p>Return a dictionary of type &quot;StandardPythonParameterType&quot; named\n<strong>Results<\/strong> and nested.&quot;<\/p>\n<\/blockquote>\n<p>I've already test this and it is case sensitive\nSo it will be like this:<\/p>\n<pre><code>import numpy as np\nimport pandas as pd\nimport joblib\n\nfrom azureml.core.model import Model\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.standard_py_parameter_type import \n    StandardPythonParameterType\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n\ndef init():\n    global model\n    # Model name is the name of the model registered under the workspace\n    model_path = Model.get_model_path(model_name = 'databricksmodelpowerbi2')\n    model = joblib.load(model_path)\n\n# Provide 3 sample inputs for schema generation for 2 rows of data\nnumpy_sample_input = NumpyParameterType(np.array([[2400.0, 78.26086956521739, 11100.0, \n3.612565445026178, 3.0, 0.0], [368.55, 96.88311688311687, 709681.1600000012, \n73.88059701492537, 44.0, 0.0]], dtype = 'float64'))\n\npandas_sample_input = PandasParameterType(pd.DataFrame({'value': [2400.0, 368.55], \n'delayed_percent': [78.26086956521739, 96.88311688311687], 'total_value_delayed': \n[11100.0, 709681.1600000012], 'num_invoices_per30_dealing_days': [3.612565445026178, \n73.88059701492537], 'delayed_streak': [3.0, 44.0], 'prompt_streak': [0.0, 0.0]}))\n\nstandard_sample_input = StandardPythonParameterType(0.0)\n\n# This is a nested input sample, any item wrapped by `ParameterType` will be described \nby schema\nsample_input = StandardPythonParameterType({'input1': numpy_sample_input, \n                                         'input2': pandas_sample_input, \n                                         'input3': standard_sample_input})\n\nsample_global_parameters = StandardPythonParameterType(1.0) #this is optional\n\nnumpy_sample_output = NumpyParameterType(np.array([1.0, 2.0]))\n\n# 'Results' is case sensitive\nsample_output = StandardPythonParameterType({'Results': numpy_sample_output})\n\n# 'Inputs' is case sensitive\n@input_schema('Inputs', sample_input)\n@input_schema('global_parameters', sample_global_parameters) #this is optional\n@output_schema(sample_output)\ndef run(Inputs, global_parameters):\n    try:\n        data = inputs['input1']\n        # data will be convert to target format\n        assert isinstance(data, np.ndarray)\n        result = model.predict(data)\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n<\/code><\/pre>\n<p>`<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1614800344830,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1614801695373,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64315239",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":51702359,
        "Question_title":"In Azure ML Studio, score model doesn't return predicted values from an R model",
        "Question_body":"<p>I built a multiclass SVM model in R and used Create R model module from azure to train and predict my testing dataset. Here are the trainer and the score R scripts.<\/p>\n\n<p><strong>Trainer R script:<\/strong> <\/p>\n\n<pre><code>library(e1071)\nfeatures &lt;- get.feature.columns(dataset)\nlabels   &lt;- as.factor(get.label.column(dataset))\ntrain.data &lt;- data.frame(features, labels)\nfeature.names &lt;- get.feature.column.names(dataset)\nnames(train.data) &lt;- c(feature.names, \"Class\")\nmodel &lt;- svm(Class ~ . , train.data)\n<\/code><\/pre>\n\n<p><strong>Scores R script:<\/strong><\/p>\n\n<pre><code>library(e1071)    \nclasses &lt;- predict(model, dataset)\nclasses &lt;- as.factor(classes)\nres &lt;- data.frame(classes, probabilities = 0.5)\nprint(str(res))\nprint(res)\nscores &lt;- res\n<\/code><\/pre>\n\n<p>Note in my code, I hardcoded the probability values to simplify the code.<\/p>\n\n<p>Here is my component design in Azure: <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/hjMC4.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/hjMC4.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When I run the experiment, all the components work fine. However, in the score model, the scored dataset port does not show the predicted values. It only shows feature values from the testing dataset. I checked the output log of <em>Score model<\/em> and I could see the model has nicely predicted the testing data (note I added print commands in the Scores R script). But this is not enough and I need the prediction returned from the score model so I can pass it via API.<\/p>\n\n<p>Has anyone faced this issue before?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1533539693247,
        "Question_score":0,
        "Question_tags":"r|azure|azure-machine-learning-studio|ml-studio",
        "Question_view_count":657,
        "Owner_creation_time":1501114346137,
        "Owner_last_access_time":1605792960497,
        "Owner_location":"Australia",
        "Owner_reputation":37,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Question_last_edit_time":1533560847647,
        "Answer_body":"<p>I found an answer for this. In fact, I cannot see the result in the outcome of the scoring model but when I linked it to a <em>select column in the dataset<\/em> module, I see the predicted columns there.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1534294797823,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51702359",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58816515,
        "Question_title":"Databricks UDF calling an external web service cannot be serialised (PicklingError)",
        "Question_body":"<p>I am using Databricks and have a column in a dataframe that I need to update for every record with an external web service call. In this case it is using the Azure Machine Learning Service SDK and does a service call. This code works fine when not run as a UDF in spark (ie. just python) however it throws a serialization error when I try to call it as a UDF. The same happens if I use a lambda and a map with an rdd.<\/p>\n\n<p>The model uses fastText and can be invoked fine from Postman or python via a normal http call or using the WebService SDK from AMLS - it's just when it is a UDF that it fails with this message:<\/p>\n\n<p>TypeError: can't pickle _thread._local objects<\/p>\n\n<p>The only workaround I can think of is to loop through each record in the dataframe sequentially and update the record with a call, however this is not very efficient. I don't know if this is a spark error or because the service is loading a fasttext model. When I use the UDF and mock a return value it works though.<\/p>\n\n<p>Error at bottom...<\/p>\n\n<pre><code>from azureml.core.webservice import Webservice, AciWebservice\nfrom azureml.core import Workspace\n\ndef predictModelValue2(summary, modelName, modelLabel):  \n    raw_data = '[{\"label\": \"' + modelLabel + '\", \"model\": \"' + modelName + '\", \"as_full_account\": \"' + summary + '\"}]'\n    prediction = service.run(raw_data)\n    return prediction\n\nfrom pyspark.sql.types import FloatType\nfrom pyspark.sql.functions import udf\n\npredictModelValueUDF = udf(predictModelValue2)\n\nDVIRCRAMFItemsDFScored1 = DVIRCRAMFItemsDF.withColumn(\"Result\", predictModelValueUDF(\"Summary\", \"ModelName\", \"ModelLabel\"))\n<\/code><\/pre>\n\n<blockquote>\n  <p>TypeError: can't pickle _thread._local objects<\/p>\n  \n  <p>During handling of the above exception, another exception occurred:<\/p>\n  \n  <p>PicklingError                             Traceback (most recent call\n  last)  in \n  ----> 2 x = df.withColumn(\"Result\", predictModelValueUDF(\"Summary\",\n  \"ModelName\", \"ModelLabel\"))<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in wrapper(*args)\n      194         @functools.wraps(self.func, assigned=assignments)\n      195         def wrapper(*args):\n  --> 196             return self(*args)\n      197 \n      198         wrapper.<strong>name<\/strong> = self._name<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in <strong>call<\/strong>(self, *cols)\n      172 \n      173     def <strong>call<\/strong>(self, *cols):\n  --> 174         judf = self._judf\n      175         sc = SparkContext._active_spark_context\n      176         return Column(judf.apply(_to_seq(sc, cols, _to_java_column)))<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in _judf(self)\n      156         # and should have a minimal performance impact.\n      157         if self._judf_placeholder is None:\n  --> 158             self._judf_placeholder = self._create_judf()\n      159         return self._judf_placeholder\n      160 <\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in _create_judf(self)\n      165         sc = spark.sparkContext\n      166 \n  --> 167         wrapped_func = _wrap_function(sc, self.func, self.returnType)\n      168         jdt = spark._jsparkSession.parseDataType(self.returnType.json())\n      169         judf = sc._jvm.org.apache.spark.sql.execution.python.UserDefinedPythonFunction(<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/sql\/udf.py in _wrap_function(sc,\n  func, returnType)\n       33 def _wrap_function(sc, func, returnType):\n       34     command = (func, returnType)\n  ---> 35     pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)\n       36     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n       37                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/rdd.py in _prepare_for_python_RDD(sc,\n  command)    2461     # the serialized command will be compressed by\n  broadcast    2462     ser = CloudPickleSerializer()\n  -> 2463     pickled_command = ser.dumps(command)    2464     if len(pickled_command) >\n  sc._jvm.PythonUtils.getBroadcastThreshold(sc._jsc):  # Default 1M<br>\n  2465         # The broadcast will have same life cycle as created\n  PythonRDD<\/p>\n  \n  <p>\/databricks\/spark\/python\/pyspark\/serializers.py in dumps(self, obj)\n      709                 msg = \"Could not serialize object: %s: %s\" % (e.<strong>class<\/strong>.<strong>name<\/strong>, emsg)\n      710             cloudpickle.print_exec(sys.stderr)\n  --> 711             raise pickle.PicklingError(msg)\n      712 \n      713 <\/p>\n  \n  <p>PicklingError: Could not serialize object: TypeError: can't pickle\n  _thread._local objects<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1573553894003,
        "Question_score":1,
        "Question_tags":"pyspark|user-defined-functions|pickle|azure-databricks|azure-machine-learning-service",
        "Question_view_count":931,
        "Owner_creation_time":1256089885500,
        "Owner_last_access_time":1663046676847,
        "Owner_location":"Sydney, Australia",
        "Owner_reputation":4947,
        "Owner_up_votes":277,
        "Owner_down_votes":8,
        "Owner_views":531,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I am not expert in DataBricks or Spark, but pickling functions from the local notebook context is always problematic when you are touching complex objects like the <code>service<\/code> object. In this particular case, I would recommend removing the dependency on the azureML <code>service<\/code> object and just use <code>requests<\/code> to call the service. <\/p>\n\n<p>Pull the key from the service:<\/p>\n\n<pre><code># retrieve the API keys. two keys were generated.\nkey1, key2 = service.get_keys()\nscoring_uri = service.scoring_uri\n<\/code><\/pre>\n\n<p>You should be able to use these strings in the UDF directly without pickling issues -- <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/9233ce089afb81d466076e36e7e61c3ce4cfafec\/how-to-use-azureml\/ml-frameworks\/chainer\/deployment\/train-hyperparameter-tune-deploy-with-chainer\/train-hyperparameter-tune-deploy-with-chainer.ipynb\" rel=\"nofollow noreferrer\">here is an example<\/a> of  how you would call the service with just requests. Below applied to your UDF:<\/p>\n\n<pre><code>import requests, json\ndef predictModelValue2(summary, modelName, modelLabel):  \n  input_data = json.dumps({\"summary\": summary, \"modelName\":, ....})\n\n  headers = {'Content-Type':'application\/json', 'Authorization': 'Bearer ' + key1}\n\n  # call the service for scoring\n  resp = requests.post(scoring_uri, input_data, headers=headers)\n\n  return resp.text[1]\n\n<\/code><\/pre>\n\n<p>On a side node, though: your UDF will be called for each row in your data frame and each time it will make a network call -- that will be very slow. I would recommend looking for ways to batch the execution. As you can see from your constructed json <code>service.run<\/code> will accept an array of items, so you should call it in batches of 100s or so.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1573841167917,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1573844785320,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58816515",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60637170,
        "Question_title":"How to pass arguments to scoring file when deploying a Model in AzureML",
        "Question_body":"<p>I am deploying a trained model to an ACI endpoint on Azure Machine Learning, using the Python SDK.\nI have created my score.py file, but I would like that file to be called with an argument being passed (just like with a training file) that I can interpret using <code>argparse<\/code>.\nHowever, I don't seem to find how I can pass arguments\nThis is the code I have to create the InferenceConfig environment and which obviously does not work.  Should I fall back on using the extra Docker file steps or so?<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.environment import Environment\nfrom azureml.core.model import InferenceConfig\n\nenv = Environment('my_hosted_environment')\nenv.python.conda_dependencies = CondaDependencies.create(\n    conda_packages=['scikit-learn'],\n    pip_packages=['azureml-defaults'])\nscoring_script = 'score.py --model_name ' + model_name\ninference_config = InferenceConfig(entry_script=scoring_script, environment=env)\n<\/code><\/pre>\n\n<p>Adding the score.py for reference on how I'd love to use the arguments in that script:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>#removed imports\nimport argparse\n\ndef init():\n    global model\n\n    parser = argparse.ArgumentParser(description=\"Load sklearn model\")\n    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n    args, _ = parser.parse_known_args()\n\n    model_path = Model.get_model_path(model_name=args.model_name)\n    model = joblib.load(model_path)\n\ndef run(raw_data):\n    try:\n        data = json.loads(raw_data)['data']\n        data = np.array(data)\n        result = model.predict(data)\n        return result.tolist()\n\n    except Exception as e:\n        result = str(e)\n        return result\n<\/code><\/pre>\n\n<p>Interested to hear your thoughts<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_creation_time":1583933260433,
        "Question_score":4,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":1681,
        "Owner_creation_time":1360655430743,
        "Owner_last_access_time":1663784892907,
        "Owner_location":"Belgium",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Question_last_edit_time":1584005920357,
        "Answer_body":"<p>How to deploy using environments can be found here <a href=\"https:\/\/nam06.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fgithub.com%2FAzure%2FMachineLearningNotebooks%2Fblob%2Fmaster%2Fhow-to-use-azureml%2Fdeployment%2Fdeploy-to-cloud%2Fmodel-register-and-deploy.ipynb&amp;data=02%7C01%7CRamprasad.Mula%40microsoft.com%7Ce06d310b0447416ab46b08d7bc836a81%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637185146436156499&amp;sdata=uQo332dpjuiNqWFCguvs3Kgg7UUMN8MBEzLxTPyH4MM%3D&amp;reserved=0\" rel=\"nofollow noreferrer\">model-register-and-deploy.ipynb<\/a> .  InferenceConfig class accepts  source_directory and entry_script <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.inferenceconfig?view=azure-ml-py#parameters\" rel=\"nofollow noreferrer\">parameters<\/a>, where source_directory  is a path to the folder that contains all files(score.py and any other additional files) to create the image. <\/p>\n\n<p>This <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb\" rel=\"nofollow noreferrer\">multi-model-register-and-deploy.ipynb<\/a> has code snippets on how to create InferenceConfig with source_directory and entry_script.<\/p>\n\n<pre><code>from azureml.core.webservice import Webservice\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.environment import Environment\n\nmyenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\ninference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n\nservice = Model.deploy(workspace=ws,\n                       name='sklearn-mnist-svc',\n                       models=[model], \n                       inference_config=inference_config,\n                       deployment_config=aciconfig)\n\nservice.wait_for_deployment(show_output=True)\n\nprint(service.scoring_uri)\n<\/code><\/pre>",
        "Answer_comment_count":4.0,
        "Answer_creation_time":1584005785480,
        "Answer_score":-2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1584011988083,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60637170",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67988138,
        "Question_title":"Azure ML Tutorial - Failed to load entrypoint automl",
        "Question_body":"<p>I'm doing following tutorial. I failed to run &quot;Create a control script&quot;.<\/p>\n<p>What could be wrong?<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world<\/a><\/p>\n<pre><code>azureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$ python run-hello.py \nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = \nazureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 4.0.0 \n(\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), \nRequirement.parse('pyarrow&lt;4.0.0,&gt;=0.17.0'), {'azureml-dataset-runtime'}).\nhttps:\/\/ml.azure.com\/runs\/day1-experiment-hello_1623766747_073126f5? \nwsid=\/subscriptions\/1679753a-501e-4e46-9bff- \n6120ed5694cf\/resourcegroups\/kensazuremlrg\/workspaces\/kensazuremlws&amp;tid=94fe1041-ba47-4f49- \n866b- \n06c297c116cc\nazureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1623766974453,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1241,
        "Owner_creation_time":1478251050693,
        "Owner_last_access_time":1663835968943,
        "Owner_location":"Finland",
        "Owner_reputation":1519,
        "Owner_up_votes":116,
        "Owner_down_votes":0,
        "Owner_views":375,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I think the error indicates that your environment is using pyarrow package which is of version 4.0.0 whereas azureml-dataset-runtime requires the package to be &gt;=0.17.0 but &lt;4.0.0<\/p>\n<p>It would be easier for you to uninstall the package and install a specific version. The list of releases of pyarrow are available here.<\/p>\n<p>Since you are using a notebook create new cells and run these commands.<\/p>\n<pre><code> !pip uninstall pyarrow\n !pip install -y pyarrow==3.0.0\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1623861331177,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67988138",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":45796489,
        "Question_title":"Azure Machine Learning: What error is this?",
        "Question_body":"<p>I am using a Classic Web Service with a non-default endpoint for a Update Resource activity on the Azure Data Factory. This is the error I get:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/shK0R.png\" rel=\"nofollow noreferrer\">Screenshot of Error<\/a><\/p>\n\n<p>I didn't find any info on the web and couldn't figure it out myself. <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/data-factory\/data-factory-azure-ml-update-resource-activity\" rel=\"nofollow noreferrer\">This<\/a> website shows an example that I used by just filling in my values for mlEndpoint, apiKey and updateRessourceEndpoint:<\/p>\n\n<pre><code>{\n    \"name\": \"updatableScoringEndpoint2\",\n    \"properties\": {\n        \"type\": \"AzureML\",\n        \"typeProperties\": {\n            \"mlEndpoint\": \"https:\/\/ussouthcentral.services.azureml.net\/workspaces\/xxx\/services\/--scoring experiment--\/jobs\",\n            \"apiKey\": \"endpoint2Key\",\n            \"updateResourceEndpoint\": \"https:\/\/management.azureml.net\/workspaces\/xxx\/webservices\/--scoring experiment--\/endpoints\/endpoint2\"\n        }\n    }\n}\n<\/code><\/pre>\n\n<p>There is no mention of a token that needs to be passed...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1503316557373,
        "Question_score":0,
        "Question_tags":"azure|azure-data-factory|azure-machine-learning-studio",
        "Question_view_count":253,
        "Owner_creation_time":1476806455803,
        "Owner_last_access_time":1661945674687,
        "Owner_location":"Holzkirchen, Deutschland",
        "Owner_reputation":3068,
        "Owner_up_votes":186,
        "Owner_down_votes":66,
        "Owner_views":386,
        "Question_last_edit_time":null,
        "Answer_body":"<p>this error is basically saying the apiKey you provided is invalid to perform the update resource operation. Here is some posts for your reference: <a href=\"https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/3bb77e37-8860-43c6-bcaa-d6ebd70617b8\/retrain-predictive-web-service-programmatically-when-do-not-have-access-to-managementazuremlnet?forum=MachineLearning\" rel=\"nofollow noreferrer\">https:\/\/social.msdn.microsoft.com\/Forums\/azure\/en-US\/3bb77e37-8860-43c6-bcaa-d6ebd70617b8\/retrain-predictive-web-service-programmatically-when-do-not-have-access-to-managementazuremlnet?forum=MachineLearning<\/a><\/p>\n\n<p>Please also be noted that if you modified your linked service in ADF, remember to re-deploy the pipeline as well to reflect your change in time.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1503393687923,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/45796489",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":39376560,
        "Question_title":"How to call Tensorflow in Azure ML",
        "Question_body":"<p>I've so far seen people using tensorflow in Azure using in this <a href=\"http:\/\/www.mikelanzetta.com\/tensorflow-on-azure-using-docker.html\" rel=\"nofollow\">link<\/a>.\nAlso using the advantage of ubuntu in windows tensorflow can be run on\nwindows pc as well.Here is the <a href=\"http:\/\/www.hanselman.com\/blog\/PlayingWithTensorFlowOnWindows.aspx\" rel=\"nofollow\">link<\/a>.\nHowever during a conversation with Windows Azure engineer Hai Ning it came out\nthat \"Azure ML PaaS VMs use Windows OS; TensorFlow is not supported on Windows as of now.\"\nHence there is no direct way of running tensorflow in Azure ML.\nIs there any work around anyone figured out that allows running tensorflow in Azure ML.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1473271529687,
        "Question_score":1,
        "Question_tags":"tensorflow|azure-machine-learning-studio",
        "Question_view_count":1743,
        "Owner_creation_time":1435075201580,
        "Owner_last_access_time":1663954259410,
        "Owner_location":"Seattle, WA, USA",
        "Owner_reputation":546,
        "Owner_up_votes":232,
        "Owner_down_votes":1,
        "Owner_views":59,
        "Question_last_edit_time":1473276447317,
        "Answer_body":"<p>Quick update for you. As of TensorFlow r0.12 there is now a native TensorFlow package for Windows. I have it running successfully on my Windows 10 laptop. See this <a href=\"https:\/\/developers.googleblog.com\/2016\/11\/tensorflow-0-12-adds-support-for-windows.html\" rel=\"nofollow noreferrer\">blog post<\/a> from Google for more information.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1486144727963,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/39376560",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":49604773,
        "Question_title":"Azure Machine Learning Studio vs. Workbench",
        "Question_body":"<p>What is the difference between <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-studio\/\" rel=\"noreferrer\">Azure Machine Learning Studio<\/a> and <a href=\"https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning-services\/\" rel=\"noreferrer\">Azure Machine Learning Workbench<\/a>?  What is the <em>intended<\/em> difference? And is it expected that Workbench is heading towards deprecation in favor of Studio?<\/p>\n\n<p>I have gathered an assorted collection of differences:<\/p>\n\n<ul>\n<li>Studio has a hard limit of 10 GB total input of training data per module, whereas Workbench has a variable limit by price.<\/li>\n<li>Studio appears to have a more fully-featured GUI and user-friendly deployment tools, whereas Workbench appears to have more powerful \/ customizable deployment tools.<\/li>\n<li>etc.<\/li>\n<\/ul>\n\n<p>However, I have also found several scattered references claiming that Studio is a renamed updated of Workbench, even though both services appear to still be offered.<\/p>\n\n<p>For a fresh Data Scientist looking to adopt the Microsoft stack (potentially on an enterprise scale within the medium-term and for the long-term), which offering should I prefer?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1522638099293,
        "Question_score":8,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-workbench",
        "Question_view_count":3387,
        "Owner_creation_time":1434736108840,
        "Owner_last_access_time":1663241421093,
        "Owner_location":"Dallas, TX, United States",
        "Owner_reputation":2045,
        "Owner_up_votes":1074,
        "Owner_down_votes":66,
        "Owner_views":166,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Azure Machine Learning Workbench is a preview downloadable application. It provides a UI for many of the Azure Machine Learning CLI commands, particularly around experimentation submission for Python based jobs to DSVM or HDI. The Azure Machine Learning CLI is made up of many key functions, such as job submisison, and creation of real time web services. The workbench installer provided a way to install everything required to participate in the preview. <\/p>\n\n<p>Azure Machine Learning Studio is an older product, and provides a drag and drop interface for creating simply machine learning processes. It has limitations about the size of the data that can be handled (about 10gigs of processing). Learning and customer requests have based on this service have contributed to the design of the new Azure Machine Learning CLI mentioned above.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1524806701633,
        "Answer_score":6.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/49604773",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":37228027,
        "Question_title":"How do get my custom Python code into Azure Machine Learning for use a a ZIP resource?",
        "Question_body":"<p>The <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-execute-python-scripts\/\" rel=\"nofollow\">documentation<\/a> for the Azure Machine Learning Python script module describes using a ZIP file containing code as a resource, but I don't see how to create and upload such a ZIP file in the first place.<\/p>\n\n<p>How do get my custom Python code into Azure Machine Learning for use as a ZIP resource?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1463237105637,
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-studio",
        "Question_view_count":664,
        "Owner_creation_time":1299959670313,
        "Owner_last_access_time":1663787198420,
        "Owner_location":"United States",
        "Owner_reputation":41475,
        "Owner_up_votes":1198,
        "Owner_down_votes":107,
        "Owner_views":1912,
        "Question_last_edit_time":1463238039270,
        "Answer_body":"<p>Just upload it as a dataset. <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-execute-python-scripts\/\" rel=\"nofollow\">Reference.<\/a> (search for it, as it is not on the first page).<\/p>\n\n<p><a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-walkthrough-2-upload-data\/#upload-the-dataset-to-machine-learning-studio\" rel=\"nofollow\">Reference<\/a> on how to upload the dataset. <\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1463238158720,
        "Answer_score":1.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/37228027",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":68463080,
        "Question_title":"how create azure machine learning scoring image using local package",
        "Question_body":"<p>I have pkl package saved in my azure devops repository<\/p>\n<p>using below code it searches for package in workspace.\nHow to provide package saved in repository<\/p>\n<pre><code> ws = Workspace.get(\n         name=workspace_name,\n         subscription_id=subscription_id,\n        resource_group=resource_group,\n        auth=cli_auth)\n\nimage_config = ContainerImage.image_configuration(\n    execution_script=&quot;score.py&quot;,\n    runtime=&quot;python-slim&quot;,\n    conda_file=&quot;conda.yml&quot;,\n    description=&quot;Image with ridge regression model&quot;,\n    tags={&quot;area&quot;: &quot;ml&quot;, &quot;type&quot;: &quot;dev&quot;},\n)\n\nimage = Image.create(\n    name=image_name,  models=[model], image_config=image_config, workspace=ws\n)\n\nimage.wait_for_creation(show_output=True)\n\nif image.creation_state != &quot;Succeeded&quot;:\n    raise Exception(&quot;Image creation status: {image.creation_state}&quot;)\n\nprint(\n    &quot;{}(v.{} [{}]) stored at {} with build log {}&quot;.format(\n        image.name,\n        image.version,\n        image.creation_state,\n        image.image_location,\n        image.image_build_log_uri,\n    )\n)\n\n# Writing the image details to \/aml_config\/image.json\nimage_json = {}\nimage_json[&quot;image_name&quot;] = image.name\nimage_json[&quot;image_version&quot;] = image.version\nimage_json[&quot;image_location&quot;] = image.image_location\nwith open(&quot;aml_config\/image.json&quot;, &quot;w&quot;) as outfile:\n    json.dump(image_json, outfile)\n<\/code><\/pre>\n<p>I tried to provide path to models but its fails saying package not found<\/p>\n<p>models = $(System.DefaultWorkingDirectory)\/package_model.pkl<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1626831896507,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":140,
        "Owner_creation_time":1567209656790,
        "Owner_last_access_time":1663349187993,
        "Owner_location":null,
        "Owner_reputation":417,
        "Owner_up_votes":53,
        "Owner_down_votes":0,
        "Owner_views":233,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Register model:\nRegister a file or folder as a model by calling <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none-\" rel=\"nofollow noreferrer\">Model.register()<\/a>.<\/p>\n<p>In addition to the content of the model file itself, your registered model will also store model metadata -- model description, tags, and framework information -- that will be useful when managing and deploying models in your workspace. Using tags, for instance, you can categorize your models and apply filters when listing models in your workspace.<\/p>\n<pre><code>model = Model.register(workspace=ws,\n                       model_name='',                # Name of the registered model in your workspace.\n                       model_path='',  # Local file to upload and register as a model.\n                       model_framework=Model.Framework.SCIKITLEARN,  # Framework used to create the model.\n                       model_framework_version=sklearn.__version__,  # Version of scikit-learn used to create the model.\n                       sample_input_dataset=input_dataset,\n                       sample_output_dataset=output_dataset,\n                       resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5),\n                       description='Ridge regression model to predict diabetes progression.',\n                       tags={'area': 'diabetes', 'type': 'regression'})\n\nprint('Name:', model.name)\nprint('Version:', model.version)\n<\/code><\/pre>\n<p>Deploy machine learning models to Azure: <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python<\/a><\/p>\n<p>To Troubleshooting remote model deployment Please follow the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?tabs=azcli#function-fails-get_model_path\" rel=\"nofollow noreferrer\">document<\/a>.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/BL0Nm.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BL0Nm.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1627276170737,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1627278873550,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68463080",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64546521,
        "Question_title":"Azure ML FileDataset registers, but cannot be accessed for Data Labeling project",
        "Question_body":"<p><strong>Objective<\/strong>: Generate a down-sampled FileDataset using random sampling from a larger FileDataset to be used in a Data Labeling project.<\/p>\n<hr \/>\n<p><strong>Details<\/strong>: I have a large FileDataset containing millions of images. Each filename contains details about the 'section' it was taken from. A section may contain thousands of images. I want to randomly select a specific number of <strong>sections<\/strong> and all the images associated with those sections. Then register the sample as a new dataset.<\/p>\n<p>Please note that the code below is not a direct copy and paste as there are elements such as filepaths and variables that have been renamed for confidentiality reasons.<\/p>\n<pre><code>import azureml.core\nfrom azureml.core import Dataset, Datastore, Workspace\n\n# Load in work space from saved config file\nws = Workspace.from_config()\n\n# Define full dataset of interest and retrieve it\ndataset_name = 'complete_2017'\ndata = Dataset.get_by_name(ws, dataset_name)\n\n# Extract file references from dataset as relative paths\nrel_filepaths = data.to_path()\n\n# Stitch back in base directory path to get a list of absolute paths\nsrc_folder = '\/raw-data\/2017'\nabs_filepaths = [src_folder + path for path in rel_filepaths]\n\n# Define regular expression pattern for extracting source section\nimport re\npattern = re.compile('\\\/(S.+)_image\\d+.jpg')\n\n# Create new list of all unique source sections\nsections = sorted(set([m.group(1) for m in map(pattern.match, rel_filepaths) if m]))\n\n# Randomly select sections\nnum_sections = 5\nset_seed = 221020\nrandom.seed(set_seed)   # for repeatibility\nsample_sections = random.choices(sections, k = num_sections)\n\n# Extract images related to the selected sections\nmatching_images = [filename for filename in abs_filepaths if any(section in filename for section in sample_sections)]\n\n# Define datastore of interest\ndatastore = Datastore.get(ws, 'ml-datastore')\n\n# Convert string paths to Azure Datapath objects and relate back to datastore\nfrom azureml.data.datapath import DataPath\ndatastore_path = [DataPath(datastore, filepath) for filepath in matching_images]\n\n# Generate new dataset using from_files() and filtered list of paths\nsample = Dataset.File.from_files(datastore_path)\n\nsample_name = 'random-section-sample'\nsample_dataset = sample.register(workspace = ws, name = sample_name, description = 'Sampled sections from full dataset using set seed.')\n<\/code><\/pre>\n<hr \/>\n<p><strong>Issue<\/strong>: The code I've written in Python SDK runs and the new FileDataset registers, but when I try to look at the dataset details or use it for a Data Labeling project I get the following error even as <em>Owner<\/em>.<\/p>\n<pre><code>Access denied: Failed to authenticate data access with Workspace system assigned identity. Make sure to add the identity as Reader of the data service.\n<\/code><\/pre>\n<p>Additionally, under the details tab <strong>Files in dataset<\/strong> is <em>Unknown<\/em> and <strong>Total size of files in dataset<\/strong> is <em>Unavailable<\/em>.<\/p>\n<p>I haven't come across this issue anywhere else. I'm able to generate datasets in other ways, so I suspect it's an issue with the code given that I'm working with the data in an unconventional way.<\/p>\n<hr \/>\n<p><strong>Additional Notes<\/strong>:<\/p>\n<ul>\n<li>Azure ML version is 1.15.0<\/li>\n<\/ul>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_time":1603756226340,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":801,
        "Owner_creation_time":1603750656893,
        "Owner_last_access_time":1619302917223,
        "Owner_location":"New Zealand",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Question_last_edit_time":null,
        "Answer_body":"<p>One of my colleagues discovered that the managed identities were preventing the preview functionality. Once this aspect of the identities was modified, we could examine the data and use it for a data labelling project.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1603917086963,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64546521",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73720626,
        "Question_title":"How can I select a column product of a math operation in Azure Machine Learning Designer?",
        "Question_body":"<p>I have created a pipeline in Azure Machine Learning that includes a <strong>Math Operation<\/strong> (natural logarithm of a column named <em>charges<\/em>). The next pill to the <strong>Math Operatio<\/strong>n is <strong>Select Column in Dataset<\/strong>. Since the pipeline has not ben submitted and run I cannot access the column <em>ln(charges)<\/em> in the pill <strong>Select Column in Dataset<\/strong>.\nMy problem is that if I submit it I am able to run it and see the results in the pipeline once completed, but I have found no way of accessing those results (and thus the <em>ln(charges)<\/em> column in Designer.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/DOddA.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/DOddA.png\" alt=\"Pipeline Job after submitting and running\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Hp6Dc.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Hp6Dc.png\" alt=\"Pipeline in designer after submitting and running the job\" \/><\/a><\/p>\n<p><strong>UPDATE:<\/strong><\/p>\n<p><strong>I have found a workaround. Still in designer the column ln(charges) is not selectable but if I manually enter Ln(charges) in the select column fields it works.<\/strong><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1663174586247,
        "Question_score":1,
        "Question_tags":"azure|machine-learning|designer|azure-machine-learning-studio",
        "Question_view_count":55,
        "Owner_creation_time":1526397625170,
        "Owner_last_access_time":1663935384777,
        "Owner_location":"Spain",
        "Owner_reputation":47,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Question_last_edit_time":1663233012833,
        "Answer_body":"<p>The following is the procedure of the math operation in Azure ML designer to select the column to be implemented. The following procedure will help to give the column name as well as we can also give the index number of the column. This answer contains both the procedures.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9YV8f.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9YV8f.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>We can click on edit column.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/bAnfq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bAnfq.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/cZFfF.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/cZFfF.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Based on the dataset which the experiment was running, both are options are mentioned in the above screen. We can choose either of the options.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/PblH7.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PblH7.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>To access the data, right click and go to access data and click on result_dataset<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/8jHz5.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/8jHz5.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>The following page will open and click on any file mentioned in the box<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4jWxT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4jWxT.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Click on download and open in the editor according to your wish.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wfGPV.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wfGPV.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>It looks like the above result screen.\nThe below screens are the designer created.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/bTWGR.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bTWGR.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/6kUAw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6kUAw.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/I2Ej1.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/I2Ej1.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>To check the final model result. Go to evaluate model and get the results in visualization manner.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1663747263323,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73720626",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70873347,
        "Question_title":"Recommended options for Feature store in Azure ML",
        "Question_body":"<p>This is regard to ML Feature Stores, is Feast the recommended option today for Feature Store with Azure ML or is there any other options?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1643257477277,
        "Question_score":3,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":327,
        "Owner_creation_time":1632461310820,
        "Owner_last_access_time":1650860148037,
        "Owner_location":null,
        "Owner_reputation":107,
        "Owner_up_votes":49,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":null,
        "Answer_body":"<p>We have roadmap to support that is something more native and also tightly integrates into Azure ML.<\/p>\n<p>Here is <a href=\"https:\/\/techcommunity.microsoft.com\/t5\/ai-customer-engineering-team\/bringing-feature-store-to-azure-from-microsoft-azure-redis-and\/ba-p\/2918917\" rel=\"nofollow noreferrer\">doc<\/a> to integration with OSS tool such as Hopsworks\/Feast and leveraging existing functionalities (designer\/pipelines, dataset) for an end-to-end &quot;feature store&quot; solution.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1643267855687,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70873347",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60978808,
        "Question_title":"When should I use Azure ML Notebooks VS Azure Databricks? Both are competitor products in my opinion",
        "Question_body":"<p>Pretty self-explanatory question. When should I use Azure ML Notebooks VS Azure Databricks? I feel there\u2019s a great overlap between the two products and one is definitely better marketed than the other.. <\/p>\n\n<p>I\u2019m mainly looking for information concerning datasets sizes and typical workflow. Why should I use Databricks over AzureML if I don\u2019t have a Spark oriented workflow ?<\/p>\n\n<p>Thanks !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1585769120130,
        "Question_score":7,
        "Question_tags":"azure|machine-learning|databricks|azure-machine-learning-service",
        "Question_view_count":3755,
        "Owner_creation_time":1447320137140,
        "Owner_last_access_time":1663776204940,
        "Owner_location":null,
        "Owner_reputation":313,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":40,
        "Question_last_edit_time":1625712808263,
        "Answer_body":"<p>@Nethim, from my pov these are the main difference:<br><\/p>\n\n<ol>\n<li><p>Data Distribution:<\/p>\n\n<ul>\n<li>Azure ML Notebooks are good when you are training with a limited data on single machine. Though Azure ML provides training clusters, the data distribution among the nodes is to be handled in the code.<\/li>\n<li>Azure Databricks with its RDDs are designed to handle data distributed on multiple nodes.This is advantageous when your data size is huge.When your data size is small and can fit in a scaled up single machine\/ you are using a pandas dataframe, then use of Azure databricks is a overkill<\/li>\n<\/ul><\/li>\n<li><p>Data Cleaning:\nDatabricks can support a lot of file formats natively and querying and cleaning huge datasets are easy where as this has to be handled custom in AzureML notebooks. This can be done with a aml notebooks but cleaning and writing to stores has to be handled.<\/p><\/li>\n<li>Training\nBoth has the capabilities if distributing the training, Databricks provides inbuilt ML algorithms that can act on chunk of data on that node and coordinate with other nodes. Though this can be done on both AzureMachineLearning and Databricks with tf,horovod etc.,<\/li>\n<\/ol>\n\n<p>In general(just my opinion), if the dataset is small, aml notebooks is good.If the data size is huge, then Azure databricks is easy for datacleanup and format conversions.Then the training can happen on AML or databricks.Though databricks has a learning curve whereas Azure ML can be easy with the python and pandas.<\/p>\n\n<p>Thanks.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1585823280850,
        "Answer_score":6.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60978808",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63807950,
        "Question_title":"Letter Recognition Error in Azure ML Studio",
        "Question_body":"<p>I'm having troubles with a Letter Recognition model I'm creating in Azure ML Studio.<\/p>\n<p>I'm running a few algorithms - Decision Jungle, Neural Network, Decision Forest, Logistic Regression, One vs. All Multiclass, and then I append them using the Add rows method (Neural Network and Desicion Jungle\/ Decision Forest and Logistic Regression), until I append them all.<\/p>\n<p>However, appending Decision Forest and Logistic Regression I get the following error:<\/p>\n<pre><code>requestId = 9292bc066f51404eb5e0d0d219d3a072 errorComponent=Module. taskStatusCode=400. {&quot;Exception&quot;:{&quot;ErrorId&quot;:&quot;NotInRangeValue&quot;,&quot;ErrorCode&quot;:&quot;0008&quot;,&quot;ExceptionType&quot;:&quot;ModuleException&quot;,&quot;Message&quot;:&quot;Error 0008: Parameter \\&quot;Dataset2(number of columns)\\&quot; value should be in the range of [3, 3].&quot;}}Error: Error 0008: Parameter &quot;Dataset2(number of columns)&quot; value should be in the range of [3, 3]. Process exited with error code -2\n<\/code><\/pre>\n<p>Any advice what should I do? Huge thanks in advance<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1599640980777,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":37,
        "Owner_creation_time":1599640856987,
        "Owner_last_access_time":1645372502427,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":1599642150897,
        "Answer_body":"<p>This error occurs when there is a mismatch of number of columns of the two dataset you are appending.<\/p>\n<p>Looking at the error :<\/p>\n<p>The output of one model is returning rows with 3 columns and other one is having either more or less than 3 columns.<\/p>\n<p>Before this step &quot;Add Rows&quot; step -&gt; Do quick Visualize<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/PsYQT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PsYQT.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>This will give a view of the dataset that you are planning to append.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/x442d.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/x442d.png\" alt=\"![enter image description here\" \/><\/a><\/p>\n<p>Ensure for both, the columns numbers are same.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1599653828450,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63807950",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":46797468,
        "Question_title":"Incorrect neural network schema in training output",
        "Question_body":"<p>I'm training a model in Azure ML Studio and the Net# specification I'm using doesn't match the NET# specification in the training output.<\/p>\n\n<p>Here's my experiment - <a href=\"https:\/\/i.stack.imgur.com\/WFMGs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/WFMGs.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>and here are my NN params - <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/sVzcA.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/sVzcA.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>and finally here is the NET# specification in the Hyperparams output -<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/ehImq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ehImq.png\" alt=\"enter image description here\"><\/a>\nIt's not using two hidden layers and it's also using sigmoid instead of ReLu. Is this expected behavior?<\/p>\n\n<p>Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1508267201980,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":36,
        "Owner_creation_time":1274124294967,
        "Owner_last_access_time":1642446534253,
        "Owner_location":null,
        "Owner_reputation":655,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":47,
        "Question_last_edit_time":null,
        "Answer_body":"<p>There is an issue with using custom NET# and parameter sweeps together: it switches over to using the default fully connected topology. <\/p>\n\n<p>Unfortunately, the workaround is to train the model for each parameter value separately.  <\/p>\n\n<p>-Roope  <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1508336707887,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/46797468",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":63425902,
        "Question_title":"Are Machine Learning Studios's web services public?",
        "Question_body":"<p>I have created an experiment in Machine Learning Studio and deployed it as a web service. I've got a request-response API in my workspace that works. Can it be also used by other people?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1597493508787,
        "Question_score":0,
        "Question_tags":"azure|web-services|machine-learning|azure-machine-learning-studio",
        "Question_view_count":39,
        "Owner_creation_time":1575044869560,
        "Owner_last_access_time":1604600830650,
        "Owner_location":null,
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Question_last_edit_time":null,
        "Answer_body":"<p>When you deploy a model, a Webservice object is returned with information about the service.<\/p>\n<pre><code>from azureml.core.webservice import AciWebservice, Webservice\nfrom azureml.core.model import Model\n\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores = 3, memory_gb = 15, location = &quot;centralus&quot;)\nservice = Model.deploy(ws, &quot;aciservice&quot;, [model], inference_config, deployment_config)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/AvVgY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/AvVgY.png\" alt=\"enter image description here\" \/><\/a>\nPlease follow the below to Consume an Azure Machine Learning model deployed as a web service\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1597984478140,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63425902",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50209284,
        "Question_title":"How to use the trained model developed in AZURE ML",
        "Question_body":"<p>I trained a model in AZURE ML. Now i want to use that model in my ios app to predict the output\u00a0.<\/p>\n\n<p>How to download the model from AZURE and use it my swift code.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1525678856837,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":516,
        "Owner_creation_time":1510206999777,
        "Owner_last_access_time":1630651881373,
        "Owner_location":null,
        "Owner_reputation":81,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Question_last_edit_time":1558224843257,
        "Answer_body":"<p>As far as I know, the model could run in <strong>Azure Machine Learning Studio<\/strong>.It seems that you are unable to download it, the model could do nothing outside of Azure ML. <\/p>\n\n<p><a href=\"https:\/\/stackoverflow.com\/questions\/41236871\/how-to-download-the-trained-models-from-azure-machine-studio\">Here<\/a> is a similar post for you to refer, I have also tried @Ahmet's \nmethod, but result is like @mrjrdnthms says.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1525849618930,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1525850503193,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50209284",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":71075255,
        "Question_title":"AzureML: TabularDataset.to_pandas_dataframe() hangs when parquet file is empty",
        "Question_body":"<p>I have created a Tabular Dataset using Azure ML python API. Data under question is a bunch of parquet files (~10K parquet files each of size of 330 KB) residing in Azure Data Lake Gen 2 spread across multiple partitions. When I try to load the dataset using the API <code>TabularDataset.to_pandas_dataframe()<\/code>, it continues forever (hangs), if there are empty parquet files included in the Dataset. If the tabular dataset doesn't include those empty parquet files, <code>TabularDataset.to_pandas_dataframe()<\/code> completes within few minutes.<\/p>\n<p>By empty parquet file, I mean that the if I read the individual parquet file using pandas (pd.read_parquet()), it results in an empty DF (df.empty == True).<\/p>\n<p>I discovered the root cause while working on another issue mentioned <code>[here][1]<\/code>.<\/p>\n<p><strong>My question is how can make <code>TabularDataset.to_pandas_dataframe()<\/code> work even when there are empty parquet files?<\/strong><\/p>\n<p><strong>Update<\/strong>\nThe issue has been fixed in the following version:<\/p>\n<ul>\n<li>azureml-dataprep : 3.0.1<\/li>\n<li>azureml-core :  1.40.0<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1644552863947,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-service|azureml-python-sdk",
        "Question_view_count":300,
        "Owner_creation_time":1280505139753,
        "Owner_last_access_time":1663935737867,
        "Owner_location":"Bangalore, India",
        "Owner_reputation":4265,
        "Owner_up_votes":315,
        "Owner_down_votes":11,
        "Owner_views":403,
        "Question_last_edit_time":1648643447773,
        "Answer_body":"<p>Thanks for reporting it.\nThis is a bug in handling of the parquet files with columns but empty row set. This has been fixed already and will be included in next release.<\/p>\n<p>I could not repro the hang on multiple files, though, so if you could provide more info on that would be nice.<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1646432724770,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71075255",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40302499,
        "Question_title":"Recommendation API: what is the difference between null results and empty results",
        "Question_body":"<p>In the Azure Recommendation API sample there is a snippet like this:<\/p>\n\n<pre><code>     if (itemSets.RecommendedItemSetInfo != null)\n        {\n            ...\n        }\n        else\n        {\n            Console.WriteLine(\"No recommendations found.\");\n        }\n<\/code><\/pre>\n\n<p>So I assume that nullable recommended set means no recommendations. But what is the case with this set being not nullable but still empty ( as I am having it running the example)?<\/p>\n\n<p>I provided my own usages and catalog files. I have not too many entries there however for i2i recommendations I have results and for u2i there is an empty set.\nAllowColdItemPlacement doesn't change a think here.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1477648288960,
        "Question_score":0,
        "Question_tags":"azure|microsoft-cognitive|azure-machine-learning-studio",
        "Question_view_count":130,
        "Owner_creation_time":1354118434117,
        "Owner_last_access_time":1613750840957,
        "Owner_location":"Wroc\u0142aw, Poland",
        "Owner_reputation":393,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":43,
        "Question_last_edit_time":null,
        "Answer_body":"<p>We did not mean to convey a difference in meaning between null recommendations and empty recommendations. I will check why we may be sending two different types of results. Either way, don't treat those two cases as different cases. <\/p>\n\n<p>If you are not getting results for user-to-item recommendations, most likely there was no data for that user when the build was created or the items that the user interacted with do not have enough co-occurrences with other items in the usage.<\/p>\n\n<p>What to do when you get empty recommendations is up to you, you may decide to not show any recommendations, or back-fill with popular items you may want to promote.<\/p>\n\n<p>Thanks!<\/p>\n\n<p>Luis Cabrera\nProgram Manager - Recommendations API.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1478186851717,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40302499",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60975078,
        "Question_title":"How to only load one portion of an AzureML tabular dataset (linked to Azure Blob Storage)",
        "Question_body":"<p>I have a DataSet defined in my AzureML workspace that is linked to an Azure Blob Storage csv file of 1.6Gb.  This file contains timeseries information of around 10000 devices.  So, I could've also created 10000 smaller files (since I use ADF for the transmission pipeline).<\/p>\n\n<p>My question now is: is it possible to load a part of the AzureML DataSet in my python notebook or script instead of loading the entire file?<br>\nThe only code I have now load the full file:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>dataset = Dataset.get_by_name(workspace, name='devicetelemetry')\ndf = dataset.to_pandas_dataframe()\n<\/code><\/pre>\n\n<p>The only concept of partitions I found with regards to the AzureML datasets was around time series and partitioning of timestamps &amp; dates.  However, here I would love to partition per device, so I can very easily just do a load of all telemetry of a specific device.<\/p>\n\n<p>Any pointers to docs or any suggestions? (I couldn't find any so far)<\/p>\n\n<p>Thanks already<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_creation_time":1585756434767,
        "Question_score":1,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":560,
        "Owner_creation_time":1360655430743,
        "Owner_last_access_time":1663784892907,
        "Owner_location":"Belgium",
        "Owner_reputation":2947,
        "Owner_up_votes":297,
        "Owner_down_votes":16,
        "Owner_views":355,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You're right there are the <code>.time_*()<\/code> filtering methods available with a <code>TabularDataset<\/code>.<\/p>\n\n<p>I'm not aware of anyway to do filtering as you suggest (but I agree it would be a useful feature). To get per-device partitioning, my recommendation would be to structure your container like so:<\/p>\n\n<pre><code>- device1\n    - 2020\n        - 2020-03-31.csv\n        - 2020-04-01.csv\n- device2\n   - 2020\n        - 2020-03-31.csv\n        - 2020-04-01.csv\n<\/code><\/pre>\n\n<p>In this way you can define an all-up Dataset, but also per-device Datasets by passing folder of the device to the DataPath<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code># all up dataset\nds_all = Dataset.Tabular.from_delimited_files(\n    path=DataPath(datastore, '*')\n)\n# device 1 dataset\nds_d1 = Dataset.Tabular.from_delimited_files(\n    path=DataPath(datastore, 'device1\/*')\n)\n<\/code><\/pre>\n\n<p><strong>CAVEAT<\/strong><\/p>\n\n<p>dataprep SDK is optimized for blobs around 200MB in size. So you can work with many small files, but sometimes it can be slower than expected, especially considering the overhead of enumerating all blobs in a container.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1585761136673,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60975078",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":56848293,
        "Question_title":"What is Random seed in Azure Machine Learning?",
        "Question_body":"<p>I am learning Azure Machine Learning. I am frequently encountering the <strong>Random Seed<\/strong> in some of the steps like,<\/p>\n\n<ol>\n<li>Split Data<\/li>\n<li>Untrained algorithm models as Two Class Regression, Multi-class regression, Tree, Forest,..<\/li>\n<\/ol>\n\n<p>In the tutorial, they choose Random Seed as '123'; trained model has high accuracy but when I try to choose other random integers like 245, 256, 12, 321,.. it did not do well.<\/p>\n\n<hr>\n\n<p><strong>Questions<\/strong><\/p>\n\n<ul>\n<li>What is a Random Seed Integer?<\/li>\n<li>How to carefully choose a Random Seed from range of integer values? What is the key or strategy to choose it?<\/li>\n<li>Why does Random Seed significantly affect the ML Scoring, Prediction and Quality of the trained model?<\/li>\n<\/ul>\n\n<hr>\n\n<p><strong>Pretext<\/strong><\/p>\n\n<ol>\n<li>I have <a href=\"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/iris\/iris.data\" rel=\"nofollow noreferrer\">Iris-Sepal-Petal-Dataset<\/a> with Sepal (<em>Length &amp; Width<\/em>) and Petal (<em>Length &amp; Width<\/em>)<\/li>\n<li>Last column in data-set is 'Binomial ClassName'<\/li>\n<li>I am training the data-set with Multiclass Decision Forest Algorithm and splitting the data with different random seeds 321, 123 and 12345 in order<\/li>\n<li>It affects the final quality of trained model. Random seed#123 being best of Prediction probability score: 1.<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/12OyD.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/12OyD.png\" alt=\"ML Studio Snap\"><\/a><\/p>\n\n<hr>\n\n<p><strong>Observations<\/strong><\/p>\n\n<p><strong>1. Random seed: 321<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/YcsiS.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/YcsiS.png\" alt=\"Random-seed-321\"><\/a><\/p>\n\n<p><strong>2. Random seed: 123<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/Qrk4G.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Qrk4G.png\" alt=\"Random-seed-123\"><\/a><\/p>\n\n<p><strong>3. Random seed: 12345<\/strong><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/D1Rki.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/D1Rki.png\" alt=\"Random-seed-12345\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":9,
        "Question_creation_time":1562056038867,
        "Question_score":0,
        "Question_tags":"machine-learning|azure-machine-learning-studio|random-seed|iris-dataset",
        "Question_view_count":2046,
        "Owner_creation_time":1475691108437,
        "Owner_last_access_time":1658651167790,
        "Owner_location":"India",
        "Owner_reputation":1849,
        "Owner_up_votes":366,
        "Owner_down_votes":21,
        "Owner_views":253,
        "Question_last_edit_time":1562066943383,
        "Answer_body":"<blockquote>\n  <p>What is a Random Seed Integer?<\/p>\n<\/blockquote>\n\n<p>Will not go into any details regarding what a random seed is in general; there is plenty of material available by a simple web search (see for example <a href=\"https:\/\/stackoverflow.com\/questions\/22639587\/random-seed-what-does-it-do\">this SO thread<\/a>).<\/p>\n\n<p>Random seed serves just to initialize the (pseudo)random number generator, mainly in order to make ML examples reproducible.<\/p>\n\n<blockquote>\n  <p>How to carefully choose a Random Seed from range of integer values? What is the key or strategy to choose it?<\/p>\n<\/blockquote>\n\n<p>Arguably this is already answered implicitly above: you are simply not supposed to choose any particular random seed, and your results should be roughly the same across different random seeds.<\/p>\n\n<blockquote>\n  <p>Why does Random Seed significantly affect the ML Scoring, Prediction and Quality of the trained model?<\/p>\n<\/blockquote>\n\n<p>Now, to the heart of your question. The answer <em>here<\/em> (i.e. with the iris dataset) is the <strong>small-sample effects<\/strong>...<\/p>\n\n<p>To start with, your reported results across different random seeds are not <em>that<\/em> different. Nevertheless, I agree that, at first sight, a difference in macro-average precision of 0.9 and 0.94 might <em>seem<\/em> large; but looking more closely it is revealed that the difference is really not an issue. Why?<\/p>\n\n<p>Using the 20% of your (only) 150-samples dataset leaves you with only 30 samples in your test set (where the evaluation is performed); this is stratified, i.e. about 10 samples from each class. Now, for datasets of <em>that<\/em> small size, it is not difficult to imagine that a difference in the correct classification of <strong>only 1-2<\/strong> samples can have this apparent difference in the performance metrics reported.<\/p>\n\n<p>Let's try to verify this in scikit-learn using a decision tree classifier (the essence of the issue does not depend on the specific framework or the ML algorithm used):<\/p>\n\n<pre class=\"lang-python prettyprint-override\"><code>from sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nX, y = load_iris(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=321, stratify=y)\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n<\/code><\/pre>\n\n<p>Result:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  9  1]\n [ 0  0 10]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      0.90      0.95        10\n           2       0.91      1.00      0.95        10\n\n   micro avg       0.97      0.97      0.97        30\n   macro avg       0.97      0.97      0.97        30\nweighted avg       0.97      0.97      0.97        30\n<\/code><\/pre>\n\n<p>Let's repeat the code above, changing only the <code>random_state<\/code> argument in <code>train_test_split<\/code>; for <code>random_state=123<\/code> we get:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  7  3]\n [ 0  2  8]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       0.78      0.70      0.74        10\n           2       0.73      0.80      0.76        10\n\n   micro avg       0.83      0.83      0.83        30\n   macro avg       0.84      0.83      0.83        30\nweighted avg       0.84      0.83      0.83        30\n<\/code><\/pre>\n\n<p>while for <code>random_state=12345<\/code> we get:<\/p>\n\n<pre><code>[[10  0  0]\n [ 0  8  2]\n [ 0  0 10]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      0.80      0.89        10\n           2       0.83      1.00      0.91        10\n\n   micro avg       0.93      0.93      0.93        30\n   macro avg       0.94      0.93      0.93        30\nweighted avg       0.94      0.93      0.93        30\n<\/code><\/pre>\n\n<p>Looking at the <em>absolute numbers<\/em> of the 3 confusion matrices (in <em>small samples<\/em>, percentages can be <strong>misleading<\/strong>), you should be able to convince yourself that the differences are not that big, and they can be arguably justified by the random element inherent in the whole procedure (here the exact split of the dataset into training and test).<\/p>\n\n<p>Should your test set be significantly bigger, these discrepancies would be practically negligible... <\/p>\n\n<p>A last notice; I have used the exact same seed numbers as you, but this does not actually mean anything, as in general the random number generators <em>across<\/em> platforms &amp; languages are not the same, hence the corresponding seeds are not actually compatible. See own answer in <a href=\"https:\/\/stackoverflow.com\/questions\/52293899\/are-random-seeds-compatible-between-systems\">Are random seeds compatible between systems?<\/a> for a demonstration.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1562069850057,
        "Answer_score":2.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1562070151170,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56848293",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72133111,
        "Question_title":"Azure ML: What means reconnecting terminal?",
        "Question_body":"<p>I am a newbie in this, and I am facing some problems with the Azure ML workspace. I ran a python code from the terminal, and then I opened another terminal to check the process. I got the following message in the terminal that checked the process:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/9XLPw.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/9XLPw.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>What does this mean? It keeps running, but I don't know if it is a bad message. It takes soo long, and I don't want to lose the processing time.<\/p>\n<p>I appreciate any tips.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1651781550743,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-service|azure-python-sdk",
        "Question_view_count":48,
        "Owner_creation_time":1575137776887,
        "Owner_last_access_time":1663955477980,
        "Owner_location":null,
        "Owner_reputation":45,
        "Owner_up_votes":21,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Question_last_edit_time":null,
        "Answer_body":"<blockquote>\n<p>What does this mean? It keeps running, but I don't know if it is a bad message. It takes soo long, and I don't want to lose the processing time.<\/p>\n<\/blockquote>\n<ul>\n<li><code>Reconnecting terminal<\/code> message can appear for multiple reasons like intermittent connectivity issues, unused active terminal sessions, processing of different size\/format of data.<\/li>\n<li>Make sure you close any unused terminal sessions to preserve your compute instance's resources. Idle terminals may impact the performance of compute instances.<\/li>\n<\/ul>\n<p>You can refer to <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-terminal#manage-terminal-sessions\" rel=\"nofollow noreferrer\">Access a compute instance terminal in your workspace<\/a>, <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-optimize-data-processing\" rel=\"nofollow noreferrer\">Optimize data processing with Azure Machine Learning<\/a> and <a href=\"https:\/\/www.youtube.com\/watch?v=kiScfw9i4FM\" rel=\"nofollow noreferrer\">Azure ML: Speed up processing time<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1651825622423,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72133111",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34948242,
        "Question_title":"Azure: plot without labels",
        "Question_body":"<p>Suppose I have a dataframe (myDataframe) with two column of values (third and fourth). I want to plot them in a bi-dimensional graph. If I do it in R it works, but it returns me a graph without labels when I run the script from Azure Machine Learning. Someone with ideas?<\/p>\n\n<pre><code>...\nplot(myDataframe[,3],myDataframe[,4], \n       main=\"my title\",\n       xlab= \"x\"\n       ylab= \"y\",\n       col= \"blue\", pch = 19, cex = 0.1, lty = \"solid\", lwd = 2)\n\n# lines(x,y=x, col=\"yellow\")\n\n# add LABELS\ntext(DF_relativo[,A], DF_relativo[,B], \n       labels=DF_relativo$names, cex= 0.7, pos=2)\n...\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1453470518060,
        "Question_score":0,
        "Question_tags":"r|plot|label|azure-machine-learning-studio",
        "Question_view_count":91,
        "Owner_creation_time":1436432728610,
        "Owner_last_access_time":1663607665487,
        "Owner_location":"Colleferro, Italy",
        "Owner_reputation":809,
        "Owner_up_votes":109,
        "Owner_down_votes":0,
        "Owner_views":361,
        "Question_last_edit_time":null,
        "Answer_body":"<p>using ggplot2() in AzureML is bit different. It can use to have plots with labels. Here's the <a href=\"https:\/\/gallery.cortanaintelligence.com\/Experiment\/b1c26728eb6c4e4d80dddceae992d653\" rel=\"nofollow\">Cortana Intelligence gallery example<\/a> for the particular task.  <\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1466402236047,
        "Answer_score":-1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34948242",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60306240,
        "Question_title":"export azure ml studio designer project as jupyter notebook?",
        "Question_body":"<p>I hope I am not missing something obvious here. I am using the new azure ml studio designer. I am able to use to create datasets, train models and use them just fine.<\/p>\n\n<p>azure ml studio allows creation of Jupyter notebooks (also) and use them to do machine learning. I am able to do that too. <\/p>\n\n<p>So, now, I am wondering, can I build my ML pipeline\/experiment in ML studio designer, and once it is in good shape, export it as a python and jupyter notebook? then, use it in the same designer provided notebook option or may be use it locally?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":4,
        "Question_creation_time":1582134046887,
        "Question_score":5,
        "Question_tags":"azure|jupyter-notebook|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":789,
        "Owner_creation_time":1442334437953,
        "Owner_last_access_time":1664002198907,
        "Owner_location":"Bangalore, Karnataka, India",
        "Owner_reputation":2272,
        "Owner_up_votes":1340,
        "Owner_down_votes":67,
        "Owner_views":516,
        "Question_last_edit_time":null,
        "Answer_body":"<p>This is not currently supported, but I am 80% sure it is in the roadmap.\nAn alternative would be to use the SDK to create the same pipeline using <code>ModuleStep<\/code> where  I <em>believe<\/em> you can reference a Designer Module by its name to use it like a <code>PythonScriptStep<\/code><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1582139574710,
        "Answer_score":6.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":1582241388597,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60306240",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70156610,
        "Question_title":"Accessing an Azure ML Model Registry from another Azure ML Workspace",
        "Question_body":"<p>Suppose I have two Azure ML workspaces:<\/p>\n<ol>\n<li><p>Workspace1 - This is being used by one team (Team1) who only train the model and store the model in model registry of Workspace1<\/p>\n<\/li>\n<li><p>Workspace2 - This is used by another team  (Team2) who containerise the model, push it to ACR and then deploy the containerised model in Azure ML Compute.<\/p>\n<\/li>\n<\/ol>\n<p>Is it possible for Team2 to access the model registry of Workspace1 from their Workspace2 and retrieve the model for containerisation and subsequent deployment? Alternatively, is there any concept of a shared model registry in Azure ML where both the teams can store and access a common model registry? If none of these are possible, then what is the way for Team1 and Team2 to work together on a single model with the given responsibilities as described above?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1638197253147,
        "Question_score":1,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":421,
        "Owner_creation_time":1373471094267,
        "Owner_last_access_time":1663943798093,
        "Owner_location":"United Kingdom",
        "Owner_reputation":395,
        "Owner_up_votes":11,
        "Owner_down_votes":3,
        "Owner_views":66,
        "Question_last_edit_time":null,
        "Answer_body":"<p>As described, I think the best solution is to use one Workspace, not two.  It sounds like you have Team 1 and Team 2 sharing contributions on a single project.  What may work better is to define user roles in the Azure ML workspace, such that Team 2 has permissions to deploy models, and Team 1 has permission to create models.<\/p>\n<p>Otherwise you can always write Python code using the ML SDK to connect to any workspace given you know the subscription, resource group, workspace name etc.<\/p>\n<pre><code>from azure.core import Workspace, Model\n\n# connect to an existing workspace\nname = 'WorkspaceName'\nsub = 'subscriptionName'\nresource_group = 'resourceGroupName'\nws = Workspace.get(name=name, subscription_id=sub, resource_group=resource_group) \n\n# retrieve existing model\nmodel = Model(ws, name='your model name')\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_time":1638210489530,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1638220015580,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70156610",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64979752,
        "Question_title":"Unable to access python packages installed in Azure ML",
        "Question_body":"<p>I am trying to deploy a pre-trained ML model (saved as .h5 file) to Azure ML. I have created an AKS cluster and trying to deploy the model as shown below:<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.model import Model\n\nfrom azureml.core.environment import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.model import InferenceConfig\n\nfrom azureml.core.webservice import AksWebservice, LocalWebservice\nfrom azureml.core.compute import ComputeTarget\n\nworkspace = Workspace.from_config(path=&quot;config.json&quot;)\n\nenv = Environment.get(workspace, name='AzureML-TensorFlow-1.13-GPU')\n\n# Installing packages present in my requirements file\nwith open('requirements.txt') as f:\n    dependencies = f.readlines()\ndependencies = [x.strip() for x in dependencies if '# ' not in x]\ndependencies.append(&quot;azureml-defaults&gt;=1.0.45&quot;)\n\nenv.python.conda_dependencies = CondaDependencies.create(conda_packages=dependencies)\n\n# Including the source folder so that all helper scripts are included in my deployment\ninference_config = InferenceConfig(entry_script='app.py', environment=env, source_directory='.\/ProcessImage')\n\naks_target = ComputeTarget(workspace=workspace, name='sketch-ppt-vm')\n\n# Deployment with suitable config\ndeployment_config = AksWebservice.deploy_configuration(cpu_cores=4, memory_gb=32)\nmodel = Model(workspace, 'sketch-inference')\nservice = Model.deploy(workspace, &quot;process-sketch-dev&quot;, [model], inference_config, deployment_config, deployment_target=aks_target, overwrite=True)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n<p>My main entry script requires some additional helper scripts, which I include by mentioning the source folder in my inference config.<\/p>\n<p>I was expecting that the helper scripts I add should be able to access the packages installed while setting up the environment during deployment, but I get ModuleNotFoundError.<\/p>\n<p>Here is the error output, along with the a couple of environment variables I printed while executing entry script:<\/p>\n<pre><code>    AZUREML_MODEL_DIR ----  azureml-models\/sketch-inference\/1\n    PYTHONPATH ----  \/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages:\/var\/azureml-server:\n    PATH ----  \/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/bin:\/opt\/miniconda\/bin:\/usr\/local\/nvidia\/bin:\/usr\/local\/cuda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin:\/opt\/intel\/compilers_and_libraries\/linux\/mpi\/bin64\n    Exception in worker process\n    Traceback (most recent call last):\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py&quot;, line 583, in spawn_worker\n        worker.init_process()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 129, in init_process\n        self.load_wsgi()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py&quot;, line 138, in load_wsgi\n        self.wsgi = self.app.wsgi()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py&quot;, line 67, in wsgi\n        self.callable = self.load()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 52, in load\n        return self.load_wsgiapp()\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py&quot;, line 41, in load_wsgiapp\n        return util.import_app(self.app_uri)\n    File &quot;\/azureml-envs\/azureml_6dc005c11e151f8d9427c0c6091a1bb9\/lib\/python3.6\/site-packages\/gunicorn\/util.py&quot;, line 350, in import_app\n        __import__(module)\n    File &quot;\/var\/azureml-server\/wsgi.py&quot;, line 1, in &lt;module&gt;\n        import create_app\n    File &quot;\/var\/azureml-server\/create_app.py&quot;, line 3, in &lt;module&gt;\n        from app import main\n    File &quot;\/var\/azureml-server\/app.py&quot;, line 32, in &lt;module&gt;\n        from aml_blueprint import AMLBlueprint\n    File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 25, in &lt;module&gt;\n        import main\n    File &quot;\/var\/azureml-app\/main.py&quot;, line 12, in &lt;module&gt;\n        driver_module_spec.loader.exec_module(driver_module)\n    File &quot;\/structure\/azureml-app\/ProcessImage\/app.py&quot;, line 16, in &lt;module&gt;\n        from ProcessImage.samples.coco.inference import run as infer\n    File &quot;\/var\/azureml-app\/ProcessImage\/samples\/coco\/inference.py&quot;, line 1, in &lt;module&gt;\n        import skimage.io\n    ModuleNotFoundError: No module named 'skimage'\n<\/code><\/pre>\n<p>The existing answers related to this aren't of much help. I believe there must be a simpler way to fix this, since AzureML specifically provides the feature to setup environment with pip\/conda packages installed either by supplying requirements.txt file or individually.<\/p>\n<p>What am I missing here? Kindly help.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1606187763027,
        "Question_score":3,
        "Question_tags":"azure|azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":1381,
        "Owner_creation_time":1429811498813,
        "Owner_last_access_time":1663968181117,
        "Owner_location":"Boston, MA, USA",
        "Owner_reputation":1910,
        "Owner_up_votes":85,
        "Owner_down_votes":6,
        "Owner_views":316,
        "Question_last_edit_time":null,
        "Answer_body":"<p>So, after some trial and error, creating a fresh environment and then adding the packages solved the problem for me. I am still not clear on why this didn't work when I tried to use <a href=\"http:\/\/from%20azureml.core%20import%20Workspace%20from%20azureml.core.model%20import%20Model%20from%20azureml.core.environment%20import%20Environment,%20DEFAULT_GPU_IMAGE%20from%20azureml.core.conda_dependencies%20import%20CondaDependencies%20from%20azureml.core.model%20import%20InferenceConfig%20from%20azureml.core.webservice%20import%20AksWebservice,%20LocalWebservice%20from%20azureml.core.compute%20import%20ComputeTarget%20%20%20#%201.%20Instantiate%20the%20workspace%20workspace%20=%20Workspace.from_config(path=%22config.json%22)%20%20#%202.%20Setup%20the%20environment%20env%20=%20Environment(%27sketchenv%27)%20with%20open(%27requirements.txt%27)%20as%20f:%20#%20Fetch%20all%20dependencies%20as%20a%20list%20%20%20%20%20dependencies%20=%20f.readlines()%20dependencies%20=%20%5Bx.strip()%20for%20x%20in%20dependencies%20if%20%27#%20%27%20not%20in%20x%5D%20env.docker.base_image%20=%20DEFAULT_GPU_IMAGE%20env.python.conda_dependencies%20=%20CondaDependencies.create(conda_packages=%5B%27numpy==1.17.4%27,%20%27Cython%27%5D,%20pip_packages=dependencies)%20%20#%203.%20Inference%20Config%20inference_config%20=%20InferenceConfig(entry_script=%27app.py%27,%20environment=env,%20source_directory=%27.\/ProcessImage%27)%20%20#%204.%20Compute%20target%20(using%20existing%20cluster%20from%20the%20workspacke)%20aks_target%20=%20ComputeTarget(workspace=workspace,%20name=%27sketch-ppt-vm%27)%20%20#%205.%20Deployment%20config%20deployment_config%20=%20AksWebservice.deploy_configuration(cpu_cores=6,%20memory_gb=100)%20%20#%206.%20Model%20deployment%20model%20=%20Model(workspace,%20%27sketch-inference%27)%20#%20Registered%20model%20(which%20contains%20model%20files\/folders)%20service%20=%20Model.deploy(workspace,%20%22process-sketch-dev%22,%20%5Bmodel%5D,%20inference_config,%20deployment_config,%20deployment_target=aks_target,%20overwrite=True)%20service.wait_for_deployment(show_output%20=%20True)%20print(service.state)\" rel=\"nofollow noreferrer\">Environment.from_pip_requirements()<\/a>. A detailed answer in this regard would be interesting to read.<\/p>\n<p>My primary task was inference - object detection given an image, and we have our own model developed by our team. There are two types of imports I wanted to have:<\/p>\n<p><strong>1. Standard python packages (installed through pip)<\/strong><br \/>\nThis was solved by creating conda dependencies and add it to env object (Step 2)<\/p>\n<p><strong>2. Methods\/vars from helper scripts<\/strong> (if you have pre\/post processing to be done during model inference):<br \/>\nThis was done by mentioning <code>source_directory<\/code> in InferenceConfig (step 3)<\/p>\n<p>Here is my updated script which combines Environment creation, Inference and Deployment configs and using existing compute in the workspace (created through portal).<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.environment import Environment, DEFAULT_GPU_IMAGE\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.webservice import AksWebservice, LocalWebservice\nfrom azureml.core.compute import ComputeTarget\n\n\n# 1. Instantiate the workspace\nworkspace = Workspace.from_config(path=&quot;config.json&quot;)\n\n# 2. Setup the environment\nenv = Environment('sketchenv')\nwith open('requirements.txt') as f: # Fetch all dependencies as a list\n    dependencies = f.readlines()\ndependencies = [x.strip() for x in dependencies if '# ' not in x]\nenv.docker.base_image = DEFAULT_GPU_IMAGE\nenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['numpy==1.17.4', 'Cython'], pip_packages=dependencies)\n\n# 3. Inference Config\ninference_config = InferenceConfig(entry_script='app.py', environment=env, source_directory='.\/ProcessImage')\n\n# 4. Compute target (using existing cluster from the workspacke)\naks_target = ComputeTarget(workspace=workspace, name='sketch-ppt-vm')\n\n# 5. Deployment config\ndeployment_config = AksWebservice.deploy_configuration(cpu_cores=6, memory_gb=100)\n\n# 6. Model deployment\nmodel = Model(workspace, 'sketch-inference') # Registered model (which contains model files\/folders)\nservice = Model.deploy(workspace, &quot;process-sketch-dev&quot;, [model], inference_config, deployment_config, deployment_target=aks_target, overwrite=True)\nservice.wait_for_deployment(show_output = True)\nprint(service.state)\n<\/code><\/pre>\n<hr \/>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1606249620653,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64979752",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72035391,
        "Question_title":"AzureML schema \"list index out of range\" error",
        "Question_body":"<p>I developed a machine learning model using Azure ML's clustering. Few of the requests made from the cluster are triggering 404 HTTP error. I followed the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script\" rel=\"nofollow noreferrer\">document<\/a> to do modifications in my swagger.json file. Finally ended up with &quot;list index out of range&quot; error. It seems to be having issue with the global parameter but I am no sure about it. I am using the API from postman with some default headers like mentioned in the body below<\/p>\n<pre><code>{\n    &quot;Inputs&quot;: {\n         &quot;input_1&quot; : &quot;content&quot;\n         &quot;input_2: : &quot;content&quot;\n         ......\n    },\n    &quot;GlobalParameters&quot;: 0\n}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1651094225790,
        "Question_score":1,
        "Question_tags":"python|azure|azure-machine-learning-service",
        "Question_view_count":78,
        "Owner_creation_time":1651093614703,
        "Owner_last_access_time":1659335138797,
        "Owner_location":"Netherland",
        "Owner_reputation":19,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Question_last_edit_time":1651098753480,
        "Answer_body":"<p>Change the &quot;GlobalParameter&quot; value to any floating number other than 1.0 or even you can remove it and execute. Sometimes, Global parameter will cause the issue. Check the below documentation.<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/746784\/azure-ml-studio-error-while-testing-real-time-endp.html\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/746784\/azure-ml-studio-error-while-testing-real-time-endp.html<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1651111084097,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72035391",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":43278593,
        "Question_title":"evaluating linear regression (in microsoft machine learning",
        "Question_body":"<p>Im playing with linear regression in azure machine learning and evaluating a model. <\/p>\n\n<p>Im still a bit unsure what the various metrics for evaluation mean and show, so would appreciate some correction if i am incorrect.<\/p>\n\n<ol>\n<li><strong>Mean Absolute Error:<\/strong> Mean of the residuals (errors).<\/li>\n<li><strong>Root Mean Squared Error:<\/strong> Std Dev of the residuals. With this i can see how far from the mean\/median my absolute error is.<\/li>\n<li><strong>Relative absolute error<\/strong>: a percentage value that shows the percentage difference between relative error and absolute error. lower values are better, indicating lower difference.<\/li>\n<li><strong>relative squared error:<\/strong> square of the error relative to the square of the absolute. Unsure what this gives me over the relative absolute error.<\/li>\n<li><strong>coefficient of determination:<\/strong> indication of correlation between inputs. +1 or -1 indicate perfect correlation, 0 indicates none.<\/li>\n<li>The histogram is showing the frequency of various buckets of error magnitudes. this shows a lot of small errors. with frequency decreasing as the value of error increases, indicating, when taken along with the poor metrics above that there are probably some sku or outliers having a large influence on the model, making it less accurate.<\/li>\n<\/ol>\n\n<p>Are these definitions and assumptions correct?<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/dJqJr.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/dJqJr.jpg\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1491569249220,
        "Question_score":0,
        "Question_tags":"r|machine-learning|statistics|azure-machine-learning-studio",
        "Question_view_count":289,
        "Owner_creation_time":1447682287793,
        "Owner_last_access_time":1542307482427,
        "Owner_location":"Nairobi, Kenya",
        "Owner_reputation":194,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":44,
        "Question_last_edit_time":1491571206763,
        "Answer_body":"<p>You are almost correct on most points. To make sure we are talking in the same terms, a little bit of background:<\/p>\n\n<p>A linear regression uses data on some outcome variable <code>y<\/code> and independent variables <code>x1, x2, ..<\/code> and tries to find the linear combination of <code>x1, x2, ..<\/code> that best predicts <code>y<\/code>. Once this \"best linear combination\" is established, you can assess the quality of the fit (i.e. quality of the model) in multiple ways. The six points you mention are all key metrics for the quality of a regression equation. <\/p>\n\n<p>Running a regression gives you multiple \"ingredients\". For example, every observation will get a <em>predicted value<\/em> for the outcome variable. The difference between the observed value of <code>y<\/code> and the predicted value is called the residual or error. Residuals can be negative (if the <code>y<\/code> is overestimated) and positive (if <code>y<\/code> is underestimated). The closer the residuals are to zero, the better. But, what is \"close\"? The metrics you present are supposed to give an insight in this.<\/p>\n\n<ul>\n<li><strong>Mean absolute error<\/strong>: takes the <em>absolute value<\/em>  of the residuals and takes the mean of that. <\/li>\n<li><strong>Root Mean Square Error<\/strong>: is the standard deviation of your residuals. This will help you see, how large the <em>spread<\/em>  is of your residuals. The residuals are squared and therefore, high residuals will count in more than small residuals. A low RMSE is good. <\/li>\n<li><p><strong>Relative Absolute Error<\/strong>: The absolute error as a fraction of the real value of the outcome variable <code>y<\/code>. In your case, the predictions are on average 75% higher\/lower than the actual value of <code>y<\/code>.<\/p><\/li>\n<li><p><strong>Relative Squared Error<\/strong>: The squared error (<code>residual^2<\/code>) as a fraction of the real value. <\/p><\/li>\n<li><strong>Coefficient of Determination<\/strong>: Almost correct. This ranges between 0 and 1 and can be interpreted as the explanatory power of the independent variables in explaining <code>y<\/code>. In fact, in your case the independent variables can model 38,15% of the variation in <code>y<\/code>.  Also, if you have only one independent variable, this coefficient is equal to the squared correlation coefficient. <\/li>\n<\/ul>\n\n<p>Root Mean Squared Error and Coefficient of Determination are the most important metrics in nearly all situations. To be honest, I've never really seen the other metrics being reported.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1491575868100,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1491576306820,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/43278593",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":48197524,
        "Question_title":"How to remove the entire rows if value is NULL in Azure ML studio",
        "Question_body":"<p>I am preparing the data for regression model. <\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LFaYl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LFaYl.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>I want to remove the entire row If all columns have value <code>NULL<\/code>. <\/p>\n\n<p>With Clean Missing Data module seems to me like I only able to remove missing values. But <code>NULL<\/code> is not considers mission value. <\/p>\n\n<p>So are there any other modules that simply can remove the entire row if all values are <code>NULL<\/code>'s<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1515625426463,
        "Question_score":0,
        "Question_tags":"azure|machine-learning|azure-machine-learning-studio",
        "Question_view_count":1477,
        "Owner_creation_time":1457596845393,
        "Owner_last_access_time":1663977598457,
        "Owner_location":"San Diego, CA, United States",
        "Owner_reputation":4046,
        "Owner_up_votes":505,
        "Owner_down_votes":7,
        "Owner_views":825,
        "Question_last_edit_time":null,
        "Answer_body":"<p>you could use \"<strong>Execute Python Script<\/strong>\" or \"<strong>Execute R Script<\/strong>\" to archive that. Or just use \"<strong>Apply SQL Transformation<\/strong>\" -> <code>SELECT * FROM tbl1 where column1 IS NULL AND column2 IS NULL<\/code>.... <\/p>\n\n<p>Greetings,\nStefan<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1516614808533,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1526560111353,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/48197524",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":70976353,
        "Question_title":"After installing scrubadub_spacy package, spacy.load(\"en_core_web_sm\") not working OSError: [E053] Could not read config.cfg",
        "Question_body":"<p>I am getting the below error when I'm trying to run the following line of code to load en_core_web_sm in the Azure Machine Learning instance.<\/p>\n<p>I debugged the issue and found out that once I install scrubadub_spacy, that seems is the issue causing the error.<\/p>\n<pre><code>spacy.load(&quot;en_core_web_sm&quot;)\n<\/code><\/pre>\n<pre><code>OSError                                   Traceback (most recent call last)\n&lt;ipython-input-2-c6e652d70518&gt; in &lt;module&gt;\n     1 # Load English tokenizer, tagger, parser and NER\n----&gt; 2 nlp = spacy.load(&quot;en_core_web_sm&quot;)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/__init__.py in load(name, vocab, disable, exclude, config)\n    50     &quot;&quot;&quot;\n    51     return util.load_model(\n---&gt; 52         name, vocab=vocab, disable=disable, exclude=exclude, config=config\n    53     )\n    54 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model(name, vocab, disable, exclude, config)\n   418             return get_lang_class(name.replace(&quot;blank:&quot;, &quot;&quot;))()\n   419         if is_package(name):  # installed as package\n--&gt; 420             return load_model_from_package(name, **kwargs)  # type: ignore[arg-type]\n   421         if Path(name).exists():  # path to model data directory\n   422             return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_package(name, vocab, disable, exclude, config)\n   451     &quot;&quot;&quot;\n   452     cls = importlib.import_module(name)\n--&gt; 453     return cls.load(vocab=vocab, disable=disable, exclude=exclude, config=config)  # type: ignore[attr-defined]\n   454 \n   455 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/en_core_web_sm\/__init__.py in load(**overrides)\n    10 \n    11 def load(**overrides):\n---&gt; 12     return load_model_from_init_py(__file__, **overrides)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_init_py(init_file, vocab, disable, exclude, config)\n   619         disable=disable,\n   620         exclude=exclude,\n--&gt; 621         config=config,\n   622     )\n   623 \n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_model_from_path(model_path, meta, vocab, disable, exclude, config)\n   485     config_path = model_path \/ &quot;config.cfg&quot;\n   486     overrides = dict_to_dot(config)\n--&gt; 487     config = load_config(config_path, overrides=overrides)\n   488     nlp = load_model_from_config(config, vocab=vocab, disable=disable, exclude=exclude)\n   489     return nlp.from_disk(model_path, exclude=exclude, overrides=overrides)\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/spacy\/util.py in load_config(path, overrides, interpolate)\n   644     else:\n   645         if not config_path or not config_path.exists() or not config_path.is_file():\n--&gt; 646             raise IOError(Errors.E053.format(path=config_path, name=&quot;config.cfg&quot;))\n   647         return config.from_disk(\n   648             config_path, overrides=overrides, interpolate=interpolate\n\nOSError: [E053] Could not read config.cfg from \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/en_core_web_sm\/en_core_web_sm-2.3.1\/config.cfg\n<\/code><\/pre>\n<p>I installed the packages using the below three lines codes from <a href=\"https:\/\/spacy.io\/usage\" rel=\"nofollow noreferrer\">Spacy<\/a><\/p>\n<pre><code>pip install -U pip setuptools wheel\npip install -U spacy\npython -m spacy download en_core_web_sm\n<\/code><\/pre>\n<p>How should I fix this issue? thanks in advance.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1643912383590,
        "Question_score":2,
        "Question_tags":"python|python-3.6|spacy|azure-machine-learning-service|oserror",
        "Question_view_count":201,
        "Owner_creation_time":1573605534107,
        "Owner_last_access_time":1656003381830,
        "Owner_location":"Saint Louis, MO, USA",
        "Owner_reputation":25,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Question_last_edit_time":1643998339103,
        "Answer_body":"<p>Taking the path from your error message:<\/p>\n<pre><code>en_core_web_sm-2.3.1\/config.cfg\n<\/code><\/pre>\n<p>You have a model for v2.3, but it's looking for a <code>config.cfg<\/code>, which is only a thing in v3 of spaCy. It looks like you upgraded spaCy without realizing it.<\/p>\n<p>There are two ways to fix this. One is to reinstall the model with <code>spacy download<\/code>, which will get a version that matches your current spaCy version. If you are just starting something that is probably the best idea. Based on the release date of scrubadub, it seems to be intended for use with spaCy v3.<\/p>\n<p>However, note that v2 and v3 are pretty different - if you have a project with v2 of spaCy you might want to downgrade instead.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1644122814723,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70976353",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40028165,
        "Question_title":"Azure ML's web service asking for label?",
        "Question_body":"<p>I built a linear regression algorithm in Azure ML. On the &quot;Score Model&quot; module I can actually see the predictions and the rest of the features. However, when I deploy this project as a web service, the service is expecting the actual label of the data (e.g. I'm trying to predict a house's price and it asks me for the price of the house to make the prediction), which doesn't make any sense to me... What am I doing wrong? On the &quot;Train Model&quot; module I set that the label column is the HousePrice, which is what I'm trying to predict...<\/p>\n<p>This is my model:\n<a href=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/kI8qu.jpg\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I tried leaving that field blank but the prediction returns null...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_time":1476382562787,
        "Question_score":4,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":1012,
        "Owner_creation_time":1401729936860,
        "Owner_last_access_time":1662997148480,
        "Owner_location":null,
        "Owner_reputation":1102,
        "Owner_up_votes":390,
        "Owner_down_votes":25,
        "Owner_views":120,
        "Question_last_edit_time":1592644375060,
        "Answer_body":"<p>The input schema (names\/types of required input) based on the location in the graph where you attach the \"Web Service Input\" module. To get the schema you want, you will need to find -- or if necessary, create -- a place in the experiment where the data has the column names\/types you desire.<\/p>\n\n<p>Consider this simple example experiment that predicts whether a field called \"income\" will be above or below $50k\/year:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/nWaN2.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>When we click \"Set up web service\", the following graph is automatically generated:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/NMMpV.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>Since the input dataset and \"Web service input\" modules are connected to the same port, the web service schema will perfectly match the schema of the input dataset. This is unfortunate because the input dataset contains a column called \"income\", which is what our web service is supposed to predict -- this is equivalent to the problem that you are having.<\/p>\n\n<p>To get around it, we need to create a place in our experiment graph where we've dropped the unneeded \"income\" field from the input dataset, and attach the \"Web service input\" module there:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" rel=\"nofollow\"><img src=\"https:\/\/i.stack.imgur.com\/WPeSB.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>With this arrangement, the web service only requests the features actually needed to score the model. I'm sure you can use a similar method to create a predictive experiment with whatever input schema you need for your own work.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1476730527013,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40028165",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":66704314,
        "Question_title":"How to get Model ID of the Latest Version registered in Azure Machine Learning Service Model Registry using az ml cli?",
        "Question_body":"<p>Using Azure Machine Learning CLI extension, how do we get the Model ID for the latest version of a Model (with known model name)?<\/p>\n<p>To get the entire list of Model Details with a given name the command is<\/p>\n<pre><code>az ml model list --model-name [Model_Name] --resource-group [RGP_NAME] --subscription-id [SUB_ID] --workspace-name [WS_NAME]\n<\/code><\/pre>\n<p>Running this will give a list of all the models:<\/p>\n<pre><code>[\n  {\n    &quot;createdTime&quot;: &quot;2021-03-19T07:02:03.814172+00:00&quot;,\n    &quot;framework&quot;: &quot;Custom&quot;,\n    &quot;frameworkVersion&quot;: null,\n    &quot;id&quot;: &quot;model:2&quot;\n    &quot;name&quot;: &quot;model&quot;,\n    &quot;version&quot;: 3\n  },\n  {\n    &quot;createdTime&quot;: &quot;2021-03-19T06:46:34.301054+00:00&quot;,\n    &quot;framework&quot;: &quot;Custom&quot;,\n    &quot;frameworkVersion&quot;: null,\n    &quot;id&quot;: &quot;model:2&quot;,\n    &quot;name&quot;: &quot;model&quot;,\n    &quot;version&quot;: 2\n  },\n  {\n    &quot;createdTime&quot;: &quot;2021-03-19T06:38:56.558385+00:00&quot;,\n    &quot;framework&quot;: &quot;Custom&quot;,\n    &quot;frameworkVersion&quot;: null,\n    &quot;id&quot;: &quot;model:1&quot;,\n    &quot;name&quot;: &quot;model&quot;,\n    &quot;version&quot;: 1\n  }\n]\n<\/code><\/pre>\n<p>The <a href=\"https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/model?view=azure-cli-latest#ext_azure_cli_ml_az_ml_model_list\" rel=\"nofollow noreferrer\">Microsoft Documentation<\/a> mentions, we can use a <code>-l<\/code> parameter to get the latest version details:<\/p>\n<pre><code>az ml model list --model-name [Model_Name] --resource-group [RGP_NAME] --subscription-id [SUB_ID] --workspace-name [WS_NAME] -l\n<\/code><\/pre>\n<p>However, running this gives the following error:<\/p>\n<pre><code>ERROR: UnrecognizedArgumentError: unrecognized arguments: -l\n<\/code><\/pre>\n<p>What is the syntax to use this <code>-l<\/code> flag?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_time":1616140269540,
        "Question_score":2,
        "Question_tags":"azure|azure-cli|azure-machine-learning-service",
        "Question_view_count":545,
        "Owner_creation_time":1601729162437,
        "Owner_last_access_time":1663774065773,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Question_last_edit_time":null,
        "Answer_body":"<p>If we wish to obtain the model-id for the latest model, instead of using <code>az ml model<\/code> list with <code>-l<\/code> flag, using <code>az model show<\/code> will return the details for the latest model. The syntax to get a string for model-id will be:<\/p>\n<pre><code>az ml model show --model-id $(TRN_MODEL_ID) --resource-group $(AML_TRN_RG) --subscription-id $(AML_TRN_SUB_ID) --workspace-name $(AML_TRN_WS) --query name -o tsv\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1616423749203,
        "Answer_score":0.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66704314",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":40714064,
        "Question_title":"How \"Azure ML export data to SQL database by insert in a row of database.\"",
        "Question_body":"<p>I can only export data from AzureML by write instead to database that created previously. I need to know How to insert and fetch the data continuously the database because I need to use old data as well as the new data that get as the AzureML output to plot graph.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1479709864747,
        "Question_score":0,
        "Question_tags":"sql|database|azure|azure-sql-database|azure-machine-learning-studio",
        "Question_view_count":193,
        "Owner_creation_time":1455005478600,
        "Owner_last_access_time":1649248026317,
        "Owner_location":null,
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Question_last_edit_time":1480314865163,
        "Answer_body":"<ol>\n<li>Create a web service from the AzureML experiment. <\/li>\n<li>Access the web service using a program you written from C# or any language.<\/li>\n<li>You can get the output of the web service as a JSON.<\/li>\n<li>Use typical SQL ADD\/UPDATE queries to update the table<\/li>\n<li>When giving an input for the web service, fetch the data from the DB and pass as the JSON for it. <\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1480308703073,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/40714064",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58933565,
        "Question_title":"How to register model from the Azure ML Pipeline Script step",
        "Question_body":"<p>I am running the <code>pipeline.submit()<\/code> in AzureML, which has a <code>PythonScriptStep<\/code>.\nInside this step, I download a model from tensorflow-hub, retrain it and save it as a <code>.zip<\/code>, and finally, I would like to register it in the Azure ML.\nBut as inside the script I do not have a workspace, <code>Model.register()<\/code> is not the case.\nSo I am trying to use <code>Run.register_model()<\/code> method as below:<\/p>\n\n<pre><code>os.replace(os.path.join('.', archive_name + '.zip'), \n           os.path.join('.', 'outputs', archive_name + '.zip'))\n\nprint(os.listdir('.\/outputs'))\nprint('========================')\n\nrun_context = Run.get_context()\nfinetuning_model = run_context.register_model(model_name='finetuning_similarity_model',\n                                              model_path=os.path.join(archive_name+'.zip'),\n                                              tags={},\n                                              description=\"Finetuning Similarity model\")\n<\/code><\/pre>\n\n<p>But then I have got an error:<\/p>\n\n<blockquote>\n  <p>ErrorResponse \n  {\n      \"error\": {\n          \"message\": \"Could not locate the provided model_path retrained.zip in the set of files uploaded to the run:<\/p>\n<\/blockquote>\n\n<p>despite I have the retrained <code>.zip<\/code> in the <code>.\/outputs<\/code> dir as we can see from the log:<\/p>\n\n<pre><code>['retrained.zip']\n========================\n<\/code><\/pre>\n\n<p>I guess that I am doing something wrong?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1574164584153,
        "Question_score":7,
        "Question_tags":"python|azure-machine-learning-service",
        "Question_view_count":3429,
        "Owner_creation_time":1574162655727,
        "Owner_last_access_time":1632472959343,
        "Owner_location":null,
        "Owner_reputation":75,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Question_last_edit_time":1578744224353,
        "Answer_body":"<p>I was able to fix the same issue (<a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.exceptions.modelpathnotfoundexception?view=azure-ml-py\" rel=\"noreferrer\"><code>ModelPathNotFoundException<\/code><\/a>) by explicitly uploading the model into the run history record before trying to register the model:<\/p>\n\n<pre><code>run.upload_file(\"outputs\/my_model.pickle\", \"outputs\/my_model.pickle\")\n<\/code><\/pre>\n\n<p>Which I found surprising because this wasn't mentioned in many of the official examples and according to the <code>upload_file()<\/code> <a href=\"https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run.run?view=azure-ml-py#upload-file-name--path-or-stream-\" rel=\"noreferrer\">documentation<\/a>:<\/p>\n\n<blockquote>\n  <p>Runs automatically capture file in the specified output directory, which defaults to \".\/outputs\" for most run types. Use upload_file only when additional files need to be uploaded or an output directory is not specified.<\/p>\n<\/blockquote>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1578745983587,
        "Answer_score":14.0,
        "Question_favorite_count":2.0,
        "Answer_last_edit_time":1578746319987,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58933565",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38077884,
        "Question_title":"Can Azure calculate confidence interval for regressions?",
        "Question_body":"<p>I plan to try different regression methods provided by Azure ML Studio to predict numeric values. I wonder if it is possible to get the predictions together with corresponding confidence intervals. In other words, I would like the regression function to tell me not only the expected value (prediction) but also how confident it (the model) is about this value. Does Azure regression support this functionality?<\/p>\n\n<p><strong>ADDED<\/strong><\/p>\n\n<p>A related question. Can build in \"regressors\" estimate probability density functions? For example for a given case (a row in a data table) I would like to have not only a single number as a prediction (expected value) but also probabilities of all possible values.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1467121249227,
        "Question_score":1,
        "Question_tags":"azure|regression|confidence-interval|azure-machine-learning-studio",
        "Question_view_count":332,
        "Owner_creation_time":1262870449817,
        "Owner_last_access_time":1652799411040,
        "Owner_location":null,
        "Owner_reputation":116085,
        "Owner_up_votes":820,
        "Owner_down_votes":37,
        "Owner_views":4661,
        "Question_last_edit_time":1467123550237,
        "Answer_body":"<p>Currently, you will have to use R or python within Azure ML for confidence interval <\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1467268176063,
        "Answer_score":2.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38077884",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":34614582,
        "Question_title":"Send request as Json on UWP",
        "Question_body":"<p>I have deployed an AzureML published experiment with deployed web service. I tried to use the <a href=\"https:\/\/azure.microsoft.com\/en-us\/documentation\/articles\/machine-learning-consume-web-services\/\" rel=\"nofollow\">sample code provided in the configuration page<\/a>, but universal apps do not implement Http.Formatting yet, thus I couldn't use <a href=\"https:\/\/msdn.microsoft.com\/en-us\/library\/hh944521(v=vs.118).aspx\" rel=\"nofollow\">postasjsonasync<\/a>.<\/p>\n\n<p>I tried to follow the sample code as much as possible, but I'm getting statuscode of 415 \"Unsupported Media Type\", What's the mistake I'm doing?<\/p>\n\n<pre><code>var client = new HttpClient();\nclient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", apiKey);\n\/\/ client.BaseAddress = uri;\n\nvar scoreRequest = new\n{\n            Inputs = new Dictionary&lt;string, StringTable&gt;() {\n                    {\n                        \"dataInput\",\n                        new StringTable()\n                        {\n                            ColumnNames = new [] {\"Direction\", \"meanX\", \"meanY\", \"meanZ\"},\n                            Values = new [,] {  { \"\", x.ToString(), y.ToString(), z.ToString() },  }\n                        }\n                    },\n                },\n            GlobalParameters = new Dictionary&lt;string, string&gt;() { }\n };\n var stringContent = new StringContent(scoreRequest.ToString());\n HttpResponseMessage response = await client.PostAsync(uri, stringContent);\n<\/code><\/pre>\n\n<p>Many Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1452005613750,
        "Question_score":1,
        "Question_tags":"c#|json|uwp|dotnet-httpclient|azure-machine-learning-studio",
        "Question_view_count":3194,
        "Owner_creation_time":1352139399460,
        "Owner_last_access_time":1655105886893,
        "Owner_location":"Cyprus",
        "Owner_reputation":820,
        "Owner_up_votes":1492,
        "Owner_down_votes":12,
        "Owner_views":256,
        "Question_last_edit_time":null,
        "Answer_body":"<p>You'll need to serialize the object to a JSON string (I recommend using NewtonSoft.Json to make it easier) and set the content type accordingly. Here's an implementation I'm using in my UWP apps (note that <code>_client<\/code> is an <code>HttpClient<\/code>):<\/p>\n\n<pre><code>    public async Task&lt;HttpResponseMessage&gt; PostAsJsonAsync&lt;T&gt;(Uri uri, T item)\n    {\n        var itemAsJson = JsonConvert.SerializeObject(item);\n        var content = new StringContent(itemAsJson);\n        content.Headers.ContentType = new MediaTypeHeaderValue(\"application\/json\");\n\n        return await _client.PostAsync(uri, content);\n    }\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1452007973623,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/34614582",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":50439489,
        "Question_title":"Delete Project Azure ML Studio ( Web App)",
        "Question_body":"<p>How do I delete projects in my workspace ?when I click to delete a project the delete button is inactive. Tried clearing cache and whatnot but cannot delete the project from studio.azureml.net... how do I do this ? <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1526851287060,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":576,
        "Owner_creation_time":1506435894640,
        "Owner_last_access_time":1664081964040,
        "Owner_location":"Southeast Asia",
        "Owner_reputation":1922,
        "Owner_up_votes":1232,
        "Owner_down_votes":72,
        "Owner_views":404,
        "Question_last_edit_time":null,
        "Answer_body":"<p>I have reproduced your issue. Try to go to your project -> EDIT ->remove the <strong>ASSETS<\/strong> of your project. Then the delete button will be able.<\/p>\n\n<p>You could follow the screenshot.<\/p>\n\n<ol>\n<li>The <strong>DELETE<\/strong> button is disable.<\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/E850F.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/E850F.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>2.Go to <strong>EDIT<\/strong> and remove the <strong>ASSETS<\/strong>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/PbEZC.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PbEZC.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/2kBgO.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/2kBgO.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>3.Then the <strong>DELETE<\/strong> button will be able<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/08lOW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/08lOW.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1526865758890,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1526866401040,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/50439489",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":36260727,
        "Question_title":"Equivalent of Subset in Azure machine learning studio",
        "Question_body":"<p>I have a dataset in azure machine learning (.csv), on the same dataset I have multiple models build, I want to subset data for each of the model based on a different column<\/p>\n\n<p>Input:<\/p>\n\n<pre><code>ID col1 col2 col3\n1  0    13   0\n2  5    45   0\n3  10   0    34\n4  12   1    3\n<\/code><\/pre>\n\n<p>For the 1st model I want to retain all records where col1 not equal to None<\/p>\n\n<pre><code>ID col1 col2 col3\n2  5    45   0\n3  10   0    34\n4  12   1    3\n<\/code><\/pre>\n\n<p>Similarly for model 2<\/p>\n\n<pre><code>ID col1 col2 col3\n1  0    13   0\n2  5    45   0\n4  12   1    3\n<\/code><\/pre>\n\n<p>Hope it was clear<\/p>\n\n<p>The equivalent in R would be <\/p>\n\n<pre><code>df[!df$col1 == \"None\",] \n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1459161991533,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio",
        "Question_view_count":243,
        "Owner_creation_time":1406266059940,
        "Owner_last_access_time":1663232189147,
        "Owner_location":"Link\u00f6ping, Sweden",
        "Owner_reputation":1677,
        "Owner_up_votes":82,
        "Owner_down_votes":2,
        "Owner_views":221,
        "Question_last_edit_time":1459256566467,
        "Answer_body":"<p>You can use the \"Execute R Script\" module and just plug in your R code there.<\/p>\n\n<pre><code>df &lt;- maml.mapInputPort(1)\ndf &lt;- df[!df$col1 == \"None\",] \nmaml.mapOutputPort(\"df\");\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1461479422230,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/36260727",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":64394661,
        "Question_title":"Erro InvalidInputDatatype: Input of type 'Unknown' is not supported in azure (azureml.train.automl)",
        "Question_body":"<p>I have a pandas's DataFrame created by:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>TB_HISTORICO_MODELO = pd.read_sql(&quot;&quot;&quot;select DAT_INICIO_SEMANA_PLAN\n,COD_NEGOCIO\n,VENDA\n,LUCRO\n,MODULADO\n,RUPTURA\n,QTD_ESTOQUE_MEDIO\n,PECAS from TB&quot;&quot;&quot;, cursor)\n\nTB_HISTORICO_MODELO[&quot;DAT_INICIO_SEMANA_PLAN&quot;] = pd.to_datetime(TB_HISTORICO_MODELO[&quot;DAT_INICIO_SEMANA_PLAN&quot;])\n\ndataset = TB_HISTORICO_MODELO[TB_HISTORICO_MODELO['COD_NEGOCIO']=='A101'].drop(columns=['COD_NEGOCIO']) .reset_index(drop=True)\n<\/code><\/pre>\n<p>Everything look like right.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; dataset.dtypes\nDAT_INICIO_SEMANA_PLAN    datetime64[ns]\nVENDA                            float64\nLUCRO                            float64\nMODULADO                           int64\nRUPTURA                            int64\nQTD_ESTOQUE_MEDIO                  int64\nPECAS                            float64\ndtype: object\n<\/code><\/pre>\n<p>But when I rum this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>#%% Create the AutoML Config file and run the experiment on Azure\n\nfrom azureml.train.automl import AutoMLConfig\n\ntime_series_settings = {\n   'time_column_name': 'DAT_INICIO_SEMANA_PLAN',\n   'max_horizon': 14,\n   'country_or_region': 'BR',\n   'target_lags': 'auto'\n}\n\nautoml_config = AutoMLConfig(task='forecasting',\n                            primary_metric='normalized_root_mean_squared_error',\n                            blocked_models=['ExtremeRandomTrees'],\n                            experiment_timeout_minutes=30,\n                            training_data=dataset,\n                            label_column_name='VENDA',\n                            compute_target = compute_cluster,\n                            enable_early_stopping=True,\n                            n_cross_validations=3,\n                            # max_concurrent_iterations=4,\n                            # max_cores_per_iteration=-1,\n                            verbosity=logging.INFO,\n                            **time_series_settings)\n\nremote_run = Experimento.submit(automl_config, show_output=True)\n<\/code><\/pre>\n<p>I get the message<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; remote_run = Experimento.submit(automl_config, show_output=True)\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/core\/experiment.py&quot;, line 219, in submit\n    run = submit_func(config, self.workspace, self.name, **kwargs)\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 92, in _automl_static_submit\n    automl_config_object._validate_config_settings(workspace)\n  File &quot;\/home\/fnord\/venv\/lib64\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py&quot;, line 1775, in _validate_config_settings\n    supported_types=&quot;, &quot;.join(SupportedInputDatatypes.REMOTE_RUN_SCENARIO)\nazureml.train.automl.exceptions.ConfigException: ConfigException:\n        Message: Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset]\n        InnerException: None\n        ErrorResponse \n{\n    &quot;error&quot;: {\n        &quot;code&quot;: &quot;UserError&quot;,\n        &quot;message&quot;: &quot;Input of type 'Unknown' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset, azureml.pipeline.core.pipeline_output_dataset.PipelineOutputTabularDataset]&quot;,\n        &quot;details_uri&quot;: &quot;https:\/\/aka.ms\/AutoMLConfig&quot;,\n        &quot;target&quot;: &quot;training_data&quot;,\n        &quot;inner_error&quot;: {\n            &quot;code&quot;: &quot;BadArgument&quot;,\n            &quot;inner_error&quot;: {\n                &quot;code&quot;: &quot;ArgumentInvalid&quot;,\n                &quot;inner_error&quot;: {\n                    &quot;code&quot;: &quot;InvalidInputDatatype&quot;\n                }\n            }\n        }\n    }\n}\n\n<\/code><\/pre>\n<p>Where is wrong?<\/p>\n<p>documentation:\n<a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train<\/a>\n<a href=\"https:\/\/docs.microsoft.com\/pt-br\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/pt-br\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1602873387197,
        "Question_score":1,
        "Question_tags":"python|pandas|azure|azure-machine-learning-service",
        "Question_view_count":382,
        "Owner_creation_time":1522634496793,
        "Owner_last_access_time":1663943775803,
        "Owner_location":"Rio de Janeiro, RJ, Brasil",
        "Owner_reputation":264,
        "Owner_up_votes":276,
        "Owner_down_votes":2,
        "Owner_views":23,
        "Question_last_edit_time":null,
        "Answer_body":"<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#data-source-and-format?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">Configure AutoML Doc<\/a> says:<\/p>\n<blockquote>\n<p>For remote experiments, training data must be accessible from the remote compute. AutoML only accepts Azure Machine Learning TabularDatasets when working on a remote compute.<\/p>\n<\/blockquote>\n<p>It looks as if your <code>dataset<\/code> object is a Pandas DataFrame, when it should really be an Azure ML <code>Dataset<\/code>. Check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets?WT.mc_id=AI-MVP-5003930\" rel=\"nofollow noreferrer\">this doc<\/a> on creating Datasets.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1603004866533,
        "Answer_score":3.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1603005259150,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64394661",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":73146779,
        "Question_title":"ML Studio language studio failing to detect the source language",
        "Question_body":"<p>I am running a program in python to detect a language and translate that to English using azure machine learning studio. The code block mentioned below throwing error when trying to detect the language.<\/p>\n<blockquote>\n<p>Error 0002: Failed to parse parameter.<\/p>\n<\/blockquote>\n<pre><code>def sample_detect_language():\n    print(\n        &quot;This sample statement will be translated to english from any other foreign language&quot;\n       \n    )\n    \n    from azure.core.credentials import AzureKeyCredential\n    from azure.ai.textanalytics import TextAnalyticsClient\n\n    endpoint = os.environ[&quot;AZURE_LANGUAGE_ENDPOINT&quot;]\n    key = os.environ[&quot;AZURE_LANGUAGE_KEY&quot;]\n\n    text_analytics_client = TextAnalyticsClient(endpoint=endpoint)\n    documents = [\n        &quot;&quot;&quot;\n        The feedback was awesome\n        &quot;&quot;&quot;,\n        &quot;&quot;&quot;\n        la recensione \u00e8 stata fantastica\n        &quot;&quot;&quot;\n    ]\n\n    result = text_analytics_client.detect_language(documents)\n    reviewed_docs = [doc for doc in result if not doc.is_error]\n\n    print(&quot;Check the languages we got review&quot;)\n\n    for idx, doc in enumerate(reviewed_docs):\n        print(&quot;Number#{} is in '{}', which has ISO639-1 name '{}'\\n&quot;.format(\n            idx, doc.primary_language.name, doc.primary_language.iso6391_name\n        ))\n        if doc.is_error:\n            print(doc.id, doc.error)\n    \n    print(\n        &quot;Storing reviews and mapping to their respective ISO639-1 name &quot;\n        \n    )\n\n    review_to_language = {}\n    for idx, doc in enumerate(reviewed_docs):\n        review_to_language[documents[idx]] = doc.primary_language.iso6391_name\n\n\nif __name__ == '__main__':\n    sample_detect_language()\n<\/code><\/pre>\n<p>Any help to solve the issue is appreciated.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1658977363490,
        "Question_score":0,
        "Question_tags":"azure|azure-machine-learning-studio",
        "Question_view_count":50,
        "Owner_creation_time":1652123310643,
        "Owner_last_access_time":1663298985173,
        "Owner_location":null,
        "Owner_reputation":31,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The issue was raised because of missing the called parameters in the function. While doing language detection in machine learning studio, we need to assign end point and key credentials. In the code mentioned above, endpoint details were mentioned, but missed <strong>AzureKeyCredential.<\/strong><\/p>\n<pre><code>endpoint = os.environ[&quot;AZURE_LANGUAGE_ENDPOINT&quot;]\nkey = os.environ[&quot;AZURE_LANGUAGE_KEY&quot;]\ntext_analytics_client = TextAnalyticsClient(endpoint=endpoint)\n<\/code><\/pre>\n<p>replace the above line with the code block mentioned below<\/p>\n<pre><code>text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential= AzureKeyCredential(key))\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1659007284270,
        "Answer_score":1.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73146779",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":58019308,
        "Question_title":"ScriptRunConfig with datastore reference on AML",
        "Question_body":"<p>When trying to run a ScriptRunConfig, using :<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>src = ScriptRunConfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', ds.as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>\n\n<p>It doesn't work and breaks with this when I submit the job : <\/p>\n\n<pre><code>... lots of things... and then\nTypeError: Object of type 'DataReference' is not JSON serializable\n<\/code><\/pre>\n\n<p>However if I run it with the Estimator, it works. One of the differences is the fact that with a <code>ScriptRunConfig<\/code> we're using a list for parameters and the other is a dictionary.<\/p>\n\n<p>Thanks for any pointers!<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_time":1568929720367,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":1541,
        "Owner_creation_time":1538275960603,
        "Owner_last_access_time":1658458641830,
        "Owner_location":"Montreal, QC, Canada",
        "Owner_reputation":381,
        "Owner_up_votes":75,
        "Owner_down_votes":2,
        "Owner_views":50,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Being able to use <code>DataReference<\/code> in <code>ScriptRunConfig<\/code> is a bit more involved than doing just <code>ds.as_mount()<\/code>. You will need to convert it into a string in <code>arguments<\/code> and then update the <code>RunConfiguration<\/code>'s <code>data_references<\/code> section with the <code>DataReferenceConfiguration<\/code> created from <code>ds<\/code>. Please <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-remote-vm\/train-on-remote-vm.ipynb\" rel=\"nofollow noreferrer\">see here<\/a> for an example notebook on how to do that.<\/p>\n<p>If you are just reading from the input location and not doing any writes to it, please check out <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-create-register-datasets\" rel=\"nofollow noreferrer\"><code>Dataset<\/code><\/a>. It allows you to do exactly what you are doing without doing anything extra. <a href=\"https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/train-with-datasets.ipynb\" rel=\"nofollow noreferrer\">Here is an example notebook<\/a> that shows this in action.<\/p>\n<p>Below is a short version of the notebook<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from azureml.core import Dataset\n\n# more imports and code\n\nds = Datastore(workspace, 'mydatastore')\ndataset = Dataset.File.from_files(path=(ds, 'path\/to\/input-data\/within-datastore'))\n\nsrc = ScriptRunConfig(source_directory=project_folder, \n                      script='train.py', \n                      arguments=['--input-data-dir', dataset.as_named_input('input').as_mount(),\n                                 '--reg', '0.99'],\n                      run_config=run_config) \nrun = experiment.submit(config=src)\n<\/code><\/pre>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1568945686667,
        "Answer_score":4.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":1595974462437,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58019308",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":60397252,
        "Question_title":"Can I use Azure interactive mode for azure-cli-ml extension?",
        "Question_body":"<p>I'm using Azure CLI interactive mode <code>az interactive<\/code> to run below command. <br \/>\n<code>az ml folder attach -w yhd-mlws -g yhd-mlws-rg<\/code><br \/><br \/>\nIt prompts me with below error message.<br \/>\n<code>az: error: unrecognized arguments: -w yhd-mlws -g yhd-mlws-rg<\/code><br \/><br \/>\nBTW, both my Machine Learning workspace <code>yhd-mlws<\/code> and resource group <code>yhd-mlws-rg<\/code> had been created in my Azure subscription. Azure CLI extension for machine learning service had also been installed via <code>az extension add -n azure-cli-ml<\/code>.<br \/><br \/>\nThen I run command <code>az ml folder attach<\/code> without any argument. I get bellow error message.<br \/><\/p>\n\n<pre><code>Message: Error, default workspace not set and workspace name parameter not provided.\nPlease set a default workspace using \"az ml folder attach -w myworkspace -g myresourcegroup\" or provide a value for the workspace name parameter.\n<\/code><\/pre>\n\n<p>The command window exit the interactive mode after above error message. Then I try the command <code>az ml folder attach -w yhd-mlws -g yhd-mlws-rg<\/code> again, bingo! It works. <br \/>\nHere comes my question, does azure-cli-ml extension support Azure CLI interactive mode? You know, Azure CLI interactive mode is amazing and I want to use it whenever possible. Thanks!<br \/><br \/>\nBTW, I'm running windows command window in Windows Server 2016 Datcenter. Azure-cli version is 2.0.79.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1582642024300,
        "Question_score":1,
        "Question_tags":"azure|azure-cli|azure-machine-learning-service",
        "Question_view_count":408,
        "Owner_creation_time":1582361231693,
        "Owner_last_access_time":1655516080367,
        "Owner_location":"Guangzhou, China",
        "Owner_reputation":393,
        "Owner_up_votes":37,
        "Owner_down_votes":1,
        "Owner_views":58,
        "Question_last_edit_time":1582678582157,
        "Answer_body":"<p>I can reproduce your issue, the interactive mode should support the <code>azure-cli-ml<\/code> extension, because when I run <code>az ml workspace list<\/code>, it works, once I pass the <code>-g<\/code> parameter, it gives the same error, maybe it is a bug, but I am not sure, the <code>interactive<\/code> is in preview currently.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/g4FvM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/g4FvM.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>If you want to run <code>az ml folder attach -w yhd-mlws -g yhd-mlws-rg<\/code> in the interactive mode, my workaround is to pass the <code>#<\/code>, i.e. <code># az ml folder attach -w yhd-mlws -g yhd-mlws-rg<\/code>.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/pWMyH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/pWMyH.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1582686710413,
        "Answer_score":2.0,
        "Question_favorite_count":0.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60397252",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":38189399,
        "Question_title":"azure ml experiment return different results than webservice",
        "Question_body":"<p>same input is used in two cases, but different result is returned from python module<\/p>\n\n<p>here is the python script that return the result to the webservice:<\/p>\n\n<pre><code>import pandas as pd\nimport sys\n\n\n  def get_segments(dataframe):\n     dataframe['segment']=dataframe['segment'].astype('str')\n     segments = dataframe.loc[~dataframe['segment'].duplicated()]['segment']\n     return segments\n\n\n  def azureml_main(dataframe1 = None, dataframe2 = None):\n\n   df = dataframe1\n   segments = get_segments(df)\n   segmentCount =segments.size\n\n   if (segmentCount &gt; 0) :\n      res = pd.DataFrame(columns=['segmentId','recommendation'],index=[range(segmentCount)])\n    i=0    \n    for seg in segments:\n        d= df.query('segment ==[\"{}\"]'.format(seg)).sort(['count'],ascending=[0])\n\n        res['segmentId'][i]=seg\n        recommendation='['\n        for index, x in d.iterrows():\n            item=str(x['ItemId'])\n            recommendation = recommendation + item + ','\n        recommendation = recommendation[:-1] + ']'\n        res['recommendation'][i]= recommendation\n        i=i+1\n   else:\n\n      res = pd.DataFrame(columns=[seg,pdver],index=[range(segmentCount)])\n\nreturn res,\n<\/code><\/pre>\n\n<p>when in experiment it returnd the actual itemIds, when in webservice it returns some numbers<\/p>\n\n<p>the purpose of this code is to pivot some table by segment column for recommendation<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1467651436410,
        "Question_score":3,
        "Question_tags":"python|web-services|azure|cortana-intelligence|azure-machine-learning-studio",
        "Question_view_count":264,
        "Owner_creation_time":1320061998253,
        "Owner_last_access_time":1656424560827,
        "Owner_location":null,
        "Owner_reputation":778,
        "Owner_up_votes":176,
        "Owner_down_votes":6,
        "Owner_views":89,
        "Question_last_edit_time":1468140771380,
        "Answer_body":"<p>After discussion with the product team from Microsoft. the issue was resolved.\nthe product team rolled out an update to the web service first, and only later to the ML-Studio, which fixed an issue with categorical attributes in \"Execute python script\".\nthe issue was in a earlier stage of the flow and has nothing to do with the python code above.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_time":1468139423743,
        "Answer_score":0.0,
        "Question_favorite_count":1.0,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/38189399",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":67734831,
        "Question_title":"Does a AzureML webservice overwrite reset the Data Collection Dataset?",
        "Question_body":"<p>If we have an AzureML web service endpoint that is collecting data (for Data Drift Monitoring), does overwriting the web service endpoint with a new version of the model break links with the Dataset registered for collecting data.<\/p>\n<p>The relative path to this dataset is:\n<code>&lt;Subscription-ID&gt;\/&lt;Resource-Group&gt;\/&lt;Workspace&gt;\/&lt;Webservice-Name&gt;\/&lt;model-name&gt;\/&lt;version&gt;\/inputs\/**\/inputs*.csv<\/code><\/p>\n<p>If we redeploy a new version using <code>az ml model deploy ..... --overwrite<\/code>, will we need a new reference to a new Dataset for detecting Data Drift?<\/p>\n<p>If we use <code>az ml service update ..<\/code>, will the Dataset reference be kept intact?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_time":1622187967130,
        "Question_score":2,
        "Question_tags":"azure-machine-learning-service",
        "Question_view_count":44,
        "Owner_creation_time":1601729162437,
        "Owner_last_access_time":1663774065773,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Owner_reputation":887,
        "Owner_up_votes":187,
        "Owner_down_votes":32,
        "Owner_views":130,
        "Question_last_edit_time":null,
        "Answer_body":"<p>Since the Dataset Asset is a simple reference to a location in a Datastore. Assuming the model version and service name does not change, the Dataset reference also will not change. If however, with every Service Update - The model version changes then adding a Dataset with Relative Path:<\/p>\n<pre><code>&lt;Subscription-ID&gt;\/&lt;Resource-Group&gt;\/&lt;Workspace&gt;\/&lt;Webservice-Name&gt;\/&lt;model-name&gt;\/*\/inputs\/**\/inputs*.csv\n<\/code><\/pre>\n<p>Will solve the problem. Since Data Drift is another service referencing this Dataset asset, it will keep working as expected.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_time":1624012850200,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67734831",
        "Question_exclusive_tag":"Azure Machine Learning"
    },
    {
        "Question_id":72659937,
        "Question_title":"CI \/ CD and repository integration for Azure ML Workspace",
        "Question_body":"<p>I am interested in knowing how can I integrate a repository with Azure Machine Learning Workspace.<\/p>\n<h2>What have I tried ?<\/h2>\n<p>I have some experience with Azure Data Factory and usually I have setup workflows where<\/p>\n<ol>\n<li><p>I have a <code>dev<\/code> azure data factory instance that is linked to azure repository.<\/p>\n<\/li>\n<li><p>Changes made to the repository using the code editor.<\/p>\n<\/li>\n<li><p>These changes are published via the <code>adf_publish<\/code> branch to the live <code>dev<\/code> instance<\/p>\n<\/li>\n<li><p>I use CI \/ CD pipeline and the AzureRMTemplate task to deploy the templates in the publish branch to release the changes to <code>production<\/code> environment<\/p>\n<\/li>\n<\/ol>\n<h2>Question:<\/h2>\n<ul>\n<li>How can I achieve the same \/ similar workflow with Azure Machine Learning Workspace ?<\/li>\n<li>How is CI \/ CD done with Azure ML Workspace<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_time":1655471491697,
        "Question_score":0,
        "Question_tags":"azure-machine-learning-studio|azure-machine-learning-service",
        "Question_view_count":94,
        "Owner_creation_time":1271093246887,
        "Owner_last_access_time":1663988177550,
        "Owner_location":"United States",
        "Owner_reputation":9826,
        "Owner_up_votes":1723,
        "Owner_down_votes":15,
        "Owner_views":1238,
        "Question_last_edit_time":null,
        "Answer_body":"<p>The following workflow is the official practice to be followed to achieve the task required.<\/p>\n<ol>\n<li>Starting with the architecture mentioned below<\/li>\n<\/ol>\n<p><a href=\"https:\/\/i.stack.imgur.com\/KdRUa.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/KdRUa.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ul>\n<li>we need to have a specific data store to handle the dataset<\/li>\n<li>Perform the regular code modifications using the IDE like Jupyter Notebook or VS Code<\/li>\n<li>Train and test the model<\/li>\n<li>To register and operate on the model, deploy the model image as a web service and operate the rest.<\/li>\n<\/ul>\n<ol start=\"2\">\n<li><strong>Configure the CI Pipeline:<\/strong><\/li>\n<\/ol>\n<ul>\n<li><p>Follow the below steps to complete the procedure<\/p>\n<p><strong>Before implementation:<\/strong><\/p>\n<pre><code>- We need azure subscription enabled account\n- DevOps activation must be activated.\n<\/code><\/pre>\n<\/li>\n<li><p>Open DevOps portal with enabled SSO<\/p>\n<\/li>\n<li><p>Navigate to <strong>Pipeline -&gt; Builds -&gt; Choose the model which was created -&gt; Click on EDIT<\/strong>\n<a href=\"https:\/\/i.stack.imgur.com\/yUVZl.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/yUVZl.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>Build pipeline will be looking like below screen\n<a href=\"https:\/\/i.stack.imgur.com\/VSKJq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/VSKJq.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<\/li>\n<li><p>We need to use Anaconda distribution for this example to get all the dependencies.<\/p>\n<\/li>\n<li><p>To install environment dependencies, check the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/devops\/pipelines\/tasks\/package\/conda-environment?view=azure-devops&amp;viewFallbackFrom=azdevops\" rel=\"nofollow noreferrer\">link<\/a><\/p>\n<\/li>\n<li><p>Use the python environment, under <strong>Install Requirements<\/strong> in user setup.<\/p>\n<\/li>\n<li><p>Select <strong>create or get workspace<\/strong> select your account subscription as mentioned in below screen<\/p>\n<\/li>\n<\/ul>\n<p><a href=\"https:\/\/i.stack.imgur.com\/vt0el.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/vt0el.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<ul>\n<li>Save the changes happened in other tasks and all those muse be in same subscription.\n<a href=\"https:\/\/i.stack.imgur.com\/WJxCL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/WJxCL.png\" alt=\"enter image description here\" \/><\/a><\/li>\n<\/ul>\n<p>The entire CI\/CD procedure and solution was documented in <a href=\"https:\/\/www.azuredevopslabs.com\/labs\/vstsextend\/aml\/#author-praneet-singh-solanki\" rel=\"nofollow noreferrer\">link<\/a><\/p>\n<p><strong>Document Credit: Praneet Singh Solanki<\/strong><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_time":1655682328283,
        "Answer_score":0.0,
        "Question_favorite_count":null,
        "Answer_last_edit_time":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72659937",
        "Question_exclusive_tag":"Azure Machine Learning"
    }
]