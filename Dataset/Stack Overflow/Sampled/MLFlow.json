[
    {
        "Question_id":73746436,
        "Question_title":"Mlflow-got error no host supplied,provided uri tracking,help me to resolve it",
        "Question_body":"<p>In below image can see i mention tracking uri and trying to load model but facing error in host supplied. <a href=\"https:\/\/i.stack.imgur.com\/GmLeq.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/GmLeq.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-16 14:34:29.023 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"mlflow|mlops",
        "Question_view_count":12,
        "Owner_creation_date":"2019-12-12 05:07:25.14 UTC",
        "Owner_last_access_date":"2022-09-24 21:10:52.373 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Mumbai, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73746436",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70618366,
        "Question_title":"Mlflow model in Heroku",
        "Question_body":"<p>I built an MLflow model and call a prediction on a streamlit dashboard, in it work fine in local.\nIn Heroku, the app which works fine locally failed to send the request online, what am I missing to such deployment?<\/p>\n<p>Below the error code raised.<\/p>\n<p>Procfile :<\/p>\n<pre><code>web: mlflow sagemaker deploy -m mlflow_model\/\nweb: sh setup.sh &amp;&amp; streamlit run app.py\n<\/code><\/pre>\n<p>Heroku logs:<\/p>\n<pre><code>2022-01-07T10:14:15.759252+00:00 app[web.1]: Traceback (most recent call last):\n2022-01-07T10:14:15.759252+00:00 app[web.1]: File &quot;\/app\/.heroku\/python\/lib\/python3.9\/site-packages\/streamlit\/script_runner.py&quot;, line 354, in _run_script\n2022-01-07T10:14:15.759252+00:00 app[web.1]: exec(code, module.__dict__)\n2022-01-07T10:14:15.759252+00:00 app[web.1]: File &quot;\/app\/app.py&quot;, line 204, in &lt;module&gt;\n2022-01-07T10:14:15.759252+00:00 app[web.1]: main()\n2022-01-07T10:14:15.759252+00:00 app[web.1]: File &quot;\/app\/app.py&quot;, line 119, in main\n2022-01-07T10:14:15.759253+00:00 app[web.1]: pred = request_prediction(MLFLOW_URI, ml_data)[0]\n2022-01-07T10:14:15.759253+00:00 app[web.1]: File &quot;\/app\/app.py&quot;, line 63, in request_prediction\n2022-01-07T10:14:15.759253+00:00 app[web.1]: response = requests.request(\n2022-01-07T10:14:15.759253+00:00 app[web.1]: File &quot;\/app\/.heroku\/python\/lib\/python3.9\/site-packages\/requests\/api.py&quot;, line 61, in request\n2022-01-07T10:14:15.759253+00:00 app[web.1]: return session.request(method=method, url=url, **kwargs)\n2022-01-07T10:14:15.759254+00:00 app[web.1]: File &quot;\/app\/.heroku\/python\/lib\/python3.9\/site-packages\/requests\/sessions.py&quot;, line 529, in request\n2022-01-07T10:14:15.759254+00:00 app[web.1]: resp = self.send(prep, **send_kwargs)\n2022-01-07T10:14:15.759254+00:00 app[web.1]: File &quot;\/app\/.heroku\/python\/lib\/python3.9\/site-packages\/requests\/sessions.py&quot;, line 645, in send\n2022-01-07T10:14:15.759254+00:00 app[web.1]: r = adapter.send(request, **kwargs)\n2022-01-07T10:14:15.759254+00:00 app[web.1]: File &quot;\/app\/.heroku\/python\/lib\/python3.9\/site-packages\/requests\/adapters.py&quot;, line 519, in send\n2022-01-07T10:14:15.759254+00:00 app[web.1]: raise ConnectionError(e, request=request)\n2022-01-07T10:14:15.759259+00:00 app[web.1]: requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: \/invocations (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7f2452d23790&gt;: Failed to establish a new connection: [Errno 111] Connection refused'))\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-07 08:15:18.273 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-01-07 11:19:14.363 UTC",
        "Question_score":0,
        "Question_tags":"heroku|streamlit|mlflow",
        "Question_view_count":148,
        "Owner_creation_date":"2022-01-03 11:45:30.27 UTC",
        "Owner_last_access_date":"2022-01-31 05:12:53.3 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70618366",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73366433,
        "Question_title":"How to restore code of pyfunc class in MlFlow?",
        "Question_body":"<p>I have lost a code of my pyfunc class which I uploaded to MlFlow. Model is working on a production but via MLFlow UI I can't get code view of model class. For some R models I can get code class using load_model. After call this method I get the whole code view of class which is uploaded to MlFlow. Unfortunately, it doesnt work the same way in python. All files are inside hdfs directory of MLFlow.<\/p>\n<pre><code>import mlflow\nlogged_model = '&quot;file:\/\/\/var\/mm\/mlflow\/artifacts\/***\/*******\/artifacts\/my_model_name'\n\n# Load model as a PyFuncModel.\nloaded_model = mlflow.pyfunc.load_model(logged_model)\n<\/code><\/pre>\n<p>After invoking to loaded_model I get only some not important infos about model:<\/p>\n<pre><code>mlflow.pyfunc.loaded_model:\n  artifact_path: my_model_name\n  flavor: mlflow.pyfunc.model\n  run_id: *****\n<\/code><\/pre>\n<p>How can I check the code of the class which was uploaded to MLFlow earlier?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-15 21:07:53.73 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-16 07:14:09.49 UTC",
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":31,
        "Owner_creation_date":"2021-04-03 20:09:07.677 UTC",
        "Owner_last_access_date":"2022-09-23 14:47:28.92 UTC",
        "Owner_reputation":7,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73366433",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68722437,
        "Question_title":"Azure : Ansible role for deploying ML model integrated over databricks",
        "Question_body":"<p>I have developed ML predictive model on historical data in Azure Databricks using python notebook.\nWhich means i have done data extraction, preparation, feature engineering and model training everything done in Databricks using python notebook.\nI have almost completed development part of it, now we want to deploy ML model into production using ansible roles.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-08-10 07:13:27.8 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-08-11 06:34:36.903 UTC",
        "Question_score":1,
        "Question_tags":"deployment|databricks|mlflow|mlmodel",
        "Question_view_count":128,
        "Owner_creation_date":"2020-11-16 06:35:10.493 UTC",
        "Owner_last_access_date":"2021-11-29 05:21:57.803 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68722437",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72098661,
        "Question_title":"Failed to write to mlflow after deleting experiment via mlflow UI",
        "Question_body":"<p>I'm using mlflow version 1.18.0<\/p>\n<p>When I delete experiment from <code>mlflow<\/code> <em>UI<\/em>, and than try to create and write a new experiment (with same name which I just deleted) I'm getting error on this line code:<\/p>\n<pre><code>mlflow.start_run(run_name=run_name)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>error mlflow.util.rest_util API resest to faild with code 500 != 200\n<\/code><\/pre>\n<p>If I change the experiment name, I have no problem to write new tests.<\/p>\n<ol>\n<li>Why is this happening ? (as I wrote, I delete the experiment name)<\/li>\n<li>Is there a way to solve it (without giving new experiment name) ?<\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-03 11:22:45.597 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python-3.x|mlflow",
        "Question_view_count":45,
        "Owner_creation_date":"2014-05-23 08:26:35.28 UTC",
        "Owner_last_access_date":"2022-09-19 12:37:21.063 UTC",
        "Owner_reputation":3934,
        "Owner_up_votes":1052,
        "Owner_down_votes":6,
        "Owner_views":416,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72098661",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72694707,
        "Question_title":"Multiple artifact paths when logging a model using mlflow and sklearn",
        "Question_body":"<p>I'm using mlflow to log parameters and artifacts of a Logistic Regression, but when I try to log the model so I can see all the files in the Mlflow UI, I see two folders: one named 'model' and the other one named 'logger' (the one I set).<\/p>\n<pre><code>model = LogisticRegression()\n\nmlflow.set_tracking_uri('file:\/\/\/artifacts')\nmlflow.set_experiment('test')\nmlflow.autolog()\n\nwith mlflow.start_run(run_name=run_name) as run:\n   model.train(X_train, y_train)\n   mlflow.sklearn.log_model(model, 'logreg')\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/BtIHo.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/BtIHo.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Not sure if I'm missing something or if there's a configuration for that.<\/p>\n<p>I hope someone out there can help me!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-21 02:24:59.153 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|machine-learning|scikit-learn|mlflow|scikit-learn-pipeline",
        "Question_view_count":122,
        "Owner_creation_date":"2018-12-10 18:48:11.223 UTC",
        "Owner_last_access_date":"2022-08-01 19:20:26.413 UTC",
        "Owner_reputation":131,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":42,
        "Answer_body":"<p>You have set <code>autolog<\/code> and you are also logging the model explicitly. Remove one and then try.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-22 21:24:47.183 UTC",
        "Answer_score":2.0,
        "Owner_location":"Zacatecas, Mexico",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72694707",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69479488,
        "Question_title":"Hi. I am very new to MLFlow, and want to implement MLFlow project on my own ML model. However I am getting \"\"Could not find main among entry points\"\"",
        "Question_body":"<p>The full error message is as below:<\/p>\n<pre><code>ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] ===\n\n<\/code><\/pre>\n<p>I also try the solutions suggested here <code>https:\/\/github.com\/mlflow\/mlflow\/issues\/1094<\/code>, but the result is the same.<\/p>\n<p>Below I provide all the required files to run <code>MLflow<\/code> project.<\/p>\n<p>The <code>conda.yaml<\/code> file<\/p>\n<pre><code>name: lightgbm-example\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.6\n  - pip\n  - pip:\n      - mlflow&gt;=1.6.0\n      - lightgbm\n      - pandas\n      - numpy\n<\/code><\/pre>\n<p>The MLProject file<\/p>\n<pre><code>name: lightgbm-example\nconda_env: ~\/Desktop\/MLflow\/conda.yaml\nentry-points:\n    main:\n      parameters:\n        learning_rate: {type: float, default: 0.1}\n        colsample_bytree: {type: float, default: 1.0}\n        subsample: {type: float, default: 1.0} \n      command: |\n          python3 ~\/Desktop\/MLflow\/Test.py \\\n            --learning-rate={learning_rate} \\\n            --colsample-bytree={colsample_bytree} \\\n            --subsample={subsample}\n<\/code><\/pre>\n<p>My Test.py file<\/p>\n<pre><code>import pandas as pd\nimport lightgbm as lgb\nimport numpy as np\nimport mlflow\nimport mlflow.lightgbm\nimport argparse\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=&quot;LightGBM example&quot;)\n    parser.add_argument(\n        &quot;--learning-rate&quot;,\n        type=float,\n        default=0.1,\n        help=&quot;learning rate to update step size at each boosting step (default: 0.3)&quot;,\n    )\n    parser.add_argument(\n        &quot;--colsample-bytree&quot;,\n        type=float,\n        default=1.0,\n        help=&quot;subsample ratio of columns when constructing each tree (default: 1.0)&quot;,\n    )\n    parser.add_argument(\n        &quot;--subsample&quot;,\n        type=float,\n        default=1.0,\n        help=&quot;subsample ratio of the training instances (default: 1.0)&quot;,\n    )\n    return parser.parse_args()\n\ndef find_specificity(c_matrix):\n    specificity = c_matrix[1][1]\/(c_matrix[1][1]+c_matrix[0][1])\n    return specificity\n    \n    \ndef main():\n\n    args = parse_args()\n\n    df = pd.read_csv('~\/Desktop\/MLflow\/Churn_demo.csv')\n    train_df = df.sample(frac=0.8, random_state=25)\n    test_df = df.drop(train_df.index)\n\n\n        \n    train_df.drop(['subscriberid'], axis = 1, inplace = True)\n    test_df.drop(['subscriberid'], axis = 1, inplace = True)\n\n    TrainX = train_df.iloc[:,:-1]\n    TrainY = train_df.iloc[:,-1]\n\n    TestX = test_df.iloc[:,:-1]\n    TestY = test_df.iloc[:,-1]\n    \n    mlflow.lightgbm.autolog()\n    \n    dtrain = lgb.Dataset(TrainX, label=TrainY)\n    dtest = lgb.Dataset(TestX, label=TestY)\n    \n    with mlflow.start_run():\n\n        parameters = {\n            'objective': 'binary',\n            'device':'cpu',\n            'num_threads': 6,\n            'num_leaves': 127,\n            'metric' : 'binary',\n            'lambda_l2':5,\n            'max_bin': 63,\n            'bin_construct_sample_cnt' :2*1000*1000,\n            'learning_rate': args.learning_rate,\n            'colsample_bytree': args.colsample_bytree,\n            'subsample': args.subsample,\n            'verbose': 1\n        }\n\n\n\n        model = lgb.train(parameters,\n                       dtrain,\n                       valid_sets=dtest,\n                       num_boost_round=10000,\n                       early_stopping_rounds=10)\n                       \n               \n        y_proba=model.predict(TestX)\n        pred=np.where(y_proba&gt;0.25,1,0) \n        conf_matrix = confusion_matrix(TestY,pred)\n        \n        specificity = find_specificity(conf_matrix)\n        acc = accuracy_score(TestY,pred)\n        \n        mlflow.log_metric({&quot;specificity&quot; : specificity, &quot;accuracy&quot; : acc})\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n        \n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-07 10:24:39.323 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|yaml|mlflow",
        "Question_view_count":418,
        "Owner_creation_date":"2020-03-06 10:50:11.22 UTC",
        "Owner_last_access_date":"2022-09-21 15:31:59.043 UTC",
        "Owner_reputation":23,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>Fortunately, I have been resolved my problem. I list some solutions for the same error which can help you in the future if you face the same problem.<\/p>\n<ol>\n<li>File names. The file names should be the same suggested in MLFlow docs <code>https:\/\/mlflow.org\/ <\/code>. For example not <code>conda.yamp<\/code>, but <code>conda.yaml<\/code>, as there was such problem in <code>https:\/\/github.com\/mlflow\/mlflow\/issues\/3856<\/code><\/li>\n<li>The <code>conda.yaml<\/code> file does not support Tab, please consider using spaces instead<\/li>\n<li>In the MLProject file name 'P' should be the upper case before MLFlow 1.4. But the later versions it does not matter as explained there <code>https:\/\/github.com\/mlflow\/mlflow\/issues\/1094<\/code><\/li>\n<li>(In my case) MLProject file is space sensitive. Let the <code> https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples<\/code> GitHub examples guide you.<\/li>\n<\/ol>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-11 10:01:04.143 UTC",
        "Answer_score":0.0,
        "Owner_location":"Baku, Azerbaijan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69479488",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64771247,
        "Question_title":"Logging a PySpark dataframe into a MLFlow Artifact",
        "Question_body":"<p>I am currently writing an MLFlow artifact to the dbfs but I am using pandas using the code below...<\/p>\n<pre><code>temp = tempfile.NamedTemporaryFile(prefix=&quot;*****&quot;, suffix=&quot;.csv&quot;)\ntemp_name = temp.name\ntry:\n  df.to_csv(temp_name, index=False)\n  mlflow.log_artifact(temp_name, &quot;******&quot;)\nfinally:\n  temp.close() # Delete the temp file\n<\/code><\/pre>\n<p>How would I write this if 'df' was a spark dataframe?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2020-11-10 14:53:20.127 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|pyspark|mlflow",
        "Question_view_count":810,
        "Owner_creation_date":"2020-06-30 12:25:39.237 UTC",
        "Owner_last_access_date":"2022-08-12 13:42:28.437 UTC",
        "Owner_reputation":129,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64771247",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64168937,
        "Question_title":"Writing a custom predict method using MLFlow and pyspark",
        "Question_body":"<p>I am having trouble writing a custom predict method using MLFlow and pyspark (2.4.0). What I have so far is a custom transformer that changes the data into the format I need.<\/p>\n<pre><code>class CustomGroupBy(Transformer):\n    def __init__(self):\n        pass\n    def _transform(self, dataset):\n        df = dataset.select(&quot;userid&quot;, explode(split(&quot;widgetid&quot;, ',')).alias(&quot;widgetid&quot;))\n        return(df)\n<\/code><\/pre>\n<p>Then I built a custom estimator to run one of the pyspark machine learning algorithms<\/p>\n<pre><code>class PipelineFPGrowth(Estimator, HasInputCol, DefaultParamsReadable, DefaultParamsWritable): \n    def __init__(self, inputCol=None, minSupport=0.005, minConfidence=0.01):\n        super(PipelineFPGrowth, self).__init__()\n        self.minSupport = minSupport\n        self.minConfidence = minConfidence\n    def setInputCol(self, value):\n        return(self._set(inputCol=value))\n    def _fit(self, dataset):\n        c = self.getInputCol() \n        fpgrowth = FPGrowth(itemsCol=c, minSupport=self.minSupport, minConfidence=self.minConfidence)\n        model = fpgrowth.fit(dataset)\n        return(model)\n<\/code><\/pre>\n<p>This runs in the MLFlow pipeline.<\/p>\n<pre><code>pipeline = Pipeline(stages = [CustomGroupBy,PipelineFPGrowth]).fit(df)\n<\/code><\/pre>\n<p>This all works. If I create a new pyspark dataframe with new data to predict on, I get predictions.<\/p>\n<pre><code>newDF = spark.createDataFrame([(123456,['123ABC', '789JSF'])], [&quot;userid&quot;, &quot;widgetid&quot;])\npipeline.stages[1].transform(newDF).show(3, False)\n\n# How to access frequent itemset.\npipeline.stages[1].freqItemsets.show(3, False)\n<\/code><\/pre>\n<p>Where I run into problems is writing a custom predict. I need to append the frequent itemset that FPGrowth generates to the end of the predictions. I have written the logic for that, but I am having a hard time figuring out how to put it into a custom method. I have tried adding it to my custom estimator but this didn't work. Then I wrote a separate class to take in the returned model and give the extended predictions. This was also unsuccessful.<\/p>\n<p>Eventually I need to log and save the model so I can Dockerize it, which means I will need a custom flavor and to use the pyfunc function. Does anyone have a hint on how to extend the predict method and then log and save the model?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-02 09:07:10.127 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2020-10-02 09:55:20.82 UTC",
        "Question_score":3,
        "Question_tags":"python|docker|machine-learning|pyspark|mlflow",
        "Question_view_count":331,
        "Owner_creation_date":"2011-12-06 11:56:12.023 UTC",
        "Owner_last_access_date":"2022-07-04 20:51:05.6 UTC",
        "Owner_reputation":45,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Switzerland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64168937",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71687131,
        "Question_title":"How to import MLflow tracking server WSGI application via Flask or FastAPI?",
        "Question_body":"<p>MLflow provides a very cool tracking server, however, this server does not provide authentication or RBAC which is required for my needs.<\/p>\n<p>I would like to add my own authentication and RBAC functionality. I think one way to accomplish this is to import the MLflow WSGI application object and add some middleware layers to perform authentication \/ authorization before passing requests through to the tracking server, essentially proxying requests through my custom middleware stack.<\/p>\n<p>How do I go about doing this? I can see from <a href=\"https:\/\/fastapi.tiangolo.com\/advanced\/wsgi\/\" rel=\"nofollow noreferrer\">these docs<\/a> that I can use FastAPI to import another WSGI application and add custom middleware, but I'm not sure of a few things<\/p>\n<ol>\n<li>Where do I find the MLflow tracking server WSGI app (where can it be imported from)?<\/li>\n<li>How do I pass through the relevant arguments to the MLflow tracking server? I.e. the tracking server expects params to configure the backend storage layer, host, and port. If I just import the application object, how do I pass those parameters to it?<\/li>\n<\/ol>\n<p>edit - it looks like the Flask application can be found here <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/__init__.py#L28\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/server\/__init__.py#L28<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-31 05:05:57.78 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-03-31 05:47:50.28 UTC",
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":394,
        "Owner_creation_date":"2015-03-10 05:37:19.877 UTC",
        "Owner_last_access_date":"2022-09-23 19:26:30.29 UTC",
        "Owner_reputation":3256,
        "Owner_up_votes":81,
        "Owner_down_votes":0,
        "Owner_views":164,
        "Answer_body":"<p>This was actually very simple, below is an example using FastAPI to import and mount the MLflow WSGI application.<\/p>\n<pre><code>import os\nimport subprocess\nfrom fastapi import FastAPI\nfrom fastapi.middleware.wsgi import WSGIMiddleware\n\nfrom mlflow.server import app as mlflow_app\n\napp = FastAPI()\napp.mount(&quot;\/&quot;, WSGIMiddleware(mlflow_app))\n\nBACKEND_STORE_URI_ENV_VAR = &quot;_MLFLOW_SERVER_FILE_STORE&quot;\nARTIFACT_ROOT_ENV_VAR = &quot;_MLFLOW_SERVER_ARTIFACT_ROOT&quot;\nARTIFACTS_DESTINATION_ENV_VAR = &quot;_MLFLOW_SERVER_ARTIFACT_DESTINATION&quot;\nPROMETHEUS_EXPORTER_ENV_VAR = &quot;prometheus_multiproc_dir&quot;\nSERVE_ARTIFACTS_ENV_VAR = &quot;_MLFLOW_SERVER_SERVE_ARTIFACTS&quot;\nARTIFACTS_ONLY_ENV_VAR = &quot;_MLFLOW_SERVER_ARTIFACTS_ONLY&quot;\n\ndef parse_args():\n    a = argparse.ArgumentParser()\n    a.add_argument(&quot;--host&quot;, type=str, default=&quot;0.0.0.0&quot;)\n    a.add_argument(&quot;--port&quot;, type=str, default=&quot;5000&quot;)\n    a.add_argument(&quot;--backend-store-uri&quot;, type=str, default=&quot;sqlite:\/\/\/mlflow.db&quot;)\n    a.add_argument(&quot;--serve-artifacts&quot;, action=&quot;store_true&quot;, default=False)\n    a.add_argument(&quot;--artifacts-destination&quot;, type=str)\n    a.add_argument(&quot;--default-artifact-root&quot;, type=str)\n    a.add_argument(&quot;--gunicorn-opts&quot;, type=str, default=&quot;&quot;)\n    a.add_argument(&quot;--n-workers&quot;, type=str, default=1)\n    return a.parse_args()\n\ndef run_command(cmd, env, cwd=None):\n    cmd_env = os.environ.copy()\n    if cmd_env:\n        cmd_env.update(env)\n    child = subprocess.Popen(\n        cmd, env=cmd_env, cwd=cwd, text=True, stdin=subprocess.PIPE\n    )\n    child.communicate()\n    exit_code = child.wait()\n    if exit_code != 0:\n        raise Exception(&quot;Non-zero exitcode: %s&quot; % (exit_code))\n    return exit_code\n\ndef run_server(args):\n    env_map = dict()\n    if args.backend_store_uri:\n        env_map[BACKEND_STORE_URI_ENV_VAR] = args.backend_store_uri\n    if args.serve_artifacts:\n        env_map[SERVE_ARTIFACTS_ENV_VAR] = &quot;true&quot;\n    if args.artifacts_destination:\n        env_map[ARTIFACTS_DESTINATION_ENV_VAR] = args.artifacts_destination\n    if args.default_artifact_root:\n        env_map[ARTIFACT_ROOT_ENV_VAR] = args.default_artifact_root\n\n    print(f&quot;Envmap: {env_map}&quot;)\n\n    #opts = args.gunicorn_opts.split(&quot; &quot;) if args.gunicorn_opts else []\n    opts = args.gunicorn_opts if args.gunicorn_opts else &quot;&quot;\n\n    cmd = [\n        &quot;gunicorn&quot;, &quot;-b&quot;, f&quot;{args.host}:{args.port}&quot;, &quot;-w&quot;, f&quot;{args.n_workers}&quot;, &quot;-k&quot;, &quot;uvicorn.workers.UvicornWorker&quot;, &quot;server:app&quot;\n    ]\n    run_command(cmd, env_map)\n\ndef main():\n    args = parse_args()\n    run_server(args)\n\nif __name__ == &quot;__main__&quot;:\n    main()\n<\/code><\/pre>\n<p>Run like<\/p>\n<pre><code>python server.py --artifacts-destination s3:\/\/mlflow-mr --default-artifact-root s3:\/\/mlflow-mr --serve-artifacts\n<\/code><\/pre>\n<p>Then navigate to your browser and see the tracking server running! This allows you to insert custom FastAPI middleware in front of the tracking server<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-03-31 06:40:38.09 UTC",
        "Answer_score":2.0,
        "Owner_location":"Santa Cruz, CA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71687131",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63275517,
        "Question_title":"Unable to set up sftp artifact storage for MLFlow",
        "Question_body":"<p>I want to set up a tracking MLFlow server with external metrics and artifact storage.\nI have the following docker containers inside docker network: mlflow-server, postgres, sftp-mlflow and python-client.\nI was able to set up postgres and connect it to the mlflow-server and the client:<\/p>\n<pre><code>mlflow server --backend-store-uri postgresql:\/\/postgres:&lt;pass&gt;@mlflow_db:5432\/mlflow_db --default-artifact-root sftp:\/\/sftp:&lt;pass&gt;@sftp-mlflow:22 -h 0.0.0.0 -p 8000\n<\/code><\/pre>\n<p>However I cannot do anything about artifact storage. Tried the following sftp images<\/p>\n<ul>\n<li><a href=\"https:\/\/hub.docker.com\/r\/atmoz\/sftp\" rel=\"nofollow noreferrer\">https:\/\/hub.docker.com\/r\/atmoz\/sftp<\/a><\/li>\n<li><a href=\"https:\/\/github.com\/madnificent\/root-sftp-docker\" rel=\"nofollow noreferrer\">https:\/\/github.com\/madnificent\/root-sftp-docker<\/a><\/li>\n<\/ul>\n<p>Also followed this <a href=\"https:\/\/medium.com\/@gyani91\/setup-mlflow-in-production-d72aecde7fef\" rel=\"nofollow noreferrer\">guide<\/a>.\nBut still artifact storage doesn't work =(<\/p>\n<p>On my client side I have<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nremote_server_uri = &quot;http:\/\/mlflow-server:8000&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\n# plotting\nfig.savefig(&quot;test.png&quot;)\n\nARTIFACT_URI = &quot;sftp:\/\/sftp:&lt;pass&gt;@sftp-mlflow:22&quot;\nEXPERIMENT_NAME = &quot;test&quot;\nmlflow.create_experiment(EXPERIMENT_NAME, artifact_location=ARTIFACT_URI)\nmlflow.set_experiment(EXPERIMENT_NAME)\nwith mlflow.start_run():\n    mlflow.log_param(&quot;a&quot;, 1)\n    mlflow.log_metric(&quot;b&quot;, 2)\n    mlflow.log_artifact('test.png')\n\n<\/code><\/pre>\n<p>and when running this code I get:<\/p>\n<pre><code>2020\/08\/06 01:05:19 ERROR mlflow.utils.rest_utils: API request to http:\/\/mlflow-server:8000\/api\/2.0\/mlflow\/experiments\/create failed with code 500 != 200, retrying up to 0 more times. API response body: &lt;!DOCTYPE HTML PUBLIC &quot;-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN&quot;&gt;\n&lt;title&gt;500 Internal Server Error&lt;\/title&gt;\n&lt;h1&gt;Internal Server Error&lt;\/h1&gt;\n&lt;p&gt;The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.&lt;\/p&gt;\n\nTraceback (most recent call last):\n  File &quot;\/usr\/local\/lib\/python3.8\/runpy.py&quot;, line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File &quot;\/usr\/local\/lib\/python3.8\/runpy.py&quot;, line 87, in _run_code\n    exec(code, run_globals)\n  File &quot;\/run.py&quot;, line 24, in &lt;module&gt;\n    mlflow.create_experiment(EXPERIMENT_NAME, artifact_location=ARTIFACT_URI)\n  File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 357, in create_experiment\n    return MlflowClient().create_experiment(name, artifact_location)\n  File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/client.py&quot;, line 164, in create_experiment\n    return self._tracking_client.create_experiment(name, artifact_location)\n  File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py&quot;, line 126, in create_experiment\n    return self.store.create_experiment(\n  File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/rest_store.py&quot;, line 54, in create_experiment\n    response_proto = self._call_endpoint(CreateExperiment, req_body)\n  File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/store\/tracking\/rest_store.py&quot;, line 32, in _call_endpoint\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\n  File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 142, in call_endpoint\n    response = http_request(\n  File &quot;\/usr\/local\/lib\/python3.8\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 86, in http_request\n    raise MlflowException(&quot;API request to %s failed to return code 200 after %s tries&quot; %\nmlflow.exceptions.MlflowException: API request to http:\/\/mlflow-server:8000\/api\/2.0\/mlflow\/experiments\/create failed to return code 200 after 3 tries\n<\/code><\/pre>\n<p>I can connect to sftp storage from mlflow-server contaner and from python client using sftp:\n<code>sftp -P 22 sftp@sftp-mlflow<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-08-06 01:14:23.44 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|postgresql|docker|sftp|mlflow",
        "Question_view_count":1969,
        "Owner_creation_date":"2017-01-13 15:57:38.31 UTC",
        "Owner_last_access_date":"2022-05-31 08:17:03.24 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Moscow, \u0420\u043e\u0441\u0441\u0438\u044f",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63275517",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73570230,
        "Question_title":"How to access Mlflow running on fargate (ECS) with only VPN in\/outbound rules from sagemaker notebook instance?",
        "Question_body":"<p><strong>Context:<\/strong><\/p>\n<p>I have deployed Mlflow on ECS(Fargate) using terraform using this public <a href=\"https:\/\/github.com\/Glovo\/terraform-aws-mlflow\" rel=\"nofollow noreferrer\">git-repo<\/a>. After deploying Mlflow which was publicly accessible using the link, I made some changes in the security group and changed in\/outbound rule to the only company VPN ips, now that link is only accessible under the VPN.<\/p>\n<p><strong>Question:<\/strong><\/p>\n<p>Now I have Sagemake notebook instance and want to access that link inside the notebook and the notebook is running on AWS internet(outside Company-VPN) and I'm not able to access that link. What could be the possible solution?<\/p>\n<p>I don't want to open access of Mlflow-link publicaly to accessible form anywhere on the internet.<\/p>\n<p><strong>Running this code on notebook:<\/strong><\/p>\n<pre><code>!pip install mlflow\nimport mlflow\nmlflow.set_tracking_uri(&quot;http:\/\/mlflow-mlp-xyz-xyz.eu-west-1.elb.amazonaws.com\/&quot;)\nmlflow.get_experiment_by_name('mlpmlflowlogger')\ncurrent_experiment=dict(mlflow.get_experiment_by_name('mlpmlflowlogger'))\nprint(current_experiment)\nexperiment_id=current_experiment['experiment_id']\nprint(experiment_id)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-09-01 13:31:23.46 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"amazon-web-services|amazon-ecs|amazon-vpc|aws-security-group|mlflow",
        "Question_view_count":31,
        "Owner_creation_date":"2017-11-29 13:03:57.98 UTC",
        "Owner_last_access_date":"2022-09-20 13:40:47.487 UTC",
        "Owner_reputation":813,
        "Owner_up_votes":87,
        "Owner_down_votes":1,
        "Owner_views":115,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Deggendorf, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73570230",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68059536,
        "Question_title":"Could not connect to MLFlow model hosted on Docker",
        "Question_body":"<p>I hosted a model inside a docker container.\nOn running the DockerFile, It runs the following command:<\/p>\n<p><code>mlflow models serve -m model --port 8080 --no-conda<\/code><\/p>\n<p>It serves the model succesfully , And I can now make calls to it.\nBut, I keep getting Max retries exceeded with url<\/p>\n<p>When I host the same model without using Docker(And follow the same steps), it works perfectly.<\/p>\n<p>I use the following command to run the docker container\n<code>docker run -it --rm --network host imagename:random<\/code><\/p>\n<p>I have also tried mapping port 8080, But still not able to get a response.<\/p>\n<p>Not able to understand what the possible issues could be.<\/p>\n<p>Dockerfile for reference<\/p>\n<pre><code>  \nFROM ubuntu:20.04\nENV DEBIAN_FRONTEND=noninteractive\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    build-essential software-properties-common\\\n    libboost-dev libboost-serialization-dev libssl-dev \\\n    cmake vim\\\n    wget \\\n    make libbz2-dev libexpat1-dev swig python-dev\nRUN add-apt-repository -y ppa:ubuntugis\/ppa &amp;&amp; apt-get -q update\nRUN apt-get -y install gdal-bin libgdal-dev\nRUN apt-get update\n\nRUN apt install -y python3-pip\nRUN pip3 install --upgrade pip\nRUN pip install mlflow\nRUN pip install pandas\n\nRUN mkdir -p \/tmp\nCOPY .\/main.py \/tmp\/\nCOPY .\/run.sh \/tmp\/\n\nENV LC_ALL=C.UTF-8\nENV LANG=C.UTF-8\nRUN chmod +x run.sh\nCMD .\/run.sh\n<\/code><\/pre>\n<p>Where, run.sh is<\/p>\n<pre><code>python3 main.py\nmlflow models serve -m \/tmp\/mlflow_model --port 8080 --no-conda\n<\/code><\/pre>\n<p>When I run the commands of run.sh file outside of docker container, It is able to serve the model correctly,And I get the correct response.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-20 19:52:04.787 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"docker|python-requests|port|mlflow",
        "Question_view_count":195,
        "Owner_creation_date":"2018-10-08 22:27:01.213 UTC",
        "Owner_last_access_date":"2022-07-27 16:40:50.953 UTC",
        "Owner_reputation":75,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"New Delhi, Delhi, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68059536",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66855807,
        "Question_title":"How to add more metrics to a finished MLflow run?",
        "Question_body":"<p>Once an MLflow run is finished, external scripts can access its parameters and metrics using python <code>mlflow<\/code> client and <code>mlflow.get_run(run_id)<\/code> method, but the <code>Run<\/code> object returned by <code>get_run<\/code> seems to be read-only.<\/p>\n<p>Specifically, <code>.log_param<\/code> <code>.log_metric<\/code>, or <code>.log_artifact<\/code> cannot be used on the object returned by <code>get_run<\/code>, raising errors like these:<\/p>\n<pre><code>AttributeError: 'Run' object has no attribute 'log_param'\n<\/code><\/pre>\n<p>If we attempt to run any of the <code>.log_*<\/code> methods on <code>mlflow<\/code>, it would log them into to a new run  with auto-generated run ID in the <code>Default<\/code> experiment.<\/p>\n<p>Example:<\/p>\n<pre><code>final_model_mlflow_run = mlflow.get_run(final_model_mlflow_run_id)\n\nwith mlflow.ActiveRun(run=final_model_mlflow_run) as myrun:    \n    \n    # this read operation uses correct run\n    run_id = myrun.info.run_id\n    print(run_id)\n    \n    # this write operation writes to a new run \n    # (with auto-generated random run ID) \n    # in the &quot;Default&quot; experiment (with exp. ID of 0)\n    mlflow.log_param(&quot;test3&quot;, &quot;This is a test&quot;)\n   \n<\/code><\/pre>\n<p>Note that the above problem exists regardless of the <code>Run<\/code> status (<code>.info.status<\/code> can be both &quot;FINISHED&quot; or &quot;RUNNING&quot;, without making any difference).<\/p>\n<p>I wonder if this read-only behavior is by design (given that immutable modeling runs improve experiments reproducibility)? I can appreciate that, but it also goes against code modularity if everything has to be done within a single monolith like the <code>with mlflow.start_run()<\/code> context...<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-03-29 14:12:06.043 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-03-29 17:50:32.537 UTC",
        "Question_score":3,
        "Question_tags":"python|databricks|mlflow",
        "Question_view_count":1269,
        "Owner_creation_date":"2018-06-19 12:32:08.93 UTC",
        "Owner_last_access_date":"2022-09-24 20:14:44.457 UTC",
        "Owner_reputation":3260,
        "Owner_up_votes":1100,
        "Owner_down_votes":4,
        "Owner_views":466,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"EU",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66855807",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73501103,
        "Question_title":"Getting Bad request while searching run in mlflow",
        "Question_body":"<p>Training a ml model with mlflow in azure environment.<\/p>\n<pre><code>import mlflow\nfrom mlflow import MlflowClient\nfrom azureml.core import Experiment, Workspace\n\nexperiment_name = 'housing-lin-mlflow'\n\nexperiment = Experiment(ws, experiment_name)\n\nruns = mlflow.search_runs(experiment_ids=[ experiment.id ])\n\n<\/code><\/pre>\n<p>While fetching runs from search_runs getting this error :<\/p>\n<pre><code>RestException: BAD_REQUEST: For input string: &quot;5b649b3c-3b8f-497a-bb4f&quot;\n<\/code><\/pre>\n<p>MLflow version : 1.28.0\nIn Azure studio jobs have been created and successfully run.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-26 12:33:35.98 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-27 18:36:19.893 UTC",
        "Question_score":0,
        "Question_tags":"python|azure|azure-machine-learning-service|mlflow",
        "Question_view_count":56,
        "Owner_creation_date":"2020-02-19 08:37:57.803 UTC",
        "Owner_last_access_date":"2022-09-23 17:24:33.503 UTC",
        "Owner_reputation":171,
        "Owner_up_votes":17,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":"<p>The bad request in MLFlow after successful running the job is because of not giving proper API permissions for the application.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/rP6Ja.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/rP6Ja.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Search for <strong>MLFLOW<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TGU2C.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TGU2C.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p><strong>Scroll down<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/s50AL.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/s50AL.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Click on View API Permissions<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/f7Txf.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/f7Txf.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Under API permissions, assign the permissions according to the application running region and requirements. Checkout the <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models-mlflow\" rel=\"nofollow noreferrer\">document<\/a> for further information.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-08-27 12:38:02.123 UTC",
        "Answer_score":1.0,
        "Owner_location":"Delhi, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73501103",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73760705,
        "Question_title":"Does the Mlflow platform (or any other you can suggst) fits as an experiment management tool for image processing CNNs on NVIDIA TAO workframe",
        "Question_body":"<p>we would like to make sure that the MLFLOW experiment management platform fits our needs and workflow.\nWe work with image processing  CNNs like Yolo, UNET, and RetinaNet based on an NVIDIA TAO framework.<br \/>\nWhat we actually need is a tool that concentrates on one place (in a nice and representative way comfortable for comparison) at least the three following things for each experiment:<\/p>\n<p>a- chosen by user typical meta parameters that were used to train a network (such as batches, subdivisions, max batches, etc)\nb- a link to the dataset the network was trained on, located on our cloud storage (such as one-drive, google drive or google cloud) or a list of filenames or a link to a file storage cloud or online drive suggested by MLFLOW service if there is such a thing.\nc- a result of running the trained network - the number of detected objects<\/p>\n<p>Thus the question is:<\/p>\n<p>Does the MLFLOW fit our needs?\nIf not ill be glad if anyone could suggest a relevant alternative.\nThank you<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-18 07:00:51.18 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"version-control|nvidia|yolo|mlflow|unet-neural-network",
        "Question_view_count":19,
        "Owner_creation_date":"2022-01-31 09:17:13.293 UTC",
        "Owner_last_access_date":"2022-09-22 17:23:30.217 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73760705",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59331417,
        "Question_title":"MLFlow Projects can't find conda executable",
        "Question_body":"<p>I am following the tutorial on MLFlow website. I was able to run the train.py and mlflow ui worked fine. Packaging the project tries to use env variable  MLFLOW_CONDA_HOME but can't find conda.\nI have tried setting the variable to the path of anaconda3\/condabin but it doesn't seem to find my executable. This is the error I get:\n ERROR mlflow.cli: === Could not find Conda executable at \/anaconda3\/condabin\\bin\/conda. Ensure Conda is installed as per the inst\nructions at <a href=\"https:\/\/conda.io\/docs\/user-guide\/install\/index.html\" rel=\"nofollow noreferrer\">https:\/\/conda.io\/docs\/user-guide\/install\/index.html<\/a>. You can also configure MLflow to look for a specific Conda executable by setting the MLFLOW_CONDA_HOME environment variable\n to the path of the Conda executable ===<\/p>\n\n<p>Adding \\bin\/conda at the end of my path seems to be the problem, I am not sure why mlflow is doing it. I even tried setting it to my python.exe in my conda env, but no luck. I can't find bin\/conda folder in my Anaconda folder anywhere.<\/p>",
        "Question_answer_count":7,
        "Question_comment_count":2,
        "Question_creation_date":"2019-12-14 00:47:58.197 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|anaconda|conda|mlflow",
        "Question_view_count":3001,
        "Owner_creation_date":"2013-03-25 16:26:12.147 UTC",
        "Owner_last_access_date":"2020-08-11 23:36:17.443 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59331417",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71601655,
        "Question_title":"Train model after load in MLFlow",
        "Question_body":"<p>My goal is to store an empty model into MLFlow Registry and then load it for training.<\/p>\n<p>I have a register_model.py which looks like this:<\/p>\n<pre><code>if __name__ == &quot;__main__&quot;:\n\n    remote_server_uri = &quot;http:\/\/127.0.0.1:5000&quot;\n    mlflow.set_tracking_uri(remote_server_uri)\n\n    # Load and compile Keras model\n    model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None)\n    model.compile(&quot;adam&quot;, &quot;sparse_categorical_crossentropy&quot;, metrics=[&quot;accuracy&quot;])\n\n\n    # Load CIFAR-10 dataset\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\n    epochs = 1\n    batch_size = 32\n    mlflow.tensorflow.autolog()\n    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)\n\n    tf.keras.models.save_model(model, &quot;models\/tensorflow&quot;)\n\n    mlflow.tensorflow.log_model(\n        tf_saved_model_dir='models\/tensorflow',\n        tf_meta_graph_tags=None,\n        tf_signature_def_key='serving_default',\n        artifact_path=&quot;saved\/models\/tensorflow&quot;,\n        registered_model_name=&quot;tensorflow-MobileNetV2-32inputs&quot;\n    )\n<\/code><\/pre>\n<p>Then I'm trying to load it using:<\/p>\n<pre><code>if __name__ == &quot;__main__&quot;:\n\n    remote_server_uri = &quot;http:\/\/127.0.0.1:5000&quot;\n    mlflow.set_tracking_uri(remote_server_uri)\n\n\n    model_name = &quot;tensorflow-MobileNetV2-32inputs&quot;\n    model_version = 1\n\n    model = mlflow.tensorflow.load_model(\n        model_uri=f&quot;models:\/{model_name}\/{model_version}&quot;\n    )\n<\/code><\/pre>\n<p>I would expect my model to be a able to do things like 'model.fit()' and 'model.predict()' but Im always getting:<\/p>\n<pre><code>AttributeError: '_WrapperFunction' object has no attribute 'fit'\n<\/code><\/pre>\n<p>So my question is: it is possible to save a tensorflow\/keras model and to load the architecture to be trained\/retrained and even modified through mlflow? Load the model, add a new layer, store the model either as a new version or as a new model itself, for example.<\/p>\n<p>Thanks in advance!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-24 11:27:48.757 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|tensorflow|mlflow",
        "Question_view_count":116,
        "Owner_creation_date":"2012-05-19 11:47:02.397 UTC",
        "Owner_last_access_date":"2022-09-20 08:15:38.867 UTC",
        "Owner_reputation":1176,
        "Owner_up_votes":61,
        "Owner_down_votes":7,
        "Owner_views":80,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"M\u00e1laga, Spain",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71601655",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71751564,
        "Question_title":"Register model version via MLflow Python API while carrying over input\/output schemas",
        "Question_body":"<p>I am trying to use the mlflow Python API to register models to an mlflow server's model registry. And in fact this does work:<\/p>\n<pre><code>model_version = client.create_model_version(\n    source=run.info.artifact_uri,\n    name='my_model',\n    run_id=run.info.run_id)    \n<\/code><\/pre>\n<p>Meaning the newly registered model version appears in the server's web UI.<\/p>\n<p>However, the input and output schemas that have been logged with the respective run are not carried over to the new model version (i.e. in the UI, the &quot;Schema&quot; tab under &quot;Registered Models &gt; my_model &gt; Version 2&quot; is empty). When I instead register the new model version via the web UI, the input and output schemas do appear there.<\/p>\n<p>How can I get mlflow to carry over the schemas even when using the Python API?<\/p>\n<p>Thanks!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-05 12:13:17.57 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-04-08 11:10:42.09 UTC",
        "Question_score":0,
        "Question_tags":"mlflow|mlops",
        "Question_view_count":118,
        "Owner_creation_date":"2020-03-31 09:43:43.903 UTC",
        "Owner_last_access_date":"2022-09-22 18:39:23.323 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Bochum, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71751564",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60995542,
        "Question_title":"Perform GridSearchCV with MLFlow",
        "Question_body":"<p>I just started using MLFlow and I am happy with what it can do. However, I cannot find a way to log different runs in a <code>GridSearchCV<\/code> from scikit learn.<\/p>\n\n<p>For example, I can do this manually<\/p>\n\n<pre><code>params = ['l1', 'l2']\nfor param in params:\n    with mlflow.start_run(experiment_id=1):\n        clf = LogisticRegression(penalty = param).fit(X_train, y_train)\n        y_predictions = clf.predict(X_test)\n\n        precision = precision_score(y_test, y_predictions)\n        recall = recall_score(y_test, y_predictions)\n        f1 = f1_score(y_test, y_predictions)\n\n        mlflow.log_param(\"penalty\", param)\n        mlflow.log_metric(\"Precision\", precision)\n        mlflow.log_metric(\"Recall\", recall)\n        mlflow.log_metric(\"F1\", f1)\n\n        mlflow.sklearn.log_model(clf, \"model\")\n<\/code><\/pre>\n\n<p>But when I want to use the <code>GridSearchCV<\/code> like that <\/p>\n\n<pre><code>pipe = Pipeline([('classifier' , RandomForestClassifier())])\n\nparam_grid = [\n    {'classifier' : [LogisticRegression()],\n     'classifier__penalty' : ['l1', 'l2'],\n    'classifier__C' : np.logspace(-4, 4, 20),\n    'classifier__solver' : ['liblinear']},\n    {'classifier' : [RandomForestClassifier()],\n    'classifier__n_estimators' : list(range(10,101,10)),\n    'classifier__max_features' : list(range(6,32,5))}\n]\n\n\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n\nbest_clf = clf.fit(X_train, y_train)\n<\/code><\/pre>\n\n<p>I cannot think of any way to log all the individual models that the GridSearch tests. Is there any way to do it or I have to keep using the manual process?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-02 15:44:47.48 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-04-02 15:51:44.26 UTC",
        "Question_score":11,
        "Question_tags":"python|scikit-learn|mlflow",
        "Question_view_count":4620,
        "Owner_creation_date":"2013-04-22 22:07:18.85 UTC",
        "Owner_last_access_date":"2022-09-24 18:16:29.973 UTC",
        "Owner_reputation":6815,
        "Owner_up_votes":153,
        "Owner_down_votes":12,
        "Owner_views":875,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Greece",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60995542",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56006477,
        "Question_title":"Can't run mlflow standalone react server",
        "Question_body":"<p>I need to run the frontend UI on a separate server as a stand-alone react app (not with all of the mlflow python server and packages). But when I run the production build, I get the following error:<\/p>\n\n<blockquote>\n  <p>You need to enable JavaScript to run this app.<\/p>\n<\/blockquote>\n\n<p>Reproduce:<\/p>\n\n<pre><code>git clone https:\/\/github.com\/mlflow\/mlflow.git\ncd mlflow\/mlflow\/server\/js\n<\/code><\/pre>\n\n<p>In development mode, \"npm start\" it works just fine:<\/p>\n\n<pre><code>npm install\nnpm start\n<\/code><\/pre>\n\n<p>But when I've run it in production, I am getting the above error.  <\/p>\n\n<pre><code>npm install\nnpm install -g serve\nnpm run build\nserve -s build\n<\/code><\/pre>\n\n<p>I tried many things searching in forums, including this one:\n<a href=\"https:\/\/stackoverflow.com\/questions\/50286927\/i-am-getting-error-in-console-you-need-to-enable-javascript-to-run-this-app-r\">I am getting error in console &quot;You need to enable JavaScript to run this app.&quot; reactjs<\/a>.\nbut I didn't manage to make it work.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2019-05-06 13:42:33.067 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-05-07 17:02:15.987 UTC",
        "Question_score":2,
        "Question_tags":"reactjs|mlflow",
        "Question_view_count":286,
        "Owner_creation_date":"2014-11-21 23:30:15.303 UTC",
        "Owner_last_access_date":"2019-07-28 11:08:18.773 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56006477",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69738859,
        "Question_title":"Multiple values for a single parameter in the mlflow run command",
        "Question_body":"<p>I just started learning mlflow and wanted to know how to pass multiple values to  each parameter in the mlflow run command.<\/p>\n<p>The objective is to pass a dictionary to GridSearchCV as a param_grid to perform cross validation.<\/p>\n<p>In my main code, I retrieve the command line parameters using argparse. And by adding nargs='+' in the add_argument(), I can write spaced values for each hyper parameter and then applying vars() to create the dictionary. See code below:<\/p>\n<pre><code>import argparse\n\n# Build the parameters for the command-line\nparam_names = list(RandomForestClassifier().get_params().keys())\n\n# Param types in the same order they appear in param_names by using get_params()\nparam_types = [bool, float, dict, str, int, float, int, float, float, float,\n               float, float, float, int, int, bool, int, int, bool]\n\n# Allow for only optional command-line arguments\nparser = argparse.ArgumentParser()\ngrid_group = parser.add_argument_group('param_grid_group')\nfor i, p in enumerate(param_names):\n    grid_group.add_argument(f'--{p}', type=param_types[i], nargs='+')\n#Create a param_grid to be passed to GridSearchCV\nparam_grid_unprocessed = vars(parser.parse_args())\n<\/code><\/pre>\n<p>This works well with the classic python command :<\/p>\n<pre><code>python my_code.py --max_depth 2 3 4 --n_estimators 400 600 1000\n<\/code><\/pre>\n<p>As I said, here I can just write spaced values for each hyper-parameter and the code above does the magic by grouping the values inside a list and returning the dictionary below that I can then pass to GridSearchCV :<\/p>\n<pre><code>{'max_depth':[2, 3, 4], 'n_estimators':[400, 600, 1000]}\n<\/code><\/pre>\n<p>However with the mlflow run command, I can't get it right so far as it only accepts one value for each parameter. Here's my MLproject file :<\/p>\n<pre><code>name: mlflow_project\n\nconda_env: conda.yml\n\nentry_points:\n\n  main:\n    parameters:\n      max_depth: int\n      n_estimators: int\n    command: &quot;python my_code.py --max_depth {max_depth} --n_estimators {n_estimators}&quot;\n<\/code><\/pre>\n<p>So this works :<\/p>\n<pre><code>mlflow run . -P max_depth=2 -P n_estimators=400\n<\/code><\/pre>\n<p>But not this :<\/p>\n<pre><code> mlflow run . -P max_depth=[2, 3, 4] -P n_estimators=[400, 600, 1000]\n<\/code><\/pre>\n<p>In the <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#mlflow-run\" rel=\"nofollow noreferrer\">documentation<\/a>, it seems that it's impossible to do it. So, is there is any hack to overcome this problem ?<\/p>\n<p>Thank you in advance !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-27 12:39:14.137 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|gridsearchcv|mlflow",
        "Question_view_count":356,
        "Owner_creation_date":"2020-04-10 11:23:52.39 UTC",
        "Owner_last_access_date":"2022-08-12 18:19:53.33 UTC",
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69738859",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71001833,
        "Question_title":"Accessing Delta Lake Table in Databricks via Spark in MLflow project",
        "Question_body":"<p>I am currently accessing deltalake table from databricks notebook using spark. However now I need to access delta tables from MLflow project. MLflow spark api only allows logging and loading of SparkML models. Any idea on how can I accomplish this?<\/p>\n<p>Currently I am trying to access spark via this code in MLflow project:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>\nspark = pyspark.sql.SparkSession._instantiatedSession\nif spark is None:\n  # NB: If there is no existing Spark context, create a new local one.\n  # NB: We're disabling caching on the new context since we do not need it and we want to\n  # avoid overwriting cache of underlying Spark cluster when executed on a Spark Worker\n  # (e.g. as part of spark_udf).\n  spark = ( pyspark.sql.SparkSession.builder \\\n   .config(&quot;spark.python.worker.reuse&quot;, True)\n   .config(&quot;spark.databricks.io.cache.enabled&quot;, False)\n   # In Spark 3.1 and above, we need to set this conf explicitly to enable creating\n   # a SparkSession on the workers\n   .config(&quot;spark.executor.allowSparkContext&quot;, &quot;true&quot;)\n   .master(&quot;local[*]&quot;)\n   .appName(&quot;MLflow Project&quot;)\n   .getOrCreate()\n  )\n<\/code><\/pre>\n<p>But I am getting this error:<\/p>\n<pre><code>py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2022-02-05 20:21:43 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-06 17:51:53.797 UTC",
        "Question_score":1,
        "Question_tags":"apache-spark|pyspark|databricks|delta-lake|mlflow",
        "Question_view_count":282,
        "Owner_creation_date":"2016-10-23 15:09:44.12 UTC",
        "Owner_last_access_date":"2022-09-23 01:20:21.6 UTC",
        "Owner_reputation":71,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":9,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71001833",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73153142,
        "Question_title":"Mlflow UI can't show artifacts",
        "Question_body":"<p>I have mlflow running on an azure VM and connected to Azure Blob as the artifact storage.<\/p>\n<p>After uploading artifacts to the storage from the Client.<\/p>\n<p>I tried the MLflow UI and successfully was able to show the uploaded file.<\/p>\n<p>The problem happens when I try to run MLFLOW with Docker, I get the error:\n<strong>Unable to list artifacts stored under <code>{artifactUri}<\/code> for the current run. Please contact your tracking server administrator to notify them of this error, which can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory<\/strong><\/p>\n<p>Dockerfile:<\/p>\n<pre><code>FROM python:3.7-slim-buster\n# Install python packages\nRUN pip install mlflow pymysql\n\nRUN pip install azure-storage-blob\n\nENV AZURE_STORAGE_ACCESS_KEY=&quot;#########&quot;\nENV AZURE_STORAGE_CONNECTION_STRING=&quot;#######&quot;\n<\/code><\/pre>\n<p>docker-compose.yml<\/p>\n<pre><code>web:\n        restart: always\n        build: .\/mlflow_server\n        image: mlflow_server\n        container_name: mlflow_server\n        expose:\n            - &quot;5000&quot;\n        networks:\n            - frontend\n            - backend\n        environment:\n            - AZURE_STORAGE_ACCESS_KEY=&quot;#####&quot;\n            - AZURE_STORAGE_CONNECTION_STRING=&quot;#####&quot;\n        command: mlflow server --backend-store-uri mysql+pymysql:\/\/mlflow_user:123456@db:3306\/mlflow --default-artifact-root wasbs:\/\/etc..\n<\/code><\/pre>\n<p>I tried multiple solutions:<\/p>\n<ol>\n<li>Making sure that boto3 is installed (Didn't do anything)<\/li>\n<li>Adding Environment Variables in the Dockerfile so the command runs after they're set<\/li>\n<li>I double checked the url of the storage blob<\/li>\n<\/ol>\n<p>And MLFLOW doesn't show any logs it just kills the process and restarts again.<\/p>\n<p>Anyone got any idea what might be the solution or how can i access the logs<\/p>\n<p>here're the docker logs of the container:<\/p>\n<pre><code>[2022-07-28 12:23:33 +0000] [10] [INFO] Starting gunicorn 20.1.0\n[2022-07-28 12:23:33 +0000] [10] [INFO] Listening at: http:\/\/0.0.0.0:5000 (10)\n[2022-07-28 12:23:33 +0000] [10] [INFO] Using worker: sync\n[2022-07-28 12:23:33 +0000] [13] [INFO] Booting worker with pid: 13\n[2022-07-28 12:23:33 +0000] [14] [INFO] Booting worker with pid: 14\n[2022-07-28 12:23:33 +0000] [15] [INFO] Booting worker with pid: 15\n[2022-07-28 12:23:33 +0000] [16] [INFO] Booting worker with pid: 16\n[2022-07-28 12:24:24 +0000] [10] [CRITICAL] WORKER TIMEOUT (pid:14)\n[2022-07-28 12:24:24 +0000] [14] [INFO] Worker exiting (pid: 14)\n[2022-07-28 12:24:24 +0000] [21] [INFO] Booting worker with pid: 21\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-28 12:43:31.5 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"docker|docker-compose|azure-blob-storage|mlflow",
        "Question_view_count":97,
        "Owner_creation_date":"2022-07-28 12:16:55.837 UTC",
        "Owner_last_access_date":"2022-09-19 22:11:22.013 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73153142",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56597812,
        "Question_title":"Nested runs using MLflowClient",
        "Question_body":"<p>In <code>mlflow<\/code>, you can run nested runs using the fluent projects API which are collapsable in the UI. E.g. by using the following code (see <a href=\"https:\/\/databricks.com\/blog\/2018\/11\/21\/mlflow-v0-8-0-features-improved-experiment-ui-and-deployment-tools.html\" rel=\"noreferrer\">this<\/a> for UI support):<\/p>\n\n<pre><code>with mlflow.start_run(nested=True):\n  mlflow.log_param(\"mse\", 0.10)\n  mlflow.log_param(\"lr\", 0.05)\n  mlflow.log_param(\"batch_size\", 512)\n  with mlflow.start_run(nested=True):\n    mlflow.log_param(\"max_runs\", 32)\n    mlflow.log_param(\"epochs\", 20)\n    mlflow.log_metric(\"acc\", 98)\n    mlflow.log_metric(\"rmse\", 98)\n  mlflow.end_run()\n<\/code><\/pre>\n\n<p>Due to database connection issues, I want to use a single mlflow client across my application.<\/p>\n\n<p>How can I stack runs, e.g. for hyperparameter optimization, using created runs via <code>MlflowClient().create_run()<\/code>?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-06-14 12:02:38.62 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":7,
        "Question_tags":"python|mlflow",
        "Question_view_count":4030,
        "Owner_creation_date":"2015-02-02 20:14:19.383 UTC",
        "Owner_last_access_date":"2022-08-10 17:44:00.06 UTC",
        "Owner_reputation":391,
        "Owner_up_votes":51,
        "Owner_down_votes":18,
        "Owner_views":48,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Paderborn, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56597812",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63821130,
        "Question_title":"what is the value of mlflow nested runs?",
        "Question_body":"<p>What is the value of nested runs in mlflow? I thought it would be that a child run inherits params of the parent, but I dont see that<\/p>\n<pre><code>with mlflow.start_run(run_name='myrun'):\n    mlflow.log_param('kl', '0p0')\n    mlflow.log_param('name', 'ios')\n    mlflow.log_metric('mu', 1.0)\n    with mlflow.start_run(run_name='myrun2', nested=True):\n        mlflow.log_param('name', 'weighted')        \n        mlflow.log_metric('mu', 2.0)\n<\/code><\/pre>\n<p>if I collect the run info in python<\/p>\n<pre><code>df = mlflow.search_runs()\n<\/code><\/pre>\n<p>then we have<\/p>\n<pre><code>df['params.kl']\n<\/code><\/pre>\n<p>giving<\/p>\n<pre><code>0    None\n1     0p0\nName: params.kl, dtype: object\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-10 00:13:32.703 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":5,
        "Question_tags":"mlflow",
        "Question_view_count":674,
        "Owner_creation_date":"2013-04-14 16:23:58.77 UTC",
        "Owner_last_access_date":"2022-09-21 20:00:03.557 UTC",
        "Owner_reputation":1879,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":147,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"San Francisco, CA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63821130",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71203995,
        "Question_title":"RuntimeError: Java gateway process exited before sending its port number when Deploying Pyspark model to Azure Container Instance",
        "Question_body":"<p>I am trying to deploy a PySpark model trained in Azure Databricks with MLflow to an ACI in Azure Machine Learning.<\/p>\n<p>I am following the steps in this link:<\/p>\n<p><a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-mlflow-models#example-notebooks\" rel=\"nofollow noreferrer\">https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-mlflow-models#example-notebooks<\/a><\/p>\n<p>but I get this error:<\/p>\n<pre><code>SPARK_HOME not set. Skipping PySpark Initialization.\nInitializing logger\n2022-02-21 09:29:30,269 | root | INFO | Starting up app insights client\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2022-02-21 09:29:30,270 | root | INFO | Starting up request id generator\n2022-02-21 09:29:30,270 | root | INFO | Starting up app insight hooks\n2022-02-21 09:29:30,270 | root | INFO | Invoking user's init function\nJAVA_HOME is not set\n2022-02-21 09:29:31,267 | root | ERROR | User's init function failed\n2022-02-21 09:29:31,268 | root | ERROR | Encountered Exception Traceback (most recent call last):\n  File &quot;\/var\/azureml-server\/aml_blueprint.py&quot;, line 191, in register\n    main.init()\n  File &quot;\/var\/azureml-app\/execution_script.py&quot;, line 15, in init\n    model = load_model(model_path)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 667, in load_model\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/mlflow\/spark.py&quot;, line 703, in _load_pyfunc\n    pyspark.sql.SparkSession.builder.config(&quot;spark.python.worker.reuse&quot;, True)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/sql\/session.py&quot;, line 228, in getOrCreate\n    sc = SparkContext.getOrCreate(sparkConf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 392, in getOrCreate\n    SparkContext(conf=conf or SparkConf())\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 144, in __init__\n    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/context.py&quot;, line 339, in _ensure_initialized\n    SparkContext._gateway = gateway or launch_gateway(conf)\n  File &quot;\/azureml-envs\/azureml_5d25bdfadca034daea176336163db1e0\/lib\/python3.8\/site-packages\/pyspark\/java_gateway.py&quot;, line 108, in launch_gateway\n    raise RuntimeError(&quot;Java gateway process exited before sending its port number&quot;)\nRuntimeError: Java gateway process exited before sending its port number\n<\/code><\/pre>\n<p>My code looks like this:<\/p>\n<pre><code>from mlflow.deployments import get_deploy_client\n\n# set the tracking uri as the deployment client\nclient = get_deploy_client(mlflow.get_tracking_uri())\n\n# set the model path \nmodel_path = &quot;k_means_model&quot;\n\n    # define the model path and the name is the service name\n    # the model gets registered automatically and a name is autogenerated using the &quot;name&quot; parameter below \n    client.create_deployment(model_uri='runs:\/{}\/{}'.format(run_id, model_path), name = 'k-means-model-ml-flow')\n<\/code><\/pre>\n<p>While my model settings are:<\/p>\n<pre><code>artifact_path: k_means_model\ndatabricks_runtime: 10.3.x-cpu-ml-scala2.12\nflavors:\n  python_function:\n    data: sparkml\n    env: conda.yaml\n    loader_module: mlflow.spark\n    python_version: 3.8.10\n  spark:\n    model_data: sparkml\n    pyspark_version: 3.2.1\nmodel_uuid: 76ba9dfb01e1428ab8145a161ec3cf32\nrun_id: c0090fa9-b382-45b8-be08-d05e16f3cd62\nutc_time_created: '2022-02-21 08:47:34.967167'\n<\/code><\/pre>\n<p>Can someone help please?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-02-21 09:34:04.4 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-21 10:39:12.347 UTC",
        "Question_score":1,
        "Question_tags":"pyspark|azure-databricks|azure-machine-learning-service|mlflow",
        "Question_view_count":289,
        "Owner_creation_date":"2021-11-02 14:59:46.583 UTC",
        "Owner_last_access_date":"2022-07-12 04:13:09.513 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71203995",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57078147,
        "Question_title":"How should I mount docker volumes in mlflow project?",
        "Question_body":"<p>I use <code>mlflow<\/code> in a docker environment as described in this <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker\" rel=\"nofollow noreferrer\">example<\/a> and I start my runs with <code>mlflow run .<\/code>.<\/p>\n\n<p>I get output like this<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>2019\/07\/17 16:08:16 INFO mlflow.projects: === Building docker image mlflow-myproject-ab8e0e4 ===\n2019\/07\/17 16:08:18 INFO mlflow.projects: === Created directory \/var\/folders\/93\/xt2vz36s7jd1fh9bkhkk9sgc0000gn\/T\/tmp1lxyqqw9 for downloading remote URIs passed to arguments of type 'path' ===\n2019\/07\/17 16:08:18 INFO mlflow.projects: === Running command 'docker run \n--rm -v \/Users\/foo\/bar\/mlruns:\/mlflow\/tmp\/mlruns -e \nMLFLOW_RUN_ID=ef21de61d8a6436b97b643e5cee64ae1 -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 mlflow-myproject-ab8e0e4 python train.py' in run with ID 'ef21de61d8a6436b97b643e5cee64ae1' ===\n<\/code><\/pre>\n\n<p>I would like to mount a docker volume named <code>my_docker_volume<\/code> to the container\n at \nthe path <code>\/data<\/code>. So instead of the <code>docker run<\/code> shown above, I would like to\n use<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>docker run --rm --mount source=my_docker_volume,target=\/data -v \/Users\/foo\/bar\/mlruns:\/mlflow\/tmp\/mlruns -e MLFLOW_RUN_ID=ef21de61d8a6436b97b643e5cee64ae1 -e MLFLOW_TRACKING_URI=file:\/\/\/mlflow\/tmp\/mlruns -e MLFLOW_EXPERIMENT_ID=0 mlflow-myproject-ab8e0e4 python train.py\n<\/code><\/pre>\n\n<p>I see that I could in principle run it once without mounted volume and then \ncopy the <code>docker run ...<\/code> and add <code>--mount source=my_volume,target=\/data<\/code> but\n I'd rather use something like<\/p>\n\n<pre class=\"lang-sh prettyprint-override\"><code>mlflow run --mount source=my_docker_volume,target=\/data .\n<\/code><\/pre>\n\n<p>but this obviously doesn't work because --mount is not a parameter for \n<code>mlflow run<\/code>.\nWhat's the recommened way of mounting a docker volume then?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-07-17 14:22:29.4 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-02 14:08:39.9 UTC",
        "Question_score":4,
        "Question_tags":"docker|mlflow",
        "Question_view_count":1301,
        "Owner_creation_date":"2013-08-08 09:55:24.343 UTC",
        "Owner_last_access_date":"2022-09-24 13:14:05.257 UTC",
        "Owner_reputation":191,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":11,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Freiburg im Breisgau, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57078147",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60641337,
        "Question_title":"mlflow R installation MLFLOW_PYTHON_BIN",
        "Question_body":"<p>I am trying to install mlflow in R and im getting this error message saying <\/p>\n\n<blockquote>\n  <p>mlflow::install_mlflow()\n  Error in mlflow_conda_bin() :\n    Unable to find conda binary. Is Anaconda installed?\n    If you are not using conda, you can set the environment variable MLFLOW_PYTHON_BIN to the path of yourpython executable.<\/p>\n<\/blockquote>\n\n<p>I have tried the following<\/p>\n\n<pre><code>export MLFLOW_PYTHON_BIN=\"\/usr\/bin\/python\" \nsource ~\/.bashrc\necho $MLFLOW_PYTHON_BIN  -&gt; this prints the \/usr\/bin\/python.\n<\/code><\/pre>\n\n<p>or in R,<\/p>\n\n<pre><code>sys.setenv(MLFLOW_PYTHON_BIN=\"\/usr\/bin\/python\")\nsys.getenv() -&gt; prints MLFLOW_PYTHON_BIN is set to \/usr\/bin\/python.\n<\/code><\/pre>\n\n<p>however, it still does not work<\/p>\n\n<p>I do not want to use conda environment.<\/p>\n\n<p>how to I get past this error?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-03-11 17:17:32.94 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-17 00:07:46.973 UTC",
        "Question_score":5,
        "Question_tags":"r|mlflow|system-variable",
        "Question_view_count":1141,
        "Owner_creation_date":"2018-10-10 22:41:41.843 UTC",
        "Owner_last_access_date":"2022-09-24 01:18:25.137 UTC",
        "Owner_reputation":117,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":"<p>The install_mlflow command only works with conda right now, sorry about the confusing message. You can either:<\/p>\n<ul>\n<li>install conda - this is the recommended way of installing and using mlflow<\/li>\n<\/ul>\n<p>or<\/p>\n<ul>\n<li>install mlflow python package yourself via pip<\/li>\n<\/ul>\n<p>To install mlflow yourself, pip install correct (matching the the R package) python version of mlflow and set the MLFLOW_PYTHON_BIN environment variable as well as MLFLOW_BIN evn variable: e.g.<\/p>\n<pre><code>library(mlflow)\nsystem(paste(&quot;pip install -U mlflow==&quot;, mlflow:::mlflow_version(), sep=&quot;&quot;))\nSys.setenv(MLFLOW_BIN=system(&quot;which mlflow&quot;))\nSys.setenv(MLFLOW_PYTHON_BIN=system(&quot;which python&quot;))\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2020-03-18 18:03:05.177 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-06-20 15:16:15.903 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60641337",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72506125,
        "Question_title":"Does MLflow require to have docker installed?",
        "Question_body":"<p>I am reading a book about how to use MLflow.\nThe method is to install MLflow <em>inside<\/em> a container (not natively)\nThe dockerfile is<\/p>\n<pre><code>FROM continuumio\/miniconda3\n\nRUN pip install mlflow&gt;=1.18.0 \\\n    &amp;&amp; pip install numpy \\\n    &amp;&amp; pip install scipy \\\n    &amp;&amp; pip install pandas \\\n    &amp;&amp; pip install scikit-learn \\\n    &amp;&amp; pip install cloudpickle \\\n    &amp;&amp; pip install pandas_datareader==0.10.0 \\\n    &amp;&amp; pip install yfinance\n<\/code><\/pre>\n<p>So I build this with <code>docker build -t stockpred -f Dockerfile .<\/code><\/p>\n<p>Then I run it with <code>docker run -v $(pwd):\/workfolder -it --rm stockpred<\/code><\/p>\n<p>So I am inside the container, mlflow is installed there and I do:<\/p>\n<pre><code>mlflow run .\n2022\/06\/05 08:55:12 ERROR mlflow.cli: === Could not find Docker executable. Ensure Docker is installed as per the instructions at https:\/\/docs.docker.com\/install\/overview\/. ===\n<\/code><\/pre>\n<p>What does this mean? MLflow requires to have docker installed <em>inside<\/em> the docker container? Does that mean that MLflow <em>uses docker<\/em>?<\/p>\n<p>EDIT:\nReading MLflow tutorial (which uses conda) it seems that in fact Docker has to be installed <em>inside<\/em> Docker because when I use a <code>MLproject<\/code> file that uses <code>conda_env<\/code> and not <code>docker_env<\/code> <code>mlflow run .<\/code> seems to work well.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-06-05 09:18:34.013 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-06 12:32:42.367 UTC",
        "Question_score":0,
        "Question_tags":"docker|mlflow",
        "Question_view_count":81,
        "Owner_creation_date":"2015-01-14 01:17:49.333 UTC",
        "Owner_last_access_date":"2022-09-24 09:09:14.427 UTC",
        "Owner_reputation":5585,
        "Owner_up_votes":792,
        "Owner_down_votes":53,
        "Owner_views":1350,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72506125",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66297459,
        "Question_title":"MLFlow properly installed in conda env but can't use it",
        "Question_body":"<p>Once the conda env is activated, <code>which mlflow<\/code> returns the correct path.\nHowever, when running <code>mlflow server<\/code>, it doesn't seem to find it.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Ex1bB.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ex1bB.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Did anyone meet this problem before?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_date":"2021-02-20 23:05:52.513 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"conda|mlflow",
        "Question_view_count":357,
        "Owner_creation_date":"2017-09-17 20:23:36.77 UTC",
        "Owner_last_access_date":"2022-09-24 08:39:00.303 UTC",
        "Owner_reputation":37,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66297459",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60597319,
        "Question_title":"Running MLFlow on GCP VM",
        "Question_body":"<p>I have installed mlflow on GCP VM instance, \nnow I want to access mlflow UI with external IP.\nI tried setting up a firewall rule and opening the default port for mlflow, but not able to access it.\nCan someone give step by step process for just running mlflow on VM instance?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2020-03-09 08:59:47.613 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-03-10 09:27:00.66 UTC",
        "Question_score":4,
        "Question_tags":"python|google-cloud-platform|mlflow",
        "Question_view_count":1537,
        "Owner_creation_date":"2015-12-26 10:00:57.623 UTC",
        "Owner_last_access_date":"2022-09-24 13:39:24.72 UTC",
        "Owner_reputation":736,
        "Owner_up_votes":69,
        "Owner_down_votes":2,
        "Owner_views":234,
        "Answer_body":"<p>I've decided to check on my test VM and run mlflow server on GCE VM. Have a look at my steps below:<\/p>\n\n<ol>\n<li>create VM instance based on Ubuntu Linux 18.04 LTS<\/li>\n<li><p><a href=\"https:\/\/www.mlflow.org\/docs\/latest\/quickstart.html\" rel=\"noreferrer\">install MLflow<\/a>:<\/p>\n\n<pre><code>$ sudo apt update\n$ sudo apt upgrade\n$ cd ~\n$ git clone https:\/\/github.com\/mlflow\/mlflow\n$ cd mlflow\n$ sudo apt install python3-pip\n$ pip3 install mlflow\n$ python3 setup.py build\n$ sudo python3 setup.py install\n$ mlflow --version\nmlflow, version 1.7.1.dev0\n<\/code><\/pre><\/li>\n<li><p>run mlflow server on internal IP of VM instance (default 127.0.0.1):<\/p>\n\n<pre><code>$ ifconfig \nens4: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1460\ninet 10.XXX.15.XXX  netmask 255.255.255.255  broadcast 0.0.0.0\n...\n\n$ mlflow server --host 10.XXX.15.XXX\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Starting gunicorn 20.0.4\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Listening at: http:\/\/10.128.15.211:5000 (8631)\n[2020-03-09 15:05:50 +0000] [8631] [INFO] Using worker: sync\n[2020-03-09 15:05:50 +0000] [8634] [INFO] Booting worker with pid: 8634\n[2020-03-09 15:05:51 +0000] [8635] [INFO] Booting worker with pid: 8635\n[2020-03-09 15:05:51 +0000] [8636] [INFO] Booting worker with pid: 8636\n[2020-03-09 15:05:51 +0000] [8638] [INFO] Booting worker with pid: 8638\n<\/code><\/pre><\/li>\n<li><p>check from VM instance (from second connection):<\/p>\n\n<pre><code>$ curl -I http:\/\/10.XXX.15.XXX:5000\nHTTP\/1.1 200 OK\nServer: gunicorn\/20.0.4\nDate: Mon, 09 Mar 2020 15:06:08 GMT\nConnection: close\nContent-Length: 853\nContent-Type: text\/html; charset=utf-8\nLast-Modified: Mon, 09 Mar 2020 14:57:11 GMT\nCache-Control: public, max-age=43200\nExpires: Tue, 10 Mar 2020 03:06:08 GMT\nETag: \"1583765831.3202355-853-3764264575\"\n<\/code><\/pre><\/li>\n<li><p><a href=\"https:\/\/cloud.google.com\/vpc\/docs\/add-remove-network-tags\" rel=\"noreferrer\">set network tag<\/a> <code>mlflow-server<\/code> <\/p><\/li>\n<li><p><a href=\"https:\/\/cloud.google.com\/vpc\/docs\/using-firewalls#creating_firewall_rules\" rel=\"noreferrer\">create firewall rule<\/a> to allow access on port 5000<\/p>\n\n<pre><code>$ gcloud compute --project=test-prj firewall-rules create mlflow-server --direction=INGRESS --priority=999 --network=default --action=ALLOW --rules=tcp:5000 --source-ranges=0.0.0.0\/0 --target-tags=mlflow-server\n<\/code><\/pre><\/li>\n<li><p>check from on-premises Linux machine <code>nmap -Pn 35.225.XXX.XXX<\/code><\/p>\n\n<pre><code>Starting Nmap 7.80 ( https:\/\/nmap.org ) at 2020-03-09 16:20 CET\nNmap scan report for 74.123.225.35.bc.googleusercontent.com (35.225.XXX.XXX)\nHost is up (0.20s latency).\nNot shown: 993 filtered ports\nPORT     STATE  SERVICE\n...\n5000\/tcp open   upnp\n...\n<\/code><\/pre><\/li>\n<li><p>go to web browser <a href=\"http:\/\/35.225.XXX.XXX:5000\/\" rel=\"noreferrer\">http:\/\/35.225.XXX.XXX:5000\/<\/a><\/p><\/li>\n<\/ol>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/u2aFt.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/u2aFt.png\" alt=\"mlflow\"><\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-03-09 15:26:38.37 UTC",
        "Answer_score":5.0,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60597319",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72745109,
        "Question_title":"No FileSystem for scheme \"s3\" exception when using spark with mlflow",
        "Question_body":"<p>we are running a Spark job against our Kubernetes cluster and try to log the model to MLflow. We are running Spark 3.2.1 and MLflow 1.26.1 and we are using the following jars to communicate with s3 <code>hadoop-aws-3.2.2.jar<\/code> and <code>aws-java-sdk-bundle-1.11.375.jar<\/code> and configure our spark-submit job with the following parameters:<\/p>\n<pre class=\"lang-bash prettyprint-override\"><code>  --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider \\\n  --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \\\n  --conf spark.hadoop.fs.s3a.fast.upload=true \\\n<\/code><\/pre>\n<p>When we try to save our Spark model with <code>mlflow.spark.log_model()<\/code> we are getting the following exception:<\/p>\n<pre class=\"lang-java prettyprint-override\"><code>22\/06\/24 13:27:21 ERROR Instrumentation: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme &quot;s3&quot;\n    at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n    at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n    at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n    at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n    at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n    at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n    at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n    at org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:673)\n    at org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n    at org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n    at org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n    at org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n    at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n    at scala.util.Try$.apply(Try.scala:213)\n    at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n    at org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n    at java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n    at java.base\/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n    at java.base\/java.lang.reflect.Method.invoke(Unknown Source)\n    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n    at py4j.Gateway.invoke(Gateway.java:282)\n    at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n    at py4j.commands.CallCommand.execute(CallCommand.java:79)\n    at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n    at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n    at java.base\/java.lang.Thread.run(Unknown Source)\n<\/code><\/pre>\n<p>We tried to start our MLflow server with <code>-default-artifact-root<\/code> set to <code>s3a:\/\/...<\/code> but when we run our spark job and we call <code>mlflow.get_artifact_uri()<\/code> (which is also used to construct the upload uri in <code>mlflow.spark.log_model()<\/code>) the result starts with <code>s3<\/code> which probably cause the former mentioned exception.\nSince Hadoop dropped support for the <code>s3:\/\/<\/code> filesystem does anyone know how to log spark models to s3 using MLflow?<\/p>\n<p>Cheers<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-06-24 13:52:05.497 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-25 14:06:10.247 UTC",
        "Question_score":1,
        "Question_tags":"apache-spark|amazon-s3|pyspark|mlflow",
        "Question_view_count":148,
        "Owner_creation_date":"2015-09-19 07:52:59.16 UTC",
        "Owner_last_access_date":"2022-09-22 17:32:09.817 UTC",
        "Owner_reputation":773,
        "Owner_up_votes":380,
        "Owner_down_votes":6,
        "Owner_views":58,
        "Answer_body":"<p>Additional to the <code>spark.hadoop.fs.s3a.impl<\/code> config parameter, you can try to also set <code>spark.hadoop.fs.s3.impl<\/code> to <code>org.apache.hadoop.fs.s3a.S3AFileSystem<\/code><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-27 11:49:11.533 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72745109",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67546769,
        "Question_title":"Kedro-mlflow usage - when to use it from notebooks, and when from kedro pipeline?",
        "Question_body":"<p>I'm a bit confused - what is the common practice for kedro-mlflow usage? It's seems slightly uncomfortable to use it only from kedro pipelines, but kedro intention is fully reproducible research.<\/p>\n<p>At the same time rather rare tutorials on kedro-mlflow usage describe experiments creation from Jupiter notebooks, which seems natural, but then full reproducibility without the full pipeline is broken.<\/p>\n<p>Question - what are common patterns on kedro-mlflow usage, as well as subexperiments creation (in scope of CrossValidation or HyperOptimisation)? When kedro pipelines should be used, and when code (and which code) should be placed in notebooks?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_creation_date":"2021-05-15 12:32:57.757 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mlflow|kedro",
        "Question_view_count":160,
        "Owner_creation_date":"2018-01-02 12:23:30.993 UTC",
        "Owner_last_access_date":"2021-07-08 08:48:54.77 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Riga, Latvia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67546769",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70051420,
        "Question_title":"MLFlow projects; bash: python: command not found",
        "Question_body":"<p>I'm running MLflow Project for a model using following command from my ubuntu 20.04 terminal<\/p>\n<pre><code>mlflow run . --no-conda -P alpha=0.5\n<\/code><\/pre>\n<p>My system doesn't have conda or python (It does however have python3). So, I added alias for python using terminal<\/p>\n<pre><code>alias python='python3'\n<\/code><\/pre>\n<p>After which I could open python in terminal using <code>python<\/code>. However, I still got the same error<\/p>\n<pre><code>2021\/11\/21 08:07:34 INFO mlflow.projects.utils: === Created directory \/tmp\/tmpp4h595ql for downloading remote URIs passed to arguments of type 'path' ===\n2021\/11\/21 08:07:34 INFO mlflow.projects.backend.local: === Running command 'python tracking.py 0.5 0.1' in run with ID 'e50ca47b3f8848a083906be6220c26fc' === \nbash: python: command not found\n2021\/11\/21 08:07:34 ERROR mlflow.cli: === Run (ID 'e50ca47b3f8848a083906be6220c26fc') failed ===\n<\/code><\/pre>\n<p>How to get rid of this error?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-21 02:44:17.297 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|bash|ubuntu|terminal|mlflow",
        "Question_view_count":281,
        "Owner_creation_date":"2020-09-25 03:31:49.207 UTC",
        "Owner_last_access_date":"2022-09-24 07:17:02.153 UTC",
        "Owner_reputation":1074,
        "Owner_up_votes":239,
        "Owner_down_votes":21,
        "Owner_views":143,
        "Answer_body":"<p>Change <code>python<\/code> to <code>python3<\/code> in the <code>MLproject<\/code> file to the resolve error.<\/p>\n<pre><code>command: &quot;python3 tracking.py {alpha} {l1_ratio}&quot;\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-21 03:02:34.447 UTC",
        "Answer_score":0.0,
        "Owner_location":"Pune, Maharashtra, India",
        "Answer_last_edit_date":"2021-11-21 13:56:33.977 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70051420",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61145399,
        "Question_title":"MLflow Tracking On EC2",
        "Question_body":"<p>I'm attempting to follow the instructions given here (<a href=\"https:\/\/medium.com\/@alexanderneshitov\/how-to-run-an-mlflow-tracking-server-on-aws-ec2-d7afd0ac8008\" rel=\"nofollow noreferrer\">https:\/\/medium.com\/@alexanderneshitov\/how-to-run-an-mlflow-tracking-server-on-aws-ec2-d7afd0ac8008<\/a>) to test running MLflow tracker on an ec2 instance. I have done the following from the article<\/p>\n\n<ol>\n<li>Install mlflow on ec2<\/li>\n<li>Install and configure NGINX following the steps given<\/li>\n<li>Start mlflow server on ec2 using <code>mlflow server --default-artifact-root s3:\/\/test.bucket.for.mlflow\/ --host 0.0.0.0<\/code><\/li>\n<li>Access server using its public DNS<\/li>\n<\/ol>\n\n<p>According to the article, I should see the mlflow ui when accessing with my ec2 public DNS, but all I see is the following page:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/U5o1C.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/U5o1C.png\" alt=\"NGINX page instead of MLflow UI\"><\/a><\/p>\n\n<p>Why would I be seeing this page and not the mlflow page like:<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/6RiiT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/6RiiT.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":5,
        "Question_creation_date":"2020-04-10 17:23:33.373 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-04-13 17:01:16.79 UTC",
        "Question_score":0,
        "Question_tags":"nginx|amazon-ec2|dns|mlflow",
        "Question_view_count":1547,
        "Owner_creation_date":"2014-11-26 14:40:35.813 UTC",
        "Owner_last_access_date":"2021-08-12 15:37:44.573 UTC",
        "Owner_reputation":945,
        "Owner_up_votes":35,
        "Owner_down_votes":1,
        "Owner_views":148,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61145399",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72855204,
        "Question_title":"MLflow is taking longer than expected time to finish logging metrics and parameters",
        "Question_body":"<p>I'm running a code where I have to perform multiple iterations for a set of products to select the best performing model. While running multiple iterations for a single product, I need to log details of every single run using mlflow(using mlflow with pandas-udf). While logging for individual iterations are taking around 2 seconds but the parent run under which I'm tracking every iteration details is taking 1.5 hours to finish. Here is the code -<\/p>\n<pre><code>@F.pandas_udf( model_results_schema, F.PandasUDFType.GROUPED_MAP )\ndef get_gam_pe_results( model_input ):\n    ...\n    ...\n    for j, gam_terms in enumerate(term_list[-1]):\n        results_iteration_output_1, results_iteration_output, results_iteration_all = run_gam_model(gam_terms)\n        \n        results_iteration_version = results_iteration_version.append(results_iteration_output)\n        unique_id = uuid.uuid1()\n        metric_list = [&quot;AIC&quot;, &quot;AICc&quot;, &quot;GCV&quot;, &quot;adjusted_R2&quot;, &quot;deviance&quot;, &quot;edof&quot;, &quot;elasticity_in_k&quot;, &quot;loglikelihood&quot;,\n                      &quot;scale&quot;]\n        param_list = [&quot;features&quot;]\n        start_time = str(datetime.now())\n        with mlflow.start_run(run_id=parent_run_id, experiment_id=experiment_id):\n            with mlflow.start_run(run_name=str(model_input['prod_id'].iloc[1]) + &quot;-&quot; + unique_id.hex,\n                                  experiment_id=experiment_id, nested=True):\n                for item in results_iteration_output.columns.values.tolist():\n                        if item in metric_list:\n                            mlflow.log_metric(item, results_iteration_output[item].iloc[0])\n                        if item in param_list:\n                            mlflow.log_param(item, results_iteration_output[item].iloc[0])\n                            \n                end_time = str(datetime.now())\n                mlflow.log_param(&quot;start_time&quot;, start_time)\n                mlflow.log_param(&quot;end_time&quot;, end_time)\n<\/code><\/pre>\n<p>Outside pandas-udf -<\/p>\n<pre><code>current_time = str(datetime.today().replace(microsecond=0))\nrun_id = None\nwith mlflow.start_run(run_name=&quot;MLflow_pandas_udf_testing-&quot;+current_time, experiment_id=experiment_id) as run:\n    run_id = run.info.run_uuid\n    gam_model_output = (Product_data\n                        .withColumn(&quot;run_id&quot;, F.lit(run_id))\n                        .groupby(['prod_id'])\n                        .apply(get_gam_pe_results)\n                       )\n<\/code><\/pre>\n<p>Note - Running this entire code in Databricks(cluster has 8 cores and 28gb ram).<\/p>\n<p>Any idea why this parent run is taking so long to finish while it's only 2 seconds to finish each iterations?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/jzqkx.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/jzqkx.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-04 10:20:55.54 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-23 16:06:47.68 UTC",
        "Question_score":0,
        "Question_tags":"python-3.x|machine-learning|azure-databricks|mlflow|pandas-udf",
        "Question_view_count":76,
        "Owner_creation_date":"2016-01-12 12:36:46.603 UTC",
        "Owner_last_access_date":"2022-09-23 16:01:34.33 UTC",
        "Owner_reputation":55,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Kolkata, West Bengal, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72855204",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71315446,
        "Question_title":"How do I take an already existing MLflow model on my local filesystem and log it to a remote tracking server?",
        "Question_body":"<p>Let's say I already have an existing MLflow model on my local system of the <code>mlflow.pyfunc<\/code> flavor.<\/p>\n<p>The directory looks like this<\/p>\n<pre><code>model\/\n  data\/\n  code\/\n  conda.yml\n  MLmodel\n<\/code><\/pre>\n<p>Where <code>MLmodel<\/code> is something like<\/p>\n<pre><code>flavors:\n  python_function:\n    code: code\n    data: data\n    env: conda.yml\n    loader_module: loader # model\/code\/loader.py has the entrypoint\n<\/code><\/pre>\n<p>I now try and log this model to a remote tracking server using (I'm in the directory above <code>model\/<\/code>, so <code>.\/model\/data<\/code> works, etc)<\/p>\n<pre><code>import mlflow\nmlflow.set_tracking_uri(&quot;http:\/\/localhost:5000&quot;)\nmlflow.pyfunc.log_model(\n  &quot;my-model-artifact&quot;,\n  registered_model_name=&quot;my-model&quot;, # same for all model versions,\n  data_path=&quot;model\/data&quot;,\n  code_path=&quot;model\/code&quot;,\n  loader_module=&quot;model\/code\/loader&quot;\n)\n<\/code><\/pre>\n<p>The tracking server ends up logging a nested MLflow model.. this is inside of the <code>.\/artifacts\/my-model-artifact<\/code> directory on the tracking server<\/p>\n<pre><code>.\/artifacts\/my-model-artifact\n  conda.yaml\n  MLmodel # *not* my MLmodel, one newly generated by MLflow\n  data\/\n  code\/\n<\/code><\/pre>\n<p>Where <code>data<\/code> now points nested to my entire <code>model\/data<\/code> directory and <code>code<\/code> points to a nested <code>model\/code<\/code> directory.<\/p>\n<p>It's like it doesn't understand that I already have this full artifact..<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-03-01 22:43:04.637 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"model|mlflow",
        "Question_view_count":336,
        "Owner_creation_date":"2015-03-10 05:37:19.877 UTC",
        "Owner_last_access_date":"2022-09-23 19:26:30.29 UTC",
        "Owner_reputation":3256,
        "Owner_up_votes":81,
        "Owner_down_votes":0,
        "Owner_views":164,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Santa Cruz, CA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71315446",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65849787,
        "Question_title":"Mlflow and KerasTuner integration",
        "Question_body":"<p>I am trying to integrate together <code>KerasTuner<\/code> and <code>Mlflow<\/code>. I'd like to record the loss at each epoch of each trial of Keras Tuner.<\/p>\n<p>My approach is:<\/p>\n<pre><code>class MlflowCallback(tf.keras.callbacks.Callback):\n    \n    # This function will be called after each epoch.\n    def on_epoch_end(self, epoch, logs=None):\n        if not logs:\n            return\n        # Log the metrics from Keras to MLflow     \n        mlflow.log_metric(&quot;loss&quot;, logs[&quot;loss&quot;], step=epoch)\n    \n\nfrom kerastuner.tuners import RandomSearch\n\nwith mlflow.start_run(run_name=&quot;myrun&quot;, nested=True) as run:\n  \n  tuner = RandomSearch(\n      train_fn,\n      objective='loss',\n      max_trials=25, \n  )\n  tuner.search(train,\n              validation_data=validation, \n              validation_steps=validation_steps,\n              steps_per_epoch=steps_per_epoch, \n              epochs=5, \n              callbacks=[MlflowCallback()]\n  )\n<\/code><\/pre>\n<p>However, the loss values are reported (sequentially) in one single experiment. Is there a way to record them independently?\n<a href=\"https:\/\/i.stack.imgur.com\/awObK.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/awObK.png\" alt=\"Loss values\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-22 17:17:09.787 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"tensorflow|keras|callback|mlflow|keras-tuner",
        "Question_view_count":390,
        "Owner_creation_date":"2011-10-15 10:06:34.37 UTC",
        "Owner_last_access_date":"2021-07-07 15:02:50.657 UTC",
        "Owner_reputation":3651,
        "Owner_up_votes":12,
        "Owner_down_votes":1,
        "Owner_views":269,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Rome",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65849787",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63229784,
        "Question_title":"How to load a keras model (.h5 file) from local to Azure databricks workspace",
        "Question_body":"<p>I have a keras model created on my local machine and I saved it as a model.h5 format. Now how do I load this model into my workspace on Azure databricks and import inside a databricks notebook and use the model?<\/p>\n<p>trying the below URL but not successful, seems like its useful if and only if you save the model from databricks notebook using mlFlow and load it back under databricks using mlFlow:<\/p>\n<p><a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.keras.html\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.keras.html<\/a><\/p>\n<p>what if I have a keras model created in my local machine, how do I go ahead for importing?, please help.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-03 12:50:32.557 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"keras|databricks|mlflow",
        "Question_view_count":692,
        "Owner_creation_date":"2016-11-18 20:17:30.887 UTC",
        "Owner_last_access_date":"2022-01-28 17:12:45.737 UTC",
        "Owner_reputation":9,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63229784",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70680222,
        "Question_title":"Does MLflow allow to log artifacts from remote locations like S3?",
        "Question_body":"<h2>My setting<\/h2>\n<p>I have developed an environment for ML experiments that looks like the following: training happens in the AWS cloud with SageMaker Training Jobs. The trained model is stored in the <code>\/opt\/ml\/model<\/code> directory, <a href=\"https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/your-algorithms-training-algo-output.html\" rel=\"nofollow noreferrer\">which is reserved by SageMaker to pack models<\/a> as a <code>.tar.gz<\/code> in SageMaker's own S3 bucket. Several evaluation metrics are computed during training and testing, and recorded to an MLflow infrastructure consisting of an S3-based artifact store (see <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#scenario-4-mlflow-with-remote-tracking-server-backend-and-artifact-stores\" rel=\"nofollow noreferrer\">Scenario 4<\/a>). Note that this is a different S3 bucket than SageMaker's.<\/p>\n<p>A very useful feature from MLflow is that any model artifacts can be logged to a training run, so data scientists have access to both metrics and more complex outputs through the UI. These outputs include (but are not limited to) the trained model itself.<\/p>\n<p>A limitation is that, as I understand it, the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.log_artifact\" rel=\"nofollow noreferrer\">MLflow API for logging artifacts<\/a> only accepts as input a local path to the artifact itself, and will always upload it to its artifact store. This is suboptimal when the artifacts are stored somewhere outside MLflow, as you have to store them twice. A transformer model may weigh more than 1GB.<\/p>\n<h2>My questions<\/h2>\n<ul>\n<li>Is there a way to pass an S3 path to MLflow and make it count as an artifact, without having to download it locally first?<\/li>\n<li>Is there a way to avoid pushing a copy of an artifact to the artifact store? If my artifacts already reside in another remote location, it would be ideal to just have a link to such location in MLflow and not a copy in MLflow storage.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-12 10:49:12.913 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|amazon-s3|amazon-sagemaker|mlflow|mlops",
        "Question_view_count":533,
        "Owner_creation_date":"2016-01-08 20:55:48.08 UTC",
        "Owner_last_access_date":"2022-09-23 10:18:38.03 UTC",
        "Owner_reputation":118,
        "Owner_up_votes":28,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Madrid, Spain",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70680222",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73763836,
        "Question_title":"MLFlow - count number of runs given an experiment name",
        "Question_body":"<p>Is there a way count number of runs given an experiment name? I'm using python.\nE.g. I have an experiment name: &quot;Test&quot; and I wish to get the number of runs somehow like this, but I couldn't find anything in the documentation:<\/p>\n<pre><code>experiment_name = &quot;test&quot;\ncount = mlflow.get_number_of_runs(experiment_name)\nprint(f'There are {count} runs in {experiment_name}')\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-09-18 15:07:03.92 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-18 15:14:05.807 UTC",
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":11,
        "Owner_creation_date":"2021-12-02 08:15:11.713 UTC",
        "Owner_last_access_date":"2022-09-22 13:13:02.7 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73763836",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71747662,
        "Question_title":"FastAPI slow in MLFlow",
        "Question_body":"<p>I have a use case where I want to deploy ML Models with low latency and high throughput.\nIn MLFlow, I couldn't achieve it, so I tried FastAPI and it showed quite good results.<\/p>\n<p>Thus, I tried to replace the Flask engine with FastAPI in MLFlow. But I am getting very low throughput per process on using FastAPI in MLFlow as compared to standalone FastAPI serving for the same model.<\/p>\n<p><a href=\"https:\/\/github.com\/tsenart\/vegeta\" rel=\"nofollow noreferrer\">Vegeta<\/a> benchmarking results:<\/p>\n<p>MLFlow with FastAPI Test1:<\/p>\n<pre><code>(base) [ec2-user@ip-172-31-43-232 testing]$ cat target_all.txt | .\/vegeta attack -duration=1m -rate=100 -max-workers=20 | .\/vegeta report\nRequests [total, rate, throughput] 1174, 100.09, 100.07\nDuration [total, attack, wait] 11.732s, 11.73s, 2.03ms\nLatencies [min, mean, 50, 90, 95, 99, max] 1.71ms, 2.23ms, 1.87ms, 3.394ms, 3.911ms, 7.58ms, 9.813ms\nBytes In [total, mean] 111530, 95.00\nBytes Out [total, mean] 224234, 191.00\nSuccess [ratio] 100.00%\nStatus Codes [code:count] 200:1174\n<\/code><\/pre>\n<p>MLFlow with FastAPI Test2:<\/p>\n<pre><code>(base) [ec2-user@ip-172-31-43-232 testing]$ cat target_all.txt | .\/vegeta attack -duration=1m -rate=200 -max-workers=20 | .\/vegeta report\nRequests [total, rate, throughput] 2159, 158.75, 157.30\nDuration [total, attack, wait] 13.725s, 13.6s, 125.605ms\nLatencies [min, mean, 50, 90, 95, 99, max] 10.256ms, 124.783ms, 125.951ms, 129.294ms, 133.891ms, 148.876ms, 293.218ms\nBytes In [total, mean] 209423, 97.00\nBytes Out [total, mean] 412369, 191.00\nSuccess [ratio] 100.00%\nStatus Codes [code:count] 200:2159\n<\/code><\/pre>\n<p>Standalone FastAPI Test3:<\/p>\n<pre><code>Requests [total, rate, throughput] 36000, 600, 599\nLatencies [min, mean, 50, 90, 95, 99, max] 1.515ms, 2.608ms, 2.734ms, 3.386ms, 3.611ms, 4.204ms, 4.795ms\n<\/code><\/pre>\n<p>On using FastAPI, I am getting throughput to be more than 600 RPS per Gunicorn worker, while on using FastAPI with MLFlow, I am getting 100 RPS at max without affecting the response time of the model.\nI think I am missing something in this <a href=\"https:\/\/github.com\/mlflow\/mlflow\/pull\/5599\" rel=\"nofollow noreferrer\">PR<\/a>. Can someone please help?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-04-05 07:17:27.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"fastapi|mlflow|mlops",
        "Question_view_count":296,
        "Owner_creation_date":"2016-09-30 18:28:36.607 UTC",
        "Owner_last_access_date":"2022-05-25 08:19:33.757 UTC",
        "Owner_reputation":490,
        "Owner_up_votes":7,
        "Owner_down_votes":11,
        "Owner_views":30,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71747662",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69944447,
        "Question_title":"How to change the directory of mlflow logs?",
        "Question_body":"<p>I am using MLflow to log the metrics but I want to change the default saving logs directory. So, instead of writing log files besides my main file, I want to store them to <code>\/path\/outputs\/lg <\/code>. I don't know how to change it. I use it without in the <code>Model<\/code>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import os\nfrom time import time\n\nimport mlflow\nimport numpy as np\nimport torch\nimport tqdm\n\n# from segmentation_models_pytorch.utils import metrics\nfrom AICore.emergency_landing.metrics import IoU, F1\nfrom AICore.emergency_landing.utils import AverageMeter\nfrom AICore.emergency_landing.utils import TBLogger\n\n\nclass Model:\n    def __init__(self, model, num_classes=5, ignore_index=0, optimizer=None, scheduler=None, criterion=None,\n                 device=None, epochs=30, train_loader=None, val_loader=None, tb_logger: TBLogger = None,\n                 logger=None,\n                 best_model_path=None,\n                 model_check_point_path=None,\n                 load_from_best_model=None,\n                 load_from_model_checkpoint=None,\n                 early_stopping=None,\n                 debug=False):\n\n        self.debug = debug\n\n        self.early_stopping = {\n            'init': early_stopping,\n            'changed': 0\n        }\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.criterion = criterion\n        self.device = device\n        self.epochs = epochs\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        self.model = model.to(device)\n\n        self.tb_logger = tb_logger\n        self.logger = logger\n\n        self.best_loss = np.Inf\n\n        if not os.path.exists(best_model_path):\n            os.makedirs(best_model_path)\n        self.best_model_path = best_model_path\n\n        if not os.path.exists(model_check_point_path):\n            os.makedirs(model_check_point_path)\n        self.model_check_point_path = model_check_point_path\n\n        self.load_from_best_model = load_from_best_model\n        self.load_from_model_checkpoint = load_from_model_checkpoint\n\n        if self.load_from_best_model is not None:\n            self.load_model(path=self.load_from_best_model)\n        if self.load_from_model_checkpoint is not None:\n            self.load_model_checkpoint(path=self.load_from_model_checkpoint)\n\n        self.train_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n        self.val_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n        self.test_iou = IoU(num_classes=num_classes, ignore_index=ignore_index)\n\n        self.train_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n        self.val_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n        self.test_f1 = F1(num_classes=num_classes, ignore_index=ignore_index, mdmc_average='samplewise')\n\n    def metrics(self, is_train=True):\n        if is_train:\n            train_losses = AverageMeter('Training Loss', ':.4e')\n            train_iou = AverageMeter('Training iou', ':6.2f')\n            train_f_score = AverageMeter('Training F_score', ':6.2f')\n\n            return train_losses, train_iou, train_f_score\n        else:\n            val_losses = AverageMeter('Validation Loss', ':.4e')\n            val_iou = AverageMeter('Validation mean iou', ':6.2f')\n            val_f_score = AverageMeter('Validation F_score', ':6.2f')\n\n            return val_losses, val_iou, val_f_score\n\n    def fit(self):\n\n        self.logger.info(&quot;\\nStart training\\n\\n&quot;)\n        start_training_time = time()\n\n        with mlflow.start_run():\n            for e in range(self.epochs):\n                start_training_epoch_time = time()\n                self.model.train()\n                train_losses_avg, train_iou_avg, train_f_score_avg = self.metrics(is_train=True)\n                with tqdm.tqdm(self.train_loader, unit=&quot;batch&quot;) as tepoch:\n                    tepoch.set_description(f&quot;Epoch {e}&quot;)\n                    for image, target in tepoch:\n                        # Transfer Data to GPU if available\n                        image = image.to(self.device)\n                        target = target.to(self.device)\n                        # Clear the gradients\n                        self.optimizer.zero_grad()\n                        # Forward Pass\n                        # out = self.model(image)['out']\n                        # if unet == true =&gt; remove ['out']\n                        out = self.model(image)\n                        # Find the Loss\n                        loss = self.criterion(out, target)\n                        # Calculate Loss\n                        train_losses_avg.update(loss.item(), image.size(0))\n                        # Calculate gradients\n                        loss.backward()\n                        # Update Weights\n                        self.optimizer.step()\n\n                        iou = self.train_iou(out.cpu(), target.cpu()).item()\n                        train_iou_avg.update(iou)\n\n                        f1_score = self.train_f1(out.cpu(), target.cpu()).item()\n                        train_f_score_avg.update(f1_score)\n\n                        tepoch.set_postfix(loss=train_losses_avg.avg,\n                                           iou=train_iou_avg.avg,\n                                           f_score=train_f_score_avg.avg)\n                        if self.debug:\n                            break\n\n                self.tb_logger.log(log_type='criterion\/training', value=train_losses_avg.avg, epoch=e)\n                self.tb_logger.log(log_type='iou\/training', value=train_iou_avg.avg, epoch=e)\n                self.tb_logger.log(log_type='f_score\/training', value=train_f_score_avg.avg, epoch=e)\n\n                mlflow.log_metric('criterion\/training', train_losses_avg.avg, step=e)\n                mlflow.log_metric('iou\/training', train_iou_avg.avg, step=e)\n                mlflow.log_metric('f_score\/training', train_f_score_avg.avg, step=e)\n\n                end_training_epoch_time = time() - start_training_epoch_time\n                print('\\n')\n                self.logger.info(\n                    f'Training Results - [{end_training_epoch_time:.3f}s] Epoch: {e}:'\n                    f' f_score: {train_f_score_avg.avg:.3f},'\n                    f' IoU: {train_iou_avg.avg:.3f},'\n                    f' Loss: {train_losses_avg.avg:.3f}')\n\n                # validation step\n                val_loss = self.evaluation(e)\n                # apply scheduler\n                if self.scheduler:\n                    self.scheduler.step()\n                # early stopping\n                if self.early_stopping['init'] &gt;= self.early_stopping['changed']:\n                    self._early_stopping_model(val_loss=val_loss)\n                else:\n                    print(f'The model can not learn more, Early Stopping at epoch[{e}]')\n                    break\n\n                # save best model\n                if self.best_model_path is not None:\n                    self._best_model(val_loss=val_loss, path=self.best_model_path)\n\n                # model check points\n                if self.model_check_point_path is not None:\n                    self.save_model_check_points(path=self.model_check_point_path, epoch=e, net=self.model,\n                                                 optimizer=self.optimizer, loss=self.criterion,\n                                                 avg_loss=train_losses_avg.avg)\n\n                # log mlflow\n                if self.scheduler:\n                    mlflow.log_param(&quot;get_last_lr&quot;, self.scheduler.get_last_lr())\n                    mlflow.log_param(&quot;scheduler&quot;, self.scheduler.state_dict())\n\n                self.tb_logger.flush()\n                if self.debug:\n                    break\n\n            end_training_time = time() - start_training_time\n            print(f'Finished Training after {end_training_time:.3f}s')\n            self.tb_logger.close()\n\n    def evaluation(self, epoch):\n        print('Validating...')\n        start_validation_epoch_time = time()\n        self.model.eval()  # Optional when not using Model Specific layer\n        with torch.no_grad():\n            val_losses_avg, val_iou_avg, val_f_score_avg = self.metrics(is_train=False)\n            with tqdm.tqdm(self.val_loader, unit=&quot;batch&quot;) as tepoch:\n                for image, target in tepoch:\n                    # Transfer Data to GPU if available\n                    image = image.to(self.device)\n                    target = target.to(self.device)\n                    # out = self.model(image)['out']\n                    # if unet == true =&gt; remove ['out']\n                    out = self.model(image)\n                    # Find the Loss\n                    loss = self.criterion(out, target)\n                    # Calculate Loss\n                    val_losses_avg.update(loss.item(), image.size(0))\n\n                    iou = self.val_iou(out.cpu(), target.cpu()).item()\n                    val_iou_avg.update(iou)\n\n                    f1_score = self.val_f1(out.cpu(), target.cpu()).item()\n                    val_f_score_avg.update(f1_score)\n\n                    tepoch.set_postfix(loss=val_losses_avg.avg,\n                                       iou=val_iou_avg.avg,\n                                       f_score=val_f_score_avg.avg)\n                    if self.debug:\n                        break\n            print('\\n')\n            self.tb_logger.log(log_type='criterion\/validation', value=val_losses_avg.avg, epoch=epoch)\n            self.tb_logger.log(log_type='iou\/validation', value=val_iou_avg.avg, epoch=epoch)\n            self.tb_logger.log(log_type='f_score\/validation', value=val_f_score_avg.avg, epoch=epoch)\n\n            mlflow.log_metric('criterion\/validation', val_losses_avg.avg, step=epoch)\n            mlflow.log_metric('iou\/validation', val_iou_avg.avg, step=epoch)\n            mlflow.log_metric('f_score\/validation', val_f_score_avg.avg, step=epoch)\n\n            end_validation_epoch_time = time() - start_validation_epoch_time\n            self.logger.info(\n                f'validation Results - [{end_validation_epoch_time:.3f}s] Epoch: {epoch}:'\n                f' f_score: {val_f_score_avg.avg:.3f},'\n                f' IoU: {val_iou_avg.avg:.3f},'\n                f' Loss: {val_losses_avg.avg:.3f}')\n            print('\\n')\n            return val_losses_avg.avg\n\n    def _save_model(self, name, path, params):\n        torch.save(params, path)\n\n    def _early_stopping_model(self, val_loss):\n        if self.best_loss &lt; val_loss:\n            self.early_stopping['changed'] += 1\n        else:\n            self.early_stopping['changed'] = 0\n\n    def _best_model(self, val_loss, path):\n        if self.best_loss &gt; val_loss:\n            self.best_loss = val_loss\n            name = f'\/best_model_loss_{self.best_loss:.2f}'.replace('.', '_')\n            self._save_model(name, path=f'{path}\/{name}.pt', params={\n                'model_state_dict': self.model.state_dict(),\n            })\n\n            print(f'The best model is saved with criterion: {self.best_loss:.2f}')\n\n    def save_model_check_points(self, path, epoch, net, optimizer, loss, avg_loss):\n        name = f'\/model_epoch_{epoch}_loss_{avg_loss:.2f}'.replace('.', '_')\n        self._save_model(name, path=f'{path}\/{name}.pt', params={\n            'epoch': epoch,\n            'model_state_dict': net.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'criterion': loss,\n        })\n        print(f'model checkpoint is saved at model_epoch_{epoch}_loss_{avg_loss:.2f}')\n\n    def load_model_checkpoint(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        epoch = checkpoint['epoch']\n        self.criterion = checkpoint['criterion']\n\n        return epoch\n\n    def load_model(self, path):\n        best_model = torch.load(path)\n        self.model.load_state_dict(best_model['model_state_dict'])\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-11-12 14:25:19.83 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-12 22:16:19.243 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|deep-learning|pytorch|mlflow",
        "Question_view_count":436,
        "Owner_creation_date":"2014-09-10 07:11:45.327 UTC",
        "Owner_last_access_date":"2022-09-06 18:46:08.593 UTC",
        "Owner_reputation":477,
        "Owner_up_votes":133,
        "Owner_down_votes":0,
        "Owner_views":130,
        "Answer_body":"<p>The solution is:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.set_tracking_uri(uri=f'file:\/\/{hydra.utils.to_absolute_path(&quot;..\/output\/mlruns&quot;)}')\nexp = mlflow.get_experiment_by_name(name='Emegency_landing')\nif not exp:\n    experiment_id = mlflow.create_experiment(name='Emegency_landing',\n                                                 artifact_location=f'file:\/\/{hydra.utils.to_absolute_path(&quot;..\/output\/mlruns&quot;)}')\nelse:\n    experiment_id = exp.experiment_id\n<\/code><\/pre>\n<p>And then you should pass the experiment Id to:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>with mlflow.start_run(experiment_id=experiment_id):\n     pass \n<\/code><\/pre>\n<p>If you don't mention the <code>\/path\/mlruns<\/code>, when you run the command of <code>mlflow ui<\/code>, it will create another folder automatically named <code>mlruns<\/code>. so, pay attention to this point to have the same name as <code>mlruns<\/code>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-12 15:50:35.59 UTC",
        "Answer_score":0.0,
        "Owner_location":"Turin, Metropolitan City of Turin, Italy",
        "Answer_last_edit_date":"2021-11-12 22:19:00.677 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69944447",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66471862,
        "Question_title":"mlflow on Windows10 and desktop.ini",
        "Question_body":"<p>it's the first time for me to leave a question here.<br \/>\nI'm currently using PyTorch on my research and trying to organize results with MLFlow.<br \/>\nI know that many problems when using MLflow on Windows10 but since there are no options for this... I'm trying to get used to it.\nErrors that I encounter here are &quot;Metrics 'desktop.ini' is malformed ...'<br \/>\nThis error is nagging me when -<\/p>\n<ol>\n<li>Using <code>mlflow ui<\/code> to see experiment results from the past <a href=\"https:\/\/i.stack.imgur.com\/k070v.png\" rel=\"nofollow noreferrer\">mlflow ui error<\/a><\/li>\n<li>When trying to use <code>mlflow.pytorch.log_model(model, ...)<\/code> <a href=\"https:\/\/i.stack.imgur.com\/X3mUX.png\" rel=\"nofollow noreferrer\">pytorch.log_model error<\/a><\/li>\n<\/ol>\n<p>These two are the main concerns for me. My question here is<\/p>\n<ol>\n<li>Is there other result organizing tools that I can use except tensorboard?<\/li>\n<li>Is there any method that can save <code>model.pth<\/code> from pytorch to mlflow? + if it's impossible, are there  any other formats that we use to save the configuration (such as YAML, other hierarchical languages like XML..)<\/li>\n<\/ol>\n<p>Thank you<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-04 09:10:21.7 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"pytorch|mlflow",
        "Question_view_count":58,
        "Owner_creation_date":"2020-07-14 08:34:06.357 UTC",
        "Owner_last_access_date":"2022-01-05 07:08:20.457 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Korea",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66471862",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70619317,
        "Question_title":"How to add retry in mlflow",
        "Question_body":"<p>In order to track machine learning modules I am using mlflow.\nI am starting a mlflow server with command line script <code>my backend store uri is postgresql<\/code><\/p>\n<pre><code>something like \nmlflow server --backend-store-uri postgresql --default-artifact-roots 3:\/\/my-mlflow-bucket\/ --host 0.0.0.0 \n<\/code><\/pre>\n<p>Many a time a postgresql gets down how do to ensure retry a connectivity to  postgresql to n limit only if its not up.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-07 09:42:17.39 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-01-07 11:51:09.63 UTC",
        "Question_score":0,
        "Question_tags":"postgresql|machine-learning|artificial-intelligence|mlflow",
        "Question_view_count":92,
        "Owner_creation_date":"2021-07-08 08:00:42.2 UTC",
        "Owner_last_access_date":"2022-08-04 06:25:20.98 UTC",
        "Owner_reputation":145,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70619317",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67835498,
        "Question_title":"MLflow - How to point interface path to show the expected result",
        "Question_body":"<p>I just started MLflow today and fail to display the log result on MLflow ui interface.\nWill appreciate a lot if someone can give me some hint..<\/p>\n<p>tried the sample code below<\/p>\n<pre><code>import os\nfrom random import random, randint\nfrom mlflow import log_metric, log_param, log_artifacts\n\nif __name__ == &quot;__main__&quot;:\n    # Log a parameter (key-value pair)\n    log_param(&quot;param1&quot;, randint(0, 100))\n\n    # Log a metric; metrics can be updated throughout the run\n    log_metric(&quot;foo&quot;, random())\n    log_metric(&quot;foo&quot;, random() + 1)\n    log_metric(&quot;foo&quot;, random() + 2)\n\n    # Log an artifact (output file)\n    if not os.path.exists(&quot;outputs&quot;):\n        os.makedirs(&quot;outputs&quot;)\n    with open(&quot;outputs\/test.txt&quot;, &quot;w&quot;) as f:\n        f.write(&quot;hello world!&quot;)\n    log_artifacts(&quot;outputs&quot;)\n<\/code><\/pre>\n<p>ran the script above for 3 times and it gave me the result in the following structure. 3 folders representing 3 runs separately:<\/p>\n<pre><code>file:\/\/\/home\/devuser\/project\/mlruns\/0\n0 - 0737fec7d4824384b6320070cd688b78\n    355d57e092a242b7aa263451d280b497 \n    ed2614ffe2fd4f2db991d5d7166635f8  \n    meta.yaml\n<\/code><\/pre>\n<p>with folders\/files <code>artifacts, meta.yaml, metrics, params, tags<\/code> in each folder separately.<\/p>\n<p>I ran <code>mlflow ui<\/code> under <code>file:\/\/\/home\/devuser\/project\/mlruns\/<\/code> but nothing was showed on the interface. tried to look this up but no one has come across this problem with this kind of simple code.<\/p>\n<p>Appreciate a lot if someone could kindly let me know how I can change my setting.. Thank you..<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-06-04 10:15:40.88 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":379,
        "Owner_creation_date":"2015-10-18 08:44:37.637 UTC",
        "Owner_last_access_date":"2021-12-02 14:27:03.627 UTC",
        "Owner_reputation":267,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":111,
        "Answer_body":"<p>You need to run <code>mlflow ui<\/code> in the project directory itself, not inside the <code>mlruns<\/code> - if you look into the <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#mlflow-ui\" rel=\"nofollow noreferrer\">documentation for <code>mlflow ui<\/code> command<\/a>, it says:<\/p>\n<blockquote>\n<p><code>--default-artifact-root &lt;URI&gt;<\/code><\/p>\n<p>Path to local directory to store artifacts, for new experiments. Note that this flag does not impact already-created experiments. <strong>Default: .\/mlruns<\/strong><\/p>\n<\/blockquote>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-06-06 08:39:43.72 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67835498",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67212760,
        "Question_title":"Why is the Databricks notebook cell training my ML model \"Running command...\" forever?",
        "Question_body":"<p>I am training PyTorch models on a Azure Databricks cluster (on a notebook), using PyTorch Lightning, and doing the tracking using mlflow.<\/p>\n<p>I would like to store training metrics + artifacts on the Databricks-hosted tracking server.<\/p>\n<p>To enable that, code is as follows:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.pytorch.autolog()\ntrainer = pl.Trainer(gpus=1, max_epochs=30, callbacks=[EarlyStopping(monitor='val_loss', patience = 6)], progress_bar_refresh_rate=0)\ntrainer.fit(classifier, train_dl, valid_dl)\nprint(&quot;Done&quot;)\n<\/code><\/pre>\n<p>However, the notebook cell gets stuck in a &quot;Running command...&quot; state for way too long:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/e3k4X.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/e3k4X.png\" alt=\"Running forever\" \/><\/a><\/p>\n<p>even though in the driver logs execution seems to have ended:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/bT3Xc.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/bT3Xc.png\" alt=\"Run is over\" \/><\/a><\/p>\n<p>and the experiment is marked as FINISHED in the mlflow UI:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/lwObH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/lwObH.png\" alt=\"mlflow tracking\" \/><\/a><\/p>\n<p>Stopping execution manually doesn't solve either, as the cell would stay in a &quot;Cancelling...&quot; state forever. So the only option left is to clear the cluster state.<\/p>\n<p>This is a problem because I can't execute further commands that would be useful for artifact logging:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mapping.to_json(&quot;\/tmp\/mapping.json&quot;, orient = &quot;records&quot;)\nmlflow.log_artifact(&quot;\/tmp\/mapping.json&quot;, &quot;mapping&quot;)\n\ntorch.save(classifier.state_dict(), &quot;\/tmp\/model.pt&quot;)\nmlflow.log_artifact(&quot;\/tmp\/model.pt&quot;, &quot;model.pt&quot;)\n<\/code><\/pre>\n<p>This problem seems to correlate with GC problems:<\/p>\n<blockquote>\n<p>2021-04-22T07:58:58.025+0000: [GC (Allocation Failure) [PSYoungGen:\n28399104K-&gt;100290K(28499456K)] 28696488K-&gt;397698K(85935104K),\n0.0755720 secs] [Times: user=0.15 sys=0.06, real=0.08 secs]  2021-04-22T08:01:01.645+0000: [GC (System.gc()) [PSYoungGen:\n4522724K-&gt;54360K(28561920K)] 4820132K-&gt;351776K(85997568K), 0.0237712\nsecs] [Times: user=0.09 sys=0.01, real=0.02 secs]\n2021-04-22T08:01:01.669+0000: [Full GC (System.gc()) [PSYoungGen:\n54360K-&gt;0K(28561920K)] [ParOldGen: 297416K-&gt;123173K(57435648K)]\n351776K-&gt;123173K(85997568K), [Metaspace: 203356K-&gt;203325K(219136K)],\n0.3513905 secs] [Times: user=0.99 sys=0.00, real=0.36 secs]<\/p>\n<\/blockquote>\n<p>Am I doing something wrong? Should I track experiments + artifacts in another way? Running neither single-node nor cluster works, nor reducing the size of the training set.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2021-04-22 11:52:52.593 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-04-22 21:20:04.54 UTC",
        "Question_score":2,
        "Question_tags":"python|pytorch|azure-databricks|mlflow|pytorch-lightning",
        "Question_view_count":387,
        "Owner_creation_date":"2014-11-11 16:17:30.717 UTC",
        "Owner_last_access_date":"2022-09-24 20:31:18.173 UTC",
        "Owner_reputation":4811,
        "Owner_up_votes":376,
        "Owner_down_votes":73,
        "Owner_views":713,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Verona, VR, Italy",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67212760",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65789715,
        "Question_title":"MLFlow sklearn autologging prints too many info messages in colab",
        "Question_body":"<p>I am trying mlflow sklearn auto logging, in colab, mlflow prints a lot of info messages and at times it crashes the browser. Attaching the pic of info logs<a href=\"https:\/\/i.stack.imgur.com\/RqvNM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/RqvNM.png\" alt=\"mlflow info logs\" \/><\/a><\/p>\n<p>codes are in <a href=\"https:\/\/colab.research.google.com\/drive\/1wvHSgYk6boKW0AMPqIt-AByyFHSO26wm?usp=sharing\" rel=\"nofollow noreferrer\">this colab file<\/a><\/p>\n<p>Am not sure what am missing here, but the same code works fine without producing these info logs on my local computer.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-19 10:31:50.507 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":194,
        "Owner_creation_date":"2020-12-22 10:45:25.527 UTC",
        "Owner_last_access_date":"2022-07-10 06:14:47.843 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":"<p>This is a known issue with MLFlow package, in which a hotfix has been raised.<\/p>\n<p>See here: <a href=\"https:\/\/github.com\/mlflow\/mlflow\/pull\/3978\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/pull\/3978<\/a><\/p>\n<p><strong>Description of fault<\/strong><\/p>\n<p>In MLflow 1.13.0 and 1.13.1, the following Python event logging message is emitted when a patched ML training function begins execution within a preexisting MLflow run.<\/p>\n<p>Unfortunately, for patched ML training routines that make child calls to other patched ML training routines (e.g. sklearn random forests that call fit() on a collection of sklearn DecisionTree instances), this event log is printed to stdout every time a child is called.<\/p>\n<p>This can produce hundreds of redundant event logging calls that don't provide value to the user.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-01-19 10:55:13.91 UTC",
        "Answer_score":1.0,
        "Owner_location":"Dubai - United Arab Emirates",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65789715",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63133902,
        "Question_title":"How to send data to server for Prediction - MLflow",
        "Question_body":"<p>I am able to create ml model server using following command<\/p>\n<pre><code>mlflow models serve -m file:\/\/\/C:\/Users\/SawarkarFamily\/Desktop\/mlflow-master\/examples\/sklearn_elasticnet_wine\/mlruns\/0\/9aeb7ba16d7e4c20870b664e267524ea\/artifacts\/model -p 8000\n2020\/07\/28 17:10:59 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n2020\/07\/28 17:11:03 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d &amp; waitress-serve --host=127.0.0.1 --port=8000 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\nc:\\users\\sawarkarfamily\\anaconda3\\envs\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\lib\\site-packages\\waitress\\adjustments.py:441: DeprecationWarning: In future versions of Waitress clear_untrusted_proxy_headers will be set to True by default. You may opt-out by setting this value to False, or opt-in explicitly by setting this to True.\n  warnings.warn(\nServing on http:\/\/DESKTOP-AO59MJC:8000\n<\/code><\/pre>\n<p>In documentation it is given that send that for prediction using curl command as follows:<\/p>\n<pre><code>curl -X POST -H &quot;Content-Type:application\/json; format=pandas-split&quot; --data '{&quot;columns&quot;:[&quot;alcohol&quot;, &quot;chlorides&quot;, &quot;citric acid&quot;, &quot;density&quot;, &quot;fixed acidity&quot;, &quot;free sulfur dioxide&quot;, &quot;pH&quot;, &quot;residual sugar&quot;, &quot;sulphates&quot;, &quot;total sulfur dioxide&quot;, &quot;volatile acidity&quot;],&quot;data&quot;:[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http:\/\/127.0.0.1:1234\/invocations\n<\/code><\/pre>\n<p>I replaced port number with 8000, but getting error.<\/p>\n<pre><code>curl: (6) Could not resolve host: chlorides,\ncurl: (6) Could not resolve host: citric acid,\ncurl: (6) Could not resolve host: density,\ncurl: (6) Could not resolve host: fixed acidity,\ncurl: (6) Could not resolve host: free sulfur dioxide,\ncurl: (6) Could not resolve host: pH,\ncurl: (6) Could not resolve host: residual sugar,\ncurl: (6) Could not resolve host: sulphates,\ncurl: (6) Could not resolve host: total sulfur dioxide,\ncurl: (3) [globbing] unmatched close brace\/bracket in column 17\ncurl: (6) Could not resolve host: 0.029,\ncurl: (6) Could not resolve host: 0.48,\ncurl: (6) Could not resolve host: 0.98,\ncurl: (6) Could not resolve host: 6.2,\ncurl: (6) Could not resolve host: 29,\ncurl: (6) Could not resolve host: 3.33,\ncurl: (6) Could not resolve host: 1.2,\ncurl: (6) Could not resolve host: 0.39,\ncurl: (6) Could not resolve host: 75,\ncurl: (3) [globbing] unmatched close brace\/bracket in column 5\n{&quot;error_code&quot;: &quot;MALFORMED_REQUEST&quot;, &quot;message&quot;: &quot;Failed to parse input as a Pandas DataFrame. Ensure that the input is a valid JSON-formatted Pandas DataFrame with the `split` orient produced using the `pandas.DataFrame.to_json(..., orient='split')` method.&quot;, &quot;stack_trace&quot;: &quot;Traceback (most recent call last):\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\mlflow\\\\pyfunc\\\\scoring_server\\\\__init__.py\\&quot;, line 74, in parse_json_input\\n    return _dataframe_from_json(json_input, pandas_orient=orient, schema=schema)\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\mlflow\\\\utils\\\\proto_json_utils.py\\&quot;, line 106, in _dataframe_from_json\\n    return pd.read_json(path_or_str, orient=pandas_orient, dtype=False,\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\util\\\\_decorators.py\\&quot;, line 214, in wrapper\\n    return func(*args, **kwargs)\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 608, in read_json\\n    result = json_reader.read()\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 731, in read\\n    obj = self._get_object_parser(self.data)\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 753, in _get_object_parser\\n    obj = FrameParser(json, **kwargs).parse()\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 857, in parse\\n    self._parse_no_numpy()\\n  File \\&quot;c:\\\\users\\\\sawarkarfamily\\\\anaconda3\\\\envs\\\\mlflow-76d7aedf36021b9bb7f176264305cf2b7868ca8d\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\json\\\\_json.py\\&quot;, line 1094, in _parse_no_numpy\\n    for k, v in loads(json, precise_float=self.precise_float).items()\\nValueError: Expected object or value\\n&quot;}\n<\/code><\/pre>\n<p>Kindly someone help me with this.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-07-28 12:15:01.813 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-28 13:16:24.983 UTC",
        "Question_score":3,
        "Question_tags":"python|json|curl|mlflow|mlops",
        "Question_view_count":1362,
        "Owner_creation_date":"2020-07-28 12:10:36.26 UTC",
        "Owner_last_access_date":"2021-09-30 13:53:40.19 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63133902",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73562615,
        "Question_title":"MlflowException: API request (Caused by ResponseError('too many 503 error responses'))",
        "Question_body":"<p>I am using mlflow to register my model. I try to use 'Scenario 4' when artifacts load to S3 bucket from local.<\/p>\n<ol>\n<li><p>Add credentials of S3 bucket to .aws\/credentials<\/p>\n<\/li>\n<li><p>Set endpoint and mlflow URI:<\/p>\n<p>os.environ[&quot;MLFLOW_S3_ENDPOINT_URL&quot;]='https:\/\/storage.yandexcloud.net'\nos.environ[&quot;MLFLOW_TRACKING_URI&quot;]='http:\/\/:8000'<\/p>\n<\/li>\n<li><p>Log model to S3 via mlflow:<\/p>\n<p>import mlflow\nimport mlflow.sklearn\nmlflow.set_experiment(&quot;my&quot;)\n...\nmlflow.sklearn.log_model(model, artifact_path=&quot;models_mlflow&quot;)<\/p>\n<\/li>\n<\/ol>\n<p>But get error:<\/p>\n<pre><code>MlflowException: API request to http:\/\/&lt;IP&gt;:8000\/api\/2.0\/mlflow-artifacts\/artifacts\/6\/95972bcc493c4a8cbd8432fea4cc8bac\/artifacts\/models_mlflow\/model.pkl failed with exception HTTPConnectionPool(host='62.84.121.234', port=8000): Max retries exceeded with url: \/api\/2.0\/mlflow-artifacts\/artifacts\/6\/95972bcc493c4a8cbd8432fea4cc8bac\/artifacts\/models_mlflow\/model.pkl (Caused by ResponseError('too many 503 error responses'))\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-31 22:41:17.113 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|amazon-s3|mlflow|mlops|yandexcloud",
        "Question_view_count":38,
        "Owner_creation_date":"2014-04-07 09:58:41.17 UTC",
        "Owner_last_access_date":"2022-09-23 11:17:10.007 UTC",
        "Owner_reputation":75,
        "Owner_up_votes":105,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Moscow, Russia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73562615",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64312888,
        "Question_title":"Does MLflow support distributed XGBoost model?",
        "Question_body":"<p>I  use single-instance xgboost model to train, which works fine with mlflow to log all the model-related parameters by using <code>mlflow.xgboost.autolog()<\/code>, but when i change to distributed xgboost version changing from python package to JVM package by including the xgboost4j.jar and xgboost4j-spark.jar files, and also include mlflow module into it, (<code>mlflow.xgboost.autolog()<\/code>). The mlflow cannot show all the parameters on the page. They are empty.\n<img src=\"https:\/\/i.stack.imgur.com\/dt91a.png\" alt=\"screenshot\" \/><\/p>\n<p>So I looked at the source code in the mlflow.xgboost, in line 271, <code>def autolog(importance_types=[&quot;weight&quot;]):<\/code> says it imports the xgboost package, which i think is the single-instance xgboost model, I wonder if it is support the distributed version? Or is there any other methods to solve the problem?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-12 06:44:14.15 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-10-12 08:50:46.443 UTC",
        "Question_score":2,
        "Question_tags":"xgboost|mlflow",
        "Question_view_count":133,
        "Owner_creation_date":"2019-08-25 23:46:06.673 UTC",
        "Owner_last_access_date":"2020-11-12 10:03:15.497 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64312888",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59642900,
        "Question_title":"Unable to connect Mlflow server to my mlflow project image",
        "Question_body":"<p>My final purpose is to run experiment from  an Api.<\/p>\n\n<p>the experiment come from :\n<a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/tensorflow\/tf2\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/tensorflow\/tf2<\/a>\nbut export the file in my custom git where I clone it, in the image below -><\/p>\n\n<p>I have 2 images in my docker compose :\ntree project : <\/p>\n\n<pre><code>|_app\/\n| |_Dockerfile\n|\n|_mlflow\/\n| |_Dockerfile\n|\n|_docker-compose.yml\n\n<\/code><\/pre>\n\n<p>app\/Dockerfile<\/p>\n\n<pre><code>FROM continuumio\/anaconda3\n\nENV APP_HOME .\/\nWORKDIR ${APP_HOME}\nRUN conda config --append channels conda-forge\nRUN conda install --quiet --yes \\\n    'mlflow' \\\n    'psycopg2' \\\n    'tensorflow'\nRUN pip install pylint\nRUN pwd;ls \\\n&amp;&amp; git clone https:\/\/github.com\/MChrys\/QuickSign.git \nRUN pwd;ls \\\n    &amp;&amp; cd QuickSign \\\n    &amp;&amp; pwd;ls\n\nCOPY . .\n\n#RUN conda install jupyter \n#CMD jupyter notebook --ip=0.0.0.0 --port=8888 --allow-root --no-browser\nCMD cd QuickSign &amp;&amp; mlflow run .\n<\/code><\/pre>\n\n<p>mlflow\/Dockerfile<\/p>\n\n<pre><code>FROM python:3.7.0\n\nRUN pip install mlflow\n\nRUN mkdir \/mlflow\/\n\nCMD mlflow server \\\n    --backend-store-uri \/mlflow \\\n    --host 0.0.0.0\n<\/code><\/pre>\n\n<p>docker-compose.yml<\/p>\n\n<pre><code>version: '3'\nservices:\n  notebook:\n    build:\n      context: .\/app\n    ports:\n      - \"8888:8888\"\n    depends_on: \n      - mlflow\n    environment: \n      MLFLOW_TRACKING_URI: 'http:\/\/mlflow:5000'\n  mlflow:\n    build:\n      context: .\/mlflow\n    expose: \n      - \"5000\"\n    ports:\n      - \"5000:5000\"\n<\/code><\/pre>\n\n<p>when I <code>docker-compose up<\/code> the image I obtain  :<\/p>\n\n<pre><code>notebook_1_74059cdc20ce |     response = requests.request(**kwargs)\nnotebook_1_74059cdc20ce |   File \"\/opt\/conda\/lib\/python3.7\/site-packages\/requests\/api.py\", line 60, in request\nnotebook_1_74059cdc20ce |     return session.request(method=method, url=url, **kwargs)\nnotebook_1_74059cdc20ce |   File \"\/opt\/conda\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 533, in request\nnotebook_1_74059cdc20ce |     resp = self.send(prep, **send_kwargs)\nnotebook_1_74059cdc20ce |   File \"\/opt\/conda\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 646, in send\nnotebook_1_74059cdc20ce |     r = adapter.send(request, **kwargs)\nnotebook_1_74059cdc20ce |   File \"\/opt\/conda\/lib\/python3.7\/site-packages\/requests\/adapters.py\", line 516, in send\nnotebook_1_74059cdc20ce |     raise ConnectionError(e, request=request)\nnotebook_1_74059cdc20ce | requests.exceptions.ConnectionError: HTTPConnectionPool(host='mlflow', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/create (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x7fd5db4edc50&gt;: Failed to establish a new connection: [Errno 111] Connection refused'))\n\n<\/code><\/pre>\n\n<p>The problem look like that I run a project which is not found in the server images, as I run it in the app image, but I don't know how figure it out I have to trigger  the experiment from a futur flask app <\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-08 09:28:18.63 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-01-08 09:55:26.563 UTC",
        "Question_score":0,
        "Question_tags":"docker|docker-compose|mlflow",
        "Question_view_count":2937,
        "Owner_creation_date":"2016-04-02 19:35:23.203 UTC",
        "Owner_last_access_date":"2022-03-27 00:55:04.593 UTC",
        "Owner_reputation":56,
        "Owner_up_votes":4,
        "Owner_down_votes":0,
        "Owner_views":39,
        "Answer_body":"<p>The problem came from  docker for windows, I was unable to make working docker compose on it but there are no problem to build it when I run it on virtual machine with ubuntu.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-04-09 12:53:57.59 UTC",
        "Answer_score":0.0,
        "Owner_location":"Grenoble, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59642900",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72886409,
        "Question_title":"MLflow proxied artifact access: Unable to locate credentials",
        "Question_body":"<p>I am using MLflow to track my experiments. I am using an S3 bucket as an artifact store. For acessing it, I want to use <em>proxied artifact access<\/em>, as described in the <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-5\" rel=\"nofollow noreferrer\">docs<\/a>, however this does not work for me, since it locally looks for credentials (but the server should handle this).<\/p>\n<h2>Expected Behaviour<\/h2>\n<p>As described in the docs, I would expect that locally, I do not need to specify my AWS credentials, since the server handles this for me. From <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-5\" rel=\"nofollow noreferrer\">docs<\/a>:<\/p>\n<blockquote>\n<p>This eliminates the need to allow end users to have direct path access to a remote object store (e.g., s3, adls, gcs, hdfs) for artifact handling and eliminates the need for an end-user to provide access credentials to interact with an underlying object store.<\/p>\n<\/blockquote>\n<h2>Actual Behaviour \/ Error<\/h2>\n<p>Whenever I run an experiment on my machine, I am running into the following error:<\/p>\n<p><code>botocore.exceptions.NoCredentialsError: Unable to locate credentials<\/code><\/p>\n<p>So the error is local. However, this should not happen since the server should handle the auth instead of me needing to store my credentials locally. Also, I would expect that I would not even need library <code>boto3<\/code> locally.<\/p>\n<h2>Solutions Tried<\/h2>\n<p>I am aware that I need to create a new experiment, because existing experiments might still use a different artifact location which is proposed in <a href=\"https:\/\/stackoverflow.com\/a\/71417933\/10465165\">this SO answer<\/a> as well as in the note in the <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-5\" rel=\"nofollow noreferrer\">docs<\/a>. Creating a new experiment did not solve the error for me. Whenever I run the experiment, I get an explicit log in the console validating this:<\/p>\n<p><code>INFO mlflow.tracking.fluent: Experiment with name 'test' does not exist. Creating a new experiment.<\/code><\/p>\n<p>Related Questions (<a href=\"https:\/\/stackoverflow.com\/questions\/72206086\/cant-log-mlflow-artifacts-to-s3-with-docker-based-tracking-server\">#1<\/a> and <a href=\"https:\/\/stackoverflow.com\/questions\/72236258\/mlflow-unable-to-store-artifacts-to-s3\/72261826#comment128726676_72261826\">#2<\/a>) refer to a different scenario, which is also <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-4-mlflow-with-remote-tracking-server-backend-and-artifact-stores\" rel=\"nofollow noreferrer\">described in the docs<\/a><\/p>\n<h2>Server Config<\/h2>\n<p>The server runs on a kubernetes pod with the following config:<\/p>\n<pre><code>mlflow server \\\n    --host 0.0.0.0 \\\n    --port 5000 \\\n    --backend-store-uri postgresql:\/\/user:pw@endpoint \\\n    --artifacts-destination s3:\/\/my_bucket\/artifacts \\\n    --serve-artifacts \\\n    --default-artifact-root s3:\/\/my_bucket\/artifacts \\\n<\/code><\/pre>\n<p>I would expect my config to be correct, looking at doc <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#scenario-5\" rel=\"nofollow noreferrer\">page 1<\/a> and <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#using-the-tracking-server-for-proxied-artifact-access\" rel=\"nofollow noreferrer\">page 2<\/a><\/p>\n<p>I am able to see the mlflow UI if I forward the port to my local machine. I also see the experiment runs as failed, because of the error I sent above.<\/p>\n<h2>My Code<\/h2>\n<p>The relevant part of my code which fails is the logging of the model:<\/p>\n<pre><code>mlflow.set_tracking_uri(&quot;http:\/\/localhost:5000&quot;)\nmlflow.set_experiment(&quot;test2)\n\n...\n\n# this works\nmlflow.log_params(hyperparameters)\n                        \nmodel = self._train(model_name, hyperparameters, X_train, y_train)\ny_pred = model.predict(X_test)\nself._evaluate(y_test, y_pred)\n\n# this fails with the error from above\nmlflow.sklearn.log_model(model, &quot;artifacts&quot;)\n\n<\/code><\/pre>\n<h2>Question<\/h2>\n<p>I am probably overlooking something. Is there a need to locally indicate that I want to use proxied artified access? If yes, how do I do this? Is there something I have missed?<\/p>\n<h2>Full Traceback<\/h2>\n<pre><code>  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/models\/model.py&quot;, line 295, in log\n    mlflow.tracking.fluent.log_artifacts(local_path, artifact_path)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 726, in log_artifacts\n    MlflowClient().log_artifacts(run_id, local_dir, artifact_path)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/tracking\/client.py&quot;, line 1001, in log_artifacts\n    self._tracking_client.log_artifacts(run_id, local_dir, artifact_path)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py&quot;, line 346, in log_artifacts\n    self._get_artifact_repo(run_id).log_artifacts(local_dir, artifact_path)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/store\/artifact\/s3_artifact_repo.py&quot;, line 141, in log_artifacts\n    self._upload_file(\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/mlflow\/store\/artifact\/s3_artifact_repo.py&quot;, line 117, in _upload_file\n    s3_client.upload_file(Filename=local_file, Bucket=bucket, Key=key, ExtraArgs=extra_args)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/boto3\/s3\/inject.py&quot;, line 143, in upload_file\n    return transfer.upload_file(\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/boto3\/s3\/transfer.py&quot;, line 288, in upload_file\n    future.result()\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/futures.py&quot;, line 103, in result\n    return self._coordinator.result()\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/futures.py&quot;, line 266, in result\n    raise self._exception\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/tasks.py&quot;, line 139, in __call__\n    return self._execute_main(kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/tasks.py&quot;, line 162, in _execute_main\n    return_value = self._main(**kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/s3transfer\/upload.py&quot;, line 758, in _main\n    client.put_object(Bucket=bucket, Key=key, Body=body, **extra_args)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/client.py&quot;, line 508, in _api_call\n    return self._make_api_call(operation_name, kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/client.py&quot;, line 898, in _make_api_call\n    http, parsed_response = self._make_request(\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/client.py&quot;, line 921, in _make_request\n    return self._endpoint.make_request(operation_model, request_dict)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/endpoint.py&quot;, line 119, in make_request\n    return self._send_request(request_dict, operation_model)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/endpoint.py&quot;, line 198, in _send_request\n    request = self.create_request(request_dict, operation_model)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/endpoint.py&quot;, line 134, in create_request\n    self._event_emitter.emit(\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/hooks.py&quot;, line 412, in emit\n    return self._emitter.emit(aliased_event_name, **kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/hooks.py&quot;, line 256, in emit\n    return self._emit(event_name, kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/hooks.py&quot;, line 239, in _emit\n    response = handler(**kwargs)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/signers.py&quot;, line 103, in handler\n    return self.sign(operation_name, request)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/signers.py&quot;, line 187, in sign\n    auth.add_auth(request)\n  File \/dir\/venv\/lib\/python3.9\/site-packages\/botocore\/auth.py&quot;, line 407, in add_auth\n    raise NoCredentialsError()\nbotocore.exceptions.NoCredentialsError: Unable to locate credentials\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-06 15:40:30.593 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-06 15:52:51.947 UTC",
        "Question_score":0,
        "Question_tags":"amazon-web-services|machine-learning|amazon-s3|boto3|mlflow",
        "Question_view_count":237,
        "Owner_creation_date":"2018-10-06 09:06:11.613 UTC",
        "Owner_last_access_date":"2022-09-22 14:26:03.733 UTC",
        "Owner_reputation":647,
        "Owner_up_votes":971,
        "Owner_down_votes":39,
        "Owner_views":61,
        "Answer_body":"<p>The problem is that the server is running on wrong run parameters, the <code>--default-artifact-root<\/code> needs to either be removed or set to <code>mlflow-artifacts:\/<\/code>.<\/p>\n<p>From <code>mlflow server --help<\/code>:<\/p>\n<pre><code>  --default-artifact-root URI  Directory in which to store artifacts for any\n                               new experiments created. For tracking server\n                               backends that rely on SQL, this option is\n                               required in order to store artifacts. Note that\n                               this flag does not impact already-created\n                               experiments with any previous configuration of\n                               an MLflow server instance. By default, data\n                               will be logged to the mlflow-artifacts:\/ uri\n                               proxy if the --serve-artifacts option is\n                               enabled. Otherwise, the default location will\n                               be .\/mlruns.\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-07 09:40:14.37 UTC",
        "Answer_score":0.0,
        "Owner_location":"Berlin",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72886409",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68527422,
        "Question_title":"mlflow.pyfunc.spark_udf and vector struct type",
        "Question_body":"<p>My <em>PySpark<\/em> dataset contains categorical data.<\/p>\n<p>To train a model on this data, I followed this <a href=\"https:\/\/docs.databricks.com\/_static\/notebooks\/binary-classification.html\" rel=\"nofollow noreferrer\">example notebook<\/a>. Especially, see the <em>Preprocess Data<\/em> section for the encoding part.<\/p>\n<p>I now need to use this model somewhere else; hence, I followed <em>Databricks<\/em> recommendation to save and load this model.<\/p>\n<p>It's working fine with <em>Pandas<\/em> (cf. code below).<\/p>\n<pre><code>logged_model = 'runs:\/e905f5759d434a1391bbe1e54a2b\/best-model'\n\n# Load model as a PyFuncModel.\nloaded_model = mlflow.pyfunc.load_model(logged_model)\n\n# Predict on a Pandas DataFrame.\nimport pandas as pd\nloaded_model.predict(pd.DataFrame(data))\n<\/code><\/pre>\n<p>However the dataframe is to big to be converted to <em>Pandas<\/em>. Hence I need to make it work in <em>Spark<\/em>:<\/p>\n<pre><code>import mlflow\nlogged_model = 'runs:\/e905f5759d434a131bbe1e54a2b\/best-model'\n\n# Load model as a Spark UDF.\nloaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model)\n\n# Predict on a Spark DataFrame.\ndf.withColumn('predictions', loaded_model(*columns)).collect()\n<\/code><\/pre>\n<p>But this snippet is producing:<\/p>\n<pre><code>java.lang.UnsupportedOperationException: Unsupported data type: struct&amp;lt;type:tinyint,size:int,indices:array&amp;lt;int&amp;gt;,values:array&amp;lt;double&amp;gt;&amp;gt;\n<\/code><\/pre>\n<p>My feeling is that the udf doesn't accept this type of data as input.\nIs there a way to fix it ?\nAnother solution ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-07-26 09:23:08.767 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pyspark|databricks|mlflow",
        "Question_view_count":790,
        "Owner_creation_date":"2016-11-29 05:56:02.23 UTC",
        "Owner_last_access_date":"2022-09-24 11:32:25.87 UTC",
        "Owner_reputation":440,
        "Owner_up_votes":21,
        "Owner_down_votes":4,
        "Owner_views":56,
        "Answer_body":"<p>Have you tried using the <code>mlflow.spark.load_model<\/code>?<\/p>\n<p>I'm having a very similar issue over here, but but using the spark method. I tried using the <code>mlflow.spark.load_model('runs:\/run-id\/my-model')<\/code> method and I got this weird error:<\/p>\n<pre><code>FileNotFoundError: [Errno 2] No such file or directory: '\/dbfs\/tmp\/mlflow\/weird-id-folder'\n<\/code><\/pre>\n<p>Searching for the docs, I see the problem that we are facing (which seems to be different), seems to be a signature problem.<\/p>\n<p>According with other part of the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#model-signature\" rel=\"nofollow noreferrer\">docs<\/a> we have that the signature logged with the model will help to define what type of input the model has. The problem for me here is that my input is a Spark Sparse Vector -- which is not supported... Right now I'm trying to convert that into a column-based signature.<\/p>\n<p>Have you tried something like this?<\/p>\n<hr \/>\n<p>UPDATE:<\/p>\n<p>I would like to add that in my case adding the signature did solve the problem. All I did was ignore the vectors and consider only the input data and output data.<\/p>\n<p>I took a look into the notebook, but haven't seen any mlflow logs, anyway, I do suppose you are logging your experiment according to <a href=\"https:\/\/docs.databricks.com\/applications\/mlflow\/tracking.html#log-runs-to-a-notebook-or-workspace-experiment\" rel=\"nofollow noreferrer\">this<\/a> and using the <code>mlflow.spark<\/code> flavor.<\/p>\n<p>If so, consider using all your data transformation and model fit in the same pipeline, using <code>from pyspark.ml import Pipeline<\/code>. Before logging the model, consider going under signature and registering the model schema.<\/p>\n<pre><code>import mlflow.spark\nfrom mlflow.models.signature import infer_signature\n\nwith mlflow.start_run():\n    [...]\n    # executing train &amp; test pipelines:\n    model = pipeline.fit(train_features) # training model\n    predictions = model.transform(test_features) # testing model\n    train_signature = train_features.select('input_data') # ignores all other features created on the pipeline\n    prediction_signature = predictions.select('input_data', 'prediction') # ignores all other features created on the training pipeline \n    signature = infer_signature(train_signature, prediction_signature) # register model schema\n    mlflow.spark.log_model(model, 'transactions-classification', signature=signature) # logging model to mlflow\n    [...]\n<\/code><\/pre>\n<p>After logging the model to the experiment, in a different notebook, you can use the load_model function as:<\/p>\n<pre><code># importing model\nimport mlflow.spark\nmodel_path = 'runs:\/run-id'\nmodel = mlflow.spark.load_model(model_path)\n<\/code><\/pre>\n<p>And it will work! :D<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-08-19 13:07:40.77 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-08-31 22:03:50.98 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68527422",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67650010,
        "Question_title":"Different training results on TF 2.4.1\/2.2.0 and 2.0.0 with the same script",
        "Question_body":"<p>How are you? Hope y'all good.<\/p>\n<p>I have a very specific scenario and it would be awesome to have your input. I'm working on a project in which I've developed a training script using TF 2.4.1. Just to give you context, I used MobileNetV2 as the base model to feature extraction and just a Dense layer with one neuron, and, with time, it got necessary to have different base models so as to perform a benchmark, so I started using different base models, such as InceptionV3 and VGG16, defining it as a command option while running my script. However, so as to the others in my research team to run my script, I had to use TF 2.0.0 due to a software limitation on the laboratory machine (CUDA 10 instead of 11), and that's when it started getting weird.<\/p>\n<p>You can find the script that I've written at the end of the questions, I changed nothing on it and ran it in the same machine (Windows 10, GTX 1060 6GB, i7 10700K), pointing some environment variables to the correct CUDA version (10.1 or 11). So, okay, what's the problem, right? It occurs that the validation loss does not decrease while running the script using TensorFlow 2.0.0. I tried to check the documentation, if there were any breaking changes or something like this, after checking if the data and the seeds were the same. However, I wasn't able to find anything that helped me understand why the validation loss changed so much, the performance was degraded. For instance, running the same script, initializing the seed with the same value, using the two different versions, I got the following results:<\/p>\n<ul>\n<li>TF 2.0.0<\/li>\n<\/ul>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>name<\/th>\n<th>val_accuracy<\/th>\n<th>val_loss<\/th>\n<th>val_precision<\/th>\n<th>val_recall<\/th>\n<th>test_accuracy<\/th>\n<th>test_loss<\/th>\n<th>test_precision<\/th>\n<th>test_recall<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>fold_5<\/td>\n<td>80.2899%<\/td>\n<td>0.442051<\/td>\n<td>85.1852%<\/td>\n<td>73.3333%<\/td>\n<td>81.2022%<\/td>\n<td>0.456165<\/td>\n<td>93.0514%<\/td>\n<td>67.3961%<\/td>\n<\/tr>\n<tr>\n<td>fold_4<\/td>\n<td>77.3913%<\/td>\n<td>0.507347<\/td>\n<td>85.6604%<\/td>\n<td>65.7971%<\/td>\n<td>83.4973%<\/td>\n<td>0.412218<\/td>\n<td>95.0000%<\/td>\n<td>70.6783%<\/td>\n<\/tr>\n<tr>\n<td>fold_3<\/td>\n<td>75.9420%<\/td>\n<td>0.517585<\/td>\n<td>78.7781%<\/td>\n<td>71.0145%<\/td>\n<td>76.3934%<\/td>\n<td>0.515756<\/td>\n<td>81.6273%<\/td>\n<td>68.0525%<\/td>\n<\/tr>\n<tr>\n<td>fold_2<\/td>\n<td>74.8191%<\/td>\n<td>0.595039<\/td>\n<td>95.2381%<\/td>\n<td>52.1739%<\/td>\n<td>74.7541%<\/td>\n<td>0.521118<\/td>\n<td>95.9350%<\/td>\n<td>51.6411%<\/td>\n<\/tr>\n<tr>\n<td>fold_1<\/td>\n<td>73.0825%<\/td>\n<td>0.652833<\/td>\n<td>92.5532%<\/td>\n<td>50.2890%<\/td>\n<td>72.5683%<\/td>\n<td>0.590006<\/td>\n<td>96.3964%<\/td>\n<td>46.8271%<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<ul>\n<li>TF 2.4.1<\/li>\n<\/ul>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>name<\/th>\n<th>val_accuracy<\/th>\n<th>val_loss<\/th>\n<th>val_precision<\/th>\n<th>val_recall<\/th>\n<th>test_accuracy<\/th>\n<th>test_loss<\/th>\n<th>test_precision<\/th>\n<th>test_recall<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td>fold_5<\/td>\n<td>96.6667%<\/td>\n<td>0.096043<\/td>\n<td>96.0000%<\/td>\n<td>97.3913%<\/td>\n<td>95.5191%<\/td>\n<td>0.156118<\/td>\n<td>92.2764%<\/td>\n<td>99.3435%<\/td>\n<\/tr>\n<tr>\n<td>fold_4<\/td>\n<td>94.4928%<\/td>\n<td>0.134758<\/td>\n<td>92.5208%<\/td>\n<td>96.8116%<\/td>\n<td>96.3934%<\/td>\n<td>0.145110<\/td>\n<td>93.6214%<\/td>\n<td>99.5624%<\/td>\n<\/tr>\n<tr>\n<td>fold_3<\/td>\n<td>96.0870%<\/td>\n<td>0.094560<\/td>\n<td>96.7647%<\/td>\n<td>95.3623%<\/td>\n<td>96.3934%<\/td>\n<td>0.136126<\/td>\n<td>94.1667%<\/td>\n<td>98.9059%<\/td>\n<\/tr>\n<tr>\n<td>fold_2<\/td>\n<td>97.3951%<\/td>\n<td>0.101784<\/td>\n<td>97.6676%<\/td>\n<td>97.1014%<\/td>\n<td>96.6120%<\/td>\n<td>0.131193<\/td>\n<td>94.5607%<\/td>\n<td>98.9059%<\/td>\n<\/tr>\n<tr>\n<td>fold_1<\/td>\n<td>96.3821%<\/td>\n<td>0.095308<\/td>\n<td>97.3451%<\/td>\n<td>95.3757%<\/td>\n<td>96.5027%<\/td>\n<td>0.118284<\/td>\n<td>95.1168%<\/td>\n<td>98.0306%<\/td>\n<\/tr>\n<\/tbody>\n<\/table>\n<\/div>\n<p>It's possible to notice in the first plot that it seems that nothing is happening in the validation data. It seems that the model kind of learns something, because the training loss is decreasing, but &quot;nothing&quot; is happening with the validation loss. I honestly tried to search for a lot of things in order to explain this behavior, since it's exactly the same code but wasn't able to find anything useful. I do understand that, depending on the implementation, fluctuations might happen, but it seems to me that the scenario that I presented before is really specific.<\/p>\n<p>Unfortunately, this is a no-go for my project because I do need to run the experiments in the other machine, which has CUDA 10, but I develop the whole application in the computer that I have access to, which is my personal one.<\/p>\n<p>Given this scenario, can you, please, help me trying to understand what is going on? Am I missing any other change that I have to do in the script? Is this type of behavior expected? I would appreciate any help! It might be worth saying that for me to test it, I installed both CUDAs (10.1 and 11) on my computer and created two different <em>conda<\/em> environments so I can switch between them easily. It's also important to say that I've tried to use TF 2.2.0 and it works as expected, just like 2.4.1.<\/p>\n<p>I'm sorry if I'm not in the right channel to ask this, and if it's not, please redirect me to the correct one. Thank you so much!<\/p>\n<p>Below you can find my training script:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from pathlib import Path\n\nimport mlflow.tensorflow\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom classes.Evaluator import Evaluator\nfrom utils.args import get_args_train\nfrom utils.callbacks import TrainingAndValidationMetrics\nfrom utils.inputs import get_inputs_paths_and_targets\nfrom utils.model import build_model, get_image_size, get_preprocess_function\nfrom utils.seed import set_seeds\n\n# Setting the random_state to get reproducible results\nseed = set_seeds()\n\n# Constants\nROOT_FOLDER = Path(__file__).resolve().parent.parent\nFOLDS_NUMBER = 5\nEPOCHS_NUMBER = 100\nEPOCHS_WAITING_FOR_IMPROVEMENT = 5\n\n# Gets which input we're going to use\nargs = get_args_train()\nIMAGE_FOLDER_PATH = ROOT_FOLDER \/ f&quot;crop_result_prop_{args.proportion}&quot;\n\n# Instantiates GroupKFold class to split into train and test\ngroup_k_fold = GroupKFold(n_splits=FOLDS_NUMBER)\n\n# Configuration dictionary that is going to be used to compile the model\nconfig = {\n    &quot;optimizer&quot;: &quot;adam&quot;,\n    &quot;loss&quot;: &quot;binary_crossentropy&quot;,\n    &quot;metrics&quot;: [&quot;accuracy&quot;, Precision(), Recall()],\n}\n\n# Gets the dataframe that are going to be used in the flow_from_dataframe\n# method from the ImageDataGenerator class\ninput_df = get_inputs_paths_and_targets(args.proportion)\n\n# Using GroupKFold only to guarantee that a group (in this case, the slide)\n# will contain data only in the train or the test group\nfor train_idx, test_idx in group_k_fold.split(\n    input_df.input, input_df.target, input_df.slide\n):\n    train_data = input_df.iloc[train_idx]\n    test_data = input_df.iloc[test_idx]\n\n    # Break here is being used to get only the first fold\n    break\n\nprint(&quot;### Testing data distribution ###&quot;)\nprint(f&quot;{test_data.groupby('slide').count()}&quot;)\n\ngenerator_kwargs = {\n    &quot;directory&quot;: IMAGE_FOLDER_PATH,\n    &quot;x_col&quot;: &quot;input&quot;,\n    &quot;y_col&quot;: &quot;target&quot;,\n    &quot;seed&quot;: seed,\n    &quot;target_size&quot;: get_image_size(args.model.lower()),\n    &quot;classes&quot;: [&quot;0&quot;, &quot;1&quot;],\n}\n\nidg = ImageDataGenerator(\n    fill_mode=&quot;nearest&quot;,\n    preprocessing_function=get_preprocess_function(args.model.lower()),\n)\n# Generator that will be used to evaluate the model\ntest_data_generator = idg.flow_from_dataframe(\n    test_data, class_mode=&quot;binary&quot;, shuffle=False, **generator_kwargs\n)\n\n# Callbacks\nearly_stopping = EarlyStopping(\n    monitor=&quot;val_loss&quot;, patience=EPOCHS_WAITING_FOR_IMPROVEMENT\n)\ncallbacks = [early_stopping, TrainingAndValidationMetrics()]\n\n# Starts run on mlflow to register metrics (experiment)\nmlflow.start_run(\n    run_name=f&quot;{args.model.lower()}&quot;,\n    tags={&quot;data_proportion&quot;: args.proportion, &quot;environment&quot;: &quot;pads&quot;},\n)\n\ncurrent_fold = 1\nkfold = StratifiedKFold(n_splits=FOLDS_NUMBER, shuffle=True, random_state=seed)\nfor train_idx, val_idx in kfold.split(train_data.input, train_data.target):\n    model = build_model(args.model.lower(), [Dense(1, activation=&quot;sigmoid&quot;)], config)\n\n    # Starts run on mlflow to register metrics (runs)\n    with mlflow.start_run(run_name=f&quot;fold_{current_fold}&quot;, nested=True):\n        fitting_data = train_data.iloc[train_idx]\n        val_data = train_data.iloc[val_idx]\n\n        mlflow.log_text(\n            f&quot;Training data: \\n{fitting_data.groupby('target').count()} \\n&quot;\n            f&quot;Validation data: \\n{val_data.groupby('target').count()} \\n&quot;\n            f&quot;Data proportion: {args.proportion} \\n&quot;,\n            artifact_file=&quot;data_description.txt&quot;,\n        )\n\n        train_data_generator = idg.flow_from_dataframe(\n            fitting_data, class_mode=&quot;binary&quot;, **generator_kwargs\n        )\n        valid_data_generator = idg.flow_from_dataframe(\n            val_data, class_mode=&quot;binary&quot;, **generator_kwargs\n        )\n        training = model.fit(\n            train_data_generator,\n            epochs=EPOCHS_NUMBER,\n            validation_data=valid_data_generator,\n            callbacks=callbacks,\n        )\n\n        # Logging model\n        mlflow.keras.log_model(keras_model=model, artifact_path=&quot;model&quot;)\n\n        # Evaluating and logging\n        evaluator = Evaluator(model, training, test_data_generator, test_data.target)\n        test_metrics = evaluator.evaluate_model()\n        mlflow.log_metrics(test_metrics)\n\n        # Saving files to mlflow\n        mlflow.log_text(\n            evaluator.generate_classification_report(),\n            artifact_file=&quot;classification_report.txt&quot;,\n        )\n        mlflow.log_figure(\n            evaluator.generate_training_history_image(),\n            artifact_file=&quot;accuracy_loss_epochs.png&quot;,\n        )\n        mlflow.log_figure(evaluator.generate_roc_figure(), artifact_file=&quot;roc.png&quot;)\n\n    current_fold += 1\nmlflow.end_run()\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-05-22 13:24:48.047 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-05-24 21:11:31.873 UTC",
        "Question_score":1,
        "Question_tags":"python|tensorflow|keras|gpu|mlflow",
        "Question_view_count":58,
        "Owner_creation_date":"2021-05-21 17:12:26.16 UTC",
        "Owner_last_access_date":"2022-09-21 19:05:12.147 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Rio de Janeiro",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67650010",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68356746,
        "Question_title":"Changing subdirectory of MLflow artifact store",
        "Question_body":"<p>Is there anything in the Python API that lets you alter the artifact subdirectories? For example, I have a .json file stored here:<\/p>\n<p><code>s3:\/\/mlflow\/3\/1353808bf7324824b7343658882b1e45\/artifacts\/feature_importance_split.json<\/code><\/p>\n<p>MlFlow creates a <code>3\/<\/code> key in s3. Is there a way to change to modify this key to something else (a date or the name of the experiment)?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-07-13 05:02:26.053 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":1493,
        "Owner_creation_date":"2014-03-06 03:54:30.85 UTC",
        "Owner_last_access_date":"2022-09-20 20:56:03.467 UTC",
        "Owner_reputation":913,
        "Owner_up_votes":156,
        "Owner_down_votes":5,
        "Owner_views":88,
        "Answer_body":"<p>As I commented above, yes, <code>mlflow.create_experiment()<\/code> does allow you set the artifact location using the <code>artifact_location<\/code> parameter.<\/p>\n<p>However, sort of related, the problem with setting the <code>artifact_location<\/code> using the <code>create_experiment()<\/code> function is that once you create a experiment, MLflow will throw an error if you run the <code>create_experiment()<\/code> function again.<\/p>\n<p>I didn't see this in the docs but it's confirmed that if an experiment already exists in the backend-store, MlFlow will not allow you to run the same <code>create_experiment()<\/code> function again. And as of this post, MLfLow does not have <code>check_if_exists<\/code> flag or a <code>create_experiments_if_not_exists()<\/code> function.<\/p>\n<p>To make things more frustrating, you cannot set the <code>artifcact_location<\/code> in the <code>set_experiment()<\/code> function either.<\/p>\n<p>So here is a pretty easy work around, it also avoids the &quot;ERROR mlflow.utils.rest_utils...&quot; stdout logging as well.\n:<\/p>\n<pre><code>import os\nfrom random import random, randint\n\nfrom mlflow import mlflow,log_metric, log_param, log_artifacts\nfrom mlflow.exceptions import MlflowException\n\ntry:\n    experiment = mlflow.get_experiment_by_name('oof')\n    experiment_id = experiment.experiment_id\nexcept AttributeError:\n    experiment_id = mlflow.create_experiment('oof', artifact_location='s3:\/\/mlflow-minio\/sample\/')\n\nwith mlflow.start_run(experiment_id=experiment_id) as run:\n    mlflow.set_tracking_uri('http:\/\/localhost:5000')\n    print(&quot;Running mlflow_tracking.py&quot;)\n\n    log_param(&quot;param1&quot;, randint(0, 100))\n    \n    log_metric(&quot;foo&quot;, random())\n    log_metric(&quot;foo&quot;, random() + 1)\n    log_metric(&quot;foo&quot;, random() + 2)\n\n    if not os.path.exists(&quot;outputs&quot;):\n        os.makedirs(&quot;outputs&quot;)\n    with open(&quot;outputs\/test.txt&quot;, &quot;w&quot;) as f:\n        f.write(&quot;hello world!&quot;)\n\n    log_artifacts(&quot;outputs&quot;)\n<\/code><\/pre>\n<p>If it is the user's first time creating the experiment, the code will run into an AttributeError since <code>experiment_id<\/code> does not exist and the <code>except<\/code> code block gets executed creating the experiment.<\/p>\n<p>If it is the second, third, etc the code is run, it will only execute the code under the <code>try<\/code> statement since the experiment now exists. Mlflow will now create a 'sample' key in your s3 bucket. Not fully tested but it works for me at least.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-07-13 22:05:27.413 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2021-07-14 04:26:34.42 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68356746",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61225156,
        "Question_title":"sagemaker endpoint invocation randomly throws error",
        "Question_body":"<p>Env:<\/p>\n\n<ul>\n<li>XGBoost model trained on static data (excel).<\/li>\n<li>Model Saved and deployed to Sagemaker with MLFlow.<\/li>\n<li>Sagemaker Model and Sagemaker Endpoint are running.<\/li>\n<\/ul>\n\n<p>Invocation:\n - I invoke the model with new data via REST Request (POSTMAN) and via boto3.sagemaker<\/p>\n\n<pre><code>client.invoke_endpoint(\n    EndpointName=\"xxxxxxx\",\n    Body=data,\n    ContentType=\"application\/json\",\n    Accept=\"string\",\n)\n<\/code><\/pre>\n\n<p>Problem:\nIt seems that Sagemaker randomly (~50% of the time) fails with following Exception:<\/p>\n\n<pre><code>{\n\"ErrorCode\": \"CLIENT_ERROR_FROM_MODEL\",\n\"LogStreamArn\": \"arn:aws:logs:eu-central-1:xxxxxxxxxx:log-group:\/aws\/sagemaker\/Endpoints\/xxxxxxxx\",\n\"Message\": \"Received client error (400) from mfs-xxxxxxxxx-model-dztwabjotscyoc-zx7lzyfg with message \\\"{\\\"error_code\\\": \\\"BAD_REQUEST\\\", \\\"message\\\": \\\"Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\\\", \\\"stack_trace\\\": \\\"Traceback (most recent call last):\\\\n  File \\\\\\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/scoring_server\/__init__.py\\\\\\\", line 196, in transformation\\\\n    raw_predictions = model.predict(data)\\\\n  File \\\\\\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/xgboost.py\\\\\\\", line 198, in predict\\\\n    return self.xgb_model.predict(xgb.DMatrix(dataframe))\\\\n  File \\\\\\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/xgboost\/core.py\\\\\\\", line 1443, in predict\\\\n    self._validate_features(data)\\\\n  File \\\\\\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/xgboost\/core.py\\\\\\\", line 1862, in _validate_features\\\\n    data.feature_names))\\\\nValueError: feature_names mismatch: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81'] ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85']\\\\ntraining data did not have the following fields: 83, 85, 84, 82\\\\n\\\"}\\\". See https:\/\/eu-central-1.console.aws.amazon.com\/cloudwatch\/home?region=eu-central-1#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/xxxxxxxxx in account xxxxxxxfor more information.\",\n\"OriginalMessage\": \"{\\\"error_code\\\": \\\"BAD_REQUEST\\\", \\\"message\\\": \\\"Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\\\", \\\"stack_trace\\\": \\\"Traceback (most recent call last):\\\\n  File \\\\\\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/pyfunc\/scoring_server\/__init__.py\\\\\\\", line 196, in transformation\\\\n    raw_predictions = model.predict(data)\\\\n  File \\\\\\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/mlflow\/xgboost.py\\\\\\\", line 198, in predict\\\\n    return self.xgb_model.predict(xgb.DMatrix(dataframe))\\\\n  File \\\\\\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/xgboost\/core.py\\\\\\\", line 1443, in predict\\\\n    self._validate_features(data)\\\\n  File \\\\\\\"\/miniconda\/envs\/custom_env\/lib\/python3.6\/site-packages\/xgboost\/core.py\\\\\\\", line 1862, in _validate_features\\\\n    data.feature_names))\\\\nValueError: feature_names mismatch: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81'] ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85']\\\\ntraining data did not have the following fields: 83, 85, 84, 82\\\\n\\\"}\",\n\"OriginalStatusCode\": 400\n<\/code><\/pre>\n\n<p>}<\/p>\n\n<p>After this Exception, i hit again \"Send Request\" in Postman (with the exact same Body Data) and get a successful response:<\/p>\n\n<pre><code>[\n0.9989840388298035\n]\n<\/code><\/pre>\n\n<p>The problem is exactly the same (randomly) when using boto3.sagemaker either in AWS Lambda or locally when testing.<\/p>\n\n<p><strong>UPDATE 1:<\/strong>\nWhen i load the exported function with mlflow.xgboost.load_model() and run the prediction, it works everytime. Here is the code:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    import mlflow\n    from mlflow import xgboost\n    from xgboost import DMatrix\n    import numpy as np\n    import pandas as pd\n    base_path = \"src\/models\/\"\n\n\n    model_path_name_a = f\"{base_path}\/model_a\"\n    model_path_name_b = f\"{base_path}\/model_b\"\n    # xgboost.log_model(xgb_model_a, artifact_path='https:\/\/mlflow-server-tracking.s3.eu-central-1.amazonaws.com')\n    xgb_model_a = xgboost.load_model(model_path_name_a)\n    xgb_model_b = xgboost.load_model(model_path_name_b)\n\n    X_test = DMatrix(\n        np.array(\n            [\n                [7.60000e+01, 2.57000e+02, 9.25200e+03, 2.00400e+03, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n                 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00]\n            ]\n        )\n    )\n\n\n    ############# Prediction Model A ################\n    y_predA = xgb_model_a.predict(X_test)\n    print(f\"y_predA: {y_predA}\")\n\n    ############# Prediction Model B ################\n    y_predB = xgb_model_b.predict(X_test)\n    print(f\"y_predA: {y_predB}\")\n<\/code><\/pre>\n\n<p>Does that mean that the problem is with Sagemaker Inference\/Endpoint Service?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_creation_date":"2020-04-15 09:13:53.927 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-04-15 11:20:45.103 UTC",
        "Question_score":0,
        "Question_tags":"python|amazon-web-services|xgboost|amazon-sagemaker|mlflow",
        "Question_view_count":558,
        "Owner_creation_date":"2017-02-19 13:12:04.9 UTC",
        "Owner_last_access_date":"2022-08-26 11:25:49.307 UTC",
        "Owner_reputation":177,
        "Owner_up_votes":227,
        "Owner_down_votes":5,
        "Owner_views":82,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Nuremberg, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61225156",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63255631,
        "Question_title":"MLflow: INVALID_PARAMETER_VALUE: Unsupported URI '.\/mlruns' for model registry store",
        "Question_body":"<p>I got this error when I was trying to have a model registered in the model registry. Could someone help me?<\/p>\n<pre><code>RestException: INVALID_PARAMETER_VALUE: Unsupported URI '.\/mlruns' for model registry store. \nSupported schemes are: ['postgresql', 'mysql', 'sqlite', 'mssql']. \nSee https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to setup a compatible server.\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-04 21:54:55.187 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2020-08-30 19:18:05.667 UTC",
        "Question_score":10,
        "Question_tags":"python|mlflow",
        "Question_view_count":12594,
        "Owner_creation_date":"2014-12-26 18:42:31.727 UTC",
        "Owner_last_access_date":"2022-02-07 21:07:16.15 UTC",
        "Owner_reputation":125,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<p>Mlflow required DB as datastore for Model Registry\nSo you have to run tracking server with DB as backend-store and log model to this tracking server.\nThe easiest way to use DB is to use SQLite.<\/p>\n<pre><code>mlflow server \\\n    --backend-store-uri sqlite:\/\/\/mlflow.db \\\n    --default-artifact-root .\/artifacts \\\n    --host 0.0.0.0\n<\/code><\/pre>\n<p>And set MLFLOW_TRACKING_URI environment variable to <em>http:\/\/localhost:5000<\/em> or<\/p>\n<pre><code>mlflow.set_tracking_uri(&quot;http:\/\/localhost:5000&quot;)\n<\/code><\/pre>\n<p>After got to http:\/\/localhost:5000 and you can register a logged model from UI or from the code.<\/p>",
        "Answer_comment_count":5.0,
        "Answer_creation_date":"2020-08-05 11:19:29.48 UTC",
        "Answer_score":27.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63255631",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58076263,
        "Question_title":"mlflow tracking server does not start after specifying backend-store-uri",
        "Question_body":"<p>I run mlflow as following:<\/p>\n\n<p><code>Dockerfile<\/code> contains the the following CMD command<\/p>\n\n<pre><code>CMD mlflow server \\\n    --host 0.0.0.0 \\\n    --backend-store-uri \"${BACKEND_STORE_URI}\" \\\n    --default-artifact-root \"${DEFAULT_ARTIFACT_ROOT}\"\n<\/code><\/pre>\n\n<p>after <code>docker run --rm --name mlflow -p 5000:5000 -e BACKEND_STORE_URI=mssql+pymssql:\/\/user:pass@mybackendstoreuri\/mlflow mlflow<\/code><\/p>\n\n<p>it shows <\/p>\n\n<pre><code>INFO  [alembic.runtime.migration] Context impl MSSQLImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Context impl MSSQLImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\n<\/code><\/pre>\n\n<p>but then, the container exits without starting the server. <\/p>\n\n<p>Without specifying <code>backend store uri<\/code>, I can see the logs related to binding to host, and the container does not exist<\/p>\n\n<p>How to run mlflow tracking server and use backend store uri ?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-24 08:38:35.91 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-09-24 08:56:06.81 UTC",
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":3168,
        "Owner_creation_date":"2014-08-18 14:07:01.673 UTC",
        "Owner_last_access_date":"2022-09-15 04:40:38.707 UTC",
        "Owner_reputation":2521,
        "Owner_up_votes":447,
        "Owner_down_votes":13,
        "Owner_views":197,
        "Answer_body":"<p>The root cause is <\/p>\n\n<pre><code>MLflow UI and client code expects a default experiment with ID 0.\nThis method uses SQL insert statement to create the default experiment as a hack, since\nexperiment table uses 'experiment_id' column is a PK and is also set to auto increment.\nMySQL and other implementation do not allow value '0' for such cases.\n<\/code><\/pre>\n\n<p>ref: <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.2.0\/mlflow\/store\/sqlalchemy_store.py#L171\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.2.0\/mlflow\/store\/sqlalchemy_store.py#L171<\/a> <\/p>\n\n<p>No error is raised during migration, so no error shows up, and alembic version is the newest when fail silently. \nref:<a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.2.0\/mlflow\/store\/db_migrations\/env.py#L71\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.2.0\/mlflow\/store\/db_migrations\/env.py#L71<\/a><\/p>\n\n<p>If using the same idea as the MySQL test(<a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.2.0\/mlflow\/store\/sqlalchemy_store.py#L171\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/v1.2.0\/mlflow\/store\/sqlalchemy_store.py#L171<\/a>), the exception is raised - <code>Cannot insert explicit value for identity column in table 'experiment' when IDENTITY_INSERT is set to OFF.<\/code><\/p>\n\n<p>Test snippet:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>class TestSqlAlchemyStoreMssqlDb(unittest.TestCase):\n    \"\"\"\n    Run tests against a MSSQL database\n    \"\"\"\n    def setUp(self):\n        db_username = \"test\"\n        db_password = \"test\"\n        host = \"test\"\n        db_name = \"TEST_DB\"\n\n        db_server_url = \"mssql+pymssql:\/\/%s:%s@%s\" % (db_username, db_password, host)\n        self._engine = sqlalchemy.create_engine(db_server_url)\n\n        self._db_url = \"%s\/%s\" % (db_server_url, db_name)\n        print(\"Connect to %s\" % self._db_url)\n\n    def test_store(self):\n        self.store = SqlAlchemyStore(db_uri=self._db_url, default_artifact_root=ARTIFACT_URI)\n<\/code><\/pre>\n\n<p>Using postgres server completes the migration as the log shows.<\/p>\n\n<pre><code>mlflow_1    | 2019\/09\/24 09:03:55 INFO mlflow.store.sqlalchemy_store: Creating initial MLflow database tables...\nmlflow_1    | 2019\/09\/24 09:03:55 INFO mlflow.store.db.utils: Updating database tables at postgresql:\/\/postgres:postgres@postgres:5432\/postgres\nmlflow_1    | INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nmlflow_1    | INFO  [alembic.runtime.migration] Will assume transactional DDL.\nmlflow_1    | INFO  [alembic.runtime.migration] Running upgrade  -&gt; 451aebb31d03, add metric step\nmlflow_1    | INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -&gt; 90e64c465722, migrate user column to tags\nmlflow_1    | INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -&gt; 181f10493468, allow nulls for metric values\nmlflow_1    | INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -&gt; df50e92ffc5e, Add Experiment Tags Table\nmlflow_1    | INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -&gt; 7ac759974ad8, Update run tags with larger limit\nmlflow_1    | INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nmlflow_1    | INFO  [alembic.runtime.migration] Will assume transactional DDL.\nmlflow_1    | [2019-09-24 09:03:55 +0000] [15] [INFO] Starting gunicorn 19.9.0\nmlflow_1    | [2019-09-24 09:03:55 +0000] [15] [INFO] Listening at: http:\/\/0.0.0.0:5000 (15)\nmlflow_1    | [2019-09-24 09:03:55 +0000] [15] [INFO] Using worker: sync\nmlflow_1    | [2019-09-24 09:03:55 +0000] [18] [INFO] Booting worker with pid: 18\nmlflow_1    | [2019-09-24 09:03:56 +0000] [22] [INFO] Booting worker with pid: 22\nmlflow_1    | [2019-09-24 09:03:56 +0000] [26] [INFO] Booting worker with pid: 26\nmlflow_1    | [2019-09-24 09:03:56 +0000] [27] [INFO] Booting worker with pid: 27\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-09-24 09:14:17.01 UTC",
        "Answer_score":0.0,
        "Owner_location":"Berlin, Germany",
        "Answer_last_edit_date":"2019-09-24 15:26:41.717 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58076263",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70544873,
        "Question_title":"mlflow serving r models failed if use LDA instead of linear regression",
        "Question_body":"<p>I have a mlflow question regarding to serve R models, below is my code to train and serialize the R model.<\/p>\n<pre><code>library(mlflow)\nlibrary(caret)\nlibrary(carrier)\n\nset.seed(101)\nsample &lt;- createDataPartition(iris$Species, p=0.80, list=FALSE)\niris_train &lt;- iris[sample,]\niris_test &lt;- iris[-sample,]\n\n\nwith(mlflow_start_run()  , {\n  control &lt;- trainControl(method='cv', number=10)\n  metric &lt;- 'Accuracy'\n\n  # Linear Discriminant Analysis (LDA)\n  model &lt;- train(Species~., data=iris_train, method='lda', trControl=control, metric=metric,\n                preProcess=c(&quot;center&quot;, &quot;scale&quot;))\n  fn &lt;- crate(~ caret::predict.train(model, .x), model = model)\n  # fn &lt;- crate(~ stats::predict(model, .x), model = model)\n  iris_prediction &lt;- predict(model, iris_test)\n\n  mlflow_log_model(model = fn, artifact_path=&quot;model&quot;)\n})\n\n<\/code><\/pre>\n<p>However, when I serve it with the API request,<\/p>\n<pre><code>curl --location --request POST 'localhost:5000\/invocations' \\\n--header 'Content-Type: application\/json' \\\n--data-raw '{&quot;columns&quot;: [&quot;Sepal.Length&quot;, &quot;Sepal.With&quot;, &quot;Petal.Length&quot;, &quot;Petal.Width&quot;], &quot;data&quot;: [[5.2, 4.1, 1.5, 0.1], [6.4, 2.8, 5.6, 2.1], [7.9, 3.8, 6.4, 2.0], [6.7, 3.1, 5.6, 2.4], [6.3, 3.4, 5.6, 2.4]]}'\n<\/code><\/pre>\n<p>I have the following error:\n<code>Invalid Request.  object 'Sepal.Width' not found<\/code><\/p>\n<p>Note, if I change the training to use linear regression model,<\/p>\n<pre><code>with(mlflow_start_run(), {\n  model &lt;- lm(Sepal.Width ~ Sepal.Length, iris)\n  mlflow_log_model(\n    crate(~ stats::predict(model, .x), model=model), &quot;model&quot;)\n})\n<\/code><\/pre>\n<p>The same API request, everything works fine.<\/p>\n<p>Can anyone help me find any clue? I am not that familiar with R.<\/p>\n<p>Thanks a lot!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-31 18:37:08.923 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"r|mlflow",
        "Question_view_count":57,
        "Owner_creation_date":"2013-11-04 03:19:11.877 UTC",
        "Owner_last_access_date":"2022-09-23 02:06:10.57 UTC",
        "Owner_reputation":502,
        "Owner_up_votes":24,
        "Owner_down_votes":1,
        "Owner_views":40,
        "Answer_body":"<p>it turns out the issue is a typo in curl script. it's Sepal.Width not Sepal.With.<\/p>\n<pre><code>curl --location --request POST 'localhost:5000\/invocations' \\\n--header 'Content-Type: application\/json' \\\n--data-raw '{&quot;columns&quot;: [&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;, &quot;Petal.Length&quot;, &quot;Petal.Width&quot;], &quot;data&quot;: [[5.2, 4.1, 1.5, 0.1], [6.4, 2.8, 5.6, 2.1], [7.9, 3.8, 6.4, 2.0], [6.7, 3.1, 5.6, 2.4], [6.3, 3.4, 5.6, 2.4]]}'\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-03 16:41:11.91 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70544873",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71676204,
        "Question_title":"How to log model using mlflow REST api? Does mlflow REST APIs support it?",
        "Question_body":"<p>I'm writing a library using mlflow REST APIs.\nI'm looking for mlflow REST api for logging different mlflow models.<\/p>\n<p>In the doc, <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#log-model\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/rest-api.html#log-model<\/a> it says the api will be removed in future and doesn't have description about model_json request body.<\/p>\n<p>If I see github, <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/docs\/source\/rest-api.rst\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/docs\/source\/rest-api.rst<\/a> mlflow REST API for Log model is missing.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_date":"2022-03-30 11:14:03.58 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-03-30 12:06:26.563 UTC",
        "Question_score":3,
        "Question_tags":"machine-learning|mlflow|mlops",
        "Question_view_count":390,
        "Owner_creation_date":"2017-05-31 04:12:26.49 UTC",
        "Owner_last_access_date":"2022-09-24 08:59:44.06 UTC",
        "Owner_reputation":838,
        "Owner_up_votes":89,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71676204",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72456891,
        "Question_title":"Filter mlflow runs by run name (runName)",
        "Question_body":"<p>How to filter out runs whose runName starts with the string &quot;iteration11_run_number&quot;?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-01 05:39:12.59 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure|databricks|mlflow",
        "Question_view_count":586,
        "Owner_creation_date":"2017-01-14 09:03:21.68 UTC",
        "Owner_last_access_date":"2022-09-15 14:59:07.703 UTC",
        "Owner_reputation":314,
        "Owner_up_votes":963,
        "Owner_down_votes":7,
        "Owner_views":37,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72456891",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61391499,
        "Question_title":"EKS Pod S3 Access Denied",
        "Question_body":"<p>I'm trying to create an EKS pod to use as a service for mlflow. The issue that I'm having though is that I'm unable to connect to s3 to store the mlflow run artifacts. I have tried connecting to the pod using <code>kubectl exec -it &lt;pod_name&gt; -- \/bin\/bash<\/code> and setting the aws credentials there as well. When doing this, I'm able to ls the s3 bucket.<\/p>\n\n<p>But when I attempt to save an mlflow artifact to the same s3 location, I get the following error:<\/p>\n\n<pre><code>An error occurred (AccessDenied) when calling the AssumeRoleWithWebIdentity operation: Not authorized to perform sts:AssumeRoleWithWebIdentity\n<\/code><\/pre>\n\n<p>What would be the issue causing this? Is there an IAM that needs to be set with the EKS pod or something along those lines?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-23 15:51:47.257 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-12-06 13:41:23.467 UTC",
        "Question_score":1,
        "Question_tags":"amazon-s3|amazon-iam|amazon-eks|mlflow",
        "Question_view_count":6784,
        "Owner_creation_date":"2014-11-26 14:40:35.813 UTC",
        "Owner_last_access_date":"2021-08-12 15:37:44.573 UTC",
        "Owner_reputation":945,
        "Owner_up_votes":35,
        "Owner_down_votes":1,
        "Owner_views":148,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61391499",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57816617,
        "Question_title":"not able to dockerize mlflow",
        "Question_body":"<p>while dockerizing mlflow , only .trash is getting created\nbeacuse of that in mlflow ui , getting error as \"no experiments exists\"<\/p>\n\n<pre><code>dockerfile\n\nFROM python:3.7.0\n\nRUN pip install mlflow==1.0.0\n\nWORKDIR \/data\n\nEXPOSE 5000\n\nCMD mlflow server \\\n    --backend-store-uri \/data\/ \\\n    --default-artifact-root \/data\/ \\\n    --host 0.0.0.0\n<\/code><\/pre>\n\n<p>docker compose :<\/p>\n\n<pre><code>  mlflow:\n    # builds track_ml Dockerfile\n    build:\n      context: .\/mlflow_dockerfile\n    expose: \n      - \"5000\"\n    ports:\n      - \"5000:5000\"\n    volumes: \n      - .\/data:\/data\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-06 06:13:34.503 UTC",
        "Question_favorite_count":4.0,
        "Question_last_edit_date":"2019-09-06 06:37:22.187 UTC",
        "Question_score":9,
        "Question_tags":"docker|mlflow",
        "Question_view_count":4718,
        "Owner_creation_date":"2019-08-27 12:56:33.52 UTC",
        "Owner_last_access_date":"2022-07-25 14:43:47.543 UTC",
        "Owner_reputation":91,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57816617",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72999852,
        "Question_title":"Issues in opening the mlflow ui with pygrok",
        "Question_body":"<p>I am very new to MLops and Ml flow. I am trying to use MLflow on google Colab to track models. however, i am not able to open the ui on the local server.\nI got a couple of errors:<\/p>\n<pre><code>The connection to http:xxxx was successfully tunneled to your ngrok client, but the client failed to establish a connection to the local address localhost:80.\n\nMake sure that a web service is running on localhost:80 and that it is a valid address.\n\nThe error encountered was: dial tcp 127.0.0.1:80: connect: connection refused\n<\/code><\/pre>\n<p>Post this error, i did certain changes to the environment and downloaded ngrok.\nand provided the auth token to <code>NGROK_AUTH_TOKEN = &quot;xxxx&quot;<\/code>\nNow i am getting the below message:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/1o5pe.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/1o5pe.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>The code that i am using is:<\/p>\n<pre><code>!pip install pyngrok --quiet\nfrom pyngrok import ngrok\n\nngrok.kill()\n\nNGROK_AUTH_TOKEN = &quot;&quot;\nngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\npublic_url = ngrok.connect(port=&quot;127.0.0.1:5000 &quot;, proto=&quot;http&quot;, options={&quot;bind_tls&quot;: True})\nprint(&quot;MLflow Tracking UI:&quot;, public_url)\n<\/code><\/pre>\n<p>Any help is highly appreciated.\nTIA...<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-15 21:42:58.923 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"google-colaboratory|ngrok|mlflow|pyngrok",
        "Question_view_count":51,
        "Owner_creation_date":"2015-09-11 13:52:59.697 UTC",
        "Owner_last_access_date":"2022-09-22 11:13:17.457 UTC",
        "Owner_reputation":1405,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":123,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72999852",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72454747,
        "Question_title":"Problem when loading a xgboost model from mlflow registry",
        "Question_body":"<p>I create a xgboost classifier:<\/p>\n<pre><code>   xg_reg = xgb.XGBClassifier(objective ='reg:squarederror',  learning_rate = 0.1,\n                max_depth = 20, alpha = 10, n_estimators = 50, use_label_encoder=False)\n<\/code><\/pre>\n<p>After training the model, I am logging it to the MLFLow registry:<\/p>\n<pre><code>   mlflow.xgboost.log_model(\n        xgb_model = xg_reg, \n        artifact_path = &quot;xgboost-models&quot;,\n        registered_model_name = &quot;xgb-regression-model&quot;\n    )\n<\/code><\/pre>\n<p>In the remote UI, I can see the logged model:<\/p>\n<pre><code>artifact_path: xgboost-models\nflavors:\n  python_function:\n    data: model.xgb\n    env: conda.yaml\n    loader_module: mlflow.xgboost\n    python_version: 3.7.9\n  xgboost:\n    code: null\n    data: model.xgb\n    model_class: xgboost.sklearn.XGBClassifier\n    xgb_version: 1.5.2\nmlflow_version: 1.25.1\nmodel_uuid: 5fd42554cf184d8d96afae34dbb96de2\nrun_id: acdccd9f610b4c278b624fca718f76b4\nutc_time_created: '2022-05-17 17:54:53.039242\n<\/code><\/pre>\n<p>Now, on the server side, to load the logged model:<\/p>\n<pre><code>   model = mlflow.xgboost.load_model(model_uri=model_path)\n<\/code><\/pre>\n<p>which loads OK, but the model type is<\/p>\n<blockquote>\n<p>&lt;xgboost.core.Booster object at 0x00000234DBE61D00&gt;<\/p>\n<\/blockquote>\n<p>and the predictions are numpy.float32 (eg 0.5) instead of int64 (eg 0, 1) for the original model.<\/p>\n<p>Any ideas what can be wrong? Many thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-31 22:35:54.297 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|xgboost|mlflow",
        "Question_view_count":163,
        "Owner_creation_date":"2013-05-22 19:51:34.28 UTC",
        "Owner_last_access_date":"2022-09-21 19:50:10.223 UTC",
        "Owner_reputation":324,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Answer_body":"<p>It turns out this was caused by using different versions of mlflow. The model was uploaded to registry with the newest version but was loaded with a previous one. When updated the server to load it, it now works! :)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-22 21:43:18.727 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72454747",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70377991,
        "Question_title":"Setting tracking and artifact locations",
        "Question_body":"<p>I read the documentation for setting the tracking and artifact location. For tracking URI, the options are:<\/p>\n<ol>\n<li>set the <code>MLFLOW_TRACKING_URI<\/code> in bash or the environment I use<\/li>\n<li>set the location with <code>mlflow.set_tracking_uri<\/code> inside the python code<\/li>\n<li>Start a server and then set the above parameters to reflect the server information.<\/li>\n<\/ol>\n<p>How can I set the tracking uri in MLproject? I want to use minimal external code in my project. One way I think of is to use the environment section of the MLproject file environment, like <code>[[&quot;NEW_ENV_VAR&quot;, &quot;new_var_value&quot;]<\/code> Is this correct? Or is there any other way to do it? I could find no example for this except under docker section.<\/p>\n<p>Secondly, same for the artifact registry. Can this be set somewhere in the MLproject file?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-16 11:11:37.383 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-12-16 13:42:18.947 UTC",
        "Question_score":0,
        "Question_tags":"tracking|artifact|mlflow",
        "Question_view_count":146,
        "Owner_creation_date":"2016-05-05 05:51:57.847 UTC",
        "Owner_last_access_date":"2022-03-04 13:01:23.96 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70377991",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67959892,
        "Question_title":"Log experiments with MLflow to DAGsHub tracking server",
        "Question_body":"<p>I'm trying to use MLflow and log my experiments to DAGsHub's remote-tracking server but I get this error message:<\/p>\n<p><code>WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'NoneType' object has no attribute 'info' <\/code> with a lot of HTML text.<\/p>\n<p>When I check my DAGsHub repo, no new experiment is created.<\/p>\n<p>What am I'm doing wrong?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-06-13 15:27:08.067 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":95,
        "Owner_creation_date":"2021-05-04 13:06:44.91 UTC",
        "Owner_last_access_date":"2022-01-11 19:04:29.99 UTC",
        "Owner_reputation":53,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"New York, NY, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67959892",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70539698,
        "Question_title":"MlFlow - Unable to run with S3 as default-artifact-root",
        "Question_body":"<p>I am trying to store my model artifacts using mlflow to s3. In the API services, we use <code>MLFLOW_S3_ENDPOINT_URL<\/code> as the s3 bucket. In the mlflow service, we pass it as an environment variable. But, the mlflow container servicer fails with the below exception:<\/p>\n<pre><code>mflow_server  | botocore.exceptions.HTTPClientError: An HTTP Client raised an unhandled exception: Not supported URL scheme s3\n<\/code><\/pre>\n<p>docker-compose file as below:<\/p>\n<pre><code>version: &quot;3.3&quot;\nservices:\n  prisim-api:\n    image: prisim-api:latest\n    container_name: prisim-api\n    expose:\n      - &quot;8000&quot;\n    environment: \n    - S3_URL=s3:\/\/mlflow-automation-artifacts\/\n    - MLFLOW_SERVER=http:\/\/mlflow:5000\n    - AWS_ID=xyz+\n    - AWS_KEY=xyz\n\n    networks:\n      - prisim \n    depends_on:\n      - mlflow\n    links:\n            - mlflow\n    volumes:\n      - app_data:\/usr\/data\n  mlflow:\n    image: mlflow_server:latest\n    container_name: mflow_server\n    ports:\n      - &quot;5000:5000&quot;    \n    environment:\n      - AWS_ACCESS_KEY_ID=xyz+\n      - AWS_SECRET_ACCESS_KEY=xyz\n      - MLFLOW_S3_ENDPOINT_URL=s3:\/\/mlflow-automation-artifacts\/\n    healthcheck:\n      test: [&quot;CMD&quot;, &quot;echo&quot;, &quot;mlflow server is running&quot;]\n      interval: 1m30s\n      timeout: 10s\n      retries: 3\n    networks:\n       - prisim \nnetworks:\n prisim:\nvolumes:\n  app_data:\n<\/code><\/pre>\n<p>Why the scheme s3 is not supported?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-31 06:46:29.943 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"amazon-s3|docker-compose|mlflow",
        "Question_view_count":932,
        "Owner_creation_date":"2011-07-17 08:59:45.21 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:29.02 UTC",
        "Owner_reputation":2763,
        "Owner_up_votes":373,
        "Owner_down_votes":7,
        "Owner_views":851,
        "Answer_body":"<p>I found the solution.<\/p>\n<p>I have added <code>[&quot;AWS_DEFAULT_REGION&quot;]<\/code> to the environment variables and it worked.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-01-04 05:46:56.08 UTC",
        "Answer_score":0.0,
        "Owner_location":"Thiruvananthapuram, Kerala, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70539698",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69159962,
        "Question_title":"MLFlow doesnt copy properly my artifacts to the mlruns folder when used in a container",
        "Question_body":"<p>I am logging a few models using MLflow. The corresponding scripts are executed in a docker container.<\/p>\n<p>The command <code>mlflow.log_artifacts<\/code> doesn't seem to work properly since I can t see the corresponding files under the mlruns folder. The command doesn't return any error though.<\/p>\n<p>EDIT1: after some further investigations, <strong>it seems that the problem arises whenever I mount the folder containing <code>mlruns\/<\/code><\/strong> as a docker volume.\nI did some tests with the example provided by the <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/4bf54ce9ae22248d2692d2f981e776719a767acf\/mlflow\/tracking\/fluent.py#L565\" rel=\"nofollow noreferrer\">docstring<\/a> of <code>log_artifacts<\/code><\/p>\n<pre><code>import os\nimport json\nimport mlflow\n# Create some files to preserve as artifacts\nfeatures = &quot;rooms, zipcode, median_price, school_rating, transport&quot;\ndata = {&quot;state&quot;: &quot;TX&quot;, &quot;Available&quot;: 25, &quot;Type&quot;: &quot;Detached&quot;}\n# Create couple of artifact files under the directory &quot;data&quot;\nos.makedirs(&quot;data&quot;, exist_ok=True)\nwith open(&quot;data\/data.json&quot;, 'w', encoding='utf-8') as f:\n    json.dump(data, f, indent=2)\nwith open(&quot;data\/features.txt&quot;, 'w') as f:\n    f.write(features)\n# Write all files in &quot;data&quot; to root artifact_uri\/states\nwith mlflow.start_run():\n    mlflow.log_artifacts(&quot;data&quot;, artifact_path=&quot;states&quot;)\n<\/code><\/pre>\n<p>If I run this in a <strong>container without volume mounting, it runs just fine<\/strong>, ie the artifacts appear under <code>mlruns\/&lt;exp-id&gt;\/&lt;run-id&gt;\/artifacts\/state<\/code><\/p>\n<p>However If I run this in a container <strong>with the folder containing <code>mlruns\/<\/code> mounted, it doesn't work,<\/strong> ie the folder <code>mlruns\/&lt;exp-id&gt;\/&lt;run-id&gt;\/artifacts\/<\/code> is empty.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-09-13 09:00:07.203 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-09-15 16:07:11.07 UTC",
        "Question_score":0,
        "Question_tags":"python|docker|mlflow",
        "Question_view_count":519,
        "Owner_creation_date":"2016-02-02 12:29:08.173 UTC",
        "Owner_last_access_date":"2022-09-23 16:13:35.343 UTC",
        "Owner_reputation":515,
        "Owner_up_votes":72,
        "Owner_down_votes":2,
        "Owner_views":68,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69159962",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65939058,
        "Question_title":"MLflow stores artifacts on GCP buckets but is not able to read them",
        "Question_body":"<p>I've found an almost identical question <a href=\"https:\/\/stackoverflow.com\/questions\/63727235\/mlflow-artifacts-storing-artifactsgoogle-cloud-storage-but-not-displaying-them?newreg=923da08a362547daab64c7d7e2275423\">here<\/a> but don't have enough reputation to add comments so will ask again hoping that someone has found a solution in the mean time.<\/p>\n<p>I am using MLflow (1.13.1) to track model performance and GCP Storage to store model artifacts.\nMLflow is running on a GCP VM instance and my python application uses a service account with Storage Object Creator and Storage Object Viewer roles (and then I've also added storage.buckets.get permissions) to store artifacts in GCP buckets and read from them.\nEverything is working as expected with parameters and metrics correctly displaying in MLflow UI and model artifacts correctly stored in buckets. The problem is that the model artifacts do not show up in MLflow UI because of this error:<\/p>\n<pre><code>Unable to list artifacts stored under gs:\/******\/artifacts for the current run. \nPlease contact your tracking server administrator to notify them of this error, \nwhich can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory.\n<\/code><\/pre>\n<p>The quoted artifacts location exists and contains the correct model artifacts, and MLflow should be able to read the artifacts because of the Storage Object Viewer role and the storage.buckets.get permissions.<\/p>\n<p>Any suggestion on what could be wrong? Thank you.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-28 14:24:55.217 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"google-cloud-platform|mlflow",
        "Question_view_count":428,
        "Owner_creation_date":"2021-01-28 13:53:16.69 UTC",
        "Owner_last_access_date":"2021-11-25 23:39:43.27 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":"<p>I've found the problem just after posting the question.\nI had forgotten to install the <code>google-cloud-storage<\/code> library on the GCP VM. Everything works as expected now.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-01-28 14:48:14.603 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65939058",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63230793,
        "Question_title":"How to handle errors in MLflow when a model has been served using \"mlflow models serve\"?",
        "Question_body":"<p>During training, it is possible to use tags as a way to handle exceptions according to <a href=\"https:\/\/stackoverflow.com\/questions\/59856641\/how-can-i-throw-an-exception-from-within-an-mlflow-project\">this question<\/a>.<\/p>\n<p>If a model has been created using <code>mlflow.pyfunc.PythonModel<\/code>, is it possible to throw exceptions? Is there a way to allow error handling for a model that has been served?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-03 13:55:43.31 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|rest|mlflow",
        "Question_view_count":266,
        "Owner_creation_date":"2016-09-03 19:53:45.4 UTC",
        "Owner_last_access_date":"2021-06-15 09:20:57.057 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Pune, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63230793",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71738738,
        "Question_title":"How to set custom path for databricks mlflow artifacts on s3",
        "Question_body":"<p>I've created an empty experiments from databricks experiments console and given the path for my artifacts on s3 i.e. s3:\/\/\/. When i run the scripts, the artifacts are stored at<\/p>\n<pre><code>s3:\/\/&lt;bucket&gt;\/\/&lt;32 char id&gt;\/artifacts\/model-Elasticnet\/model.pkl\n<\/code><\/pre>\n<p>I want to replace \/\/&lt;32 char id&gt;\/artifacts\/ with \/datetime\/artifacts\/ so something like<\/p>\n<pre><code>s3:\/\/&lt;bucket&gt;\/&lt;datetime&gt;\/artifacts\/model-Elasticnet\/model.pkl\n<\/code><\/pre>\n<p>Is there any way i could achieve that?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/wUDcE.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/wUDcE.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Note: experiment_id is from databricks experiment console<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-04-04 14:12:33.88 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-04-07 07:21:35.153 UTC",
        "Question_score":2,
        "Question_tags":"databricks|mlflow|aws-databricks|mlops",
        "Question_view_count":140,
        "Owner_creation_date":"2018-05-12 15:57:03.12 UTC",
        "Owner_last_access_date":"2022-09-24 08:37:01.693 UTC",
        "Owner_reputation":962,
        "Owner_up_votes":106,
        "Owner_down_votes":9,
        "Owner_views":128,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Berlin, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71738738",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65937623,
        "Question_title":"Unable to serve an mlflow model locally",
        "Question_body":"<p>I have created an mlflow model with custom pyfunc. It shows the results when I send input to the loaded model in Jupyter notebook.\nHowever if I am trying to serve it to a local port<\/p>\n<pre><code>!mlflow models serve -m Home\/miniconda3\/envs\/mlruns\/0\/baa40963927a49258c845421e3175c06\/artifacts\/model -p 8001\n<\/code><\/pre>\n<p>I am getting this error<\/p>\n<pre><code> Traceback (most recent call last):\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/bin\/mlflow&quot;, line 10, in &lt;module&gt;\n    sys.exit(cli())\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 829, in __call__\n    return self.main(*args, **kwargs)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 782, in main\n    rv = self.invoke(ctx)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 1259, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 1066, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/click\/core.py&quot;, line 610, in invoke\n    return callback(*args, **kwargs)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/models\/cli.py&quot;, line 56, in serve\n    install_mlflow=install_mlflow).serve(model_uri=model_uri, port=port,\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/models\/cli.py&quot;, line 163, in _get_flavor_backend\n    append_to_uri_path(underlying_model_uri, &quot;MLmodel&quot;), output_path=tmp.path())\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/tracking\/artifact_utils.py&quot;, line 76, in _download_artifact_from_uri\n    artifact_path=artifact_path, dst_path=output_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/local_artifact_repo.py&quot;, line 67, in download_artifacts\n    return super(LocalArtifactRepository, self).download_artifacts(artifact_path, dst_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py&quot;, line 140, in download_artifacts\n    return download_file(artifact_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py&quot;, line 105, in download_file\n    self._download_file(remote_file_path=fullpath, local_path=local_file_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/site-packages\/mlflow\/store\/artifact\/local_artifact_repo.py&quot;, line 95, in _download_file\n    shutil.copyfile(remote_file_path, local_path)\n  File &quot;\/home\/subhojyoti\/miniconda3\/envs\/python3-env\/lib\/python3.6\/shutil.py&quot;, line 120, in copyfile\n    with open(src, 'rb') as fsrc:\nFileNotFoundError: [Errno 2] No such file or directory: 'Home\/miniconda3\/envs\/mlruns\/0\/baa40963927a49258c845421e3175c06\/artifacts\/model\/MLmodel'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-01-28 13:01:27.777 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"deployment|localhost|mlflow",
        "Question_view_count":1277,
        "Owner_creation_date":"2019-11-14 13:58:10.56 UTC",
        "Owner_last_access_date":"2022-09-23 08:37:32.563 UTC",
        "Owner_reputation":115,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":25,
        "Answer_body":"<p>From your error traceback, the model artifact can't be located. In your code, you are executing the 'mlflow' command from within a Jupyter Notebook. I would suggest trying the following:<\/p>\n<ol>\n<li>Check if your models artifacts are on the path you are using Home\/miniconda3\/envs\/mlruns\/0\/baa40963927a49258c845421e3175c06\/artifacts\/model<\/li>\n<li>Try opening a terminal, then <code>cd \/Home\/miniconda3\/envs<\/code> and  execute <code>mlflow models serve -m .\/mlruns\/0\/baa40963927a49258c845421e3175c06\/artifacts\/model -p 8001<\/code><\/li>\n<li>MLFlow offers different solutions to serve a model, you can try to register your model and refer to it as &quot;models:\/{model_name}\/{stage}&quot; as mentioned in the Model Registry <a href=\"https:\/\/mlflow.org\/docs\/latest\/model-registry.html#serving-an-mlflow-model-from-model-registry\" rel=\"nofollow noreferrer\">docs<\/a><\/li>\n<\/ol>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-01-28 13:30:03.1 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65937623",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72280328,
        "Question_title":"MLflow artifacts on S3 but not in UI",
        "Question_body":"<p>I'm running mlflow on my local machine and logging everything through a remote tracking server with my artifacts going to an S3 bucket.  I've confirmed that they are present in S3 after a run but when I look at the UI the artifacts section is completely blank.  There's no error, just empty space.  <a href=\"https:\/\/i.stack.imgur.com\/ZeHJ8.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ZeHJ8.png\" alt=\"enter image description here\" \/><\/a>\nAny idea why this is?  I've included a picture from the UI.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_creation_date":"2022-05-17 20:31:02.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-29 15:50:33.417 UTC",
        "Question_score":1,
        "Question_tags":"amazon-s3|mlflow",
        "Question_view_count":502,
        "Owner_creation_date":"2021-12-16 00:24:08.31 UTC",
        "Owner_last_access_date":"2022-09-23 00:00:12.383 UTC",
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72280328",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62778020,
        "Question_title":"Embarrassingly parallel hyperparameter search via Azure + DataBricks + MLFlow",
        "Question_body":"<p>Conceptual question.  My company is pushing Azure + DataBricks.  I am trying to understand where this can take us.<\/p>\n<p>I am porting some work I've done locally to the Azure + Databricks platform.  I want to run an experiment with a large number of hyperparameter combinations using Azure + Databricks + MLfLow.  I am using PyTorch to implement my models.<\/p>\n<p>I have a cluster with 8 nodes.  I want to kick off the parameter search across all of the nodes in an embarrassingly parallel manner (one run per node, running independently).  Is this as simple as creating a MLflow project and then using the mlflow.projects.run command for each hyperparameter combination and Databricks + MLflow will take care of the rest?<\/p>\n<p>Is this technology capable of this?  I'm looking for some references I could use to make this happen.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2020-07-07 14:52:06.057 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-07 15:12:05.2 UTC",
        "Question_score":0,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":262,
        "Owner_creation_date":"2012-02-09 20:11:42.35 UTC",
        "Owner_last_access_date":"2022-09-16 14:37:11.437 UTC",
        "Owner_reputation":325,
        "Owner_up_votes":254,
        "Owner_down_votes":4,
        "Owner_views":51,
        "Answer_body":"<p>The short answer is yes, it's possible, but won't be exactly as easy as running a single mlflow command. You can paralelize single-node workflows using spark Python UDFs, a good example of this is this <a href=\"https:\/\/pages.databricks.com\/rs\/094-YMS-629\/images\/Fine-Grained-Time-Series-Forecasting.html?_ga=2.64430959.1760852900.1593769579-972789996.1561118598\" rel=\"nofollow noreferrer\">notebook<\/a><\/p>\n<p>I'm not sure if this will work with pytorch, but there is hyperopt library that lets you parallelize search across parameters using Spark - it's integrated with mlflow and available in databricks ML runtime. I've been using it only with scikit-learn, but it may be <a href=\"https:\/\/docs.databricks.com\/applications\/machine-learning\/automl\/hyperopt\/hyperopt-model-selection.html\" rel=\"nofollow noreferrer\">worth checking out<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-07-17 11:52:54.773 UTC",
        "Answer_score":1.0,
        "Owner_location":"Sioux City, IA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62778020",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62160734,
        "Question_title":"Hyperopt failed to execute mlflow.end_run() with tracking URI: databricks",
        "Question_body":"<p>I'm using Azure Databricks + Hyperopt + MLflow for some hyperparameter tuning on a small dataset.  Seem like the job is running, and I get output in MLflow, but the job ends with the following error message:<\/p>\n\n<pre><code>Hyperopt failed to execute mlflow.end_run() with tracking URI: databricks\n<\/code><\/pre>\n\n<p>Here is my code code with some information redacted:<\/p>\n\n<pre><code>from pyspark.sql import SparkSession\n\n# spark session initialization\nspark = (SparkSession.builder.getOrCreate())\nsc = spark.sparkContext\n\n# Data Processing\nimport pandas as pd\nimport numpy as np\n# Hyperparameter Tuning\nfrom hyperopt import fmin, tpe, hp, anneal, Trials, space_eval, SparkTrials, STATUS_OK\nfrom sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n# Modeling\nfrom sklearn.ensemble import RandomForestClassifier\n# cleaning\nimport gc\n# tracking\nimport mlflow\n# track runtime\nfrom datetime import date, datetime\n\nmlflow.set_experiment('\/user\/myname\/myexp')\n# notebook settings \\ variable settings\nn_splits = #\nn_repeats = #\nmax_evals = #\n\ndfL = pd.read_csv(\"\/my\/data\/loc\/mydata.csv\")\n\nx_train = dfL[['f1','f2','f3']]\ny_train = dfL['target']\n\ndef define_model(params):\n    model = RandomForestClassifier(n_estimators=int(params['n_estimators']),\n                                   criterion=params['criterion'], \n                                   max_depth=int(params['max_depth']), \n                                   min_samples_split=params['min_samples_split'], \n                                   min_samples_leaf=params['min_samples_leaf'], \n                                   min_weight_fraction_leaf=params['min_weight_fraction_leaf'], \n                                   max_features=params['max_features'], \n                                   max_leaf_nodes=None, \n                                   min_impurity_decrease=params['min_impurity_decrease'], \n                                   min_impurity_split=None, \n                                   bootstrap=params['bootstrap'], \n                                   oob_score=False, \n                                   n_jobs=-1, \n                                   random_state=int(params['random_state']), \n                                   verbose=0, \n                                   warm_start=False, \n                                   class_weight={0:params['class_0_weight'], 1:params['class_1_weight']})\n        return model\n\n\nspace = {'n_estimators': hp.quniform('n_estimators', #, #, #),\n         'criterion': hp.choice('#', ['#','#']),\n         'max_depth': hp.quniform('max_depth', #, #, #),\n         'min_samples_split': hp.quniform('min_samples_split', #, #, #),\n         'min_samples_leaf': hp.quniform('min_samples_leaf', #, #, #),\n         'min_weight_fraction_leaf': hp.quniform('min_weight_fraction_leaf', #, #, #),\n         'max_features': hp.quniform('max_features', #, #, #),\n         'min_impurity_decrease': hp.quniform('min_impurity_decrease', #, #, #),\n         'bootstrap': hp.choice('bootstrap', [#,#]),\n         'random_state': hp.quniform('random_state', #, #, #),\n         'class_0_weight': hp.choice('class_0_weight', [#,#,#]),\n         'class_1_weight': hp.choice('class_1_weight', [#,#,#])}\n\n# define hyperopt objective\ndef objective(params, n_splits=n_splits, n_repeats=n_repeats):\n\n    # define model\n    model = define_model(params)\n    # get cv splits\n    kfold = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=1331)\n    # define and run sklearn cv scorer\n    scores = cross_val_score(model, x_train, y_train, cv=kfold, scoring='roc_auc')\n    score = scores.mean()\n\n    return {'loss': score*(-1), 'status': STATUS_OK}\n\nspark_trials = SparkTrials(parallelism=36, spark_session=spark)\nwith mlflow.start_run():\n  best = fmin(objective, space, algo=tpe.suggest, trials=spark_trials, max_evals=max_evals)\n<\/code><\/pre>\n\n<p>and then at the end I get..<\/p>\n\n<pre><code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 200\/200 [1:35:28&lt;00:00, 100.49s\/trial, best loss: -0.9584565527065526]\n\nHyperopt failed to execute mlflow.end_run() with tracking URI: databricks\n\nException: 'MLFLOW_RUN_ID'\n\nTotal Trials: 200: 200 succeeded, 0 failed, 0 cancelled.\n<\/code><\/pre>\n\n<p>My Azure Databricks cluster is..<\/p>\n\n<pre><code>6.6 ML (includes Apache Spark 2.4.5, Scala 2.11)\nStandard_DS3_v2\nmin 9 max 18 nodes\n<\/code><\/pre>\n\n<p>Am I doing something wrong or is this a bug?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_creation_date":"2020-06-02 20:19:55.507 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"pyspark|databricks|azure-databricks|mlflow|hyperopt",
        "Question_view_count":604,
        "Owner_creation_date":"2018-06-10 03:57:32.363 UTC",
        "Owner_last_access_date":"2022-09-23 22:17:15.213 UTC",
        "Owner_reputation":247,
        "Owner_up_votes":637,
        "Owner_down_votes":0,
        "Owner_views":53,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62160734",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72689380,
        "Question_title":"mlflow cannot load model , no module optimizer_experimental",
        "Question_body":"<p>I am trying to load a model using mlflow.<\/p>\n<pre><code>model = mlflow.keras.load_model(model_path, custom_objects=custom_objects)\n<\/code><\/pre>\n<p>An Error occured:<\/p>\n<p>ModuleNotFoundError: No module named 'keras.optimizers.optimizer_experimental'; 'keras.optimizers' is not a package<\/p>\n<p>Please any ideas?<\/p>\n<p>I am using these versions:\nmlflow                        1.24.0\ntensorflow                    2.8.2\nkeras                         2.8.0<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-20 15:20:46.573 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|tensorflow|keras|mlflow",
        "Question_view_count":69,
        "Owner_creation_date":"2020-08-11 13:26:47.053 UTC",
        "Owner_last_access_date":"2022-09-23 15:21:54.383 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72689380",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73241326,
        "Question_title":"Can't see artifact ui in mlflow dashboard",
        "Question_body":"<p>mlflow server <br \/>\n--host 0.0.0.0 <br \/>\n--port 5000 <br \/>\n--backend-store-uri sqlite:\/\/\/\/tmp\/test.db <br \/>\n--artifacts-destination s3:\/\/mlflow <br \/>\n--serve-artifacts<\/p>\n<p>Using minio as S3\nAnd env. Variable as secret key &amp; access key<\/p>\n<p>#mlflow #artifactui #proxyartifact<a href=\"https:\/\/i.stack.imgur.com\/Q3h0B.png\" rel=\"nofollow noreferrer\">enter image description here<\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-08-04 19:27:24.373 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-09 05:42:34.677 UTC",
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":65,
        "Owner_creation_date":"2018-11-12 18:06:29.23 UTC",
        "Owner_last_access_date":"2022-09-23 09:49:57.85 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Gandhinagar, Gujarat, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73241326",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71703913,
        "Question_title":"How to set mlflow version field",
        "Question_body":"<p>I just started to work with <code>mlflow<\/code> (<code>1.24.0<\/code>)<\/p>\n<p>How can I set (update) the version field ?<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/fCNy3.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/fCNy3.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-01 08:24:28.933 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":147,
        "Owner_creation_date":"2014-05-23 08:26:35.28 UTC",
        "Owner_last_access_date":"2022-09-19 12:37:21.063 UTC",
        "Owner_reputation":3934,
        "Owner_up_votes":1052,
        "Owner_down_votes":6,
        "Owner_views":416,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71703913",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72604450,
        "Question_title":"MLflow load model fails Python",
        "Question_body":"<p>I am trying to build an API using an MLflow model.<\/p>\n<p>the funny thing is it works from one location on my PC and not from another. So, the reason for doing I wanted to change my repo etc.<\/p>\n<p>So, the simple code of<\/p>\n<pre><code>from mlflow.pyfunc import load_model\nMODEL_ARTIFACT_PATH = &quot;.\/model\/model_name\/&quot;\nMODEL = load_model(MODEL_ARTIFACT_PATH)\n<\/code><\/pre>\n<p>now fails with<\/p>\n<pre><code>ERROR:    Traceback (most recent call last):\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 540, in lifespan\n    async for item in self.lifespan_context(app):\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 481, in default_lifespan\n    await self.startup()\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/starlette\/routing.py&quot;, line 516, in startup\n    await handler()\n  File &quot;\/code\/.\/app\/main.py&quot;, line 32, in startup_load_model\n    MODEL = load_model(MODEL_ARTIFACT_PATH)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/pyfunc\/__init__.py&quot;, line 733, in load_model\n    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/spark.py&quot;, line 737, in _load_pyfunc\n    return _PyFuncModelWrapper(spark, _load_model(model_uri=path))\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/mlflow\/spark.py&quot;, line 656, in _load_model\n    return PipelineModel.load(model_uri)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/util.py&quot;, line 332, in load\n    return cls.read().load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/pipeline.py&quot;, line 258, in load\n    return JavaMLReader(self.cls).load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/ml\/util.py&quot;, line 282, in load\n    java_obj = self._jread.load(path)\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/py4j\/java_gateway.py&quot;, line 1321, in __call__\n    return_value = get_return_value(\n  File &quot;\/usr\/local\/lib\/python3.8\/dist-packages\/pyspark\/sql\/utils.py&quot;, line 117, in deco\n    raise converted from None\npyspark.sql.utils.AnalysisException: Unable to infer schema for Parquet. It must be specified manually.\n<\/code><\/pre>\n<p>The model artifacts are already downloaded to the folder \/model folder which has the following structure.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/oqxRW.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/oqxRW.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>the load model call is in the main.py file\nAs I mentioned it works from another directory, but there is no reference to any absolute paths. Also, I have made sure that my package references are identical. e,g I have pinned them all down<\/p>\n<pre><code># Model\nmlflow==1.25.1\nprotobuf==3.20.1\npyspark==3.2.1\nscipy==1.6.2\nsix==1.15.0\n<\/code><\/pre>\n<p>also, the same docker file is used both places, which among other things, makes sure that the final resulting folder structure is the same<\/p>\n<pre><code>......other stuffs\n\nCOPY .\/app \/code\/app\nCOPY .\/model \/code\/model\n<\/code><\/pre>\n<p>what can explain it throwing this exception whereas in another location (on my PC), it works (same model artifacts) ?<\/p>\n<p>Since it uses load_model function, it should be able to read the parquet files ?<\/p>\n<p>Any question and I can explain.<\/p>\n<p>EDIT1: I have debugged this a little more in the docker container and it seems the parquet files in the itemFactors folder (listed in my screenshot above) are not getting copied over to my image , even though I have the copy command to copy all files under the model folder. It is copying the _started , _committed and _SUCCESS files, just not the parquet files. Anyone knows why would that be? I DO NOT have a .dockerignore file. Why are those files ignored while copying?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-13 14:21:39.67 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-13 15:37:50.387 UTC",
        "Question_score":2,
        "Question_tags":"python|docker|databricks|mlflow",
        "Question_view_count":109,
        "Owner_creation_date":"2015-04-10 08:31:54.763 UTC",
        "Owner_last_access_date":"2022-09-24 09:37:37.383 UTC",
        "Owner_reputation":596,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":80,
        "Answer_body":"<p>I found the problem. Like I wrote in the EDIT1 of my post, with further observations, the parquet files were missing in the docker container. That was strange because I was copying the entire folder in my Dockerfile.<\/p>\n<p>I then realized that I was hitting this problem <a href=\"https:\/\/github.com\/moby\/buildkit\/issues\/1366\" rel=\"nofollow noreferrer\">mentioned here<\/a>. File paths exceeding 260 characters, silently fail and do not get copied over to the docker container. This was really frustrating because nothing failed during build and then during run, it gave me that cryptic error of &quot;unable to infer schema for parquet&quot;, essentially because the parquet files were not copied over during docker build.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-14 07:29:05.993 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2022-06-14 10:34:01.06 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72604450",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69551533,
        "Question_title":"Error can't get attribute Net when saving PyTorch model with MLFlow",
        "Question_body":"<p>After installing MLFlow using <a href=\"https:\/\/github.com\/artefactory\/one-click-mlflow\" rel=\"nofollow noreferrer\">one-click-mlflow<\/a> I save a pytorch model using the default command that I found in the user guide. You can find the command bellow:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.pytorch.log_model(net, artifact_path=&quot;model&quot;, pickle_module=pickle)\n<\/code><\/pre>\n<p>The neural network saved is very simple, this is basically a two layer neural network with Xavier initialization and hyperbolic tangent as activation function.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Net(T.nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        self.hid1 = T.nn.Linear(n_features, 10)\n        self.hid2 = T.nn.Linear(10, 10)\n        self.oupt = T.nn.Linear(10, 1)\n        T.nn.init.xavier_uniform_(self.hid1.weight) \n        T.nn.init.zeros_(self.hid1.bias)\n        T.nn.init.xavier_uniform_(self.hid2.weight)\n        T.nn.init.zeros_(self.hid2.bias)\n        T.nn.init.xavier_uniform_(self.oupt.weight)\n        T.nn.init.zeros_(self.oupt.bias)\n        \n    def forward(self, x):\n        z = T.tanh(self.hid1(x))\n        z = T.tanh(self.hid2(z))\n        z = self.oupt(z)\n        return z\n<\/code><\/pre>\n<p>Every things is runing fine in the Jupyter Notebook. I can log metrics and other artifact but when I save the model I got the following error message:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>2021\/10\/13 09:21:00 WARNING mlflow.utils.requirements_utils: Found torch version (1.9.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torch==1.9.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2021\/10\/13 09:21:00 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.10.0+cu111) contains a local version label (+cu111). MLflow logged a pip requirement for this package as 'torchvision==0.10.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n2021\/10\/13 09:21:01 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: \/tmp\/tmpnl9dsoye\/model\/data, flavor: pytorch)\nTraceback (most recent call last):\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/environment.py&quot;, line 212, in infer_pip_requirements\n    return _infer_requirements(model_uri, flavor)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/requirements_utils.py&quot;, line 263, in _infer_requirements\n    modules = _capture_imported_modules(model_uri, flavor)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/requirements_utils.py&quot;, line 221, in _capture_imported_modules\n    _run_command(\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/requirements_utils.py&quot;, line 173, in _run_command\n    raise MlflowException(msg)\nmlflow.exceptions.MlflowException: Encountered an unexpected error while running ['\/home\/ucsky\/.virtualenv\/mymodel\/bin\/python', '\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/_capture_modules.py', '--model-path', '\/tmp\/tmpnl9dsoye\/model\/data', '--flavor', 'pytorch', '--output-file', '\/tmp\/tmplyj0w2fr\/imported_modules.txt', '--sys-path', '[&quot;\/home\/ucsky\/project\/ofi-ds-research\/incubator\/ofi-pe-fr\/notebook\/guillaume-simon\/06-modelisation-pytorch&quot;, &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/git\/ext\/gitdb&quot;, &quot;\/usr\/lib\/python39.zip&quot;, &quot;\/usr\/lib\/python3.9&quot;, &quot;\/usr\/lib\/python3.9\/lib-dynload&quot;, &quot;&quot;, &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages&quot;, &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/IPython\/extensions&quot;, &quot;\/home\/ucsky\/.ipython&quot;, &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/gitdb\/ext\/smmap&quot;]']\nexit status: 1\nstdout: \nstderr: Traceback (most recent call last):\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/_capture_modules.py&quot;, line 125, in &lt;module&gt;\n    main()\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/_capture_modules.py&quot;, line 118, in main\n    importlib.import_module(f&quot;mlflow.{flavor}&quot;)._load_pyfunc(model_path)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/pytorch\/__init__.py&quot;, line 723, in _load_pyfunc\n    return _PyTorchWrapper(_load_model(path, **kwargs))\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/pytorch\/__init__.py&quot;, line 626, in _load_model\n    return torch.load(model_path, **kwargs)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 607, in load\n    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 882, in _load\n    result = unpickler.load()\n  File &quot;\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/torch\/serialization.py&quot;, line 875, in find_class\n    return super().find_class(mod_name, name)\nAttributeError: Can't get attribute 'Net' on &lt;module '__main__' from '\/home\/ucsky\/.virtualenv\/mymodel\/lib\/python3.9\/site-packages\/mlflow\/utils\/_capture_modules.py'&gt;\n<\/code><\/pre>\n<p>Can somebody explain me what is wrong?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-13 07:44:49.723 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|pytorch|virtualenv|mlflow|mlops",
        "Question_view_count":343,
        "Owner_creation_date":"2010-01-10 16:57:11.61 UTC",
        "Owner_last_access_date":"2022-08-25 13:06:27.853 UTC",
        "Owner_reputation":382,
        "Owner_up_votes":248,
        "Owner_down_votes":3,
        "Owner_views":61,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69551533",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58600732,
        "Question_title":"Is there a way to hide mlflow ui header when start the server with mlflow server?",
        "Question_body":"<p>I want to integrate mlflow ui to our website by using an iframe, but with the header hidden if possible. I found there is an environment variable setting in the source code \/mlflow\/server\/js\/components\/HomeView.js:\n<code>const headerHeight = process.env.HIDE_HEADER === 'true' ? 0 : 60;<\/code> But how can I specify this environment by running the server with <code>mlflow server<\/code>? I tried with <code>HIDE_HEADER=true mlflow server<\/code>, but this doesn't work. Or is there any other way to solve this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-29 02:30:04.85 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"node.js|reactjs|mlflow",
        "Question_view_count":296,
        "Owner_creation_date":"2015-09-01 23:50:47.41 UTC",
        "Owner_last_access_date":"2022-09-23 03:26:58.597 UTC",
        "Owner_reputation":626,
        "Owner_up_votes":75,
        "Owner_down_votes":1,
        "Owner_views":79,
        "Answer_body":"<p>@Jason good question, those environment variables are read at build-time for the MLflow UI's Javascript assets. Since the PyPI MLflow wheel comes with pre-built Javascript assets, it's difficult to achieve your use case using a PyPI installation of <code>mlflow<\/code>.<\/p>\n\n<p>However, you can build a custom MLflow wheel from source with the UI header hidden by following the instructions <a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/branch-1.3\/CONTRIBUTING.rst#building-a-distributable-artifact\" rel=\"nofollow noreferrer\">here<\/a>, replacing the <code>npm run build<\/code> step with <code>HIDE_HEADER=true npm run build<\/code> (basically, the idea is to set the desired environment variables prior to building Javascript assets via <code>npm run build<\/code>). You can then pip-install that wheel on the node hosting your MLflow server &amp; launch the server via <code>mlflow server<\/code>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-10-30 20:52:32.163 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58600732",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61879913,
        "Question_title":"ModuleNotFoundError: No module named 'pyspark.dbutils' while running multiple.py file\/notebook on job clusters in databricks",
        "Question_body":"<p>I am working in TravisCI, MlFlow and Databricks environment where .tavis.yml sits at git master branch and detects any change in <code>.py<\/code> file and whenever it gets updated, It will run mlflow command to run .py file in databricks environment. \nmy MLProject file looks as following:<\/p>\n\n<pre><code>name: mercury_cltv_lib\nconda_env: conda-env.yml\n\n\nentry_points:    \n  main:\n    command: \"python3 run-multiple-notebooks.py\"\n<\/code><\/pre>\n\n<p>Workflow is as following:\nTravisCI detects change in master branch-->triggers build which will run MLFlow command and it'll spin up a job cluster in databricks to run .py file from repo.<\/p>\n\n<p>It worked fine with one .py file but when I tried to run multiple notebook using dbutils, it is throwing <\/p>\n\n<pre><code>  File \"run-multiple-notebooks.py\", line 3, in &lt;module&gt;\n    from pyspark.dbutils import DBUtils\nModuleNotFoundError: No module named 'pyspark.dbutils'\n<\/code><\/pre>\n\n<p>Please find below the relevant code section from run-multiple-notebooks.py<\/p>\n\n<pre><code>  def get_spark_session():\n    from pyspark.sql import SparkSession\n    return SparkSession.builder.getOrCreate()\n\n  def get_dbutils(self, spark = None):\n    try:\n        if spark == None:\n            spark = spark\n\n        from pyspark.dbutils import DBUtils #error line\n        dbutils = DBUtils(spark) #error line\n    except ImportError:\n        import IPython\n        dbutils = IPython.get_ipython().user_ns[\"dbutils\"]\n    return dbutils\n\n  def submitNotebook(notebook):\n    print(\"Running notebook %s\" % notebook.path)\n    spark = get_spark_session()\n    dbutils = get_dbutils(spark)\n<\/code><\/pre>\n\n<p>I tried all the options and tried <\/p>\n\n<pre><code>https:\/\/stackoverflow.com\/questions\/61546680\/modulenotfounderror-no-module-named-pyspark-dbutils\n<\/code><\/pre>\n\n<p>as well. It is not working :(<\/p>\n\n<p>Can someone please suggest if there is fix for the above-mentioned error while running .py in job cluster. My code works fine inside databricks local notebook but running from outside using TravisCI and MLFlow isn't working which is must requirement for pipeline automation.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-18 22:15:02.237 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-05-20 13:47:56.477 UTC",
        "Question_score":2,
        "Question_tags":"pyspark|travis-ci|databricks|mlflow|dbutils",
        "Question_view_count":401,
        "Owner_creation_date":"2019-04-15 16:50:36.127 UTC",
        "Owner_last_access_date":"2022-09-20 17:21:27.237 UTC",
        "Owner_reputation":352,
        "Owner_up_votes":27,
        "Owner_down_votes":1,
        "Owner_views":88,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Minnesota, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61879913",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58995329,
        "Question_title":"Artifact storage and MLFLow on remote server",
        "Question_body":"<p>I am trying to get MLFlow on another machine in a local network to run and I would like to ask for some help because I don't know what to do now.<\/p>\n\n<p>I have a mlflow server running on a <em>server<\/em>. The mlflow server is running under my user on the <em>server<\/em> and has been started like this: <\/p>\n\n<pre><code>mlflow server --host 0.0.0.0 --port 9999 --default-artifact-root sftp:\/\/&lt;MYUSERNAME&gt;@&lt;SERVER&gt;:&lt;PATH\/TO\/DIRECTORY\/WHICH\/EXISTS&gt;\n<\/code><\/pre>\n\n<p>My program which should log all the data to the mlflow server looks like this:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>from mlflow import log_metric, log_param, log_artifact, set_tracking_uri\n\nif __name__ == \"__main__\":\n    remote_server_uri = '&lt;SERVER&gt;' # this value has been replaced\n    set_tracking_uri(remote_server_uri)\n    # Log a parameter (key-value pair)\n    log_param(\"param1\", 5)\n\n    # Log a metric; metrics can be updated throughout the run\n    log_metric(\"foo\", 1)\n    log_metric(\"foo\", 2)\n    log_metric(\"foo\", 3)\n\n    # Log an artifact (output file)\n    with open(\"output.txt\", \"w\") as f:\n        f.write(\"Hello world!\")\n    log_artifact(\"output.txt\")\n\n<\/code><\/pre>\n\n<p>The parameters get and metrics get transfered to the server but not the artifacts. Why is that so?<\/p>\n\n<p>Note on the SFTP part:\nI can log in via SFTP and the pysftp package is installed<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2019-11-22 13:32:02.373 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-11-22 14:43:48.62 UTC",
        "Question_score":9,
        "Question_tags":"python|mlflow",
        "Question_view_count":3483,
        "Owner_creation_date":"2014-03-21 14:59:04.963 UTC",
        "Owner_last_access_date":"2022-06-30 17:07:48.553 UTC",
        "Owner_reputation":422,
        "Owner_up_votes":12,
        "Owner_down_votes":1,
        "Owner_views":13,
        "Answer_body":"<p>I don't know if I will get an answer to my problem but I did <em>solved<\/em> it this way.<\/p>\n\n<p>On the server I created the directory <code>\/var\/mlruns<\/code>. I pass this directory to mlflow via <code>--backend-store-uri file:\/\/\/var\/mlruns<\/code><\/p>\n\n<p>Then I mount this directory via e.g. <code>sshfs<\/code> on my local machine under the same path.<\/p>\n\n<p>I don't like this solution but it solved the problem good enough for now.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-12-10 08:50:01.237 UTC",
        "Answer_score":2.0,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58995329",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56857709,
        "Question_title":"How to change experiment being tracked by Databricks \"runs\" tab?",
        "Question_body":"<p>I'm trying to use the mlflow databricks integration, specifically the tracking API. Normally, I can view past runs info in the handy sidebar of a notebook, as you can see <a href=\"https:\/\/i.stack.imgur.com\/JWY1c.png\" rel=\"nofollow noreferrer\">here<\/a> and which I got from the <a href=\"https:\/\/docs.databricks.com\/applications\/mlflow\/quick-start.html#mlflow-mlflow-quick-start-python\" rel=\"nofollow noreferrer\">tutorial<\/a>. However, what I want now is to use multiple notebooks to send runs to the same experiment. Additionally, I would like to view the results of all these common runs in each of the notebooks. To do this, I need to change the (default) experiment tracked by the \"runs\" tab. <\/p>\n\n<p>Ultimately, my question boils down to the following: how can I set the experiment being tracked by the \"runs\" tab? I have tried using <code>mlflow.set_tracking_uri<\/code> and <code>mlflow.set_experiment(mlflow_experiment_name)<\/code><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-07-02 17:47:57.383 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|databricks|mlflow",
        "Question_view_count":257,
        "Owner_creation_date":"2016-05-29 00:42:03.397 UTC",
        "Owner_last_access_date":"2022-09-14 17:22:55.647 UTC",
        "Owner_reputation":2168,
        "Owner_up_votes":440,
        "Owner_down_votes":35,
        "Owner_views":1631,
        "Answer_body":"<p>I don't believe this is possible today, as the design choice is to associate the runs tab to the notebook experiment.  From the <a href=\"https:\/\/docs.databricks.com\/applications\/mlflow\/tracking.html#notebook-experiments\" rel=\"nofollow noreferrer\">docs<\/a>:<\/p>\n<blockquote>\n<p>Every Python and R notebook in a Databricks workspace has its own experiment. When you use MLflow in a notebook, it records runs in the notebook experiment.<\/p>\n<p>A notebook experiment shares the same name and ID as its corresponding notebook. The notebook ID is the numerical identifier at the end of a Notebook URL.<\/p>\n<\/blockquote>\n<p>You can create experiments independent of the notebook experiment and log runs to it from different sources.  You'll still have to open up the tracking UI to explore the results though.<\/p>\n<p>In other words, you can send multiple runs from different notebooks to the same experiment, but today you cannot log multiple runs to the 'Runs' tab in a specific notebook.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2019-08-23 00:06:47.737 UTC",
        "Answer_score":1.0,
        "Owner_location":"Canada",
        "Answer_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56857709",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69573565,
        "Question_title":"How to configure artifact store of mlflow tracking service to connect to minio S3 using minio STS generated acces_key, secret_key and session_token",
        "Question_body":"<ul>\n<li><p>Minio is configured with LDAP and am generating credentials of user\nwith AssumeRoleWithLDAPIdentity using STS API (<a href=\"https:\/\/docs.min.io\/minio\/baremetal\/security\/ad-ldap-external-identity-management\/AssumeRoleWithLDAPIdentity.html#assumerolewithldapidentity\" rel=\"nofollow noreferrer\">reference<\/a>)<\/p>\n<\/li>\n<li><p>From above values, I'm setting the variables AWS_ACCESS_KEY, AWS_SECRET_KEY, AWS_SESSION_TOKEN (<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#amazon-s3-and-s3-compatible-storage\" rel=\"nofollow noreferrer\">reference<\/a>)<\/p>\n<\/li>\n<\/ul>\n<p>I'm getting error when am trying to push model to mlflow to store in minio artifact<\/p>\n<pre><code>S3UploadFailedError: Failed to upload \/tmp\/tmph68xubhm\/model\/MLmodel to mlflow\/1\/xyz\/artifacts\/model\/MLmodel: An error occurred (InvalidTokenId) when calling the PutObject operation: The security token included in the request is invalid\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-14 15:38:30.19 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"amazon-s3|minio|mlflow|mlops",
        "Question_view_count":255,
        "Owner_creation_date":"2017-05-31 04:12:26.49 UTC",
        "Owner_last_access_date":"2022-09-24 08:59:44.06 UTC",
        "Owner_reputation":838,
        "Owner_up_votes":89,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69573565",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72900375,
        "Question_title":"Runtime error using MLFlow and Spark on databricks",
        "Question_body":"<p>Here is some model I created:<\/p>\n<pre><code>class SomeModel(mlflow.pyfunc.PythonModel):\n    def predict(self, context, input):\n        # do fancy ML stuff\n        # log results\n        pandas_df = pd.DataFrame(...insert predictions here...)\n        spark_df = spark.createDataFrame(pandas_df)\n        spark_df.write.saveAsTable('tablename', mode='append')\n<\/code><\/pre>\n<p>I'm trying to log my model in this manner by calling it later in my code:<\/p>\n<pre><code>with mlflow.start_run(run_name=&quot;SomeModel_run&quot;):\n    model = SomeModel()\n    mlflow.pyfunc.log_model(&quot;somemodel&quot;, python_model=model)\n<\/code><\/pre>\n<p>Unfortunately it gives me this Error Message:<\/p>\n<p><code>RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.<\/code><\/p>\n<p>The error is caused because of the line <code>mlflow.pyfunc.log_model(&quot;somemodel&quot;, python_model=model)<\/code>, if I comment it out my model will make its predictions and log the results in my table.<\/p>\n<p>Alternatively, removing the lines in my predict function where I call spark to create a dataframe and save the table, I am able to log my model.<\/p>\n<p>How do I go about resolving this issue? I need my model to not only write to the table but also be logged<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_creation_date":"2022-07-07 15:17:36.183 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|pyspark|apache-spark-sql|databricks|mlflow",
        "Question_view_count":93,
        "Owner_creation_date":"2017-04-05 06:51:07.557 UTC",
        "Owner_last_access_date":"2022-09-23 15:20:00.157 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72900375",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63806335,
        "Question_title":"How to migrate MlFlow experiments from one Databricks workspace to another with registered models?",
        "Question_body":"<p>so unfortunatly we have to redeploy our Databricks Workspace in which we use the MlFlow functonality with the Experiments and the registering of Models.<\/p>\n<p>However if you export the user folder where the eyperiment is saved with a DBC and import it into the new workspace, the Experiments are not migrated and are just missing.<\/p>\n<p>So the easiest solution did not work. The next thing I tried was to create a new experiment in the new workspace. Copy all the experiment data from the dbfs of the old workspace (with dbfs cp -r dbfs:\/databricks\/mlflow source, and then the same again to upload it to the new workspace) to the new one. And then just reference the location of the data to the experiment like in the following picture:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/emgGs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/emgGs.png\" alt=\"Create Experiment with existing path\" \/><\/a><\/p>\n<p>This is also not working, no run is visible, although the path is already existing.<\/p>\n<p>The next idea was that the registred models are the most important one so at least those should be there and accessible. For that I used the documentation here: <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/model-registry.html\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/model-registry.html<\/a>.<\/p>\n<p>With the following code you get a list of the registred models on the old workspace with the reference on the run_id and location.<\/p>\n<pre><code>from mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\nfor rm in client.list_registered_models():\n    pprint(dict(rm), indent=4)\n<\/code><\/pre>\n<p>And with this code you can add models to a model registry with a reference to the location of the artifact data (on the new workspace):<\/p>\n<pre><code># first the general model must be defined\nclient.create_registered_model(name='MyModel')\n\n# and then the run of the model you want to registre will be added to the model as version one\nclient.create_model_version( name='MyModel', run_id='9fde022012046af935fe52435840cf1', source='dbfs:\/databricks\/mlflow\/experiment_id\/run_id\/artifacts\/model')\n<\/code><\/pre>\n<p>But that did also not worked out. if you go into the Model Registry you get a message like this: <a href=\"https:\/\/i.stack.imgur.com\/Ham4y.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ham4y.png\" alt=\"error message of the registred model\" \/><\/a>.<\/p>\n<p>And I really checked, at the given path (the source) there the data is really uploaded and also a model is existing.<\/p>\n<p>Do you have any new ideas to migrate those models in Databricks?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-09-09 07:00:21.84 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"migration|databricks|azure-databricks|mlflow",
        "Question_view_count":1704,
        "Owner_creation_date":"2015-07-26 16:16:59.34 UTC",
        "Owner_last_access_date":"2022-06-14 06:51:49.997 UTC",
        "Owner_reputation":416,
        "Owner_up_votes":20,
        "Owner_down_votes":0,
        "Owner_views":90,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63806335",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72236258,
        "Question_title":"MLflow: Unable to store artifacts to S3",
        "Question_body":"<p>I'm running my mlflow tracking server in a docker container on a remote server and trying to log mlflow runs from local computer with the eventual goal that anyone on my team can send their run data to the same tracking server.  I've set the tracking URI to be <code>http:\/\/&lt;ip of remote server &gt;:&lt;port on docker container&gt;<\/code>.  I'm not explicitly setting any of the AWS credentials on the local machine because I would like to just be able to train locally and log to the remote server (run data to RDS and artifacts to S3).  I have no problem logging my runs to an RDS database but I keep getting the following error when it get to the point of trying to log artifacts: <code>botocore.exceptions.NoCredentialsError: Unable to locate credentials<\/code>.  Do I have to have the credentials available outside of the tracking server for this to work (ie: on my local machine where the mlflow runs are taking place)?  I know that all of my credentials are available in the docker container that is hosting the tracking server. I've be able to upload files to my S3 bucket using the aws cli inside of the container that hosts my tracking server so I know that it as access.  I'm confused by the fact that I can log to RDS but not S3. I'm not sure what I'm doing wrong at this point.  TIA.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-13 23:32:23.673 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"docker|amazon-s3|boto3|mlflow",
        "Question_view_count":223,
        "Owner_creation_date":"2021-12-16 00:24:08.31 UTC",
        "Owner_last_access_date":"2022-09-23 00:00:12.383 UTC",
        "Owner_reputation":51,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72236258",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71135260,
        "Question_title":"Python assert a function is called within a certain `with` statement's context",
        "Question_body":"<p>In python I would like to check that a given function is called within a <code>with<\/code> statement of a given type<\/p>\n<pre><code>class Bar:\n def __init__(self, x):\n  self.x = x\n def __enter__(self):\n  return self\n def __exit__(self, *a, **k):\n  pass\n\ndef foo(x):\n # assert that the enclosing context is an instance of bar\n # assert isinstance('enclosed context', Bar)\n print(x*2)\n\nwith Bar(1) as bar:\n foo(bar.x)\n<\/code><\/pre>\n<p>I could do something like enforcing an arg passed into <code>foo<\/code> and wrapping functions in a decorator i.e.<\/p>\n<pre><code>class Bar:\n def __init__(self, x):\n  self.x = x\n def __enter__(self):\n  return self\n def __exit__(self, *a, **k):\n  pass\n\ndef assert_bar(func):\n def inner(bar, *a, **k):\n  assert isinstance(bar, Bar)\n  return func(*a, **k)\n return inner\n\n\n@assert_bar\ndef foo(x):\n print(x*2)\n\nwith Bar(1) as bar:\n foo(bar, bar.x)\n\n<\/code><\/pre>\n<p>but then I would have to pass around <code>bar<\/code> everywhere.<\/p>\n<p>As a result I'm trying to see if there's a way to access the <code>with<\/code> context<\/p>\n<p>Note: The real world application of this is ensuring that <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html#mlflow.pyfunc.log_model\" rel=\"nofollow noreferrer\"><code>mlflow.pyfunc.log_model<\/code><\/a> is called within an <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.ActiveRun\" rel=\"nofollow noreferrer\"><code>mlflow.ActiveRun<\/code><\/a> context, or it leaves an <code>ActiveRun<\/code> open, causing problems later on<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_creation_date":"2022-02-16 01:03:09.773 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":77,
        "Owner_creation_date":"2016-09-06 20:29:03.197 UTC",
        "Owner_last_access_date":"2022-07-09 22:04:27.333 UTC",
        "Owner_reputation":617,
        "Owner_up_votes":21,
        "Owner_down_votes":2,
        "Owner_views":75,
        "Answer_body":"<p>Here's an ugly way to do it: global state.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>class Bar:\n    active = 0\n    def __init__(self, x):\n        self.x = x\n    def __enter__(self):\n        Bar.active += 1\n        return self\n    def __exit__(self, *a, **k):\n        Bar.active -= 1\n\nfrom functools import wraps\n\ndef assert_bar(func):\n    @wraps(func)\n    def wrapped(*vargs, **kwargs):\n        if Bar.active &lt;= 0:\n            # raises even if asserts are disabled\n            raise AssertionError()\n        return func(*vargs, **kwargs)\n    return wrapped\n<\/code><\/pre>\n<p>Unfortunately I don't think there is any non-ugly way to do it. If you aren't going to pass around a <code>Bar<\/code> instance yourself then you must rely on some state existing somewhere else to tell you that a <code>Bar<\/code> instance exists and is currently being used as a context manager.<\/p>\n<p>The only way you can avoid that global state is to store the state in the instance, which means the decorator needs to be an instance method and the instance needs to exist before the function is declared:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>from functools import wraps\n\nclass Bar:\n    def __init__(self, x):\n        self.x = x\n        self.active = 0\n    def __enter__(self):\n        self.active += 1\n        return self\n    def __exit__(self, *a, **k):\n        self.active -= 1\n    def assert_this(self, func):\n        @wraps(func)\n        def wrapped(*vargs, **kwargs):\n            if self.active &lt;= 0:\n                raise AssertionError()\n            return func(*vargs, **kwargs)\n        return wrapped\n\nbar = Bar(1)\n\n@bar.assert_this\ndef foo(x):\n    print(x + 1)\n\nwith bar:\n    foo(1)\n<\/code><\/pre>\n<p>This is still &quot;global state&quot; in the sense that the function <code>foo<\/code> now holds a reference to the <code>Bar<\/code> instance that holds the state. But it may be more palatable if <code>foo<\/code> is only ever going to be a local function.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-02-16 01:13:37.813 UTC",
        "Answer_score":2.0,
        "Owner_location":"London, United Kingdom",
        "Answer_last_edit_date":"2022-02-16 01:21:18.49 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71135260",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70820661,
        "Question_title":"Track to database, artifacts to specific destination",
        "Question_body":"<p>I am running <code>mlflow ui<\/code> and PostgreSQL db in docker compose.<\/p>\n<p>Mlflow UI container runs like this: <code>mlflow ui --backend-store-uri &quot;postgresql+psycopg2:\/\/postgres:passw0rd@database:5432\/postgres&quot; --host 0.0.0.0<\/code><\/p>\n<p>Then I run my models locally from jupyter, e.g.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>remote_server_uri = &quot;postgresql+psycopg2:\/\/postgres:passw0rd@localhost:5432\/postgres&quot;\nmlflow.set_tracking_uri(remote_server_uri)\nmlflow.set_experiment(&quot;exp2&quot;)\n\nX = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\ny = np.array([0, 0, 1, 1, 1, 0])\nlr = LogisticRegression()\nlr.fit(X, y)\nscore = lr.score(X, y)\nprint(&quot;Score: %s&quot; % score)\nwith mlflow.start_run():\n    mlflow.log_metric(&quot;score&quot;, score)\n<\/code><\/pre>\n<p>Everything works fine - experiments get logged into PostgreSQL and mlflow UI can read it from PostgreSQL .<\/p>\n<p>One thing that bothers me is that artifacts are stored locally into .\/mlruns folder. How to change it to save it somewhere else?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-23 09:18:47.63 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-01-23 09:23:27.49 UTC",
        "Question_score":0,
        "Question_tags":"python|postgresql|mlflow",
        "Question_view_count":361,
        "Owner_creation_date":"2016-04-04 13:56:35.087 UTC",
        "Owner_last_access_date":"2022-09-24 15:49:58.61 UTC",
        "Owner_reputation":622,
        "Owner_up_votes":296,
        "Owner_down_votes":11,
        "Owner_views":59,
        "Answer_body":"<p>So apparently <code>--default-artifact-root<\/code> argument has to be used when launching server\/ui. The only downside is that that default artifact root is relative to development environment, so if you are running mlflow server in docker and specify default-artifact-root to e.g. <code>some\/path<\/code> then the artifacts are going to be saved to your <strong>local machine<\/strong> to that path (<strong>not inside docker container<\/strong>). Probably the best solution is to use remote storage such as S3\/Blob.<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-01-23 18:03:46.12 UTC",
        "Answer_score":0.0,
        "Owner_location":"Czech Republic",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70820661",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72569496,
        "Question_title":"In mlflow, is it possible to track an artifact without having mlflow store it separately?",
        "Question_body":"<p>I am new to mlflow. I am trying to track\/log some artifacts (a directory of images output by my model) such that they are affiliated with the run that generated them, and so that I can view them in the mlflow UI along with all the other tracked information.<\/p>\n<p>This directory of images is generated in a custom folder path location (with a unique identifier for each run). My goal is to point mlflow to this directory so that it can recognize that these images are artifacts to track.<\/p>\n<p>Is this possible? From my understanding, the mlflow.log_artifact() function will simply create a duplicate of this image and store it within mlflow's default artifact path (ie, something like <em>mydrive1\/mlflow\/0\/\/artifacts\/<\/em>). I do not want to create a duplicate; I want to keep these images where I originally saved them.<\/p>\n<p>Example of file tree:<br \/>\nmydrive1\/<br \/>\n--\/train.py<br \/>\n--\/mlflow\/<br \/>\n----\/0\/<br \/>\n------\/meta.yaml<br \/>\n------\/[random char sequence]<br \/>\n--------\/artifacts\/<br \/>\n--------\/meta.yaml<\/p>\n<p>mydrive2\/<br \/>\n--\/output\/<br \/>\n----\/my_experiment0\/<br \/>\n------\/images\/<br \/>\n--------\/image1.png<br \/>\n--------\/image2.png<\/p>\n<p>I have found that if I manually edit the <em>artifact_uri<\/em> variable (in the meta.yaml file of the relevant run) to point to the relevant directory of images (ie, <em>mydrive2\/my_experiment0\/images\/<\/em>), all those images will show up in the artifact viewer in the mlflow UI. Is there a way to edit the <em>artifact_uri<\/em> variable via the mlflow API (or some other principled way)?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-10 05:34:05.583 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":164,
        "Owner_creation_date":"2019-06-17 20:41:49.483 UTC",
        "Owner_last_access_date":"2022-09-25 00:26:57.013 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Tokyo, Japan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72569496",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":54773795,
        "Question_title":"Accessing MLFlow UI with a folder name different than mlruns",
        "Question_body":"<p>I set the <code>tracking_uri<\/code> to a folder name different than <code>mlruns<\/code>. <\/p>\n\n<p>Is there a way I can open the <strong>MLFlow UI<\/strong> pointing to the new folder name for mlruns? <\/p>\n\n<p>I know I can rename the folder back to <code>mlruns<\/code>, which gets me access to all of my metrics and parameters for each experiment, but the artifacts are not accessible, since they were logged to a different folder name than mlruns. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-02-19 19:41:07.453 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-02-19 20:50:20.313 UTC",
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":1521,
        "Owner_creation_date":"2019-02-19 19:38:23.667 UTC",
        "Owner_last_access_date":"2019-12-06 03:47:18.253 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54773795",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56647549,
        "Question_title":"MLflow Error while deploying the Model to local REST server",
        "Question_body":"<blockquote>\n  <p><strong>System Details:<\/strong><\/p>\n  \n  <p>Operating System: Ubuntu 19.04<\/p>\n  \n  <p>Anaconda version: 2019.03<\/p>\n  \n  <p>Python version: 3.7.3<\/p>\n  \n  <p>mlflow version: 1.0.0<\/p>\n<\/blockquote>\n\n<p><strong>Steps to Reproduce:<\/strong> <a href=\"https:\/\/mlflow.org\/docs\/latest\/tutorial.html\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/tutorial.html<\/a><\/p>\n\n<p><strong>Error at line\/command:<\/strong> <code>mlflow models serve -m [path_to_model] -p 1234<\/code><\/p>\n\n<p><strong>Error:<\/strong>\nCommand 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1>&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 1<\/p>\n\n<p><strong>Terminal Log:<\/strong><\/p>\n\n<pre><code>(mlflow) root@user:\/home\/user\/mlflow\/mlflow\/examples\/sklearn_elasticnet_wine\/mlruns\/0\/e3dd02d5d84545ffab858db13ede7366\/artifacts\/model# mlflow models serve -m $(pwd) -p 1234\n2019\/06\/18 16:15:16 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n2019\/06\/18 16:15:17 INFO mlflow.pyfunc.backend: === Running command 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1&gt;&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app'\nbash: activate: No such file or directory\nTraceback (most recent call last):\n  File \"\/root\/anaconda3\/envs\/mlflow\/bin\/mlflow\", line 10, in &lt;module&gt;\n    sys.exit(cli())\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/click\/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/models\/cli.py\", line 43, in serve\n    host=host)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 76, in serve\n    command_env=command_env)\n  File \"\/root\/anaconda3\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/backend.py\", line 147, in _execute_in_conda_env\n    command, rc\nException: Command 'source activate mlflow-c4536834c2e6e0e2472b58bfb28dce35b4bd0be6 1&gt;&amp;2 &amp;&amp; gunicorn --timeout 60 -b 127.0.0.1:1234 -w 4 mlflow.pyfunc.scoring_server.wsgi:app' returned non zero return code. Return code = 1\n(mlflow) root@user:\/home\/user\/mlflow\/mlflow\/examples\/sklearn_elasticnet_wine\/mlruns\/0\/e3dd02d5d84545ffab858db13ede7366\/artifacts\/model# \n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-06-18 10:56:39.15 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python-3.x|deployment|mlflow",
        "Question_view_count":1840,
        "Owner_creation_date":"2017-08-29 10:04:18.09 UTC",
        "Owner_last_access_date":"2021-09-06 18:21:49.9 UTC",
        "Owner_reputation":2101,
        "Owner_up_votes":3,
        "Owner_down_votes":0,
        "Owner_views":41,
        "Answer_body":"<p>Following the steps mentioned in the GitHub Issue <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/1507\" rel=\"nofollow noreferrer\">1507<\/a> (<a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/1507\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/1507<\/a>) I was able to resolve this issue.<\/p>\n\n<p>In reference to this post, the \"<strong>anaconda\/bin\/<\/strong>\" directory is never added to the list of environment variables i.e. PATH variable. In order to resolve this issue, add the \"<strong>else<\/strong>\" part of conda initialize code block from ~\/.bashrc file to your PATH variable.<\/p>\n\n<pre><code># &gt;&gt;&gt; conda initialize &gt;&gt;&gt;\n# !! Contents within this block are managed by 'conda init' !!\n__conda_setup=\"$('\/home\/atulk\/anaconda3\/bin\/conda' 'shell.bash' 'hook' 2&gt; \/dev\/null)\"\nif [ $? -eq 0 ]; then\n    eval \"$__conda_setup\"\nelse\n    if [ -f \"\/home\/atulk\/anaconda3\/etc\/profile.d\/conda.sh\" ]; then\n        . \"\/home\/atulk\/anaconda3\/etc\/profile.d\/conda.sh\"\n    else\n        export PATH=\"\/home\/atulk\/anaconda3\/bin:$PATH\"\n    fi\nfi\nunset __conda_setup\n# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;\n<\/code><\/pre>\n\n<p>In this case, I added <strong>export PATH=\"\/home\/atulk\/anaconda3\/bin:$PATH\"<\/strong> to the PATH variable. However, this is just a temporary fix until the issue is fixed in the project.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-06-28 14:02:54.53 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56647549",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57578354,
        "Question_title":"How do I set a custom gunicorn worker timeout when serving an MLflow model with the \"mlflow models serve\" CLI?",
        "Question_body":"<p>When serving an MLflow Python model with the \"pyfunc\" backend (<a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/backend.py\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/pyfunc\/backend.py<\/a>), how can I set a custom gunicorn worker timeout? The default timeout of 60 seconds may be insufficient when serving large models that take a long time to load.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-20 16:55:18.683 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"mlflow",
        "Question_view_count":1763,
        "Owner_creation_date":"2019-08-20 16:51:28.34 UTC",
        "Owner_last_access_date":"2022-09-23 19:12:51.593 UTC",
        "Owner_reputation":61,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57578354",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73321771,
        "Question_title":"Mlflow authorization with spnego",
        "Question_body":"<p>I saw this topic about Kerberos authntication - <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/2678\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/2678<\/a> . It was in 2020 . Our team trying to do authentication with kerberos by spnego. We did spnego on nginx server and it is fine - and get code 200 when we do curl to mlflow http uri . BUT we can't do it with mlflow environment variable .<\/p>\n<p>The question is - Does mlflow has some feature to make authentication with spnego or not? Or it has just these environment variables for authentication and such methods :<\/p>\n<ul>\n<li>MLFLOW_TRACKING_USERNAME and MLFLOW_TRACKING_PASSWORD - username and password to use with HTTP Basic authentication. To use Basic authentication, you must set both environment variables .<\/li>\n<li>MLFLOW_TRACKING_TOKEN - token to use with HTTP Bearer authentication. Basic authentication takes precedence if set.<\/li>\n<li>MLFLOW_TRACKING_INSECURE_TLS - If set to the literal true, MLflow does not verify the TLS connection, meaning it does not validate certificates or hostnames for https:\/\/ tracking URIs. This flag is not recommended for production environments. If this is set to true then MLFLOW_TRACKING_SERVER_CERT_PATH must not be set.<\/li>\n<li>MLFLOW_TRACKING_SERVER_CERT_PATH - Path to a CA bundle to use. Sets the verify param of the requests.request function (see <a href=\"https:\/\/requests.readthedocs.io\/en\/master\/api\/\" rel=\"nofollow noreferrer\">https:\/\/requests.readthedocs.io\/en\/master\/api\/<\/a>). When you use a self-signed server certificate you can use this to verify it on client side. If this is set MLFLOW_TRACKING_INSECURE_TLS must not be set (false).<\/li>\n<li>MLFLOW_TRACKING_CLIENT_CERT_PATH - Path to ssl client cert file (.pem). Sets the cert param of the requests.request function (see <a href=\"https:\/\/requests.readthedocs.io\/en\/master\/api\/\" rel=\"nofollow noreferrer\">https:\/\/requests.readthedocs.io\/en\/master\/api\/<\/a>). This can be used to use a (self-signed) client certificate.<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-11 13:44:58.58 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"authentication|kerberos|mlflow|spnego",
        "Question_view_count":25,
        "Owner_creation_date":"2018-09-07 16:23:40.893 UTC",
        "Owner_last_access_date":"2022-09-04 09:09:48.817 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73321771",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63395148,
        "Question_title":"MLflow conda_env offline environment",
        "Question_body":"<p>We want to use the <a href=\"https:\/\/mlflow.org\/docs\/latest\/projects.html#mlproject-file\" rel=\"nofollow noreferrer\">MLproject <code>conda_env<\/code><\/a> feature in an offline environment, in order to reproduce the models in various computers.<\/p>\n<p>When running on an internet connected computer we see that the <code>conda environment<\/code> is created by downloading the packages from anaconda.<\/p>\n<ol>\n<li>Is there an option to run <code>MLflow run .<\/code> with an <code>MLproject<\/code> file that will use an <strong>existing conda environment<\/strong>? (without creating a new one based on the <code>conda.yaml<\/code> file). Setting the <a href=\"https:\/\/mlflow.org\/docs\/latest\/projects.html#project-environments\" rel=\"nofollow noreferrer\">MLFLOW_CONDA_HOME<\/a> environment just points to the location folder where to create the environment. But I can't find how to specify an existing environment.<\/li>\n<li>If Is there an option to point to a <a href=\"https:\/\/conda.github.io\/conda-pack\/\" rel=\"nofollow noreferrer\">conda pack<\/a> file?<\/li>\n<\/ol>\n<p><strong>UPDATE<\/strong><br \/>\nI guess this <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/2984\" rel=\"nofollow noreferrer\">github issue<\/a> is related<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-13 12:26:11.003 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-08-13 13:37:44.827 UTC",
        "Question_score":0,
        "Question_tags":"conda|mlflow",
        "Question_view_count":537,
        "Owner_creation_date":"2016-01-20 20:19:09.903 UTC",
        "Owner_last_access_date":"2022-09-11 19:40:57.297 UTC",
        "Owner_reputation":1153,
        "Owner_up_votes":113,
        "Owner_down_votes":14,
        "Owner_views":168,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Israel",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63395148",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67290963,
        "Question_title":"How to explicitly define the AWS credentials for MLFlow when using AWS S3 as artifact store",
        "Question_body":"<p>so I'm using a MLFlow tracking server where I define a S3 bucket to be the artifact stores. Right now, MLFlow by default is getting the credentials to write\/read the bucket via my <code>default<\/code> profile in <code>.aws\/credentials<\/code> but I do have a <code>staging<\/code> and <code>dev<\/code> profile as well. So my question is is there a way to explicitly tells MLFlow to use the <code>staging<\/code> or <code>dev<\/code> profile credentials instead of <code>default<\/code>? I can't seem to find this info anywhere. Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-27 21:34:30.29 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"amazon-s3|mlflow",
        "Question_view_count":1132,
        "Owner_creation_date":"2016-11-02 19:47:53.16 UTC",
        "Owner_last_access_date":"2021-11-05 19:47:27.24 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67290963",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73456259,
        "Question_title":"Pins + Vetiver vs MLflow which one to choose for MLOps",
        "Question_body":"<p>I am a big fan boy of <code>tidymodels<\/code> and played around with <code>vetiver<\/code> + <code>pins<\/code> in <code>R<\/code> and <code>Python<\/code> in order to not only develop models but actually deploy them.<\/p>\n<p>However, if you are looking for tools that support in the area of MLOps, sooner or later you will stumble across <code>MLflow<\/code>. Just like <code>vetiver<\/code> + <code>pins<\/code>, <code>MLflow<\/code> helps to track and deploy models and to build a model registry.\nI see some pros for <code>vetiver<\/code> like:<\/p>\n<ul>\n<li>you can directly dockerize a model or create a REST service<\/li>\n<li><code>vetiver<\/code>+ <code>pins<\/code> is very, very easy to use and does not require a lot of setup<\/li>\n<\/ul>\n<p>At this point, I'd like to ask the community if there are any other advantages of <code>vetiver<\/code> + <code>pins<\/code> over <code>MLflow<\/code> or is it advisable to use <code>MLflow<\/code> directly, since it is completely agnostic regarding the programming language and already has a very large community?\nMany thanks for your answers! M.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-08-23 09:29:57.483 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2022-08-24 10:12:25.713 UTC",
        "Question_score":0,
        "Question_tags":"mlflow|tidymodels|mlops|pins|vetiver",
        "Question_view_count":90,
        "Owner_creation_date":"2020-07-12 20:27:53.933 UTC",
        "Owner_last_access_date":"2022-09-23 10:34:10.827 UTC",
        "Owner_reputation":97,
        "Owner_up_votes":13,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73456259",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72516775,
        "Question_title":"I expose ports in docker but it does not connect",
        "Question_body":"<p>I have a simple docker image (I post the Dockerfile at the end) and I run it with<\/p>\n<pre><code>docker run -p 8888:8888 -p 5000:5000 -v $(pwd):\/workfolder -it --rm stockpred\n<\/code><\/pre>\n<p>I am expecting to expose the ports 8888 and 5000.<\/p>\n<p>Inside the container I do:<\/p>\n<pre><code>(base) root@41131b74043f:\/workfolder# mlflow ui\n[2022-06-06 10:59:24 +0000] [26] [INFO] Starting gunicorn 20.1.0\n[2022-06-06 10:59:24 +0000] [26] [INFO] Listening at: http:\/\/127.0.0.1:5000 (26)\n[2022-06-06 10:59:24 +0000] [26] [INFO] Using worker: sync\n[2022-06-06 10:59:24 +0000] [27] [INFO] Booting worker with pid: 27\n<\/code><\/pre>\n<p>so I go and open that address in my browser but I got<\/p>\n<p>The connection was reset<\/p>\n<blockquote>\n<p>The connection to the server was reset while the page was loading.<\/p>\n<pre><code>The site could be temporarily unavailable or too busy. Try again in a few moments.\nIf you are unable to load any pages, check your computer\u2019s network connection.\nIf your computer or network is protected by a firewall or proxy, make sure that Firefox is permitted to access the Web.\n<\/code><\/pre>\n<\/blockquote>\n<p>I thought that I could open the page externally. It must be something I am missing but what am I doing wrong?<\/p>\n<pre><code>FROM continuumio\/miniconda3\n\nRUN pip install mlflow&gt;=1.18.0 \\\n    &amp;&amp; pip install numpy \\\n    &amp;&amp; pip install scipy \\\n    &amp;&amp; pip install pandas \\\n    &amp;&amp; pip install scikit-learn \\\n    &amp;&amp; pip install cloudpickle \\\n    &amp;&amp; pip install pandas_datareader==0.10.0 \\\n    &amp;&amp; pip install yfinance\n<\/code><\/pre>\n<p>EDIT:<\/p>\n<p>It worked when I did<\/p>\n<pre><code>docker run --network=&quot;host&quot; -p 8888:8888 -p 5000:5000 -v $(pwd):\/workfolder -it --rm stockpred\n<\/code><\/pre>\n<p>Notice that I did not expose the ports in the Dockerfile.<\/p>\n<p>Can someone explain me why this is working like this?<\/p>\n<p>(I also tried exposing the ports in the Dockerfile and running like originally but it didn't work)<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2022-06-06 11:09:46.37 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-06-06 11:56:50.19 UTC",
        "Question_score":0,
        "Question_tags":"docker|mlflow",
        "Question_view_count":121,
        "Owner_creation_date":"2015-01-14 01:17:49.333 UTC",
        "Owner_last_access_date":"2022-09-24 09:09:14.427 UTC",
        "Owner_reputation":5585,
        "Owner_up_votes":792,
        "Owner_down_votes":53,
        "Owner_views":1350,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72516775",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70383800,
        "Question_title":"How can I run Tensorboard with MLFlow's logs?",
        "Question_body":"<p>I use MLFlow with autolog to keep track of my Tensorflow models:<\/p>\n<pre><code>mlflow.tensorflow.autolog(every_n_iter=1)\nwith mlflow.start_run():\n  model = ...\n  model.compile(...)\n  model.fit(...)\n<\/code><\/pre>\n<p>and then I want to use my tensorboard logs located in the artifacts.\nBut when I run:<\/p>\n<pre><code>%tensorboard --logdir=&lt;logs_path&gt;\n<\/code><\/pre>\n<p>I have the error message:\n&quot;No dashboards are active for the current data set.\nProbable causes:<\/p>\n<p>You haven\u2019t written any data to your event files.\nTensorBoard can\u2019t find your event files.&quot;<\/p>\n<p>I work on Databricks, so log_path is something like:<\/p>\n<pre><code>\/dbfs\/databricks\/mlflow-tracking\/..\n<\/code><\/pre>\n<p>Any ideas?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-12-16 18:15:45.067 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"tensorflow|databricks|tensorboard|mlflow",
        "Question_view_count":501,
        "Owner_creation_date":"2021-12-16 18:03:10.923 UTC",
        "Owner_last_access_date":"2022-09-22 13:52:41.243 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70383800",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71262010,
        "Question_title":"Download model artefact from Databricks workspace",
        "Question_body":"<p>How can I download a mlflow model artefact in a docker container from databricks workspace?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-25 06:40:55.51 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-25 13:33:11.323 UTC",
        "Question_score":0,
        "Question_tags":"docker|databricks|azure-databricks|mlflow",
        "Question_view_count":370,
        "Owner_creation_date":"2014-09-22 04:46:57.027 UTC",
        "Owner_last_access_date":"2022-09-03 08:12:58.187 UTC",
        "Owner_reputation":569,
        "Owner_up_votes":41,
        "Owner_down_votes":3,
        "Owner_views":123,
        "Answer_body":"<p>To download a model from Databricks workspace you need to do two things:<\/p>\n<ol>\n<li><p>Set MLFlow tracking URI to databricks using python API<\/p>\n<\/li>\n<li><p>Setup databricks authentication. I prefer authenticating by setting the following environment variables, you can also use databricks CLI to authenticate:<\/p>\n<pre><code>DATABRICKS_HOST\n\nDATABRICKS_TOKEN\n<\/code><\/pre>\n<\/li>\n<li><p>Here's a basic code snippet to download a model from Databricks workspace model registry:<\/p>\n<pre><code>import os\nimport mlflow\nfrom mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n\nmodel_name = &quot;example-model-name&quot;\nmodel_stage = &quot;Staging&quot;  # Should be either 'Staging' or 'Production'\n\nmlflow.set_tracking_uri(&quot;databricks&quot;)\n\nos.makedirs(&quot;model&quot;, exist_ok=True)\nlocal_path = ModelsArtifactRepository(\n    f'models:\/{model_name}\/{model_stage}').download_artifacts(&quot;&quot;, dst_path=&quot;model&quot;)\n\nprint(f'{model_stage} Model {model_name} is downloaded at {local_path}')\n<\/code><\/pre>\n<p>Running above python script will download an ML model in the model directory.<\/p>\n<p><strong>Containerizing MLFlow model serving with Docker<\/strong><\/p>\n<p>The next step is to package this downloaded model in a docker image and serve a model when you run the image.<\/p>\n<\/li>\n<\/ol>\n<p>Here's a basic Dockerfile to do the same:<\/p>\n<pre><code>FROM continuumio\/miniconda3\n\nENV MLFLOW_HOME \/opt\/mlflow\nENV MLFLOW_VERSION 1.12.1\nENV PORT 5000\n\nRUN conda install -c conda-forge mlflow=${MLFLOW_VERSION}\n\nCOPY model\/ ${MLFLOW_HOME}\/model\n\nWORKDIR ${MLFLOW_HOME}\n\nRUN mlflow models prepare-env -m ${MLFLOW_HOME}\/model\n\nRUN useradd -d ${MLFLOW_HOME} mlflow\nRUN chown mlflow: ${MLFLOW_HOME}\nUSER mlflow\n\nCMD mlflow models serve -m ${MLFLOW_HOME}\/model --host 0.0.0.0 --port ${PORT}\n<\/code><\/pre>\n<p>For more information you can follow this <a href=\"https:\/\/dev.to\/itachiredhair\/downloading-mlflow-model-from-databricks-and-serving-with-docker-38ip\" rel=\"nofollow noreferrer\">article<\/a> from Akshay Milmile<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2022-02-25 08:12:59.603 UTC",
        "Answer_score":2.0,
        "Owner_location":"Bengaluru, Karnataka, India",
        "Answer_last_edit_date":"2022-02-25 13:32:17.627 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71262010",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":51079061,
        "Question_title":"Unable to access to mlflow ui",
        "Question_body":"<p>By following quickstart and tutorial at <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/quickstart.html\" rel=\"noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/quickstart.html<\/a>, and <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/tutorial.html\" rel=\"noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/tutorial.html<\/a>, the execution of train.py works fine. <\/p>\n\n<pre><code>Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n  RMSE: 0.8222428497595403\n  MAE: 0.6278761410160693\n  R2: 0.12678721972772622\n<\/code><\/pre>\n\n<p>But when launching the ui <code>mlflow ui<\/code>, and accessing to the web page localhost:5000, the browser complains <\/p>\n\n<pre><code>Not Found\n\nThe requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.\n<\/code><\/pre>\n\n<p>What went wrong and how to fix this? <\/p>\n\n<p>Thanks<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_creation_date":"2018-06-28 09:16:37.51 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":5,
        "Question_tags":"python|python-3.x|mlflow",
        "Question_view_count":7497,
        "Owner_creation_date":"2018-05-07 11:18:44.777 UTC",
        "Owner_last_access_date":"2018-07-06 14:40:51.58 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/51079061",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70774084,
        "Question_title":"How to use mlflow.log_params to append params when used alongside mlflow.autolog()",
        "Question_body":"<p>I am using mlflow.autolog() to log params and metrics for a tensorflow based training and it works well. It captures 26 different parameters automatically.\nHowever if I use mlflow.log_params() to log custom params those 26 are not being logged anymore. I am wondering if there is a way to append params alongside regular params?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-01-19 16:16:30.92 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":149,
        "Owner_creation_date":"2015-10-06 10:55:49.56 UTC",
        "Owner_last_access_date":"2022-07-08 04:01:26.25 UTC",
        "Owner_reputation":51,
        "Owner_up_votes":6,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70774084",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68622242,
        "Question_title":"Copying Experiments from a MLFlow server to another MLFlow server",
        "Question_body":"<p>I have a user in a Linux machine and I run a mlflow server from this user. Artifacts are stored in local mlruns folder. Lets call this user as user A. Then I run another mlflow server from another Linux user and call this user as user B. I wanted to move older experiments that resides in mlruns directory of user A to mlflow that run in user B. I simply moved mlruns directory of user A to the home directory of user B and run mlflow from there again. When I accessed to mlflow UI by browser I saw that artifact location is configured correctly to mlruns folder of user B, but I couldn't see the experiments that moved from user A's mlruns directory. How can I see them in the UI too?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-02 13:14:04.223 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":303,
        "Owner_creation_date":"2018-08-02 10:29:26.067 UTC",
        "Owner_last_access_date":"2022-09-14 12:43:17.12 UTC",
        "Owner_reputation":275,
        "Owner_up_votes":167,
        "Owner_down_votes":2,
        "Owner_views":85,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"\u0130stanbul, T\u00fcrkiye",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68622242",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56194788,
        "Question_title":"In MLflow project using docker environment, how to setup aws credentials",
        "Question_body":"<p>I am working on using 'MLflow' project and one use case is like this.<\/p>\n\n<pre><code>The MLflow running target\/environment is docker.\nData lives on aws s3\nWhen developing on a laptop. The laptop has an aws profile to access data. \n(When developing on EC2, the EC2 have role attached to access s3) \n<\/code><\/pre>\n\n<p>Currently, I have credentials stored on the host as '~\/.aws\/credential', and can access s3 in the host. Question is: In MLflow project, how do I make program running on docker access s3 files? <\/p>\n\n<p>Note that the question is not \"in general\" how to setup docker. The question is the recommended way to do the aws setup\/configuration in a MLflow project. Thanks!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-17 23:41:22.55 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-06-11 07:41:03.49 UTC",
        "Question_score":1,
        "Question_tags":"docker|amazon-s3|amazon-ec2|mlflow",
        "Question_view_count":495,
        "Owner_creation_date":"2013-12-11 04:18:22.123 UTC",
        "Owner_last_access_date":"2022-09-23 23:07:48.663 UTC",
        "Owner_reputation":3405,
        "Owner_up_votes":641,
        "Owner_down_votes":8,
        "Owner_views":1094,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56194788",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60531166,
        "Question_title":"How to safely shutdown mlflow ui?",
        "Question_body":"<p>After running <code>mlflow ui<\/code> on a remote server, I'm unable to reopen the <code>mlflow ui<\/code> again.<br>\nA workaround is to kill all my processes in the server using <code>pkill -u MyUserName<\/code>.<br>\nOtherwise I get the following error:  <\/p>\n\n<pre><code>[INFO] Starting gunicorn 20.0.4  \n[ERROR] Connection in use: ('127.0.0.1', 5000)\n[ERROR] Retrying in 1 second.  \n...\nRunning the mlflow server failed. Please see ther logs above for details.\n<\/code><\/pre>\n\n<p>I understand the error but I don't understand:<br>\n1. What is the correct way to shutdown <code>mlflow ui<\/code><br>\n2. How can I identify the <code>mlflow ui<\/code> process in order to only kill that process and not use the <code>pkill<\/code>  <\/p>\n\n<p>Currently I close the browser or use ctrl+C <\/p>",
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-04 17:00:47.02 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2021-08-31 18:18:00.327 UTC",
        "Question_score":6,
        "Question_tags":"python|r|machine-learning|mlflow",
        "Question_view_count":9850,
        "Owner_creation_date":"2016-01-20 20:19:09.903 UTC",
        "Owner_last_access_date":"2022-09-11 19:40:57.297 UTC",
        "Owner_reputation":1153,
        "Owner_up_votes":113,
        "Owner_down_votes":14,
        "Owner_views":168,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Israel",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60531166",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66152375,
        "Question_title":"MLFlow active run does not match environment run id",
        "Question_body":"<p>I am trying to perform an MLFlow run but stuck with the following error after trying a lot of things.<\/p>\n<pre><code>\nrun = mlflow.active_run()\nif run:\n    print(&quot;Active run_id: {}&quot;.format(run.info.run_id))\n    mlflow.end_run()\n\nmlflow.set_experiment('TNF_EXP') \nmlflow.set_tracking_uri(&quot;http:\/\/localhost:5000\/&quot;) # Actual Server URI instead of localhost\nexperiment = mlflow.get_experiment_by_name(&quot;TNF_EXP&quot;)\n\nwith mlflow.start_run(experiment_id=experiment.experiment_id) as run:\n...\n...\n\nmlflow.end_run()\n<\/code><\/pre>\n<p>Error -<\/p>\n<pre><code>File &quot;\/...\/ModelTrainer.py&quot;, line 108, in train\n    with mlflow.start_run(experiment_id=experiment.experiment_id) as run:\n  File &quot;\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 207, in start_run\n    &quot;arguments&quot;.format(existing_run_id)\nmlflow.exceptions.MlflowException: Cannot start run with ID e9953eb5918845bb9be1xxxxxx because active run ID does not match environment run ID. Make sure --experiment-name or --experiment-id matches experiment set with set_experiment(), or just use command-line arguments\n2021\/02\/11 09:41:36 ERROR mlflow.cli: === Run (ID 'e9953eb5918845bb9be1xxxxxx') failed ===\n<\/code><\/pre>\n<p>I noticed I had an <code>active run<\/code> earlier so I included the first <code>if block<\/code> to end that run. The code ran successfully and I was able to log the data on MLFlow UI but now when I run it I start getting the same issue. There are no active runs found before starting a new run currently.<\/p>\n<blockquote>\n<p>FYI, I am running the code on Azure server with the respective tracking URI mentioned in the code.<\/p>\n<\/blockquote>\n<p>However the code runs fine if I include an argument <code>--experiment-name=&quot;TNF_EXP&quot;<\/code> in the <code>mlflow run<\/code> command on the CLI<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-02-11 09:55:19.843 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|mlflow",
        "Question_view_count":4094,
        "Owner_creation_date":"2019-06-06 12:06:56.093 UTC",
        "Owner_last_access_date":"2022-09-19 19:12:46.643 UTC",
        "Owner_reputation":861,
        "Owner_up_votes":117,
        "Owner_down_votes":6,
        "Owner_views":149,
        "Answer_body":"<p>That is primarily because you have started a run with <code>default experiment name<\/code> and then you are trying to set the <code>experiment_name<\/code> as &quot;TNF_EXP&quot;.<\/p>\n<p>Will suggest you to make use of <code>mlflow.run(..., experiment_name=&quot;TNF_EXP&quot;)<\/code> python method then running it from the <code>CLI<\/code>.<\/p>\n<p>You can find more information <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.run\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-03-25 07:27:52.013 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66152375",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60667610,
        "Question_title":"How to deploy mlflow model with data preprocessing(text data)",
        "Question_body":"<p>I have developed keras text classification model. I have preprocessed data(tokenization). I have logged trained model successfully(mlflow.keras.log_model). I have served model using mlflow serve. Now while doing prediction on text data I need to do preprocessing using same tokenizer object used for training.\nHow to preprocess test data and get predictions from served model.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-03-13 09:08:37.703 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":1996,
        "Owner_creation_date":"2017-06-26 09:55:36.987 UTC",
        "Owner_last_access_date":"2021-03-05 03:19:48.693 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":"<p>You can log a custom python model: \n<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#custom-python-models\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/models.html#custom-python-models<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-03-18 17:25:58.667 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60667610",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62664183,
        "Question_title":"MLflow: find model version with best metric using python code",
        "Question_body":"<p>I am trying to use API workflow (python code) to find a model version that has the best metric (for instance, \u201caccuracy\u201d) among several model versions. I understand we can use web UI to do so, but I would love to write python code to achieve this. Could someone help me?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-06-30 18:44:19.82 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"python|mlflow",
        "Question_view_count":445,
        "Owner_creation_date":"2014-12-26 18:42:31.727 UTC",
        "Owner_last_access_date":"2022-02-07 21:07:16.15 UTC",
        "Owner_reputation":125,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":"<pre><code>import mlflow \nclient = mlflow.tracking.MlflowClient()\nruns = client.search_runs(&quot;my_experiment_id&quot;, &quot;&quot;, order_by=[&quot;metrics.rmse DESC&quot;], max_results=1)\nbest_run = runs[0]\n<\/code><\/pre>\n<p><a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.search_runs\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.search_runs<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-07-23 05:03:25.94 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62664183",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71408963,
        "Question_title":"Getting `dtype of input object does not match expected dtype <U0` when invoking MLflow-deployed NLP model in SageMaker",
        "Question_body":"<p>I deployed a Huggingface Transformer model in SageMaker using MLflow's <code>sagemaker.deploy()<\/code>.<\/p>\n<p>When logging the model I used <code>infer_signature(np.array(test_example), loaded_model.predict(test_example))<\/code> to infer input and output signatures.<\/p>\n<p>Model is deployed successfully. When trying to query the model I get <code>ModelError<\/code> (full traceback below).<\/p>\n<p>To query the model, I am using precisely the same <code>test_example<\/code> that I used for <code>infer_signature()<\/code>:<\/p>\n<p><code>test_example = [['This is the subject', 'This is the body']]<\/code><\/p>\n<p>The only difference is that when querying the deployed model, I am not wrapping the test example in <code>np.array()<\/code> as that is not <code>json<\/code>-serializeable.<\/p>\n<p>To query the model I tried two different approaches:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import boto3\n\nSAGEMAKER_REGION = 'us-west-2'\nMODEL_NAME = '...'\n\nclient = boto3.client(&quot;sagemaker-runtime&quot;, region_name=SAGEMAKER_REGION)\n\n# Approach 1\nclient.invoke_endpoint(\n                EndpointName=MODEL_NAME,\n                Body=json.dumps(test_example),\n                ContentType=&quot;application\/json&quot;,\n            )\n\n# Approach 2\nclient.invoke_endpoint(\n                EndpointName=MODEL_NAME,\n                Body=pd.DataFrame(test_example).to_json(orient=&quot;split&quot;),\n                ContentType=&quot;application\/json; format=pandas-split&quot;,\n            )\n<\/code><\/pre>\n<p>but they result in the same error.<\/p>\n<p>Will be grateful for your suggestions.<\/p>\n<p>Thank you!<\/p>\n<p>Note: I am using Python 3 and all <strong>strings are unicode<\/strong>.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>---------------------------------------------------------------------------\nModelError                                Traceback (most recent call last)\n&lt;ipython-input-89-d09862a5f494&gt; in &lt;module&gt;\n      2                 EndpointName=MODEL_NAME,\n      3                 Body=test_example,\n----&gt; 4                 ContentType=&quot;application\/json; format=pandas-split&quot;,\n      5             )\n\n~\/anaconda3\/envs\/amazonei_tensorflow_p36\/lib\/python3.6\/site-packages\/botocore\/client.py in _api_call(self, *args, **kwargs)\n    393                     &quot;%s() only accepts keyword arguments.&quot; % py_operation_name)\n    394             # The &quot;self&quot; in this scope is referring to the BaseClient.\n--&gt; 395             return self._make_api_call(operation_name, kwargs)\n    396 \n    397         _api_call.__name__ = str(py_operation_name)\n\n~\/anaconda3\/envs\/amazonei_tensorflow_p36\/lib\/python3.6\/site-packages\/botocore\/client.py in _make_api_call(self, operation_name, api_params)\n    723             error_code = parsed_response.get(&quot;Error&quot;, {}).get(&quot;Code&quot;)\n    724             error_class = self.exceptions.from_code(error_code)\n--&gt; 725             raise error_class(parsed_response, operation_name)\n    726         else:\n    727             return parsed_response\n\nModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message &quot;{&quot;error_code&quot;: &quot;BAD_REQUEST&quot;, &quot;message&quot;: &quot;dtype of input object does not match expected dtype &lt;U0&quot;}&quot;. See https:\/\/us-west-2.console.aws.amazon.com\/cloudwatch\/home?region=us-west-2#logEventViewer:group=\/aws\/sagemaker\/Endpoints\/bec-sagemaker-model-test-app in account 543052680787 for more information.\n<\/code><\/pre>\n<p>Environment info:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>{'channels': ['defaults', 'conda-forge', 'pytorch'],\n 'dependencies': ['python=3.6.10',\n  'pip==21.3.1',\n  'pytorch=1.10.2',\n  'cudatoolkit=10.2',\n  {'pip': ['mlflow==1.22.0',\n    'transformers==4.17.0',\n    'datasets==1.18.4',\n    'cloudpickle==1.3.0']}],\n 'name': 'bert_bec_test_env'}\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-09 11:56:29.87 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-03-09 14:44:47.963 UTC",
        "Question_score":0,
        "Question_tags":"amazon-web-services|nlp|amazon-sagemaker|mlflow",
        "Question_view_count":61,
        "Owner_creation_date":"2017-03-23 13:26:01.927 UTC",
        "Owner_last_access_date":"2022-09-22 20:27:37.72 UTC",
        "Owner_reputation":83,
        "Owner_up_votes":30,
        "Owner_down_votes":0,
        "Owner_views":56,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Tel Aviv",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71408963",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73654072,
        "Question_title":"how to properly install mlflow in R studio?",
        "Question_body":"<p>I followed the official document but found error<\/p>\n<pre><code>&gt; install.package(&quot;mlflow&quot;)\nError in install.package(&quot;mlflow&quot;) : \n  could not find function &quot;install.package&quot;\n&gt; install.packages(&quot;mlflow&quot;)\nInstalling package into \u2018C:\/Users\/fzhu\/AppData\/Local\/R\/win-library\/4.2\u2019\n(as \u2018lib\u2019 is unspecified)\ntrying URL 'https:\/\/cran.rstudio.com\/bin\/windows\/contrib\/4.2\/mlflow_1.28.0.zip'\nContent type 'application\/zip' length 237435 bytes (231 KB)\ndownloaded 231 KB\n\npackage \u2018mlflow\u2019 successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\fzhu\\AppData\\Local\\Temp\\RtmpgzY6Uy\\downloaded_packages\n&gt; mlflow::install_mlflow()\nError in mlflow_conda_bin() : \n  Unable to find conda binary. Is Anaconda installed?\n  If you are not using conda, you can set the environment variable MLFLOW_PYTHON_BIN to the path of your python executable.\n&gt; Sys.getenv(&quot;MLFLOW_PYTHON_BIN&quot;)\n[1] &quot;C:\\\\py310\\\\python.exe&quot;\n&gt; Sys.getenv(&quot;MLFLOW_BIN&quot;)\n[1] &quot;C:\\\\py310\\\\Scripts\\\\mlflow&quot;\n\n<\/code><\/pre>\n<p>any help is appreciated!<\/p>\n<p>refer:\n<a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/6738\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/6738<\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_date":"2022-09-08 19:14:47.383 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"r|installation|rstudio|mlflow",
        "Question_view_count":27,
        "Owner_creation_date":"2013-11-04 03:19:11.877 UTC",
        "Owner_last_access_date":"2022-09-23 02:06:10.57 UTC",
        "Owner_reputation":502,
        "Owner_up_votes":24,
        "Owner_down_votes":1,
        "Owner_views":40,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73654072",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70516388,
        "Question_title":"Defining routes in MLflow serving",
        "Question_body":"<p>When we serve mlflow model we define different ports for each serving and to access these models we use IP:port\/invocations<\/p>\n<p>ex:<\/p>\n<p>app 1 : IP:2020\/invocations<\/p>\n<p>app 2 : IP:2021\/invocations<\/p>\n<p>But I want to serve 2 mlflow models at same port with different routes.<\/p>\n<p>ex:<\/p>\n<p>app 1 : IP:2020\/app1<\/p>\n<p>app 2 : IP:2020\/app2<\/p>\n<p>How can I achieve it using MLflow.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-29 07:32:38.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-12-30 05:36:53.347 UTC",
        "Question_score":0,
        "Question_tags":"python|routes|mlflow|serving",
        "Question_view_count":56,
        "Owner_creation_date":"2017-09-04 04:11:52.457 UTC",
        "Owner_last_access_date":"2022-09-21 08:05:37.62 UTC",
        "Owner_reputation":334,
        "Owner_up_votes":105,
        "Owner_down_votes":8,
        "Owner_views":24,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70516388",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69227917,
        "Question_title":"Connect MLflow server to minio in local",
        "Question_body":"<p>I am trying to connect mlflow with Minio server, both are running on my local machine, I am able to connect my client code to minio by adding the below lines to the code,<\/p>\n<pre><code>os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] =&quot;xxxx&quot;\nos.environ['AWS_SECRET_ACCESS_KEY'] =&quot;xxxxxx&quot; \nos.environ['MLFLOW_TRACKING_URI'] = 'http:\/\/localhost:5000'\n<\/code><\/pre>\n<p>But the mlflow server is not getting connected to Minio. To run Mlflow server, command I use:<\/p>\n<pre><code>mlflow server -h 0.0.0.0 -p 5000 --default-artifact-root s3:\/\/mlbucket --backend-store-uri sqlite:\/\/\/mlflow.db\n<\/code><\/pre>\n<p>The mlflow server runs, but while accessing the artifacts page the server, it throws the error:<\/p>\n<pre><code>raise NoCredentialsError()\nbotocore.exceptions.NoCredentialsError: Unable to locate credentials\n<\/code><\/pre>\n<p>So how can I pass the credentials of the Minio to the mlflow server command?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_creation_date":"2021-09-17 18:17:06.293 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|minio|mlflow",
        "Question_view_count":1136,
        "Owner_creation_date":"2011-07-17 08:59:45.21 UTC",
        "Owner_last_access_date":"2022-09-24 02:56:29.02 UTC",
        "Owner_reputation":2763,
        "Owner_up_votes":373,
        "Owner_down_votes":7,
        "Owner_views":851,
        "Answer_body":"<p>Just add the below environment variables:<\/p>\n<pre><code>export AWS_ACCESS_KEY_ID=&lt;your-aws-access-key-id&gt;\nexport AWS_SECRET_ACCESS_KEY = &lt;your-aws-secret-access-key&gt;\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-10-20 15:29:11.773 UTC",
        "Answer_score":1.0,
        "Owner_location":"Thiruvananthapuram, Kerala, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69227917",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72425907,
        "Question_title":"How to log a tensorflow model with mlflow.tensorflow.log_model (error module 'tensorflow._api.v2.saved_model' has no attribute 'tag_constants')",
        "Question_body":"<p>I am trying to log a trained model with MLFlow using mlflow.tensorflow.log_model.<\/p>\n<p>After training a simple sequential tf model<\/p>\n<pre><code>history = binary_model.fit(train_ds, validation_data=val_ds, epochs=num_epochs)\n<\/code><\/pre>\n<p>I am trying to log it:<\/p>\n<pre><code>    from tensorflow.python.saved_model import signature_constants\n    tag=[tf.saved_model.tag_constants.SERVING]\n    key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n\n    mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path,\n                                tf_meta_graph_tags=tag,\n                                tf_signature_def_key=key,\n                                artifact_path=&quot;tf-models&quot;,\n                                registered_model_name=model_name)\n<\/code><\/pre>\n<p>but I get the error:<\/p>\n<pre><code>    AttributeError                            Traceback (most recent call last)\n    \/var\/folders\/2k\/g7p7j2gx6v54vkwv3v401h2m0000gn\/T\/ipykernel_73638\/562549064.py in &lt;module&gt;\n          1 from tensorflow.python.saved_model import signature_constants\n    ----&gt; 2 tag=[tf.saved_model.tag_constants.SERVING]\n          3 key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n          4 \n          5 mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path,\n\n    AttributeError: module 'tensorflow._api.v2.saved_model' has no attribute 'tag_constants'\n<\/code><\/pre>\n<p>Any idea how to get the tags and keys correctly from the model to log it in MLFlow?<\/p>\n<p>Many thanks in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-05-29 17:36:29.63 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|tensorflow|mlflow",
        "Question_view_count":319,
        "Owner_creation_date":"2013-05-22 19:51:34.28 UTC",
        "Owner_last_access_date":"2022-09-21 19:50:10.223 UTC",
        "Owner_reputation":324,
        "Owner_up_votes":57,
        "Owner_down_votes":0,
        "Owner_views":32,
        "Answer_body":"<p>The <code>tag_constants<\/code> is in <code>tf.compat.v1.saved_model<\/code>.<\/p>\n<p>To resolve the error replace this line<\/p>\n<pre><code>tag=[tf.saved_model.tag_constants.SERVING]\n<\/code><\/pre>\n<p>with this<\/p>\n<pre><code>tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n<\/code><\/pre>\n<p>Please refer <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/compat\/v1\/saved_model\/tag_constants\" rel=\"nofollow noreferrer\">this<\/a> for more details.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-06-13 04:29:29.433 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72425907",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71151054,
        "Question_title":"How to log a table of metrics into mlflow",
        "Question_body":"<p>I am trying to see if mlflow is the right place to store my metrics in the model tracking.  According to the doc log_metric takes either a key value or a dict of key-values.  I am wondering how to log something like below into mlflow so it can be visualized meaningfully.<\/p>\n<pre><code>          precision    recall  f1-score   support\n\n  class1       0.89      0.98      0.93       174\n  class2       0.96      0.90      0.93        30\n  class3       0.96      0.90      0.93        30\n  class4       1.00      1.00      1.00         7\n  class5       0.93      1.00      0.96        13\n  class6       1.00      0.73      0.85        15\n  class7       0.95      0.97      0.96        39\n  class8       0.80      0.67      0.73         6\n  class9       0.97      0.86      0.91        37\n class10       0.95      0.81      0.88        26\n class11       0.50      1.00      0.67         5\n class12       0.93      0.89      0.91        28\n class13       0.73      0.84      0.78        19\n class14       1.00      1.00      1.00         6\n class15       0.45      0.83      0.59         6\n class16       0.97      0.98      0.97       245\n class17       0.93      0.86      0.89       206\n\naccuracy                           0.92       892\n<\/code><\/pre>\n<p>macro avg       0.88      0.90      0.88       892\nweighted avg       0.93      0.92      0.92       892<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-02-17 00:35:43.563 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":546,
        "Owner_creation_date":"2015-03-18 00:41:20.947 UTC",
        "Owner_last_access_date":"2022-04-21 20:46:05.3 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71151054",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68155750,
        "Question_title":"Mlflow - empty artifact folder",
        "Question_body":"<p>All,<\/p>\n<p>I started the <strong>mlflow server<\/strong> as below. I do see the <strong>backend store<\/strong> containing the expected metadata. However, the <strong>artifact folder<\/strong> is <em><strong>empty<\/strong><\/em> despite many runs.<\/p>\n<pre><code>&gt; mlflow server --backend-store-uri mlflow_db --default-artifact-root\n&gt; .\/mlflowruns --host 0.0.0.0 --port 5000\n<\/code><\/pre>\n<p>The mlflow ui has the below message for the artifacts section:<\/p>\n<blockquote>\n<pre><code>              No Artifacts Recorded\n Use the log artifact APIs to store file outputs from MLflow runs.\n<\/code><\/pre>\n<\/blockquote>\n<p>What am I doing wrong?<\/p>\n<p>Thanks,\ngrajee<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2021-06-27 22:26:29.703 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python-3.x|mlflow",
        "Question_view_count":599,
        "Owner_creation_date":"2018-02-07 01:32:14.63 UTC",
        "Owner_last_access_date":"2022-06-26 08:34:21.763 UTC",
        "Owner_reputation":340,
        "Owner_up_votes":41,
        "Owner_down_votes":1,
        "Owner_views":110,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68155750",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59773167,
        "Question_title":"When will experiment be deleted with lifecycle_stage is set as deleted",
        "Question_body":"<p>I can see experiment 2 is in deleted, but when it will be deleted actually?<\/p>\n\n<pre><code>2   test    hdfs:\/\/\/1234\/mlflow deleted\n<\/code><\/pre>\n\n<p>If the experiment is not deleted automatically, how can I delete it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-16 15:41:36.547 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":412,
        "Owner_creation_date":"2014-08-18 14:07:01.673 UTC",
        "Owner_last_access_date":"2022-09-15 04:40:38.707 UTC",
        "Owner_reputation":2521,
        "Owner_up_votes":447,
        "Owner_down_votes":13,
        "Owner_views":197,
        "Answer_body":"<p>I am assuming you use sql store?<\/p>\n\n<p>Currently there is no way to tell mlflow to hard-delete experiments. We are working with open source contributors to add a cli command that would perform garbage-collection of deleted experiments. This should be added soon in one of the upcoming mlflow releases. In the meantime, you can connect to your sql store and delete the experiments manually.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-01-22 23:47:09.917 UTC",
        "Answer_score":1.0,
        "Owner_location":"Berlin, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59773167",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73320708,
        "Question_title":"Set run description programmatically in mlflow",
        "Question_body":"<p>Similar to <a href=\"https:\/\/stackoverflow.com\/questions\/57199472\/is-it-possible-to-set-change-mlflow-run-name-after-run-initial-creation#:%7E:text=It%20is%20possible%20to%20edit,you%27d%20like%20to%20edit.&amp;text=There%27s%20currently%20no%20stable%20public,the%20tag%20with%20key%20mlflow.\">this question<\/a>, I'd like to edit\/set the description of a run via code, instead of editing it via UI.<\/p>\n<p>To clarify, I don't want to set the description of my entire experiment, only of a single run.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ogUgu.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ogUgu.png\" alt=\"Image showing what I want to edit\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-11 12:32:23.727 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|artificial-intelligence|mlflow",
        "Question_view_count":89,
        "Owner_creation_date":"2018-05-28 16:43:18.183 UTC",
        "Owner_last_access_date":"2022-09-24 22:46:27.093 UTC",
        "Owner_reputation":736,
        "Owner_up_votes":829,
        "Owner_down_votes":8,
        "Owner_views":57,
        "Answer_body":"<p>There are two ways to set the description.<\/p>\n<h3>1. <code>description<\/code> parameter<\/h3>\n<p>You can set a description using a markdown string for your run in <code>mlflow.start_run()<\/code> using <code>description<\/code> parameter. Here is an example.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>if __name__ == &quot;__main__&quot;:\n    # load dataset and other stuff\n\n    run_description = &quot;&quot;&quot;\n### Header\nThis is a test **Bold**, *italic*, ~~strikethrough~~ text.\n[And this is an example hayperlink](http:\/\/example.com\/).\n    &quot;&quot;&quot;\n\n    with mlflow.start_run(description=run_description) as run:\n        # train model and other stuff\n<\/code><\/pre>\n<h3>2. <code>mlflow.note.content<\/code> tag<\/h3>\n<p>You can set\/edit run names by setting the tag with the key <code>mlflow.note.content<\/code>, which is what the UI (currently) does under the hood.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>if __name__ == &quot;__main__&quot;:\n    # load dataset and other stuff\n\n    run_description = &quot;&quot;&quot;\n### Header\nThis is a test **Bold**, *italic*, ~~strikethrough~~ text.\n[And this is an example hayperlink](http:\/\/example.com\/).\n    &quot;&quot;&quot;\n\n    tags = {\n        'mlflow.note.content': run_description\n    }\n\n    with mlflow.start_run(tags=tags) as run:\n        # train model and other stuff\n<\/code><\/pre>\n<h3>Result<\/h3>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4zZa9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4zZa9.png\" alt=\"output of the given example\" \/><\/a><\/p>\n<hr \/>\n<p>If you set <code>description<\/code> parameter and <code>mlflow.note.content<\/code> tag in <code>mlflow.start_run()<\/code>, you'll get this error.<\/p>\n<pre><code>Description is already set via the tag mlflow.note.content in tags.\nRemove the key mlflow.note.content from the tags or omit the description.\n<\/code><\/pre>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2022-08-11 15:21:04.753 UTC",
        "Answer_score":1.0,
        "Owner_location":"Sarajevo, Bosnia and Herzegovina",
        "Answer_last_edit_date":"2022-08-12 12:36:55.687 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73320708",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58452063,
        "Question_title":"How to integrate mlflow with tensorflow object detection api",
        "Question_body":"<p>I am trying to use the <strong>mlflow.tensorflow.autolog()<\/strong> with <a href=\"https:\/\/github.com\/tensorflow\/models\/tree\/master\/research\/object_detection\" rel=\"nofollow noreferrer\">tensorflow object detection api<\/a>. Adding <strong>mlflow.tensorflow.autolog()<\/strong> to <strong><a href=\"https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/model_main.py\" rel=\"nofollow noreferrer\">model_main.py<\/a><\/strong> logs some parameters like global_norm\/clipped_gradient_norm,global_norm\/gradient_norm,global_step\/sec,learning_rate_1,loss_1,loss_2 in mlflow. However the more important metrics like map,precision,recall are not being logged in mlfow.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-10-18 13:38:39.713 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-10-25 07:38:09.043 UTC",
        "Question_score":3,
        "Question_tags":"python|tensorflow|object-detection-api|mlflow",
        "Question_view_count":882,
        "Owner_creation_date":"2017-10-12 07:35:46.993 UTC",
        "Owner_last_access_date":"2022-01-03 18:02:21.733 UTC",
        "Owner_reputation":101,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58452063",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70968664,
        "Question_title":"How to run data bricck notebook with mlflow in azure data factory pipeline?",
        "Question_body":"<p>My colleagues and I are facing an issue when trying to run my databricks notebook in Azure Data Factory and the error is coming from MLFlow.<\/p>\n<p>The command that is failing is the following:<\/p>\n<pre><code># Take the parent notebook path to use as path for the experiment\ncontext = json.loads(dbutils.notebook.entry_point.getDbutils().notebook().getContext().toJson())\nnb_base_path = context['extraContext']['notebook_path'][:-len(&quot;00_training_and_validation&quot;)]\n\nexperiment_path = nb_base_path + 'trainings'\nmlflow.set_experiment(experiment_path)\nexperiment = mlflow.get_experiment_by_name(experiment_path)\nexperiment_id = experiment.experiment_id\n\nrun = mlflow.start_run(experiment_id=experiment_id, run_name=f&quot;run_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}&quot;)\n<\/code><\/pre>\n<p>And the error that is throwing is:<\/p>\n<p>An exception was thrown from a UDF: 'mlflow.exceptions.RestException: INVALID_PARAMETER_VALUE: No experiment ID was specified. An experiment ID must be specified in Databricks Jobs and when logging to the MLflow server from outside the Databricks workspace. If using the Python fluent API, you can set an active experiment under which to create runs by calling mlflow.set_experiment(&quot;\/path\/to\/experiment\/in\/workspace&quot;) at the start of your program.', from , line 32.<\/p>\n<p>The pipeline just runs the notebook from ADF, it does not have any other step and the cluster we are using is type 7.3 ML.<\/p>\n<p>Could you please help us?<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-03 09:23:02.26 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"azure-data-factory|databricks|mlflow",
        "Question_view_count":392,
        "Owner_creation_date":"2020-04-08 07:25:08.36 UTC",
        "Owner_last_access_date":"2022-02-03 09:43:32.287 UTC",
        "Owner_reputation":35,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Madrid, Spain",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70968664",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70931309,
        "Question_title":"How to retrieve the model signature from the MLflow Model Registry",
        "Question_body":"<p>I have registered a scikit learn model on my MLflow Tracking server, and I am loading it with <code>sklearn.load_model(model_uri)<\/code>.<\/p>\n<p>Now, I would like to access the signature of the model so I can get a list of the model's required inputs\/features so I can retrieve them from my feature store by name. I can't seem to find any utility or method in the <code>mlflow<\/code> API or the <code>MLFlowClient<\/code> API that will let me access a signature or inputs\/outputs attribute, even though I can see a list of inputs and outputs under each version of the model in the UI.<\/p>\n<p>I know that I can find the input sample and the model configuration in the model's artifacts, but that would require me actually downloading the artifacts and loading them manually in my script. I don't need to avoid that, but I am surprised that I can't just return the signature as a dictionary the same way I can return a run's parameters or metrics.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-31 18:51:28.92 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"mlflow",
        "Question_view_count":904,
        "Owner_creation_date":"2016-06-17 18:38:51.113 UTC",
        "Owner_last_access_date":"2022-09-22 17:49:54.303 UTC",
        "Owner_reputation":414,
        "Owner_up_votes":25,
        "Owner_down_votes":5,
        "Owner_views":39,
        "Answer_body":"<p>The way to access the model's signature without downloading the MLModel file is under the loaded model. And then you'll access the model's attributes, such as its signature or even other Pyfunc-defined methods.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\nmodel = mlflow.pyfunc.load_model(&quot;runs:\/&lt;run_id&gt;\/model&quot;)\nprint(model._model_meta._signature)\n<\/code><\/pre>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2022-02-21 18:56:57.663 UTC",
        "Answer_score":3.0,
        "Owner_location":"Michigan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70931309",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65922084,
        "Question_title":"AttributeError: module 'time' has no attribute 'clock' in MLFlow UI",
        "Question_body":"<p>I have successfully installed <strong>MLFlow<\/strong> using <code>pip install mlflow<\/code> but while running <code>mlflow ui<\/code> command in the console it gives the following <strong>error<\/strong><\/p>\n<pre><code>    time_func = time.clock\nAttributeError: module 'time' has no attribute 'clock'\n<\/code><\/pre>\n<p>I am aware of the fact that <code>time.clock<\/code> is deprecated for <code>Python v3.8<\/code> and above. How can I fix this, as I don't want to downgrade python version.<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_creation_date":"2021-01-27 15:19:26.83 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|python-datetime|python-dateutil|mlflow",
        "Question_view_count":589,
        "Owner_creation_date":"2020-12-23 08:27:44.26 UTC",
        "Owner_last_access_date":"2022-09-24 16:36:21.65 UTC",
        "Owner_reputation":66,
        "Owner_up_votes":33,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65922084",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63232368,
        "Question_title":"Storing mlflow artifacts to s3, while having SQL databse as backend",
        "Question_body":"<p>When using a SQL database as backend for <code>mlflow<\/code> are the artifacts stored in the same database or in default <code>.\/mlruns<\/code> directory?<\/p>\n<p>Is it possible to store them in different location as in AWS S3?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-08-03 15:29:20.843 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-08-04 09:44:39.3 UTC",
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":610,
        "Owner_creation_date":"2020-08-03 15:21:47.063 UTC",
        "Owner_last_access_date":"2021-06-29 08:56:40.15 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63232368",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70620074,
        "Question_title":"Serving multiple ML models using mlflow in a single VM",
        "Question_body":"<p>I have setup an mlflow service in a VM and I am able to serve the model using mlflow serve command.\nWanted to know if we can host multiple models in a single VM ?<\/p>\n<p>I am using the below command to serve a model using mlflow in a vm.<\/p>\n<p>command:<\/p>\n<pre><code>\/mlflow models serve -m models:\/$Model-Name\/$Version --no-conda -p 443 -h 0.0.0.0\n<\/code><\/pre>\n<p>Above command creates a model serving and runs it on 443 port.\nIs it possible to have an endpoint like below being created with model name in it ?<\/p>\n<p>Current URL:\nhttps:\/\/localhost:443\/invocations<\/p>\n<p>Expected URL:\nhttps:\/\/localhost:443\/model-name\/invocations ?<\/p>",
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_creation_date":"2022-01-07 10:48:20.16 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2022-01-07 12:33:40.04 UTC",
        "Question_score":0,
        "Question_tags":"apache-spark|machine-learning|databricks|mlflow",
        "Question_view_count":544,
        "Owner_creation_date":"2019-09-20 08:55:45.383 UTC",
        "Owner_last_access_date":"2022-09-23 06:49:38.593 UTC",
        "Owner_reputation":344,
        "Owner_up_votes":39,
        "Owner_down_votes":0,
        "Owner_views":72,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70620074",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69484727,
        "Question_title":"Pyspark: How to save and apply IndexToString to convert labels back to original values in a new predicted dataset",
        "Question_body":"<p>I am using pyspark.ml.RandomForestClassifier and one of the steps here involves <strong>StringIndexer<\/strong> on the training data target variable to convert it into labels.<\/p>\n<pre><code>indexer = StringIndexer(inputCol = target_variable_name, outputCol = 'label').fit(df)\ndf = indexer.transform(df)\n<\/code><\/pre>\n<p>After fitting the final model I am saving it using mlflow.spark.log_model(). So, when applying the model on a new dataset in future, I just load the model again and apply to the new data:<\/p>\n<pre><code>model = mlflow.sklearn.load_model(&quot;models:\/RandomForest_model\/None&quot;)\npredictions = rfModel.transform(new_data)\n<\/code><\/pre>\n<p>In the new_data the prediction will come as <strong>labels<\/strong> and not in original value. So, if I have to get the original values I have to use <strong>IndexToString<\/strong><\/p>\n<pre><code>labelConverter = IndexToString(inputCol=&quot;prediction&quot;, outputCol=&quot;predictedLabel&quot;,labels=indexer.labels)\npredictions = labelConverter.transform(predictions)\n<\/code><\/pre>\n<p>So, the question is, my model doesn't save the <strong>indexer.labels<\/strong> as only the model gets saved. How do, I save and use the indexer.labels from my training dataset on any new dataset. Can this be saved and retrived in mlflow ?<\/p>\n<p>Apologies, if Iam sounding na\u00efve here . But, getting back the original values in the new dataset is really getting me confused.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2021-10-07 16:29:57.133 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-10-08 07:06:50.887 UTC",
        "Question_score":1,
        "Question_tags":"pyspark|databricks|random-forest|apache-spark-mllib|mlflow",
        "Question_view_count":115,
        "Owner_creation_date":"2017-07-27 12:59:26.927 UTC",
        "Owner_last_access_date":"2022-09-21 07:04:54.843 UTC",
        "Owner_reputation":459,
        "Owner_up_votes":100,
        "Owner_down_votes":0,
        "Owner_views":61,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69484727",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73127303,
        "Question_title":"Get Experiment that Created Model in MLflow",
        "Question_body":"<p>I want to get the name of the experiment that contains the run that created a registered MLflow model. How can I do this using MLflow, if I just have the name of the model and the version?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-26 17:10:29.667 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":44,
        "Owner_creation_date":"2018-03-24 01:53:05.82 UTC",
        "Owner_last_access_date":"2022-09-24 16:46:35.903 UTC",
        "Owner_reputation":820,
        "Owner_up_votes":389,
        "Owner_down_votes":1,
        "Owner_views":165,
        "Answer_body":"<p>As @Andre has said, I had to write my own function to achieve this,<\/p>\n<pre><code>def get_model_experiment(model_name, model_version):\n    # get run_id of the model version\n    run_id = mlflow_client.get_model_version(model_name, model_version).run_id\n\n    # get the experiment_id from the run_id\n    experiment_id = mlflow_client.get_run(run_id).info.experiment_id\n\n    # get the experiment name from the experiment_id\n    return mlflow_client.get_experiment(experiment_id).name\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-29 05:46:47.99 UTC",
        "Answer_score":0.0,
        "Owner_location":"Sri Lanka",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73127303",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60530176,
        "Question_title":"mlflow How to save a sklearn pipeline with custom transformer?",
        "Question_body":"<p>I am trying to save with mlflow a sklearn machine-learning model, which is a pipeline containing a custom transformer I have defined, and load it in another project.\nMy custom transformer inherits from BaseEstimator and TransformerMixin.<\/p>\n\n<p>Let's say I have 2 projects:<\/p>\n\n<ul>\n<li>train_project: it has the custom transformers in src.ml.transformers.py<\/li>\n<li>use_project: it has other things in src, or has no src catalog at all<\/li>\n<\/ul>\n\n<p>So in my train_project I do :<\/p>\n\n<pre><code>mlflow.sklearn.log_model(preprocess_pipe, 'model\/preprocess_pipe')\n<\/code><\/pre>\n\n<p>and then when I try to load it into use_project :<\/p>\n\n<pre><code>preprocess_pipe = mlflow.sklearn.load_model(f'{ref_model_path}\/preprocess_pipe')\n<\/code><\/pre>\n\n<p>An error occurs :<\/p>\n\n<pre><code>[...]\nFile \"\/home\/quentin\/anaconda3\/envs\/api_env\/lib\/python3.7\/site-packages\/mlflow\/sklearn.py\", line 210, in _load_model_from_local_file\n    return pickle.load(f)\nModuleNotFoundError: No module named 'train_project'\n<\/code><\/pre>\n\n<p>I tried to use format mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE :<\/p>\n\n<pre><code>mlflow.sklearn.log_model(preprocess_pipe, 'model\/preprocess_pipe', serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE)\n<\/code><\/pre>\n\n<p>but I get the same error during load.<\/p>\n\n<p>I saw option <strong>code_path<\/strong> into <strong>mlflow.pyfunc.log_model<\/strong> but its use and purpose is not clear to me. <\/p>\n\n<p>I thought mlflow provide a easy way to save model and serialize them so they can be used anywhere, Is that true only if you have native sklearn models (or keras, ...)?<\/p>\n\n<p>It's seem that this issue is more related to pickle functioning (mlflow use it and pickle needs to have all dependencies installed). <\/p>\n\n<p>The only solution I found so far is to make my transformer a package, import it in both project. Save version of my transformer library with <em>conda_env<\/em> argument of <em>log_model<\/em>, and check if it's same version when I load the model into my use_project.\nBut it's painfull if I have to change my transformer or debug in it...<\/p>\n\n<p>Is anybody have a better solution? \nMore elegent? Maybe there is some mlflow functionality I would have missed?<\/p>\n\n<p>other informations :<br>\nworking on linux (ubuntu)<br>\nmlflow=1.5.0<br>\npython=3.7.3   <\/p>\n\n<p>I saw in test of mlflow.sklearn api that they do a test with custom transformer, but they load it into the same file so it seems not resolve my issue but maybe it can helps other poeple :<\/p>\n\n<p><a href=\"https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/tests\/sklearn\/test_sklearn_model_export.py\" rel=\"noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/tests\/sklearn\/test_sklearn_model_export.py<\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2020-03-04 16:08:03.85 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":8,
        "Question_tags":"python|machine-learning|scikit-learn|pickle|mlflow",
        "Question_view_count":3317,
        "Owner_creation_date":"2020-03-03 16:04:16.143 UTC",
        "Owner_last_access_date":"2020-03-11 11:11:57.02 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60530176",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57676613,
        "Question_title":"Saving artifacts on remote mlflow server",
        "Question_body":"<p>I am trying to store <code>MLflow<\/code> artifacts on a remote server running <code>MLflow<\/code>. The server I am accessing from and server running <code>MLflow<\/code> are both VMs on google cloud. I can see the matrices in the <code>MLflow<\/code> server but not the artifacts.<\/p>\n\n<p>I tried the flollowing methods but nonoe of them is working:<\/p>\n\n<ul>\n<li><code>mlflow server     --backend-store-uri \/mnt\/persistent-disk     --default-artifact-root \/tmp\/ --host=0.0.0.0<\/code><\/li>\n<li>mlflow server     --backend-store-uri \/mnt\/persistent-disk     --default-artifact-root \/path\/to\/folder\/with\/mlrun --host=0.0.0.0<\/li>\n<\/ul>\n\n<p>I also gave <code>rwx<\/code> permissions to the path but still getting the same error :<\/p>\n\n<pre><code>PermissionError: [Errno 13] Permission denied: '\/home\/user\/folder'\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-27 14:13:07.633 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-27 14:30:43.157 UTC",
        "Question_score":3,
        "Question_tags":"python|mlflow",
        "Question_view_count":2002,
        "Owner_creation_date":"2014-05-29 12:37:30.427 UTC",
        "Owner_last_access_date":"2020-10-15 08:35:10.407 UTC",
        "Owner_reputation":1990,
        "Owner_up_votes":49,
        "Owner_down_votes":1,
        "Owner_views":268,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Kuala Lumpur Federal Territory of Kuala Lumpur Malaysia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57676613",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58554979,
        "Question_title":"Cannot Start mlflow ui on google cloud platform virtual machine instance",
        "Question_body":"<p>after running mlflow ui on command line\nand  clicking <a href=\"http:\/\/127.0.0.1:5000\/\" rel=\"nofollow noreferrer\">http:\/\/127.0.0.1:5000\/<\/a>\ni get site cannot be reached\n127.0.0.1 refused to connect.<\/p>\n<p>I have already updated firewall rules on VPC network in GCP and on my local machine and activated the ports<\/p>\n<blockquote>\n<p>This site can\u2019t be reached127.0.0.1 refused to connect.<\/p>\n<p>Try:<\/p>\n<ul>\n<li>Checking the connection<\/li>\n<li>Checking the proxy and the firewall<\/li>\n<\/ul>\n<p>ERR_CONNECTION_REFUSED<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-25 08:35:26.673 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-06-20 09:12:55.06 UTC",
        "Question_score":0,
        "Question_tags":"google-cloud-platform|mlflow",
        "Question_view_count":360,
        "Owner_creation_date":"2018-01-21 16:42:32.317 UTC",
        "Owner_last_access_date":"2021-03-20 09:36:52.253 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Haryana, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58554979",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69950235,
        "Question_title":"MLflow saving a run to a specific experiment id",
        "Question_body":"<p>I am trying to save runs called from MLflow Projects to specific experiment names\/ids.<\/p>\n<p>Currently, my MLflow project looks like this:<\/p>\n<pre><code>name: Echo NLP Project\n\nentry_points:\n    generate:\n        parameters:\n            ...\n        command: &quot;python scripts\/generate_data.py ... --exp_name {exp_name}&quot;\n<\/code><\/pre>\n<p>The project calls in the command to the script <code>generate_data.py<\/code> where I would do some functions and record a run in the function.<\/p>\n<p>I would like to specify where this run would be saved with the <code>exp_name<\/code> parameter and I am doing this by having this code in <code>generate_data.py<\/code>:<\/p>\n<pre><code>mlflow.set_experiment(experiment_name)\nmlflow.run(uri=os.getcwd(), experiment_name=experiment_name)\n<\/code><\/pre>\n<p>However, it is giving me this error:<\/p>\n<pre><code>2021\/11\/12 15:45:06 INFO mlflow.projects.utils: === Created directory \/tmp\/tmp3jx68uph for downloading remote URIs passed to arguments of type 'path' ===\n2021\/11\/12 15:45:06 INFO mlflow.projects.backend.local: === Running command 'source \/...\/profile.d\/conda.sh &amp;&amp; conda activate mlflow-667a7951db8b0b02e9ac567ea087405cbc28af02 1&gt;&amp;2 &amp;&amp; python scripts\/generate_data.py ... --exp_name test' in run with ID 'cd2b5b20f00344e5a6257deafabc4791' ===\nTraceback (most recent call last):\n  File &quot;scripts\/generate_data.py&quot;, line 32, in &lt;module&gt;\n    x = tm(json_folder=args.json_folder, spacy_folder=args.spacy_folder, report_source=args.reports, experiment_name=args.exp_name)\n  File &quot;\/mnt\/c\/Users\/username\/Documents\/echo-nlp-model\/scripts\/train_class.py&quot;, line 157, in __init__\n    mlflow.run(uri=os.getcwd(), experiment_name=experiment_name)\n  File &quot;\/mnt\/c\/Users\/username\/Documents\/venv\/lib\/python3.8\/site-packages\/mlflow\/projects\/__init__.py&quot;, line 293, in run\n    submitted_run_obj = _run(\n  File &quot;\/mnt\/c\/Users\/username\/Documents\/venv\/lib\/python3.8\/site-packages\/mlflow\/projects\/__init__.py&quot;, line 92, in _run\n    submitted_run = backend.run(\n  File &quot;\/mnt\/c\/Users\/username\/Documents\/venv\/lib\/python3.8\/site-packages\/mlflow\/projects\/backend\/local.py&quot;, line 45, in run\n    work_dir = fetch_and_validate_project(project_uri, version, entry_point, params)\n  File &quot;\/mnt\/c\/Users\/username\/Documents\/venv\/lib\/python3.8\/site-packages\/mlflow\/projects\/utils.py&quot;, line 126, in fetch_and_validate_project\n    project.get_entry_point(entry_point)._validate_parameters(parameters)\n  File &quot;\/mnt\/c\/Users\/username\/Documents\/venv\/lib\/python3.8\/site-packages\/mlflow\/projects\/_project_spec.py&quot;, line 132, in get_entry_point\n    raise ExecutionException(\nmlflow.exceptions.ExecutionException: Could not find main among entry points ['generate', 'train', 'complete'] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh']\n2021\/11\/12 15:45:21 ERROR mlflow.cli: === Run (ID 'cd2b5b20f00344e5a6257deafabc4791') failed ===\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-11-12 23:50:58.823 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"python|mlflow|spacy-3",
        "Question_view_count":289,
        "Owner_creation_date":"2021-07-08 23:05:35.423 UTC",
        "Owner_last_access_date":"2022-09-19 05:28:03.52 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Vancouver, BC, Canada",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69950235",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73015639,
        "Question_title":"Issues with deploying spark and mlflow to sagemaker",
        "Question_body":"<p>My goal is to deploy a spark\/mlflow to sagemaker with the following command:<\/p>\n<pre><code>    mlflow sagemaker deploy .. \n<\/code><\/pre>\n<p>I've successfully pushed a image to EC2 with<\/p>\n<pre><code>mlflow sagemaker build-and-push-container\n<\/code><\/pre>\n<p>I encounter errors when attempting to run mlflow sagemaker deploy:<\/p>\n<pre><code>[error] 446#446: *69 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 10.32.0.2, server: , request: &quot;GET \/ping HTTP\/1.1&quot;, upstream: &quot;http:\/\/127.0.0.1:8000\/ping&quot;, host: &quot;model.aws.local:8080&quot;\njava.io.IOException: Failed to connect to model.aws.local\/172.17.0.2:34473\n<\/code><\/pre>\n<p>Therefore, I added the following as I thought I was mishandling pyspark in sagemaker:<\/p>\n<pre><code>classpath = &quot;:&quot;.join(sagemaker_pyspark.classpath_jars()) \nspark = SparkSession.builder.config( &quot;spark.driver.extraClassPath&quot;, classpath ).appName('audit-risk-predictor-training').getOrCreate()          \n<\/code><\/pre>\n<p>However this outputted the following error:<\/p>\n<pre><code>Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org\/apache\/commons\/configuration\/Configuration\n    at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.&lt;init&gt;(DefaultMetricsSystem.java:38)\n    at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.&lt;clinit&gt;(DefaultMetricsSystem.java:36)\n    at org.apache.hadoop.security.UserGroupInformation$UgiMetrics.create(UserGroupInformation.java:134)\n    at org.apache.hadoop.security.UserGroupInformation.&lt;clinit&gt;(UserGroupInformation.java:254)\n    at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2487)\n    at scala.Option.getOrElse(Option.scala:189)\n    at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2487)\n    at org.apache.spark.SecurityManager.&lt;init&gt;(SecurityManager.scala:79)\n    at org.apache.spark.deploy.SparkSubmit.secMgr$lzycompute$1(SparkSubmit.scala:368)\n    at org.apache.spark.deploy.SparkSubmit.secMgr$1(SparkSubmit.scala:368)\n    at org.apache.spark.deploy.SparkSubmit.$anonfun$prepareSubmitEnvironment$8(SparkSubmit.scala:376)\n    at scala.Option.map(Option.scala:230)\n    at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:376)\n    at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:894)\n    at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n    at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n    at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n    at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)\n    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)\n    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\nCaused by: java.lang.ClassNotFoundException: org.apache.commons.configuration.Configuration\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n    ... 20 more\n---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\nInput In [7], in &lt;cell line: 3&gt;()\n      1 # Create Spark Session\n      2 classpath = &quot;:&quot;.join(sagemaker_pyspark.classpath_jars()) \n----&gt; 3 spark = SparkSession.builder.config( &quot;spark.driver.extraClassPath&quot;, classpath ).appName('audit-risk-predictor-training').getOrCreate()\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/sql\/session.py:228, in SparkSession.Builder.getOrCreate(self)\n    226         sparkConf.set(key, value)\n    227     # This SparkContext may be an existing one.\n--&gt; 228     sc = SparkContext.getOrCreate(sparkConf)\n    229 # Do not update `SparkConf` for existing `SparkContext`, as it's shared\n    230 # by all sessions.\n    231 session = SparkSession(sc)\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/context.py:384, in SparkContext.getOrCreate(cls, conf)\n    382 with SparkContext._lock:\n    383     if SparkContext._active_spark_context is None:\n--&gt; 384         SparkContext(conf=conf or SparkConf())\n    385     return SparkContext._active_spark_context\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/context.py:144, in SparkContext.__init__(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\n    139 if gateway is not None and gateway.gateway_parameters.auth_token is None:\n    140     raise ValueError(\n    141         &quot;You are trying to pass an insecure Py4j gateway to Spark. This&quot;\n    142         &quot; is not allowed as it is a security risk.&quot;)\n--&gt; 144 SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n    145 try:\n    146     self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n    147                   conf, jsc, profiler_cls)\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/context.py:331, in SparkContext._ensure_initialized(cls, instance, gateway, conf)\n    329 with SparkContext._lock:\n    330     if not SparkContext._gateway:\n--&gt; 331         SparkContext._gateway = gateway or launch_gateway(conf)\n    332         SparkContext._jvm = SparkContext._gateway.jvm\n    334     if instance:\n\nFile ~\/.local\/lib\/python3.8\/site-packages\/pyspark\/java_gateway.py:108, in launch_gateway(conf, popen_kwargs)\n    105     time.sleep(0.1)\n    107 if not os.path.isfile(conn_info_file):\n--&gt; 108     raise Exception(&quot;Java gateway process exited before sending its port number&quot;)\n    110 with open(conn_info_file, &quot;rb&quot;) as info:\n    111     gateway_port = read_int(info)\n\nException: Java gateway process exited before sending its port number\n<\/code><\/pre>\n<p>Any insight on where I'm going wrong? Is spark capable of running in sagemaker?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-17 22:00:01.223 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|apache-spark|deployment|amazon-sagemaker|mlflow",
        "Question_view_count":59,
        "Owner_creation_date":"2022-01-13 10:12:59.037 UTC",
        "Owner_last_access_date":"2022-09-23 16:16:27.333 UTC",
        "Owner_reputation":45,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73015639",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67196775,
        "Question_title":"Is there a workaround to make opencensus work with MLFlow?",
        "Question_body":"<p>I'm not able to import mlflow after having launched a log with opencensus Azure.\nThe MLFlow import runs forever.<\/p>\n<p>My environment is the following:<\/p>\n<ul>\n<li>Python 3.7<\/li>\n<li>opencensus-ext-azure 1.0.7<\/li>\n<li>opencensus-ext-logging 0.1.0<\/li>\n<li>mlflow 1.15.0<\/li>\n<\/ul>\n<p>Here is the code to repoduce the bug:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import logging\n\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\n\nlogger = logging.getLogger(__name__)\nlogger.addHandler(AzureLogHandler(connection_string='InstrumentationKey=&lt;your-key&gt;'))\nlogger.warning('Hello, World!')\n\nimport mlflow\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-21 13:21:10.043 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure|mlflow|opencensus",
        "Question_view_count":41,
        "Owner_creation_date":"2015-02-11 07:34:40.283 UTC",
        "Owner_last_access_date":"2022-09-23 14:32:37.963 UTC",
        "Owner_reputation":457,
        "Owner_up_votes":19,
        "Owner_down_votes":2,
        "Owner_views":125,
        "Answer_body":"<p>I found a workaround, not the cleanest one though.<\/p>\n<p>I import mlflow at the beginning even if it's not useful this way:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\nimport logging\n\nfrom opencensus.ext.azure.log_exporter import AzureLogHandler\n\nlogger = logging.getLogger(__name__)\nlogger.addHandler(AzureLogHandler(connection_string='InstrumentationKey=&lt;your-key&gt;'))\nlogger.warning('Hello, World!')\n\nimport mlflow\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-22 07:42:57.893 UTC",
        "Answer_score":1.0,
        "Owner_location":"Lyon, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67196775",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69208039,
        "Question_title":"load MLFlow model and plot feature importance with feature names",
        "Question_body":"<p>If I save a xgboost model in mlflow with <code>mlflow.xgboost.log_model(model, &quot;model&quot;)<\/code> and load it with <code>model = mlflow.xgboost.load_model(&quot;models:\/model_uri&quot;)<\/code> and want to plot the feature importance with <code>xgboost.plot_importance(model)<\/code> the problem is that the features are not shown with names (see plot). If I plot the feature without saving in mlflow the origin feature names are shown. Do I have to store the model in another way?\n<a href=\"https:\/\/i.stack.imgur.com\/PTvD2.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/PTvD2.png\" alt=\"enter image description here\" \/><\/a><\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2021-09-16 11:59:15.093 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"xgboost|mlflow",
        "Question_view_count":498,
        "Owner_creation_date":"2020-02-10 22:25:37.247 UTC",
        "Owner_last_access_date":"2022-08-23 08:27:31.153 UTC",
        "Owner_reputation":169,
        "Owner_up_votes":7,
        "Owner_down_votes":0,
        "Owner_views":26,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69208039",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71582416,
        "Question_title":"How to display version in Mlflow UI in column",
        "Question_body":"<p>I have developed multiple modeling in mlflow where in I would like to create model versioning so that the version of that model can be track down for the easy identification based on the timestamp.<\/p>\n<p>Kindly provide the documentation specific to model versioning.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2022-03-23 05:54:52.247 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-03-23 16:20:54.723 UTC",
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":94,
        "Owner_creation_date":"2022-03-23 05:43:50.177 UTC",
        "Owner_last_access_date":"2022-09-19 05:47:27.913 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71582416",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73620580,
        "Question_title":"Hi everyone, I'm trying to authentication and authorize MLFlow my infra is in AWS and my mlflow will run in eks ? can we do it with mlflow plugin",
        "Question_body":"<p>Do we have any way to do this?<\/p>\n<ol>\n<li>I tried to authenticate using AWS ALB that did not work for me.<\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-09-06 10:35:19.567 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"kubernetes|mlflow",
        "Question_view_count":26,
        "Owner_creation_date":"2019-07-04 04:13:21.02 UTC",
        "Owner_last_access_date":"2022-09-23 05:56:35.94 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73620580",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60283575,
        "Question_title":"How can I use Hyperopt with MLFlow within a pandas_udf?",
        "Question_body":"<p>I'm building multiple Prophet models where each model is passed to a pandas_udf function which trains the model and stores the results with MLflow.<\/p>\n\n<pre><code>@pandas_udf(result_schema, PandasUDFType.GROUPED_MAP)\ndef forecast(data):\n......\n   with mlflow.start_run() as run: \n......\n<\/code><\/pre>\n\n<p>Then I call this UDF which trains a model for each KPI.<\/p>\n\n<pre><code>df.groupBy('KPI').apply(forecast)\n<\/code><\/pre>\n\n<p>The idea is that, for each KPI a model will be trained with multiple hyperparameters and store the best params for each model in MLflow. I would like to use Hyperopt to make the search more efficient. <\/p>\n\n<p>In this case, where should I place the objective function? Since the data is passed to the UDF for each model I thought of creating an inner function within the UDF that uses the data for each run. Does this make sense?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-18 14:50:29.823 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-09-18 07:30:21.983 UTC",
        "Question_score":3,
        "Question_tags":"apache-spark|mlflow|hyperopt|facebook-prophet",
        "Question_view_count":432,
        "Owner_creation_date":"2012-10-03 14:16:28.797 UTC",
        "Owner_last_access_date":"2022-06-27 13:31:44.52 UTC",
        "Owner_reputation":81,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":23,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Copenhagen, Denmark",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60283575",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60418931,
        "Question_title":"How to create a custom pyfunc to make predictions using a model that requires an input shape with more than two dimensions using MLflow?",
        "Question_body":"<p>I'm new to TensorFlow and MLFlow and I have a similar problem to the one asked in <a href=\"https:\/\/stackoverflow.com\/questions\/58917918\/how-to-make-predictions-using-a-model-that-requires-an-input-shape-with-more-tha\/60416642#60416642\">here<\/a>. I am implementing a TensorFlow model to predict timeseries values. With that aim, I used MLFlow's mlflow.tensorflow.autolog() to track and serve the models in my instance. Nevertheless, since my input shape has more than 2 dimensions, I was not able to use that method. <\/p>\n\n<p>As previously <a href=\"https:\/\/stackoverflow.com\/a\/60129726\/8338272\">suggested<\/a>, I've tried to encode\/decode the input data in prediction by using a custom pyfunc to do it. <\/p>\n\n<p>In this way, I have a function <em>model_test.py<\/em> with a predict method that decode its input data that is:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import sys\nimport os\nimport json\nimport mlflow\nimport numpy as np\nimport pandas as pd\nfrom mlflow.pyfunc import PythonModel\nimport tensorflow as tf\nimport base64\n\n\n\nclass ModelTest(PythonModel):\n\n    def __init__(self, estimator=None,window_size = 64,batch_size = 256,shuffle_buffer_size = 100):\n        # CODE TO CREATE THE EXPERIMENT\n        self.window_size = window_size\n        self.batch_size = batch_size\n        self.shuffle_buffer_size = shuffle_buffer_size\n\n    def windowed_dataset(self,series, window_size, batch_size, shuffle_buffer):\n            series = tf.expand_dims(series, axis=-1)\n            ds = tf.data.Dataset.from_tensor_slices(series)\n            ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n            ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n            ds = ds.shuffle(shuffle_buffer)\n            ds = ds.map(lambda w: (w[:-1], w[1:]))\n            self.windowed_ds = ds.batch(batch_size).prefetch(1)\n            return self\n\n    def train(self, train_set, y = None, epochs = 500):\n\n        model = tf.keras.models.Sequential([\n                  tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n                                      strides=1, padding=\"causal\",\n                                      activation=\"relu\",\n                                      input_shape=[None, 1]),\n                  tf.keras.layers.LSTM(60, return_sequences=True),\n                  tf.keras.layers.Dense(10, activation=\"relu\"),\n                  tf.keras.layers.Dense(1),\n                  tf.keras.layers.Lambda(lambda x: x * 400)\n                ])\n        optimizer = tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9)\n        model.compile(loss=tf.keras.losses.Huber(),optimizer=optimizer,metrics=[\"mae\"])\n        model.fit(x=train_set, y=y,epochs=5)\n        self.modelo = model\n\n        return self\n\n    def predict(self, series_encoded):\n        # Decode the data that arrives to the method\n        def decode_ts(x):\n            return pd.Series(np.frombuffer(base64.b64decode(x)))\n        series_decode = decode_ts(series_encoded)\n        # Preprocess data\n        series = np.expand_dims(series_decode, axis=1)\n        ds = tf.data.Dataset.from_tensor_slices(series)\n        # Replace the number by a variable window_size\n        ds = ds.window(60, shift=1, drop_remainder=True)\n        # Replace the number by a variable window_size\n        ds = ds.flat_map(lambda w: w.batch(60))\n        ds = ds.batch(32).prefetch(1)\n        # Prediction\n        forecast = self.modelo.predict(ds)\n\n        return forecast\n<\/code><\/pre>\n\n<p>And a <em>run.py<\/em> file to train and save the model:<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import os\nimport mlflow.pyfunc\nimport ModelTest as model_test\nimport sys\nimport json\nimport mlflow\nimport numpy as np\nfrom pymongo import MongoClient\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport Preprocessing as pre\n\n#@click(...) # define the click options according to MLproject file\ndef run():\n    # Code to load time series data from MongoDB and preprocess it\n\n    window_size = 64\n    batch_size = 256\n    shuffle_buffer_size = 100\n    split_time = 400\n\n    series = np.array(data_df['sensor_ts'])\n    time = np.array(data_df['time'])\n    time_train = time[:split_time]\n    x_train = series[:split_time]\n    time_valid = time[split_time:]\n    x_valid = series[split_time:]\n\n\n    modelo = modelo_tercero.ModelTest()\n    modelo.windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n\n    with mlflow.start_run() as run:\n        model = modelo.train(modelo.windowed_ds)\n        model_path = os.path.join('models', run.info.run_id)\n\n        # Save model\n        mlflow.pyfunc.save_model(\n            path=model_path,\n            python_model= modelo.train(modelo.windowed_ds),\n            code_path=['Modelthird.py'],\n            conda_env={\n                'channels': ['defaults', 'conda-forge'],\n                'dependencies': [\n                    'mlflow=1.6.0',\n                    'numpy=1.18.1',\n                    'tensorflow=2.1.0',\n                    'pandas=0.25.3',\n                    'python=3.7.6',\n                    'cloudpickle==0.5.8'\n                ],\n                'name': 'mlflow-env'\n            }\n        )\n\n\nif __name__ == \"__main__\":\n    run()\n\n<\/code><\/pre>\n\n<p>When I execute the run.py I get the next errors when the model is going to be saved:<\/p>\n\n<pre><code> Traceback (most recent call last):\n\nFile \"run.py\", line 116, in &lt;module&gt;\n    run()\n  File \"run.py\", line 110, in run\n    'name': 'mlflow-env'\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/__init__.py\", line 596, in save_model\n    code_paths=code_path, mlflow_model=mlflow_model)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/pyfunc\/model.py\", line 141, in _save_model_with_class_artifacts_params\n    cloudpickle.dump(python_model, out)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/cloudpickle\/cloudpickle.py\", line 1109, in dump\n    CloudPickler(file, protocol=protocol).dump(obj)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/cloudpickle\/cloudpickle.py\", line 482, in dump\n    return Pickler.dump(self, obj)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 437, in dump\n    self.save(obj)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 859, in save_dict\n    self._batch_setitems(obj.items())\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 885, in _batch_setitems\n    save(v)\n  File \"\/opt\/conda\/lib\/python3.7\/pickle.py\", line 524, in save\n    rv = reduce(self.proto)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/framework\/ops.py\", line 873, in __reduce__\n    return convert_to_tensor, (self._numpy(),)\n  File \"\/opt\/conda\/lib\/python3.7\/site-packages\/tensorflow_core\/python\/framework\/ops.py\", line 910, in _numpy\n    six.raise_from(core._status_to_exception(e.code, e.message), None)\n  File \"&lt;string&gt;\", line 3, in raise_from\n<\/code><\/pre>\n\n<p>I have looked at different documentation related to save and serialize TensorFlow models, but there is not so much documentation about TensorFlow models and custom pyfunc functions in MLFlow. Could anyone help me or give me any hint?<\/p>\n\n<p>Thanks in advance!! :D<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2020-02-26 17:00:05.89 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"tensorflow|keras|tensorflow2.0|tensorflow-serving|mlflow",
        "Question_view_count":1669,
        "Owner_creation_date":"2017-07-20 12:31:30.863 UTC",
        "Owner_last_access_date":"2020-04-23 12:05:27.61 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Madrid, Espa\u00f1a",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60418931",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58611088,
        "Question_title":"Is there a way to manage permissions at an experiment level in MLflow?",
        "Question_body":"<p>Is there a way to manage permissions at an experiment level in MLflow?  We would like to have a shared server but would like to be able to manage permissions at an experiment level - e.g. admin can view all experiments, user_group1 can manage experiment1 - perhaps different groups can see results vs post results.<\/p>\n\n<p>It looks like it is possible in databricks: <a href=\"https:\/\/docs.databricks.com\/administration-guide\/access-control\/workspace-acl.html#experiment-permissions\" rel=\"nofollow noreferrer\">https:\/\/docs.databricks.com\/administration-guide\/access-control\/workspace-acl.html#experiment-permissions<\/a>  but I can't find anything in the opensource APIdocs.<\/p>\n\n<p>Thanks.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-10-29 15:57:37.393 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":4,
        "Question_tags":"mlflow",
        "Question_view_count":1567,
        "Owner_creation_date":"2017-02-17 11:58:49.157 UTC",
        "Owner_last_access_date":"2022-09-21 13:15:40.707 UTC",
        "Owner_reputation":289,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58611088",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65992591,
        "Question_title":"send post request using curl to mlflow api to multiple records",
        "Question_body":"<p>I have served an mlflow model and am sending POST requests in this format:<\/p>\n<pre><code>curl -X POST -H &quot;Content-Type:application\/json; format=pandas-split&quot; \n--data '{&quot;columns&quot;:[&quot;alcohol&quot;, &quot;chlorides&quot;, &quot;citric acid&quot;, &quot;density&quot;, \n&quot;fixed acidity&quot;, &quot;free sulfur dioxide&quot;, &quot;pH&quot;, &quot;residual sugar&quot;, &quot;sulphates&quot;, \n&quot;total sulfur dioxide&quot;, &quot;volatile acidity&quot;],&quot;data&quot;:[[12.8, 0.029, 0.48, 0.98, \n6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' \nhttp:\/\/127.0.0.1:1234\/invocations\n<\/code><\/pre>\n<p>It is getting scored. However for my particular project, the input to rest api for scoring will always be multiple records in dataframe\/csv format instead of a single record. Can someone point me to how to achieve this ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-02-01 12:17:21.393 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"curl|post|deployment|mlflow|serving",
        "Question_view_count":407,
        "Owner_creation_date":"2019-11-14 13:58:10.56 UTC",
        "Owner_last_access_date":"2022-09-23 08:37:32.563 UTC",
        "Owner_reputation":115,
        "Owner_up_votes":16,
        "Owner_down_votes":0,
        "Owner_views":25,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65992591",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62841756,
        "Question_title":"Can't use HDFS path to set_tracking_uri in mlflow within python",
        "Question_body":"<p>I'm new to mlflow so I may misunderstand how things are supposed to work on a fundamental level.<\/p>\n<p>However when I try to do the following:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>TRACKING_URI = os.path.join(\n    &quot;hdfs:\/\/namenode\/user\/userid\/&quot;,\n    &quot;mlflow&quot;,\n    &quot;anomaly_detection&quot;,\n)\n        \nmlflow.set_tracking_uri(TRACKING_URI)\nclient = mlflow.tracking.MlflowClient(TRACKING_URI)\n<\/code><\/pre>\n<p>I get the following error:<\/p>\n<pre class=\"lang-sh prettyprint-override\"><code>UnsupportedModelRegistryStoreURIException:  Model registry functionality is unavailable; got unsupported URI 'hdfs:\/\/nameservice1\/user\/rxb427\/mlflow\/anomaly_detection' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.\n<\/code><\/pre>\n<p>Within the above link provided by the error it states that hdfs is supported. Bug or am I missing something?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-10 20:21:30.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-07-10 21:00:46.223 UTC",
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":621,
        "Owner_creation_date":"2014-06-23 16:02:53.873 UTC",
        "Owner_last_access_date":"2022-09-23 14:18:04.92 UTC",
        "Owner_reputation":458,
        "Owner_up_votes":76,
        "Owner_down_votes":5,
        "Owner_views":119,
        "Answer_body":"<p>Ok. So it looks like while the ARTIFACTS STORE does support hdfs, you have to use either file or a sql like for the BACKEND STORE.<\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2020-07-13 17:24:30.47 UTC",
        "Answer_score":0.0,
        "Owner_location":"Atlanta, GA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62841756",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73051157,
        "Question_title":"Using MLflow and Sagemaker with preprocessing steps",
        "Question_body":"<p>I'm deploying my models to Sagemaker using MLflow integration. However, my ML pipeline includes some basic preprocessing steps, such as scalers, and I need it to be part of my inference endpoint. Is there a way to do that with MLflow? I looked in the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html\" rel=\"nofollow noreferrer\">mlflow_pyfunc<\/a> is closer to what I want, but I'm not sure if it is compatible with Sagemaker.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-20 11:52:22.35 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|amazon-sagemaker|mlflow",
        "Question_view_count":34,
        "Owner_creation_date":"2016-10-17 11:39:35.777 UTC",
        "Owner_last_access_date":"2022-07-28 17:26:21.417 UTC",
        "Owner_reputation":109,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":21,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73051157",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72303932,
        "Question_title":"Spark Model serving: How to compute the state just once, then keep the state to answer all real-time requests? (recommendation engine)",
        "Question_body":"<p>I try to implement a recommendation engine using Kafka to collect real-time click data and then process it using Spark Structured Streaming. My problem is about how to server predictions in near real-time using this streaming dataframe.<\/p>\n<p>What works fine is: collecting click data, sending to Kafka, subscribing from Spark, using Strcutured Streaming to compute a dataframe which describes the 'state of a visitor'. Now having this streaming dataframe, there are just few lines of code (business logic) telling which is the best recommendation.<\/p>\n<p>Now my problem is: how do I put this in production. I could create a mlflow.pyfunc model. But this would not contain the 'state of a visitor' dataframe. When looking at model serving frameworks, I understand that every inference request would create an independent runtime which would have to do the whole data pipeline again.<\/p>\n<p>My idea would be to have 1 Spark instance which would:<\/p>\n<ol>\n<li>create this streaming dataframe<\/li>\n<li>wait for incoming request and answer those by using the dataframe from (1.)<\/li>\n<\/ol>\n<p>Is this a reasonable approach? If yes: How do I set this up? If no: What is the preferred way to do real-time recommendations?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-19 11:42:39.7 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"apache-spark|apache-kafka|spark-streaming|recommendation-engine|mlflow",
        "Question_view_count":28,
        "Owner_creation_date":"2016-01-08 13:26:58.953 UTC",
        "Owner_last_access_date":"2022-08-06 19:01:56.227 UTC",
        "Owner_reputation":39,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72303932",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60680528,
        "Question_title":"Max retries exceeded with url, Failed to establish a new connect [Errno 60] Operation timed out'",
        "Question_body":"<p>I used nginx to build mlflow server with its proxy_pass and integrated simple HTTP auth in nginx.  However, when I ran the experiment for a while, the mlflow client met this exception. And I have no idea how to fix it.<\/p>\n\n<p>Here is the error messages:<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/connection.py\", line 159, in _new_conn\n    (self._dns_host, self.port), self.timeout, **extra_kw)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/util\/connection.py\", line 80, in create_connection\n    raise err\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/util\/connection.py\", line 70, in create_connection\n    sock.connect(sa)\nTimeoutError: [Errno 60] Operation timed out\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/connectionpool.py\", line 600, in urlopen\n    chunked=chunked)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/connectionpool.py\", line 354, in _make_request\n    conn.request(method, url, **httplib_request_kw)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/http\/client.py\", line 1239, in request\n    self._send_request(method, url, body, headers, encode_chunked)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/http\/client.py\", line 1285, in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/http\/client.py\", line 1234, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/http\/client.py\", line 1026, in _send_output\n    self.send(msg)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/http\/client.py\", line 964, in send\n    self.connect()\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/connection.py\", line 181, in connect\n    conn = self._new_conn()\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/connection.py\", line 168, in _new_conn\n    self, \"Failed to establish a new connection: %s\" % e)\nurllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x1280a8438&gt;: Failed to establish a new connection: [Errno 60] Operation timed out\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/requests\/adapters.py\", line 449, in send\n    timeout=timeout\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/connectionpool.py\", line 638, in urlopen\n    _stacktrace=sys.exc_info()[2])\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/urllib3\/util\/retry.py\", line 398, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&lt;host_ip&gt;, port=&lt;port&gt;): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/get-by-name?experiment_name=&lt;exp_name&gt; (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x1280a8438&gt;: Failed to establish a new connection: [Errno 60] Operation timed out',))\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"tmp_experiment_entry.py\", line 4, in &lt;module&gt;\n    mlflow.set_experiment(&lt;exp_name&gt;)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/mlflow\/tracking\/fluent.py\", line 47, in set_experiment\n    experiment = client.get_experiment_by_name(experiment_name)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 151, in get_experiment_by_name\n    return self._tracking_client.get_experiment_by_name(name)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py\", line 114, in get_experiment_by_name\n    return self.store.get_experiment_by_name(name)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 219, in get_experiment_by_name\n    response_proto = self._call_endpoint(GetExperimentByName, req_body)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/mlflow\/store\/tracking\/rest_store.py\", line 32, in _call_endpoint\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 133, in call_endpoint\n    host_creds=host_creds, endpoint=endpoint, method=method, params=json_body)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 70, in http_request\n    url=url, headers=headers, verify=verify, **kwargs)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/mlflow\/utils\/rest_utils.py\", line 51, in request_with_ratelimit_retries\n    response = requests.request(**kwargs)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/requests\/api.py\", line 60, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/requests\/sessions.py\", line 533, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/requests\/sessions.py\", line 646, in send\n    r = adapter.send(request, **kwargs)\n  File \"\/usr\/local\/opt\/python\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/requests\/adapters.py\", line 516, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host=&lt;host_ip&gt;, port=&lt;port&gt;): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/get-by-name?experiment_name=&lt;exp_name&gt; (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object at 0x1280a8438&gt;: Failed to establish a new connection: [Errno 60] Operation timed out',))\n<\/code><\/pre>\n\n<p>In the client, I use mlflow log by the following format and log_params, log_metrics in main function<\/p>\n\n<pre><code>with mlflow.start_run():\n    main(params)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2020-03-14 07:06:08.24 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2020-03-15 17:30:39.973 UTC",
        "Question_score":3,
        "Question_tags":"python-3.x|nginx|python-requests|nginx-config|mlflow",
        "Question_view_count":7609,
        "Owner_creation_date":"2015-05-05 19:13:59.17 UTC",
        "Owner_last_access_date":"2022-08-21 14:45:40.787 UTC",
        "Owner_reputation":108,
        "Owner_up_votes":35,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Taipei City, Taiwan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60680528",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71985302,
        "Question_title":"How to see results via `mlflow ui` for experiments logged on a other server?",
        "Question_body":"<p>I was running ML experiments on a ssh server, the experiments were logged via mlflow and stored in local <code>mlruns<\/code> on the server.<\/p>\n<p>The code were just basic usage of mlflow and looks like this<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport mlflow\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n\nif __name__ == '__main__':\n    Path('.\/plot').mkdir(exist_ok = True)\n    mlflow.set_experiment('demo-exp')\n    with mlflow.start_run():\n        x     = np.random.randn(10, 1)\n        y     = np.random.randn(10, 1)\n        model = LinearRegression().fit(x, y)\n        py    = model.predict(x)\n        r2    = r2_score(y, py)\n        plt.plot(y, py, '+')\n        plt.savefig('.\/plot\/result.png')\n        plt.close()\n\n        mlflow.log_metric('r2', r2)\n        mlflow.log_artifact('.\/plot\/result.png')\n<\/code><\/pre>\n<p>Now I want to see the logged metrics and artifactos from my own laptop, so I tried<\/p>\n<pre><code>mlflow ui \\\n    --default-artifact-root=sftp:\/\/\/USER_NAME@ADDRESS\/path\/to\/experiment\/mlruns \\\n    --port=8888 \\\n\n<\/code><\/pre>\n<p>However, it looks like nothing showed in <code>localhost:8888<\/code> on my own laptop.<\/p>\n<p>Anything I did wrong about the code and <code>mlflow ui<\/code> command?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-24 03:32:45.373 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|mlflow|mlops",
        "Question_view_count":358,
        "Owner_creation_date":"2013-04-19 13:57:13.543 UTC",
        "Owner_last_access_date":"2022-09-22 13:01:34.857 UTC",
        "Owner_reputation":3157,
        "Owner_up_votes":52,
        "Owner_down_votes":7,
        "Owner_views":163,
        "Answer_body":"<ul>\n<li>Run mlflow on a remote server<\/li>\n<\/ul>\n<pre><code>mlflow server --host 0.0.0.0 --port 8888\n<\/code><\/pre>\n<ul>\n<li>Configure ssh local port forward on your local machine, like this:\n<a href=\"https:\/\/stackoverflow.com\/questions\/9146457\/ssh-port-forwarding-in-a-ssh-config-file\">SSH Port forwarding in a ~\/.ssh\/config file?<\/a><\/li>\n<\/ul>\n<pre><code>LocalForward 8888 your_remote_machine_addr:8888\n<\/code><\/pre>\n<ul>\n<li>Connect to localhost:8888 on your browser<\/li>\n<\/ul>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-04-26 05:35:47.493 UTC",
        "Answer_score":0.0,
        "Owner_location":"China,Shanghai.",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71985302",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67237264,
        "Question_title":"MLFlow runs alembicruntime.migration when I connect to a new SQLite database",
        "Question_body":"<p>For performance reasons I want to use the SQLite backend instead of the default mlruns folder in MLFlow. I set the tracking_uri to <code>sqlite:\/\/\/outputs\/test.sqlite<\/code> and then create a new experiment using the default API (not tracking API, but it happens with that too).<\/p>\n<p>This is the code:<\/p>\n<pre><code>import mlflow\nmlflow.set_tracking_uri(&quot;sqlite:\/\/\/outputs\/test.sqlite&quot;)\nmlflow.create_experiment(&quot;experiment&quot;)\n<\/code><\/pre>\n<p>The code works, but I get this output:<\/p>\n<pre><code>2021\/04\/23 22:43:22 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n2021\/04\/23 22:43:22 INFO mlflow.store.db.utils: Updating database tables\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.runtime.migration] Running upgrade  -&gt; 451aebb31d03, add metric step\nINFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -&gt; 90e64c465722, migrate user column to tags\nINFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -&gt; 181f10493468, allow nulls for metric values\nINFO  [alembic.runtime.migration] Running upgrade 181f10493468 -&gt; df50e92ffc5e, Add Experiment Tags Table\nINFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -&gt; 7ac759974ad8, Update run tags with larger limit\nINFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -&gt; 89d4b8295536, create latest metrics table\nINFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\nINFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -&gt; 2b4d017a5e9b, add model registry tables to db\nINFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\nINFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\nINFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -&gt; cfd24bdc0731, Update run status constraint with killed\nINFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -&gt; 0a8213491aaa, drop_duplicate_killed_constraint\nWARNI [0a8213491aaa_drop_duplicate_killed_constraint_py] Failed to drop check constraint. Dropping check constraints may not be supported by your SQL database. Exception content: No support for ALTER of constraints in SQLite dialectPlease refer to the batch mode feature which allows for SQLite migrations using a copy-and-move strategy.\nINFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -&gt; 728d730b5ebd, add registered model tags table\nINFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -&gt; 27a6a02d2cf1, add model version tags table\nINFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -&gt; 84291f40a231, add run_link to model_version\nINFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -&gt; a8c4a736bde6, allow nulls for run_id\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n<\/code><\/pre>\n<p>This information is not shown when I run the code a second time (with a different experiment ID). It is only shown when I specify a SQLite tracking URI that does not exist yet.<\/p>\n<p>My questions are:<\/p>\n<ol>\n<li>Why does that happen?<\/li>\n<li>Can I somehow disable this output? It clutters my output too much because if I directly start calling log_params, log_metrics, etc., I get warnings for these calls too. These warnigns then look like:<\/li>\n<\/ol>\n<pre><code>INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\nINFO  [alembic.runtime.migration] Context impl SQLiteImpl.\nINFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n<\/code><\/pre>\n<ol start=\"3\">\n<li>What is the correct way to create a new SQLite database in mlflow?<\/li>\n<\/ol>\n<p><strong>Addition<\/strong>:\nThis also happens when I create multiple experiments in the same script, but this does NOT happen when I create one experiment in a script, then run the script again to create the second experiment. It seems like some kind of global state is not set properly in MLFlow \/ the SQLite engine?<\/p>\n<pre><code>for i in range(3):\n    print(_i)\n    mlflow.set_tracking_uri(tracking_uri)\n    mlflow.create_experiment(&quot;experiment_%d&quot; % _)\n<\/code><\/pre>\n<p><strong>EDIT<\/strong><\/p>\n<p>It can be disabled this way:<\/p>\n<pre><code>import logging, sys\nlogging.disable(sys.maxsize)\n<\/code><\/pre>\n<p>Unfortunately that is not a good solution as it disables logging globally.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-04-23 21:57:53.907 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-04-23 22:10:43.19 UTC",
        "Question_score":2,
        "Question_tags":"python|database|sqlite|mlflow",
        "Question_view_count":308,
        "Owner_creation_date":"2014-07-10 22:45:36.71 UTC",
        "Owner_last_access_date":"2021-11-11 21:25:20.757 UTC",
        "Owner_reputation":1607,
        "Owner_up_votes":139,
        "Owner_down_votes":15,
        "Owner_views":248,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"London, UK",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67237264",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68823606,
        "Question_title":"Difference between tracking_uri and the backend store uri in MLFLOW",
        "Question_body":"<p>I am using Mlflow for my project hosting it in an EC2 instance. I was wondering in MlFlow what is the difference between the backend_store_uri we set when we launch the server and the trarcking_uri ?<\/p>\n<p>Thanks,<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-17 20:25:00.84 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"uri|tracking|mlflow",
        "Question_view_count":682,
        "Owner_creation_date":"2020-03-25 10:10:52.3 UTC",
        "Owner_last_access_date":"2022-09-23 08:20:45.11 UTC",
        "Owner_reputation":13,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":"<p><code>tracking_uri<\/code> is the URL of the MLflow server (remote, or built-in in Databricks) that will be used to log metadata &amp; model (see <a href=\"https:\/\/mlflow.org\/docs\/latest\/quickstart.html#launch-a-tracking-server-on-a-remote-machine\" rel=\"nofollow noreferrer\">doc<\/a>).  In your case, this will be the URL pointing to your EC2 instance that should be configured in programs that will log parameters into your server.<\/p>\n<p><code>backend_store_uri<\/code> - is used by MLflow server to configure where to store this data - on filesystem, in SQL-compatible database, etc. (see <a href=\"https:\/\/mlflow.org\/docs\/latest\/cli.html#cmdoption-mlflow-server-backend-store-uri\" rel=\"nofollow noreferrer\">doc<\/a>). If you use SQL database, then you also need to provide the <code>--default-artifact-root<\/code> option to point where to store generated artifacts (images, model files, etc.)<\/p>",
        "Answer_comment_count":2.0,
        "Answer_creation_date":"2021-08-18 06:58:43.973 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68823606",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61871515,
        "Question_title":"MLflow Artifacts Storing But Not Listing In UI",
        "Question_body":"<p>I've run into an issue using MLflow server. When I first ran the command to start an mlflow server on an ec2 instance, everything worked fine. Now, although logs and artifacts are being stored to postgres and s3, the UI is not listing the artifacts. Instead, the artifact section of the UI shows:<\/p>\n\n<pre><code>Loading Artifacts Failed\nUnable to list artifacts stored under &lt;s3-location&gt; for the current run. Please contact your tracking server administrator to notify them of this error, which can happen when the tracking server lacks permission to list artifacts under the current run's root artifact directory.\n<\/code><\/pre>\n\n<p>But when I check in s3, I see the artifact in the s3 location that the error shows. What could possibly have started causing this as it used to work not too long ago and nothing was changed on the ec2 that is hosting mlflow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-18 14:09:54.053 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":9,
        "Question_tags":"amazon-s3|amazon-ec2|artifact|mlflow",
        "Question_view_count":3949,
        "Owner_creation_date":"2014-11-26 14:40:35.813 UTC",
        "Owner_last_access_date":"2021-08-12 15:37:44.573 UTC",
        "Owner_reputation":945,
        "Owner_up_votes":35,
        "Owner_down_votes":1,
        "Owner_views":148,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61871515",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56700687,
        "Question_title":"Installing dependencies from (Conda) environment.yml without Conda?",
        "Question_body":"<p>I currently use Conda to capture my dependencies for a python project in a <code>environment.yml<\/code>.<\/p>\n\n<p>When I build a docker service from the project I need to reinstall these dependencies. I would like to get around, having to add (mini-)conda to my docker image.<\/p>\n\n<p>Is it possible to parse <code>environment.yml<\/code> with pip\/pipenv or transform this into a corresponding <code>requirements.txt<\/code>?<\/p>\n\n<p>(I don't want to leave conda just yet, as this is what MLflow captures, when I log models)<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-06-21 09:33:50.463 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-06-21 09:57:48.257 UTC",
        "Question_score":1,
        "Question_tags":"python|docker|pip|conda|mlflow",
        "Question_view_count":1601,
        "Owner_creation_date":"2012-05-13 19:20:30.51 UTC",
        "Owner_last_access_date":"2022-09-13 14:34:11.823 UTC",
        "Owner_reputation":948,
        "Owner_up_votes":592,
        "Owner_down_votes":1,
        "Owner_views":132,
        "Answer_body":"<p>Nope.<\/p>\n\n<ol>\n<li><p><code>conda<\/code> automatically installs dependencies of conda packages. These are resolved differently by <code>pip<\/code>, so you'd have to resolve the Anaconda dependency tree in your transformation script.<\/p><\/li>\n<li><p>Many <code>conda<\/code> packages are non-Python. You couldn't install those dependencies with <code>pip<\/code> at all.<\/p><\/li>\n<li><p>Some <code>conda<\/code> packages contain binaries that were compiled with the Anaconda compiler toolchain. Even if the corresponding <code>pip<\/code> package can compile such binaries on installation, it wouldn't be using the Anaconda toolchain. What you'd get would be fundamentally different from the corresponding <code>conda<\/code> package.<\/p><\/li>\n<li><p>Some <code>conda<\/code> packages have fixes applied, which are missing from corresponding <code>pip<\/code> packages.<\/p><\/li>\n<\/ol>\n\n<p>I hope this is enough to convince you that your idea won't fly.<\/p>\n\n<p>Installing Miniconda isn't really a big deal. Just do it :-)<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2019-06-21 09:46:43.227 UTC",
        "Answer_score":3.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56700687",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72443352,
        "Question_title":"How to save summary of pyGAM using MLflow?",
        "Question_body":"<p>Getting None in return while trying to save output of pyGAM summary function in a variable or file to log it using MLflow .<\/p>\n<pre><code>gam = LinearGAM(s(0, n_splines=20) + s(1) + s(2)+ s(3)+s(4)+s(5)+s(6)+s(7)+s(8)+s(9)+s(10)+s(11)+s(12)+s(13)+s(14)+s(15)+s(16)+s(17)).fit(X_GAM, Y_GAM)\ngam.summary()\noutput = gam.summary()\ntype(output)\n<\/code><\/pre>\n<p><strong>Output:<\/strong><\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/Ub0Gs.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/Ub0Gs.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>NoneType<\/p>\n<p>Is there any efficient way to store pyGAM summary output using MLflow?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-31 06:53:01.097 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-05-31 07:17:08.13 UTC",
        "Question_score":0,
        "Question_tags":"python-3.x|machine-learning|mlflow|pygam",
        "Question_view_count":28,
        "Owner_creation_date":"2016-01-12 12:36:46.603 UTC",
        "Owner_last_access_date":"2022-09-23 16:01:34.33 UTC",
        "Owner_reputation":55,
        "Owner_up_votes":14,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Kolkata, West Bengal, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72443352",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73064066,
        "Question_title":"Error logging Spark model with mlflow to databricks registry, via databricks-connect",
        "Question_body":"<p>I'm trying to log a trained spark model on mlflow using databricks-connect. I want this model to be logged in the Databricks registry. For now, my code looks like this:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.set_tracking_uri(&quot;databricks&quot;)\nmlflow.set_experiment(&quot;\/Users\/xxxxx\/experiment_name&quot;)\n\nwith mlflow.start_run(run_name=&quot;my_run&quot;) as _:\n    mlflow.spark.log_model(my_spark_model, &quot;my_model&quot;)\n<\/code><\/pre>\n<p>When it runs the log_model line, execution breaks with the following stack trace:<\/p>\n<blockquote>\n<p>22\/07\/21 11:05:03 WARN ProtoSerializer: Failed to deserialize remote exception\njava.io.InvalidClassException: failed to read class descriptor\nat java.io.ObjectInputStream.readNonProxyDesc(Unknown Source)\nat java.io.ObjectInputStream.readClassDesc(Unknown Source)\nat java.io.ObjectInputStream.readOrdinaryObject(Unknown Source)\nat java.io.ObjectInputStream.readObject0(Unknown Source)\nat java.io.ObjectInputStream.readObject(Unknown Source)\nat java.io.ObjectInputStream.readObject(Unknown Source)\nat org.apache.spark.sql.util.ProtoSerializer.$anonfun$deserializeObject$1(ProtoSerializer.scala:6618)\nat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\nat org.apache.spark.sql.util.ProtoSerializer.deserializeObject(ProtoSerializer.scala:6603)\nat org.apache.spark.sql.util.ProtoSerializer.deserializeException(ProtoSerializer.scala:6634)\nat com.databricks.service.SparkServiceRemoteFuncRunner.executeRPC(SparkServiceRemoteFuncRunner.scala:188)\nat com.databricks.service.SparkServiceRemoteFuncRunner.$anonfun$execute0$1(SparkServiceRemoteFuncRunner.scala:121)\nat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\nat com.databricks.service.SparkServiceRemoteFuncRunner.withRetry(SparkServiceRemoteFuncRunner.scala:135)\nat com.databricks.service.SparkServiceRemoteFuncRunner.execute0(SparkServiceRemoteFuncRunner.scala:113)\nat com.databricks.service.SparkServiceRemoteFuncRunner.$anonfun$execute$1(SparkServiceRemoteFuncRunner.scala:86)\nat com.databricks.spark.util.Log4jUsageLogger.recordOperation(UsageLogger.scala:247)\nat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:429)\nat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:408)\nat com.databricks.service.SparkServiceRPCClientStub.recordOperation(SparkServiceRPCClientStub.scala:58)\nat com.databricks.service.SparkServiceRemoteFuncRunner.execute(SparkServiceRemoteFuncRunner.scala:78)\nat com.databricks.service.SparkServiceRemoteFuncRunner.execute$(SparkServiceRemoteFuncRunner.scala:67)\nat com.databricks.service.SparkServiceRPCClientStub.execute(SparkServiceRPCClientStub.scala:58)\nat com.databricks.service.SparkServiceRPCClientStub.fileSystemOperation(SparkServiceRPCClientStub.scala:297)\nat com.databricks.service.FSClient.send(FSClient.scala:51)\nat com.databricks.service.FSClient.getFileStatus(FSClient.scala:181)\nat org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426)\nat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:675)\nat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\nat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\nat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\nat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:175)\nat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:170)\nat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:43)\nat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\nat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\nat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:284)\nat scala.util.Try$.apply(Try.scala:213)\nat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:284)\nat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\nat java.lang.reflect.Method.invoke(Unknown Source)\nat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\nat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\nat py4j.Gateway.invoke(Gateway.java:295)\nat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\nat py4j.commands.CallCommand.execute(CallCommand.java:79)\nat py4j.GatewayConnection.run(GatewayConnection.java:251)\nat java.lang.Thread.run(Unknown Source)\nCaused by: java.lang.ClassNotFoundException: com.databricks.backend.daemon.data.common.InvalidMountException\nat java.net.URLClassLoader.findClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat java.lang.ClassLoader.loadClass(Unknown Source)\nat java.lang.Class.forName0(Native Method)\nat java.lang.Class.forName(Unknown Source)\nat org.apache.spark.util.Utils$.classForName(Utils.scala:242)\nat org.apache.spark.sql.util.SparkServiceObjectInputStream.readResolveClassDescriptor(SparkServiceObjectInputStream.scala:60)\nat org.apache.spark.sql.util.SparkServiceObjectInputStream.readClassDescriptor(SparkServiceObjectInputStream.scala:55)\n... 51 more\n**22\/07\/21 11:05:03 ERROR Instrumentation: com.databricks.service.SparkServiceRemoteException: com.databricks.backend.daemon.data.common.InvalidMountException: Error while using path \/databricks\/mlflow-tracking\/000000000000000\/0a0a0a0a0a0a0a0a0a0a\/artifacts\\experiment_name\/sparkml for resolving path '\/000000000000000\/0a0a0a0a0a0a0a0a0a0a\/artifacts\\experiment_name\/sparkml' within mount at '\/databricks\/mlflow-tracking'.&gt; **<\/p>\n<\/blockquote>\n<blockquote>\n<p>&lt;...&gt;&gt;<\/p>\n<\/blockquote>\n<blockquote>\n<p><strong>Caused by: java.io.IOException: No FileSystem for scheme: unsupported-access-mechanism-for-path--use-mlflow-client<\/strong>\nat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2660)\nat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\nat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\nat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\nat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\nat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\nat com.databricks.backend.daemon.data.client.DatabricksFileSystemV2Factory.createFileSystem(DatabricksFileSystemV2Factory.scala:124)\nat com.databricks.backend.daemon.data.filesystem.MountEntryResolver.$anonfun$resolve$1(MountEntryResolver.scala:67)\nat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:395)\nat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:484)\nat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:504)\nat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:266)\nat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\nat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:261)\nat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:258)\nat com.databricks.common.util.locks.LoggedLock$.withAttributionContext(LoggedLock.scala:73)\nat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:305)\nat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:297)\nat com.databricks.common.util.locks.LoggedLock$.withAttributionTags(LoggedLock.scala:73)\nat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:479)\nat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:404)\nat com.databricks.common.util.locks.LoggedLock$.recordOperationWithResultTags(LoggedLock.scala:73)\nat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:395)\nat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:367)\nat com.databricks.common.util.locks.LoggedLock$.recordOperation(LoggedLock.scala:73)\nat com.databricks.common.util.locks.LoggedLock$.withLock(LoggedLock.scala:120)\nat com.databricks.common.util.locks.PerKeyLock.withLock(PerKeyLock.scala:36)\nat com.databricks.backend.daemon.data.filesystem.MountEntryResolver.resolve(MountEntryResolver.scala:64)&gt;<\/p>\n<\/blockquote>\n<blockquote>\n<p>&lt;...&gt;\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _&gt;<\/p>\n<\/blockquote>\n<blockquote>\n<p>answer = 'xro1535'\ngateway_client = &lt;py4j.java_gateway.GatewayClient object at 0x0000023716B5BE20&gt;\ntarget_id = 'o1532', name = 'copyToLocalFile'&gt;<\/p>\n<pre><code>def get_return_value(answer, gateway_client, target_id=None, name=None):\n    &quot;&quot;&quot;Converts an answer received from the Java gateway into a Python object.\n\n    For example, string representation of integers are converted to Python\n    integer, string representation of objects are converted to JavaObject\n    instances, etc.\n\n    :param answer: the string returned by the Java gateway\n    :param gateway_client: the gateway client used to communicate with the Java\n        Gateway. Only necessary if the answer is a reference (e.g., object,\n        list, map)\n    :param target_id: the name of the object from which the answer comes from\n        (e.g., *object1* in `object1.hello()`). Optional.\n    :param name: the name of the member from which the answer comes from\n        (e.g., *hello* in `object1.hello()`). Optional.\n    &quot;&quot;&quot;\n    if is_error(answer)[0]:\n        if len(answer) &gt; 1:\n            type = answer[1]\n            value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\n            if answer[1] == REFERENCE_TYPE:\n               raise Py4JJavaError(\n                    &quot;An error occurred while calling {0}{1}{2}.\\n&quot;.\n                    format(target_id, &quot;.&quot;, name), value)\n<\/code><\/pre>\n<p>E                   py4j.protocol.Py4JJavaError: An error occurred while calling o1532.copyToLocalFile.\nE                   : <strong>java.io.IOException: (null) entry in command string: null chmod 0644 C:\\Users\\itscarlayall\\AppData\\Local\\Temp\\tmpalmxdo16\\model\\sparkml\\metadata_SUCCESS<\/strong>\nE                       at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\nE                       at org.apache.hadoop.util.Shell.execCommand(Shell.java:869)\nE                       at org.apache.hadoop.util.Shell.execCommand(Shell.java:852)\nE                       at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\nE                       at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.(RawLocalFileSystem.java:225)\nE                       at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.(RawLocalFileSystem.java:209)\nE                       at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\nE                       at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\nE                       at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-21 09:50:54.547 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|databricks|mlflow|databricks-connect",
        "Question_view_count":50,
        "Owner_creation_date":"2017-09-24 08:15:07.953 UTC",
        "Owner_last_access_date":"2022-09-23 11:38:23.76 UTC",
        "Owner_reputation":56,
        "Owner_up_votes":47,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Madrid, Espa\u00f1a",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73064066",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":55715401,
        "Question_title":"Migrating Runs to MLFlow 0.9",
        "Question_body":"<p>we have been using MLFlow 0.8.2 (with a local file store) for a while, and I was happy to see the release of MLFlow 0.9. After upgrading to the new version, I realized that pointing the MLFLow server to the old file store leads to a non-working web UI (I just see some image of a waterfall).<\/p>\n\n<p>Is there a recommendation for proper migration of data when upgrading?<\/p>\n\n<p>Thanks a lot in advance,<\/p>\n\n<p>Da<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2019-04-16 19:29:35.623 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"mlflow",
        "Question_view_count":49,
        "Owner_creation_date":"2014-06-23 05:48:30.47 UTC",
        "Owner_last_access_date":"2019-05-09 18:45:09.163 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"M\u00fcnchen, Deutschland",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/55715401",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61570597,
        "Question_title":"How to log source name and version on a MLFlow server from Jupyer lab",
        "Question_body":"<p>My setup:<\/p>\n\n<ol>\n<li>I have a running remote MLFlow server.<\/li>\n<li>I have a git tracked project consisting of a .ipynb notebook.<\/li>\n<\/ol>\n\n<p>What am I doing:<\/p>\n\n<ol>\n<li>Firing up a jupyer lab server from inside the git tracked project.<\/li>\n<li><p>Running mlflow runs from the notebook. <\/p>\n\n<pre><code>        mlflow.log_params(params)\n        mlflow.log_metrics(metrics)\n        mlflow.h2o.log_model(m, \"model\")```\n<\/code><\/pre><\/li>\n<\/ol>\n\n<p>Now the issue is, as shown below in the image, MLFlow by default cannot track:<\/p>\n\n<ul>\n<li>The source name -> defaults to the ipython kernel name. <\/li>\n<li>The source version.<\/li>\n<\/ul>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/eGeCJ.png\" rel=\"nofollow noreferrer\">tracking server snapshot<\/a><\/p>\n\n<ol>\n<li>Is there a way to manually control the source name and the source version? I noticed the older mlflow versions exposed these two parameters as part of mlflow.start_run() method. This is not the case anymore.<\/li>\n<li>Is there a specific setup I need to follow to enable source and version tracking from jupyter by default?<\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-03 06:42:42.917 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"jupyter-lab|mlflow",
        "Question_view_count":66,
        "Owner_creation_date":"2014-01-30 08:58:09.527 UTC",
        "Owner_last_access_date":"2021-12-08 01:50:32.913 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Auckland, New Zealand",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61570597",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70538098,
        "Question_title":"Databricks MLFlow AutoML XGBoost can't predict_proba()",
        "Question_body":"<p>I used AutoML in Databricks Notebooks for a binary classification problem and the winning model flavor was XGBoost (big surprise).<\/p>\n<p>The outputted model is of this variety:<\/p>\n<pre><code>mlflow.pyfunc.loaded_model:\n      artifact_path: model\n      flavor: mlflow.sklearn\n      run_id: 123456789\n<\/code><\/pre>\n<p>Any idea why when I use <code>model.predict_proba(X)<\/code>, I get this response?<\/p>\n<p><code>AttributeError: 'PyFuncModel' object has no attribute 'predict_proba'<\/code><\/p>\n<p>I know it is possible to get the probabilities because ROC\/AUC is a metric used for tuning the model. Any help would be amazing!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-31 01:02:03.883 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pandas|scikit-learn|databricks|xgboost|mlflow",
        "Question_view_count":451,
        "Owner_creation_date":"2019-07-11 07:02:37.217 UTC",
        "Owner_last_access_date":"2022-09-21 21:43:57.89 UTC",
        "Owner_reputation":77,
        "Owner_up_votes":35,
        "Owner_down_votes":0,
        "Owner_views":17,
        "Answer_body":"<p>I had the same issue with catboost model.\nThe way I solved it was by saving the artifacts in a local dir<\/p>\n<pre><code>import os\nfrom mlflow.tracking import MlflowClient\nclient = MlflowClient()\nlocal_dir = &quot;\/dbfs\/FileStore\/user\/models&quot;\nlocal_path = client.download_artifacts('run_id', &quot;model&quot;, local_dir)```\n\n```model_path = '\/dbfs\/FileStore\/user\/models\/model\/model.cb'\nmodel = CatBoostClassifier()\nmodel = model.load_model(model_path)\nmodel.predict_proba(test_set)```\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-03-08 12:56:27.86 UTC",
        "Answer_score":2.0,
        "Owner_location":"San Francisco, CA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70538098",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57987999,
        "Question_title":"Delete a run in the experiment of mlflow from the UI so the run does not exist in backend store",
        "Question_body":"<p>I found deleting a <code>run<\/code> only change the state from <code>active<\/code> to <code>deleted<\/code>, because the run is still visible in the UI if searching by <code>deleted<\/code>. <\/p>\n\n<p>Is it possible to remove a <code>run<\/code> from the UI to save the space? \nWhen removing a run, does the artifact correspond to the run is also removed?<\/p>\n\n<p>If not, can the run be removed through rest call?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-09-18 08:10:47.973 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-09-18 08:47:48.593 UTC",
        "Question_score":6,
        "Question_tags":"mlflow",
        "Question_view_count":3582,
        "Owner_creation_date":"2014-08-18 14:07:01.673 UTC",
        "Owner_last_access_date":"2022-09-15 04:40:38.707 UTC",
        "Owner_reputation":2521,
        "Owner_up_votes":447,
        "Owner_down_votes":13,
        "Owner_views":197,
        "Answer_body":"<p>You can't do it via the web UI but you can from a python terminal<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\nmlflow.delete_experiment(69)\n<\/code><\/pre>\n\n<p>Where 69 is the experiment ID<\/p>",
        "Answer_comment_count":3.0,
        "Answer_creation_date":"2019-09-29 21:39:34.477 UTC",
        "Answer_score":2.0,
        "Owner_location":"Berlin, Germany",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57987999",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60616879,
        "Question_title":"Logging Artifacts from MlFlow on GCS Bucket",
        "Question_body":"<p>I have a running MlFlow server on GCS VM instance. I have created a bucket to log the artifacts.\nThis is the command I'm running to start the server and for specifying bucket path-<\/p>\n\n<pre><code>mlflow server --default-artifact-root gs:\/\/gcs_bucket\/artifacts --host x.x.x.x\n<\/code><\/pre>\n\n<p>But facing this error:<\/p>\n\n<pre><code>TypeError: stat: path should be string, bytes, os.PathLike or integer, not ElasticNet\n<\/code><\/pre>\n\n<p>Note- The mlflow server is running fine with the specified host alone. The problem is in the way when I'm specifying the storage bucket path.\nI have given permission of storage api by using these commands:<\/p>\n\n<pre><code>gcloud auth application-default login\ngcloud auth login\n<\/code><\/pre>\n\n<p>Also, on printing the artifact URI, this is what I'm getting:<\/p>\n\n<pre><code>mlflow.get_artifact_uri()\n<\/code><\/pre>\n\n<p>Output:<\/p>\n\n<pre><code>gs:\/\/gcs_bucket\/artifacts\/0\/122481bf990xxxxxxxxxxxxxxxxxxxxx\/artifacts\n<\/code><\/pre>\n\n<p>So in the above path from where this is coming <code>0\/122481bf990xxxxxxxxxxxxxxxxxxxxx\/artifacts<\/code> and why it's not getting auto-created at <code>gs:\/\/gcs_bucket\/artifacts<\/code><\/p>\n\n<p>After debugging more, why it's not able to get the local path from VM:\n<a href=\"https:\/\/i.stack.imgur.com\/ubDU0.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ubDU0.png\" alt=\"enter image description here\"><\/a><\/p>\n\n<p>And this error I'm getting on VM:<\/p>\n\n<pre><code>ARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '.\/mlruns\/mlruns\/meta.yaml' does not exist.\nTraceback (most recent call last):\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 197, in list_experiments\n   experiment = self._get_experiment(exp_id, view_type)\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/store\/tracking\/file_store.py\", line 256, in _get_experiment\n   meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n File \"\/usr\/local\/lib\/python3.6\/dist-packages\/mlflow\/utils\/file_utils.py\", line 160, in read_yaml\n   raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\nmlflow.exceptions.MissingConfigException: Yaml file '.\/mlruns\/mlruns\/meta.yaml' does not exist.\n<\/code><\/pre>\n\n<p>Can I get a solution to this and what I'm missing?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_creation_date":"2020-03-10 11:40:20.677 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-03-11 10:26:11.777 UTC",
        "Question_score":4,
        "Question_tags":"python|google-cloud-platform|google-cloud-storage|mlflow",
        "Question_view_count":2153,
        "Owner_creation_date":"2015-12-26 10:00:57.623 UTC",
        "Owner_last_access_date":"2022-09-24 13:39:24.72 UTC",
        "Owner_reputation":736,
        "Owner_up_votes":69,
        "Owner_down_votes":2,
        "Owner_views":234,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60616879",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69873383,
        "Question_title":"MLflow FileNotFound when calling spark_udf from pycharm with databricks-connect",
        "Question_body":"<p>I am saving a scikit-learn trained model to MLflow's model registry in my Windows laptop. I am using databricks-connect to connect to an Azure Databricks cluster and train models there from my local Pycharm, but for development I launch the model registry in my laptopt and save the trained models in it - to avoid having to set up accessing DBFS remotely.<\/p>\n<p>I am having trouble with the spark_udf function. <strong>I can read the model from my laptop's model registry but cannot use it as a UDF in my Databricks cluster<\/strong>:<\/p>\n<pre><code>model_udf = mlflow.pyfunc.spark_udf(spark, &quot;models:\/mymodel\/production&quot;)  # this works fine\nstruct_col = F.struct(*df.columns)\npredictions = df.withColumn(&quot;pred_spark&quot;, model_udf(struct_col))  \npredictions.show()                                        # throws an exception(see below)\n<\/code><\/pre>\n<p>pyspark.sql.utils.PythonException: An exception was thrown from a UDF: 'FileNotFoundError:<\/p>\n<p>[Errno 2] No such file or directory:<\/p>\n<p>'\/local_disk0\/spark-1fa39b20-9d2c-4697-957c-392d80326dee\/executor-57b039d8-7405-47c4-b072-612e9b87b3dd\/spark-e442241d-4007-4c6e-8acd-bf2a35b1a455\/isolatedSparkFiles\/044cd765-f5f7-46b3-9efb-0944cc91ef4d\/c:\\temp\\tmpsl4hpeyt.zip'<\/p>\n<p>The last part is weird as it mixes linux-style routes with Windows route (like a route in my Windows laptop's local dir). I thought that the driver would read the model from the model registry and broadcast it to the workers to call the UDF, but looks like the workers are trying to fetch it directly from the remote model registry, is this right? Is there a solution that does not require saving the model in the remote model registry - or at least, configuring the security to access DBFS?<\/p>\n<p><strong>EDIT:<\/strong> After having set up registering the model into the remote registry (<a href=\"https:\/\/docs.databricks.com\/applications\/mlflow\/access-hosted-tracking-server.html\" rel=\"nofollow noreferrer\">not that difficult!<\/a>) I can now download the registered model as a sklearn model and do predictions with it, but I cannot do the same via spark_udf. I get either<\/p>\n<ul>\n<li>The same FileNotFound error if I specify the model via runs:\/.... in function spark_udf<\/li>\n<li>An SSL error (unverified self-signed certificate) if I specify the model via model:\/... in the spark_udf, even though I have explicitly added a new line <code>insecure = True<\/code> in my .databrickscfg - and because that was not working, also added <code>os.environ[&quot;MLFLOW_TRACKING_INSECURE_TLS&quot;] = &quot;true&quot;<\/code> but has no effect. I guess it is doing something because at least I can download the model from the registry when it is not a spark_udf, but looks like &quot;the workers?&quot; are having issues when they try to do the same (that's my guess, no idea if it makes sense)<\/li>\n<\/ul>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-07 14:35:05.043 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-08 21:13:35.477 UTC",
        "Question_score":1,
        "Question_tags":"apache-spark|pyspark|mlflow|databricks-connect",
        "Question_view_count":180,
        "Owner_creation_date":"2015-12-29 08:10:18.09 UTC",
        "Owner_last_access_date":"2022-09-21 18:17:26.213 UTC",
        "Owner_reputation":308,
        "Owner_up_votes":10,
        "Owner_down_votes":1,
        "Owner_views":75,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Madrid, Spain",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69873383",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68643893,
        "Question_title":"Upload an image file with JSON Format",
        "Question_body":"<p>I am trying to build a machine learning algorithm an deploy it with REST API. While I am doing this I got some error like &quot;MALFORMED_REQUEST&quot;, &quot;message&quot;: &quot;Failed to parse input from JSON. Ensure that input is a valid JSON formatted string.&quot;. In below you can see my code. Can you please tell me what am I doing wrong? Thanks in advance.<\/p>\n<pre><code>import json\nimport requests\nimport base64\n\n#data = 'cat_Test2.jpg'\n\n\nwith open('.\/Dataset\/test2\/cat_Test2.jpg', mode='rb') as file:\n    img = file.read()\ndata = base64.encodebytes(img).decode('utf-8')\n\n#print(json.dumps(data))\n#print(data)\nheaders = {'Content-Type': 'application\/json'}\nrequest_uri = 'http:\/\/127.0.0.1:5000\/invocations'\n\nif __name__ == '__main__':\n    try:\n        response = requests.post(request_uri, data=data, headers=headers)\n        print(response.content)\n        print('done!!!')\n    except Exception as ex:\n        raise (ex)\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-08-03 23:47:20.357 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|json|rest|mlflow",
        "Question_view_count":389,
        "Owner_creation_date":"2016-04-14 18:05:16.247 UTC",
        "Owner_last_access_date":"2022-05-18 21:45:05.52 UTC",
        "Owner_reputation":98,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":"<p>The MLflow model server accepts as input either JSON (pandas split-orient format) or CSV.\n<a href=\"https:\/\/mlflow.org\/docs\/latest\/models.html#deploy-mlflow-models\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/models.html#deploy-mlflow-models<\/a><\/p>\n<p>You will need to convert your image into one of those two formats. Example:\n<a href=\"https:\/\/github.com\/amesar\/mlflow-examples\/tree\/master\/python\/keras_tf_mnist#score-mnist-png-file\" rel=\"nofollow noreferrer\">https:\/\/github.com\/amesar\/mlflow-examples\/tree\/master\/python\/keras_tf_mnist#score-mnist-png-file<\/a><\/p>",
        "Answer_comment_count":1.0,
        "Answer_creation_date":"2021-08-04 00:09:05.37 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68643893",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73213365,
        "Question_title":"Mlflow \"invocations\" prefix",
        "Question_body":"<p>We are deploying some MLflow models using docker and Kubernetes and\nWe are using Ingress load balancer in K8S is mandatory for security reasons, but right now we need to deploy more than one mlflow image in the same cluster.\nWhen we run the container the model serving start the application using  &quot;\/invocations&quot; path for the POST requests.\nThat means that we cann\u00b4t differentiate the model using the prefix, cause every container is using the same prefix.<\/p>\n<p>My question is,is there any way to change &quot;\/invocations&quot; prefix on model Mlflow images?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-02 20:21:59.17 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-03 21:46:53.487 UTC",
        "Question_score":0,
        "Question_tags":"python|databricks|mlflow",
        "Question_view_count":44,
        "Owner_creation_date":"2022-06-10 19:20:31.17 UTC",
        "Owner_last_access_date":"2022-09-23 16:37:58.107 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73213365",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":54233746,
        "Question_title":"Filter mlflow runs by commit ID",
        "Question_body":"<p>When using the UI of MlFlow, is it possible to filter\/search the runs using the (git) commit ID? I manage to search by parameters but it doesn't seem like there's a way to filter by the commit ID.<\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/npkFO.png\" rel=\"noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/npkFO.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-01-17 10:22:40.897 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-01-18 07:23:50.323 UTC",
        "Question_score":4,
        "Question_tags":"machine-learning|version-control|mlflow",
        "Question_view_count":982,
        "Owner_creation_date":"2011-03-22 10:28:37.227 UTC",
        "Owner_last_access_date":"2022-09-23 13:51:41.56 UTC",
        "Owner_reputation":11410,
        "Owner_up_votes":2846,
        "Owner_down_votes":6,
        "Owner_views":1782,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/54233746",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73499320,
        "Question_title":"Error loading model from mlflow: java.io.StreamCorruptedException: invalid type code: 00",
        "Question_body":"<p>I'm using Databricks Connect version 9.1.16 to connect to a databricks external cluster with spark version 3.1 and download a Pyspark ML model that's been trained and saved using mlflow.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.set_tracking_uri(&quot;databricks&quot;)\nmodel_h = mlflow.spark.load_model(model_uri=&quot;models:\/model_name\/model_version&quot;)\n<\/code><\/pre>\n<p>I get the following output and error:<\/p>\n<pre><code>2022\/08\/26 11:54:18 INFO mlflow.spark: 'models:\/model_name\/model_version' resolved as 'dbfs:\/\/databricks\/databricks\/mlflow-registry\/model_id\/models\/model'\n2022\/08\/26 11:54:25 INFO mlflow.spark: URI 'dbfs:\/\/databricks\/databricks\/mlflow-registry\/model_id\/models\/model\/sparkml' does not point to the current DFS.\n2022\/08\/26 11:54:25 INFO mlflow.spark: File 'dbfs:\/\/databricks\/databricks\/mlflow-registry\/model_id\/models\/model\/sparkml' not found on DFS. Will attempt to upload the file.\n2022\/08\/26 11:55:06 INFO mlflow.spark: Copied SparkML model to \/tmp\/mlflow\/model_id\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\nc:\\Users\\carlafernandez\\Documents\\my_notebook.ipynb Celda 5 in &lt;cell line: 2&gt;()\n      1 mlflow.set_tracking_uri(&quot;databricks&quot;)\n----&gt; 2 model_h = mlflow.spark.load_model(model_uri=&quot;models:\/model_name\/model_version&quot;)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\mlflow\\spark.py:711, in load_model(model_uri, dfs_tmpdir)\n    708 local_model_path = _download_artifact_from_uri(model_uri)\n    709 _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\n--&gt; 711 return _load_model(model_uri=model_uri, dfs_tmpdir_base=dfs_tmpdir)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\mlflow\\spark.py:660, in _load_model(model_uri, dfs_tmpdir_base)\n    658     return _load_model_databricks(model_uri, dfs_tmpdir)\n    659 model_uri = _HadoopFileSystem.maybe_copy_from_uri(model_uri, dfs_tmpdir)\n--&gt; 660 return PipelineModel.load(model_uri)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\util.py:463, in MLReadable.load(cls, path)\n    460 @classmethod\n    461 def load(cls, path):\n    462     &quot;&quot;&quot;Reads an ML instance from the input path, a shortcut of `read().load(path)`.&quot;&quot;&quot;\n--&gt; 463     return cls.read().load(path)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\pipeline.py:258, in PipelineModelReader.load(self, path)\n    256 metadata = DefaultParamsReader.loadMetadata(path, self.sc)\n    257 if 'language' not in metadata['paramMap'] or metadata['paramMap']['language'] != 'Python':\n--&gt; 258     return JavaMLReader(self.cls).load(path)\n    259 else:\n    260     uid, stages = PipelineSharedReadWrite.load(metadata, self.sc, path)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\ml\\util.py:413, in JavaMLReader.load(self, path)\n    411 if not isinstance(path, str):\n    412     raise TypeError(&quot;path should be a string, got type %s&quot; % type(path))\n--&gt; 413 java_obj = self._jread.load(path)\n    414 if not hasattr(self._clazz, &quot;_from_java&quot;):\n    415     raise NotImplementedError(&quot;This Java ML type cannot be loaded into Python currently: %r&quot;\n    416                               % self._clazz)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\py4j\\java_gateway.py:1304, in JavaMember.__call__(self, *args)\n   1298 command = proto.CALL_COMMAND_NAME +\\\n   1299     self.command_header +\\\n   1300     args_command +\\\n   1301     proto.END_COMMAND_PART\n   1303 answer = self.gateway_client.send_command(command)\n-&gt; 1304 return_value = get_return_value(\n   1305     answer, self.gateway_client, self.target_id, self.name)\n   1307 for temp_arg in temp_args:\n   1308     temp_arg._detach()\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\pyspark\\sql\\utils.py:117, in capture_sql_exception.&lt;locals&gt;.deco(*a, **kw)\n    115 def deco(*a, **kw):\n    116     try:\n--&gt; 117         return f(*a, **kw)\n    118     except py4j.protocol.Py4JJavaError as e:\n    119         converted = convert_exception(e.java_exception)\n\nFile c:\\Users\\carlafernandez\\miniconda3\\envs\\prueba_databricks_connect\\lib\\site-packages\\py4j\\protocol.py:326, in get_return_value(answer, gateway_client, target_id, name)\n    324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client)\n    325 if answer[1] == REFERENCE_TYPE:\n--&gt; 326     raise Py4JJavaError(\n    327         &quot;An error occurred while calling {0}{1}{2}.\\n&quot;.\n    328         format(target_id, &quot;.&quot;, name), value)\n    329 else:\n    330     raise Py4JError(\n    331         &quot;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&quot;.\n    332         format(target_id, &quot;.&quot;, name, value))\n\nPy4JJavaError: An error occurred while calling o645.load.\n: java.io.StreamCorruptedException: invalid type code: 00\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1698)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n    at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\n    at sun.reflect.GeneratedMethodAccessor311.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.readArray(ObjectInputStream.java:2093)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1655)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.readArray(ObjectInputStream.java:2093)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1655)\n    at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)\n    at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)\n    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)\n    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)\n    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)\n    at org.apache.spark.sql.util.ProtoSerializer.$anonfun$deserializeObject$1(ProtoSerializer.scala:6631)\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n    at org.apache.spark.sql.util.ProtoSerializer.deserializeObject(ProtoSerializer.scala:6616)\n    at com.databricks.service.SparkServiceRPCHandler.execute0(SparkServiceRPCHandler.scala:728)\n    at com.databricks.service.SparkServiceRPCHandler.$anonfun$executeRPC0$1(SparkServiceRPCHandler.scala:477)\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n    at com.databricks.service.SparkServiceRPCHandler.executeRPC0(SparkServiceRPCHandler.scala:372)\n    at com.databricks.service.SparkServiceRPCHandler$$anon$2.call(SparkServiceRPCHandler.scala:323)\n    at com.databricks.service.SparkServiceRPCHandler$$anon$2.call(SparkServiceRPCHandler.scala:309)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at com.databricks.service.SparkServiceRPCHandler.$anonfun$executeRPC$1(SparkServiceRPCHandler.scala:359)\n    at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n    at com.databricks.service.SparkServiceRPCHandler.executeRPC(SparkServiceRPCHandler.scala:336)\n    at com.databricks.service.SparkServiceRPCServlet.doPost(SparkServiceRPCServer.scala:167)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:550)\n    at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n    at org.eclipse.jetty.server.Server.handle(Server.java:516)\n    at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n    at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n    at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n    at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n    at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n    at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n    at java.lang.Thread.run(Thread.java:748)\n<\/code><\/pre>\n<p>So it seems like it's able to find a copy the model, but then somehow it cannot read it. It's worth noting that the same <strong>works in a databricks notebook<\/strong>, the problem only occurs using databricks connect.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-26 10:05:08.487 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"pyspark|databricks|mlflow|databricks-connect",
        "Question_view_count":23,
        "Owner_creation_date":"2017-09-24 08:15:07.953 UTC",
        "Owner_last_access_date":"2022-09-23 11:38:23.76 UTC",
        "Owner_reputation":56,
        "Owner_up_votes":47,
        "Owner_down_votes":0,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Madrid, Espa\u00f1a",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73499320",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70792868,
        "Question_title":"Serving MLFlow artifacts through `--serve-artifacts` without passing credentials",
        "Question_body":"<p>A new version of MLFlow (1.23) provided a <code>--serve-artifacts<\/code> option (via <a href=\"https:\/\/github.com\/mlflow\/mlflow\/pull\/5045\" rel=\"nofollow noreferrer\">this<\/a> pull request) along with some example code. This <em>should<\/em> allow me to simplify the rollout of a server for data scientists by only needing to give them one URL for the tracking server, rather than a URI for the tracking server, URI for the artifacts server, and a username\/password for the artifacts server. At least, that's how I understand it.<\/p>\n<p>A complication that I have is that I need to use <code>podman<\/code> instead of <code>docker<\/code> for my containers (and without relying on <code>podman-compose<\/code>). I ask that you keep those requirements in mind; I'm aware that this is an odd situation.<\/p>\n<p>What I did before this update (for MLFlow 1.22) was to create a kubernetes play yaml config, and I was successfully able to issue a <code>podman play kube ...<\/code> command to start a pod and from a different machine successfully run an experiment and save artifacts after setting the appropriate four env variables. I've been struggling with getting things working with the newest version.<\/p>\n<p>I am following the <code>docker-compose<\/code> example provided <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/mlflow_artifacts\" rel=\"nofollow noreferrer\">here<\/a>. I am trying a (hopefully) simpler approach. The following is my kubernetes play file defining a pod.<\/p>\n<pre class=\"lang-yaml prettyprint-override\"><code>apiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: &quot;2022-01-14T19:07:15Z&quot;\n  labels:\n    app: mlflowpod\n  name: mlflowpod\nspec:\n  containers:\n  - name: minio\n    image: quay.io\/minio\/minio:latest\n    ports:\n    - containerPort: 9001\n      hostPort: 9001\n    - containerPort: 9000\n      hostPort: 9000\n    resources: {}\n    tty: true\n    volumeMounts:\n    - mountPath: \/data\n      name: minio-data\n    args:\n    - server\n    - \/data\n    - --console-address\n    - :9001\n\n  - name: mlflow-tracking\n    image: localhost\/mlflow:latest\n    ports:\n    - containerPort: 80\n      hostPort: 8090\n    resources: {}\n    tty: true\n    env:\n      - name: MLFLOW_S3_ENDPOINT_URL\n        value: http:\/\/127.0.0.1:9000\n      - name: AWS_ACCESS_KEY_ID\n        value: minioadmin\n      - name: AWS_SECRET_ACCESS_KEY\n        value: minioadmin\n    command: [&quot;mlflow&quot;]\n    args:\n      - server\n      - -p \n      - 80\n      - --host \n      - 0.0.0.0\n      - --backend-store-uri \n      - sqlite:\/\/\/root\/store.db\n      - --serve-artifacts\n      - --artifacts-destination \n      - s3:\/\/mlflow\n      - --default-artifact-root \n      - mlflow-artifacts:\/\n#      - http:\/\/127.0.0.1:80\/api\/2.0\/mlflow-artifacts\/artifacts\/experiments\n      - --gunicorn-opts \n      - &quot;--log-level debug&quot;\n    volumeMounts:\n    - mountPath: \/root\n      name: mlflow-data  \n\n  volumes:\n  - hostPath:\n      path: .\/minio\n      type: Directory\n    name: minio-data\n  - hostPath:\n      path: .\/mlflow\n      type: Directory\n    name: mlflow-data\nstatus: {}\n<\/code><\/pre>\n<p>I start this with <code>podman play kube mlflowpod.yaml<\/code>. On the same machine (or a different one, it doesn't matter), I have cloned and installed <code>mlflow<\/code> into a virtual environment. From that virtual environment, I set an environmental variable <code>MLFLOW_TRACKING_URI<\/code> to <code>&lt;name-of-server&gt;:8090<\/code>. I then run the <code>example.py<\/code> file in the <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/mlflow_artifacts\" rel=\"nofollow noreferrer\"><code>mlflow_artifacts<\/code><\/a> example directory. I get the following response:<\/p>\n<pre><code>....\nbotocore.exceptions.NoCredentialsError: Unable to locate credentials\n<\/code><\/pre>\n<p>Which seems like the client needs the server credentials to minIO, which I thought the proxy was supposed to take care of.<\/p>\n<p>If I also provide the env variables<\/p>\n<pre><code>$env:MLFLOW_S3_ENDPOINT_URL=&quot;http:\/\/&lt;name-of-server&gt;:9000\/&quot; \n$env:AWS_ACCESS_KEY_ID=&quot;minioadmin&quot;\n$env:AWS_SECRET_ACCESS_KEY=&quot;minioadmin&quot;\n<\/code><\/pre>\n<p>Then things work. But that kind of defeats the purpose of the proxy...<\/p>\n<p>What is it about the proxy setup via kubernates play yaml and podman that is going wrong?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-20 20:15:11.853 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2022-01-20 20:23:39.863 UTC",
        "Question_score":1,
        "Question_tags":"kubernetes|mlflow|podman",
        "Question_view_count":773,
        "Owner_creation_date":"2011-11-14 15:53:50.42 UTC",
        "Owner_last_access_date":"2022-01-21 19:03:06.807 UTC",
        "Owner_reputation":428,
        "Owner_up_votes":11,
        "Owner_down_votes":0,
        "Owner_views":33,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70792868",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73113338,
        "Question_title":"MLFlow run not recognize Entry Point",
        "Question_body":"<p>I'm trying to deploy an experiment but when I try to run the mlflow run I have an error saying that Got unexpected extra arguments with  the name of my entry point<\/p>\n<p>my MLprojetc is<\/p>\n<pre><code>conda_env: data\/conda.yaml\n\nentry_points:\n  etl:\n    parameters:\n      username: username\n    command: &gt;\n      python includes\/main\/python\/etl.py\n      --username {username}\n  experiment:\n    parameters:\n      penalty: penalty\n      max_iter: {type: int, default: 10000}\n      username: username\n      experiment_name: experiment_name\n    command: &gt;\n      python includes\/main\/python\/experiment.py\n      --penalty {penalty}\n      --max-iter {max_iter}\n      --username {username}\n      --experiment-name {experiment_name}\n<\/code><\/pre>\n<p>And I configured a file to run on my bash called run.sh:<\/p>\n<pre><code>set MLFLOW_TRACKING_URI=databricks\nset EXPERIMENT_NAME=\/Users\/myemail\/building-deploying\nset EXPERIMENT_ID=00000000000000000\nset GITHUB_REPO=https:\/\/github.com\/databricks-edu\/Deploying-ML-Models-At-Scale\nmlflow run . \\\n  --backend databricks \\\n  --backend-config data\/cluster.json \\\n  --experiment-id $EXPERIMENT_ID \\\n  --entry-point etl \\\n  --param-list username=vnlvih\nmlflow run . \\\n  --backend databricks \\\n  --backend-config data\/cluster.json \\\n  --experiment-id $EXPERIMENT_ID \\\n  --entry-point experiment \\\n  --param-list username=vnlvih \\\n  --param-list penalty=l1 \\\n  --param-list max_iter=10000 \\\n  --param-list experiment_name=$EXPERIMENT_NAME\n<\/code><\/pre>\n<p>When I try to run this last file on bash I got the next error:<\/p>\n<pre><code>$ .\/bin\/run.sh\nUsage: mlflow run [OPTIONS] URI  \nTry 'mlflow run --help' for help.\n\nError: Got unexpected extra argument (etl)\nUsage: mlflow run [OPTIONS] URI  \nTry 'mlflow run --help' for help.\n\nError: Got unexpected extra argument (experiment)\n<\/code><\/pre>\n<p>Someone can help me?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-25 17:45:48.25 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"mlflow|entry-point",
        "Question_view_count":45,
        "Owner_creation_date":"2020-01-17 21:52:34.91 UTC",
        "Owner_last_access_date":"2022-08-07 00:17:40.293 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73113338",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72239105,
        "Question_title":"MLFlow Webhook calling Azure DevOps pipeline - retrieve body",
        "Question_body":"<p>I am using the MLFlow Webhooks , mentioned <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/model-registry-webhooks\" rel=\"nofollow noreferrer\">here<\/a>. I am using that to queue an Azure Devops Pipeline.<\/p>\n<p>However, I can't seem to to find a way to retrieve the payload variables inside my pipeline.<\/p>\n<p>E.g. during transition of models, according to the document, such a payload is passed<\/p>\n<pre><code>POST\n\/your\/endpoint\/for\/event\/model-versions\/stage-transition\n--data {\n  &quot;event&quot;: &quot;MODEL_VERSION_TRANSITIONED_STAGE&quot;,\n  &quot;webhook_id&quot;: &quot;c5596721253c4b429368cf6f4341b88a&quot;,\n  &quot;event_timestamp&quot;: 1589859029343,\n  &quot;model_name&quot;: &quot;Airline_Delay_SparkML&quot;,\n  &quot;version&quot;: &quot;8&quot;,\n  &quot;to_stage&quot;: &quot;Production&quot;,\n  &quot;from_stage&quot;: &quot;None&quot;,\n  &quot;text&quot;: &quot;Registered model 'someModel' version 8 transitioned from None to Production.&quot;\n}\n<\/code><\/pre>\n<p>My webhook is created like this:<\/p>\n<pre><code>mlflow_webhook_triggerDevOps={\n  &quot;events&quot;: [&quot;TRANSITION_REQUEST_CREATED&quot;, &quot;REGISTERED_MODEL_CREATED&quot;],\n  &quot;description&quot;: &quot;Integration with Azure DevOps&quot;,\n  &quot;status&quot;: &quot;ACTIVE&quot;,\n  &quot;http_url_spec&quot;: {\n                    &quot;url&quot;: &quot;https:\/\/dev.azure.com\/orgname\/ProjectName\/_apis\/build\/builds?definitionId=742&amp;api-version=6.0&quot;,\n                    &quot;authorization&quot;: &quot;Basic &quot; + base64_message\n                    }\n }\n\nmlflow_createwebhook=requests.post('https:\/\/databricksurl\/api\/2.0\/mlflow\/registry-webhooks\/create', headers=header, proxies=proxies, json=mlflow_webhook_body)\n<\/code><\/pre>\n<p>How do I then retrieve the payload variable e.g. model_name, inside my pipeline definition in Azure Devops?.<\/p>\n<p>I looked at <a href=\"https:\/\/stackoverflow.com\/questions\/50838651\/vsts-use-api-to-set-build-parameters-at-queue-time\">this post<\/a>, but I can't seem to see any payload information (like mentioned above) under the Network-payload tab (or I am not using properly).<\/p>\n<p>Right now, I can trigger the pipeline, but can't seem to find a way to retrieve the payload.<\/p>\n<p>Is it possible? Am I missing something?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2022-05-14 09:55:21.283 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-devops|databricks|webhooks|azure-databricks|mlflow",
        "Question_view_count":125,
        "Owner_creation_date":"2015-04-10 08:31:54.763 UTC",
        "Owner_last_access_date":"2022-09-24 09:37:37.383 UTC",
        "Owner_reputation":596,
        "Owner_up_votes":53,
        "Owner_down_votes":1,
        "Owner_views":80,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72239105",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72899762,
        "Question_title":"upload a pre-trained model on databricks mlflow experiment",
        "Question_body":"<p>Is it possible to upload  a pre-trained machine learning model (from my local computer, for which I generated a model.pkl) on databricks, and serve it?\nOr is it impossible on Databricks ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-07-07 14:38:21.163 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-08 06:55:10.48 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|databricks|mlflow|pre-trained-model",
        "Question_view_count":48,
        "Owner_creation_date":"2019-03-03 11:21:20.527 UTC",
        "Owner_last_access_date":"2022-09-23 12:01:19.95 UTC",
        "Owner_reputation":314,
        "Owner_up_votes":18,
        "Owner_down_votes":2,
        "Owner_views":105,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72899762",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71795643,
        "Question_title":"Error when loading ML model from the remote MLflow instance",
        "Question_body":"<p>I tried to load a model from the remote MLflow instance, using <code>load_model<\/code> function:<\/p>\n<pre><code>import mlflow\n\nmodel = mlflow.pyfunc.load_model(&quot;http:\/\/remote_IP_address:5000\/runs:\/&lt;run_id&gt;\/model&quot;)\n<\/code><\/pre>\n<p>I found the run_id by using the REST API:<\/p>\n<pre><code>import requests\n\nrequests.get(&quot;http:\/\/remote_IP_address:5000\/api\/2.0\/preview\/mlflow\/runs\/search&quot;,params={&quot;experiment_ids&quot;:[0,1]})\n<\/code><\/pre>\n<p>But I am receiving an error:<\/p>\n<pre><code>ValueError: not enough values to unpack (expected 2, got 1)\n<\/code><\/pre>\n<p>I suppose the error is in the URI that I am using. Can you tell me the correct way to access the remote Mlflow instance and load the model?<\/p>\n<p>p.s.\nI also tried:<\/p>\n<pre><code>mlflow.pyfunc.load_model(&quot;http:\/\/remote_Ip_address:5000\/models:\/&lt;model_name&gt;\/production&quot;)\n<\/code><\/pre>\n<p>but I received the same error.<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-08 10:44:42.147 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-04-08 10:52:44.79 UTC",
        "Question_score":0,
        "Question_tags":"python|jupyter-notebook|mlflow",
        "Question_view_count":286,
        "Owner_creation_date":"2018-06-07 09:58:08.027 UTC",
        "Owner_last_access_date":"2022-09-22 14:54:01.063 UTC",
        "Owner_reputation":499,
        "Owner_up_votes":167,
        "Owner_down_votes":1,
        "Owner_views":59,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71795643",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72143004,
        "Question_title":"How to copy local runs from mlflow to remote tracking server?",
        "Question_body":"<p>Dear mlflow community,<\/p>\n<p>I am struggeling with a performant environment for both testing and production.<\/p>\n<p>What I want to do is, train models locally and compare them in mlflow. In case I have found a good model I would like to push it to a remote mlflow instance.<\/p>\n<p>For this purpose I have set up a tracking server with postgres and S3.<\/p>\n<p>How can I push the model and all artifacts in the run to the remote mlflfow instance?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-06 14:19:46.927 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python-3.x|tensorflow|mlflow",
        "Question_view_count":72,
        "Owner_creation_date":"2014-12-23 23:50:02.193 UTC",
        "Owner_last_access_date":"2022-09-21 11:10:16 UTC",
        "Owner_reputation":1499,
        "Owner_up_votes":98,
        "Owner_down_votes":14,
        "Owner_views":297,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72143004",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69017477,
        "Question_title":"MLflow - TypeError: Only dict and DataFrame input types are supported",
        "Question_body":"<p>I'm fairly new to the software MLflow and I'm trying to make an HTTP POST request to the served model I developed but the error up in the title appears.<\/p>\n<p>Here's the situation.\nI use as a backend storage a SQLite db and as an artifact storage a local folder.\nThe command to run the mlflow server is the following (the model is in the Staging stage):\n<code>mlflow models serve -m &quot;models:\/nuovo_modello\/Staging&quot; -p 1234<\/code><\/p>\n<p>I registered the model on MLflow and this is the model schema:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/ERL5m.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/ERL5m.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>When I try to make a POST request as follows (as suggested in the TF serving guide: <a href=\"https:\/\/www.tensorflow.org\/tfx\/serving\/api_rest#request_format_2\" rel=\"nofollow noreferrer\">https:\/\/www.tensorflow.org\/tfx\/serving\/api_rest#request_format_2<\/a>)\n<code>{ &quot;instances&quot;: [ [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 3, 1, 4]] }<\/code><\/p>\n<p>or even in the JSON Content-Type as follows:\n<code>curl http:\/\/127.0.0.1:1234\/invocations -H &quot;Content-Type: application\/json; format=pandas-split&quot; -d '{&quot;columns&quot;:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99], &quot;data&quot;:[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,3,1,4]]}'<\/code><\/p>\n<p>I get this error and I don't really know what's causing it:<\/p>\n<blockquote>\n<p>{&quot;error_code&quot;: &quot;BAD_REQUEST&quot;, &quot;message&quot;: &quot;Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.&quot;, &quot;stack_trace&quot;: &quot;Traceback [...]<\/p>\n<\/blockquote>\n<blockquote>\n<p>File &quot;\/Path\/to\/the\/file\/venv\/lib\/python3.8\/site-packages\/mlflow\/tensorflow.py&quot;, line 584, in predict\\n    raise TypeError(f&quot;Only dict and DataFrame input types are supported}&quot;)\\nTypeError: Only dict and DataFrame input types are supported<\/p>\n<\/blockquote>\n<p>The data it's causing this error is not a <code>DataFrame<\/code> nor a <code>dict<\/code> but is a <code>numpy.ndarray<\/code> instead (I checked it with a type(...) while debugging).<\/p>\n<p>The shape of the inputs are correct but I really don't know how to solve this. It seems MLflow converts the data into the numpy.ndarray without any reason<\/p>\n<p>Thanks in advance to anyone who'll help me<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-09-01 16:23:16.477 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|dataframe|tensorflow|tensorflow-serving|mlflow",
        "Question_view_count":291,
        "Owner_creation_date":"2020-01-15 20:34:13.467 UTC",
        "Owner_last_access_date":"2022-09-22 12:56:39.437 UTC",
        "Owner_reputation":49,
        "Owner_up_votes":19,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Reggio Emilia, RE, Italia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69017477",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61266578,
        "Question_title":"How can an mlflow model be scaled to serve more requests?",
        "Question_body":"<p>I would like to have multiple instances of my MLFlow model running in parallel but hidden behind a common the same endpoint\/port so it's not visible to the user. <\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-04-17 07:51:03.51 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"multithreading|gunicorn|mlflow",
        "Question_view_count":228,
        "Owner_creation_date":"2020-01-14 16:04:32.663 UTC",
        "Owner_last_access_date":"2021-11-19 17:01:44.77 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":8,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61266578",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73074887,
        "Question_title":"'mlflow' has no attribute 'last_active_run'",
        "Question_body":"<p>For the first time, it is proceeding mlflow with port 5000.<\/p>\n<p>Testing Mlflow, problem is no attribute last_active_run in mlflow<\/p>\n<p>But, It was an example provided by Mlflow. <br \/>\nlink is here <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/sklearn_autolog\" rel=\"nofollow noreferrer\">mlflow<\/a><\/p>\n<p>What is problem and how can I change code?<\/p>\n<p>shell<\/p>\n<pre><code>wget https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/master\/examples\/sklearn_autolog\/utils.py\nwget https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/master\/examples\/sklearn_autolog\/pipeline.py\n<\/code><\/pre>\n<p>pipeline.py<\/p>\n<pre><code>from pprint import pprint\n\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nimport mlflow\nfrom utils import fetch_logged_data\n\n\ndef main():\n    # enable autologging\n    mlflow.sklearn.autolog()\n\n    # prepare training data\n    X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n    y = np.dot(X, np.array([1, 2])) + 3\n\n    # train a model\n    pipe = Pipeline([(&quot;scaler&quot;, StandardScaler()), (&quot;lr&quot;, LinearRegression())])\n    pipe.fit(X, y)\n    run_id = mlflow.last_active_run().info.run_id\n    print(&quot;Logged data and model in run: {}&quot;.format(run_id))\n\n    # show logged data\n    for key, data in fetch_logged_data(run_id).items():\n        print(&quot;\\n---------- logged {} ----------&quot;.format(key))\n        pprint(data)\n\n\nif __name__ == &quot;__main__&quot;:\n    main()\n<\/code><\/pre>\n<p>utils.py<\/p>\n<pre><code>import mlflow\nfrom mlflow.tracking import MlflowClient\n\n\ndef yield_artifacts(run_id, path=None):\n    &quot;&quot;&quot;Yield all artifacts in the specified run&quot;&quot;&quot;\n    client = MlflowClient()\n    for item in client.list_artifacts(run_id, path):\n        if item.is_dir:\n            yield from yield_artifacts(run_id, item.path)\n        else:\n            yield item.path\n\n\ndef fetch_logged_data(run_id):\n    &quot;&quot;&quot;Fetch params, metrics, tags, and artifacts in the specified run&quot;&quot;&quot;\n    client = MlflowClient()\n    data = client.get_run(run_id).data\n    # Exclude system tags: https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#system-tags\n    tags = {k: v for k, v in data.tags.items() if not k.startswith(&quot;mlflow.&quot;)}\n    artifacts = list(yield_artifacts(run_id))\n    return {\n        &quot;params&quot;: data.params,\n        &quot;metrics&quot;: data.metrics,\n        &quot;tags&quot;: tags,\n        &quot;artifacts&quot;: artifacts,\n    }\n<\/code><\/pre>\n<p>Error message<\/p>\n<pre><code>INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8cc3f4e03b4e417b95a64f1a9a41be63', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\nTraceback (most recent call last):\n  File &quot;\/Users\/taein\/Desktop\/mlflow\/pipeline.py&quot;, line 33, in &lt;module&gt;\n    main()\n  File &quot;\/Users\/taein\/Desktop\/mlflow\/pipeline.py&quot;, line 23, in main\n    run_id = mlflow.last_active_run().info.run_id\nAttributeError: module 'mlflow' has no attribute 'last_active_run'\n<\/code><\/pre>\n<p>Thanks for your helping<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-22 03:40:56.963 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|python-3.x|scikit-learn|mlflow",
        "Question_view_count":215,
        "Owner_creation_date":"2020-08-23 11:05:51.547 UTC",
        "Owner_last_access_date":"2022-09-23 03:21:56.017 UTC",
        "Owner_reputation":158,
        "Owner_up_votes":4,
        "Owner_down_votes":2,
        "Owner_views":29,
        "Answer_body":"<p>It's because of the mlflow version that you mentioned in the comments. <code>mlflow.last_active_run()<\/code> API was introduced in <a href=\"https:\/\/github.com\/mlflow\/mlflow\/releases\/tag\/v1.25.0\" rel=\"nofollow noreferrer\">mlflow 1.25.0\n<\/a>. So you should upgrade the mlflow or you can use the previous version of the code available <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/5e2cb3baef544b00a972dff9dd6fb764be20510b\/examples\/sklearn_autolog\" rel=\"nofollow noreferrer\">here<\/a>.<\/p>\n<pre><code>wget https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/5e2cb3baef544b00a972dff9dd6fb764be20510b\/examples\/sklearn_autolog\/utils.py\nwget https:\/\/raw.githubusercontent.com\/mlflow\/mlflow\/5e2cb3baef544b00a972dff9dd6fb764be20510b\/examples\/sklearn_autolog\/pipeline.py\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-07-24 23:47:46.923 UTC",
        "Answer_score":1.0,
        "Owner_location":"Seoul, Repulic of Korea",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73074887",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67052295,
        "Question_title":"MLflow unfinished experiment saved as finished",
        "Question_body":"<p>when I create a run using <code>mlflow.start_run()<\/code> ,even if my script is interrupted before executing <code>mlflow.end_run()<\/code>, the run gets tagged as finished instead of unfinished in Status?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2021-04-12 03:26:02.217 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":332,
        "Owner_creation_date":"2020-01-11 13:52:41.197 UTC",
        "Owner_last_access_date":"2022-09-24 12:58:48.047 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>When your notebook stops the run gets the status finished. However, if you want to continue logging metrics or artifacts to that run, you just need to use <code>mlflow.start_run(run_id=&quot;YourRunIDYouCanGetItFromUI&quot;)<\/code>. This is explained in the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.start_run\" rel=\"nofollow noreferrer\">documentation<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-04-12 10:33:23.527 UTC",
        "Answer_score":0.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67052295",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71474091,
        "Question_title":"Parallelize MLflow Project runs with Pandas UDF on Azure Databricks Spark",
        "Question_body":"<p>I'm trying to <strong>parallelize the training of multiple time-series using Spark on Azure Databricks<\/strong>.<br \/>\nOther than training, I would like to <strong>log metrics and models using MLflow<\/strong>.<\/p>\n<p>The <strong>structure of the code<\/strong> is quite simple (basically adapted <a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/hyperparam\" rel=\"nofollow noreferrer\">this example<\/a>).<\/p>\n<ol>\n<li>A Databricks notebook <strong>triggers the MLflow Project<\/strong><\/li>\n<\/ol>\n<blockquote>\n<pre><code>mlflow.run(\n    uri=&quot;\/dbfs\/mlflow-project&quot;,\n    parameters={&quot;data_path&quot;: &quot;dbfs:\/data\/&quot;, &quot;experiment_name&quot;: &quot;test&quot;}, \n    experiment_id=575501044793272,\n    use_conda=False,\n    backend=&quot;databricks&quot;,\n    backend_config={\n        &quot;new_cluster&quot;: {\n            &quot;spark_version&quot;: &quot;9.1.x-cpu-ml-scala2.12&quot;,\n            &quot;num_workers&quot;: 8,\n            &quot;node_type_id&quot;: &quot;Standard_DS4_v2&quot;,\n        },\n        &quot;libraries&quot;: [{&quot;pypi&quot;: {&quot;package&quot;: &quot;pyarrow&quot;}}]\n    },\n    synchronous=False\n)\n<\/code><\/pre>\n<\/blockquote>\n<ol start=\"2\">\n<li><p>The <strong>main function is called<\/strong>. It basically executes three steps:<\/p>\n<ol>\n<li>Read the delta table indicated by the <em>data_path<\/em> provided<\/li>\n<li>Define a function which triggers the <em>&quot;train entry&quot;<\/em> of the MLflow project<\/li>\n<li>Apply this function as a Pandas UDF on the Spark DataFrame<\/li>\n<\/ol>\n<\/li>\n<\/ol>\n<p>Here the code:<\/p>\n<pre><code>sc = sparkContext('local')\nspark = SparkSession(sc)\n\n@click.argument(&quot;data_path&quot;)\n@click.argument(&quot;experiment_name&quot;)\ndef run(data_path: str, experiment_name: str):\n            \n    df = spark.read.format(&quot;delta&quot;).load(f&quot;{data_path}&quot;)\n    result_schema = StructType([StructField(&quot;key&quot;, StringType())])\n\n    def forecast(data: pd.DataFrame) -&gt; pd.DataFrame:\n        child_run = client.create_run(\n            experiment_id=experiment,\n            tags={MLFLOW_PARENT_RUN_ID: parent_run_id},\n        )\n        p = mlflow.projects.run(\n            run_id=child_run.info.run_id, \n            uri=&quot;.&quot;,\n            entry_points=&quot;train&quot;,\n            parameters={&quot;data&quot;: data.to_json(), &quot;run_id&quot;: child_run.info.run_id}, \n            experiment_id=experiment,\n            backend=&quot;local&quot;,\n            usa_conda=False,\n            synchronous=False,\n        )\n\n        # Just a placeholder to use pandas UDF\n        out = pd.DataFrame(data={&quot;key&quot;: [&quot;1&quot;]})\n        return out\n\n    client = MLflowClient()\n    experiment_path = f&quot;\/mlflow\/experiments\/{experiment_name}&quot;\n    experiment = client.create_experiment(experiment_path)\n\n    parent_run = client.create_run(experiment_id=experiment)\n    parent_run_id = parent_run.run_id\n\n    # Apply pandas UDF (count() used just to avoid lazy evaluation)\n    df.groupBy(&quot;key&quot;).applyInPandas(forecast, result_schema).count()\n<\/code><\/pre>\n<ol start=\"3\">\n<li>The <strong>train function is called on each key<\/strong>.<br \/>\nThis basically trains a Prophet model for each time series (i.e. for each key), for which logs both parameters and model.<\/li>\n<\/ol>\n<p><strong>From cluster stderr and stdout I can see that pandas UDF is correctly applied<\/strong>, since it correctly divides the whole data based on &quot;key&quot; column, i.e. works one time series at a time.<\/p>\n<p>The problem is that <strong>monitoring the cluster usage only one node is used, the driver node: work is not distributed on the available workers<\/strong>, despite pandas UDF appears to be applied correctly.<\/p>\n<p>What might be the issue here?\nCould I provide some more details?<\/p>\n<p>Thank you very much in advance,\nMatteo<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-14 20:50:48.663 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-03-16 10:41:36.777 UTC",
        "Question_score":2,
        "Question_tags":"apache-spark|pyspark|azure-databricks|mlflow|pandas-udf",
        "Question_view_count":297,
        "Owner_creation_date":"2020-04-20 19:21:49.597 UTC",
        "Owner_last_access_date":"2022-06-08 15:27:19.097 UTC",
        "Owner_reputation":25,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":24,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71474091",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":65316586,
        "Question_title":"get the run id for an mlflow experiment with the name?",
        "Question_body":"<p>I currently created an experiment in mlflow and created multiple runs in the experiment.<\/p>\n<pre><code>from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport mlflow\n\nexperiment_name=&quot;experiment-1&quot;\nmlflow.set_experiment(experiment_name)\n\nno_of_trees=[100,200,300]\ndepths=[2,3,4]\nfor trees in no_of_trees:\n    for depth in depths:\n        with mlflow.start_run() as run:\n            model=RandomForestRegressor(n_estimators=trees, criterion='mse',max_depth=depth)\n            model.fit(x_train, y_train)\n            predictions=model.predict(x_cv)\n            mlflow.log_metric('rmse',mean_squared_error(y_cv, predictions))\n<\/code><\/pre>\n<p>after creating the runs, I wanted to get the best run_id for this experiment. for now, I can get the best run by looking at the UI of mlflow but how can we do right the program?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-12-16 02:45:27.487 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":6,
        "Question_tags":"python|mlflow",
        "Question_view_count":6374,
        "Owner_creation_date":"2016-11-15 06:12:07.737 UTC",
        "Owner_last_access_date":"2022-08-15 17:25:10.4 UTC",
        "Owner_reputation":2470,
        "Owner_up_votes":265,
        "Owner_down_votes":22,
        "Owner_views":251,
        "Answer_body":"<p>we can get the experiment id from the experiment name and we can use python API to get the best runs.<\/p>\n<pre><code>experiment_name = &quot;experiment-1&quot;\ncurrent_experiment=dict(mlflow.get_experiment_by_name(experiment_name))\nexperiment_id=current_experiment['experiment_id']\n<\/code><\/pre>\n<p>By using the experiment id, we can get all the runs and we can sort them based on metrics like below. In the below code, rmse is my metric name (so it may be different for you based on metric name)<\/p>\n<pre><code>df = mlflow.search_runs([experiment_id], order_by=[&quot;metrics.rmse DESC&quot;])\nbest_run_id = df.loc[0,'run_id']\n<\/code><\/pre>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-12-16 02:45:27.487 UTC",
        "Answer_score":15.0,
        "Owner_location":"R G U K T , basar, Andhra Pradesh, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/65316586",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56113569,
        "Question_title":"MLFlow Projects throw JSONDecode error when run",
        "Question_body":"<p>I'm trying to get MLFlow Projects to run using the MLFlow CLI and its following the tutorial leads to an error.  For any project I try to run from the CLI, I get the following error<\/p>\n\n<pre><code>Traceback (most recent call last):\n  File \"\/home\/rbc\/.local\/bin\/mlflow\", line 11, in &lt;module&gt;\n    sys.exit(cli())\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 764, in __call__\n    return self.main(*args, **kwargs)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 717, in main\n    rv = self.invoke(ctx)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 1137, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 956, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/click\/core.py\", line 555, in invoke\n    return callback(*args, **kwargs)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/cli.py\", line 139, in run\n    run_id=run_id,\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 230, in run\n    storage_dir=storage_dir, block=block, run_id=run_id)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 88, in _run\n    active_run = _create_run(uri, experiment_id, work_dir, entry_point)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/projects\/__init__.py\", line 579, in _create_run\n    active_run = tracking.MlflowClient().create_run(experiment_id=experiment_id, tags=tags)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/tracking\/client.py\", line 101, in create_run\n    source_version=source_version\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 156, in create_run\n    response_proto = self._call_endpoint(CreateRun, req_body)\n  File \"\/home\/rbc\/.local\/lib\/python3.6\/site-packages\/mlflow\/store\/rest_store.py\", line 66, in _call_endpoint\n    js_dict = json.loads(response.text)\n  File \"\/usr\/lib\/python3.6\/json\/__init__.py\", line 354, in loads\n    return _default_decoder.decode(s)\n  File \"\/usr\/lib\/python3.6\/json\/decoder.py\", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"\/usr\/lib\/python3.6\/json\/decoder.py\", line 357, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n<\/code><\/pre>\n\n<p>Here's an example of the type of command I'm using to start the run, which comes directly from the tutorial <\/p>\n\n<pre><code>mlflow run https:\/\/github.com\/mlflow\/mlflow#examples\/sklearn_elasticnet_wine -m databricks -c cluster-spec.json --experiment-id 72647065958042 -P alpha=2.0 -P l1_ratio=0.5\n<\/code><\/pre>\n\n<p>I've traced the error to something involving MLFLow returning empty when it tries to start a run but I can successfully run MLFlow experiments using the Databricks environment I'm connecting to so I'm not sure where the problem is, I'm running MLFlow 0.9.1 on Ubuntu 18.04<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_creation_date":"2019-05-13 13:37:47.253 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":386,
        "Owner_creation_date":"2017-10-31 17:37:18.9 UTC",
        "Owner_last_access_date":"2019-10-24 20:16:31.737 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Orlando, FL, United States",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56113569",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":66858683,
        "Question_title":"How to integrate mlflow and airflow? Is there any way to connect to mlflow server from airflow",
        "Question_body":"<p>Lets say I have a ML model in mlflow server artifacts. I want to run this model from airflow Dag. Also after running in airflow, metric logs should be visible in mlflow.\nHow can I achieve this?\nThere are connections in airflow, I couldn't find any connection type for mlflow.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-03-29 17:16:36.66 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":2,
        "Question_tags":"airflow|mlflow",
        "Question_view_count":389,
        "Owner_creation_date":"2017-05-31 04:12:26.49 UTC",
        "Owner_last_access_date":"2022-09-24 08:59:44.06 UTC",
        "Owner_reputation":838,
        "Owner_up_votes":89,
        "Owner_down_votes":2,
        "Owner_views":33,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/66858683",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61351024,
        "Question_title":"Kubernetes MLflow Service Pod Connection",
        "Question_body":"<p>I have deployed a build of mlflow to a pod in my kubernetes cluster. I'm able to port forward to the mlflow ui, and now I'm attempting to test it. To do this, I am running the following test on a jupyter notebook that is running on another pod in the same cluster.<\/p>\n<pre><code>import mlflow\n\nprint(&quot;Setting Tracking Server&quot;)\ntracking_uri = &quot;http:\/\/mlflow-tracking-server.default.svc.cluster.local:5000&quot;\n\nmlflow.set_tracking_uri(tracking_uri)\n\nprint(&quot;Logging Artifact&quot;)\nmlflow.log_artifact('\/home\/test\/mlflow-example-artifact.png')\n\nprint(&quot;DONE&quot;)\n<\/code><\/pre>\n<p>When I run this though, I get<\/p>\n<pre><code>ConnectionError: HTTPConnectionPool(host='mlflow-tracking-server.default.svc.cluster.local', port=5000): Max retries exceeded with url: \/api\/2.0\/mlflow\/runs\/get? (Caused by NewConnectionError('&lt;urllib3.connection.HTTPConnection object&gt;: Failed to establish a new connection: [Errno 111] Connection refused'))\n<\/code><\/pre>\n<p>The way I have deployed the mlflow pod is shown below in the yaml and docker:<\/p>\n<p>Yaml:<\/p>\n<pre><code>---\napiVersion: apps\/v1\nkind: Deployment\nmetadata:\n  name: mlflow-tracking-server\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: mlflow-tracking-server\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: mlflow-tracking-server\n    spec:\n      containers:\n      - name: mlflow-tracking-server\n        image: &lt;ECR_IMAGE&gt;\n        ports:\n        - containerPort: 5000\n        env:\n        - name: AWS_MLFLOW_BUCKET\n          value: &lt;S3_BUCKET&gt;\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: AWS_SECRET_ACCESS_KEY\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mlflow-tracking-server\n  namespace: default\n  labels:\n    app: mlflow-tracking-server\n  annotations:\n    service.beta.kubernetes.io\/aws-load-balancer-type: nlb\nspec:\n  externalTrafficPolicy: Local\n  type: LoadBalancer\n  selector:\n    app: mlflow-tracking-server\n  ports:\n    - name: http\n      port: 5000\n      targetPort: http\n<\/code><\/pre>\n<p>While the dockerfile calls a script that executes the mlflow server command: <code>mlflow server --default-artifact-root ${AWS_MLFLOW_BUCKET} --host 0.0.0.0 --port 5000<\/code>, I cannot connect to the service I have created using that mlflow pod.<\/p>\n<p>I have tried using the tracking uri <code>http:\/\/mlflow-tracking-server.default.svc.cluster.local:5000<\/code>, I've tried using the service EXTERNAL-IP:5000, but everything I tried cannot connect and log using the service. Is there anything that I have missed in deploying my mlflow server pod to my kubernetes cluster?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":6,
        "Question_creation_date":"2020-04-21 18:54:46.493 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-09-07 11:16:43.817 UTC",
        "Question_score":2,
        "Question_tags":"kubernetes|kubernetes-service|mlflow",
        "Question_view_count":855,
        "Owner_creation_date":"2014-11-26 14:40:35.813 UTC",
        "Owner_last_access_date":"2021-08-12 15:37:44.573 UTC",
        "Owner_reputation":945,
        "Owner_up_votes":35,
        "Owner_down_votes":1,
        "Owner_views":148,
        "Answer_body":"<p>Your <strong>mlflow-tracking-server<\/strong> service should have <em>ClusterIP<\/em> type, not <em>LoadBalancer<\/em>. <\/p>\n\n<p>Both pods are inside the same Kubernetes cluster, therefore, there is no reason to use <em>LoadBalancer<\/em> Service type.<\/p>\n\n<blockquote>\n  <p>For some parts of your application (for example, frontends) you may want to expose a Service onto an external IP address, that\u2019s outside of your cluster.\n  Kubernetes ServiceTypes allow you to specify what kind of Service you want. The default is ClusterIP.<\/p>\n  \n  <p>Type values and their behaviors are:<\/p>\n  \n  <ul>\n  <li><p><strong>ClusterIP<\/strong>: Exposes the Service on a cluster-internal IP. Choosing this\n  value makes the Service only reachable from within the cluster. This\n  is the default ServiceType. <\/p><\/li>\n  <li><p><strong>NodePort<\/strong>: Exposes the Service on each Node\u2019s IP at a static port (the NodePort). A > ClusterIP Service, to which the NodePort Service routes, is automatically created. You\u2019ll > be able to contact the NodePort Service, from outside the cluster, by\n  requesting :. <\/p><\/li>\n  <li><strong>LoadBalancer<\/strong>: Exposes the Service\n  externally using a cloud provider\u2019s load balancer. NodePort and\n  ClusterIP Services, to which the external load balancer routes, are\n  automatically created. <\/li>\n  <li><strong>ExternalName<\/strong>: Maps the Service to the contents\n  of the externalName field (e.g. foo.bar.example.com), by returning a\n  CNAME record with its value. No proxying of any kind is set up.<\/li>\n  <\/ul>\n  \n  <p><a href=\"https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/#publishing-services-service-types\" rel=\"nofollow noreferrer\">kubernetes.io<\/a><\/p>\n<\/blockquote>",
        "Answer_comment_count":6.0,
        "Answer_creation_date":"2020-04-21 19:52:17.657 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":"2020-04-21 20:02:33.943 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61351024",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72193802,
        "Question_title":"Can't edit the cluster created by mlflow model serving",
        "Question_body":"<p>I'm trying to deploy  Machine learning model into databricks production using mlflow. while in that process, I have registered the model to mlflow models. After that it created the cluster but then it was in pending state forever. when I checked the model events, I see a problem with https proxy, we have global init scripts which contain proxy information.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/qF9MT.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/qF9MT.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Ref: <a href=\"https:\/\/docs.databricks.com\/applications\/mlflow\/model-serving.html\" rel=\"nofollow noreferrer\">https:\/\/docs.databricks.com\/applications\/mlflow\/model-serving.html<\/a><\/p>\n<p>so the only way for us to edit the cluster and add them but in that process we are getting an error &quot;error: Cannot edit cluster created by ModelServing&quot;.<\/p>\n<pre><code>[Errno 101] Network is unreachable',)': \/simple\/mlflow\/ WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('&lt;pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f258247f710&gt;: Failed to establish a new connection:\n<\/code><\/pre>\n<p>In the &quot;Model Events page&quot;, I see the above logs,<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-10 23:07:09.1 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":125,
        "Owner_creation_date":"2016-11-15 06:12:07.737 UTC",
        "Owner_last_access_date":"2022-08-15 17:25:10.4 UTC",
        "Owner_reputation":2470,
        "Owner_up_votes":265,
        "Owner_down_votes":22,
        "Owner_views":251,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"R G U K T , basar, Andhra Pradesh, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72193802",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70563614,
        "Question_title":"How does autologging work in MLOps platforms like Comet or MLFlow?",
        "Question_body":"<p>I was wondering how the implementation of logging is done where you just need to create an experiment object from comet_ml and it auto-detects and gives out all the statistics of the trained experiment. Is there some sort of logging system used?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-01-03 09:14:21.397 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"comet|mlflow|mlops",
        "Question_view_count":55,
        "Owner_creation_date":"2020-08-05 13:21:06.543 UTC",
        "Owner_last_access_date":"2022-03-22 05:41:49.233 UTC",
        "Owner_reputation":18,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":3,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Nashik, Maharashtra, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70563614",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61615818,
        "Question_title":"Setting-up MLflow on Google Colab",
        "Question_body":"<p>I frequently use Google Colab to train TF\/PyTorch models as Colab provides me with GPU\/TPU runtime. Besides, I like working with MLflow to store and compare trained models, tracking progress, sharing, etc.  What are the available solutions to use MLflow with Google Colab?<\/p>",
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-05 14:43:59.033 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":"2021-05-25 10:17:30.167 UTC",
        "Question_score":7,
        "Question_tags":"google-colaboratory|mlflow|mlops",
        "Question_view_count":6053,
        "Owner_creation_date":"2019-03-15 14:44:06.21 UTC",
        "Owner_last_access_date":"2022-09-23 15:18:04.313 UTC",
        "Owner_reputation":1131,
        "Owner_up_votes":55,
        "Owner_down_votes":0,
        "Owner_views":49,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Paris, France\/ Ternopil, Ukraine",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61615818",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57653495,
        "Question_title":"Saving model artifacts with Kubeflow without Pipeline",
        "Question_body":"<p>I am using mlflow as of now in my jupyterhub environment for model tracking and I feel its easy to keep track of artifacts in mlflow simply by calling the run like:<\/p>\n\n<pre><code>with mlflow.start_run():\n    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n    lr.fit(train_x, train_y)\n\n    predicted_qualities = lr.predict(test_x)\n\n    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n    mlflow.log_param(\"alpha\", alpha)\n    mlflow.log_param(\"l1_ratio\", l1_ratio)\n    mlflow.log_metric(\"rmse\", rmse)\n    mlflow.log_metric(\"r2\", r2)\n    mlflow.log_metric(\"mae\", mae)\n\n    mlflow.sklearn.log_model(lr, \"model\")\n<\/code><\/pre>\n\n<p>I am moving to Kubeflow now and not sure if I can do the same thing here without creating a pipleline. What I could find is:<\/p>\n\n<pre><code>client.run_pipleline(exp.id, ....)\n<\/code><\/pre>\n\n<p>Is there any way I can keep track of experiments like mlflow in Kubeflow?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-08-26 07:28:20.46 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-26 11:18:36.08 UTC",
        "Question_score":1,
        "Question_tags":"python|kubeflow|mlflow",
        "Question_view_count":472,
        "Owner_creation_date":"2014-05-29 12:37:30.427 UTC",
        "Owner_last_access_date":"2020-10-15 08:35:10.407 UTC",
        "Owner_reputation":1990,
        "Owner_up_votes":49,
        "Owner_down_votes":1,
        "Owner_views":268,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Kuala Lumpur Federal Territory of Kuala Lumpur Malaysia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57653495",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72365934,
        "Question_title":"Running mlflow ui in AWS Sagemaker",
        "Question_body":"<p>I want to run mlflow UI in sagemaker but it simply does not work, When it outputs the http address going to it results in a &quot;this site cannot be reached&quot;<\/p>\n<p>Here is the code:<\/p>\n<pre><code>def mlflow_test(server_uri, experiment_name):\n    mlflow.set_tracking_uri(server_uri)\n    mlflow.set_experiment(experiment_name)\n    with mlflow.start_run():\n        params = {\n            &quot;n-estimators&quot;: 100,\n            &quot;min-samples-leaf&quot;: 10,\n            &quot;features&quot;: 'feature_test'\n        }\n        mlflow.log_params(params)\n        mlflow.log_metric('foo', 5)\n        mlflow.end_run()\n<\/code><\/pre>\n<p>running that code will return:<\/p>\n<pre><code>[2022-05-24 15:48:44 +0000] [27820] [INFO] Starting gunicorn 20.1.0\n[2022-05-24 15:48:44 +0000] [27820] [INFO] Listening at: http:\/\/127.0.0.1:5000 (27820)\n[2022-05-24 15:48:44 +0000] [27820] [INFO] Using worker: sync\n[2022-05-24 15:48:44 +0000] [27823] [INFO] Booting worker with pid: 27823\n<\/code><\/pre>\n<p>Going to the <a href=\"http:\/\/127.0.0.1:5000\" rel=\"nofollow noreferrer\">http:\/\/127.0.0.1:5000<\/a> link won't work. Anyone know how to get mlflow ui running in sagemaker? There's not much info on this that's at an easy to understand level. I just want to log my metrics and params in sagemaker and view them using the mlflow ui<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-24 15:54:09.377 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|amazon-web-services|amazon-sagemaker|mlflow",
        "Question_view_count":93,
        "Owner_creation_date":"2021-03-17 15:21:32.347 UTC",
        "Owner_last_access_date":"2022-07-14 10:53:41.117 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72365934",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73386272,
        "Question_title":"How to log metrics to Azure ML Metrics Tab",
        "Question_body":"<p>I have the following train.py file<\/p>\n<pre><code>import argparse\nimport os\nimport numpy as np\nimport glob\n# import joblib\nimport mlflow\nimport logging\nimport azureml.core\nimport pandas as pd\nimport numpy as np\nimport pandas as pd \n\nfrom matplotlib import pyplot as plt\nfrom azureml.core import Workspace, Dataset\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.core.dataset import Dataset\nfrom azureml.train.automl import AutoMLConfig\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nimport lightgbm as lgb\nfrom sklearn.datasets import load_boston\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom pandas import DataFrame\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\n\n\n# let user feed in 2 parameters, the dataset to mount or download,\n# and the regularization rate of the logistic regression model\nparser = argparse.ArgumentParser()\nparser.add_argument(\n    &quot;--tablename&quot;, type=str, dest=&quot;tablename&quot;, help=&quot;Table name&quot;\n)\nargs = parser.parse_args()\n\ntablename = args.tablename\n\n\nsubscription_id = ''\nresource_group = 'mlplayground'\nworkspace_name = 'mlplayground'\n\nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n\ndataset = Dataset.get_by_name(workspace, name=tablename)\ndata = dataset.to_pandas_dataframe()\n\n# use mlflow autologging\nmlflow.autolog()\n\ndata.drop(['postal_code','Column1','province','region','lattitude','longitude'], axis=1, inplace=True)\none_hot_state_of_the_building=pd.get_dummies(data.state_of_the_building) \none_hot_city = pd.get_dummies(data.city_name, prefix='city')\n\n#removing categorical features \ndata.drop(['city_name','state_of_the_building'],axis=1,inplace=True)  \n\n#Merging one hot encoded features with our dataset 'data' \ndata=pd.concat([data,one_hot_city,one_hot_state_of_the_building,],axis=1) \n\ndata['pricepersqm'] = data.price \/ data.house_area\n\nx=data.drop('price',axis=1) \ny=data.price \n\nX_df = DataFrame(x, columns= data.columns)\nX_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.20)\n\n#Converting the data into proper LGB Dataset Format\nd_train=lgb.Dataset(X_train, label=y_train)\n\n\n#Declaring the parameters\nparams = {\n    'task': 'train', \n    'boosting': 'gbdt',\n    'objective': 'regression',\n    'num_leaves': 10,\n    'learning_rate': 0.01,\n    'metric': {'l2','l1'},\n    'verbose': -1\n}\n\nprint(&quot;Train a LightGBM Regression model&quot;)\nclf=lgb.train(params,d_train,1000)\n\n#model prediction on X_test\nprint(&quot;Predict the test set&quot;)\ny_pred=clf.predict(X_test)\n\n#using RMSE error metric\nmse =mean_squared_error(y_pred,y_test)\nprint(&quot;RMSE: &quot;, mse**0.5)\nmlflow.log_metric(&quot;RMSE&quot;, mse**0.5)\n<\/code><\/pre>\n<p>And then from a notebook file I use the following:<\/p>\n<pre><code>from azureml.core import Workspace\nfrom azureml.core import Experiment\n\n# connect to your workspace\nws = Workspace.from_config()\n\nexperiment_name = &quot;get-started-with-jobsubmission-tutorial-andlightgbm&quot;\nexp = Experiment(workspace=ws, name=experiment_name)\n\n\n\nfrom azureml.core.environment import Environment\n\n# use a curated environment that has already been built for you\n\nenv = Environment.get(workspace=ws, \n                      name=&quot;AzureML-sklearn-1.0-ubuntu20.04-py38-cpu&quot;, \n                      version=1)\n\nfrom azureml.core import ScriptRunConfig\n\nargs = [&quot;--tablename&quot;, &quot;BelgiumRealEstate&quot;]\n\nsrc = ScriptRunConfig(\n    source_directory=&quot;&quot;,\n    script=&quot;train.py&quot;,\n    arguments=args,\n    compute_target=&quot;local&quot;,\n    environment=env,\n)\n\nrun = exp.submit(config=src)\nrun.wait_for_completion(show_output=True)\n<\/code><\/pre>\n<p>As you can see in the train.py file I am logging the RMSE, however the metric does not appear on the metrics tab.<\/p>\n<p>What should I do?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-08-17 09:44:50.553 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|azure-machine-learning-service|mlflow",
        "Question_view_count":40,
        "Owner_creation_date":"2011-04-05 19:05:03.093 UTC",
        "Owner_last_access_date":"2022-09-16 12:42:27.473 UTC",
        "Owner_reputation":30340,
        "Owner_up_votes":1667,
        "Owner_down_votes":79,
        "Owner_views":2937,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Brussels, B\u00e9lgica",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73386272",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70005957,
        "Question_title":"Logging the git_sha as a parameter on Mlflow using Kedro hooks",
        "Question_body":"<p>I would like to log the git_sha parameter on Mlflow as shown in the <a href=\"https:\/\/kedro.readthedocs.io\/en\/stable\/07_extend_kedro\/02_hooks.html?highlight=run_params#add-metrics-tracking-to-your-model\" rel=\"nofollow noreferrer\">documentation<\/a>. What appears to me here, is that simply running the following portion of code should be enough to get git_sha logged in the Mlflow UI. Am I right ?<\/p>\n<pre><code>@hook_impl\n    def before_pipeline_run(self, run_params: Dict[str, Any]) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to start an MLflow run\n        with the same run_id as the Kedro pipeline run.\n        &quot;&quot;&quot;\n        mlflow.start_run(run_name=run_params[&quot;run_id&quot;])\n        mlflow.log_params(run_params)\n<\/code><\/pre>\n<p>But this does not work as I get all but the git_sha parameter. And when I look at the <a href=\"https:\/\/kedro.readthedocs.io\/en\/stable\/_modules\/kedro\/framework\/hooks\/specs.html?highlight=run_params#\" rel=\"nofollow noreferrer\">hooks specs<\/a>, it seems that this param is not part of run_params (anymore?)<\/p>\n<p>Is there a way I could get the git sha (maybe from the context journal ?) and add it to the logged parameters ?<\/p>\n<p>Thank you in advance !<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-17 14:13:41.443 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-17 14:19:26.987 UTC",
        "Question_score":0,
        "Question_tags":"python|mlflow|kedro|mlops",
        "Question_view_count":172,
        "Owner_creation_date":"2020-04-10 11:23:52.39 UTC",
        "Owner_last_access_date":"2022-08-12 18:19:53.33 UTC",
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":"<p>Whilst it's heavily encouraged to use git with Kedro it's not required and as such no part of Kedro (except <a href=\"https:\/\/github.com\/quantumblacklabs\/kedro-starters\" rel=\"nofollow noreferrer\">kedro-starters<\/a> if we're being pedantic) is 'aware' of git.<\/p>\n<p>In your <code>before_pipeline_hook<\/code> there it is pretty easy for you to retrieve the info <a href=\"https:\/\/stackoverflow.com\/questions\/14989858\/get-the-current-git-hash-in-a-python-script\">via the techniques documented here<\/a>. It seems trivial for the whole codebase, a bit more involved if you want to say provide pipeline specific hashes.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-17 14:26:33.837 UTC",
        "Answer_score":1.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70005957",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72660569,
        "Question_title":"mlflow UI server doesn't start",
        "Question_body":"<p>When I run mlflow UI inside my repository and environment (anaconda), I receive the following error<\/p>\n<pre><code>Cannot open C:\\Users\\XXX\\Anaconda3\\envs\\haea\\Scripts\\waitress-serve-script.py\nRunning the mlflow server failed. Please see the logs above for details\n<\/code><\/pre>\n<p>When I checked the anaconda environment folder, I don't see a waitress-serve-script there, that might be the reason, but I can't find other online resources for the issue. Any recommendations would help.<\/p>\n<p><em>What I have tried so far<\/em><\/p>\n<ol>\n<li>Reinstalling mlflow<\/li>\n<li>Creating a new environment<\/li>\n<li>Manually install waitress (pip install waitress)<\/li>\n<\/ol>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-17 13:59:23.667 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"mlflow",
        "Question_view_count":158,
        "Owner_creation_date":"2016-06-25 14:02:52.793 UTC",
        "Owner_last_access_date":"2022-07-19 14:46:33.08 UTC",
        "Owner_reputation":3,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":10,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Michigan",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72660569",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":63175684,
        "Question_title":"fitting and predicting model with mlflow",
        "Question_body":"<p>I'm very new to understanding the use of MLFlow but need assistance, I'm trying to understand on how to try and fit and predict my model once again. I'm able to call my model by:<\/p>\n<pre><code>PLS_model = mlflow.pyfunc.load_model(&quot;runs:\/FFFFF!@#!@#@!#!\/logged_model&quot;, suppress_warnings = True)\n<\/code><\/pre>\n<p>and get:<\/p>\n<pre><code>mlflow.pyfunc.loaded_model:\n  artifact_path: logged_model\n  flavor: mlflow.sklearn\n  run_id: FFFFF!@#!@#@!#!\n<\/code><\/pre>\n<p>But when I try to call any methods as:<\/p>\n<p>1).fit or .predict. I get the following error<\/p>\n<pre><code>AttributeError: 'PyFuncModel' object has no attribute 'fit'\n\nAttributeError: 'PyFuncModel' object has no attribute 'predict'\n<\/code><\/pre>\n<p>Here I encountered on how to actually call these functions but not sure if I'm doing this correctly. In summary, how can I predict, fit to my new data.<\/p>\n<p>Thanks<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-07-30 14:47:13.613 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":1702,
        "Owner_creation_date":"2017-10-24 16:10:51.607 UTC",
        "Owner_last_access_date":"2022-08-31 12:33:53.68 UTC",
        "Owner_reputation":458,
        "Owner_up_votes":104,
        "Owner_down_votes":1,
        "Owner_views":71,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Netherlands",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/63175684",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":67472983,
        "Question_title":"Can MLFlow log new metrics in a terminated run?",
        "Question_body":"<p>I would like to use MLFlow (with Python) to log time series with time interval equal to 1 day.\nMy idea would be to create a new run with a certain ID and to use function <code>log_metric<\/code> every day (say, with a cron job) with a new value. Once my run is terminated, can I &quot;reopen&quot; it and log a new metric ?\nWhat I have in mind is:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code># Day 1\nimport mlflow\n\ntracking_uri = &quot;my_uri&quot;\nmlflow.set_tracking_uri(tracking_uri)\nxp_id = 0\nmlflow.start_run(run_name=&quot;test&quot;, experiment_id=xp_id)\nmlflow.log_metric(&quot;test_metric&quot;, 1)\nmlflow.end_run()\n<\/code><\/pre>\n<p>And the following days:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\n\ndef log_daily_metric(daily_value_metric):\n  tracking_uri = &quot;my_uri&quot;\n  mlflow.set_tracking_uri(tracking_uri)\n  xp_id = 0\n  mlflow.restart_run(run_name=&quot;test&quot;, experiment_id=xp_id)  # \/!\\ function mlflow.restart does not exist\n  mlflow.log_metric(&quot;test_metric&quot;, daily_value_metric)\n  mlflow.end_run()\n<\/code><\/pre>\n<p>so that run <code>&quot;test&quot;<\/code> would have new metrics logged every day.<\/p>\n<p>Any idea to achieve this ?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2021-05-10 15:08:42.073 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-05-10 15:59:20.137 UTC",
        "Question_score":2,
        "Question_tags":"python-3.x|time-series|mlflow",
        "Question_view_count":274,
        "Owner_creation_date":"2018-10-10 14:27:44.153 UTC",
        "Owner_last_access_date":"2022-09-23 08:46:52.787 UTC",
        "Owner_reputation":1247,
        "Owner_up_votes":690,
        "Owner_down_votes":9,
        "Owner_views":191,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Nice, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/67472983",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59826799,
        "Question_title":"Unable to download artifacts from FTP server using MLFLOW",
        "Question_body":"<p>I'm not able to load my sklearn model using <code>mlflow.sklearn.load_model<\/code>. Internally, <code>mlflow<\/code> uses the function <code>_download_artifact_from_uri<\/code> from the module <code>mlflow.tracking.artifact_utils<\/code>.<\/p>\n\n<p>If I try, to download an entire artifact folder I receive the following error message: <code>PermissionError: [Errno 13] Permission denied: '\/0'<\/code>. <\/p>\n\n<p>If I try to retrieve a single file from an artifact folder I do not get the error message, and I'm able to create a folder using the <code>os<\/code> module. <\/p>\n\n<p>The following is the converted jupyter notebook I've used.<\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import os\n\nimport mlflow\nfrom mlflow.tracking.artifact_utils import _download_artifact_from_uri\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>mlflow.set_tracking_uri(\"file:mlruns\")\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>artifact_uri = 'ftp:\/\/user:pass@ftp\/0\/69a874f1f8a6474cae6bca5b3b5f9ffc\/artifacts'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>model_uri = 'ftp:\/\/user:pass@ftp\/0\/25f46678f1d44842910f185672ca852c\/artifacts\/linear model\/model\/MLmodel'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>_download_artifact_from_uri(artifact_uri, \".\/mlruns\")\n<\/code><\/pre>\n\n<pre><code>---------------------------------------------------------------------------\n\nPermissionError                           Traceback (most recent call last)\n\n&lt;ipython-input-14-834201128eef&gt; in &lt;module&gt;\n----&gt; 1 _download_artifact_from_uri(artifact_uri, \".\/mlruns\")\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/artifact_utils.py in _download_artifact_from_uri(artifact_uri, output_path)\n     73 \n     74     return get_artifact_repository(artifact_uri=root_uri).download_artifacts(\n---&gt; 75         artifact_path=artifact_path, dst_path=output_path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_artifacts(self, artifact_path, dst_path)\n    135         # Check if the artifacts points to a directory\n    136         if self._is_directory(artifact_path):\n--&gt; 137             return download_artifact_dir(artifact_path)\n    138         else:\n    139             return download_file(artifact_path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    116                 for file_info in dir_content:\n    117                     if file_info.is_dir:\n--&gt; 118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n    120                         download_file(file_info.path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    116                 for file_info in dir_content:\n    117                     if file_info.is_dir:\n--&gt; 118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n    120                         download_file(file_info.path)\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_artifact_dir(dir_path)\n    118                         download_artifact_dir(dir_path=file_info.path)\n    119                     else:\n--&gt; 120                         download_file(file_info.path)\n    121             return local_dir\n    122         if not os.path.exists(dst_path):\n\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact\/artifact_repo.py in download_file(fullpath)\n    101             local_file_path = os.path.join(dst_path, fullpath)\n    102             if not os.path.exists(local_dir_path):\n--&gt; 103                 os.makedirs(local_dir_path)\n    104             self._download_file(remote_file_path=fullpath, local_path=local_file_path)\n    105             return local_file_path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except FileExistsError:\n    213             # Defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except FileExistsError:\n    213             # Defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except FileExistsError:\n    213             # Defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    209     if head and tail and not path.exists(head):\n    210         try:\n--&gt; 211             makedirs(head, exist_ok=exist_ok)\n    212         except FileExistsError:\n    213             # Defeats race condition when another thread created the path\n\n\n\/opt\/conda\/lib\/python3.7\/os.py in makedirs(name, mode, exist_ok)\n    219             return\n    220     try:\n--&gt; 221         mkdir(name, mode)\n    222     except OSError:\n    223         # Cannot rely on checking for EEXIST, since the operating system\n\n\nPermissionError: [Errno 13] Permission denied: '\/0'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>_download_artifact_from_uri(model_uri, \".\/mlruns\")\n<\/code><\/pre>\n\n<pre><code>'\/home\/jovyan\/notebooks\/mlruns\/MLmodel'\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>os.mkdir(\"mlruns\/0\")\n<\/code><\/pre>\n\n<pre class=\"lang-py prettyprint-override\"><code>\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2020-01-20 15:52:16.323 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2020-07-02 10:20:55.693 UTC",
        "Question_score":4,
        "Question_tags":"python|scikit-learn|mlflow",
        "Question_view_count":1099,
        "Owner_creation_date":"2020-01-20 15:44:58.393 UTC",
        "Owner_last_access_date":"2022-02-17 05:56:26.41 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":6,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Copenhagen, Denmark",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59826799",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72721109,
        "Question_title":"Problem trying to authenticate with bearer token on nginx + oauth2-proxy + docker",
        "Question_body":"<p>I'm trying to setup a Google Authentication for my MLflow application using nginx, oauth2-proxy and Docker. Everything works fine when I'm logging through web-browser, but I need to access MLflow in Python Scripts and request the MLflow API too.<\/p>\n<p>I'm trying to request the API in the following way:<\/p>\n<p><code>curl -X GET http:\/\/localhost\/api\/2.0\/mlflow\/experiments\/list -H &quot;Authorization: Bearer $(gcloud auth print-identity-token)&quot;<\/code><\/p>\n<p>Where <code>$(gcloud auth print-identity-token)<\/code> translates to my acess token of GCP (which I'm using as provider on oauth2-proxy). I'm logged on gcp cli with a valid account which has right access \/ privileges to all projects (i.e. it's not a gcp authentication problem)<\/p>\n<p>oauth2-proxy logs returns me the following message:<\/p>\n<pre><code>oauth2_proxy    | [2022\/06\/22 19:19:06] [jwt_session.go:51] Error retrieving session from token in Authorization header: [unable to verify bearer token, not implemented]\n<\/code><\/pre>\n<p>Which leads me to believe that's some misconfiguration in my nginx config file or in the env vars that I pass to oauth2-proxy.<\/p>\n<p>Nginx <code>default.conf<\/code>:<\/p>\n<pre><code>server {\n    listen       80;\n    server_name  localhost;\n    \n    location \/ {\n        proxy_pass http:\/\/web:5000;\n        auth_request \/oauth2\/auth;\n        error_page 401 = \/oauth2\/sign_in;\n        # error_page 404 = \/404.html;\n        # error_page 500 502 503 504 = \/50x.html;\n\n        auth_request_set $user   $upstream_http_x_auth_request_user;\n        auth_request_set $email  $upstream_http_x_auth_request_email;\n        proxy_set_header X-User  $user;\n        proxy_set_header X-Email $email;\n\n        auth_request_set $token  $upstream_http_x_auth_request_access_token;\n        proxy_set_header X-Access-Token $token;\n\n        auth_request_set $auth_cookie $upstream_http_set_cookie;\n        add_header Set-Cookie $auth_cookie;\n\n        auth_request_set $auth_cookie_name_upstream_1 $upstream_cookie_auth_cookie_name_1;\n\n        if ($auth_cookie ~* &quot;(; .*)&quot;) {\n            set $auth_cookie_name_0 $auth_cookie;\n            set $auth_cookie_name_1 &quot;auth_cookie_name_1=$auth_cookie_name_upstream_1$1&quot;;\n        }\n\n        if ($auth_cookie_name_upstream_1) {\n            add_header Set-Cookie $auth_cookie_name_0;\n            add_header Set-Cookie $auth_cookie_name_1;\n        }\n    }\n\n    location \/oauth2 {\n        proxy_pass            http:\/\/oauth2_proxy:4180;\n        proxy_set_header      Host                    $host;\n        proxy_set_header      X-Real-IP               $remote_addr;\n        proxy_set_header      X-Scheme                $scheme;\n        proxy_set_header      X-Auth-Request-Redirect $request_uri;\n    }\n\n    location = \/oauth2\/auth {\n        proxy_pass       http:\/\/oauth2_proxy:4180;\n        proxy_set_header Host             $host;\n        proxy_set_header X-Real-IP        $remote_addr;\n        proxy_set_header X-Scheme         $scheme;\n        proxy_set_header Content-Length   &quot;&quot;;\n        proxy_pass_request_body           off;\n    }\n}\n<\/code><\/pre>\n<p>My <code>docker-compose.yaml<\/code> file:<\/p>\n<pre><code>version: '3'\nservices:\n\n  db:\n    restart: always\n    image: mysql\/mysql-server:5.7.28\n    container_name: mlflow_db\n    expose:\n        - &quot;3306&quot;\n    networks:\n        - backend\n    environment:\n        - MYSQL_DATABASE=${MYSQL_DATABASE}\n        - MYSQL_USER=${MYSQL_USER}\n        - MYSQL_PASSWORD=${MYSQL_PASSWORD}\n        - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}\n    volumes:\n        - dbdata:\/var\/lib\/mysql\n\n  web:\n    restart: always\n    build: .\/mlflow\n    image: mlflow_server\n    container_name: mlflow_server\n    expose:\n        - &quot;5000&quot;\n    networks:\n        - frontend\n        - backend\n    environment:\n        - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}\n        - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}\n        - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}\n        - AWS_BUCKET_NAME=${AWS_BUCKET_NAME}\n    command: mlflow server --backend-store-uri mysql+pymysql:\/\/${MYSQL_USER}:${MYSQL_PASSWORD}@db:3306\/${MYSQL_DATABASE} --default-artifact-root s3:\/\/redacted\/mlflow\/ --host 0.0.0.0\n\n  oauth2_proxy:\n    build: .\/oauth2_proxy\n    container_name: oauth2_proxy\n    environment:\n      - OAUTH2_PROXY_HTTP_ADDRESS=http:\/\/0.0.0.0:4180\n      - OAUTH2_PROXY_UPSTREAM=http:\/\/localhost\n      # Restrictions (Not use in same time)\n      - OAUTH2_PROXY_AUTHENTICATED_EMAILS_FILE=\/home\/emails.txt\n      # - OAUTH2_PROXY_EMAIL_DOMAINS=*  \n      # Same url in Github Callback URL\n      - OAUTH2_PROXY_REDIRECT_URL=http:\/\/localhost\/oauth2\/callback\n      # Generate secret -&gt; python -c 'import os,base64; print(base64.urlsafe_b64encode(os.urandom(32)))'\n      - OAUTH2_PROXY_COOKIE_SECRET=redacted\n      - OAUTH2_PROXY_COOKIE_SECURE=false\n      - OAUTH2_PROXY_COOKIE_REFRESH=2h\n      - OAUTH2_PROXY_PASS_ACCESS_TOKEN=true\n      #- OAUTH2_PROXY_SET_AUTHORIZATION_HEADER=true\n      #- OAUTH2_PROXY_SET_XAUTHREQUEST=true\n      - OAUTH2_PROXY_PROVIDER=google\n      - OAUTH2_PROXY_SKIP_JWT_BEARER_TOKENS=true\n      - OAUTH2_EXTRA_JWT_ISSUERS=redacted\n      # Github CLIENT_ID and CLIENT_SECRET\n      - OAUTH2_PROXY_CLIENT_ID=redacted\n      - OAUTH2_PROXY_CLIENT_SECRET=redacted\n    networks:\n      - frontend\n\n  nginx:\n    build: .\/nginx\n    container_name: nginx\n    ports:\n      - 80:80\n    depends_on:\n      - oauth2_proxy\n    networks:\n      - frontend\n\nnetworks:\n    frontend:\n        driver: bridge\n    backend:\n        driver: bridge\n\nvolumes:\n    dbdata:\n<\/code><\/pre>\n<p>Any thoughts about it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-22 19:34:59.467 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"docker|nginx|oauth|mlflow|oauth2-proxy",
        "Question_view_count":346,
        "Owner_creation_date":"2017-03-13 23:00:52.21 UTC",
        "Owner_last_access_date":"2022-09-24 22:39:47.647 UTC",
        "Owner_reputation":344,
        "Owner_up_votes":16,
        "Owner_down_votes":3,
        "Owner_views":79,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72721109",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72013380,
        "Question_title":"Automatic flavor detection with ml_flow load_model?",
        "Question_body":"<p>I am using mlflow and want to handle different flavors (e.g. <code>sklearn<\/code> , <code>tensorflow<\/code> and <code>keras<\/code>) while loading.<\/p>\n<p>Actually I only find the information about the stored <code>flavor<\/code> as string in<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>Run.to_dictionary()['data']['tags']['mlflow.log-model.history']\n<\/code><\/pre>\n<p>output:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>[{&quot;run_id&quot;: &quot;8ea47843f7b446828dbd9cd3a1ed2339&quot;, &quot;artifact_path&quot;: &quot;model&quot;, &quot;utc_time_created&quot;: &quot;2022-04-26 10:39:55.639791&quot;, &quot;flavors&quot;: {&quot;keras&quot;: {&quot;keras_module&quot;: &quot;tensorflow.keras&quot;, &quot;keras_version&quot;: &quot;2.7.0&quot;, &quot;save_format&quot;: &quot;tf&quot;, &quot;data&quot;: &quot;data&quot;, &quot;code&quot;: null}, &quot;python_function&quot;: {&quot;loader_module&quot;: &quot;mlflow.keras&quot;, &quot;python_version&quot;: &quot;3.8.10&quot;, &quot;data&quot;: &quot;data&quot;, &quot;env&quot;: &quot;conda.yaml&quot;}}, &quot;model_uuid&quot;: &quot;3bd37bdb0aa1409aabc65f8314018642&quot;, &quot;mlflow_version&quot;: &quot;1.25.1&quot;}]\n<\/code><\/pre>\n<p>Run is the <code>mlflow.entities.Run<\/code> object.<\/p>\n<p>Using <code>ast.literal_eval<\/code> to transform the string into the dictionary fails.<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>ast.literal_eval(str(self.run.to_dictionary()['data']['tags']['mlflow.log-model.history'][1:-1]))\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-04-26 11:46:38.64 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|tensorflow|keras|mlflow",
        "Question_view_count":75,
        "Owner_creation_date":"2014-12-23 23:50:02.193 UTC",
        "Owner_last_access_date":"2022-09-21 11:10:16 UTC",
        "Owner_reputation":1499,
        "Owner_up_votes":98,
        "Owner_down_votes":14,
        "Owner_views":297,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72013380",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70962095,
        "Question_title":"what is the difference between Duration, TT (Training Time), RunTime on ML Performance Report of mlflow",
        "Question_body":"<p>I compared the performance of machine learning algorithms by applying pycaret and k-fold on a data and reported it on mlflow. There are three time columns in the report, these are duration, TT(training time) and runtime. When I look at these times, they are all different from each other. I know the training time, but what are the other times?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-02-02 19:57:48.733 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-02-02 20:54:32.06 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|classification|mlflow|pycaret",
        "Question_view_count":54,
        "Owner_creation_date":"2022-01-12 22:39:42.437 UTC",
        "Owner_last_access_date":"2022-03-29 11:38:22.727 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70962095",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68437218,
        "Question_title":"How do I load spark config for mlflow-experiment on local environment?",
        "Question_body":"<p>I could find loading mlflow experiment format would be as easy as<\/p>\n<p><code>df = spark.read.format(&quot;mlflow-experiment&quot;).load()<\/code><\/p>\n<p>But how do I load the spark config?\nCalling mlflow-experiment would give me<\/p>\n<pre><code>: java.lang.ClassNotFoundException: Failed to find data source: mlflow-experiment. Please find packages at http:\/\/spark.apache.org\/third-party-projects.html\n<\/code><\/pre>\n<p>I tried to add <code>.config(&quot;spark.jars.packages&quot;, &quot;org.mlflow.mlflow-spark&quot;)<\/code> but this does not work either.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2021-07-19 08:16:00.36 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"apache-spark|pyspark|apache-spark-sql|mlflow",
        "Question_view_count":130,
        "Owner_creation_date":"2018-07-11 04:45:22.687 UTC",
        "Owner_last_access_date":"2022-09-20 12:29:15.74 UTC",
        "Owner_reputation":415,
        "Owner_up_votes":83,
        "Owner_down_votes":0,
        "Owner_views":193,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68437218",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70111193,
        "Question_title":"How can I load the latest model version from MLflow model registry?",
        "Question_body":"<p>I can load a specific version of a model using the mlflow client:<\/p>\n<pre><code>import mlflow\n\nmodel_version = 1\n\nmodel = mlflow.pyfunc.load_model(\n    model_uri=f&quot;models:\/c3760a15e6ac48f88ad7e5af940047d4\/{model_version}&quot;\n)\n<\/code><\/pre>\n<p>But is there a way to load the latest model version?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-11-25 12:32:21.287 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-11-25 14:31:27.89 UTC",
        "Question_score":3,
        "Question_tags":"mlflow",
        "Question_view_count":1873,
        "Owner_creation_date":"2012-10-24 12:12:59.277 UTC",
        "Owner_last_access_date":"2022-09-25 05:49:23.95 UTC",
        "Owner_reputation":3126,
        "Owner_up_votes":1817,
        "Owner_down_votes":2,
        "Owner_views":262,
        "Answer_body":"<p>There is no such thing, like load <code>latest<\/code>, but:<\/p>\n<ul>\n<li>You can specify the stage (<code>staging<\/code>, <code>production<\/code>) - see <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/concepts.html#referencing-artifacts\" rel=\"nofollow noreferrer\">docs<\/a><\/li>\n<li>You can find latest version using the <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.tracking.html#mlflow.tracking.MlflowClient.get_latest_versions\" rel=\"nofollow noreferrer\">get_latest_versions<\/a> function - but it will also return latest per stage<\/li>\n<\/ul>\n<p>So you need to define what <code>latest<\/code> means for you.<\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2021-11-25 15:13:20.393 UTC",
        "Answer_score":2.0,
        "Owner_location":"Leuven, Belgium",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70111193",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61635540,
        "Question_title":"Mlflow tutorial issue",
        "Question_body":"<p>I am trying <a href=\"https:\/\/mlflow.org\/docs\/latest\/quickstart.html\" rel=\"nofollow noreferrer\">this quickstart tutorial<\/a> but I have troubles with the serving phase<\/p>\n\n<p>I issued the command<\/p>\n\n<pre><code>         mlflow models serve -m runs:\/c94c36bb6c0c48a2a7c895d93ec1866f\/model\n<\/code><\/pre>\n\n<p>I get the following<\/p>\n\n<pre><code>2020\/05\/06 14:04:33 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n\n2020\/05\/06 14:04:35 INFO mlflow.projects: === Creating conda environment mlflow 4133253245e67fa1d3bbd74212a1eb60c04fbc0a ===\n\nCollecting package metadata (repodata.json): done\n\nSolving environment: failed\n\nResolvePackageNotFound:\n\nscikit-learn=0.22.2.post1\n<\/code><\/pre>\n\n<p>It seems conda cannot find this version of scikit-learn<\/p>\n\n<p>I have installed <a href=\"https:\/\/repo.anaconda.com\/archive\/Anaconda3-2020.02-Linux-x86_64.sh\" rel=\"nofollow noreferrer\">https:\/\/repo.anaconda.com\/archive\/Anaconda3-2020.02-Linux-x86_64.sh<\/a><\/p>\n\n<p>Please help me,<\/p>\n\n<p>Aurel<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":14,
        "Question_creation_date":"2020-05-06 12:42:38.953 UTC",
        "Question_favorite_count":0.0,
        "Question_last_edit_date":"2020-05-06 12:43:36.247 UTC",
        "Question_score":0,
        "Question_tags":"python|anaconda|mlflow",
        "Question_view_count":295,
        "Owner_creation_date":"2011-04-20 12:45:41.213 UTC",
        "Owner_last_access_date":"2022-09-21 09:13:14.577 UTC",
        "Owner_reputation":161,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":27,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61635540",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72938327,
        "Question_title":"How do I setup the _SERVER_MODEL_PATH variable?",
        "Question_body":"<p>I'm trying to replicate the quickstart save and serve example.\nI go to the example folder, run the python script and can see the model runs and artifacts when I type <code>mlflow ui<\/code>.\nHowever, when I try the mlflow serve command with different model run Ids and ports I get a 404 in my browser, even though the command seems successful:<\/p>\n<pre><code>mlflow models serve -m runs:\/e1dabe8fc6e84286af5bee28ca89cdde\/model --port 1234\n2022\/07\/11 07:40:01 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n2022\/07\/11 07:40:02 INFO mlflow.utils.conda: Conda environment mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 already exists.\n2022\/07\/11 07:40:02 INFO mlflow.pyfunc.backend: === Running command 'conda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 &amp; waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app'\nINFO:waitress:Serving on http:\/\/127.0.0.1:1234\n<\/code><\/pre>\n<p>I tried running directly from anaconda prompt, and I get the following error:<\/p>\n<pre><code>conda activate mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4 &amp; waitress-serve --host=127.0.0.1 --port=1234 --ident=mlflow mlflow.pyfunc.scoring_server.wsgi:app\n\nTraceback (most recent call last):\nFile &quot;C:\\Users\\sergio ferro.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py&quot;, line 197, in _run_module_as_main\nreturn _run_code(code, main_globals, None,\n\nFile &quot;C:\\Users\\sergio ferro.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\runpy.py&quot;, line 87, in run_code\nexec(code, run_globals)\n\nFile &quot;C:\\Users\\sergio ferro.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\Scripts\\waitress-serve.exe_main.py&quot;, line 7, in\n\nFile &quot;C:\\Users\\sergio ferro.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py&quot;, line 283, in run\napp = resolve(module, obj_name)\n\nFile &quot;C:\\Users\\sergio ferro.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\waitress\\runner.py&quot;, line 218, in resolve\nobj = import(module_name, fromlist=segments[:1])\n\nFile &quot;C:\\Users\\sergio ferro.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\site-packages\\mlflow\\pyfunc\\scoring_server\\wsgi.py&quot;, line 6, in\napp = scoring_server.init(load_model(os.environ[scoring_server._SERVER_MODEL_PATH]))\n\nFile &quot;C:\\Users\\sergio ferro.conda\\envs\\mlflow-ddf4db606beaa0e9bb42ff0ed98e8f4c4c7cb1f4\\lib\\os.py&quot;, line 679, in getitem\nraise KeyError(key) from None\nKeyError: 'pyfunc_model_path'\n<\/code><\/pre>\n<p>I have tried deleting and creating a new anaconda environment, ran from git bash, anaconda prompt, added anaconda3 environment variables. I know it has something to do with the <code>_SERVER_MODEL_PATH<\/code> variable but I wouldn't know how to set it up or which path add to my environment variables so it can read this variable from there.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2022-07-11 12:06:46.68 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-07-24 11:12:09.07 UTC",
        "Question_score":0,
        "Question_tags":"anaconda|mlflow",
        "Question_view_count":14,
        "Owner_creation_date":"2017-03-21 14:16:28.373 UTC",
        "Owner_last_access_date":"2022-09-20 12:01:20.917 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72938327",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69366816,
        "Question_title":"what are the events (ex MODEL_VERSION_CREATED) associated with ML FLow Databricks CI\/CD",
        "Question_body":"<p>ML Flow has multiple events to subscribe like MODEL_VERSION_CREATED when a model version is created. what are the other events available to subscribe.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-09-28 18:27:45.547 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"databricks|azure-databricks|mlflow",
        "Question_view_count":26,
        "Owner_creation_date":"2013-06-12 10:44:50.553 UTC",
        "Owner_last_access_date":"2021-11-16 16:58:46.133 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69366816",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":61644716,
        "Question_title":"MlflowException: API request to ...URL... failed to return code 200 after 3 tries",
        "Question_body":"<p>I am currently trying to track my machine learning model metrics using the MLFlow API in Azure Databricks.<\/p>\n\n<p>I registered the experiment under my team's machine learning workspace and had tried a few metric log commands that worked but were simply used as a test.<\/p>\n\n<p>My notebook ran a for loop logging metrics per calculation within the loop.\nIt took a while (3-5 seconds) before sending out the error.<\/p>\n\n<p>I tried to look at the experiment metrics and it seems to have logged a bit of the for loop's metrics before crashing.<\/p>\n\n<p>Not sure as to why it does it and now it throws the exception to my earlier test calls to log metrics.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2020-05-06 20:25:38.017 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"azure-databricks|mlflow|azure-machine-learning-service",
        "Question_view_count":696,
        "Owner_creation_date":"2019-10-19 18:12:14.813 UTC",
        "Owner_last_access_date":"2020-08-17 16:11:58.507 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":0,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/61644716",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73591190,
        "Question_title":"MLFlow & Conda: store envs in project dir instead of ~\/opt\/anaconda3\/envs",
        "Question_body":"<p>As per conda's <a href=\"https:\/\/docs.conda.io\/projects\/conda\/en\/latest\/user-guide\/tasks\/manage-environments.html#id3\" rel=\"nofollow noreferrer\">documentation<\/a>:<\/p>\n<blockquote>\n<p>You can control where a conda environment lives by providing a path to a target directory when creating the environment. [...]:\n<code>conda create --prefix .\/envs jupyterlab=3.2 matplotlib=3.5 numpy=1.21<\/code><\/p>\n<\/blockquote>\n<p>Is it possible to modify how mlflow invoques <code>conda create<\/code> when generating all the components' environments, in order save those at the root of the project instead of the default <code>...\/anaconda3\/envs<\/code> ?<\/p>\n<p>Many thanks in advance for your help,<br \/>\nKind regards<br \/>\nMarc<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-03 09:41:14.837 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-03 09:42:54.733 UTC",
        "Question_score":0,
        "Question_tags":"conda|mlflow|anaconda3",
        "Question_view_count":18,
        "Owner_creation_date":"2020-08-30 09:51:48.953 UTC",
        "Owner_last_access_date":"2022-09-25 05:43:43.343 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73591190",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58871771,
        "Question_title":"MLflow run example gives me CommandNotFoundError",
        "Question_body":"<p>I was trying to run the mlflow run exercise in the anaconda prompt, and it keeps giving me the error.\nI'm using mlflow version 1.40, and the code above works fine if I execute it with --no-conda <\/p>\n\n<p><code>mlflow run https:\/\/github.com\/mlflow\/mlflow-example -P alpha=0.5<\/code> - doesn't work<\/p>\n\n<p><code>mlflow run https:\/\/github.com\/mlflow\/mlflow-example -P alpha=0.5 --no-conda<\/code> - works<\/p>\n\n<p>It gives me the error when activating the conda environment. The specific conda environment works fine if I manually activate it. It just doesn't work within the mlflow command. <\/p>\n\n<p><img src=\"https:\/\/i.stack.imgur.com\/ehUXl.png\" alt=\"capture of prompt\"><\/p>\n\n<p><a href=\"https:\/\/i.stack.imgur.com\/LjSoJ.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LjSoJ.png\" alt=\"enter image description here\"><\/a><\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2019-11-15 06:56:45.183 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2019-11-20 00:45:09.447 UTC",
        "Question_score":1,
        "Question_tags":"python|project|conda|virtual-environment|mlflow",
        "Question_view_count":251,
        "Owner_creation_date":"2018-12-29 14:34:40.583 UTC",
        "Owner_last_access_date":"2021-12-16 05:24:24.943 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":5,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58871771",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70383051,
        "Question_title":"mlflow \/ app engine error code 405 method not allowed, when using remote tracking server",
        "Question_body":"<p>I have both mlflow client and server running (both version 1.22.0).\nThe tracking server is deployed using GCP app engine.<\/p>\n<p>From the client I set the remote uri like this:<\/p>\n<pre><code>mlflow.set_tracking_uri(&quot;https:\/\/mlflow-xxx.appspot.com\/#\/&quot;)\n<\/code><\/pre>\n<p>And then I just want to run the quickstart example:<\/p>\n<pre><code>import os\nfrom random import random, randint\nfrom mlflow import log_metric, log_param, log_artifacts\n\nif __name__ == &quot;__main__&quot;:\n    # Log a parameter (key-value pair)\n    log_param(&quot;param1&quot;, randint(0, 100))\n\n    # Log a metric; metrics can be updated throughout the run\n    log_metric(&quot;foo&quot;, random())\n    log_metric(&quot;foo&quot;, random() + 1)\n    log_metric(&quot;foo&quot;, random() + 2)\n\n    # Log an artifact (output file)\n    if not os.path.exists(&quot;outputs&quot;):\n        os.makedirs(&quot;outputs&quot;)\n    with open(&quot;outputs\/test.txt&quot;, &quot;w&quot;) as f:\n        f.write(&quot;hello world!&quot;)\n    log_artifacts(&quot;outputs&quot;)\n<\/code><\/pre>\n<p>However, I get 405 method not allowed error:<\/p>\n<pre><code>Traceback (most recent call last):\n  File &quot;mlflow_test.py&quot;, line 7, in &lt;module&gt;\n    log_param(&quot;param1&quot;, randint(0, 100))\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 416, in log_param\n    run_id = _get_or_start_run().info.run_id\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 1311, in _get_or_start_run\n    return start_run()\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py&quot;, line 289, in start_run\n    active_run_obj = client.create_run(experiment_id=exp_id_for_run, tags=tags)\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/client.py&quot;, line 265, in create_run\n    return self._tracking_client.create_run(experiment_id, start_time, tags)\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/tracking\/_tracking_service\/client.py&quot;, line 108, in create_run\n    tags=[RunTag(key, value) for (key, value) in tags.items()],\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py&quot;, line 174, in create_run\n    response_proto = self._call_endpoint(CreateRun, req_body)\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/store\/tracking\/rest_store.py&quot;, line 60, in _call_endpoint\n    return call_endpoint(self.get_host_creds(), endpoint, method, json_body, response_proto)\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 229, in call_endpoint\n    response = verify_rest_response(response, endpoint)\n  File &quot;\/opt\/conda\/lib\/python3.7\/site-packages\/mlflow\/utils\/rest_utils.py&quot;, line 175, in verify_rest_response\n    raise MlflowException(&quot;%s. Response body: '%s'&quot; % (base_msg, response.text))\nmlflow.exceptions.MlflowException: API request to endpoint \/api\/2.0\/mlflow\/runs\/create failed with error code 405 != 200. Response body: '&lt;!DOCTYPE HTML PUBLIC &quot;-\/\/W3C\/\/DTD HTML 3.2 Final\/\/EN&quot;&gt;\n&lt;title&gt;405 Method Not Allowed&lt;\/title&gt;\n&lt;h1&gt;Method Not Allowed&lt;\/h1&gt;\n&lt;p&gt;The method is not allowed for the requested URL.&lt;\/p&gt;\n<\/code><\/pre>\n<p>Notes:<\/p>\n<ul>\n<li><p>If I omit the # char at the end, I get a 404 error (the requested URL was not found on this server)<\/p>\n<\/li>\n<li><p>If I run a different method (for example, get_experiment, so a GET request instead of a POST) I get a different error<\/p>\n<\/li>\n<\/ul>\n<blockquote>\n<p>mlflow.exceptions.MlflowException: API request to endpoint was\nsuccessful but the response body was not in a valid JSON format<\/p>\n<\/blockquote>\n<p>Do you have any ideas on how to solve this?\nMaybe I need to set the tracking_uri differently?<\/p>\n<p>Thank you in advance!<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2021-12-16 17:14:17.807 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"google-app-engine|http-status-code-405|mlflow",
        "Question_view_count":1070,
        "Owner_creation_date":"2021-12-16 16:49:39.263 UTC",
        "Owner_last_access_date":"2022-01-31 12:30:05.413 UTC",
        "Owner_reputation":11,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":2,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70383051",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57152695,
        "Question_title":"Unable to run mlflow ui in Jupyter",
        "Question_body":"<p>I am new to MLflow. I was trying to use it in Jupyter. As part of the quickstart, I ran the following code:<\/p>\n\n<pre><code>import os\nfrom mlflow import log_metric, log_param, log_artifact\n\nif __name__ == \"__main__\":\n    # Log a parameter (key-value pair)\n    log_param(\"param1\", 5)\n\n    # Log a metric; metrics can be updated throughout the run\n    log_metric(\"foo\", 1)\n    log_metric(\"foo\", 2)\n    log_metric(\"foo\", 3)\n\n    # Log an artifact (output file)\n    with open(\"output.txt\", \"w\") as f:\n        f.write(\"Hello world!\")\n    log_artifact(\"output.txt\")\n<\/code><\/pre>\n\n<p>which ran without any problems. However when I then typed in mlflow ui, I got the error: invalid syntax. What could I be doing wrong?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2019-07-22 19:37:33.953 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-07-22 19:39:53.66 UTC",
        "Question_score":2,
        "Question_tags":"python|mlflow",
        "Question_view_count":5356,
        "Owner_creation_date":"2017-01-16 15:48:00.953 UTC",
        "Owner_last_access_date":"2022-08-25 04:31:34.58 UTC",
        "Owner_reputation":148,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":39,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57152695",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72414899,
        "Question_title":"fastapi prediction with machine learning model from mlflow works in local but not online on Heroku",
        "Question_body":"<p>When I test my API in local it is working fine:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TXvj9.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TXvj9.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>When I test it online. It is still working fine.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/FntrH.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/FntrH.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>When I make a prediction in local; it is still working fine. It uses a model saved online on MLflow to make the prediction.<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/TIjlM.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/TIjlM.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>But when I push my API online and try the same prediction, is it not working anymore.<\/p>\n<p>When checking the status_code, I have an error 500:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/LBeYY.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/LBeYY.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>And when trying to print the answer it says:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/dOxbj.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/dOxbj.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Any idea why?<\/p>\n<p>Thank you<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_creation_date":"2022-05-28 10:33:18.743 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"heroku|fastapi|mlflow",
        "Question_view_count":99,
        "Owner_creation_date":"2015-02-08 14:10:02.997 UTC",
        "Owner_last_access_date":"2022-09-22 12:46:19.853 UTC",
        "Owner_reputation":67,
        "Owner_up_votes":9,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72414899",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59363969,
        "Question_title":"mlflow: problems with pip installation",
        "Question_body":"<p>I read through many threads regarding installation issues using pip. However, I could find a solution to help me fix my problem.\nI installed mlflow with :<\/p>\n\n<pre><code>    pip3 install mlflow\n<\/code><\/pre>\n\n<p>so mlflow is installed in \/usr\/local\/bin\/mlflow<\/p>\n\n<p>Since it is not in \/Users\/xxxx\/opt\/anaconda3\/lib\/python3.7\/site-packages, I get \"ModuleNotFoundError: No module named 'mlflow' error when I try to run code that imports mlflow module. How should I fix this?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2019-12-16 20:37:11.793 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"pip|python-import|python-3.7|importerror|mlflow",
        "Question_view_count":9843,
        "Owner_creation_date":"2018-04-26 22:59:32.553 UTC",
        "Owner_last_access_date":"2021-12-14 18:54:28.437 UTC",
        "Owner_reputation":87,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"San Francisco, CA, USA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59363969",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69088149,
        "Question_title":"MlFlow: Can't find runs using api",
        "Question_body":"<p>I try get list of runs, but get empty list.<\/p>\n<p>There are my runs:<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/v8uF2.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/v8uF2.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>But if I try get it using api:\nI expect(<a href=\"https:\/\/mlflow.org\/docs\/latest\/rest-api.html#get-experiment\" rel=\"nofollow noreferrer\">by API<\/a>) that I also watch &quot;runs&quot;, but watch &quot;experiment&quot; only<\/p>\n<pre><code>http:\/\/localhost:5000\/api\/2.0\/mlflow\/experiments\/get?experiment_id=0\n<\/code><\/pre>\n<p><a href=\"https:\/\/i.stack.imgur.com\/78a3Y.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/78a3Y.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I read in doc, that &quot;This field is deprecated. Please use the \u201cSearch Runs\u201d API to fetch runs within an experiment.&quot;, Ok, I try \u201cSearch Runs\u201d<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/EExIn.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/EExIn.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>Nothing again.<\/p>\n<p>But I try get run by id(from ui):<\/p>\n<p><a href=\"https:\/\/i.stack.imgur.com\/4eHB7.png\" rel=\"nofollow noreferrer\"><img src=\"https:\/\/i.stack.imgur.com\/4eHB7.png\" alt=\"enter image description here\" \/><\/a><\/p>\n<p>I need get list of run ids by experiment id. How can I do it?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2021-09-07 12:20:53.323 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|api|mlflow",
        "Question_view_count":306,
        "Owner_creation_date":"2018-05-07 14:07:35.273 UTC",
        "Owner_last_access_date":"2022-09-24 19:23:37.137 UTC",
        "Owner_reputation":155,
        "Owner_up_votes":34,
        "Owner_down_votes":0,
        "Owner_views":30,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Moscow, Russia",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69088149",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":58199221,
        "Question_title":"Custom python model : succeed to load but fail to predict\/serve",
        "Question_body":"<p>I have a custom python model, which basically sets up several perturbations of a scikit-learn estimator. I do succeed in running the project with <code>mlflow run project_directory<\/code> CLI, saving the model with a <code>save_model()<\/code> statement. It appears on the dashboard with <code>mlflow ui<\/code>. I can even load the saved model within my <code>main.py<\/code> script and predict on a pandas.DataFrame without any problem.<\/p>\n\n<p>My problem comes when I try to <code>mlflow models serve -m project\/models\/run_id<\/code> of <code>mlflow models predict -m project\/models\/run_id -i data.json<\/code>. I get the following error : <\/p>\n\n<p><code>ModuleNotFoundError: No module named 'multi_model'<\/code><\/p>\n\n<p>In the MLflow documentation, there is no example of a custom model served, so I can't figure out how to solve this dependency problem. Here is my project tree :<\/p>\n\n<pre><code>project\/\n\u251c\u2500\u2500 MLproject\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 conda.yaml\n\u251c\u2500\u2500 loader.py\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 models\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 0ef267b0c9784a118290fa1ff579adbe\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 MLmodel\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 conda.yaml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 python_model.pkl\n\u251c\u2500\u2500 multi_model.py\n<\/code><\/pre>\n\n<p><code>multi_model.py<\/code> :<\/p>\n\n<pre><code>import numpy as np\nfrom mlflow.pyfunc import PythonModel\nfrom sklearn.base import clone\n\nclass MultiModel(PythonModel):\n\n    def __init__(self, estimator=None, n=10):\n        self.n = n\n        self.estimator = estimator\n\n    def fit(self, X, y=None):\n        self.estimators = []\n        for i in range(self.n):\n            e = clone(self.estimator)\n            e.set_params(random_state=i)\n            X_bootstrap = X.sample(frac=1, replace=True, random_state=i)\n            y_bootstrap = y.sample(frac=1, replace=True, random_state=i)\n            e.fit(X_bootstrap, y_bootstrap)\n            self.estimators.append(e)\n        return self\n\n    def predict(self, context, X):\n        return np.stack([\n            np.maximum(0, self.estimators[i].predict(X))\n            for i in range(self.n)], axis=1\n        )\n<\/code><\/pre>\n\n<p><code>main.py<\/code> :<\/p>\n\n<pre><code>import os\nimport click\nfrom sklearn.ensemble import RandomForestRegressor\nimport mlflow.pyfunc\nimport multi_model\n\n@click(...) # define the click options according to MLproject file\ndef run(next_week, window_size, nfold):\n    train = loader.load(start_week, current_week)\n    x_train, y_train = train.drop(columns=['target']), train['target']\n\n    model = multi_model.MultiModel(RandomForestRegressor())\n\n    with mlflow.start_run() as run:\n        model.fit(x_train, y_train)\n        model_path = os.path.join('models', run.info.run_id)\n        mlflow.pyfunc.save_model(\n            path=model_path, \n            python_model=model,\n        )\n\nif __name__ == '__main__':\n    run()\n<\/code><\/pre>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2019-10-02 09:53:55.003 UTC",
        "Question_favorite_count":2.0,
        "Question_last_edit_date":null,
        "Question_score":7,
        "Question_tags":"mlflow",
        "Question_view_count":4972,
        "Owner_creation_date":"2015-10-02 08:45:49.683 UTC",
        "Owner_last_access_date":"2020-01-20 15:50:37.903 UTC",
        "Owner_reputation":247,
        "Owner_up_votes":69,
        "Owner_down_votes":0,
        "Owner_views":7,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/58199221",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73716706,
        "Question_title":"Using MLFlow for commercial use",
        "Question_body":"<p>It seems that from April 2020, we cannot use anaconda for &quot;commercial use&quot; meaning for example (organizations with more than 200 employees for example)<\/p>\n<p>Since MLFlow seems to use yaml files that contain allusions to conda, how is the situation with MLFlow?<\/p>\n<p>Can MLFlow be used for commercial use?<\/p>\n<p>Note: This question <em>is<\/em> about programming since I intend to use MLFlow in our programs and I have to decide if we can or not<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-14 12:16:23.36 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"anaconda|mlflow",
        "Question_view_count":21,
        "Owner_creation_date":"2015-01-14 01:17:49.333 UTC",
        "Owner_last_access_date":"2022-09-24 09:09:14.427 UTC",
        "Owner_reputation":5585,
        "Owner_up_votes":792,
        "Owner_down_votes":53,
        "Owner_views":1350,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73716706",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69203653,
        "Question_title":"MLFlow Pytorch Model",
        "Question_body":"<p>I have a trained Yolo model and is in model.pt format, I am able to upload the model to create an artifact in mlflow. However, when I look at the yaml file it has a few dependencies listed. I am sure that I am loading in the wrong way.<\/p>\n<p>channels:<\/p>\n<ul>\n<li>conda-forge\ndependencies:<\/li>\n<li>python=3.6.13<\/li>\n<li>pip<\/li>\n<li>pip:\n**- mlflow\n<ul>\n<li>scikit-learn==0.24.2<\/li>\n<li>cloudpickle==1.6.0**\nname: mlflow-env<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<p>Anybody, please let me know how to use pre-trained model to push it to mlflow to create artifact and then containerize dependency(docker) to push to AWS ECR<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_creation_date":"2021-09-16 06:54:00.45 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"amazon-web-services|data-science|amazon-ecr|mlflow|mlops",
        "Question_view_count":92,
        "Owner_creation_date":"2021-08-31 13:27:02.787 UTC",
        "Owner_last_access_date":"2022-02-25 18:47:26.297 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69203653",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":62754017,
        "Question_title":"Save customized function inside function in MLFlow log_model",
        "Question_body":"<p>I would like to do something with MLFlow but I do not find any solution on Internet. I am working with MLFlow and R, and I want to save a regression model. The thing is that by the time I want to predict the testing data, I want to do some transformation of that data. Then I have:<\/p>\n<pre class=\"lang-r prettyprint-override\"><code>data &lt;- #some data with numeric regressors and dependent variable called 'y'\n\n# Divide into train and test\nind &lt;- sample(nrow(data), 0.8*nrow(data), replace = FALSE)\ndataTrain &lt;- data[ind,]\ndataTest &lt;- data[-ind,]\n\n# Run model in the mlflow framework\nwith(mlflow_start_run(), {\n   model &lt;- lm(y ~ ., data = dataTrain)\n   \n   predict_fun &lt;- function(model, data_to_predict){\n       data_to_predict[,3] &lt;- data_to_predict[,3]\/2\n       data_to_predict[,4] &lt;- data_to_predict[,4] + 1\n\n       return(predict(model, data_to_predict))\n       }\n\n   predictor &lt;- crate(~predict_fun(model,dataTest),model)\n\n   ### Some code to use the predictor to get the predictions and measure the accuracy as a log_metric\n   ##################\n   ##################\n   ##################\n\n   mlflow_log_model(predictor,'model')\n}\n<\/code><\/pre>\n<p>As you can notice, my prediction function not only consists in predict the new data you are evaluating, but it also makes some transformations in the third and fourth columns. All examples I saw on the web use the function predict in the <em>crate<\/em> as the default function of R.<\/p>\n<p>Once I save this model, when I run it in another notebook with some Test data, I get the error: <em>&quot;predict_fun&quot; doesn't exist<\/em>. That is because my algorithm has not saved this specific function. Do you know what can I do to save and specific prediction function that I have created instead of the default functions that are in R?<\/p>\n<p>This is not the real example I am working with, but it is an approximation of it. The fact is that I want to save extra functions apart from the model itself.<\/p>\n<p>Thank you very much!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_creation_date":"2020-07-06 10:22:26.863 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"r|predict|mlflow",
        "Question_view_count":140,
        "Owner_creation_date":"2019-09-09 07:55:57.07 UTC",
        "Owner_last_access_date":"2022-01-17 12:39:33.287 UTC",
        "Owner_reputation":61,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":13,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/62754017",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72723433,
        "Question_title":"Does MLflow support darknet framework?",
        "Question_body":"<p>I am learning yolov4 with darknet and using that model for service development.<\/p>\n<p>However, I want to track and manage the performance metric of the model.<\/p>\n<p>So, I've heard of MLflow Tracking and am looking into it.<\/p>\n<p>Does MLflow support darknet?<\/p>\n<p>If so, is there a tracking management tool for using darknet?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-06-23 00:57:36.957 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"yolo|mlflow|darknet",
        "Question_view_count":85,
        "Owner_creation_date":"2019-01-02 00:12:28.563 UTC",
        "Owner_last_access_date":"2022-09-02 00:41:48.337 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":1,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72723433",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57179575,
        "Question_title":"Assume IAM Role to store MLFlow Artifact on S3 bucket in another account",
        "Question_body":"<p>I have to save my MLFlow artifacts (using Databricks Unified Analytics) to a S3 bucket, with service-side encrpytion using a KMS key.<\/p>\n\n<p>My instances are into an AWS account A, my S3 bucket and my KMS key into an account B. I can't have my KMS Key into my account A.<\/p>\n\n<p>I don't want to use DBFS to mount S3 buckets, for security reasons (buckets can contains sensitive data and I don't want to share this between users).<\/p>\n\n<p>I have to assume an IAM role in order to access the bucket, as I did to access it through s3a (with <code>spark.hadoop.fs.s3a.credentialsType<\/code> and <code>spark.hadoop.fs.s3a.stsAssumeRole.arn<\/code> parameters).<\/p>\n\n<p>When I create an experiment with s3 and try to log a model like this : <\/p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import mlflow\nimport mlflow.sklearn\nid_exp = mlflow.create_experiment(\"\/Users\/first.last@company.org\/Experiment\",'s3:\/\/s3-bucket-name\/')\nwith mlflow.start_run(experiment_id=id_exp):\n  clf_mlf = tree.DecisionTreeClassifier()\n  clf_mlf = clf_mlf.fit(X_train, y_train)\n  y_pred = clf_mlf.predict(X_test)\n  mlflow.sklearn.log_model(clf_mlf, \"model\", serialization_format='pickle')\n<\/code><\/pre>\n\n<p>I have this error : <\/p>\n\n<pre><code>S3UploadFailedError: Failed to upload \/tmp\/tmp2yl2olhi\/model\/conda.yaml to s3-bucket-name\/\/05c17a33a33d46a5ad3cc811a9faf35a\/artifacts\/model\/conda.yaml: An error occurred (KMS.NotFoundException) when calling the PutObject operation: Key 'arn:aws:kms:eu-central-1:account_a_id:key\/key_id' does not exist\n<\/code><\/pre>\n\n<p>How can I told MLFlow to assume a role before accessing to S3 ?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2019-07-24 09:27:00.5 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"amazon-s3|amazon-iam|databricks|mlflow",
        "Question_view_count":693,
        "Owner_creation_date":"2018-03-13 17:58:54.917 UTC",
        "Owner_last_access_date":"2020-11-03 18:13:09.453 UTC",
        "Owner_reputation":31,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57179575",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":68753631,
        "Question_title":"Combine MLflow projects with docker-compose",
        "Question_body":"<p>I face the following situation:<\/p>\n<p>We train our models within docker container, which is build by running a docker-compose file. I have implemented MLflow to work with docker-compose (by doing something similar to e.g. this post: <a href=\"https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039\" rel=\"nofollow noreferrer\">https:\/\/towardsdatascience.com\/deploy-mlflow-with-docker-compose-8059f16b6039<\/a>), creating two more containers (one for the server and one for the postgresql backend).<\/p>\n<p>However, the story doesn't end here. Our goal is to implement a full ML pipeline, which includes data creation, preprocessing steps and so on. I know, that ML projects is something which helps to create such pipeline. I have seen that it is designed to work with docker images (<a href=\"https:\/\/www.mlflow.org\/docs\/latest\/projects.html\" rel=\"nofollow noreferrer\">https:\/\/www.mlflow.org\/docs\/latest\/projects.html<\/a>), but I don't get it, how one could use it with docker-compose.<\/p>\n<p>Could you help me in that by giving any tipps, guidelines, documentations, etc?<\/p>\n<p>Or in general, any advice, how a full machine learning pipeline could be implemented using mlflow?<\/p>\n<p>Thanks a lot!<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-08-12 07:58:26.943 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2021-08-12 13:31:50.07 UTC",
        "Question_score":1,
        "Question_tags":"machine-learning|docker-compose|pipeline|mlflow",
        "Question_view_count":1007,
        "Owner_creation_date":"2017-12-06 14:53:51.753 UTC",
        "Owner_last_access_date":"2022-06-23 07:16:10.68 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":14,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/68753631",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73643715,
        "Question_title":"ValueError: Enum ErrorCode has no value defined for name '403' in mlflow.set_experiment()",
        "Question_body":"<p>I am trying to run some code to train a model, while logging my results to MLflow on Databricks. I keep getting the following error when I try to make a call to <code>mlflow.set_experiment()<\/code>,<\/p>\n<pre><code>    raise ValueError('Enum {} has no value defined for name {!r}'.format(\nValueError: Enum ErrorCode has no value defined for name '403'\n<\/code><\/pre>\n<p>What exactly is going on here?<\/p>\n<p>I am using Databricks Connect to run my code and the section where the error pops up looks like this,<\/p>\n<pre><code>    # set remote tracking server URI\n    mlflow.set_tracking_uri(remote_server_uri)\n\n    # create the MLflow client\n    client = MlflowClient(remote_server_uri)\n\n    # set experiment to log mlflow runs\n    mlflow.set_experiment(experiment_name)\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-09-08 04:25:26.99 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-09-08 08:21:53.963 UTC",
        "Question_score":1,
        "Question_tags":"python|mlflow|databricks-connect",
        "Question_view_count":68,
        "Owner_creation_date":"2018-03-24 01:53:05.82 UTC",
        "Owner_last_access_date":"2022-09-24 16:46:35.903 UTC",
        "Owner_reputation":820,
        "Owner_up_votes":389,
        "Owner_down_votes":1,
        "Owner_views":165,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Sri Lanka",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73643715",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70338955,
        "Question_title":"Use an Azure ML compute cluster to run Kedro + Mlflow pipeline",
        "Question_body":"<p>I want to use an Azure Machine Learning compute cluster as a compute target to run a Kedro pipeline integrated with Mlflow.<\/p>\n<p>Here's the code snippet (hooks.py) that integrates experiment tracking using Mlflow and Azure ML as backend\/artifact stores.<\/p>\n<pre><code>&quot;&quot;&quot;Project hooks.&quot;&quot;&quot;\nfrom typing import Any, Dict, Iterable, Optional\nimport git\nimport os\nimport mlflow\nimport mlflow.sklearn\nfrom kedro.config import ConfigLoader\nfrom kedro.framework.hooks import hook_impl\nfrom kedro.io import DataCatalog\nfrom kedro.pipeline.node import Node\nfrom kedro.versioning import Journal\nfrom azureml.core import Workspace\nfrom azureml.core.experiment import Experiment\n\nclass ProjectHooks:\n    @hook_impl\n    def register_config_loader(\n        self,\n        conf_paths: Iterable[str],\n        env: str,\n        extra_params: Dict[str, Any],\n    ) -&gt; ConfigLoader:\n        return ConfigLoader(conf_paths)\n\n    @hook_impl\n    def register_catalog(\n        self,\n        catalog: Optional[Dict[str, Dict[str, Any]]],\n        credentials: Dict[str, Dict[str, Any]],\n        load_versions: Dict[str, str],\n        save_version: str,\n        journal: Journal,\n    ) -&gt; DataCatalog:\n        return DataCatalog.from_config(\n            catalog, credentials, load_versions, save_version, journal\n        )\n\n\nclass ModelTrackingHooks:\n    &quot;&quot;&quot;Namespace for grouping all model-tracking hooks with MLflow together.&quot;&quot;&quot;\n\n    @hook_impl\n    def before_pipeline_run(self, run_params: Dict[str, Any]) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to start an MLflow run\n        with the same run_id as the Kedro pipeline run.\n        &quot;&quot;&quot;\n\n        # Get Azure workspace\n        ws = Workspace.get(name=workspace_name,\n                           subscription_id=subscription_id,\n                           resource_group=resource_group)\n\n        # Set tracking uri\n        mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n\n        # Create an Azure ML experiment in the workspace\n        experiment = Experiment(workspace=ws, name='kedro-mlflow-experiment')\n        mlflow.set_experiment(experiment.name)\n\n        mlflow.start_run(run_name=run_params[&quot;run_id&quot;])\n        mlflow.log_params(run_params)\n\n    @hook_impl\n    def after_node_run(\n        self, node: Node, outputs: Dict[str, Any], inputs: Dict[str, Any]\n    ) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to add model tracking after some node runs.\n        In this example, we will:\n        * Log the parameters after the data splitting node runs.\n        * Log the model after the model training node runs.\n        * Log the model's metrics after the model evaluating node runs.\n        &quot;&quot;&quot;\n        if node._func_name == &quot;function_name&quot;:\n            mlflow.log_metrics(...)\n\n    @hook_impl\n    def after_pipeline_run(self) -&gt; None:\n        &quot;&quot;&quot;Hook implementation to end the MLflow run\n        after the Kedro pipeline finishes.\n        &quot;&quot;&quot;\n        mlflow.end_run()\n<\/code><\/pre>\n<p>This works well on a <strong>compute instance<\/strong> that I created in my Azure ML workspace, simply by doing the following :<\/p>\n<ol>\n<li><code>git clone<\/code> the source code into the Azure ML compute instance<\/li>\n<li>Do a <code>kedro run<\/code> in the compute instance Terminal<\/li>\n<\/ol>\n<p>That's ok but what I really want is to use <strong>compute clusters<\/strong> to deal with hyperparameter tuning and other heavy workloads... I Just want to mention here that I still want to git clone to the compute instance and submit the run to the compute cluster from within the compute instance (but if anyone has a better approach, please feel free to share).<\/p>\n<p>I know of two ways (listed below) to specify a compute cluster as a compute target in Azure ML but both require to pass a <code>script<\/code> parameter.<\/p>\n<ol>\n<li>Pure Azure ML <code>ScriptRunConfig()<\/code> method to submit experiments by specifying <code>script<\/code> and <code>compute_target<\/code> parameters. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics\" rel=\"nofollow noreferrer\">Submit remote run with Azure Ml<\/a><\/li>\n<li>Mlflow integration with Azure ML : that requires to add an MLproject file to the project folder. See <a href=\"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-mlflow-projects\" rel=\"nofollow noreferrer\">Submit an mlflow project run<\/a>.<\/li>\n<\/ol>\n<p>I tried for quite some time now to figure out how to do that within the Kedro structure but without success. So my question here, what's the best way to push experiment runs in a Kedro Pipeline to Azure ML compute clusters?<\/p>\n<p>Thank you in advance for your help !<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_creation_date":"2021-12-13 17:56:35.97 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-12-14 08:40:44.52 UTC",
        "Question_score":1,
        "Question_tags":"python|azure|mlflow|azure-machine-learning-service|kedro",
        "Question_view_count":271,
        "Owner_creation_date":"2020-04-10 11:23:52.39 UTC",
        "Owner_last_access_date":"2022-08-12 18:19:53.33 UTC",
        "Owner_reputation":127,
        "Owner_up_votes":8,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70338955",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72162395,
        "Question_title":"Handle different runs concurrently on multiple tracking servers?",
        "Question_body":"<p>Are there any resources or insights on handling multiple tracking servers concurrently? We're trying to deploy some RESTful APIs (with FastAPI) that basically launch, potentially concurrently, multiple runs on different Tracking Servers using the MLflow Python API. We've seen that there's no clear way to explicitly assign the Tracking URI during the <code>mlflow.projects.run<\/code> function and so we're obliged to use <code>set_tracking_uri<\/code> everytime before launching the new run (which I quote &quot;does not affect the currently active run (if one exists), but takes effect for successive runs.&quot;). Problem is that it may happens that multiple runs go in conflict between each other and some random errors like <code>mlflow.exceptions.RestException: RESOURCE_DOES_NOT_EXIST<\/code> may occur.<\/p>\n<p>Is there a way to handle this use case scenario or MLflow is still too unripe to be handling multiple tracking servers on a single endpoint?<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-05-08 15:15:31.417 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"fastapi|mlflow",
        "Question_view_count":52,
        "Owner_creation_date":"2015-01-11 13:16:26.627 UTC",
        "Owner_last_access_date":"2022-09-24 16:47:22.317 UTC",
        "Owner_reputation":1065,
        "Owner_up_votes":35,
        "Owner_down_votes":0,
        "Owner_views":73,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Florence, Italy",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72162395",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":69167711,
        "Question_title":"Mlflow not running on machine",
        "Question_body":"<p>Please I am trying to run mlflow code in R after having installed it. However, after loading the library with <code>library(mlflow)<\/code> and I run <code>mlflow_log_params(&quot;foo&quot;,42)<\/code> I get the error message below printed in my console:<\/p>\n<pre><code>Error in rethrow_call(c_processx_exec, command, c(command, args), pty,  : \n  Command 'C:\/Users\/IFEANYI\/AppData\/Local\/r-miniconda\/envs\/r-mlflow-1.19.0\/mlflow' not found @win\/processx.c:982 (processx_exec)\n<\/code><\/pre>\n<p>I also get the same error message when I run <code>mlflow_ui()<\/code>. Please was there something I ought to have done during installation failure of which is affecting its functionality? Do I need to install and load the processx library in order for mlflow to run on my Windows10 machine? I really hope I can get advice to help me because I want to use mlflow in my machine learning projects. Thanks in advance of your generous help.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2021-09-13 18:48:47.983 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2021-09-14 17:21:08.23 UTC",
        "Question_score":1,
        "Question_tags":"r|machine-learning|mlflow",
        "Question_view_count":137,
        "Owner_creation_date":"2016-02-25 21:42:41.25 UTC",
        "Owner_last_access_date":"2022-09-22 21:29:37.373 UTC",
        "Owner_reputation":109,
        "Owner_up_votes":2,
        "Owner_down_votes":0,
        "Owner_views":22,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/69167711",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72238610,
        "Question_title":"how to save mlflow metrics and paramters to an s3 bucket without a server?",
        "Question_body":"<p>I want to save the parameters and metrics gotten from mlflow into an s3 bucket. Usually I get these from setting the <code>tracking_uri<\/code> in mlflow and that saves it on a server but I can't have a server in this case(was told no) and just want to store my parameters and metrics on the s3 bucket in the same manner as it would using the <code>tracking_uri<\/code>.<\/p>\n<p>I can store the artifacts on the s3 bucket without issue but not the params\/metrics.<\/p>\n<p>Here is some code:<\/p>\n<pre class=\"lang-py prettyprint-override\"><code>def mlflow_testing():\n    \n    tracking_uri =  &quot;s3:\/\/bucket_name\/mlflow\/&quot;,\n    experiment_name = &quot;test&quot;,\n    artifact_uri= &quot;s3:\/\/bucket_name\/mlflow\/&quot;\n    \n    mlflow.set_tracking_uri(tracking_uri)\n    mlflow.create_experiment(experiment_name, artifact_uri)\n    mlflow.set_experiment(experiment_name)\n    \n    with mlflow.start_run() as run:\n        mlflow.log_param(&quot;test1&quot;, 0)\n        mlflow.log_metric(&quot;test2&quot;, 1)\n    \n        with open(&quot;test.txt&quot;, &quot;w&quot;) as f:\n            f.write(&quot;this is an artifact&quot;)\n    \n        mlflow.log_artifact(&quot;test.txt&quot;)\n        mlflow.end_run()\n<\/code><\/pre>\n<p>This is capable of storing the artifact text file on the s3 bucket(so long as I make the uri a local path like <code>local_data\/mlflow<\/code> instead of the s3 bucket).<\/p>\n<p>Setting the s3 bucket for the <code>tracking_uri<\/code> results in this error:<\/p>\n<pre><code>mlflow.tracking.registry.UnsupportedModelRegistryStoreURIException:\nModel registry functionality is unavailable; got unsupported URI\n's3:\/\/bucket_location\/mlflow\/' for model registry data storage.\nSupported URI schemes are: ['', 'file', 'databricks', 'http', 'https',\n'postgresql', 'mysql', 'sqlite', 'mssql']. See\nhttps:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to\nrun an MLflow server against one of the supported backend storage\nlocations.\n<\/code><\/pre>\n<p>Does anyone have advice on getting around this without setting up a server? I just want those metrics and params.<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-05-14 08:41:29.357 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":"2022-05-14 14:14:43.397 UTC",
        "Question_score":2,
        "Question_tags":"python|amazon-s3|amazon-sagemaker|mlflow",
        "Question_view_count":818,
        "Owner_creation_date":"2021-03-17 15:21:32.347 UTC",
        "Owner_last_access_date":"2022-07-14 10:53:41.117 UTC",
        "Owner_reputation":21,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":12,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72238610",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":73469166,
        "Question_title":"Can we print the configurations on which the MLflow server has started?",
        "Question_body":"<p>I am using the following command to start the MLflow server:<\/p>\n<pre><code>mlflow server --backend-store-uri postgresql:\/\/mlflow_user:mlflow@localhost\/mlflow  --artifacts-destination &lt;S3 bucket location&gt; --serve-artifacts  -h 0.0.0.0 -p 8000\n<\/code><\/pre>\n<p>Before production deployment, we have a requirement that we need to print or fetch the under what configurations the server is running. For example, the above command uses localhost postgres connection and S3 bucket.<\/p>\n<p>Is there a way to achieve this?<\/p>\n<p>Also, how do I set the server's environment as &quot;production&quot;? So finally I should see a log like this:<\/p>\n<pre><code>[LOG] Started MLflow server:\nEnv: production\npostgres: localhost:5432\nS3: &lt;S3 bucket path&gt;\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-08-24 07:37:33.987 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2022-08-24 07:44:47.603 UTC",
        "Question_score":0,
        "Question_tags":"machine-learning|mlflow|model-management",
        "Question_view_count":17,
        "Owner_creation_date":"2017-01-15 18:29:12.247 UTC",
        "Owner_last_access_date":"2022-09-24 17:54:49.473 UTC",
        "Owner_reputation":4433,
        "Owner_up_votes":121,
        "Owner_down_votes":31,
        "Owner_views":885,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Mumbai, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/73469166",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":72715325,
        "Question_title":"ML Flow autolog with catboost",
        "Question_body":"<p>I am trying to use auto logging of ML Flow with catboost - but looking at the UI of the experiment (in Databricks UI) I don't see any parameters or metrics logged.<\/p>\n<p>My code is:<\/p>\n<pre><code>mlflow.sklearn.autolog()\nmodel_for_analytics = catboost.CatBoostRegressor(**cb_params)\nmodel_for_analytics.fit(x_train, y_train, **cb_fit_params)```\n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_creation_date":"2022-06-22 12:16:59.683 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"databricks|mlflow",
        "Question_view_count":119,
        "Owner_creation_date":"2016-03-21 08:49:39.92 UTC",
        "Owner_last_access_date":"2022-07-17 11:53:14.84 UTC",
        "Owner_reputation":383,
        "Owner_up_votes":10,
        "Owner_down_votes":0,
        "Owner_views":19,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/72715325",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":70742204,
        "Question_title":"How to add new stages\/rename a stage in MLflow",
        "Question_body":"<p>I was doing some experiments with MLflow using Python 3.7, and I was wondering if I can rename a stage or add a new one to the pre-existing<\/p>\n<blockquote>\n<p>None | Staging | Production | Archived<\/p>\n<\/blockquote>\n<p>Currently, I registered a model obtained from an experiment, but I would like to add multiple developing phases. I read the <a href=\"https:\/\/mlflow.org\/docs\/latest\/model-registry.html#concepts\" rel=\"nofollow noreferrer\">docs<\/a> concerning that part, but the only thing I've found is the following:<\/p>\n<blockquote>\n<p>Each distinct model version can be assigned one stage at any given\ntime. MLflow provides predefined stages for common use-cases such as\nStaging, Production or Archived. You can transition a model version\nfrom one stage to another stage.<\/p>\n<\/blockquote>",
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_creation_date":"2022-01-17 13:32:13.72 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|python-3.x|machine-learning|mlflow",
        "Question_view_count":212,
        "Owner_creation_date":"2021-04-28 08:36:26.397 UTC",
        "Owner_last_access_date":"2022-09-23 07:50:30.617 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/70742204",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":57550351,
        "Question_title":"MLflow 1.2.0 define MLproject file",
        "Question_body":"<p>Trying to run mlflow run by specifying MLproject and code which lives in a different location as MLproject file.<\/p>\n\n<p>I have the following directory structure:<\/p>\n\n<pre><code>\/root\/mflow_test\n.\n\u251c\u2500\u2500 conda\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 conda.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 MLproject\n\u251c\u2500\u2500 docker\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Dockerfile\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 MLproject\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 trainer\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 task.py\n    \u2514\u2500\u2500 utils.py\n<\/code><\/pre>\n\n<p>When I'm run from: <code>\/root\/<\/code><\/p>\n\n<pre><code>mlflow run mlflow_test\/docker\n<\/code><\/pre>\n\n<p>I get:<\/p>\n\n<pre><code>\/root\/miniconda3\/bin\/python: Error while finding module specification for 'trainer.task' (ImportError: No module named 'trainer')\n<\/code><\/pre>\n\n<p>Since my <code>MLproject<\/code> file can't find the Python code.\nI moved MLproject to <code>mflow_test<\/code> and this works fine.<\/p>\n\n<p>This is my MLproject entry point:<\/p>\n\n<pre><code>name: mlflow_sample\ndocker_env:\n  image: mlflow-docker-sample\nentry_points:\n  main:\n    parameters:\n      job_dir:\n        type: string\n        default: '\/tmp\/'\n    command: |\n        python -m trainer.task --job-dir {job_dir}\n<\/code><\/pre>\n\n<p>How can I run <code>mlflow run<\/code> and pass the MLproject and ask it to look in a different folder?<\/p>\n\n<p>I tried:<\/p>\n\n<pre><code>\"cd .. &amp;&amp; python -m trainer.task --job-dir {job_dir}\" \n<\/code><\/pre>\n\n<p>and I get:<\/p>\n\n<p><code>\/entrypoint.sh: line 5: exec: cd: not found<\/code><\/p>\n\n<p><strong>Dockerfile<\/strong><\/p>\n\n<pre><code># docker build -t mlflow-gcp-example -f Dockerfile .\nFROM gcr.io\/deeplearning-platform-release\/tf-cpu \nRUN git clone github.com\/GoogleCloudPlatform\/ml-on-gcp.git \nWORKDIR ml-on-gcp\/tutorials\/tensorflow\/mlflow_gcp \nRUN pip install -r requirements.txt \n<\/code><\/pre>",
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_creation_date":"2019-08-19 04:02:46.53 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-08-19 05:51:16.957 UTC",
        "Question_score":0,
        "Question_tags":"docker|databricks|mlflow",
        "Question_view_count":660,
        "Owner_creation_date":"2010-01-28 09:42:15.677 UTC",
        "Owner_last_access_date":"2022-09-25 05:06:35.287 UTC",
        "Owner_reputation":8619,
        "Owner_up_votes":1916,
        "Owner_down_votes":102,
        "Owner_views":1286,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"San Francisco, CA",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/57550351",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71679081,
        "Question_title":"How can I connect mlflow server via nginx ssl authentication?",
        "Question_body":"<p>System information\nOS Platform and Distribution: Windows 10\nMLflow installed: using pip\nMLflow version: version 1.24.0\n**Python version: Python 3.9.7 **<\/p>\n<p>Describe the problem\nI have created a docker-compose system with a backend\/artifact storages, mlflow server and nginx to add an authentication layer.<\/p>\n<pre><code>...\nmlflow:\n        restart: always\n        build: .\n        environment:\n            - AWS_ACCESS_KEY_ID=${MINIO_USR}\n            - AWS_SECRET_ACCESS_KEY=${MINIO_PASS}       \n        expose:\n            - '5000'\n        networks:\n            - frontend\n            - backend\n        depends_on:\n            - storage                       \n        image: 'mlflow:Dockerfile'\n        container_name: mlflow_server_nginx\n\n    nginx:\n        restart: always\n        build: .\/nginx\n        container_name: mlflow_nginx\n        ports:\n            - 5043:443\n        links:\n            - mlflow:mlflow\n        volumes:\n            - 'path\/to\/nginx\/auth:\/etc\/nginx\/conf.d'\n            - 'path\/to\/nginx\/nginx.conf:\/etc\/nginx\/nginx.conf:ro'\n        networks:\n            - frontend\n        depends_on:\n            - mlflow\n<\/code><\/pre>\n<p>I have created an user\/password via htpasswd and a custom SSL CA (.pem\/.key) using openssl and my-mlflow.com server-name.<\/p>\n<p>When the docker-compose system is built i can access to mlflow UI via my browser. But when i try to create a new experiment using python trying diferent approaches, i get next errors:\nExecuted code 1:<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\n#os.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n#os.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1108)')))\n<\/code><\/pre>\n<p>After read some notes in the documentation and realated issues I tryed next<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\n#os.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\nos.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4012)')))\n<\/code><\/pre>\n<p>Finally<\/p>\n<pre><code># Setting the requried environment variables\nos.environ['MLFLOW_S3_ENDPOINT_URL'] = 'https:\/\/localhost:9000'\nos.environ['AWS_ACCESS_KEY_ID'] = 'user'\nos.environ['AWS_SECRET_ACCESS_KEY'] = 'password'\n# Set username and password for added authentication\n#os.environ['MLFLOW_TRACKING_URI '] = 'https:\/\/localhost:5043\/'\n#os.environ['MLFLOW_TRACKING_USERNAME '] = 'user'\n#os.environ['MLFLOW_TRACKING_PASSWORD '] = 'password'\nos.environ['MLFLOW_TRACKING_SERVER_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n#os.environ['MLFLOW_TRACKING_CLIENT_CERT_PATH'] = 'path\/to\/nginx\/auth\/domain.pem'\n# MLflow enviroment\nremote_server_uri = &quot;https:\/\/user:password@localhost:5043\/&quot; # set to your server URI\nmlflow.set_tracking_uri(remote_server_uri)\n\nmlflow.set_experiment(&quot;MLflow_demo&quot;)\n<\/code><\/pre>\n<p>Error:<\/p>\n<pre><code>MlflowException: API request to https:\/\/user:password@localhost:5043\/api\/2.0\/mlflow\/experiments\/list failed with exception HTTPSConnectionPool(host='localhost', port=5043): Max retries exceeded with url: \/api\/2.0\/mlflow\/experiments\/list?view_type=ALL (Caused by SSLError(SSLCertVerificationError(&quot;hostname 'localhost' doesn't match '*.my-mlflow.com'&quot;)))\n<\/code><\/pre>\n<p>Can you give me some hints about how to solve it?<\/p>\n<p>Thank you very much!\nFernando....<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2022-03-30 14:25:39.347 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python-3.x|docker|nginx|docker-compose|mlflow",
        "Question_view_count":625,
        "Owner_creation_date":"2020-02-04 18:43:25.373 UTC",
        "Owner_last_access_date":"2022-09-21 20:36:53.347 UTC",
        "Owner_reputation":33,
        "Owner_up_votes":1,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":"<p>You can set:<\/p>\n<pre><code>os.environ['MLFLOW_TRACKING_INSECURE_TLS'] = 'true'\n<\/code><\/pre>\n<p>And then try to get your cert-chain straight from there for production use.<\/p>\n<p>Also see Documentation: <a href=\"https:\/\/mlflow.org\/docs\/latest\/tracking.html#id19\" rel=\"nofollow noreferrer\">https:\/\/mlflow.org\/docs\/latest\/tracking.html#id19<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2022-05-11 13:38:19.263 UTC",
        "Answer_score":0.0,
        "Owner_location":"Seville, Spain",
        "Answer_last_edit_date":"2022-05-13 13:35:43.407 UTC",
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71679081",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":60362994,
        "Question_title":"How to copy local MLflow run to remote tracking server?",
        "Question_body":"<p>I am currently tracking my MLflow runs to a local file path URI. I would also like to set up a remote tracking server to share with my collaborators. One thing I would like to avoid is to log everything to the server, as it might soon be flooded with failed runs.<\/p>\n\n<p>Ideally, I'd like to keep my local tracker, and then be able to send only the promising runs to the server.<\/p>\n\n<p>What is the recommended way of copying a run from a local tracker to a remote server?<\/p>",
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_creation_date":"2020-02-23 14:04:36.413 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":7,
        "Question_tags":"mlflow",
        "Question_view_count":611,
        "Owner_creation_date":"2017-04-14 20:16:23.87 UTC",
        "Owner_last_access_date":"2022-06-30 12:51:59.29 UTC",
        "Owner_reputation":199,
        "Owner_up_votes":132,
        "Owner_down_votes":1,
        "Owner_views":16,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/60362994",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":64513552,
        "Question_title":"How to have multiple MLFlow runs in parallel?",
        "Question_body":"<p>I'm not very familiar with parallelization in Python and I'm getting an error when trying to train a model on multiple training folds in parallel. Here's a simplified version of my code:<\/p>\n<pre><code>def train_test_model(fold):\n    # here I train the model etc...\n    \n    # now I want to save the parameters and metrics\n    with mlflow.start_run():\n        mlflow.log_param(&quot;run_name&quot;, run_name)\n        mlflow.log_param(&quot;modeltype&quot;, modeltype)\n        # and so on...\n\nif __name__==&quot;__main__&quot;:\n    pool = ThreadPool(processes = num_trials)\n    # run folds in parallel\n    pool.map(lambda fold:train_test_model(fold), folds)\n<\/code><\/pre>\n<p>I'm getting the following error:<\/p>\n<pre><code>Exception: Run with UUID 23e9bb6d22674a518e48af9c51252860 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n<\/code><\/pre>\n<p>The <a href=\"https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.start_run\" rel=\"nofollow noreferrer\">documentation<\/a> says that <code>mlflow.start_run()<\/code> starts a new run and makes it active which is the root of my problem. Every thread starts a MLFlow run for its corresponding fold and makes it active while I need the runs to run in parallel i.e. all be active(?) and save parameters\/metrics of the corresponding fold. How can I solve that issue?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-10-24 12:58:40.573 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":1,
        "Question_tags":"python|pyspark|parallel-processing|mlflow",
        "Question_view_count":2275,
        "Owner_creation_date":"2018-01-14 12:10:19.517 UTC",
        "Owner_last_access_date":"2022-09-24 19:20:31.11 UTC",
        "Owner_reputation":177,
        "Owner_up_votes":126,
        "Owner_down_votes":1,
        "Owner_views":7,
        "Answer_body":"<p>I found a solution, maybe it will be useful for someone else. You can see details with code examples here: <a href=\"https:\/\/github.com\/mlflow\/mlflow\/issues\/3592\" rel=\"nofollow noreferrer\">https:\/\/github.com\/mlflow\/mlflow\/issues\/3592<\/a><\/p>",
        "Answer_comment_count":0.0,
        "Answer_creation_date":"2020-10-28 09:26:02.673 UTC",
        "Answer_score":2.0,
        "Owner_location":null,
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/64513552",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":59881297,
        "Question_title":"How to serve custom MLflow model with Docker?",
        "Question_body":"<p>We have a project following essentially this\n<a href=\"https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/examples\/docker\" rel=\"nofollow noreferrer\">docker example<\/a> with the only difference that we created a custom model similar to <a href=\"https:\/\/www.mlflow.org\/docs\/latest\/models.html#custom-python-models\" rel=\"nofollow noreferrer\">this<\/a> whose code lies in a directory called <code>forecast<\/code>. We succeeded in running the model with <code>mlflow run<\/code>. The problem arises when we try to serve the model. After doing <\/p>\n\n<pre><code>mlflow models build-docker -m \"runs:\/my-run-id\/my-model\" -n \"my-image-name\"\n<\/code><\/pre>\n\n<p>we fail running the container with<\/p>\n\n<pre><code>docker run -p 5001:8080 \"my-image-name\"\n<\/code><\/pre>\n\n<p>with the following error:<\/p>\n\n<pre><code>ModuleNotFoundError: No module named 'forecast'\n<\/code><\/pre>\n\n<p>It seems that the docker image is not aware of the source code defining our custom model class.\nWith Conda environnement the problem does not arise thanks to the <code>code_path<\/code> argument in <code>mlflow.pyfunc.log_model<\/code>.<\/p>\n\n<p>Our Dockerfile is very basic, with just <code>FROM continuumio\/miniconda3:4.7.12, RUN pip install {model_dependencies}<\/code>.<\/p>\n\n<p>How to let the docker image know about the source code for deserialising the model and run it?<\/p>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2020-01-23 14:52:13.58 UTC",
        "Question_favorite_count":1.0,
        "Question_last_edit_date":null,
        "Question_score":3,
        "Question_tags":"docker|mlflow",
        "Question_view_count":2105,
        "Owner_creation_date":"2015-04-16 17:17:00.943 UTC",
        "Owner_last_access_date":"2022-09-10 21:14:50.857 UTC",
        "Owner_reputation":41,
        "Owner_up_votes":5,
        "Owner_down_votes":0,
        "Owner_views":20,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Paris, France",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/59881297",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":71121324,
        "Question_title":"Mlflow registed model version increment in python",
        "Question_body":"<p>I want to keep versions of the model in mlflow but not as version[1,2,3,...]\ninstead, i want to increment model's versions like 1.1 1.2 and when I feel that there is some major change I want increment to 2.0<\/p>\n<p>please let me know how this can be done.<\/p>",
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_creation_date":"2022-02-15 05:03:50.677 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":null,
        "Question_score":0,
        "Question_tags":"python|model|version-control|mlflow",
        "Question_view_count":24,
        "Owner_creation_date":"2018-01-15 08:49:21.92 UTC",
        "Owner_last_access_date":"2022-02-17 14:09:19.933 UTC",
        "Owner_reputation":1,
        "Owner_up_votes":0,
        "Owner_down_votes":0,
        "Owner_views":4,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"Arunachal Pradesh, India",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/71121324",
        "Question_exclusive_tag":"MLFlow"
    },
    {
        "Question_id":56088195,
        "Question_title":"mlflow can't find .py file",
        "Question_body":"<p>I'm trying to learn to use <code>mlflow<\/code> by creating a very simple project and log it.<\/p>\n\n<p>I've tried following <code>mlflow<\/code>'s example and my code runs properly when running the main.py as a normal bash command.<\/p>\n\n<p>I couldn't make it run using the <code>mlflow<\/code> CLI using project and a simple file.\nI got the following error.<\/p>\n\n<pre><code>(rlearning) yair@pc2016:~\/reinforced_learning101$ mlflow run src\/main.py \n2019\/05\/11 10:21:41 ERROR mlflow.cli: === Could not find main among entry points [] or interpret main as a runnable script. Supported script file extensions: ['.py', '.sh'] ===\n(rlearning) yair@pc2016:~\/reinforced_learning101$ mlflow run .\n2019\/05\/11 10:40:25 INFO mlflow.projects: === Created directory \/tmp\/tmpe26oernf for downloading remote URIs passed to arguments of type 'path' ===\n2019\/05\/11 10:40:25 INFO mlflow.projects: === Running command 'source activate mlflow-21497056aed7961402b515847613ed9f950fa9fc &amp;&amp; python src\/main.py 1.0' in run with ID 'ed51446de4c44903ab891d09cfe10e49' === \nbash: activate: No such file or directory\n2019\/05\/11 10:40:25 ERROR mlflow.cli: === Run (ID 'ed51446de4c44903ab891d09cfe10e49') failed ===\n\n<\/code><\/pre>\n\n<p>Needless to say my main has a <code>.py<\/code> suffix.<\/p>\n\n<p>Is there anything wrong that causes this issue?<\/p>\n\n<p>My main.py is:<\/p>\n\n<pre><code>import sys\n\nimport gym\nimport mlflow\n\n\nif __name__ == '__main__':\n    env = gym.make(\"CartPole-v0\")\n    right_percent = float(sys.argv[1]) if len(sys.argv) &gt; 1 else 1.0\n    with mlflow.start_run():\n        obs = env.reset()\n        print(env.action_space)\n        action = 1  # accelerate right\n        print(obs)\n        mlflow.log_param(\"right percent\", right_percent)\n        mlflow.log_metric(\"mean score\", 1)\n        mlflow.log_metric(\"std score\", 0)\n<\/code><\/pre>\n\n<p>conda_env.yaml<\/p>\n\n<pre><code>name: rlearning\nchannels:\n  - defaults\ndependencies:\n  - python=3.7\n  - numpy\n  - pandas\n  - tensorflow-gpu\n  - pip:\n      - mlflow\n      - gym\n<\/code><\/pre>\n\n<p>MLproject<\/p>\n\n<pre><code>name: reinforced learning\n\nconda_env: files\/config\/conda_environment.yaml\n\nentry_points:\n  main:\n    parameters:\n      right_percent: {type: float, default: 1.0}\n    command: \"python src\/main.py {right_percent}\"\n<\/code><\/pre>",
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_creation_date":"2019-05-11 07:32:43.29 UTC",
        "Question_favorite_count":null,
        "Question_last_edit_date":"2019-05-11 07:44:35.393 UTC",
        "Question_score":0,
        "Question_tags":"python|mlflow",
        "Question_view_count":1263,
        "Owner_creation_date":"2015-06-25 08:50:08.62 UTC",
        "Owner_last_access_date":"2022-09-08 07:19:29.283 UTC",
        "Owner_reputation":91,
        "Owner_up_votes":12,
        "Owner_down_votes":0,
        "Owner_views":44,
        "Answer_body":null,
        "Answer_comment_count":null,
        "Answer_creation_date":null,
        "Answer_score":null,
        "Owner_location":"London, UK",
        "Answer_last_edit_date":null,
        "Question_link":"https:\/\/stackoverflow.com\/questions\/56088195",
        "Question_exclusive_tag":"MLFlow"
    }
]